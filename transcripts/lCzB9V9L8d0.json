{
  "id": "l3cerszb4ea24lt6lba2erl2ti",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/lCzB9V9L8d0.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/776131 [00:00<?, ?frames/s]\n  0%|          | 2268/776131 [00:03<18:26, 699.19frames/s]\n  1%|          | 5172/776131 [00:07<19:56, 644.52frames/s]\n  1%|          | 7396/776131 [00:14<27:48, 460.73frames/s]\n  1%|▏         | 10236/776131 [00:17<21:01, 607.10frames/s]\n  2%|▏         | 12836/776131 [00:23<23:33, 540.19frames/s]\n  2%|▏         | 15700/776131 [00:31<28:16, 448.15frames/s]\n  2%|▏         | 18468/776131 [00:39<30:41, 411.34frames/s]\n  3%|▎         | 21228/776131 [00:45<29:18, 429.18frames/s]\n  3%|▎         | 24004/776131 [00:52<30:56, 405.11frames/s]\n  3%|▎         | 26612/776131 [01:00<32:42, 381.97frames/s]\n  4%|▍         | 29588/776131 [01:09<34:39, 359.02frames/s]\n  4%|▍         | 32412/776131 [01:17<34:38, 357.75frames/s]\n  5%|▍         | 35332/776131 [01:28<37:20, 330.66frames/s]\n  5%|▍         | 38252/776131 [01:37<37:21, 329.19frames/s]\n  5%|▌         | 40636/776131 [01:44<37:21, 328.10frames/s]\n  6%|▌         | 43212/776131 [01:51<35:52, 340.44frames/s]\n  6%|▌         | 45980/776131 [01:59<35:20, 344.32frames/s]\n  6%|▋         | 48780/776131 [02:05<33:09, 365.57frames/s]\n  7%|▋         | 51652/776131 [02:12<31:38, 381.64frames/s]\n  7%|▋         | 54652/776131 [02:18<28:35, 420.45frames/s]\n  7%|▋         | 57596/776131 [02:29<34:25, 347.84frames/s]\n  8%|▊         | 60548/776131 [02:35<30:41, 388.65frames/s]\n  8%|▊         | 63516/776131 [02:42<30:10, 393.62frames/s]\n  9%|▊         | 66516/776131 [02:52<32:33, 363.33frames/s]\n  9%|▉         | 69380/776131 [03:02<34:59, 336.65frames/s]\n  9%|▉         | 72220/776131 [03:09<33:03, 354.85frames/s]\n 10%|▉         | 75132/776131 [03:19<34:51, 335.12frames/s]\n 10%|▉         | 75132/776131 [03:30<34:51, 335.12frames/s]\n 10%|█         | 77940/776131 [03:31<39:29, 294.68frames/s]\n 10%|█         | 80924/776131 [03:40<37:59, 304.99frames/s]\n 11%|█         | 83420/776131 [03:51<40:54, 282.20frames/s]\n 11%|█         | 86340/776131 [04:00<39:13, 293.08frames/s]\n 12%|█▏        | 89340/776131 [04:06<34:25, 332.55frames/s]\n 12%|█▏        | 89340/776131 [04:20<34:25, 332.55frames/s]\n 12%|█▏        | 92116/776131 [04:56<1:23:58, 135.75frames/s]\n 12%|█▏        | 94284/776131 [05:03<1:12:36, 156.53frames/s]\n 13%|█▎        | 97284/776131 [05:09<55:50, 202.63frames/s]  \n 13%|█▎        | 100284/776131 [05:15<44:21, 253.93frames/s]\n 13%|█▎        | 102732/776131 [05:21<40:25, 277.65frames/s]\n 14%|█▎        | 105292/776131 [05:26<34:33, 323.58frames/s]\n 14%|█▍        | 108100/776131 [05:33<33:10, 335.61frames/s]\n 14%|█▍        | 110820/776131 [05:40<31:29, 352.12frames/s]\n 15%|█▍        | 113684/776131 [05:49<32:01, 344.84frames/s]\n 15%|█▌        | 116484/776131 [05:56<30:34, 359.67frames/s]\n 15%|█▌        | 119484/776131 [06:01<26:45, 408.89frames/s]\n 16%|█▌        | 122484/776131 [06:04<21:49, 499.30frames/s]\n 16%|█▌        | 125484/776131 [06:12<23:51, 454.41frames/s]\n 17%|█▋        | 128252/776131 [06:17<22:17, 484.37frames/s]\n 17%|█▋        | 131252/776131 [06:20<19:13, 558.84frames/s]\n 17%|█▋        | 133908/776131 [06:25<18:27, 579.78frames/s]\n 18%|█▊        | 136836/776131 [06:32<20:29, 520.03frames/s]\n 18%|█▊        | 139636/776131 [06:40<23:55, 443.42frames/s]\n 18%|█▊        | 142620/776131 [06:48<25:28, 414.38frames/s]\n 19%|█▊        | 145420/776131 [06:56<25:50, 406.73frames/s]\n 19%|█▉        | 148238/776131 [07:05<28:26, 367.97frames/s]\n 19%|█▉        | 151158/776131 [07:15<30:14, 344.51frames/s]\n 20%|█▉        | 153958/776131 [07:21<27:43, 373.99frames/s]\n 20%|██        | 156662/776131 [07:29<28:45, 358.96frames/s]\n 21%|██        | 159142/776131 [07:34<27:07, 379.04frames/s]\n 21%|██        | 162142/776131 [07:42<26:14, 390.03frames/s]\n 21%|██▏       | 165046/776131 [07:49<26:19, 386.96frames/s]\n 22%|██▏       | 168046/776131 [07:57<25:59, 389.84frames/s]\n 22%|██▏       | 170838/776131 [08:02<24:02, 419.63frames/s]\n 22%|██▏       | 173630/776131 [08:12<27:28, 365.43frames/s]\n 23%|██▎       | 175822/776131 [08:17<26:17, 380.48frames/s]\n 23%|██▎       | 178822/776131 [08:25<25:32, 389.69frames/s]\n 23%|██▎       | 178822/776131 [08:40<25:32, 389.69frames/s]\n 23%|██▎       | 181630/776131 [09:33<1:30:52, 109.03frames/s]\n 24%|██▍       | 184414/776131 [09:41<1:11:40, 137.61frames/s]\n 24%|██▍       | 187414/776131 [09:48<56:31, 173.59frames/s]  \n 25%|██▍       | 190246/776131 [09:58<49:34, 196.97frames/s]\n 25%|██▍       | 193006/776131 [10:07<44:02, 220.70frames/s]\n 25%|██▌       | 195942/776131 [10:14<37:10, 260.10frames/s]\n 26%|██▌       | 198814/776131 [10:18<30:24, 316.49frames/s]\n 26%|██▌       | 201758/776131 [10:23<25:57, 368.80frames/s]\n 26%|██▋       | 204758/776131 [10:30<24:18, 391.86frames/s]\n 27%|██▋       | 207758/776131 [10:36<22:26, 422.07frames/s]\n 27%|██▋       | 210702/776131 [10:42<21:56, 429.61frames/s]\n 27%|██▋       | 213286/776131 [10:51<24:33, 381.97frames/s]\n 28%|██▊       | 215846/776131 [10:59<25:51, 361.06frames/s]\n 28%|██▊       | 218614/776131 [11:06<24:48, 374.45frames/s]\n 29%|██▊       | 221398/776131 [11:14<25:29, 362.81frames/s]\n 29%|██▉       | 224398/776131 [11:23<26:20, 349.08frames/s]\n 29%|██▉       | 227398/776131 [11:30<23:53, 382.74frames/s]\n 30%|██▉       | 229950/776131 [11:39<26:45, 340.21frames/s]\n 30%|███       | 232918/776131 [11:49<27:31, 328.86frames/s]\n 30%|███       | 235918/776131 [11:57<26:48, 335.93frames/s]\n 31%|███       | 238590/776131 [12:03<24:40, 363.16frames/s]\n 31%|███       | 241558/776131 [12:09<22:15, 400.20frames/s]\n 31%|███▏      | 244278/776131 [12:15<21:21, 414.90frames/s]\n 32%|███▏      | 247118/776131 [12:26<24:50, 354.96frames/s]\n 32%|███▏      | 249926/776131 [12:34<25:10, 348.43frames/s]\n 33%|███▎      | 252550/776131 [12:41<24:42, 353.07frames/s]\n 33%|███▎      | 255254/776131 [12:48<23:50, 364.21frames/s]\n 33%|███▎      | 257990/776131 [12:55<22:36, 381.92frames/s]\n 34%|███▎      | 260990/776131 [13:02<22:12, 386.70frames/s]\n 34%|███▍      | 263830/776131 [13:11<23:42, 360.16frames/s]\n 34%|███▍      | 266830/776131 [13:19<23:11, 366.05frames/s]\n 35%|███▍      | 269542/776131 [13:26<22:49, 369.92frames/s]\n 35%|███▌      | 272310/776131 [13:32<21:31, 390.08frames/s]\n 35%|███▌      | 275182/776131 [13:40<21:58, 379.81frames/s]\n 36%|███▌      | 278182/776131 [13:50<23:05, 359.40frames/s]\n 36%|███▌      | 280990/776131 [13:58<23:34, 350.12frames/s]\n 37%|███▋      | 283734/776131 [14:06<23:44, 345.75frames/s]\n 37%|███▋      | 286470/776131 [14:14<23:17, 350.26frames/s]\n 37%|███▋      | 289398/776131 [14:23<23:41, 342.32frames/s]\n 38%|███▊      | 292286/776131 [14:33<24:36, 327.72frames/s]\n 38%|███▊      | 295102/776131 [14:42<24:47, 323.45frames/s]\n 38%|███▊      | 297878/776131 [14:48<22:44, 350.45frames/s]\n 39%|███▊      | 300750/776131 [14:56<22:36, 350.35frames/s]\n 39%|███▉      | 303750/776131 [15:03<20:51, 377.35frames/s]\n 39%|███▉      | 306342/776131 [15:11<21:27, 364.93frames/s]\n 40%|███▉      | 309222/776131 [15:19<21:30, 361.89frames/s]\n 40%|████      | 311574/776131 [15:22<19:03, 406.22frames/s]\n 41%|████      | 314574/776131 [15:27<16:50, 456.93frames/s]\n 41%|████      | 317574/776131 [15:36<18:31, 412.39frames/s]\n 41%|████▏     | 320398/776131 [15:45<19:44, 384.68frames/s]\n 42%|████▏     | 323294/776131 [15:52<19:28, 387.42frames/s]\n 42%|████▏     | 325958/776131 [15:59<19:34, 383.24frames/s]\n 42%|████▏     | 328878/776131 [16:07<19:20, 385.32frames/s]\n 43%|████▎     | 331702/776131 [16:16<20:47, 356.28frames/s]\n 43%|████▎     | 334358/776131 [16:24<21:19, 345.20frames/s]\n 43%|████▎     | 337318/776131 [16:32<20:37, 354.58frames/s]\n 44%|████▍     | 340118/776131 [16:40<20:10, 360.31frames/s]\n 44%|████▍     | 342702/776131 [16:46<19:47, 364.97frames/s]\n 44%|████▍     | 345174/776131 [16:52<18:51, 380.77frames/s]\n 45%|████▍     | 347894/776131 [17:01<19:57, 357.58frames/s]\n 45%|████▌     | 350814/776131 [17:10<20:22, 347.80frames/s]\n 46%|████▌     | 353766/776131 [17:17<19:06, 368.42frames/s]\n 46%|████▌     | 356422/776131 [17:22<17:14, 405.66frames/s]\n 46%|████▋     | 359422/776131 [17:28<16:09, 429.81frames/s]\n 47%|████▋     | 362310/776131 [17:33<14:44, 468.10frames/s]\n 47%|████▋     | 365310/776131 [17:38<13:41, 500.24frames/s]\n 47%|████▋     | 368062/776131 [17:43<13:15, 512.86frames/s]\n 48%|████▊     | 370430/776131 [17:46<12:33, 538.45frames/s]\n 48%|████▊     | 373430/776131 [17:52<12:33, 534.39frames/s]\n 48%|████▊     | 376302/776131 [17:57<11:51, 562.14frames/s]\n 49%|████▉     | 378454/776131 [18:02<13:11, 502.14frames/s]\n 49%|████▉     | 381158/776131 [18:13<16:44, 393.02frames/s]\n 49%|████▉     | 381158/776131 [18:30<16:44, 393.02frames/s]\n 49%|████▉     | 383998/776131 [19:01<46:17, 141.18frames/s]\n 50%|████▉     | 386694/776131 [19:05<35:30, 182.76frames/s]\n 50%|█████     | 389318/776131 [19:10<28:00, 230.17frames/s]\n 50%|█████     | 391918/776131 [19:16<24:28, 261.71frames/s]\n 51%|█████     | 394662/776131 [19:22<20:39, 307.85frames/s]\n 51%|█████     | 397662/776131 [19:28<18:06, 348.46frames/s]\n 51%|█████     | 397662/776131 [19:40<18:06, 348.46frames/s]\n 52%|█████▏    | 400238/776131 [20:30<55:53, 112.09frames/s]\n 52%|█████▏    | 403238/776131 [20:36<41:37, 149.31frames/s]\n 52%|█████▏    | 406182/776131 [20:43<32:52, 187.59frames/s]\n 53%|█████▎    | 409022/776131 [20:50<27:35, 221.77frames/s]\n 53%|█████▎    | 411830/776131 [20:56<22:49, 265.93frames/s]\n 53%|█████▎    | 414670/776131 [21:02<19:54, 302.72frames/s]\n 54%|█████▍    | 417494/776131 [21:08<17:45, 336.63frames/s]\n 54%|█████▍    | 420494/776131 [21:13<15:02, 393.98frames/s]\n 55%|█████▍    | 423062/776131 [21:17<13:20, 440.82frames/s]\n 55%|█████▍    | 425846/776131 [21:23<12:51, 454.05frames/s]\n 55%|█████▌    | 428406/776131 [21:27<11:33, 501.28frames/s]\n 56%|█████▌    | 431142/776131 [21:33<11:46, 488.04frames/s]\n 56%|█████▌    | 433678/776131 [21:36<10:16, 555.38frames/s]\n 56%|█████▌    | 436430/776131 [21:41<10:28, 540.55frames/s]\n 57%|█████▋    | 438726/776131 [21:47<11:33, 486.52frames/s]\n 57%|█████▋    | 441518/776131 [21:52<10:57, 508.68frames/s]\n 57%|█████▋    | 444350/776131 [21:59<12:06, 456.47frames/s]\n 57%|█████▋    | 444350/776131 [22:10<12:06, 456.47frames/s]\n 58%|█████▊    | 447350/776131 [22:11<14:49, 369.83frames/s]\n 58%|█████▊    | 450350/776131 [22:16<12:59, 417.74frames/s]\n 58%|█████▊    | 452910/776131 [22:20<11:41, 460.49frames/s]\n 59%|█████▊    | 455742/776131 [22:28<12:41, 420.67frames/s]\n 59%|█████▉    | 458398/776131 [22:36<13:14, 399.72frames/s]\n 59%|█████▉    | 460614/776131 [22:42<13:33, 387.81frames/s]\n 60%|█████▉    | 463446/776131 [22:50<13:53, 375.34frames/s]\n 60%|██████    | 466278/776131 [23:01<15:41, 329.01frames/s]\n 60%|██████    | 469278/776131 [23:07<14:06, 362.50frames/s]\n 61%|██████    | 472022/776131 [23:15<13:49, 366.43frames/s]\n 61%|██████    | 474774/776131 [23:20<12:29, 402.00frames/s]\n 62%|██████▏   | 477574/776131 [23:28<13:05, 379.85frames/s]\n 62%|██████▏   | 479926/776131 [23:32<11:39, 423.43frames/s]\n 62%|██████▏   | 482406/776131 [23:39<11:59, 408.00frames/s]\n 63%|██████▎   | 485174/776131 [23:46<12:29, 388.24frames/s]\n 63%|██████▎   | 488158/776131 [23:53<11:55, 402.65frames/s]\n 63%|██████▎   | 491110/776131 [24:01<11:43, 404.90frames/s]\n 64%|██████▎   | 493686/776131 [24:06<11:16, 417.22frames/s]\n 64%|██████▍   | 496526/776131 [24:13<11:23, 409.06frames/s]\n 64%|██████▍   | 499510/776131 [24:21<11:22, 405.41frames/s]\n 65%|██████▍   | 501982/776131 [24:27<11:25, 399.70frames/s]\n 65%|██████▍   | 504358/776131 [24:35<12:07, 373.78frames/s]\n 65%|██████▌   | 507150/776131 [24:44<12:38, 354.58frames/s]\n 66%|██████▌   | 509990/776131 [24:51<12:25, 357.16frames/s]\n 66%|██████▌   | 512982/776131 [24:58<11:25, 383.73frames/s]\n 66%|██████▋   | 515910/776131 [25:06<11:20, 382.37frames/s]\n 67%|██████▋   | 518678/776131 [25:13<11:10, 384.06frames/s]\n 67%|██████▋   | 521102/776131 [25:21<11:59, 354.59frames/s]\n 67%|██████▋   | 523702/776131 [25:29<11:59, 350.80frames/s]\n 68%|██████▊   | 526422/776131 [25:36<11:42, 355.50frames/s]\n 68%|██████▊   | 529254/776131 [25:42<10:41, 384.75frames/s]\n 69%|██████▊   | 531822/776131 [25:49<10:32, 385.96frames/s]\n 69%|██████▉   | 534622/776131 [25:54<09:21, 430.25frames/s]\n 69%|██████▉   | 537126/776131 [25:59<09:14, 431.25frames/s]\n 70%|██████▉   | 539646/776131 [26:04<08:34, 459.89frames/s]\n 70%|██████▉   | 542638/776131 [26:12<09:00, 431.74frames/s]\n 70%|███████   | 545438/776131 [26:20<09:27, 406.36frames/s]\n 71%|███████   | 547750/776131 [26:27<10:21, 367.48frames/s]\n 71%|███████   | 550430/776131 [26:34<09:59, 376.74frames/s]\n 71%|███████▏  | 553246/776131 [26:41<09:24, 394.93frames/s]\n 72%|███████▏  | 555846/776131 [26:46<08:39, 424.20frames/s]\n 72%|███████▏  | 558382/776131 [26:50<08:02, 450.96frames/s]\n 72%|███████▏  | 561190/776131 [26:58<08:27, 423.22frames/s]\n 73%|███████▎  | 564142/776131 [27:07<09:14, 382.27frames/s]\n 73%|███████▎  | 566958/776131 [27:16<09:42, 358.91frames/s]\n 73%|███████▎  | 569702/776131 [27:21<08:33, 401.98frames/s]\n 74%|███████▎  | 572318/776131 [27:27<08:05, 420.20frames/s]\n 74%|███████▍  | 574832/776131 [27:32<07:53, 425.43frames/s]\n 74%|███████▍  | 577528/776131 [27:40<08:11, 404.33frames/s]\n 75%|███████▍  | 580496/776131 [27:49<08:34, 379.96frames/s]\n 75%|███████▌  | 583200/776131 [27:58<09:14, 347.97frames/s]\n 76%|███████▌  | 586104/776131 [28:06<09:07, 347.08frames/s]\n 76%|███████▌  | 588992/776131 [28:14<08:55, 349.24frames/s]\n 76%|███████▌  | 591736/776131 [28:23<09:02, 339.83frames/s]\n 77%|███████▋  | 594696/776131 [28:31<08:31, 354.73frames/s]\n 77%|███████▋  | 597696/776131 [28:38<08:04, 368.27frames/s]\n 77%|███████▋  | 600568/776131 [28:43<06:59, 418.73frames/s]\n 78%|███████▊  | 603096/776131 [28:49<06:51, 420.09frames/s]\n 78%|███████▊  | 605432/776131 [28:52<05:58, 476.50frames/s]\n 78%|███████▊  | 608136/776131 [28:56<05:31, 506.19frames/s]\n 79%|███████▊  | 610720/776131 [29:01<05:15, 524.65frames/s]\n 79%|███████▊  | 610720/776131 [29:20<05:15, 524.65frames/s]\n 79%|███████▉  | 613696/776131 [29:56<19:42, 137.40frames/s]\n 79%|███████▉  | 616608/776131 [30:02<15:07, 175.79frames/s]\n 80%|███████▉  | 619416/776131 [30:10<12:44, 204.91frames/s]\n 80%|████████  | 621888/776131 [30:17<10:55, 235.26frames/s]\n 80%|████████  | 623864/776131 [30:20<09:14, 274.57frames/s]\n 81%|████████  | 626368/776131 [30:23<07:21, 339.24frames/s]\n 81%|████████  | 629208/776131 [30:28<06:11, 395.99frames/s]\n 81%|████████▏ | 631368/776131 [30:33<05:45, 418.99frames/s]\n 82%|████████▏ | 633328/776131 [30:38<05:49, 408.08frames/s]\n 82%|████████▏ | 636296/776131 [30:43<05:15, 443.47frames/s]\n 82%|████████▏ | 638560/776131 [30:48<04:57, 462.63frames/s]\n 83%|████████▎ | 641280/776131 [30:51<04:14, 529.24frames/s]\n 83%|████████▎ | 644080/776131 [30:57<04:19, 508.45frames/s]\n 83%|████████▎ | 646672/776131 [31:02<04:08, 521.19frames/s]\n 84%|████████▎ | 649552/776131 [31:09<04:18, 490.18frames/s]\n 84%|████████▍ | 652552/776131 [31:15<04:14, 485.26frames/s]\n 84%|████████▍ | 655552/776131 [31:20<03:51, 520.94frames/s]\n 85%|████████▍ | 658152/776131 [31:28<04:29, 438.37frames/s]\n 85%|████████▌ | 660424/776131 [31:34<04:29, 429.27frames/s]\n 85%|████████▌ | 663224/776131 [31:40<04:20, 432.60frames/s]\n 86%|████████▌ | 665976/776131 [31:47<04:22, 420.43frames/s]\n 86%|████████▌ | 668832/776131 [31:56<04:40, 382.98frames/s]\n 87%|████████▋ | 671504/776131 [32:03<04:37, 376.63frames/s]\n 87%|████████▋ | 674312/776131 [32:10<04:24, 385.36frames/s]\n 87%|████████▋ | 677312/776131 [32:20<04:34, 359.98frames/s]\n 87%|████████▋ | 677312/776131 [32:40<04:34, 359.98frames/s]\n 88%|████████▊ | 680240/776131 [32:40<06:33, 243.72frames/s]\n 88%|████████▊ | 680240/776131 [33:00<06:33, 243.72frames/s]\n 88%|████████▊ | 682640/776131 [33:15<10:34, 147.43frames/s]\n 88%|████████▊ | 685272/776131 [33:20<08:08, 186.01frames/s]\n 89%|████████▊ | 688264/776131 [33:27<06:27, 226.60frames/s]\n 89%|████████▊ | 688264/776131 [33:40<06:27, 226.60frames/s]\n 89%|████████▉ | 690906/776131 [34:37<15:25, 92.11frames/s] \n 89%|████████▉ | 693906/776131 [34:42<10:50, 126.31frames/s]\n 90%|████████▉ | 696906/776131 [34:48<07:56, 166.11frames/s]\n 90%|█████████ | 699606/776131 [34:54<06:18, 202.30frames/s]\n 91%|█████████ | 702406/776131 [35:03<05:22, 228.92frames/s]\n 91%|█████████ | 705206/776131 [35:09<04:29, 263.07frames/s]\n 91%|█████████ | 708106/776131 [35:15<03:36, 314.42frames/s]\n 92%|█████████▏| 711106/776131 [35:22<03:14, 334.61frames/s]\n 92%|█████████▏| 713906/776131 [35:31<03:10, 327.23frames/s]\n 92%|█████████▏| 716806/776131 [35:40<02:59, 330.28frames/s]\n 93%|█████████▎| 719206/776131 [35:49<03:04, 308.23frames/s]\n 93%|█████████▎| 721906/776131 [35:57<02:51, 315.27frames/s]\n 93%|█████████▎| 724606/776131 [36:06<02:41, 318.53frames/s]\n 94%|█████████▎| 727306/776131 [36:12<02:20, 347.67frames/s]\n 94%|█████████▍| 730206/776131 [36:18<02:02, 375.35frames/s]\n 94%|█████████▍| 733006/776131 [36:25<01:50, 390.21frames/s]\n 95%|█████████▍| 735806/776131 [36:30<01:34, 427.18frames/s]\n 95%|█████████▌| 738406/776131 [36:35<01:23, 451.00frames/s]\n 95%|█████████▌| 741106/776131 [36:39<01:13, 477.82frames/s]\n 96%|█████████▌| 744006/776131 [36:46<01:09, 461.52frames/s]\n 96%|█████████▌| 746306/776131 [36:51<01:03, 472.67frames/s]\n 97%|█████████▋| 749006/776131 [36:56<00:55, 485.03frames/s]\n 97%|█████████▋| 751706/776131 [37:01<00:48, 499.20frames/s]\n 97%|█████████▋| 754506/776131 [37:06<00:42, 505.31frames/s]\n 98%|█████████▊| 757206/776131 [37:12<00:37, 506.78frames/s]\n 98%|█████████▊| 759806/776131 [37:17<00:32, 504.92frames/s]\n 98%|█████████▊| 762506/776131 [37:23<00:28, 477.58frames/s]\n 99%|█████████▊| 765306/776131 [37:29<00:22, 474.71frames/s]\n 99%|█████████▉| 767906/776131 [37:35<00:17, 468.75frames/s]\n 99%|█████████▉| 769006/776131 [37:37<00:14, 485.10frames/s]\n 99%|█████████▉| 771406/776131 [37:44<00:10, 429.83frames/s]\n100%|█████████▉| 774406/776131 [37:46<00:02, 583.88frames/s]\n100%|██████████| 776131/776131 [37:50<00:00, 543.45frames/s]\n100%|██████████| 776131/776131 [37:50<00:00, 341.90frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.48151202823804773,
        "compression_ratio": 1.34375,
        "end": 16.6,
        "id": 0,
        "no_speech_prob": 0.4263022541999817,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Did you think that learning coding would be really rough?",
        "tokens": [
          50364,
          2589,
          291,
          519,
          300,
          2539,
          17720,
          576,
          312,
          534,
          5903,
          30,
          51194
        ]
      },
      {
        "avg_logprob": -0.48151202823804773,
        "compression_ratio": 1.34375,
        "end": 19.68,
        "id": 1,
        "no_speech_prob": 0.4263022541999817,
        "seek": 0,
        "start": 16.6,
        "temperature": 0,
        "text": " Throw your hands up in the air and say, enough's enough!",
        "tokens": [
          51194,
          22228,
          428,
          2377,
          493,
          294,
          264,
          1988,
          293,
          584,
          11,
          1547,
          311,
          1547,
          0,
          51348
        ]
      },
      {
        "avg_logprob": -0.48151202823804773,
        "compression_ratio": 1.34375,
        "end": 22.68,
        "id": 2,
        "no_speech_prob": 0.4263022541999817,
        "seek": 0,
        "start": 19.68,
        "temperature": 0,
        "text": " Do you want to learn to code and make some awesome stuff?",
        "tokens": [
          51348,
          1144,
          291,
          528,
          281,
          1466,
          281,
          3089,
          293,
          652,
          512,
          3476,
          1507,
          30,
          51498
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 26.44,
        "id": 3,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 22.919999999999998,
        "temperature": 0,
        "text": " Learn that anyone can when you're coding with Dan on!",
        "tokens": [
          50376,
          17216,
          300,
          2878,
          393,
          562,
          291,
          434,
          17720,
          365,
          3394,
          322,
          0,
          50552
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 35.4,
        "id": 4,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 32.92,
        "temperature": 0,
        "text": " Whether you're a pro or this is all brand new,",
        "tokens": [
          50876,
          8503,
          291,
          434,
          257,
          447,
          420,
          341,
          307,
          439,
          3360,
          777,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 42.120000000000005,
        "id": 5,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 38.92,
        "temperature": 0,
        "text": " learn the overarching concepts and some fun stuff too!",
        "tokens": [
          51176,
          1466,
          264,
          45501,
          10392,
          293,
          512,
          1019,
          1507,
          886,
          0,
          51336
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 45.480000000000004,
        "id": 6,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 42.120000000000005,
        "temperature": 0,
        "text": " And with Dan as your guide, come along for the ride on!",
        "tokens": [
          51336,
          400,
          365,
          3394,
          382,
          428,
          5934,
          11,
          808,
          2051,
          337,
          264,
          5077,
          322,
          0,
          51504
        ]
      },
      {
        "avg_logprob": -0.36253324236188617,
        "compression_ratio": 1.48,
        "end": 51.72,
        "id": 7,
        "no_speech_prob": 0.03409254178404808,
        "seek": 2268,
        "start": 48.519999999999996,
        "temperature": 0,
        "text": " Make a crazy pixel mirror to reflect your face,",
        "tokens": [
          51656,
          4387,
          257,
          3219,
          19261,
          8013,
          281,
          5031,
          428,
          1851,
          11,
          51816
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 54.92,
        "id": 8,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 51.72,
        "temperature": 0,
        "text": " you can make a jump to light speed into outer space,",
        "tokens": [
          50364,
          291,
          393,
          652,
          257,
          3012,
          281,
          1442,
          3073,
          666,
          10847,
          1901,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 58.12,
        "id": 9,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 54.92,
        "temperature": 0,
        "text": " you can generate a maze that can go on for days,",
        "tokens": [
          50524,
          291,
          393,
          8460,
          257,
          33032,
          300,
          393,
          352,
          322,
          337,
          1708,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 61.32,
        "id": 10,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 58.12,
        "temperature": 0,
        "text": " you can make your own terrain and some purple rain,",
        "tokens": [
          50684,
          291,
          393,
          652,
          428,
          1065,
          17674,
          293,
          512,
          9656,
          4830,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 64.52,
        "id": 11,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 61.32,
        "temperature": 0,
        "text": " you can make a retro game to see how it's done,",
        "tokens": [
          50844,
          291,
          393,
          652,
          257,
          18820,
          1216,
          281,
          536,
          577,
          309,
          311,
          1096,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 67.72,
        "id": 12,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 64.52,
        "temperature": 0,
        "text": " and then tweak a piece to make it yours for everyone!",
        "tokens": [
          51004,
          293,
          550,
          29879,
          257,
          2522,
          281,
          652,
          309,
          6342,
          337,
          1518,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 70.75999999999999,
        "id": 13,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 67.72,
        "temperature": 0,
        "text": " Make some fractally trees or twitter bots if you please,",
        "tokens": [
          51164,
          4387,
          512,
          17948,
          379,
          5852,
          420,
          21439,
          35410,
          498,
          291,
          1767,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.23342019608877237,
        "compression_ratio": 1.7714285714285714,
        "end": 73.96000000000001,
        "id": 14,
        "no_speech_prob": 0.0002694572613108903,
        "seek": 5172,
        "start": 70.75999999999999,
        "temperature": 0,
        "text": " and when the seeds are a stone, you can make them your own!",
        "tokens": [
          51316,
          293,
          562,
          264,
          9203,
          366,
          257,
          7581,
          11,
          291,
          393,
          652,
          552,
          428,
          1065,
          0,
          51476
        ]
      },
      {
        "avg_logprob": -0.4472346950221706,
        "compression_ratio": 1.17,
        "end": 83.8,
        "id": 15,
        "no_speech_prob": 0.03258010372519493,
        "seek": 7396,
        "start": 73.96,
        "temperature": 0,
        "text": " Run the colors of code, you can follow the road too!",
        "tokens": [
          50364,
          8950,
          264,
          4577,
          295,
          3089,
          11,
          291,
          393,
          1524,
          264,
          3060,
          886,
          0,
          50856
        ]
      },
      {
        "avg_logprob": -0.4472346950221706,
        "compression_ratio": 1.17,
        "end": 95.32,
        "id": 16,
        "no_speech_prob": 0.03258010372519493,
        "seek": 7396,
        "start": 91.96,
        "temperature": 0,
        "text": " Hello, welcome to another episode of...",
        "tokens": [
          51264,
          2425,
          11,
          2928,
          281,
          1071,
          3500,
          295,
          485,
          51432
        ]
      },
      {
        "avg_logprob": -0.4472346950221706,
        "compression_ratio": 1.17,
        "end": 102.36,
        "id": 17,
        "no_speech_prob": 0.03258010372519493,
        "seek": 7396,
        "start": 101.47999999999999,
        "temperature": 0,
        "text": " I don't know what it is.",
        "tokens": [
          51740,
          286,
          500,
          380,
          458,
          437,
          309,
          307,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 104.6,
        "id": 18,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 102.36,
        "temperature": 0,
        "text": " Okay, so hopefully you're there and watching.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          4696,
          291,
          434,
          456,
          293,
          1976,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 105.24,
        "id": 19,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 104.6,
        "temperature": 0,
        "text": " I am here.",
        "tokens": [
          50476,
          286,
          669,
          510,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 110.76,
        "id": 20,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 105.24,
        "temperature": 0,
        "text": " It's been two weeks since I've been here on the YouTube.",
        "tokens": [
          50508,
          467,
          311,
          668,
          732,
          3259,
          1670,
          286,
          600,
          668,
          510,
          322,
          264,
          3088,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 116.12,
        "id": 21,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 113.32,
        "temperature": 0,
        "text": " And I'm very excited and glad to be back.",
        "tokens": [
          50912,
          400,
          286,
          478,
          588,
          2919,
          293,
          5404,
          281,
          312,
          646,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 121.16,
        "id": 22,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 116.68,
        "temperature": 0,
        "text": " And this has been a very tricky month with busy end of semester for me,",
        "tokens": [
          51080,
          400,
          341,
          575,
          668,
          257,
          588,
          12414,
          1618,
          365,
          5856,
          917,
          295,
          11894,
          337,
          385,
          11,
          51304
        ]
      },
      {
        "avg_logprob": -0.29084238895150116,
        "compression_ratio": 1.5279187817258884,
        "end": 128.36,
        "id": 23,
        "no_speech_prob": 0.00364901265129447,
        "seek": 10236,
        "start": 121.16,
        "temperature": 0,
        "text": " with my other job, and with the holidays that have been here in New York,",
        "tokens": [
          51304,
          365,
          452,
          661,
          1691,
          11,
          293,
          365,
          264,
          15734,
          300,
          362,
          668,
          510,
          294,
          1873,
          3609,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 130.76000000000002,
        "id": 24,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 128.36,
        "temperature": 0,
        "text": " this crazy election thing that happened,",
        "tokens": [
          50364,
          341,
          3219,
          6618,
          551,
          300,
          2011,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 134.84,
        "id": 25,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 130.76000000000002,
        "temperature": 0,
        "text": " which I am upsetting on so many different kinds of levels.",
        "tokens": [
          50484,
          597,
          286,
          669,
          44109,
          322,
          370,
          867,
          819,
          3685,
          295,
          4358,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 140.68,
        "id": 26,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 134.84,
        "temperature": 0,
        "text": " But here I am anyway, alive in this room here at the School for Poetic Computation",
        "tokens": [
          50688,
          583,
          510,
          286,
          669,
          4033,
          11,
          5465,
          294,
          341,
          1808,
          510,
          412,
          264,
          5070,
          337,
          6165,
          3532,
          37804,
          399,
          50980
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 145.08,
        "id": 27,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 141.8,
        "temperature": 0,
        "text": " in the West Village of New York City.",
        "tokens": [
          51036,
          294,
          264,
          4055,
          22651,
          295,
          1873,
          3609,
          4392,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 147.48000000000002,
        "id": 28,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 145.08,
        "temperature": 0,
        "text": " And it's around 3.20 p.m.",
        "tokens": [
          51200,
          400,
          309,
          311,
          926,
          805,
          13,
          2009,
          280,
          13,
          76,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 149.08,
        "id": 29,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 147.48000000000002,
        "temperature": 0,
        "text": " I don't think it's December yet.",
        "tokens": [
          51320,
          286,
          500,
          380,
          519,
          309,
          311,
          7687,
          1939,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 151.8,
        "id": 30,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 149.08,
        "temperature": 0,
        "text": " I'm pretty sure it's still just November.",
        "tokens": [
          51400,
          286,
          478,
          1238,
          988,
          309,
          311,
          920,
          445,
          7674,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 153.08,
        "id": 31,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 151.8,
        "temperature": 0,
        "text": " Please don't be November.",
        "tokens": [
          51536,
          2555,
          500,
          380,
          312,
          7674,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 153.8,
        "id": 32,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 153.08,
        "temperature": 0,
        "text": " Actually, you know what?",
        "tokens": [
          51600,
          5135,
          11,
          291,
          458,
          437,
          30,
          51636
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 154.36,
        "id": 33,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 153.8,
        "temperature": 0,
        "text": " December.",
        "tokens": [
          51636,
          7687,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 155.96,
        "id": 34,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 154.36,
        "temperature": 0,
        "text": " Fine, let's bring on December.",
        "tokens": [
          51664,
          12024,
          11,
          718,
          311,
          1565,
          322,
          7687,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.22946876703306687,
        "compression_ratio": 1.5340501792114696,
        "end": 157,
        "id": 35,
        "no_speech_prob": 0.06654844433069229,
        "seek": 12836,
        "start": 155.96,
        "temperature": 0,
        "text": " Bring on 2000.",
        "tokens": [
          51744,
          12842,
          322,
          8132,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 160.04,
        "id": 36,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 157.32,
        "temperature": 0,
        "text": " Some jump, let's jump a bunch of years into the future.",
        "tokens": [
          50380,
          2188,
          3012,
          11,
          718,
          311,
          3012,
          257,
          3840,
          295,
          924,
          666,
          264,
          2027,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 161.88,
        "id": 37,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 160.68,
        "temperature": 0,
        "text": " And maybe that'll be a good thing.",
        "tokens": [
          50548,
          400,
          1310,
          300,
          603,
          312,
          257,
          665,
          551,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 164.36,
        "id": 38,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 161.88,
        "temperature": 0,
        "text": " Anyway, what's up with the colors?",
        "tokens": [
          50608,
          5684,
          11,
          437,
          311,
          493,
          365,
          264,
          4577,
          30,
          50732
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 166.84,
        "id": 39,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 165.88,
        "temperature": 0,
        "text": " Is anything looking weird?",
        "tokens": [
          50808,
          1119,
          1340,
          1237,
          3657,
          30,
          50856
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 170.44,
        "id": 40,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 166.84,
        "temperature": 0,
        "text": " Am I, you know, I have a little, I have some, I'm sort of lighting challenged.",
        "tokens": [
          50856,
          2012,
          286,
          11,
          291,
          458,
          11,
          286,
          362,
          257,
          707,
          11,
          286,
          362,
          512,
          11,
          286,
          478,
          1333,
          295,
          9577,
          17737,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 173.4,
        "id": 41,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 170.44,
        "temperature": 0,
        "text": " So I don't know if there's some weird colored things going on.",
        "tokens": [
          51036,
          407,
          286,
          500,
          380,
          458,
          498,
          456,
          311,
          512,
          3657,
          14332,
          721,
          516,
          322,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 177.96,
        "id": 42,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 175.32,
        "temperature": 0,
        "text": " And, but yes, I did have a haircut.",
        "tokens": [
          51280,
          400,
          11,
          457,
          2086,
          11,
          286,
          630,
          362,
          257,
          30328,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 179.16,
        "id": 43,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 177.96,
        "temperature": 0,
        "text": " Thank you for noticing.",
        "tokens": [
          51412,
          1044,
          291,
          337,
          21814,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 179.8,
        "id": 44,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 179.16,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51472,
          286,
          500,
          380,
          458,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 183.16,
        "id": 45,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 179.8,
        "temperature": 0,
        "text": " This is probably not what you tuned in for, or perhaps it is what you tuned in for.",
        "tokens": [
          51504,
          639,
          307,
          1391,
          406,
          437,
          291,
          10870,
          294,
          337,
          11,
          420,
          4317,
          309,
          307,
          437,
          291,
          10870,
          294,
          337,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.1902641605686497,
        "compression_ratio": 1.7681159420289856,
        "end": 184.68,
        "id": 46,
        "no_speech_prob": 0.0020829064305871725,
        "seek": 15700,
        "start": 183.16,
        "temperature": 0,
        "text": " So what's going on with this thing?",
        "tokens": [
          51672,
          407,
          437,
          311,
          516,
          322,
          365,
          341,
          551,
          30,
          51748
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 187.32,
        "id": 47,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 184.68,
        "temperature": 0,
        "text": " So my name is Dan.",
        "tokens": [
          50364,
          407,
          452,
          1315,
          307,
          3394,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 194.76000000000002,
        "id": 48,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 188.12,
        "temperature": 0,
        "text": " I do live streams on YouTube weekly, except for the weeks where that I miss, like last week,",
        "tokens": [
          50536,
          286,
          360,
          1621,
          15842,
          322,
          3088,
          12460,
          11,
          3993,
          337,
          264,
          3259,
          689,
          300,
          286,
          1713,
          11,
          411,
          1036,
          1243,
          11,
          50868
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 199.32,
        "id": 49,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 194.76000000000002,
        "temperature": 0,
        "text": " where I demonstrate a variety of different programming, coding techniques,",
        "tokens": [
          50868,
          689,
          286,
          11698,
          257,
          5673,
          295,
          819,
          9410,
          11,
          17720,
          7512,
          11,
          51096
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 203.4,
        "id": 50,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 199.32,
        "temperature": 0,
        "text": " generally in the creative sphere of applications.",
        "tokens": [
          51096,
          5101,
          294,
          264,
          5880,
          16687,
          295,
          5821,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 205.8,
        "id": 51,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 203.4,
        "temperature": 0,
        "text": " So look at generative algorithms for visual art,",
        "tokens": [
          51300,
          407,
          574,
          412,
          1337,
          1166,
          14642,
          337,
          5056,
          1523,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 210.52,
        "id": 52,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 206.84,
        "temperature": 0,
        "text": " different kinds of algorithms for generating and analyzing text,",
        "tokens": [
          51472,
          819,
          3685,
          295,
          14642,
          337,
          17746,
          293,
          23663,
          2487,
          11,
          51656
        ]
      },
      {
        "avg_logprob": -0.19805191375397063,
        "compression_ratio": 1.5975103734439835,
        "end": 212.28,
        "id": 53,
        "no_speech_prob": 0.0008167171617969871,
        "seek": 18468,
        "start": 210.52,
        "temperature": 0,
        "text": " which has been my focus this fall.",
        "tokens": [
          51656,
          597,
          575,
          668,
          452,
          1879,
          341,
          2100,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 215.24,
        "id": 54,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 212.28,
        "temperature": 0,
        "text": " I noticed somebody in the chat mentioned,",
        "tokens": [
          50364,
          286,
          5694,
          2618,
          294,
          264,
          5081,
          2835,
          11,
          50512
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 222.28,
        "id": 55,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 217.4,
        "temperature": 0,
        "text": " mentioned, somebody in the chat mentioned machine learning.",
        "tokens": [
          50620,
          2835,
          11,
          2618,
          294,
          264,
          5081,
          2835,
          3479,
          2539,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 224.28,
        "id": 56,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 222.28,
        "temperature": 0,
        "text": " And that's actually on my list of topics.",
        "tokens": [
          50864,
          400,
          300,
          311,
          767,
          322,
          452,
          1329,
          295,
          8378,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 228.6,
        "id": 57,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 224.28,
        "temperature": 0,
        "text": " That's going to be one of my main focuses this spring in the new year in 2017.",
        "tokens": [
          50964,
          663,
          311,
          516,
          281,
          312,
          472,
          295,
          452,
          2135,
          16109,
          341,
          5587,
          294,
          264,
          777,
          1064,
          294,
          6591,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 232.84,
        "id": 58,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 229.56,
        "temperature": 0,
        "text": " But so today, what I wanted to do, I want to do a couple things.",
        "tokens": [
          51228,
          583,
          370,
          965,
          11,
          437,
          286,
          1415,
          281,
          360,
          11,
          286,
          528,
          281,
          360,
          257,
          1916,
          721,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 235.08,
        "id": 59,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 232.84,
        "temperature": 0,
        "text": " One is I want to talk about the processing fellowships,",
        "tokens": [
          51392,
          1485,
          307,
          286,
          528,
          281,
          751,
          466,
          264,
          9007,
          24989,
          82,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 237.16,
        "id": 60,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 235.08,
        "temperature": 0,
        "text": " which might be something that you aren't aware of.",
        "tokens": [
          51504,
          597,
          1062,
          312,
          746,
          300,
          291,
          3212,
          380,
          3650,
          295,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.26129512626583834,
        "compression_ratio": 1.742537313432836,
        "end": 240.04,
        "id": 61,
        "no_speech_prob": 0.00013341403973754495,
        "seek": 21228,
        "start": 237.16,
        "temperature": 0,
        "text": " So I'm gonna spend a little time talking about the processing foundation",
        "tokens": [
          51608,
          407,
          286,
          478,
          799,
          3496,
          257,
          707,
          565,
          1417,
          466,
          264,
          9007,
          7030,
          51752
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 244.12,
        "id": 62,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 240.04,
        "temperature": 0,
        "text": " and the fellowship program that's out now that any of you might be interested in,",
        "tokens": [
          50364,
          293,
          264,
          24989,
          1461,
          300,
          311,
          484,
          586,
          300,
          604,
          295,
          291,
          1062,
          312,
          3102,
          294,
          11,
          50568
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 248.28,
        "id": 63,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 246.76,
        "temperature": 0,
        "text": " interested in applying to.",
        "tokens": [
          50700,
          3102,
          294,
          9275,
          281,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 251.64,
        "id": 64,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 248.28,
        "temperature": 0,
        "text": " Sorry, I'm trying to keep an eye on the chat, which it's very difficult to have this,",
        "tokens": [
          50776,
          4919,
          11,
          286,
          478,
          1382,
          281,
          1066,
          364,
          3313,
          322,
          264,
          5081,
          11,
          597,
          309,
          311,
          588,
          2252,
          281,
          362,
          341,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 256.2,
        "id": 65,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 252.44,
        "temperature": 0,
        "text": " to speak and have a continuous thought and read a chat at the same time.",
        "tokens": [
          50984,
          281,
          1710,
          293,
          362,
          257,
          10957,
          1194,
          293,
          1401,
          257,
          5081,
          412,
          264,
          912,
          565,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 257.8,
        "id": 66,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 257.08,
        "temperature": 0,
        "text": " Hi, Arson.",
        "tokens": [
          51216,
          2421,
          11,
          1587,
          3015,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 259.24,
        "id": 67,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 257.8,
        "temperature": 0,
        "text": " Arson, yes, I do remember.",
        "tokens": [
          51252,
          1587,
          3015,
          11,
          2086,
          11,
          286,
          360,
          1604,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 262.59999999999997,
        "id": 68,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 260.68,
        "temperature": 0,
        "text": " And yes, there will be JavaScript stuff today.",
        "tokens": [
          51396,
          400,
          2086,
          11,
          456,
          486,
          312,
          15778,
          1507,
          965,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.19313219038106627,
        "compression_ratio": 1.6398467432950192,
        "end": 266.12,
        "id": 69,
        "no_speech_prob": 0.007011260837316513,
        "seek": 24004,
        "start": 262.59999999999997,
        "temperature": 0,
        "text": " So the coding that I will do after I talk about the processing fellowships,",
        "tokens": [
          51492,
          407,
          264,
          17720,
          300,
          286,
          486,
          360,
          934,
          286,
          751,
          466,
          264,
          9007,
          24989,
          82,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 271.88,
        "id": 70,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 267,
        "temperature": 0,
        "text": " I'm going to look at sentiment analysis with a word list known as the AFIN111.",
        "tokens": [
          50408,
          286,
          478,
          516,
          281,
          574,
          412,
          16149,
          5215,
          365,
          257,
          1349,
          1329,
          2570,
          382,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 273.88,
        "id": 71,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 273.08,
        "temperature": 0,
        "text": " Is that what you woke?",
        "tokens": [
          50712,
          1119,
          300,
          437,
          291,
          12852,
          30,
          50752
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 275.16,
        "id": 72,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 273.88,
        "temperature": 0,
        "text": " You were like, you're lying in bed.",
        "tokens": [
          50752,
          509,
          645,
          411,
          11,
          291,
          434,
          8493,
          294,
          2901,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 277.8,
        "id": 73,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 277,
        "temperature": 0,
        "text": " Your alarm went off.",
        "tokens": [
          50908,
          2260,
          14183,
          1437,
          766,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 283.16,
        "id": 74,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 279.96,
        "temperature": 0,
        "text": " And you woke up and you thought, I know what I'm going to do today.",
        "tokens": [
          51056,
          400,
          291,
          12852,
          493,
          293,
          291,
          1194,
          11,
          286,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          965,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 284.36,
        "id": 75,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 283.16,
        "temperature": 0,
        "text": " I'm going to turn off my computer.",
        "tokens": [
          51216,
          286,
          478,
          516,
          281,
          1261,
          766,
          452,
          3820,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 287.8,
        "id": 76,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 284.36,
        "temperature": 0,
        "text": " I'm going to watch somebody talk about AFIN111 sentiment analysis on YouTube.",
        "tokens": [
          51276,
          286,
          478,
          516,
          281,
          1159,
          2618,
          751,
          466,
          20389,
          1464,
          5348,
          16,
          16149,
          5215,
          322,
          3088,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 289.16,
        "id": 77,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 287.8,
        "temperature": 0,
        "text": " Well, that's what's happening.",
        "tokens": [
          51448,
          1042,
          11,
          300,
          311,
          437,
          311,
          2737,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 290.6,
        "id": 78,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 289.8,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51548,
          876,
          11,
          1338,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2300543818913453,
        "compression_ratio": 1.6857142857142857,
        "end": 295.88,
        "id": 79,
        "no_speech_prob": 0.010012932121753693,
        "seek": 26612,
        "start": 290.6,
        "temperature": 0,
        "text": " By the way, I noticed that Lourdes in the chat mentions everyone check out Siraj's channel.",
        "tokens": [
          51588,
          3146,
          264,
          636,
          11,
          286,
          5694,
          300,
          441,
          396,
          14792,
          294,
          264,
          5081,
          23844,
          1518,
          1520,
          484,
          6144,
          1805,
          311,
          2269,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 299.64,
        "id": 80,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 296.2,
        "temperature": 0,
        "text": " I noticed, actually, I got a notification that Siraj was also doing a live stream.",
        "tokens": [
          50380,
          286,
          5694,
          11,
          767,
          11,
          286,
          658,
          257,
          11554,
          300,
          6144,
          1805,
          390,
          611,
          884,
          257,
          1621,
          4309,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 301.32,
        "id": 81,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 299.64,
        "temperature": 0,
        "text": " Does anyone know if that's still going on?",
        "tokens": [
          50552,
          4402,
          2878,
          458,
          498,
          300,
          311,
          920,
          516,
          322,
          30,
          50636
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 302.12,
        "id": 82,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 301.32,
        "temperature": 0,
        "text": " Let's pull it up.",
        "tokens": [
          50636,
          961,
          311,
          2235,
          309,
          493,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 305.15999999999997,
        "id": 83,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 302.76,
        "temperature": 0,
        "text": " Let's see if we can embed a live stream.",
        "tokens": [
          50708,
          961,
          311,
          536,
          498,
          321,
          393,
          12240,
          257,
          1621,
          4309,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 307.56,
        "id": 84,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 306.28,
        "temperature": 0,
        "text": " Siraj YouTube.",
        "tokens": [
          50884,
          6144,
          1805,
          3088,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 311.56,
        "id": 85,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 310.2,
        "temperature": 0,
        "text": " No, that's not right.",
        "tokens": [
          51080,
          883,
          11,
          300,
          311,
          406,
          558,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 313.56,
        "id": 86,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 311.56,
        "temperature": 0,
        "text": " Sirajology.",
        "tokens": [
          51148,
          6144,
          1805,
          1793,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 315.08,
        "id": 87,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 314.2,
        "temperature": 0,
        "text": " Sirajology?",
        "tokens": [
          51280,
          6144,
          1805,
          1793,
          30,
          51324
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 316.84,
        "id": 88,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 315.8,
        "temperature": 0,
        "text": " Sirajology.",
        "tokens": [
          51360,
          6144,
          1805,
          1793,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 319.48,
        "id": 89,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 318.2,
        "temperature": 0,
        "text": " Is he live right now?",
        "tokens": [
          51480,
          1119,
          415,
          1621,
          558,
          586,
          30,
          51544
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 319.96,
        "id": 90,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 319.48,
        "temperature": 0,
        "text": " Live.",
        "tokens": [
          51544,
          10385,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 321.96,
        "id": 91,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 320.84,
        "temperature": 0,
        "text": " Oh, but this is finished.",
        "tokens": [
          51612,
          876,
          11,
          457,
          341,
          307,
          4335,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 323.24,
        "id": 92,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 322.68,
        "temperature": 0,
        "text": " So I won't.",
        "tokens": [
          51704,
          407,
          286,
          1582,
          380,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.1973790734764037,
        "compression_ratio": 1.6195121951219513,
        "end": 324.12,
        "id": 93,
        "no_speech_prob": 0.0002611799573060125,
        "seek": 29588,
        "start": 323.24,
        "temperature": 0,
        "text": " I won't.",
        "tokens": [
          51732,
          286,
          1582,
          380,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 326.6,
        "id": 94,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 324.2,
        "temperature": 0,
        "text": " So anyway, I'm sure this was a great live stream.",
        "tokens": [
          50368,
          407,
          4033,
          11,
          286,
          478,
          988,
          341,
          390,
          257,
          869,
          1621,
          4309,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 328.68,
        "id": 95,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 327.48,
        "temperature": 0,
        "text": " Oh, by the way, am I in focus?",
        "tokens": [
          50532,
          876,
          11,
          538,
          264,
          636,
          11,
          669,
          286,
          294,
          1879,
          30,
          50592
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 329.88,
        "id": 96,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 328.68,
        "temperature": 0,
        "text": " The camera was all out of focus.",
        "tokens": [
          50592,
          440,
          2799,
          390,
          439,
          484,
          295,
          1879,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 331.56,
        "id": 97,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 329.88,
        "temperature": 0,
        "text": " I just randomly focused it.",
        "tokens": [
          50652,
          286,
          445,
          16979,
          5178,
          309,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 337.48,
        "id": 98,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 332.28000000000003,
        "temperature": 0,
        "text": " So I don't know if I got myself in focus.",
        "tokens": [
          50772,
          407,
          286,
          500,
          380,
          458,
          498,
          286,
          658,
          2059,
          294,
          1879,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 341.48,
        "id": 99,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 338.6,
        "temperature": 0,
        "text": " Siraj, I've been talking about Siraj doing a collaboration with him.",
        "tokens": [
          51088,
          6144,
          1805,
          11,
          286,
          600,
          668,
          1417,
          466,
          6144,
          1805,
          884,
          257,
          9363,
          365,
          796,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 344.04,
        "id": 100,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 341.48,
        "temperature": 0,
        "text": " So I hope hopefully that will come at some point soon.",
        "tokens": [
          51232,
          407,
          286,
          1454,
          4696,
          300,
          486,
          808,
          412,
          512,
          935,
          2321,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 345.88,
        "id": 101,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 344.04,
        "temperature": 0,
        "text": " I'm hoping to do some videos about machine learning.",
        "tokens": [
          51360,
          286,
          478,
          7159,
          281,
          360,
          512,
          2145,
          466,
          3479,
          2539,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 346.68,
        "id": 102,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 345.88,
        "temperature": 0,
        "text": " He does a ton of them.",
        "tokens": [
          51452,
          634,
          775,
          257,
          2952,
          295,
          552,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 347.48,
        "id": 103,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 346.68,
        "temperature": 0,
        "text": " They're really terrific.",
        "tokens": [
          51492,
          814,
          434,
          534,
          20899,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 349.32,
        "id": 104,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 348.76,
        "temperature": 0,
        "text": " I love them.",
        "tokens": [
          51596,
          286,
          959,
          552,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 349.96,
        "id": 105,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 349.32,
        "temperature": 0,
        "text": " I watch them.",
        "tokens": [
          51624,
          286,
          1159,
          552,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 352.04,
        "id": 106,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 349.96,
        "temperature": 0,
        "text": " And then I think, oh, maybe I could learn this stuff too.",
        "tokens": [
          51656,
          400,
          550,
          286,
          519,
          11,
          1954,
          11,
          1310,
          286,
          727,
          1466,
          341,
          1507,
          886,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.18596929158919898,
        "compression_ratio": 1.6511627906976745,
        "end": 353.32,
        "id": 107,
        "no_speech_prob": 0.006289617158472538,
        "seek": 32412,
        "start": 352.92,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51804,
          2264,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 354.59999999999997,
        "id": 108,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 353.64,
        "temperature": 0,
        "text": " Sorry, I got sidetracked.",
        "tokens": [
          50380,
          4919,
          11,
          286,
          658,
          20822,
          27965,
          25949,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 355.48,
        "id": 109,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 354.59999999999997,
        "temperature": 0,
        "text": " What was I talking about?",
        "tokens": [
          50428,
          708,
          390,
          286,
          1417,
          466,
          30,
          50472
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 359.08,
        "id": 110,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 356.12,
        "temperature": 0,
        "text": " OK, so the AFIN111 text stuff, I'm going to finish off.",
        "tokens": [
          50504,
          2264,
          11,
          370,
          264,
          20389,
          1464,
          5348,
          16,
          2487,
          1507,
          11,
          286,
          478,
          516,
          281,
          2413,
          766,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 364.04,
        "id": 111,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 359.08,
        "temperature": 0,
        "text": " So I want to do a coding challenge of just AFIN111 in the browser just to look at, hey,",
        "tokens": [
          50652,
          407,
          286,
          528,
          281,
          360,
          257,
          17720,
          3430,
          295,
          445,
          20389,
          1464,
          5348,
          16,
          294,
          264,
          11185,
          445,
          281,
          574,
          412,
          11,
          4177,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 368.52,
        "id": 112,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 364.04,
        "temperature": 0,
        "text": " I typed some text into a text field, and it gives me a sentiment score at the bottom.",
        "tokens": [
          50900,
          286,
          33941,
          512,
          2487,
          666,
          257,
          2487,
          2519,
          11,
          293,
          309,
          2709,
          385,
          257,
          16149,
          6175,
          412,
          264,
          2767,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 373.71999999999997,
        "id": 113,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 369.24,
        "temperature": 0,
        "text": " And then I'll also talk about other kinds of sentiment analysis beyond just this one",
        "tokens": [
          51160,
          400,
          550,
          286,
          603,
          611,
          751,
          466,
          661,
          3685,
          295,
          16149,
          5215,
          4399,
          445,
          341,
          472,
          51384
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 375.88,
        "id": 114,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 373.71999999999997,
        "temperature": 0,
        "text": " technique, which is a very simple approach.",
        "tokens": [
          51384,
          6532,
          11,
          597,
          307,
          257,
          588,
          2199,
          3109,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2139051547948865,
        "compression_ratio": 1.6490066225165563,
        "end": 382.52,
        "id": 115,
        "no_speech_prob": 0.0003301390679553151,
        "seek": 35332,
        "start": 377.08,
        "temperature": 0,
        "text": " And then if there's, and then I want to also finish off my examples about building your",
        "tokens": [
          51552,
          400,
          550,
          498,
          456,
          311,
          11,
          293,
          550,
          286,
          528,
          281,
          611,
          2413,
          766,
          452,
          5110,
          466,
          2390,
          428,
          51824
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 384.03999999999996,
        "id": 116,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 382.52,
        "temperature": 0,
        "text": " own API in Node.",
        "tokens": [
          50364,
          1065,
          9362,
          294,
          38640,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 390.35999999999996,
        "id": 117,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 384.03999999999996,
        "temperature": 0,
        "text": " So once we do the sentiment analysis in the browser, we'll transfer that into Node and",
        "tokens": [
          50440,
          407,
          1564,
          321,
          360,
          264,
          16149,
          5215,
          294,
          264,
          11185,
          11,
          321,
          603,
          5003,
          300,
          666,
          38640,
          293,
          50756
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 395.56,
        "id": 118,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 390.35999999999996,
        "temperature": 0,
        "text": " make a sentiment analysis API and look at what it means to make a POST request versus",
        "tokens": [
          50756,
          652,
          257,
          16149,
          5215,
          9362,
          293,
          574,
          412,
          437,
          309,
          1355,
          281,
          652,
          257,
          430,
          28067,
          5308,
          5717,
          51016
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 396.35999999999996,
        "id": 119,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 395.56,
        "temperature": 0,
        "text": " a GET request.",
        "tokens": [
          51016,
          257,
          28091,
          5308,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 398.59999999999997,
        "id": 120,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 396.35999999999996,
        "temperature": 0,
        "text": " So that's on my list for today.",
        "tokens": [
          51056,
          407,
          300,
          311,
          322,
          452,
          1329,
          337,
          965,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 403.4,
        "id": 121,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 400.12,
        "temperature": 0,
        "text": " And then if there's extra time, I got some other things I would love to do.",
        "tokens": [
          51244,
          400,
          550,
          498,
          456,
          311,
          2857,
          565,
          11,
          286,
          658,
          512,
          661,
          721,
          286,
          576,
          959,
          281,
          360,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 404.59999999999997,
        "id": 122,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 403.4,
        "temperature": 0,
        "text": " I keep whacking the microphone.",
        "tokens": [
          51408,
          286,
          1066,
          315,
          14134,
          264,
          10952,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.14808928749778055,
        "compression_ratio": 1.6131687242798354,
        "end": 406.35999999999996,
        "id": 123,
        "no_speech_prob": 0.00024536674027331173,
        "seek": 38252,
        "start": 404.59999999999997,
        "temperature": 0,
        "text": " I hope that's not making a weird sound for you.",
        "tokens": [
          51468,
          286,
          1454,
          300,
          311,
          406,
          1455,
          257,
          3657,
          1626,
          337,
          291,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 412.92,
        "id": 124,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 407.16,
        "temperature": 0,
        "text": " So let me say just a few quick words of where to find out more.",
        "tokens": [
          50404,
          407,
          718,
          385,
          584,
          445,
          257,
          1326,
          1702,
          2283,
          295,
          689,
          281,
          915,
          484,
          544,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 420.44,
        "id": 125,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 412.92,
        "temperature": 0,
        "text": " So at this website, which is hmmhmm.com, if you go there, you can subscribe.",
        "tokens": [
          50692,
          407,
          412,
          341,
          3144,
          11,
          597,
          307,
          16478,
          10250,
          13,
          1112,
          11,
          498,
          291,
          352,
          456,
          11,
          291,
          393,
          3022,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 423.72,
        "id": 126,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 420.44,
        "temperature": 0,
        "text": " You can become a patron if you are so inclined.",
        "tokens": [
          51068,
          509,
          393,
          1813,
          257,
          21843,
          498,
          291,
          366,
          370,
          28173,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 427.48,
        "id": 127,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 423.72,
        "temperature": 0,
        "text": " And there's a Slack channel that comes as a benefit of being a patron on this service",
        "tokens": [
          51232,
          400,
          456,
          311,
          257,
          37211,
          2269,
          300,
          1487,
          382,
          257,
          5121,
          295,
          885,
          257,
          21843,
          322,
          341,
          2643,
          51420
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 428.2,
        "id": 128,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 427.48,
        "temperature": 0,
        "text": " called Patreon.",
        "tokens": [
          51420,
          1219,
          15692,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.1797651216095569,
        "compression_ratio": 1.548936170212766,
        "end": 432.12,
        "id": 129,
        "no_speech_prob": 0.29090404510498047,
        "seek": 40636,
        "start": 428.84000000000003,
        "temperature": 0,
        "text": " One thing I just want to point out, though, is I get this question a lot.",
        "tokens": [
          51488,
          1485,
          551,
          286,
          445,
          528,
          281,
          935,
          484,
          11,
          1673,
          11,
          307,
          286,
          483,
          341,
          1168,
          257,
          688,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 438.92,
        "id": 130,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 433,
        "temperature": 0,
        "text": " So these days with my live streams, I'm kind of off into the weeds of doing examples and",
        "tokens": [
          50408,
          407,
          613,
          1708,
          365,
          452,
          1621,
          15842,
          11,
          286,
          478,
          733,
          295,
          766,
          666,
          264,
          26370,
          295,
          884,
          5110,
          293,
          50704
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 443.56,
        "id": 131,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 438.92,
        "temperature": 0,
        "text": " coding ideas, assuming that the people watching have done some programming before.",
        "tokens": [
          50704,
          17720,
          3487,
          11,
          11926,
          300,
          264,
          561,
          1976,
          362,
          1096,
          512,
          9410,
          949,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 447.4,
        "id": 132,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 443.56,
        "temperature": 0,
        "text": " And obviously, everybody watching, I'm sure, has a variety of different levels of experience.",
        "tokens": [
          50936,
          400,
          2745,
          11,
          2201,
          1976,
          11,
          286,
          478,
          988,
          11,
          575,
          257,
          5673,
          295,
          819,
          4358,
          295,
          1752,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 452.36,
        "id": 133,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 448.2,
        "temperature": 0,
        "text": " But I always get the question, oh, what should I do if I don't know anything, if I want to",
        "tokens": [
          51168,
          583,
          286,
          1009,
          483,
          264,
          1168,
          11,
          1954,
          11,
          437,
          820,
          286,
          360,
          498,
          286,
          500,
          380,
          458,
          1340,
          11,
          498,
          286,
          528,
          281,
          51376
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 454.28000000000003,
        "id": 134,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 452.36,
        "temperature": 0,
        "text": " start learning to program from scratch?",
        "tokens": [
          51376,
          722,
          2539,
          281,
          1461,
          490,
          8459,
          30,
          51472
        ]
      },
      {
        "avg_logprob": -0.16500513670874423,
        "compression_ratio": 1.6241610738255035,
        "end": 459.8,
        "id": 135,
        "no_speech_prob": 0.001432520803064108,
        "seek": 43212,
        "start": 454.28000000000003,
        "temperature": 0,
        "text": " And so this playlist that's at the CodingRainbow.com website, you can look at that one,",
        "tokens": [
          51472,
          400,
          370,
          341,
          16788,
          300,
          311,
          412,
          264,
          383,
          8616,
          49,
          491,
          8202,
          13,
          1112,
          3144,
          11,
          291,
          393,
          574,
          412,
          300,
          472,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 464.36,
        "id": 136,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 460.44,
        "temperature": 0,
        "text": " this will assume no knowledge of programming whatsoever and get you started using JavaScript.",
        "tokens": [
          50396,
          341,
          486,
          6552,
          572,
          3601,
          295,
          9410,
          17076,
          293,
          483,
          291,
          1409,
          1228,
          15778,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 467.72,
        "id": 137,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 464.36,
        "temperature": 0,
        "text": " Of course, there are many other languages and other videos and books and things you",
        "tokens": [
          50592,
          2720,
          1164,
          11,
          456,
          366,
          867,
          661,
          8650,
          293,
          661,
          2145,
          293,
          3642,
          293,
          721,
          291,
          50760
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 468.84000000000003,
        "id": 138,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 467.72,
        "temperature": 0,
        "text": " can use to get started.",
        "tokens": [
          50760,
          393,
          764,
          281,
          483,
          1409,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 472.12,
        "id": 139,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 468.84000000000003,
        "temperature": 0,
        "text": " But if you're looking for my stuff, this is what I would recommend right here.",
        "tokens": [
          50816,
          583,
          498,
          291,
          434,
          1237,
          337,
          452,
          1507,
          11,
          341,
          307,
          437,
          286,
          576,
          2748,
          558,
          510,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 477.88,
        "id": 140,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 472.76,
        "temperature": 0,
        "text": " I also have another playlist for processing, which is a Java-based environment, which is",
        "tokens": [
          51012,
          286,
          611,
          362,
          1071,
          16788,
          337,
          9007,
          11,
          597,
          307,
          257,
          10745,
          12,
          6032,
          2823,
          11,
          597,
          307,
          51268
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 480.44,
        "id": 141,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 477.88,
        "temperature": 0,
        "text": " beginner, for complete beginners that you can look at.",
        "tokens": [
          51268,
          22080,
          11,
          337,
          3566,
          26992,
          300,
          291,
          393,
          574,
          412,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 482.52,
        "id": 142,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 480.44,
        "temperature": 0,
        "text": " And there's a textbook that goes along with that as well.",
        "tokens": [
          51396,
          400,
          456,
          311,
          257,
          25591,
          300,
          1709,
          2051,
          365,
          300,
          382,
          731,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 483.48,
        "id": 143,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 483.16,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51532,
          2264,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.20706744492053986,
        "compression_ratio": 1.6645367412140575,
        "end": 487.8,
        "id": 144,
        "no_speech_prob": 0.04813374578952789,
        "seek": 45980,
        "start": 486.12,
        "temperature": 0,
        "text": " So what else do I need to mention?",
        "tokens": [
          51680,
          407,
          437,
          1646,
          360,
          286,
          643,
          281,
          2152,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 492.68,
        "id": 145,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 487.8,
        "temperature": 0,
        "text": " So I mentioned that I do send out emails periodically when I have a schedule for my",
        "tokens": [
          50364,
          407,
          286,
          2835,
          300,
          286,
          360,
          2845,
          484,
          12524,
          38916,
          562,
          286,
          362,
          257,
          7567,
          337,
          452,
          50608
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 493.24,
        "id": 146,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 492.68,
        "temperature": 0,
        "text": " live stream.",
        "tokens": [
          50608,
          1621,
          4309,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 494.92,
        "id": 147,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 493.24,
        "temperature": 0,
        "text": " And you can also sign up for that here.",
        "tokens": [
          50636,
          400,
          291,
          393,
          611,
          1465,
          493,
          337,
          300,
          510,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 497.08,
        "id": 148,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 496.6,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50804,
          961,
          311,
          536,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 497.72,
        "id": 149,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 497.08,
        "temperature": 0,
        "text": " Anything else?",
        "tokens": [
          50828,
          11998,
          1646,
          30,
          50860
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 503.16,
        "id": 150,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 500.04,
        "temperature": 0,
        "text": " I do have my little soundboard, if you guys want to indulge me for a second.",
        "tokens": [
          50976,
          286,
          360,
          362,
          452,
          707,
          1626,
          3787,
          11,
          498,
          291,
          1074,
          528,
          281,
          28626,
          432,
          385,
          337,
          257,
          1150,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 504.92,
        "id": 151,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 503.8,
        "temperature": 0,
        "text": " I can try to get that hooked up.",
        "tokens": [
          51164,
          286,
          393,
          853,
          281,
          483,
          300,
          20410,
          493,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 506.44,
        "id": 152,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 504.92,
        "temperature": 0,
        "text": " Let me see something here.",
        "tokens": [
          51220,
          961,
          385,
          536,
          746,
          510,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 513.64,
        "id": 153,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 506.44,
        "temperature": 0,
        "text": " Let's go back to Siraj and see if, because I want to see if sound is working.",
        "tokens": [
          51296,
          961,
          311,
          352,
          646,
          281,
          6144,
          1805,
          293,
          536,
          498,
          11,
          570,
          286,
          528,
          281,
          536,
          498,
          1626,
          307,
          1364,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 515.4,
        "id": 154,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 514.76,
        "temperature": 0,
        "text": " We're going to play.",
        "tokens": [
          51712,
          492,
          434,
          516,
          281,
          862,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 515.8,
        "id": 155,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 515.4,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51744,
          21726,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1822723732855087,
        "compression_ratio": 1.61003861003861,
        "end": 516.52,
        "id": 156,
        "no_speech_prob": 0.013427871279418468,
        "seek": 48780,
        "start": 515.8,
        "temperature": 0,
        "text": " Oh, no, add.",
        "tokens": [
          51764,
          876,
          11,
          572,
          11,
          909,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 519.48,
        "id": 157,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 517.24,
        "temperature": 0,
        "text": " I'm not being paid to play this ad.",
        "tokens": [
          50400,
          286,
          478,
          406,
          885,
          4835,
          281,
          862,
          341,
          614,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 519.8,
        "id": 158,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 519.48,
        "temperature": 0,
        "text": " Skip.",
        "tokens": [
          50512,
          46405,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 527.3199999999999,
        "id": 159,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 524.92,
        "temperature": 0,
        "text": " I don't think you guys can hear Siraj.",
        "tokens": [
          50784,
          286,
          500,
          380,
          519,
          291,
          1074,
          393,
          1568,
          6144,
          1805,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 528.28,
        "id": 160,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 527.3199999999999,
        "temperature": 0,
        "text": " So I need to fix this.",
        "tokens": [
          50904,
          407,
          286,
          643,
          281,
          3191,
          341,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 533.72,
        "id": 161,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 529,
        "temperature": 0,
        "text": " System preferences, sound, multi-output device.",
        "tokens": [
          50988,
          8910,
          21910,
          11,
          1626,
          11,
          4825,
          12,
          346,
          2582,
          4302,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 535.4,
        "id": 162,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 533.72,
        "temperature": 0,
        "text": " This might change the sound in a second.",
        "tokens": [
          51224,
          639,
          1062,
          1319,
          264,
          1626,
          294,
          257,
          1150,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 539.96,
        "id": 163,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 539.0799999999999,
        "temperature": 0,
        "text": " Speak, Siraj.",
        "tokens": [
          51492,
          27868,
          11,
          6144,
          1805,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.20342847898408964,
        "compression_ratio": 1.3875,
        "end": 545.56,
        "id": 164,
        "no_speech_prob": 0.0007553720497526228,
        "seek": 51652,
        "start": 544.6,
        "temperature": 0,
        "text": " See who we got.",
        "tokens": [
          51768,
          3008,
          567,
          321,
          658,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 547.24,
        "id": 165,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 546.52,
        "temperature": 0,
        "text": " What is that sound?",
        "tokens": [
          50364,
          708,
          307,
          300,
          1626,
          30,
          50400
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 548.04,
        "id": 166,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 547.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50428,
          2264,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 548.76,
        "id": 167,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 548.04,
        "temperature": 0,
        "text": " I heard some music.",
        "tokens": [
          50440,
          286,
          2198,
          512,
          1318,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 550.52,
        "id": 168,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 549.8,
        "temperature": 0,
        "text": " Oh, what is that?",
        "tokens": [
          50528,
          876,
          11,
          437,
          307,
          300,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 551,
        "id": 169,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 550.52,
        "temperature": 0,
        "text": " What is that?",
        "tokens": [
          50564,
          708,
          307,
          300,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 552.04,
        "id": 170,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 551,
        "temperature": 0,
        "text": " Hi, Siraj.",
        "tokens": [
          50588,
          2421,
          11,
          6144,
          1805,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 557.0799999999999,
        "id": 171,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 552.04,
        "temperature": 0,
        "text": " This is like some sort of weird meta performance thing where I'm speaking to you as if.",
        "tokens": [
          50640,
          639,
          307,
          411,
          512,
          1333,
          295,
          3657,
          19616,
          3389,
          551,
          689,
          286,
          478,
          4124,
          281,
          291,
          382,
          498,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 557.4,
        "id": 172,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 557.0799999999999,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          50892,
          2492,
          322,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 557.8,
        "id": 173,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 557.4,
        "temperature": 0,
        "text": " It's OK.",
        "tokens": [
          50908,
          467,
          311,
          2264,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 558.68,
        "id": 174,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 557.8,
        "temperature": 0,
        "text": " The sound is working.",
        "tokens": [
          50928,
          440,
          1626,
          307,
          1364,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 559.72,
        "id": 175,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 558.68,
        "temperature": 0,
        "text": " You're live, except you're not.",
        "tokens": [
          50972,
          509,
          434,
          1621,
          11,
          3993,
          291,
          434,
          406,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 560.68,
        "id": 176,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 559.72,
        "temperature": 0,
        "text": " This is recorded.",
        "tokens": [
          51024,
          639,
          307,
          8287,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 561.4,
        "id": 177,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 560.68,
        "temperature": 0,
        "text": " Hearing something.",
        "tokens": [
          51072,
          37875,
          746,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 563.3199999999999,
        "id": 178,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 561.4,
        "temperature": 0,
        "text": " See, look, we're doing a collaboration already.",
        "tokens": [
          51108,
          3008,
          11,
          574,
          11,
          321,
          434,
          884,
          257,
          9363,
          1217,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 564.28,
        "id": 179,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 563.3199999999999,
        "temperature": 0,
        "text": " I didn't realize it.",
        "tokens": [
          51204,
          286,
          994,
          380,
          4325,
          309,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 566.36,
        "id": 180,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 564.28,
        "temperature": 0,
        "text": " Somebody snapshot this and tweet it to Siraj.",
        "tokens": [
          51252,
          13463,
          30163,
          341,
          293,
          15258,
          309,
          281,
          6144,
          1805,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 569.24,
        "id": 181,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 566.36,
        "temperature": 0,
        "text": " I'm sure he would appreciate this weird thing that's happening right here.",
        "tokens": [
          51356,
          286,
          478,
          988,
          415,
          576,
          4449,
          341,
          3657,
          551,
          300,
          311,
          2737,
          558,
          510,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 571.24,
        "id": 182,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 569.24,
        "temperature": 0,
        "text": " But I think you're hearing the sound.",
        "tokens": [
          51500,
          583,
          286,
          519,
          291,
          434,
          4763,
          264,
          1626,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.19958693330938165,
        "compression_ratio": 1.6899696048632218,
        "end": 575.96,
        "id": 183,
        "no_speech_prob": 0.00036257406463846564,
        "seek": 54652,
        "start": 573.3199999999999,
        "temperature": 0,
        "text": " And I could also do this and talk to myself.",
        "tokens": [
          51704,
          400,
          286,
          727,
          611,
          360,
          341,
          293,
          751,
          281,
          2059,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 577.08,
        "id": 184,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 575.96,
        "temperature": 0,
        "text": " And that would be a little bit weird.",
        "tokens": [
          50364,
          400,
          300,
          576,
          312,
          257,
          707,
          857,
          3657,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 577.32,
        "id": 185,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 577.08,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50420,
          2264,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 583.5600000000001,
        "id": 186,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 577.88,
        "temperature": 0,
        "text": " Now what I want to do here is go to soundboard.",
        "tokens": [
          50460,
          823,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          352,
          281,
          1626,
          3787,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 585,
        "id": 187,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 583.5600000000001,
        "temperature": 0,
        "text": " I have this soundboard app.",
        "tokens": [
          50744,
          286,
          362,
          341,
          1626,
          3787,
          724,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 592.2800000000001,
        "id": 188,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 586.2800000000001,
        "temperature": 0,
        "text": " And I can airplay it to this laptop.",
        "tokens": [
          50880,
          400,
          286,
          393,
          1988,
          2858,
          309,
          281,
          341,
          10732,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 593.32,
        "id": 189,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 592.2800000000001,
        "temperature": 0,
        "text": " You're going to see it in a second.",
        "tokens": [
          51180,
          509,
          434,
          516,
          281,
          536,
          309,
          294,
          257,
          1150,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 596.84,
        "id": 190,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 595.32,
        "temperature": 0,
        "text": " Oh, mirroring on.",
        "tokens": [
          51332,
          876,
          11,
          8013,
          278,
          322,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 599,
        "id": 191,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 598.2800000000001,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51480,
          821,
          321,
          352,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 602.84,
        "id": 192,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 600.12,
        "temperature": 0,
        "text": " And now you're seeing my soundboard, by the way.",
        "tokens": [
          51572,
          400,
          586,
          291,
          434,
          2577,
          452,
          1626,
          3787,
          11,
          538,
          264,
          636,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2158651806059338,
        "compression_ratio": 1.5728643216080402,
        "end": 605.48,
        "id": 193,
        "no_speech_prob": 0.0007096478366293013,
        "seek": 57596,
        "start": 602.84,
        "temperature": 0,
        "text": " This is how this little behind the scenes.",
        "tokens": [
          51708,
          639,
          307,
          577,
          341,
          707,
          2261,
          264,
          8026,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 606.36,
        "id": 194,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 605.48,
        "temperature": 0,
        "text": " Behind the music.",
        "tokens": [
          50364,
          20475,
          264,
          1318,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 608.2,
        "id": 195,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 607.08,
        "temperature": 0,
        "text": " So let's see if this works.",
        "tokens": [
          50444,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 614.6,
        "id": 196,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 612.44,
        "temperature": 0,
        "text": " Does that sound horribly loud?",
        "tokens": [
          50712,
          4402,
          300,
          1626,
          45028,
          6588,
          30,
          50820
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 619.16,
        "id": 197,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 615.64,
        "temperature": 0,
        "text": " As always, I always forget the this dot, this dot, this dot, this dot.",
        "tokens": [
          50872,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 620.84,
        "id": 198,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 619.16,
        "temperature": 0,
        "text": " I'm going to do this dot, this dot.",
        "tokens": [
          51048,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 623.32,
        "id": 199,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 620.84,
        "temperature": 0,
        "text": " I'm going to do this, this dot, this dot, this dot.",
        "tokens": [
          51132,
          286,
          478,
          516,
          281,
          360,
          341,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 624.44,
        "id": 200,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 623.32,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          51256,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 626.36,
        "id": 201,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 624.44,
        "temperature": 0,
        "text": " So it looks like I have a soundboard working.",
        "tokens": [
          51312,
          407,
          309,
          1542,
          411,
          286,
          362,
          257,
          1626,
          3787,
          1364,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 629.5600000000001,
        "id": 202,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 626.36,
        "temperature": 0,
        "text": " In case I need to play some music or things, I can minimize this.",
        "tokens": [
          51408,
          682,
          1389,
          286,
          643,
          281,
          862,
          512,
          1318,
          420,
          721,
          11,
          286,
          393,
          17522,
          341,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 631.8000000000001,
        "id": 203,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 629.5600000000001,
        "temperature": 0,
        "text": " You guys can let me know if the audio is a problem.",
        "tokens": [
          51568,
          509,
          1074,
          393,
          718,
          385,
          458,
          498,
          264,
          6278,
          307,
          257,
          1154,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.17951665224728885,
        "compression_ratio": 1.9535864978902953,
        "end": 635.16,
        "id": 204,
        "no_speech_prob": 0.0005702982889488339,
        "seek": 60548,
        "start": 633.32,
        "temperature": 0,
        "text": " Nobody could get that screenshot in time.",
        "tokens": [
          51756,
          9297,
          727,
          483,
          300,
          27712,
          294,
          565,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 637.24,
        "id": 205,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 635.56,
        "temperature": 0,
        "text": " You can reverse back in time.",
        "tokens": [
          50384,
          509,
          393,
          9943,
          646,
          294,
          565,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 639.88,
        "id": 206,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 638.6,
        "temperature": 0,
        "text": " Maybe somebody else got it.",
        "tokens": [
          50536,
          2704,
          2618,
          1646,
          658,
          309,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 640.68,
        "id": 207,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 639.88,
        "temperature": 0,
        "text": " It doesn't really matter.",
        "tokens": [
          50600,
          467,
          1177,
          380,
          534,
          1871,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 641.3199999999999,
        "id": 208,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 640.68,
        "temperature": 0,
        "text": " This will be there.",
        "tokens": [
          50640,
          639,
          486,
          312,
          456,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 644.4399999999999,
        "id": 209,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 641.3199999999999,
        "temperature": 0,
        "text": " Somebody will watch this later and then screenshot it then,",
        "tokens": [
          50672,
          13463,
          486,
          1159,
          341,
          1780,
          293,
          550,
          27712,
          309,
          550,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 645.64,
        "id": 210,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 644.4399999999999,
        "temperature": 0,
        "text": " thinking they're watching it live.",
        "tokens": [
          50828,
          1953,
          436,
          434,
          1976,
          309,
          1621,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 646.14,
        "id": 211,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 645.64,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50888,
          2264,
          13,
          50913
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 649.8,
        "id": 212,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 649.24,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51068,
          1057,
          558,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 651,
        "id": 213,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 649.8,
        "temperature": 0,
        "text": " You guys love that song.",
        "tokens": [
          51096,
          509,
          1074,
          959,
          300,
          2153,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 652.28,
        "id": 214,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 651,
        "temperature": 0,
        "text": " Somebody sent me a new song.",
        "tokens": [
          51156,
          13463,
          2279,
          385,
          257,
          777,
          2153,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 656.92,
        "id": 215,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 653.3199999999999,
        "temperature": 0,
        "text": " Lost G Bear on Slack sent me a new song that I don't have loaded yet.",
        "tokens": [
          51272,
          23422,
          460,
          19836,
          322,
          37211,
          2279,
          385,
          257,
          777,
          2153,
          300,
          286,
          500,
          380,
          362,
          13210,
          1939,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 659.3199999999999,
        "id": 216,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 656.92,
        "temperature": 0,
        "text": " If you're watching, I don't know if I got the name right.",
        "tokens": [
          51452,
          759,
          291,
          434,
          1976,
          11,
          286,
          500,
          380,
          458,
          498,
          286,
          658,
          264,
          1315,
          558,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 659.8,
        "id": 217,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 659.3199999999999,
        "temperature": 0,
        "text": " Let me know.",
        "tokens": [
          51572,
          961,
          385,
          458,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 661,
        "id": 218,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 659.8,
        "temperature": 0,
        "text": " Maybe I'll play that song.",
        "tokens": [
          51596,
          2704,
          286,
          603,
          862,
          300,
          2153,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1813608335968632,
        "compression_ratio": 1.750915750915751,
        "end": 664.28,
        "id": 219,
        "no_speech_prob": 0.00039820739766582847,
        "seek": 63516,
        "start": 661.56,
        "temperature": 0,
        "text": " I'm hoping to have a new logo, a new name.",
        "tokens": [
          51684,
          286,
          478,
          7159,
          281,
          362,
          257,
          777,
          9699,
          11,
          257,
          777,
          1315,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 667.4,
        "id": 220,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 665.16,
        "temperature": 0,
        "text": " A new song, a new video, all of these things.",
        "tokens": [
          50364,
          316,
          777,
          2153,
          11,
          257,
          777,
          960,
          11,
          439,
          295,
          613,
          721,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 672.28,
        "id": 221,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 667.4,
        "temperature": 0,
        "text": " It's really unfortunate that I have this name and logo and video and song.",
        "tokens": [
          50476,
          467,
          311,
          534,
          17843,
          300,
          286,
          362,
          341,
          1315,
          293,
          9699,
          293,
          960,
          293,
          2153,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 674.28,
        "id": 222,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 672.28,
        "temperature": 0,
        "text": " And unfortunately, I can't use the name anymore.",
        "tokens": [
          50720,
          400,
          7015,
          11,
          286,
          393,
          380,
          764,
          264,
          1315,
          3602,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 677.0799999999999,
        "id": 223,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 674.28,
        "temperature": 0,
        "text": " So there was a lot of time and effort went into that.",
        "tokens": [
          50820,
          407,
          456,
          390,
          257,
          688,
          295,
          565,
          293,
          4630,
          1437,
          666,
          300,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 679.0799999999999,
        "id": 224,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 677.0799999999999,
        "temperature": 0,
        "text": " And there just hasn't been a lot of time to do anything new.",
        "tokens": [
          50960,
          400,
          456,
          445,
          6132,
          380,
          668,
          257,
          688,
          295,
          565,
          281,
          360,
          1340,
          777,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 680.4399999999999,
        "id": 225,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 679.0799999999999,
        "temperature": 0,
        "text": " But I will get started on that.",
        "tokens": [
          51060,
          583,
          286,
          486,
          483,
          1409,
          322,
          300,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 680.9399999999999,
        "id": 226,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 680.4399999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51128,
          2264,
          13,
          51153
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 682.36,
        "id": 227,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 681.24,
        "temperature": 0,
        "text": " Hello to Brazil.",
        "tokens": [
          51168,
          2425,
          281,
          9435,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 683.64,
        "id": 228,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 683,
        "temperature": 0,
        "text": " Oh, yes.",
        "tokens": [
          51256,
          876,
          11,
          2086,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 686.68,
        "id": 229,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 683.64,
        "temperature": 0,
        "text": " So if you're looking for the this dot song, there are actually two this dot songs.",
        "tokens": [
          51288,
          407,
          498,
          291,
          434,
          1237,
          337,
          264,
          341,
          5893,
          2153,
          11,
          456,
          366,
          767,
          732,
          341,
          5893,
          5781,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 690.36,
        "id": 230,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 686.68,
        "temperature": 0,
        "text": " One by F Looper and one by Christian Peterson.",
        "tokens": [
          51440,
          1485,
          538,
          479,
          6130,
          7192,
          293,
          472,
          538,
          5778,
          36943,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.19575868334089006,
        "compression_ratio": 1.797945205479452,
        "end": 693.8,
        "id": 231,
        "no_speech_prob": 0.0005112240905873477,
        "seek": 66516,
        "start": 691,
        "temperature": 0,
        "text": " If you're looking for those, since it was asked.",
        "tokens": [
          51656,
          759,
          291,
          434,
          1237,
          337,
          729,
          11,
          1670,
          309,
          390,
          2351,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 700.8399999999999,
        "id": 232,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 693.8,
        "temperature": 0,
        "text": " If you go to SoundCloud, I think if I just look Daniel Shiffman playlist,",
        "tokens": [
          50364,
          759,
          291,
          352,
          281,
          14673,
          32787,
          11,
          286,
          519,
          498,
          286,
          445,
          574,
          8033,
          1160,
          3661,
          1601,
          16788,
          11,
          50716
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 704.3599999999999,
        "id": 233,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 702.8399999999999,
        "temperature": 0,
        "text": " this dot, well, this comes up.",
        "tokens": [
          50816,
          341,
          5893,
          11,
          731,
          11,
          341,
          1487,
          493,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 712.04,
        "id": 234,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 704.3599999999999,
        "temperature": 0,
        "text": " But yeah, Daniel Shiffman's Coding Rainbow, the remixes is a few different remixes.",
        "tokens": [
          50892,
          583,
          1338,
          11,
          8033,
          1160,
          3661,
          1601,
          311,
          383,
          8616,
          29477,
          11,
          264,
          890,
          36005,
          307,
          257,
          1326,
          819,
          890,
          36005,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 713,
        "id": 235,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 712.04,
        "temperature": 0,
        "text": " So this is random.",
        "tokens": [
          51276,
          407,
          341,
          307,
          4974,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 713.8,
        "id": 236,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 713,
        "temperature": 0,
        "text": " This is noise.",
        "tokens": [
          51324,
          639,
          307,
          5658,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 714.76,
        "id": 237,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 713.8,
        "temperature": 0,
        "text": " This is Perlin noise.",
        "tokens": [
          51364,
          639,
          307,
          3026,
          5045,
          5658,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 719.56,
        "id": 238,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 714.76,
        "temperature": 0,
        "text": " That is in the core random algorithm, the actual random algorithm itself.",
        "tokens": [
          51412,
          663,
          307,
          294,
          264,
          4965,
          4974,
          9284,
          11,
          264,
          3539,
          4974,
          9284,
          2564,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.299670174008324,
        "compression_ratio": 1.658878504672897,
        "end": 722.1999999999999,
        "id": 239,
        "no_speech_prob": 0.0062885829247534275,
        "seek": 69380,
        "start": 719.56,
        "temperature": 0,
        "text": " Those numbers aren't related at all.",
        "tokens": [
          51652,
          3950,
          3547,
          3212,
          380,
          4077,
          412,
          439,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 725,
        "id": 240,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 722.9200000000001,
        "temperature": 0,
        "text": " I'm picking random numbers between 0 and 10.",
        "tokens": [
          50400,
          286,
          478,
          8867,
          4974,
          3547,
          1296,
          1958,
          293,
          1266,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 729.8000000000001,
        "id": 241,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 725,
        "temperature": 0,
        "text": " 9, 2, 7, 6, 1, 9, 4, 8, 9, 2, 1, 3.",
        "tokens": [
          50504,
          1722,
          11,
          568,
          11,
          1614,
          11,
          1386,
          11,
          502,
          11,
          1722,
          11,
          1017,
          11,
          1649,
          11,
          1722,
          11,
          568,
          11,
          502,
          11,
          805,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 731.8000000000001,
        "id": 242,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 729.8000000000001,
        "temperature": 0,
        "text": " So you guys can download and enjoy these songs.",
        "tokens": [
          50744,
          407,
          291,
          1074,
          393,
          5484,
          293,
          2103,
          613,
          5781,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 735,
        "id": 243,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 731.8000000000001,
        "temperature": 0,
        "text": " If anybody wants to make more songs, I love it.",
        "tokens": [
          50844,
          759,
          4472,
          2738,
          281,
          652,
          544,
          5781,
          11,
          286,
          959,
          309,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 737,
        "id": 244,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 735,
        "temperature": 0,
        "text": " Nothing thrills me more than music.",
        "tokens": [
          51004,
          6693,
          739,
          2565,
          385,
          544,
          813,
          1318,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 741.48,
        "id": 245,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 737,
        "temperature": 0,
        "text": " I'm just like a failed musical theater wannabe person.",
        "tokens": [
          51104,
          286,
          478,
          445,
          411,
          257,
          7612,
          9165,
          10612,
          38064,
          4488,
          954,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 744.0400000000001,
        "id": 246,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 741.48,
        "temperature": 0,
        "text": " And then I just make programming videos on YouTube.",
        "tokens": [
          51328,
          400,
          550,
          286,
          445,
          652,
          9410,
          2145,
          322,
          3088,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 747.8000000000001,
        "id": 247,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 744.0400000000001,
        "temperature": 0,
        "text": " So if I could somehow, you know, I forgot to enter the Hamilton lottery today.",
        "tokens": [
          51456,
          407,
          498,
          286,
          727,
          6063,
          11,
          291,
          458,
          11,
          286,
          5298,
          281,
          3242,
          264,
          18484,
          27391,
          965,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 748.6,
        "id": 248,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 747.8000000000001,
        "temperature": 0,
        "text": " Maybe there's still time.",
        "tokens": [
          51644,
          2704,
          456,
          311,
          920,
          565,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 749.72,
        "id": 249,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 748.6,
        "temperature": 0,
        "text": " Maybe I should enter it live.",
        "tokens": [
          51684,
          2704,
          286,
          820,
          3242,
          309,
          1621,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.21632301330566406,
        "compression_ratio": 1.5714285714285714,
        "end": 751.32,
        "id": 250,
        "no_speech_prob": 0.008059809915721416,
        "seek": 72220,
        "start": 749.72,
        "temperature": 0,
        "text": " Because usually you can enter it till 4.",
        "tokens": [
          51740,
          1436,
          2673,
          291,
          393,
          3242,
          309,
          4288,
          1017,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 752.6,
        "id": 251,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 751.48,
        "temperature": 0,
        "text": " You guys don't mind, do you?",
        "tokens": [
          50372,
          509,
          1074,
          500,
          380,
          1575,
          11,
          360,
          291,
          30,
          50428
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 754.12,
        "id": 252,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 753.24,
        "temperature": 0,
        "text": " I have an app.",
        "tokens": [
          50460,
          286,
          362,
          364,
          724,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 755.32,
        "id": 253,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 754.12,
        "temperature": 0,
        "text": " It's really fast, I swear.",
        "tokens": [
          50504,
          467,
          311,
          534,
          2370,
          11,
          286,
          11902,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 758.9200000000001,
        "id": 254,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 757.08,
        "temperature": 0,
        "text": " I'll put on the This Dot song for you guys.",
        "tokens": [
          50652,
          286,
          603,
          829,
          322,
          264,
          639,
          38753,
          2153,
          337,
          291,
          1074,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 760.6800000000001,
        "id": 255,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 758.9200000000001,
        "temperature": 0,
        "text": " As always, I always forget the This Dot.",
        "tokens": [
          50744,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          639,
          38753,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 762.36,
        "id": 256,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 760.6800000000001,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          50832,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 763.48,
        "id": 257,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 762.36,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot.",
        "tokens": [
          50916,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 766.6,
        "id": 258,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 763.48,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot, This Dot.",
        "tokens": [
          50972,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 767.24,
        "id": 259,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 766.6,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot, This Dot.",
        "tokens": [
          51128,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 767.8000000000001,
        "id": 260,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 767.24,
        "temperature": 0,
        "text": " What's today?",
        "tokens": [
          51160,
          708,
          311,
          965,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 768.2800000000001,
        "id": 261,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 767.8000000000001,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51188,
          639,
          38753,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 769.6400000000001,
        "id": 262,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 768.2800000000001,
        "temperature": 0,
        "text": " I'm going to do Wednesday.",
        "tokens": [
          51212,
          286,
          478,
          516,
          281,
          360,
          10579,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 770.2800000000001,
        "id": 263,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 769.6400000000001,
        "temperature": 0,
        "text": " Yes, Wednesday.",
        "tokens": [
          51280,
          1079,
          11,
          10579,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 770.6800000000001,
        "id": 264,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 770.2800000000001,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51312,
          639,
          38753,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 772.7600000000001,
        "id": 265,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 771.6400000000001,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          51380,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 773.24,
        "id": 266,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 772.7600000000001,
        "temperature": 0,
        "text": " Enter.",
        "tokens": [
          51436,
          10399,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 774.0400000000001,
        "id": 267,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 773.24,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51460,
          639,
          38753,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 775.1600000000001,
        "id": 268,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 774.0400000000001,
        "temperature": 0,
        "text": " Closes at 4 PM.",
        "tokens": [
          51500,
          2033,
          4201,
          412,
          1017,
          12499,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 776.0400000000001,
        "id": 269,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 775.1600000000001,
        "temperature": 0,
        "text": " Live on the air.",
        "tokens": [
          51556,
          10385,
          322,
          264,
          1988,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 778.0400000000001,
        "id": 270,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 776.0400000000001,
        "temperature": 0,
        "text": " I can't check at 4 o'clock.",
        "tokens": [
          51600,
          286,
          393,
          380,
          1520,
          412,
          1017,
          277,
          6,
          9023,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.29667801058231874,
        "compression_ratio": 2.289473684210526,
        "end": 779.4000000000001,
        "id": 271,
        "no_speech_prob": 0.044013746082782745,
        "seek": 75132,
        "start": 778.0400000000001,
        "temperature": 0,
        "text": " Somebody can remind me.",
        "tokens": [
          51700,
          13463,
          393,
          4160,
          385,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 780.4399999999999,
        "id": 272,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 779.4,
        "temperature": 0,
        "text": " I have to make sure I'm a pro.",
        "tokens": [
          50364,
          286,
          362,
          281,
          652,
          988,
          286,
          478,
          257,
          447,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 782.12,
        "id": 273,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 780.4399999999999,
        "temperature": 0,
        "text": " I have to select all the images with graphs.",
        "tokens": [
          50416,
          286,
          362,
          281,
          3048,
          439,
          264,
          5267,
          365,
          24877,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 785,
        "id": 274,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 783.16,
        "temperature": 0,
        "text": " I'm selecting all the images with graphs.",
        "tokens": [
          50552,
          286,
          478,
          18182,
          439,
          264,
          5267,
          365,
          24877,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 786.84,
        "id": 275,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 785.64,
        "temperature": 0,
        "text": " I'm entering the lottery.",
        "tokens": [
          50676,
          286,
          478,
          11104,
          264,
          27391,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 788.92,
        "id": 276,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 787.48,
        "temperature": 0,
        "text": " Oh, the cameras are going off.",
        "tokens": [
          50768,
          876,
          11,
          264,
          8622,
          366,
          516,
          766,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 790.1999999999999,
        "id": 277,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 789.48,
        "temperature": 0,
        "text": " I'm going to enter it.",
        "tokens": [
          50868,
          286,
          478,
          516,
          281,
          3242,
          309,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 791.9599999999999,
        "id": 278,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 791.56,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50972,
          6962,
          322,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 798.12,
        "id": 279,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 793.8,
        "temperature": 0,
        "text": " At 4 o'clock, I can check to see if I won the Hamilton lottery.",
        "tokens": [
          51084,
          1711,
          1017,
          277,
          6,
          9023,
          11,
          286,
          393,
          1520,
          281,
          536,
          498,
          286,
          1582,
          264,
          18484,
          27391,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 799.4,
        "id": 280,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 798.12,
        "temperature": 0,
        "text": " $10 front row ticket.",
        "tokens": [
          51300,
          1848,
          3279,
          1868,
          5386,
          10550,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 799.9599999999999,
        "id": 281,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 799.4,
        "temperature": 0,
        "text": " This Dot.",
        "tokens": [
          51364,
          639,
          38753,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 801.9599999999999,
        "id": 282,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 799.9599999999999,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot.",
        "tokens": [
          51392,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 804.04,
        "id": 283,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 801.9599999999999,
        "temperature": 0,
        "text": " I'm going to do This Dot, This Dot.",
        "tokens": [
          51492,
          286,
          478,
          516,
          281,
          360,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 806.68,
        "id": 284,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 805.0799999999999,
        "temperature": 0,
        "text": " This Dot, This Dot, Sorry.",
        "tokens": [
          51648,
          639,
          38753,
          11,
          639,
          38753,
          11,
          4919,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.33754515167850774,
        "compression_ratio": 2.0721153846153846,
        "end": 809.24,
        "id": 285,
        "no_speech_prob": 0.0726078525185585,
        "seek": 77940,
        "start": 806.68,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          51728,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 811.24,
        "id": 286,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 809.32,
        "temperature": 0,
        "text": " Select all the images with trees.",
        "tokens": [
          50368,
          13638,
          439,
          264,
          5267,
          365,
          5852,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 811.96,
        "id": 287,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 811.24,
        "temperature": 0,
        "text": " Oh my god.",
        "tokens": [
          50464,
          876,
          452,
          3044,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 813.5600000000001,
        "id": 288,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 811.96,
        "temperature": 0,
        "text": " Watermelon is not a tree, is it?",
        "tokens": [
          50500,
          8772,
          22710,
          307,
          406,
          257,
          4230,
          11,
          307,
          309,
          30,
          50580
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 814.92,
        "id": 289,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 813.5600000000001,
        "temperature": 0,
        "text": " It's a little stressful.",
        "tokens": [
          50580,
          467,
          311,
          257,
          707,
          19108,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 815.5600000000001,
        "id": 290,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 814.92,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          50648,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 816.6,
        "id": 291,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 815.5600000000001,
        "temperature": 0,
        "text": " I always feel so stressed out.",
        "tokens": [
          50680,
          286,
          1009,
          841,
          370,
          14471,
          484,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 819.48,
        "id": 292,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 817.32,
        "temperature": 0,
        "text": " I'm going to get in trouble if I don't answer the right one.",
        "tokens": [
          50768,
          286,
          478,
          516,
          281,
          483,
          294,
          5253,
          498,
          286,
          500,
          380,
          1867,
          264,
          558,
          472,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 820.52,
        "id": 293,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 819.48,
        "temperature": 0,
        "text": " There's trees on this one.",
        "tokens": [
          50876,
          821,
          311,
          5852,
          322,
          341,
          472,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 820.76,
        "id": 294,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 820.52,
        "temperature": 0,
        "text": " OK, fine.",
        "tokens": [
          50928,
          2264,
          11,
          2489,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 822.44,
        "id": 295,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 820.76,
        "temperature": 0,
        "text": " This Dot, This Dot, This Dot.",
        "tokens": [
          50940,
          639,
          38753,
          11,
          639,
          38753,
          11,
          639,
          38753,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 823.32,
        "id": 296,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 822.44,
        "temperature": 0,
        "text": " The This Dot song.",
        "tokens": [
          51024,
          440,
          639,
          38753,
          2153,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 824.44,
        "id": 297,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 823.32,
        "temperature": 0,
        "text": " Never forget the This Dot.",
        "tokens": [
          51068,
          7344,
          2870,
          264,
          639,
          38753,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 826.2,
        "id": 298,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 825.48,
        "temperature": 0,
        "text": " Somebody composed that song for me.",
        "tokens": [
          51176,
          13463,
          18204,
          300,
          2153,
          337,
          385,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 828.28,
        "id": 299,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 826.2,
        "temperature": 0,
        "text": " OK, I've now entered the Hamilton lottery.",
        "tokens": [
          51212,
          2264,
          11,
          286,
          600,
          586,
          9065,
          264,
          18484,
          27391,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 830.2,
        "id": 300,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 828.84,
        "temperature": 0,
        "text": " And this camera went off.",
        "tokens": [
          51344,
          400,
          341,
          2799,
          1437,
          766,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 831.4,
        "id": 301,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 830.2,
        "temperature": 0,
        "text": " Let me just fix that.",
        "tokens": [
          51412,
          961,
          385,
          445,
          3191,
          300,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2510536857273268,
        "compression_ratio": 1.7644927536231885,
        "end": 834.2,
        "id": 302,
        "no_speech_prob": 0.00004133514084969647,
        "seek": 80924,
        "start": 832.92,
        "temperature": 0,
        "text": " Let me cycle this one.",
        "tokens": [
          51548,
          961,
          385,
          6586,
          341,
          472,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 837,
        "id": 303,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 834.36,
        "temperature": 0,
        "text": " I need to erase the whiteboard.",
        "tokens": [
          50372,
          286,
          643,
          281,
          23525,
          264,
          2418,
          3787,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 839.32,
        "id": 304,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 837.5600000000001,
        "temperature": 0,
        "text": " I don't know where the eraser is.",
        "tokens": [
          50532,
          286,
          500,
          380,
          458,
          689,
          264,
          46018,
          307,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 839.82,
        "id": 305,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 839.32,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50620,
          8239,
          13,
          50645
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 843.08,
        "id": 306,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 841.08,
        "temperature": 0,
        "text": " Where is the eraser?",
        "tokens": [
          50708,
          2305,
          307,
          264,
          46018,
          30,
          50808
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 850.2800000000001,
        "id": 307,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 848.6,
        "temperature": 0,
        "text": " Where is that eraser?",
        "tokens": [
          51084,
          2305,
          307,
          300,
          46018,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 851.6400000000001,
        "id": 308,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 851,
        "temperature": 0,
        "text": " Erasure.",
        "tokens": [
          51204,
          3300,
          2508,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 852.2,
        "id": 309,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 851.6400000000001,
        "temperature": 0,
        "text": " Eraser.",
        "tokens": [
          51236,
          3300,
          17756,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 852.6800000000001,
        "id": 310,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 852.2,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51264,
          876,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 854.6800000000001,
        "id": 311,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 853.6400000000001,
        "temperature": 0,
        "text": " OK, hold on, everyone.",
        "tokens": [
          51336,
          2264,
          11,
          1797,
          322,
          11,
          1518,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 857.48,
        "id": 312,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 856.9200000000001,
        "temperature": 0,
        "text": " Oh, here it is.",
        "tokens": [
          51500,
          876,
          11,
          510,
          309,
          307,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 857.72,
        "id": 313,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 857.48,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51528,
          286,
          1352,
          309,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 858.0400000000001,
        "id": 314,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 857.72,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51540,
          286,
          1352,
          309,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 858.6800000000001,
        "id": 315,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 858.0400000000001,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51556,
          286,
          1352,
          309,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 860.12,
        "id": 316,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 858.6800000000001,
        "temperature": 0,
        "text": " Everything's going to be OK, everybody.",
        "tokens": [
          51588,
          5471,
          311,
          516,
          281,
          312,
          2264,
          11,
          2201,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 860.6800000000001,
        "id": 317,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 860.12,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51660,
          286,
          1352,
          309,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 861.24,
        "id": 318,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 860.6800000000001,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51688,
          286,
          1352,
          309,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 861.72,
        "id": 319,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 861.24,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51716,
          286,
          1352,
          309,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 862.2800000000001,
        "id": 320,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 861.72,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51740,
          286,
          1352,
          309,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 862.84,
        "id": 321,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 862.2800000000001,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51768,
          286,
          1352,
          309,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.5364498500406307,
        "compression_ratio": 2.0844155844155843,
        "end": 863.4000000000001,
        "id": 322,
        "no_speech_prob": 0.0024725785478949547,
        "seek": 83420,
        "start": 862.84,
        "temperature": 0,
        "text": " I found it.",
        "tokens": [
          51796,
          286,
          1352,
          309,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 864.04,
        "id": 323,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 863.4,
        "temperature": 0,
        "text": " Everything's going to be OK, everybody.",
        "tokens": [
          50364,
          5471,
          311,
          516,
          281,
          312,
          2264,
          11,
          2201,
          13,
          50396
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 866.68,
        "id": 324,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 865,
        "temperature": 0,
        "text": " I'm going to, this is what I had.",
        "tokens": [
          50444,
          286,
          478,
          516,
          281,
          11,
          341,
          307,
          437,
          286,
          632,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 867.24,
        "id": 325,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 866.68,
        "temperature": 0,
        "text": " Oh, look.",
        "tokens": [
          50528,
          876,
          11,
          574,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 870.06,
        "id": 326,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 869.56,
        "temperature": 0,
        "text": " Uh.",
        "tokens": [
          50672,
          4019,
          13,
          50697
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 872.04,
        "id": 327,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 871,
        "temperature": 0,
        "text": " Let me erase all this.",
        "tokens": [
          50744,
          961,
          385,
          23525,
          439,
          341,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 878.4399999999999,
        "id": 328,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 876.36,
        "temperature": 0,
        "text": " This is such a nice eraser.",
        "tokens": [
          51012,
          639,
          307,
          1270,
          257,
          1481,
          46018,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 879.72,
        "id": 329,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 878.4399999999999,
        "temperature": 0,
        "text": " Makes such a nice sound, too.",
        "tokens": [
          51116,
          25245,
          1270,
          257,
          1481,
          1626,
          11,
          886,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 882.6,
        "id": 330,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 881.56,
        "temperature": 0,
        "text": " Go to sleep.",
        "tokens": [
          51272,
          1037,
          281,
          2817,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 884.84,
        "id": 331,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 883.8,
        "temperature": 0,
        "text": " Go to sleep.",
        "tokens": [
          51384,
          1037,
          281,
          2817,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 889.72,
        "id": 332,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 886.04,
        "temperature": 0,
        "text": " Go to sleep, little eyes.",
        "tokens": [
          51496,
          1037,
          281,
          2817,
          11,
          707,
          2575,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 891.8,
        "id": 333,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 890.76,
        "temperature": 0,
        "text": " Go to sleep.",
        "tokens": [
          51732,
          1037,
          281,
          2817,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.34784033863814834,
        "compression_ratio": 1.6209150326797386,
        "end": 892.68,
        "id": 334,
        "no_speech_prob": 0.016652381047606468,
        "seek": 86340,
        "start": 891.8,
        "temperature": 0,
        "text": " OK, I'm wrong.",
        "tokens": [
          51784,
          2264,
          11,
          286,
          478,
          2085,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 896.28,
        "id": 335,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 893.88,
        "temperature": 0.6000000000000001,
        "text": " Ah, it's been a weird few weeks.",
        "tokens": [
          50388,
          2438,
          11,
          309,
          311,
          668,
          257,
          3657,
          1326,
          3259,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 900.52,
        "id": 336,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 896.28,
        "temperature": 0.6000000000000001,
        "text": " OK, um, OK.",
        "tokens": [
          50508,
          2264,
          11,
          1105,
          11,
          220,
          9443,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 904.68,
        "id": 337,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 901.4,
        "temperature": 0.6000000000000001,
        "text": " All right, so the first thing I want to do, I'm actually going to start, weirdly, with",
        "tokens": [
          50764,
          1057,
          558,
          11,
          370,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          11,
          286,
          478,
          767,
          516,
          281,
          722,
          11,
          48931,
          11,
          365,
          50928
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 906.1999999999999,
        "id": 338,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 904.68,
        "temperature": 0.6000000000000001,
        "text": " a coding challenge.",
        "tokens": [
          50928,
          257,
          17720,
          3430,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 913.48,
        "id": 339,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 907.16,
        "temperature": 0.6000000000000001,
        "text": " And that coding challenge, you should be confused, is to ch ch ch ch ch ch ch ch ch ch ch ch ch",
        "tokens": [
          51052,
          400,
          300,
          17720,
          3430,
          11,
          291,
          820,
          312,
          9019,
          11,
          307,
          220,
          1353,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          417,
          51368
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 914.04,
        "id": 340,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 913.48,
        "temperature": 0.6000000000000001,
        "text": " aphon111.",
        "tokens": [
          51368,
          257,
          950,
          266,
          5348,
          16,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.42619932743540984,
        "compression_ratio": 1.6521739130434783,
        "end": 921.16,
        "id": 341,
        "no_speech_prob": 0.00030061163124628365,
        "seek": 89340,
        "start": 917.3199999999999,
        "temperature": 0.6000000000000001,
        "text": " So what I'm going to do, if, you know, a lot of you might have watched these before,",
        "tokens": [
          51560,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          498,
          11,
          291,
          458,
          11,
          257,
          688,
          295,
          291,
          1062,
          362,
          6337,
          613,
          949,
          11,
          51752
        ]
      },
      {
        "avg_logprob": -0.18525168770237974,
        "compression_ratio": 1.615686274509804,
        "end": 925.9599999999999,
        "id": 342,
        "no_speech_prob": 0.008187144994735718,
        "seek": 92116,
        "start": 921.16,
        "temperature": 0,
        "text": " but the live streams, typically, I do a lot of, like, talking and researching and clicking",
        "tokens": [
          50364,
          457,
          264,
          1621,
          15842,
          11,
          5850,
          11,
          286,
          360,
          257,
          688,
          295,
          11,
          411,
          11,
          1417,
          293,
          24176,
          293,
          9697,
          50604
        ]
      },
      {
        "avg_logprob": -0.18525168770237974,
        "compression_ratio": 1.615686274509804,
        "end": 927,
        "id": 343,
        "no_speech_prob": 0.008187144994735718,
        "seek": 92116,
        "start": 925.9599999999999,
        "temperature": 0,
        "text": " and getting set up.",
        "tokens": [
          50604,
          293,
          1242,
          992,
          493,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.18525168770237974,
        "compression_ratio": 1.615686274509804,
        "end": 931.24,
        "id": 344,
        "no_speech_prob": 0.008187144994735718,
        "seek": 92116,
        "start": 927,
        "temperature": 0,
        "text": " And at a certain point, I start an actual, like, tutorial or coding challenge, where",
        "tokens": [
          50656,
          400,
          412,
          257,
          1629,
          935,
          11,
          286,
          722,
          364,
          3539,
          11,
          411,
          11,
          7073,
          420,
          17720,
          3430,
          11,
          689,
          50868
        ]
      },
      {
        "avg_logprob": -0.18525168770237974,
        "compression_ratio": 1.615686274509804,
        "end": 935.24,
        "id": 345,
        "no_speech_prob": 0.008187144994735718,
        "seek": 92116,
        "start": 931.24,
        "temperature": 0,
        "text": " I pretend as if I'm recording a video, even though that's what I'm doing all this time.",
        "tokens": [
          50868,
          286,
          11865,
          382,
          498,
          286,
          478,
          6613,
          257,
          960,
          11,
          754,
          1673,
          300,
          311,
          437,
          286,
          478,
          884,
          439,
          341,
          565,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.18525168770237974,
        "compression_ratio": 1.615686274509804,
        "end": 937.7199999999999,
        "id": 346,
        "no_speech_prob": 0.008187144994735718,
        "seek": 92116,
        "start": 935.24,
        "temperature": 0,
        "text": " So let me first kind of get set up here.",
        "tokens": [
          51068,
          407,
          718,
          385,
          700,
          733,
          295,
          483,
          992,
          493,
          510,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.18525168770237974,
        "compression_ratio": 1.615686274509804,
        "end": 942.8399999999999,
        "id": 347,
        "no_speech_prob": 0.008187144994735718,
        "seek": 92116,
        "start": 937.7199999999999,
        "temperature": 0,
        "text": " And let's get some links that are relevant and talk to you a little bit about aphon111.",
        "tokens": [
          51192,
          400,
          718,
          311,
          483,
          512,
          6123,
          300,
          366,
          7340,
          293,
          751,
          281,
          291,
          257,
          707,
          857,
          466,
          257,
          950,
          266,
          5348,
          16,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.21475066695102427,
        "compression_ratio": 1.4705882352941178,
        "end": 953.88,
        "id": 348,
        "no_speech_prob": 0.01854570023715496,
        "seek": 94284,
        "start": 942.84,
        "temperature": 0,
        "text": " So aphon is a list of English words rated for valence, meaning positivity or negativity,",
        "tokens": [
          50364,
          407,
          257,
          950,
          266,
          307,
          257,
          1329,
          295,
          3669,
          2283,
          22103,
          337,
          1323,
          655,
          11,
          3620,
          35198,
          420,
          39297,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.21475066695102427,
        "compression_ratio": 1.4705882352941178,
        "end": 957.96,
        "id": 349,
        "no_speech_prob": 0.01854570023715496,
        "seek": 94284,
        "start": 953.88,
        "temperature": 0,
        "text": " with an integer between minus 5 and plus 5.",
        "tokens": [
          50916,
          365,
          364,
          24922,
          1296,
          3175,
          1025,
          293,
          1804,
          1025,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.21475066695102427,
        "compression_ratio": 1.4705882352941178,
        "end": 965.08,
        "id": 350,
        "no_speech_prob": 0.01854570023715496,
        "seek": 94284,
        "start": 958.52,
        "temperature": 0,
        "text": " And so these words were manually labeled by Finn Arup Nielsen, which is why it's called",
        "tokens": [
          51148,
          400,
          370,
          613,
          2283,
          645,
          16945,
          21335,
          538,
          21066,
          316,
          11976,
          426,
          1187,
          6748,
          11,
          597,
          307,
          983,
          309,
          311,
          1219,
          51476
        ]
      },
      {
        "avg_logprob": -0.21475066695102427,
        "compression_ratio": 1.4705882352941178,
        "end": 965.72,
        "id": 351,
        "no_speech_prob": 0.01854570023715496,
        "seek": 94284,
        "start": 965.08,
        "temperature": 0,
        "text": " the aphon.",
        "tokens": [
          51476,
          264,
          257,
          950,
          266,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.21475066695102427,
        "compression_ratio": 1.4705882352941178,
        "end": 972.44,
        "id": 352,
        "no_speech_prob": 0.01854570023715496,
        "seek": 94284,
        "start": 966.9200000000001,
        "temperature": 0,
        "text": " And aphon111 is the newest version that has 2,477 words and phrases.",
        "tokens": [
          51568,
          400,
          257,
          29285,
          5348,
          16,
          307,
          264,
          17569,
          3037,
          300,
          575,
          568,
          11,
          14060,
          22,
          2283,
          293,
          20312,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.21207825342814127,
        "compression_ratio": 1.6584158415841583,
        "end": 978.6800000000001,
        "id": 353,
        "no_speech_prob": 0.0002066263259621337,
        "seek": 97284,
        "start": 973.8000000000001,
        "temperature": 0,
        "text": " So if you are a scientist, I am not a scientist, I hope you would reference the above paper.",
        "tokens": [
          50412,
          407,
          498,
          291,
          366,
          257,
          12662,
          11,
          286,
          669,
          406,
          257,
          12662,
          11,
          286,
          1454,
          291,
          576,
          6408,
          264,
          3673,
          3035,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.21207825342814127,
        "compression_ratio": 1.6584158415841583,
        "end": 982.6800000000001,
        "id": 354,
        "no_speech_prob": 0.0002066263259621337,
        "seek": 97284,
        "start": 978.6800000000001,
        "temperature": 0,
        "text": " I will reference the above paper and this link in this video's description.",
        "tokens": [
          50656,
          286,
          486,
          6408,
          264,
          3673,
          3035,
          293,
          341,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.21207825342814127,
        "compression_ratio": 1.6584158415841583,
        "end": 988.44,
        "id": 355,
        "no_speech_prob": 0.0002066263259621337,
        "seek": 97284,
        "start": 984.0400000000001,
        "temperature": 0,
        "text": " This database is copyright protected and distributed under the Open Database License.",
        "tokens": [
          50924,
          639,
          8149,
          307,
          17996,
          10594,
          293,
          12631,
          833,
          264,
          7238,
          40461,
          651,
          40627,
          1288,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.21207825342814127,
        "compression_ratio": 1.6584158415841583,
        "end": 991.5600000000001,
        "id": 356,
        "no_speech_prob": 0.0002066263259621337,
        "seek": 97284,
        "start": 988.44,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to download it so we can take a look at it.",
        "tokens": [
          51144,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          5484,
          309,
          370,
          321,
          393,
          747,
          257,
          574,
          412,
          309,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1004.6800000000001,
        "id": 357,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1002.9200000000001,
        "temperature": 0,
        "text": " OK, aphon.",
        "tokens": [
          50368,
          2264,
          11,
          257,
          950,
          266,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1008.76,
        "id": 358,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1004.6800000000001,
        "temperature": 0,
        "text": " Oh, look, I downloaded it last week or two weeks ago.",
        "tokens": [
          50456,
          876,
          11,
          574,
          11,
          286,
          21748,
          309,
          1036,
          1243,
          420,
          732,
          3259,
          2057,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1009.88,
        "id": 359,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1008.76,
        "temperature": 0,
        "text": " So let's look at the readme.",
        "tokens": [
          50660,
          407,
          718,
          311,
          574,
          412,
          264,
          1401,
          1398,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1013.64,
        "id": 360,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1010.6,
        "temperature": 0,
        "text": " This is what it says already on the site.",
        "tokens": [
          50752,
          639,
          307,
          437,
          309,
          1619,
          1217,
          322,
          264,
          3621,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1015.5600000000001,
        "id": 361,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1014.2,
        "temperature": 0,
        "text": " OK, now let's look at this.",
        "tokens": [
          50932,
          2264,
          11,
          586,
          718,
          311,
          574,
          412,
          341,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1016.6800000000001,
        "id": 362,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1015.5600000000001,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          51000,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1022.76,
        "id": 363,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1018.44,
        "temperature": 0,
        "text": " I really, really, really, really, really, really, really, really, really, really, really",
        "tokens": [
          51144,
          286,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          51360
        ]
      },
      {
        "avg_logprob": -0.19985981895810082,
        "compression_ratio": 1.893491124260355,
        "end": 1027.32,
        "id": 364,
        "no_speech_prob": 0.10519934445619583,
        "seek": 100284,
        "start": 1022.76,
        "temperature": 0,
        "text": " would like to have this list in JSON format.",
        "tokens": [
          51360,
          576,
          411,
          281,
          362,
          341,
          1329,
          294,
          31828,
          7877,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2665119965871175,
        "compression_ratio": 1.46,
        "end": 1036.36,
        "id": 365,
        "no_speech_prob": 0.1293942928314209,
        "seek": 102732,
        "start": 1028.2,
        "temperature": 0,
        "text": " So the question I have for myself is, do I make the coding challenge itself, part of it,",
        "tokens": [
          50408,
          407,
          264,
          1168,
          286,
          362,
          337,
          2059,
          307,
          11,
          360,
          286,
          652,
          264,
          17720,
          3430,
          2564,
          11,
          644,
          295,
          309,
          11,
          50816
        ]
      },
      {
        "avg_logprob": -0.2665119965871175,
        "compression_ratio": 1.46,
        "end": 1039.56,
        "id": 366,
        "no_speech_prob": 0.1293942928314209,
        "seek": 102732,
        "start": 1037.32,
        "temperature": 0,
        "text": " converting this to JSON?",
        "tokens": [
          50864,
          29942,
          341,
          281,
          31828,
          30,
          50976
        ]
      },
      {
        "avg_logprob": -0.2665119965871175,
        "compression_ratio": 1.46,
        "end": 1045.24,
        "id": 367,
        "no_speech_prob": 0.1293942928314209,
        "seek": 102732,
        "start": 1043,
        "temperature": 0,
        "text": " And also, what's up with this?",
        "tokens": [
          51148,
          400,
          611,
          11,
          437,
          311,
          493,
          365,
          341,
          30,
          51260
        ]
      },
      {
        "avg_logprob": -0.2665119965871175,
        "compression_ratio": 1.46,
        "end": 1047.8,
        "id": 368,
        "no_speech_prob": 0.1293942928314209,
        "seek": 102732,
        "start": 1046.52,
        "temperature": 0,
        "text": " What's up with this list?",
        "tokens": [
          51324,
          708,
          311,
          493,
          365,
          341,
          1329,
          30,
          51388
        ]
      },
      {
        "avg_logprob": -0.2665119965871175,
        "compression_ratio": 1.46,
        "end": 1052.9199999999998,
        "id": 369,
        "no_speech_prob": 0.1293942928314209,
        "seek": 102732,
        "start": 1047.8,
        "temperature": 0,
        "text": " Like, wow, wow, wow, wow, with two W's, I guess.",
        "tokens": [
          51388,
          1743,
          11,
          6076,
          11,
          6076,
          11,
          6076,
          11,
          6076,
          11,
          365,
          732,
          343,
          311,
          11,
          286,
          2041,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1057.8000000000002,
        "id": 370,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1053.72,
        "temperature": 0,
        "text": " Yees, there's a lot of words.",
        "tokens": [
          50404,
          398,
          4031,
          11,
          456,
          311,
          257,
          688,
          295,
          2283,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1059.96,
        "id": 371,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1057.8000000000002,
        "temperature": 0,
        "text": " But why is there no space there between the number?",
        "tokens": [
          50608,
          583,
          983,
          307,
          456,
          572,
          1901,
          456,
          1296,
          264,
          1230,
          30,
          50716
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1063.72,
        "id": 372,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1061.5600000000002,
        "temperature": 0,
        "text": " So I feel like, oh, there's probably a tab.",
        "tokens": [
          50796,
          407,
          286,
          841,
          411,
          11,
          1954,
          11,
          456,
          311,
          1391,
          257,
          4421,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1065.96,
        "id": 373,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1063.72,
        "temperature": 0,
        "text": " This is probably tab delimited, right?",
        "tokens": [
          50904,
          639,
          307,
          1391,
          4421,
          1103,
          332,
          1226,
          11,
          558,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1070.1200000000001,
        "id": 374,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1067.64,
        "temperature": 0,
        "text": " Yeah, so there's actually a space there.",
        "tokens": [
          51100,
          865,
          11,
          370,
          456,
          311,
          767,
          257,
          1901,
          456,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1073.24,
        "id": 375,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1070.8400000000001,
        "temperature": 0,
        "text": " It's just, yeah, it's just there's a tab there.",
        "tokens": [
          51260,
          467,
          311,
          445,
          11,
          1338,
          11,
          309,
          311,
          445,
          456,
          311,
          257,
          4421,
          456,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1079.48,
        "id": 376,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1073.24,
        "temperature": 0,
        "text": " OK, so what I want to do is I'm going to do, I can't decide if I should do this as two",
        "tokens": [
          51380,
          2264,
          11,
          370,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          393,
          380,
          4536,
          498,
          286,
          820,
          360,
          341,
          382,
          732,
          51692
        ]
      },
      {
        "avg_logprob": -0.22442071050660223,
        "compression_ratio": 1.6355555555555557,
        "end": 1081,
        "id": 377,
        "no_speech_prob": 0.0003250348672736436,
        "seek": 105292,
        "start": 1079.48,
        "temperature": 0,
        "text": " separate coding challenges.",
        "tokens": [
          51692,
          4994,
          17720,
          4759,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1088.44,
        "id": 378,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1081.48,
        "temperature": 0,
        "text": " Or I'm seeing in the chat that a note that the video quality is not good.",
        "tokens": [
          50388,
          1610,
          286,
          478,
          2577,
          294,
          264,
          5081,
          300,
          257,
          3637,
          300,
          264,
          960,
          3125,
          307,
          406,
          665,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1091.88,
        "id": 379,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1088.44,
        "temperature": 0,
        "text": " So I don't know if sometimes with the stream, depending on your connection, you can get",
        "tokens": [
          50736,
          407,
          286,
          500,
          380,
          458,
          498,
          2171,
          365,
          264,
          4309,
          11,
          5413,
          322,
          428,
          4984,
          11,
          291,
          393,
          483,
          50908
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1092.68,
        "id": 380,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1091.88,
        "temperature": 0,
        "text": " low quality.",
        "tokens": [
          50908,
          2295,
          3125,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1093.24,
        "id": 381,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1092.68,
        "temperature": 0,
        "text": " It is only 7.",
        "tokens": [
          50948,
          467,
          307,
          787,
          1614,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1097.64,
        "id": 382,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1093.24,
        "temperature": 0,
        "text": " I am only broadcasting at 720p because I don't have a good enough connection here, I think,",
        "tokens": [
          50976,
          286,
          669,
          787,
          30024,
          412,
          40881,
          79,
          570,
          286,
          500,
          380,
          362,
          257,
          665,
          1547,
          4984,
          510,
          11,
          286,
          519,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1100.12,
        "id": 383,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1097.64,
        "temperature": 0,
        "text": " to support 108 broadcasting at 1080p.",
        "tokens": [
          51196,
          281,
          1406,
          1266,
          23,
          30024,
          412,
          24547,
          79,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.32661815790029675,
        "compression_ratio": 1.6218487394957983,
        "end": 1108.2,
        "id": 384,
        "no_speech_prob": 0.0004108457360416651,
        "seek": 108100,
        "start": 1102.92,
        "temperature": 0,
        "text": " So let me know if anybody else is experiencing issues with quality.",
        "tokens": [
          51460,
          407,
          718,
          385,
          458,
          498,
          4472,
          1646,
          307,
          11139,
          2663,
          365,
          3125,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1112.3600000000001,
        "id": 385,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1108.52,
        "temperature": 0,
        "text": " So what I want to do, let's do, hmm.",
        "tokens": [
          50380,
          407,
          437,
          286,
          528,
          281,
          360,
          11,
          718,
          311,
          360,
          11,
          16478,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1116.52,
        "id": 386,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1114.3600000000001,
        "temperature": 0,
        "text": " I mean, this is not a complicated problem.",
        "tokens": [
          50672,
          286,
          914,
          11,
          341,
          307,
          406,
          257,
          6179,
          1154,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1120.52,
        "id": 387,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1116.52,
        "temperature": 0,
        "text": " I'm just trying to decide if I want to do it all together.",
        "tokens": [
          50780,
          286,
          478,
          445,
          1382,
          281,
          4536,
          498,
          286,
          528,
          281,
          360,
          309,
          439,
          1214,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1122.52,
        "id": 388,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1120.52,
        "temperature": 0,
        "text": " Let's do it all together as one video.",
        "tokens": [
          50980,
          961,
          311,
          360,
          309,
          439,
          1214,
          382,
          472,
          960,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1123.0800000000002,
        "id": 389,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1122.52,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51080,
          1545,
          406,
          30,
          51108
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1124.52,
        "id": 390,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1123.72,
        "temperature": 0,
        "text": " You know, who cares?",
        "tokens": [
          51140,
          509,
          458,
          11,
          567,
          12310,
          30,
          51180
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1130.6000000000001,
        "id": 391,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1125.8,
        "temperature": 0,
        "text": " So this video, what I'm going to do is I'm going to talk about what AFIN111 is.",
        "tokens": [
          51244,
          407,
          341,
          960,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          751,
          466,
          437,
          20389,
          1464,
          5348,
          16,
          307,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1132.52,
        "id": 392,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1130.6000000000001,
        "temperature": 0,
        "text": " I'm going to grab this file.",
        "tokens": [
          51484,
          286,
          478,
          516,
          281,
          4444,
          341,
          3991,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1134.8400000000001,
        "id": 393,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1132.52,
        "temperature": 0,
        "text": " I'm going to open it in p5.",
        "tokens": [
          51580,
          286,
          478,
          516,
          281,
          1269,
          309,
          294,
          280,
          20,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.33788954756642114,
        "compression_ratio": 1.7465437788018434,
        "end": 1136.8400000000001,
        "id": 394,
        "no_speech_prob": 0.0010649535106495023,
        "seek": 110820,
        "start": 1134.8400000000001,
        "temperature": 0,
        "text": " I'm going to convert it to a file.",
        "tokens": [
          51696,
          286,
          478,
          516,
          281,
          7620,
          309,
          281,
          257,
          3991,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1143.9599999999998,
        "id": 395,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1137.3999999999999,
        "temperature": 0,
        "text": " I'm going to save it as JSON.",
        "tokens": [
          50392,
          286,
          478,
          516,
          281,
          3155,
          309,
          382,
          31828,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1149.6399999999999,
        "id": 396,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1143.9599999999998,
        "temperature": 0,
        "text": " And then I'm going to make a new sketch that loads it as JSON and does the sentiment analysis",
        "tokens": [
          50720,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          12325,
          300,
          12668,
          309,
          382,
          31828,
          293,
          775,
          264,
          16149,
          5215,
          51004
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1150.12,
        "id": 397,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1149.6399999999999,
        "temperature": 0,
        "text": " part.",
        "tokens": [
          51004,
          644,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1150.36,
        "id": 398,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1150.12,
        "temperature": 0,
        "text": " OK?",
        "tokens": [
          51028,
          2264,
          30,
          51040
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1152.36,
        "id": 399,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1151.08,
        "temperature": 0,
        "text": " So great.",
        "tokens": [
          51076,
          407,
          869,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1156.12,
        "id": 400,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1154.9199999999998,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51268,
          1692,
          321,
          352,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1158.04,
        "id": 401,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1156.9199999999998,
        "temperature": 0,
        "text": " So I think I'm ready for this.",
        "tokens": [
          51368,
          407,
          286,
          519,
          286,
          478,
          1919,
          337,
          341,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1160.84,
        "id": 402,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1159.1599999999999,
        "temperature": 0,
        "text": " Let me check here.",
        "tokens": [
          51480,
          961,
          385,
          1520,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1162.04,
        "id": 403,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1160.84,
        "temperature": 0,
        "text": " Let me get a little more set up.",
        "tokens": [
          51564,
          961,
          385,
          483,
          257,
          707,
          544,
          992,
          493,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1163.48,
        "id": 404,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1162.04,
        "temperature": 0,
        "text": " I'll play you another song.",
        "tokens": [
          51624,
          286,
          603,
          862,
          291,
          1071,
          2153,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2529275417327881,
        "compression_ratio": 1.5024630541871922,
        "end": 1164.84,
        "id": 405,
        "no_speech_prob": 0.0013670030748471618,
        "seek": 113684,
        "start": 1163.48,
        "temperature": 0,
        "text": " You can have the Perlin noise one now.",
        "tokens": [
          51696,
          509,
          393,
          362,
          264,
          3026,
          5045,
          5658,
          472,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1167.3999999999999,
        "id": 406,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1164.84,
        "temperature": 0,
        "text": " Oh, that's just a clip?",
        "tokens": [
          50364,
          876,
          11,
          300,
          311,
          445,
          257,
          7353,
          30,
          50492
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1171.32,
        "id": 407,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1167.3999999999999,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50492,
          2102,
          3255,
          30,
          50688
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1176.1999999999998,
        "id": 408,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1175.32,
        "temperature": 0,
        "text": " Yeah, that was just a clip.",
        "tokens": [
          50888,
          865,
          11,
          300,
          390,
          445,
          257,
          7353,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1178.6799999999998,
        "id": 409,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1177.1599999999999,
        "temperature": 0,
        "text": " As always, I always forget the this dot.",
        "tokens": [
          50980,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          264,
          341,
          5893,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1179.48,
        "id": 410,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1178.6799999999998,
        "temperature": 0,
        "text": " Oh, that's the this dot.",
        "tokens": [
          51056,
          876,
          11,
          300,
          311,
          264,
          341,
          5893,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1181.48,
        "id": 411,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1179.48,
        "temperature": 0,
        "text": " I pressed the wrong button.",
        "tokens": [
          51096,
          286,
          17355,
          264,
          2085,
          2960,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1186.4399999999998,
        "id": 412,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1181.48,
        "temperature": 0,
        "text": " Empty example should be good.",
        "tokens": [
          51196,
          3968,
          39420,
          1365,
          820,
          312,
          665,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.5368771553039551,
        "compression_ratio": 1.4437086092715232,
        "end": 1192.04,
        "id": 413,
        "no_speech_prob": 0.11591837555170059,
        "seek": 116484,
        "start": 1189.48,
        "temperature": 0,
        "text": " 0.584 is a good version of 0.5.",
        "tokens": [
          51596,
          1958,
          13,
          20,
          25494,
          307,
          257,
          665,
          3037,
          295,
          1958,
          13,
          20,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.46398079186155083,
        "compression_ratio": 1.2755905511811023,
        "end": 1203.48,
        "id": 414,
        "no_speech_prob": 0.16663691401481628,
        "seek": 119484,
        "start": 1194.84,
        "temperature": 0,
        "text": " So let's make this A to Z.",
        "tokens": [
          50364,
          407,
          718,
          311,
          652,
          341,
          316,
          281,
          1176,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.46398079186155083,
        "compression_ratio": 1.2755905511811023,
        "end": 1205.24,
        "id": 415,
        "no_speech_prob": 0.16663691401481628,
        "seek": 119484,
        "start": 1204.52,
        "temperature": 0,
        "text": " Session.",
        "tokens": [
          50848,
          318,
          4311,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.46398079186155083,
        "compression_ratio": 1.2755905511811023,
        "end": 1207.72,
        "id": 416,
        "no_speech_prob": 0.16663691401481628,
        "seek": 119484,
        "start": 1205.24,
        "temperature": 0,
        "text": " This is still session 8, if you can believe that.",
        "tokens": [
          50884,
          639,
          307,
          920,
          5481,
          1649,
          11,
          498,
          291,
          393,
          1697,
          300,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.46398079186155083,
        "compression_ratio": 1.2755905511811023,
        "end": 1208.6799999999998,
        "id": 417,
        "no_speech_prob": 0.16663691401481628,
        "seek": 119484,
        "start": 1207.72,
        "temperature": 0,
        "text": " Oy vey, good old.",
        "tokens": [
          51008,
          40023,
          1241,
          88,
          11,
          665,
          1331,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.46398079186155083,
        "compression_ratio": 1.2755905511811023,
        "end": 1214.4399999999998,
        "id": 418,
        "no_speech_prob": 0.16663691401481628,
        "seek": 119484,
        "start": 1210.28,
        "temperature": 0,
        "text": " I mean, in a way, this example is from an earlier session.",
        "tokens": [
          51136,
          286,
          914,
          11,
          294,
          257,
          636,
          11,
          341,
          1365,
          307,
          490,
          364,
          3071,
          5481,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1228.84,
        "id": 419,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1224.84,
        "temperature": 0,
        "text": " This dot, this dot, this dot, never forget this dot.",
        "tokens": [
          50364,
          639,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          1128,
          2870,
          341,
          5893,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1231.3999999999999,
        "id": 420,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1228.84,
        "temperature": 0,
        "text": " I'm using Sublimer Atom these days.",
        "tokens": [
          50564,
          286,
          478,
          1228,
          8511,
          4197,
          260,
          1711,
          298,
          613,
          1708,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1232.4399999999998,
        "id": 421,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1231.3999999999999,
        "temperature": 0,
        "text": " I think I've been using Atom.",
        "tokens": [
          50692,
          286,
          519,
          286,
          600,
          668,
          1228,
          1711,
          298,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1237.24,
        "id": 422,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1233.24,
        "temperature": 0,
        "text": " This dot, this dot, this dot, never forget this dot.",
        "tokens": [
          50784,
          639,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          1128,
          2870,
          341,
          5893,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1241.56,
        "id": 423,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1237.9599999999998,
        "temperature": 0,
        "text": " I'm going to do the this dot, this dot, this dot, this dot, the this dot song,",
        "tokens": [
          51020,
          286,
          478,
          516,
          281,
          360,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          264,
          341,
          5893,
          2153,
          11,
          51200
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1242.6799999999998,
        "id": 424,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1241.56,
        "temperature": 0,
        "text": " never forget the this dot.",
        "tokens": [
          51200,
          1128,
          2870,
          264,
          341,
          5893,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1245.1599999999999,
        "id": 425,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1243.72,
        "temperature": 0,
        "text": " Somebody compose that song for me.",
        "tokens": [
          51308,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1246.28,
        "id": 426,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1245.9599999999998,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51420,
          21726,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1249.72,
        "id": 427,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1248.84,
        "temperature": 0,
        "text": " Oh, here we go.",
        "tokens": [
          51564,
          876,
          11,
          510,
          321,
          352,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1249.9599999999998,
        "id": 428,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1249.72,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          51608,
          639,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1251.56,
        "id": 429,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1251.1599999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51680,
          2264,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2982223569884781,
        "compression_ratio": 2.184971098265896,
        "end": 1253.3999999999999,
        "id": 430,
        "no_speech_prob": 0.04271634668111801,
        "seek": 122484,
        "start": 1251.56,
        "temperature": 0,
        "text": " I'm just opening up this project.",
        "tokens": [
          51700,
          286,
          478,
          445,
          5193,
          493,
          341,
          1716,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1256.12,
        "id": 431,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1255.1599999999999,
        "temperature": 0,
        "text": " Getting the code.",
        "tokens": [
          50380,
          13674,
          264,
          3089,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1256.76,
        "id": 432,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1256.12,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50428,
          821,
          321,
          352,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1262.04,
        "id": 433,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1258.4399999999998,
        "temperature": 0,
        "text": " I'm going to clean this up for a second.",
        "tokens": [
          50544,
          286,
          478,
          516,
          281,
          2541,
          341,
          493,
          337,
          257,
          1150,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1271,
        "id": 434,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1262.04,
        "temperature": 0,
        "text": " I want to have I don't need the sound library, but I do need the DOM library and sketch.js",
        "tokens": [
          50724,
          286,
          528,
          281,
          362,
          286,
          500,
          380,
          643,
          264,
          1626,
          6405,
          11,
          457,
          286,
          360,
          643,
          264,
          35727,
          6405,
          293,
          12325,
          13,
          25530,
          51172
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1274.4399999999998,
        "id": 435,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1272.52,
        "temperature": 0,
        "text": " and index.html.",
        "tokens": [
          51248,
          293,
          8186,
          13,
          357,
          15480,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1276.28,
        "id": 436,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1274.4399999999998,
        "temperature": 0,
        "text": " And I'm going to say title.",
        "tokens": [
          51344,
          400,
          286,
          478,
          516,
          281,
          584,
          4876,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.264958900741384,
        "compression_ratio": 1.4125,
        "end": 1282.52,
        "id": 437,
        "no_speech_prob": 0.0025507810059934855,
        "seek": 125484,
        "start": 1279.24,
        "temperature": 0,
        "text": " Title AFIN111 demo.",
        "tokens": [
          51584,
          26768,
          20389,
          1464,
          5348,
          16,
          10723,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.6072363561513473,
        "compression_ratio": 1.24,
        "end": 1288.92,
        "id": 438,
        "no_speech_prob": 0.0014325212687253952,
        "seek": 128252,
        "start": 1282.92,
        "temperature": 0,
        "text": " I just get a few things set up here and then I want to run a server.",
        "tokens": [
          50384,
          286,
          445,
          483,
          257,
          1326,
          721,
          992,
          493,
          510,
          293,
          550,
          286,
          528,
          281,
          1190,
          257,
          7154,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.6072363561513473,
        "compression_ratio": 1.24,
        "end": 1292.44,
        "id": 439,
        "no_speech_prob": 0.0014325212687253952,
        "seek": 128252,
        "start": 1291.6399999999999,
        "temperature": 0,
        "text": " Tempted.",
        "tokens": [
          50820,
          314,
          4543,
          292,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.6072363561513473,
        "compression_ratio": 1.24,
        "end": 1292.84,
        "id": 440,
        "no_speech_prob": 0.0014325212687253952,
        "seek": 128252,
        "start": 1292.44,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50860,
          2264,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.6072363561513473,
        "compression_ratio": 1.24,
        "end": 1296.28,
        "id": 441,
        "no_speech_prob": 0.0014325212687253952,
        "seek": 128252,
        "start": 1295.8,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51028,
          45263,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.6072363561513473,
        "compression_ratio": 1.24,
        "end": 1302.44,
        "id": 442,
        "no_speech_prob": 0.0014325212687253952,
        "seek": 128252,
        "start": 1300.76,
        "temperature": 0,
        "text": " Let's run a server.",
        "tokens": [
          51276,
          961,
          311,
          1190,
          257,
          7154,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.6072363561513473,
        "compression_ratio": 1.24,
        "end": 1306.68,
        "id": 443,
        "no_speech_prob": 0.0014325212687253952,
        "seek": 128252,
        "start": 1305.24,
        "temperature": 0,
        "text": " Session eight.",
        "tokens": [
          51500,
          318,
          4311,
          3180,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.21685638762356943,
        "compression_ratio": 1.2923076923076924,
        "end": 1316.04,
        "id": 444,
        "no_speech_prob": 0.0023966259323060513,
        "seek": 131252,
        "start": 1312.76,
        "temperature": 0,
        "text": " And let's take a look at everything in the browser.",
        "tokens": [
          50376,
          400,
          718,
          311,
          747,
          257,
          574,
          412,
          1203,
          294,
          264,
          11185,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.21685638762356943,
        "compression_ratio": 1.2923076923076924,
        "end": 1322.84,
        "id": 445,
        "no_speech_prob": 0.0023966259323060513,
        "seek": 131252,
        "start": 1318.84,
        "temperature": 0,
        "text": " And let's get a console open.",
        "tokens": [
          50680,
          400,
          718,
          311,
          483,
          257,
          11076,
          1269,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.21685638762356943,
        "compression_ratio": 1.2923076923076924,
        "end": 1329.32,
        "id": 446,
        "no_speech_prob": 0.0023966259323060513,
        "seek": 131252,
        "start": 1323.8,
        "temperature": 0,
        "text": " Let's do no canvas.",
        "tokens": [
          50928,
          961,
          311,
          360,
          572,
          16267,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.21685638762356943,
        "compression_ratio": 1.2923076923076924,
        "end": 1333.72,
        "id": 447,
        "no_speech_prob": 0.0023966259323060513,
        "seek": 131252,
        "start": 1331.32,
        "temperature": 0,
        "text": " Console.log sentiment.",
        "tokens": [
          51304,
          44152,
          13,
          4987,
          16149,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.21685638762356943,
        "compression_ratio": 1.2923076923076924,
        "end": 1336.52,
        "id": 448,
        "no_speech_prob": 0.0023966259323060513,
        "seek": 131252,
        "start": 1335.96,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51536,
          2264,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21685638762356943,
        "compression_ratio": 1.2923076923076924,
        "end": 1339.08,
        "id": 449,
        "no_speech_prob": 0.0023966259323060513,
        "seek": 131252,
        "start": 1336.52,
        "temperature": 0,
        "text": " So it looks like we are up and running.",
        "tokens": [
          51564,
          407,
          309,
          1542,
          411,
          321,
          366,
          493,
          293,
          2614,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1342.4399999999998,
        "id": 450,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1340.04,
        "temperature": 0,
        "text": " I need to have the website.",
        "tokens": [
          50412,
          286,
          643,
          281,
          362,
          264,
          3144,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1344.12,
        "id": 451,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1342.4399999999998,
        "temperature": 0,
        "text": " I need also this URL.",
        "tokens": [
          50532,
          286,
          643,
          611,
          341,
          12905,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1353.96,
        "id": 452,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1352.6,
        "temperature": 0,
        "text": " I will have open here.",
        "tokens": [
          51040,
          286,
          486,
          362,
          1269,
          510,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1354.1999999999998,
        "id": 453,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1353.96,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51108,
          2264,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1357.8,
        "id": 454,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1354.84,
        "temperature": 0,
        "text": " I'm just checking the chat.",
        "tokens": [
          51152,
          286,
          478,
          445,
          8568,
          264,
          5081,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1359.8799999999999,
        "id": 455,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1357.8,
        "temperature": 0,
        "text": " Are you supposed to hear the audio from the computer?",
        "tokens": [
          51300,
          2014,
          291,
          3442,
          281,
          1568,
          264,
          6278,
          490,
          264,
          3820,
          30,
          51404
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1361,
        "id": 456,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1360.52,
        "temperature": 0,
        "text": " You are.",
        "tokens": [
          51436,
          509,
          366,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1362.6,
        "id": 457,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1362.04,
        "temperature": 0,
        "text": " Did you not?",
        "tokens": [
          51512,
          2589,
          291,
          406,
          30,
          51540
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1363.6399999999999,
        "id": 458,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1363.1599999999999,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51568,
          6962,
          322,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.21538899739583334,
        "compression_ratio": 1.4316939890710383,
        "end": 1368.36,
        "id": 459,
        "no_speech_prob": 0.00364994746632874,
        "seek": 133908,
        "start": 1364.76,
        "temperature": 0,
        "text": " Oh, you can't hear my voice when I'm playing the music at the same time.",
        "tokens": [
          51648,
          876,
          11,
          291,
          393,
          380,
          1568,
          452,
          3177,
          562,
          286,
          478,
          2433,
          264,
          1318,
          412,
          264,
          912,
          565,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1368.6799999999998,
        "id": 460,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1368.4399999999998,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50368,
          2264,
          13,
          50380
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1369.3999999999999,
        "id": 461,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1368.6799999999998,
        "temperature": 0,
        "text": " That's good to know.",
        "tokens": [
          50380,
          663,
          311,
          665,
          281,
          458,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1373.6399999999999,
        "id": 462,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1370.36,
        "temperature": 0,
        "text": " I can also turn down the music and all that stuff.",
        "tokens": [
          50464,
          286,
          393,
          611,
          1261,
          760,
          264,
          1318,
          293,
          439,
          300,
          1507,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1375.08,
        "id": 463,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1373.6399999999999,
        "temperature": 0,
        "text": " But I'm not going to worry about it right now.",
        "tokens": [
          50628,
          583,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          309,
          558,
          586,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1378.28,
        "id": 464,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1377.8799999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50840,
          1057,
          558,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1379.1599999999999,
        "id": 465,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1379,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50896,
          3153,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1385.08,
        "id": 466,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1379.1599999999999,
        "temperature": 0,
        "text": " This has been the least amount of technical difficulties I've had doing this in a while.",
        "tokens": [
          50904,
          639,
          575,
          668,
          264,
          1935,
          2372,
          295,
          6191,
          14399,
          286,
          600,
          632,
          884,
          341,
          294,
          257,
          1339,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1387.9599999999998,
        "id": 467,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1385.08,
        "temperature": 0,
        "text": " But I shouldn't say anything because now everything's going to start crashing and burning.",
        "tokens": [
          51200,
          583,
          286,
          4659,
          380,
          584,
          1340,
          570,
          586,
          1203,
          311,
          516,
          281,
          722,
          26900,
          293,
          9488,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1388.6799999999998,
        "id": 468,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1387.9599999999998,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51344,
          2264,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.22839920861380442,
        "compression_ratio": 1.6072874493927125,
        "end": 1396.36,
        "id": 469,
        "no_speech_prob": 0.0003199953935109079,
        "seek": 136836,
        "start": 1388.6799999999998,
        "temperature": 0,
        "text": " So I'm checking in the chat to see if anyone is saying anything important.",
        "tokens": [
          51380,
          407,
          286,
          478,
          8568,
          294,
          264,
          5081,
          281,
          536,
          498,
          2878,
          307,
          1566,
          1340,
          1021,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1398.1999999999998,
        "id": 470,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1396.84,
        "temperature": 0,
        "text": " Like nothing is working.",
        "tokens": [
          50388,
          1743,
          1825,
          307,
          1364,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1398.9199999999998,
        "id": 471,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1398.1999999999998,
        "temperature": 0,
        "text": " I can't see anything.",
        "tokens": [
          50456,
          286,
          393,
          380,
          536,
          1340,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1399.6399999999999,
        "id": 472,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1398.9199999999998,
        "temperature": 0,
        "text": " It looks OK.",
        "tokens": [
          50492,
          467,
          1542,
          2264,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1401.8,
        "id": 473,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1400.1999999999998,
        "temperature": 0,
        "text": " So I am now going to get started.",
        "tokens": [
          50556,
          407,
          286,
          669,
          586,
          516,
          281,
          483,
          1409,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1402.6,
        "id": 474,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1401.8,
        "temperature": 0,
        "text": " Oh, hold on.",
        "tokens": [
          50636,
          876,
          11,
          1797,
          322,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1405.7199999999998,
        "id": 475,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1402.6,
        "temperature": 0,
        "text": " This microphone is awkwardly positioned.",
        "tokens": [
          50676,
          639,
          10952,
          307,
          11411,
          356,
          24889,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1407,
        "id": 476,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1405.7199999999998,
        "temperature": 0,
        "text": " That's a little bit better.",
        "tokens": [
          50832,
          663,
          311,
          257,
          707,
          857,
          1101,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1413.1599999999999,
        "id": 477,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1407,
        "temperature": 0,
        "text": " So this first video that I'm going to do, first of all, the reason why I'm doing this is because,",
        "tokens": [
          50896,
          407,
          341,
          700,
          960,
          300,
          286,
          478,
          516,
          281,
          360,
          11,
          700,
          295,
          439,
          11,
          264,
          1778,
          983,
          286,
          478,
          884,
          341,
          307,
          570,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1414.6,
        "id": 478,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1414.1999999999998,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51256,
          286,
          500,
          380,
          458,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1415.8799999999999,
        "id": 479,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1415.32,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51312,
          1545,
          406,
          30,
          51340
        ]
      },
      {
        "avg_logprob": -0.202912441889445,
        "compression_ratio": 1.5477178423236515,
        "end": 1426.1999999999998,
        "id": 480,
        "no_speech_prob": 0.00020027293066959828,
        "seek": 139636,
        "start": 1417.32,
        "temperature": 0,
        "text": " But what I want to do is have the node API that I'm making do be an example.",
        "tokens": [
          51412,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          362,
          264,
          9984,
          9362,
          300,
          286,
          478,
          1455,
          360,
          312,
          364,
          1365,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1428.68,
        "id": 481,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1426.28,
        "temperature": 0,
        "text": " Just be a sentiment analysis API.",
        "tokens": [
          50368,
          1449,
          312,
          257,
          16149,
          5215,
          9362,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1432.92,
        "id": 482,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1428.68,
        "temperature": 0,
        "text": " And so I thought it would be worth before going and adding all that code to node",
        "tokens": [
          50488,
          400,
          370,
          286,
          1194,
          309,
          576,
          312,
          3163,
          949,
          516,
          293,
          5127,
          439,
          300,
          3089,
          281,
          9984,
          50700
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1436.6000000000001,
        "id": 483,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1432.92,
        "temperature": 0,
        "text": " to just sort of show one simple technique for doing sentiment analysis.",
        "tokens": [
          50700,
          281,
          445,
          1333,
          295,
          855,
          472,
          2199,
          6532,
          337,
          884,
          16149,
          5215,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1440.68,
        "id": 484,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1438.04,
        "temperature": 0,
        "text": " And do that in a coding challenge.",
        "tokens": [
          50956,
          400,
          360,
          300,
          294,
          257,
          17720,
          3430,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1447.48,
        "id": 485,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1440.68,
        "temperature": 0,
        "text": " Also just kind of like, there's a lot of stuff I think that's interesting to explore here.",
        "tokens": [
          51088,
          2743,
          445,
          733,
          295,
          411,
          11,
          456,
          311,
          257,
          688,
          295,
          1507,
          286,
          519,
          300,
          311,
          1880,
          281,
          6839,
          510,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1448.92,
        "id": 486,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1447.48,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51428,
          407,
          510,
          321,
          352,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1451.32,
        "id": 487,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1449.64,
        "temperature": 0,
        "text": " The little shadow on the green screen.",
        "tokens": [
          51536,
          440,
          707,
          8576,
          322,
          264,
          3092,
          2568,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1452.2,
        "id": 488,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1451.32,
        "temperature": 0,
        "text": " I know.",
        "tokens": [
          51620,
          286,
          458,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2149935449872698,
        "compression_ratio": 1.680161943319838,
        "end": 1454.2,
        "id": 489,
        "no_speech_prob": 0.00041731027886271477,
        "seek": 142620,
        "start": 1452.2,
        "temperature": 0,
        "text": " It's because one of my lights is broken.",
        "tokens": [
          51664,
          467,
          311,
          570,
          472,
          295,
          452,
          5811,
          307,
          5463,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1458.3600000000001,
        "id": 490,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1454.2,
        "temperature": 0,
        "text": " Let's see if I might be able to do something about it.",
        "tokens": [
          50364,
          961,
          311,
          536,
          498,
          286,
          1062,
          312,
          1075,
          281,
          360,
          746,
          466,
          309,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1458.92,
        "id": 491,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1458.3600000000001,
        "temperature": 0,
        "text": " I shouldn't.",
        "tokens": [
          50572,
          286,
          4659,
          380,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1461.16,
        "id": 492,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1459.8,
        "temperature": 0,
        "text": " I'm a little bit afraid to do this.",
        "tokens": [
          50644,
          286,
          478,
          257,
          707,
          857,
          4638,
          281,
          360,
          341,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1461.66,
        "id": 493,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1461.16,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50712,
          7521,
          13,
          50737
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1463.96,
        "id": 494,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1462.8400000000001,
        "temperature": 0,
        "text": " Hey, that shadow's gone.",
        "tokens": [
          50796,
          1911,
          11,
          300,
          8576,
          311,
          2780,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1465.24,
        "id": 495,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1463.96,
        "temperature": 0,
        "text": " Now, oh, no, it's worse.",
        "tokens": [
          50852,
          823,
          11,
          1954,
          11,
          572,
          11,
          309,
          311,
          5324,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1466.2,
        "id": 496,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1465.24,
        "temperature": 0,
        "text": " OK, better not do that.",
        "tokens": [
          50916,
          2264,
          11,
          1101,
          406,
          360,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1468.8600000000001,
        "id": 497,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1468.3600000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51072,
          2264,
          13,
          51097
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1470.28,
        "id": 498,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1469.24,
        "temperature": 0,
        "text": " We're just going to have to live with it.",
        "tokens": [
          51116,
          492,
          434,
          445,
          516,
          281,
          362,
          281,
          1621,
          365,
          309,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1472.92,
        "id": 499,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1470.28,
        "temperature": 0,
        "text": " It's if I step over here, it gets worse.",
        "tokens": [
          51168,
          467,
          311,
          498,
          286,
          1823,
          670,
          510,
          11,
          309,
          2170,
          5324,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1474.8400000000001,
        "id": 500,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1472.92,
        "temperature": 0,
        "text": " If I stay over here, it's better.",
        "tokens": [
          51300,
          759,
          286,
          1754,
          670,
          510,
          11,
          309,
          311,
          1101,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1476.92,
        "id": 501,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1474.8400000000001,
        "temperature": 0,
        "text": " So that's just how it's going to be for now.",
        "tokens": [
          51396,
          407,
          300,
          311,
          445,
          577,
          309,
          311,
          516,
          281,
          312,
          337,
          586,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1478.46,
        "id": 502,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1477.96,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51552,
          2264,
          13,
          51577
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1481.88,
        "id": 503,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1480.76,
        "temperature": 0,
        "text": " Audio is awesome.",
        "tokens": [
          51692,
          25706,
          307,
          3476,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.1908064755526456,
        "compression_ratio": 1.6536796536796536,
        "end": 1482.38,
        "id": 504,
        "no_speech_prob": 0.000010616096005833242,
        "seek": 145420,
        "start": 1481.88,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51748,
          1057,
          558,
          13,
          51773
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1484.0600000000002,
        "id": 505,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1483.3400000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50412,
          1057,
          558,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1485.1000000000001,
        "id": 506,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1484.0600000000002,
        "temperature": 0,
        "text": " Here we go, everybody.",
        "tokens": [
          50448,
          1692,
          321,
          352,
          11,
          2201,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1488.3000000000002,
        "id": 507,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1486.22,
        "temperature": 0,
        "text": " This is a tutorial.",
        "tokens": [
          50556,
          639,
          307,
          257,
          7073,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1489.1000000000001,
        "id": 508,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1488.3000000000002,
        "temperature": 0,
        "text": " It is 3.",
        "tokens": [
          50660,
          467,
          307,
          805,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1489.5800000000002,
        "id": 509,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1489.1000000000001,
        "temperature": 0,
        "text": " Oh, my god.",
        "tokens": [
          50700,
          876,
          11,
          452,
          3044,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1490.7800000000002,
        "id": 510,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1489.5800000000002,
        "temperature": 0,
        "text": " It's 3.45 already.",
        "tokens": [
          50724,
          467,
          311,
          805,
          13,
          8465,
          1217,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1491.5,
        "id": 511,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1490.7800000000002,
        "temperature": 0,
        "text": " That's not good.",
        "tokens": [
          50784,
          663,
          311,
          406,
          665,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1492,
        "id": 512,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1491.5,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50820,
          2264,
          13,
          50845
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1495.1000000000001,
        "id": 513,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1494.5400000000002,
        "temperature": 0,
        "text": " 25.",
        "tokens": [
          50972,
          3552,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1495.8200000000002,
        "id": 514,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1495.1000000000001,
        "temperature": 0,
        "text": " Oh, I forgot.",
        "tokens": [
          51000,
          876,
          11,
          286,
          5298,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1497.9,
        "id": 515,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1495.8200000000002,
        "temperature": 0,
        "text": " I was going to talk about the processing fellowships.",
        "tokens": [
          51036,
          286,
          390,
          516,
          281,
          751,
          466,
          264,
          9007,
          24989,
          82,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1499.74,
        "id": 516,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1497.9,
        "temperature": 0,
        "text": " So that was my first thing that I was going to talk about.",
        "tokens": [
          51140,
          407,
          300,
          390,
          452,
          700,
          551,
          300,
          286,
          390,
          516,
          281,
          751,
          466,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1500.38,
        "id": 517,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1499.74,
        "temperature": 0,
        "text": " Let's do that now.",
        "tokens": [
          51232,
          961,
          311,
          360,
          300,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1501.3400000000001,
        "id": 518,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1500.38,
        "temperature": 0,
        "text": " So, oh, boy.",
        "tokens": [
          51264,
          407,
          11,
          1954,
          11,
          3237,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1503.5,
        "id": 519,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1502.7,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51380,
          2264,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1504.3000000000002,
        "id": 520,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1503.5,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          51420,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2381913321358817,
        "compression_ratio": 1.6736401673640167,
        "end": 1511.5800000000002,
        "id": 521,
        "no_speech_prob": 0.00004006352537544444,
        "seek": 148238,
        "start": 1505.8200000000002,
        "temperature": 0,
        "text": " So I just want to mention this because I think it's worth mentioning to kind of let the broadest",
        "tokens": [
          51536,
          407,
          286,
          445,
          528,
          281,
          2152,
          341,
          570,
          286,
          519,
          309,
          311,
          3163,
          18315,
          281,
          733,
          295,
          718,
          264,
          4152,
          377,
          51824
        ]
      },
      {
        "avg_logprob": -0.18191487290138422,
        "compression_ratio": 1.6062992125984252,
        "end": 1515.34,
        "id": 522,
        "no_speech_prob": 0.0017815235769376159,
        "seek": 151158,
        "start": 1511.58,
        "temperature": 0,
        "text": " audience know about this opportunity for those of you who might be interested.",
        "tokens": [
          50364,
          4034,
          458,
          466,
          341,
          2650,
          337,
          729,
          295,
          291,
          567,
          1062,
          312,
          3102,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.18191487290138422,
        "compression_ratio": 1.6062992125984252,
        "end": 1519.58,
        "id": 523,
        "no_speech_prob": 0.0017815235769376159,
        "seek": 151158,
        "start": 1515.34,
        "temperature": 0,
        "text": " Processing Foundation, I've talked about before on live streams, is a non-for-profit",
        "tokens": [
          50552,
          31093,
          278,
          10335,
          11,
          286,
          600,
          2825,
          466,
          949,
          322,
          1621,
          15842,
          11,
          307,
          257,
          2107,
          12,
          2994,
          12,
          14583,
          50764
        ]
      },
      {
        "avg_logprob": -0.18191487290138422,
        "compression_ratio": 1.6062992125984252,
        "end": 1529.02,
        "id": 524,
        "no_speech_prob": 0.0017815235769376159,
        "seek": 151158,
        "start": 1521.26,
        "temperature": 0,
        "text": " foundation whose primary mission is to promote software literacy and make code and creative",
        "tokens": [
          50848,
          7030,
          6104,
          6194,
          4447,
          307,
          281,
          9773,
          4722,
          23166,
          293,
          652,
          3089,
          293,
          5880,
          51236
        ]
      },
      {
        "avg_logprob": -0.18191487290138422,
        "compression_ratio": 1.6062992125984252,
        "end": 1533.5,
        "id": 525,
        "no_speech_prob": 0.0017815235769376159,
        "seek": 151158,
        "start": 1529.02,
        "temperature": 0,
        "text": " work with code accessible and available to diverse communities.",
        "tokens": [
          51236,
          589,
          365,
          3089,
          9515,
          293,
          2435,
          281,
          9521,
          4456,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.18191487290138422,
        "compression_ratio": 1.6062992125984252,
        "end": 1539.58,
        "id": 526,
        "no_speech_prob": 0.0017815235769376159,
        "seek": 151158,
        "start": 1533.5,
        "temperature": 0,
        "text": " And so in addition to education and diversity initiatives that we sponsor, which you can",
        "tokens": [
          51460,
          400,
          370,
          294,
          4500,
          281,
          3309,
          293,
          8811,
          16194,
          300,
          321,
          16198,
          11,
          597,
          291,
          393,
          51764
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1544.06,
        "id": 527,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1539.58,
        "temperature": 0,
        "text": " find out on the Processing Foundation's initiative page, we maintain what you're probably",
        "tokens": [
          50364,
          915,
          484,
          322,
          264,
          31093,
          278,
          10335,
          311,
          11552,
          3028,
          11,
          321,
          6909,
          437,
          291,
          434,
          1391,
          50588
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1550.06,
        "id": 528,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1544.06,
        "temperature": 0,
        "text": " more familiar with, the platform's processing, which is a Java-based creative coding platform,",
        "tokens": [
          50588,
          544,
          4963,
          365,
          11,
          264,
          3663,
          311,
          9007,
          11,
          597,
          307,
          257,
          10745,
          12,
          6032,
          5880,
          17720,
          3663,
          11,
          50888
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1554.1399999999999,
        "id": 529,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1550.06,
        "temperature": 0,
        "text": " p5.js, which is the JavaScript library that I'm using in a lot of my examples, at least",
        "tokens": [
          50888,
          280,
          20,
          13,
          25530,
          11,
          597,
          307,
          264,
          15778,
          6405,
          300,
          286,
          478,
          1228,
          294,
          257,
          688,
          295,
          452,
          5110,
          11,
          412,
          1935,
          51092
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1555.26,
        "id": 530,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1554.1399999999999,
        "temperature": 0,
        "text": " the ones that I'll do today.",
        "tokens": [
          51092,
          264,
          2306,
          300,
          286,
          603,
          360,
          965,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1557.26,
        "id": 531,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1555.26,
        "temperature": 0,
        "text": " There's also a Python version of processing.",
        "tokens": [
          51148,
          821,
          311,
          611,
          257,
          15329,
          3037,
          295,
          9007,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1557.74,
        "id": 532,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1557.26,
        "temperature": 0,
        "text": " You can't see.",
        "tokens": [
          51248,
          509,
          393,
          380,
          536,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1561.02,
        "id": 533,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1557.74,
        "temperature": 0,
        "text": " I'm hovering with this tiny little pointer on these links.",
        "tokens": [
          51272,
          286,
          478,
          44923,
          365,
          341,
          5870,
          707,
          23918,
          322,
          613,
          6123,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.19495151488761592,
        "compression_ratio": 1.6372881355932203,
        "end": 1566.62,
        "id": 534,
        "no_speech_prob": 0.00555452099069953,
        "seek": 153958,
        "start": 1561.02,
        "temperature": 0,
        "text": " So you might be familiar with all of these different projects.",
        "tokens": [
          51436,
          407,
          291,
          1062,
          312,
          4963,
          365,
          439,
          295,
          613,
          819,
          4455,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.21479320526123047,
        "compression_ratio": 1.5766129032258065,
        "end": 1572.54,
        "id": 535,
        "no_speech_prob": 0.03160475194454193,
        "seek": 156662,
        "start": 1567.5,
        "temperature": 0,
        "text": " What we started last year is a fellowship program, and the fellowship program currently",
        "tokens": [
          50408,
          708,
          321,
          1409,
          1036,
          1064,
          307,
          257,
          24989,
          1461,
          11,
          293,
          264,
          24989,
          1461,
          4362,
          50660
        ]
      },
      {
        "avg_logprob": -0.21479320526123047,
        "compression_ratio": 1.5766129032258065,
        "end": 1574.54,
        "id": 536,
        "no_speech_prob": 0.03160475194454193,
        "seek": 156662,
        "start": 1572.54,
        "temperature": 0,
        "text": " has its open call right now.",
        "tokens": [
          50660,
          575,
          1080,
          1269,
          818,
          558,
          586,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.21479320526123047,
        "compression_ratio": 1.5766129032258065,
        "end": 1580.2199999999998,
        "id": 537,
        "no_speech_prob": 0.03160475194454193,
        "seek": 156662,
        "start": 1574.54,
        "temperature": 0,
        "text": " So just to let you know briefly, let me scroll down here and get, these are the fellows from",
        "tokens": [
          50760,
          407,
          445,
          281,
          718,
          291,
          458,
          10515,
          11,
          718,
          385,
          11369,
          760,
          510,
          293,
          483,
          11,
          613,
          366,
          264,
          35595,
          490,
          51044
        ]
      },
      {
        "avg_logprob": -0.21479320526123047,
        "compression_ratio": 1.5766129032258065,
        "end": 1585.6599999999999,
        "id": 538,
        "no_speech_prob": 0.03160475194454193,
        "seek": 156662,
        "start": 1580.2199999999998,
        "temperature": 0,
        "text": " last year, Allison Parrish, who worked on advocacy documentation and tutorials for processing",
        "tokens": [
          51044,
          1036,
          1064,
          11,
          32638,
          47890,
          742,
          11,
          567,
          2732,
          322,
          22011,
          14333,
          293,
          17616,
          337,
          9007,
          51316
        ]
      },
      {
        "avg_logprob": -0.21479320526123047,
        "compression_ratio": 1.5766129032258065,
        "end": 1591.4199999999998,
        "id": 539,
        "no_speech_prob": 0.03160475194454193,
        "seek": 156662,
        "start": 1585.6599999999999,
        "temperature": 0,
        "text": " Python mode, Claire Kearney-Volpe, who was a guest here on this YouTube channel to talk",
        "tokens": [
          51316,
          15329,
          4391,
          11,
          22605,
          3189,
          289,
          2397,
          12,
          53,
          401,
          494,
          11,
          567,
          390,
          257,
          8341,
          510,
          322,
          341,
          3088,
          2269,
          281,
          751,
          51604
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1596.22,
        "id": 540,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1591.42,
        "temperature": 0,
        "text": " about her work with accessibility, working with low vision and blind people and code.",
        "tokens": [
          50364,
          466,
          720,
          589,
          365,
          15002,
          11,
          1364,
          365,
          2295,
          5201,
          293,
          6865,
          561,
          293,
          3089,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1601.9,
        "id": 541,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1596.8600000000001,
        "temperature": 0,
        "text": " Digital Citizens Lab created a learning platform about code using comics, worked with an after",
        "tokens": [
          50636,
          15522,
          44120,
          10137,
          2942,
          257,
          2539,
          3663,
          466,
          3089,
          1228,
          18756,
          11,
          2732,
          365,
          364,
          934,
          50888
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1603.98,
        "id": 542,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1601.9,
        "temperature": 0,
        "text": " school program here in the Bronx in New York City.",
        "tokens": [
          50888,
          1395,
          1461,
          510,
          294,
          264,
          41862,
          294,
          1873,
          3609,
          4392,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1609.74,
        "id": 543,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1604.54,
        "temperature": 0,
        "text": " Jessica Klein and Atul Varma worked on a bunch of different features to make p5 more friendly",
        "tokens": [
          51020,
          15570,
          33327,
          293,
          1711,
          425,
          14662,
          1696,
          2732,
          322,
          257,
          3840,
          295,
          819,
          4122,
          281,
          652,
          280,
          20,
          544,
          9208,
          51280
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1610.46,
        "id": 544,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1609.74,
        "temperature": 0,
        "text": " and accessible.",
        "tokens": [
          51280,
          293,
          9515,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1616.14,
        "id": 545,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1611.1000000000001,
        "temperature": 0,
        "text": " So these are some of the, oh, and sorry, I didn't scroll all the way down, Tiga Brain",
        "tokens": [
          51348,
          407,
          613,
          366,
          512,
          295,
          264,
          11,
          1954,
          11,
          293,
          2597,
          11,
          286,
          994,
          380,
          11369,
          439,
          264,
          636,
          760,
          11,
          314,
          9900,
          29783,
          51600
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1618.8600000000001,
        "id": 546,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1616.14,
        "temperature": 0,
        "text": " and Luisa Pereira, who worked on tutorials for p5.",
        "tokens": [
          51600,
          293,
          5047,
          3837,
          49349,
          4271,
          11,
          567,
          2732,
          322,
          17616,
          337,
          280,
          20,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.22022784575251222,
        "compression_ratio": 1.6230529595015577,
        "end": 1620.6200000000001,
        "id": 547,
        "no_speech_prob": 0.35544905066490173,
        "seek": 159142,
        "start": 1618.8600000000001,
        "temperature": 0,
        "text": " Tiga also did a tutorial for this channel.",
        "tokens": [
          51736,
          314,
          9900,
          611,
          630,
          257,
          7073,
          337,
          341,
          2269,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.20012094220544538,
        "compression_ratio": 1.6535714285714285,
        "end": 1626.14,
        "id": 548,
        "no_speech_prob": 0.00007030790584394708,
        "seek": 162142,
        "start": 1621.42,
        "temperature": 0,
        "text": " And these are some previous fellowships, Vilm Tobin, who worked on the processing sound",
        "tokens": [
          50364,
          400,
          613,
          366,
          512,
          3894,
          24989,
          82,
          11,
          35653,
          76,
          26350,
          259,
          11,
          567,
          2732,
          322,
          264,
          9007,
          1626,
          50600
        ]
      },
      {
        "avg_logprob": -0.20012094220544538,
        "compression_ratio": 1.6535714285714285,
        "end": 1631.5,
        "id": 549,
        "no_speech_prob": 0.00007030790584394708,
        "seek": 162142,
        "start": 1626.14,
        "temperature": 0,
        "text": " library, Lauren McCarthy, who now is a core director of the Processing Foundation, the",
        "tokens": [
          50600,
          6405,
          11,
          18915,
          44085,
          11,
          567,
          586,
          307,
          257,
          4965,
          5391,
          295,
          264,
          31093,
          278,
          10335,
          11,
          264,
          50868
        ]
      },
      {
        "avg_logprob": -0.20012094220544538,
        "compression_ratio": 1.6535714285714285,
        "end": 1635.9,
        "id": 550,
        "no_speech_prob": 0.00007030790584394708,
        "seek": 162142,
        "start": 1631.5,
        "temperature": 0,
        "text": " inventor of p5.js, what originally started as a fellowship, Greg Bornstein, who did a",
        "tokens": [
          50868,
          41593,
          295,
          280,
          20,
          13,
          25530,
          11,
          437,
          7993,
          1409,
          382,
          257,
          24989,
          11,
          11490,
          29808,
          9089,
          11,
          567,
          630,
          257,
          51088
        ]
      },
      {
        "avg_logprob": -0.20012094220544538,
        "compression_ratio": 1.6535714285714285,
        "end": 1638.46,
        "id": 551,
        "no_speech_prob": 0.00007030790584394708,
        "seek": 162142,
        "start": 1635.9,
        "temperature": 0,
        "text": " fellowship on OpenCV with processing.",
        "tokens": [
          51088,
          24989,
          322,
          7238,
          34,
          53,
          365,
          9007,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.20012094220544538,
        "compression_ratio": 1.6535714285714285,
        "end": 1643.66,
        "id": 552,
        "no_speech_prob": 0.00007030790584394708,
        "seek": 162142,
        "start": 1638.46,
        "temperature": 0,
        "text": " So these are fellowships that we've sponsored, and we now have an open call.",
        "tokens": [
          51216,
          407,
          613,
          366,
          24989,
          82,
          300,
          321,
          600,
          16621,
          11,
          293,
          321,
          586,
          362,
          364,
          1269,
          818,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.20012094220544538,
        "compression_ratio": 1.6535714285714285,
        "end": 1650.46,
        "id": 553,
        "no_speech_prob": 0.00007030790584394708,
        "seek": 162142,
        "start": 1643.66,
        "temperature": 0,
        "text": " The idea is that for you to propose a project that you want to spend about 100 hours on",
        "tokens": [
          51476,
          440,
          1558,
          307,
          300,
          337,
          291,
          281,
          17421,
          257,
          1716,
          300,
          291,
          528,
          281,
          3496,
          466,
          2319,
          2496,
          322,
          51816
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1657.82,
        "id": 554,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1650.54,
        "temperature": 0,
        "text": " between February 1st and May 31st, and there is a $3,000 stipend, US dollars, but you don't",
        "tokens": [
          50368,
          1296,
          8711,
          502,
          372,
          293,
          1891,
          10353,
          372,
          11,
          293,
          456,
          307,
          257,
          1848,
          18,
          11,
          1360,
          37001,
          521,
          11,
          2546,
          3808,
          11,
          457,
          291,
          500,
          380,
          50732
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1660.54,
        "id": 555,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1657.82,
        "temperature": 0,
        "text": " have to be a US citizen.",
        "tokens": [
          50732,
          362,
          281,
          312,
          257,
          2546,
          13326,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1664.14,
        "id": 556,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1660.54,
        "temperature": 0,
        "text": " You don't have to live in New York or the United States or anywhere to apply for the",
        "tokens": [
          50868,
          509,
          500,
          380,
          362,
          281,
          1621,
          294,
          1873,
          3609,
          420,
          264,
          2824,
          3040,
          420,
          4992,
          281,
          3079,
          337,
          264,
          51048
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1664.7,
        "id": 557,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1664.14,
        "temperature": 0,
        "text": " fellowship.",
        "tokens": [
          51048,
          24989,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1671.66,
        "id": 558,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1665.9,
        "temperature": 0,
        "text": " And if you are selected for the fellowship, you're assigned a mentor to work and develop",
        "tokens": [
          51136,
          400,
          498,
          291,
          366,
          8209,
          337,
          264,
          24989,
          11,
          291,
          434,
          13279,
          257,
          14478,
          281,
          589,
          293,
          1499,
          51424
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1672.54,
        "id": 559,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1671.66,
        "temperature": 0,
        "text": " this project.",
        "tokens": [
          51424,
          341,
          1716,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.1691644321788441,
        "compression_ratio": 1.5517241379310345,
        "end": 1677.42,
        "id": 560,
        "no_speech_prob": 0.0013249617768451571,
        "seek": 165046,
        "start": 1672.54,
        "temperature": 0,
        "text": " This is very similar to Google Summer of Code, which is a program that some of you might",
        "tokens": [
          51468,
          639,
          307,
          588,
          2531,
          281,
          3329,
          16161,
          295,
          15549,
          11,
          597,
          307,
          257,
          1461,
          300,
          512,
          295,
          291,
          1062,
          51712
        ]
      },
      {
        "avg_logprob": -0.20634960546726133,
        "compression_ratio": 1.7522522522522523,
        "end": 1681.5,
        "id": 561,
        "no_speech_prob": 0.012820309028029442,
        "seek": 168046,
        "start": 1680.46,
        "temperature": 0,
        "text": " be familiar with.",
        "tokens": [
          50364,
          312,
          4963,
          365,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.20634960546726133,
        "compression_ratio": 1.7522522522522523,
        "end": 1686.7,
        "id": 562,
        "no_speech_prob": 0.012820309028029442,
        "seek": 168046,
        "start": 1682.54,
        "temperature": 0,
        "text": " A key difference between the Processing Fellowship and Google Summer of Code, however, is that",
        "tokens": [
          50468,
          316,
          2141,
          2649,
          1296,
          264,
          31093,
          278,
          40011,
          1210,
          293,
          3329,
          16161,
          295,
          15549,
          11,
          4461,
          11,
          307,
          300,
          50676
        ]
      },
      {
        "avg_logprob": -0.20634960546726133,
        "compression_ratio": 1.7522522522522523,
        "end": 1695.3400000000001,
        "id": 563,
        "no_speech_prob": 0.012820309028029442,
        "seek": 168046,
        "start": 1686.7,
        "temperature": 0,
        "text": " community-based education, diversity, projects about bringing processing to different and",
        "tokens": [
          50676,
          1768,
          12,
          6032,
          3309,
          11,
          8811,
          11,
          4455,
          466,
          5062,
          9007,
          281,
          819,
          293,
          51108
        ]
      },
      {
        "avg_logprob": -0.20634960546726133,
        "compression_ratio": 1.7522522522522523,
        "end": 1702.6200000000001,
        "id": 564,
        "no_speech_prob": 0.012820309028029442,
        "seek": 168046,
        "start": 1695.3400000000001,
        "temperature": 0,
        "text": " diverse communities, or documentation, tutorials, these are valid processing fellowships, which",
        "tokens": [
          51108,
          9521,
          4456,
          11,
          420,
          14333,
          11,
          17616,
          11,
          613,
          366,
          7363,
          9007,
          24989,
          82,
          11,
          597,
          51472
        ]
      },
      {
        "avg_logprob": -0.20634960546726133,
        "compression_ratio": 1.7522522522522523,
        "end": 1708.38,
        "id": 565,
        "no_speech_prob": 0.012820309028029442,
        "seek": 168046,
        "start": 1702.6200000000001,
        "temperature": 0,
        "text": " is different than Google Summer of Code, which requires projects to be about writing code.",
        "tokens": [
          51472,
          307,
          819,
          813,
          3329,
          16161,
          295,
          15549,
          11,
          597,
          7029,
          4455,
          281,
          312,
          466,
          3579,
          3089,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1711.66,
        "id": 566,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1708.38,
        "temperature": 0,
        "text": " So you don't have to be a professional programmer, you don't have to be an advanced",
        "tokens": [
          50364,
          407,
          291,
          500,
          380,
          362,
          281,
          312,
          257,
          4843,
          32116,
          11,
          291,
          500,
          380,
          362,
          281,
          312,
          364,
          7339,
          50528
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1714.38,
        "id": 567,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1711.66,
        "temperature": 0,
        "text": " programmer, you can be a beginner, you can be a teacher.",
        "tokens": [
          50528,
          32116,
          11,
          291,
          393,
          312,
          257,
          22080,
          11,
          291,
          393,
          312,
          257,
          5027,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1717.8200000000002,
        "id": 568,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1714.38,
        "temperature": 0,
        "text": " If you want to write curriculum, these are types of things that are possible for the",
        "tokens": [
          50664,
          759,
          291,
          528,
          281,
          2464,
          14302,
          11,
          613,
          366,
          3467,
          295,
          721,
          300,
          366,
          1944,
          337,
          264,
          50836
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1718.8600000000001,
        "id": 569,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1717.8200000000002,
        "temperature": 0,
        "text": " Processing Fellowship.",
        "tokens": [
          50836,
          31093,
          278,
          40011,
          1210,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1724.22,
        "id": 570,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1718.8600000000001,
        "temperature": 0,
        "text": " So I just wanted to mention that if you are interested in the fellowship and have questions",
        "tokens": [
          50888,
          407,
          286,
          445,
          1415,
          281,
          2152,
          300,
          498,
          291,
          366,
          3102,
          294,
          264,
          24989,
          293,
          362,
          1651,
          51156
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1728.7800000000002,
        "id": 571,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1724.22,
        "temperature": 0,
        "text": " about it, on Twitter is twitter.com slash processing org.",
        "tokens": [
          51156,
          466,
          309,
          11,
          322,
          5794,
          307,
          21439,
          13,
          1112,
          17330,
          9007,
          14045,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1730.38,
        "id": 572,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1728.7800000000002,
        "temperature": 0,
        "text": " You can tweet at ProcessingOrg.",
        "tokens": [
          51384,
          509,
          393,
          15258,
          412,
          31093,
          278,
          21520,
          70,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1734.14,
        "id": 573,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1730.38,
        "temperature": 0,
        "text": " You can ask questions on the Processing Forum, which is forum.processing.org, and certainly",
        "tokens": [
          51464,
          509,
          393,
          1029,
          1651,
          322,
          264,
          31093,
          278,
          29704,
          11,
          597,
          307,
          17542,
          13,
          41075,
          278,
          13,
          4646,
          11,
          293,
          3297,
          51652
        ]
      },
      {
        "avg_logprob": -0.1958582961319277,
        "compression_ratio": 1.94,
        "end": 1736.3000000000002,
        "id": 574,
        "no_speech_prob": 0.001648412668146193,
        "seek": 170838,
        "start": 1734.14,
        "temperature": 0,
        "text": " you can get in touch with me in the comments of this video.",
        "tokens": [
          51652,
          291,
          393,
          483,
          294,
          2557,
          365,
          385,
          294,
          264,
          3053,
          295,
          341,
          960,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2585801820497255,
        "compression_ratio": 1.42,
        "end": 1739.18,
        "id": 575,
        "no_speech_prob": 0.008711032569408417,
        "seek": 173630,
        "start": 1736.3,
        "temperature": 0,
        "text": " I'm having trouble keeping up with YouTube comments, but I do read them.",
        "tokens": [
          50364,
          286,
          478,
          1419,
          5253,
          5145,
          493,
          365,
          3088,
          3053,
          11,
          457,
          286,
          360,
          1401,
          552,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2585801820497255,
        "compression_ratio": 1.42,
        "end": 1747.8999999999999,
        "id": 576,
        "no_speech_prob": 0.008711032569408417,
        "seek": 173630,
        "start": 1743.74,
        "temperature": 0,
        "text": " And so that's what I just wanted to make an announcement about and plug a little bit about",
        "tokens": [
          50736,
          400,
          370,
          300,
          311,
          437,
          286,
          445,
          1415,
          281,
          652,
          364,
          12847,
          466,
          293,
          5452,
          257,
          707,
          857,
          466,
          50944
        ]
      },
      {
        "avg_logprob": -0.2585801820497255,
        "compression_ratio": 1.42,
        "end": 1749.1,
        "id": 577,
        "no_speech_prob": 0.008711032569408417,
        "seek": 173630,
        "start": 1747.8999999999999,
        "temperature": 0,
        "text": " this fellowship program.",
        "tokens": [
          50944,
          341,
          24989,
          1461,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.2585801820497255,
        "compression_ratio": 1.42,
        "end": 1757.8999999999999,
        "id": 578,
        "no_speech_prob": 0.008711032569408417,
        "seek": 173630,
        "start": 1750.1399999999999,
        "temperature": 0,
        "text": " Okay, so the other thing I'll mention very briefly also, if I go to twitter.com processing",
        "tokens": [
          51056,
          1033,
          11,
          370,
          264,
          661,
          551,
          286,
          603,
          2152,
          588,
          10515,
          611,
          11,
          498,
          286,
          352,
          281,
          21439,
          13,
          1112,
          9007,
          51444
        ]
      },
      {
        "avg_logprob": -0.2585801820497255,
        "compression_ratio": 1.42,
        "end": 1758.22,
        "id": 579,
        "no_speech_prob": 0.008711032569408417,
        "seek": 173630,
        "start": 1757.8999999999999,
        "temperature": 0,
        "text": " org.",
        "tokens": [
          51444,
          14045,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1763.18,
        "id": 580,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1759.02,
        "temperature": 0,
        "text": " So this is the link for the Processing Fellowships on Twitter.",
        "tokens": [
          50404,
          407,
          341,
          307,
          264,
          2113,
          337,
          264,
          31093,
          278,
          40011,
          7640,
          322,
          5794,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1767.18,
        "id": 581,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1763.18,
        "temperature": 0,
        "text": " And then also if we do here.",
        "tokens": [
          50612,
          400,
          550,
          611,
          498,
          321,
          360,
          510,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1768.3,
        "id": 582,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1767.74,
        "temperature": 0,
        "text": " Ah, yes.",
        "tokens": [
          50840,
          2438,
          11,
          2086,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1771.66,
        "id": 583,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1768.8600000000001,
        "temperature": 0,
        "text": " So we have a community survey.",
        "tokens": [
          50896,
          407,
          321,
          362,
          257,
          1768,
          8984,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1777.18,
        "id": 584,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1771.66,
        "temperature": 0,
        "text": " So I would also encourage you if you are a user or a teacher or if you're a student,",
        "tokens": [
          51036,
          407,
          286,
          576,
          611,
          5373,
          291,
          498,
          291,
          366,
          257,
          4195,
          420,
          257,
          5027,
          420,
          498,
          291,
          434,
          257,
          3107,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1783.18,
        "id": 585,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1777.18,
        "temperature": 0,
        "text": " a teacher, a professional, a hobbyist, if you use processing p5.js, processing.py, please",
        "tokens": [
          51312,
          257,
          5027,
          11,
          257,
          4843,
          11,
          257,
          18240,
          468,
          11,
          498,
          291,
          764,
          9007,
          280,
          20,
          13,
          25530,
          11,
          9007,
          13,
          8200,
          11,
          1767,
          51612
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1787.02,
        "id": 586,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1783.18,
        "temperature": 0,
        "text": " fill out this survey to help us understand how people use the software and make priorities",
        "tokens": [
          51612,
          2836,
          484,
          341,
          8984,
          281,
          854,
          505,
          1223,
          577,
          561,
          764,
          264,
          4722,
          293,
          652,
          15503,
          51804
        ]
      },
      {
        "avg_logprob": -0.36253176237407486,
        "compression_ratio": 1.6477732793522266,
        "end": 1787.58,
        "id": 587,
        "no_speech_prob": 0.09945576637983322,
        "seek": 175822,
        "start": 1787.02,
        "temperature": 0,
        "text": " for them.",
        "tokens": [
          51804,
          337,
          552,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1793.02,
        "id": 588,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1788.78,
        "temperature": 1,
        "text": " It's a really, a really exciting program.",
        "tokens": [
          50392,
          467,
          311,
          257,
          534,
          11,
          257,
          534,
          4670,
          1461,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1796.6200000000001,
        "id": 589,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1793.02,
        "temperature": 1,
        "text": " And I hope this is being spread to everyone who's interested.",
        "tokens": [
          50604,
          400,
          286,
          1454,
          341,
          307,
          885,
          3974,
          281,
          1518,
          261,
          1289,
          311,
          3102,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1796.94,
        "id": 590,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1796.6200000000001,
        "temperature": 1,
        "text": " I can't wait.",
        "tokens": [
          50784,
          286,
          393,
          380,
          1699,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1799.42,
        "id": 591,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1796.94,
        "temperature": 1,
        "text": " Hopefully, you want to have a look at it when you go to this time, but hopefully, But I",
        "tokens": [
          50800,
          10429,
          11,
          220,
          5616,
          528,
          281,
          362,
          257,
          574,
          412,
          309,
          562,
          291,
          352,
          281,
          341,
          565,
          11,
          457,
          4696,
          11,
          583,
          286,
          50924
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1801.74,
        "id": 592,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1799.42,
        "temperature": 1,
        "text": " did have a question here about the advantage flush, and I've also seen the amount of",
        "tokens": [
          50924,
          630,
          362,
          257,
          1168,
          510,
          466,
          264,
          5002,
          19568,
          11,
          293,
          286,
          600,
          611,
          1612,
          264,
          2372,
          295,
          51040
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1803.18,
        "id": 593,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1801.74,
        "temperature": 1,
        "text": " penalties for that change in penalties for penalties for non physical penjobs or pen",
        "tokens": [
          51040,
          3435,
          3198,
          530,
          337,
          300,
          1319,
          294,
          3435,
          3198,
          530,
          337,
          3435,
          3198,
          530,
          337,
          2107,
          4001,
          3435,
          5134,
          929,
          420,
          3435,
          51112
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1804.94,
        "id": 594,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1803.18,
        "temperature": 1,
        "text": " quest at age states.",
        "tokens": [
          51112,
          866,
          412,
          3205,
          2219,
          279,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1806.14,
        "id": 595,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1804.94,
        "temperature": 1,
        "text": " And I don't actually understand why they do that that way.",
        "tokens": [
          51200,
          400,
          286,
          500,
          380,
          34964,
          379,
          1223,
          983,
          436,
          360,
          300,
          300,
          636,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1810.38,
        "id": 596,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1807.98,
        "temperature": 1,
        "text": " Because they just don't acknowledge that.",
        "tokens": [
          51352,
          1436,
          436,
          445,
          500,
          380,
          10692,
          300,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -3.061826566370522,
        "compression_ratio": 1.7530120481927711,
        "end": 1816.3,
        "id": 597,
        "no_speech_prob": 0.00016346295888070017,
        "seek": 178822,
        "start": 1810.38,
        "temperature": 1,
        "text": " So I guess the only real part of it is that it's unbelievable how many languages and",
        "tokens": [
          51472,
          407,
          286,
          2041,
          256,
          675,
          787,
          220,
          9342,
          644,
          295,
          309,
          307,
          43614,
          83,
          309,
          311,
          16605,
          577,
          867,
          8650,
          364,
          67,
          51768
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1821.74,
        "id": 598,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1816.86,
        "temperature": 0,
        "text": " Okay, so that is I wanted to mention and talk about can you can link the survey.",
        "tokens": [
          50392,
          1033,
          11,
          370,
          300,
          307,
          286,
          1415,
          281,
          2152,
          293,
          751,
          466,
          393,
          291,
          393,
          2113,
          264,
          8984,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1824.78,
        "id": 599,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1821.74,
        "temperature": 0,
        "text": " So I'll link this if someone in the chat is a moderator.",
        "tokens": [
          50636,
          407,
          286,
          603,
          2113,
          341,
          498,
          1580,
          294,
          264,
          5081,
          307,
          257,
          37778,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1825.5,
        "id": 600,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1824.78,
        "temperature": 0,
        "text": " Oh, thank you.",
        "tokens": [
          50788,
          876,
          11,
          1309,
          291,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1827.58,
        "id": 601,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1825.5,
        "temperature": 0,
        "text": " I think Alvaro in the chat link the survey.",
        "tokens": [
          50824,
          286,
          519,
          967,
          8517,
          78,
          294,
          264,
          5081,
          2113,
          264,
          8984,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1831.34,
        "id": 602,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1827.58,
        "temperature": 0,
        "text": " I will try and Matthew who helps me with this, of course, will try to remember to put a link",
        "tokens": [
          50928,
          286,
          486,
          853,
          293,
          7397,
          17418,
          567,
          3665,
          385,
          365,
          341,
          11,
          295,
          1164,
          11,
          486,
          853,
          281,
          1604,
          281,
          829,
          257,
          2113,
          51116
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1833.18,
        "id": 603,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1831.34,
        "temperature": 0,
        "text": " to the survey also in this video's description.",
        "tokens": [
          51116,
          281,
          264,
          8984,
          611,
          294,
          341,
          960,
          311,
          3855,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1836.06,
        "id": 604,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1835.74,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51336,
          1033,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2888891252420716,
        "compression_ratio": 1.691699604743083,
        "end": 1844.1399999999999,
        "id": 605,
        "no_speech_prob": 0.004980708006769419,
        "seek": 181630,
        "start": 1837.34,
        "temperature": 0,
        "text": " Thank you, everyone for listening and being supportive of the Processing Foundation.",
        "tokens": [
          51416,
          1044,
          291,
          11,
          1518,
          337,
          4764,
          293,
          885,
          14435,
          295,
          264,
          31093,
          278,
          10335,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1846.14,
        "id": 606,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1844.7800000000002,
        "temperature": 0,
        "text": " By the way, I have this weird idea.",
        "tokens": [
          50396,
          3146,
          264,
          636,
          11,
          286,
          362,
          341,
          3657,
          1558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1848.22,
        "id": 607,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1846.7,
        "temperature": 0,
        "text": " I shouldn't mention it.",
        "tokens": [
          50492,
          286,
          4659,
          380,
          2152,
          309,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1852.6200000000001,
        "id": 608,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1848.22,
        "temperature": 0,
        "text": " But the last week of not the last week of December, but the last week before the winter",
        "tokens": [
          50568,
          583,
          264,
          1036,
          1243,
          295,
          406,
          264,
          1036,
          1243,
          295,
          7687,
          11,
          457,
          264,
          1036,
          1243,
          949,
          264,
          6355,
          50788
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1859.3400000000001,
        "id": 609,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1852.6200000000001,
        "temperature": 0,
        "text": " holiday, I think, which ends December 23rd, I have a fairly free week that week, not the",
        "tokens": [
          50788,
          9960,
          11,
          286,
          519,
          11,
          597,
          5314,
          7687,
          6673,
          7800,
          11,
          286,
          362,
          257,
          6457,
          1737,
          1243,
          300,
          1243,
          11,
          406,
          264,
          51124
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1861.18,
        "id": 610,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1859.3400000000001,
        "temperature": 0,
        "text": " beginning of the week, but towards the end of the week.",
        "tokens": [
          51124,
          2863,
          295,
          264,
          1243,
          11,
          457,
          3030,
          264,
          917,
          295,
          264,
          1243,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1868.7,
        "id": 611,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1861.18,
        "temperature": 0,
        "text": " And I had this idea that that I see that people are getting banned in the chat, but I should",
        "tokens": [
          51216,
          400,
          286,
          632,
          341,
          1558,
          300,
          300,
          286,
          536,
          300,
          561,
          366,
          1242,
          19564,
          294,
          264,
          5081,
          11,
          457,
          286,
          820,
          51592
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1869.98,
        "id": 612,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1868.7,
        "temperature": 0,
        "text": " just like let that happen.",
        "tokens": [
          51592,
          445,
          411,
          718,
          300,
          1051,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.22057135274091105,
        "compression_ratio": 1.7898832684824904,
        "end": 1873.42,
        "id": 613,
        "no_speech_prob": 0.02404797077178955,
        "seek": 184414,
        "start": 1869.98,
        "temperature": 0,
        "text": " I'm sure it distracts me a little bit too much.",
        "tokens": [
          51656,
          286,
          478,
          988,
          309,
          9945,
          82,
          385,
          257,
          707,
          857,
          886,
          709,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1877.9,
        "id": 614,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1874.7,
        "temperature": 0,
        "text": " I had this idea of kind of doing an all day live stream.",
        "tokens": [
          50392,
          286,
          632,
          341,
          1558,
          295,
          733,
          295,
          884,
          364,
          439,
          786,
          1621,
          4309,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1881.98,
        "id": 615,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1877.9,
        "temperature": 0,
        "text": " And by all day, I don't mean I mean something like starting at 10 or 11 and finishing at",
        "tokens": [
          50552,
          400,
          538,
          439,
          786,
          11,
          286,
          500,
          380,
          914,
          286,
          914,
          746,
          411,
          2891,
          412,
          1266,
          420,
          2975,
          293,
          12693,
          412,
          50756
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1885.5,
        "id": 616,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1881.98,
        "temperature": 0,
        "text": " four or five, maybe with a little lunch break in the middle, maybe a guest would come in",
        "tokens": [
          50756,
          1451,
          420,
          1732,
          11,
          1310,
          365,
          257,
          707,
          6349,
          1821,
          294,
          264,
          2808,
          11,
          1310,
          257,
          8341,
          576,
          808,
          294,
          50932
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1886.22,
        "id": 617,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1885.5,
        "temperature": 0,
        "text": " and do something.",
        "tokens": [
          50932,
          293,
          360,
          746,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1887.5800000000002,
        "id": 618,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1886.22,
        "temperature": 0,
        "text": " I would go have some lunch.",
        "tokens": [
          50968,
          286,
          576,
          352,
          362,
          512,
          6349,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1892.7,
        "id": 619,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1887.5800000000002,
        "temperature": 0,
        "text": " I almost think of it as like a telethon, just like catch up on a lot of tutorials, have",
        "tokens": [
          51036,
          286,
          1920,
          519,
          295,
          309,
          382,
          411,
          257,
          15284,
          3293,
          266,
          11,
          445,
          411,
          3745,
          493,
          322,
          257,
          688,
          295,
          17616,
          11,
          362,
          51292
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1893.18,
        "id": 620,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1892.7,
        "temperature": 0,
        "text": " some fun.",
        "tokens": [
          51292,
          512,
          1019,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1899.18,
        "id": 621,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1893.18,
        "temperature": 0,
        "text": " It's sort of like end of the year celebration of creative code stuff.",
        "tokens": [
          51316,
          467,
          311,
          1333,
          295,
          411,
          917,
          295,
          264,
          1064,
          14184,
          295,
          5880,
          3089,
          1507,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.22032915665799338,
        "compression_ratio": 1.7605177993527508,
        "end": 1902.46,
        "id": 622,
        "no_speech_prob": 0.002934804419055581,
        "seek": 187414,
        "start": 1899.18,
        "temperature": 0,
        "text": " And I thought it could be kind of like a telethon to raise money for the Processing Foundation.",
        "tokens": [
          51616,
          400,
          286,
          1194,
          309,
          727,
          312,
          733,
          295,
          411,
          257,
          15284,
          3293,
          266,
          281,
          5300,
          1460,
          337,
          264,
          31093,
          278,
          10335,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1905.3400000000001,
        "id": 623,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1902.46,
        "temperature": 0,
        "text": " Or maybe there's another cause you should consider raising money for.",
        "tokens": [
          50364,
          1610,
          1310,
          456,
          311,
          1071,
          3082,
          291,
          820,
          1949,
          11225,
          1460,
          337,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1908.14,
        "id": 624,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1905.9,
        "temperature": 0,
        "text": " So anyway, I'm thinking about that.",
        "tokens": [
          50536,
          407,
          4033,
          11,
          286,
          478,
          1953,
          466,
          300,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1909.9,
        "id": 625,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1908.14,
        "temperature": 0,
        "text": " You could encourage or discourage me.",
        "tokens": [
          50648,
          509,
          727,
          5373,
          420,
          21497,
          609,
          385,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1910.94,
        "id": 626,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1909.9,
        "temperature": 0,
        "text": " I'm sure you all would.",
        "tokens": [
          50736,
          286,
          478,
          988,
          291,
          439,
          576,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1914.14,
        "id": 627,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1910.94,
        "temperature": 0,
        "text": " But if that happens, it would be on the 22nd or the 23rd.",
        "tokens": [
          50788,
          583,
          498,
          300,
          2314,
          11,
          309,
          576,
          312,
          322,
          264,
          5853,
          273,
          420,
          264,
          6673,
          7800,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1915.26,
        "id": 628,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1914.14,
        "temperature": 0,
        "text": " So keep that in mind.",
        "tokens": [
          50948,
          407,
          1066,
          300,
          294,
          1575,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1921.82,
        "id": 629,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1916.7,
        "temperature": 0,
        "text": " I would love to if you're in the Slack channel, if you're a patron in the Slack channel, you",
        "tokens": [
          51076,
          286,
          576,
          959,
          281,
          498,
          291,
          434,
          294,
          264,
          37211,
          2269,
          11,
          498,
          291,
          434,
          257,
          21843,
          294,
          264,
          37211,
          2269,
          11,
          291,
          51332
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1923.9,
        "id": 630,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1921.82,
        "temperature": 0,
        "text": " can tell me your ideas about this there.",
        "tokens": [
          51332,
          393,
          980,
          385,
          428,
          3487,
          466,
          341,
          456,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1924.78,
        "id": 631,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1924.46,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51464,
          2264,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1927.1000000000001,
        "id": 632,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1926.46,
        "temperature": 0,
        "text": " OK, cool.",
        "tokens": [
          51564,
          2264,
          11,
          1627,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1929.18,
        "id": 633,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1928.3,
        "temperature": 0,
        "text": " What's Nerdfighters?",
        "tokens": [
          51656,
          708,
          311,
          38367,
          14919,
          433,
          30,
          51700
        ]
      },
      {
        "avg_logprob": -0.19129209933073624,
        "compression_ratio": 1.6529850746268657,
        "end": 1930.06,
        "id": 634,
        "no_speech_prob": 0.07920365035533905,
        "seek": 190246,
        "start": 1929.18,
        "temperature": 0,
        "text": " I don't know what that is.",
        "tokens": [
          51700,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1936.7,
        "id": 635,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1930.06,
        "temperature": 0,
        "text": " But I'm definitely looking to do more collaborations and things with other folks on YouTube, especially",
        "tokens": [
          50364,
          583,
          286,
          478,
          2138,
          1237,
          281,
          360,
          544,
          36908,
          293,
          721,
          365,
          661,
          4024,
          322,
          3088,
          11,
          2318,
          50696
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1941.5,
        "id": 636,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1936.7,
        "temperature": 0,
        "text": " if they don't look like me or have different ideas and come from a different background.",
        "tokens": [
          50696,
          498,
          436,
          500,
          380,
          574,
          411,
          385,
          420,
          362,
          819,
          3487,
          293,
          808,
          490,
          257,
          819,
          3678,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1946.86,
        "id": 637,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1942.7,
        "temperature": 0,
        "text": " OK, so let's get back to that AFIN111 thing.",
        "tokens": [
          50996,
          2264,
          11,
          370,
          718,
          311,
          483,
          646,
          281,
          300,
          20389,
          1464,
          5348,
          16,
          551,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1949.02,
        "id": 638,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1946.86,
        "temperature": 0,
        "text": " I've got to do something programming-wise today.",
        "tokens": [
          51204,
          286,
          600,
          658,
          281,
          360,
          746,
          9410,
          12,
          3711,
          965,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1952.22,
        "id": 639,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1949.02,
        "temperature": 0,
        "text": " I want to just apologize that things have been a little light this month.",
        "tokens": [
          51312,
          286,
          528,
          281,
          445,
          12328,
          300,
          721,
          362,
          668,
          257,
          707,
          1442,
          341,
          1618,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1952.94,
        "id": 640,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1952.22,
        "temperature": 0,
        "text": " I missed a week.",
        "tokens": [
          51472,
          286,
          6721,
          257,
          1243,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1955.1799999999998,
        "id": 641,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1954.06,
        "temperature": 0,
        "text": " I missed two weeks, I think.",
        "tokens": [
          51564,
          286,
          6721,
          732,
          3259,
          11,
          286,
          519,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1958.46,
        "id": 642,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1956.62,
        "temperature": 0,
        "text": " When I didn't miss a week, I had shorter streams.",
        "tokens": [
          51692,
          1133,
          286,
          994,
          380,
          1713,
          257,
          1243,
          11,
          286,
          632,
          11639,
          15842,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.19276549464972445,
        "compression_ratio": 1.6046511627906976,
        "end": 1959.4199999999998,
        "id": 643,
        "no_speech_prob": 0.00267297076061368,
        "seek": 193006,
        "start": 1958.46,
        "temperature": 0,
        "text": " And today is no exception.",
        "tokens": [
          51784,
          400,
          965,
          307,
          572,
          11183,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1965.5,
        "id": 644,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1959.42,
        "temperature": 0,
        "text": " I hope that December and January will bring back more of a regular routine of content.",
        "tokens": [
          50364,
          286,
          1454,
          300,
          7687,
          293,
          7061,
          486,
          1565,
          646,
          544,
          295,
          257,
          3890,
          9927,
          295,
          2701,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1968.22,
        "id": 645,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1965.5,
        "temperature": 0,
        "text": " And I have more ideas about that in the future.",
        "tokens": [
          50668,
          400,
          286,
          362,
          544,
          3487,
          466,
          300,
          294,
          264,
          2027,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1968.46,
        "id": 646,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1968.22,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50804,
          2264,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1973.8200000000002,
        "id": 647,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1971.74,
        "temperature": 0,
        "text": " OK, so let's see.",
        "tokens": [
          50980,
          2264,
          11,
          370,
          718,
          311,
          536,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1978.38,
        "id": 648,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1975.3400000000001,
        "temperature": 0,
        "text": " I'm going to cycle the cameras again since I babbled on for way too long.",
        "tokens": [
          51160,
          286,
          478,
          516,
          281,
          6586,
          264,
          8622,
          797,
          1670,
          286,
          7564,
          18320,
          322,
          337,
          636,
          886,
          938,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1985.5800000000002,
        "id": 649,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1982.94,
        "temperature": 0,
        "text": " And it's so quiet today here.",
        "tokens": [
          51540,
          400,
          309,
          311,
          370,
          5677,
          965,
          510,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1987.9,
        "id": 650,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1987.3400000000001,
        "temperature": 0,
        "text": " Eerie.",
        "tokens": [
          51760,
          462,
          17487,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.18473975602970566,
        "compression_ratio": 1.4491978609625669,
        "end": 1988.14,
        "id": 651,
        "no_speech_prob": 0.0000760243710828945,
        "seek": 195942,
        "start": 1987.9,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51788,
          2264,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 1991.9,
        "id": 652,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 1988.94,
        "temperature": 0,
        "text": " OK, let's do AFIN111.",
        "tokens": [
          50404,
          2264,
          11,
          718,
          311,
          360,
          20389,
          1464,
          5348,
          16,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 1999.9,
        "id": 653,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 1999.42,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50928,
          6962,
          322,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 2000.7,
        "id": 654,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 1999.9,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          50952,
          4919,
          11,
          2201,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 2002.46,
        "id": 655,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 2000.7,
        "temperature": 0,
        "text": " I just want to like try to, ah!",
        "tokens": [
          50992,
          286,
          445,
          528,
          281,
          411,
          853,
          281,
          11,
          3716,
          0,
          51080
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 2009.18,
        "id": 656,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 2003.18,
        "temperature": 0,
        "text": " I'm like so overly, neurotically, anal retentive in the worst way.",
        "tokens": [
          51116,
          286,
          478,
          411,
          370,
          24324,
          11,
          43286,
          984,
          11,
          2624,
          1533,
          317,
          488,
          294,
          264,
          5855,
          636,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 2012.3000000000002,
        "id": 657,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 2011.42,
        "temperature": 0,
        "text": " OK, now we're good.",
        "tokens": [
          51528,
          2264,
          11,
          586,
          321,
          434,
          665,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.29073868268801845,
        "compression_ratio": 1.3214285714285714,
        "end": 2017.5800000000002,
        "id": 658,
        "no_speech_prob": 0.0001740038424031809,
        "seek": 198814,
        "start": 2015.42,
        "temperature": 0,
        "text": " I wish this had like a little bit of a prettier image.",
        "tokens": [
          51728,
          286,
          3172,
          341,
          632,
          411,
          257,
          707,
          857,
          295,
          257,
          36825,
          3256,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2018.86,
        "id": 659,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2017.58,
        "temperature": 0,
        "text": " But what can you help?",
        "tokens": [
          50364,
          583,
          437,
          393,
          291,
          854,
          30,
          50428
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2024.3,
        "id": 660,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2018.86,
        "temperature": 0,
        "text": " What if I do sentiment analysis images?",
        "tokens": [
          50428,
          708,
          498,
          286,
          360,
          16149,
          5215,
          5267,
          30,
          50700
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2028.54,
        "id": 661,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2027.6599999999999,
        "temperature": 0,
        "text": " This works for me.",
        "tokens": [
          50868,
          639,
          1985,
          337,
          385,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2031.82,
        "id": 662,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2029.6599999999999,
        "temperature": 0,
        "text": " OK, I want to do a whole.",
        "tokens": [
          50968,
          2264,
          11,
          286,
          528,
          281,
          360,
          257,
          1379,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2035.8999999999999,
        "id": 663,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2031.82,
        "temperature": 0,
        "text": " I also want to do like a whole live stream only about emojis, which I find to be sort of like",
        "tokens": [
          51076,
          286,
          611,
          528,
          281,
          360,
          411,
          257,
          1379,
          1621,
          4309,
          787,
          466,
          19611,
          40371,
          11,
          597,
          286,
          915,
          281,
          312,
          1333,
          295,
          411,
          51280
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2037.02,
        "id": 664,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2035.8999999999999,
        "temperature": 0,
        "text": " fascinating.",
        "tokens": [
          51280,
          10343,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2038.3799999999999,
        "id": 665,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2037.02,
        "temperature": 0,
        "text": " OK, where are the barking dogs?",
        "tokens": [
          51336,
          2264,
          11,
          689,
          366,
          264,
          32995,
          7197,
          30,
          51404
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2039.1799999999998,
        "id": 666,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2038.3799999999999,
        "temperature": 0,
        "text": " Not today, I guess.",
        "tokens": [
          51404,
          1726,
          965,
          11,
          286,
          2041,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.20830707964689835,
        "compression_ratio": 1.4477611940298507,
        "end": 2047.26,
        "id": 667,
        "no_speech_prob": 0.000013845975445292424,
        "seek": 201758,
        "start": 2045.98,
        "temperature": 0,
        "text": " Where's my bumper music?",
        "tokens": [
          51784,
          2305,
          311,
          452,
          23992,
          1318,
          30,
          51848
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2053.9,
        "id": 668,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2048.14,
        "temperature": 0,
        "text": " Can you hear that?",
        "tokens": [
          50392,
          1664,
          291,
          1568,
          300,
          30,
          50680
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2054.54,
        "id": 669,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2053.9,
        "temperature": 0,
        "text": " Is it loud?",
        "tokens": [
          50680,
          1119,
          309,
          6588,
          30,
          50712
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2055.1,
        "id": 670,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2054.54,
        "temperature": 0,
        "text": " Is that loud?",
        "tokens": [
          50712,
          1119,
          300,
          6588,
          30,
          50740
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2057.02,
        "id": 671,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2055.9,
        "temperature": 0,
        "text": " It's so quiet for me.",
        "tokens": [
          50780,
          467,
          311,
          370,
          5677,
          337,
          385,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2057.2599999999998,
        "id": 672,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2057.02,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50836,
          2264,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2067.66,
        "id": 673,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2065.66,
        "temperature": 0,
        "text": " OK, sorry, I'm paying too much attention to the chat.",
        "tokens": [
          51268,
          2264,
          11,
          2597,
          11,
          286,
          478,
          6229,
          886,
          709,
          3202,
          281,
          264,
          5081,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2069.5,
        "id": 674,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2067.66,
        "temperature": 0,
        "text": " Wow, there are really 160 people watching?",
        "tokens": [
          51368,
          3153,
          11,
          456,
          366,
          534,
          21243,
          561,
          1976,
          30,
          51460
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2071.58,
        "id": 675,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2070.2999999999997,
        "temperature": 0,
        "text": " That is insane.",
        "tokens": [
          51500,
          663,
          307,
          10838,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2072.22,
        "id": 676,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2071.58,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51564,
          876,
          452,
          8387,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.24583409472209652,
        "compression_ratio": 1.360248447204969,
        "end": 2075.2599999999998,
        "id": 677,
        "no_speech_prob": 0.000045397537178359926,
        "seek": 204758,
        "start": 2073.2599999999998,
        "temperature": 0,
        "text": " OK, OK, here we go.",
        "tokens": [
          51648,
          2264,
          11,
          2264,
          11,
          510,
          321,
          352,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2081.34,
        "id": 678,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2078.14,
        "temperature": 0,
        "text": " Let me try that again.",
        "tokens": [
          50392,
          961,
          385,
          853,
          300,
          797,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2086.7,
        "id": 679,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2084.54,
        "temperature": 0,
        "text": " Hello, welcome to a coding challenge again.",
        "tokens": [
          50712,
          2425,
          11,
          2928,
          281,
          257,
          17720,
          3430,
          797,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2092.94,
        "id": 680,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2086.7,
        "temperature": 0,
        "text": " In this coding challenge, I am going to build from scratch a web application that does sentiment",
        "tokens": [
          50820,
          682,
          341,
          17720,
          3430,
          11,
          286,
          669,
          516,
          281,
          1322,
          490,
          8459,
          257,
          3670,
          3861,
          300,
          775,
          16149,
          51132
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2093.5,
        "id": 681,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2092.94,
        "temperature": 0,
        "text": " analysis.",
        "tokens": [
          51132,
          5215,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2095.98,
        "id": 682,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2094.7799999999997,
        "temperature": 0,
        "text": " What is sentiment analysis?",
        "tokens": [
          51224,
          708,
          307,
          16149,
          5215,
          30,
          51284
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2099.2599999999998,
        "id": 683,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2095.98,
        "temperature": 0,
        "text": " So first of all, I want to mention that the actual, oops, I'm in the wrong page.",
        "tokens": [
          51284,
          407,
          700,
          295,
          439,
          11,
          286,
          528,
          281,
          2152,
          300,
          264,
          3539,
          11,
          34166,
          11,
          286,
          478,
          294,
          264,
          2085,
          3028,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.23034951121536726,
        "compression_ratio": 1.6591928251121075,
        "end": 2107.02,
        "id": 684,
        "no_speech_prob": 0.0023231252562254667,
        "seek": 207758,
        "start": 2099.2599999999998,
        "temperature": 0,
        "text": " The particular technique I'm going to use is a score-based system using a list of words",
        "tokens": [
          51448,
          440,
          1729,
          6532,
          286,
          478,
          516,
          281,
          764,
          307,
          257,
          6175,
          12,
          6032,
          1185,
          1228,
          257,
          1329,
          295,
          2283,
          51836
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2108.7,
        "id": 685,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2107.02,
        "temperature": 0,
        "text": " known as the AFIN111.",
        "tokens": [
          50364,
          2570,
          382,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2110.94,
        "id": 686,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2108.7,
        "temperature": 0,
        "text": " So there are a lot of ways to do sentiment analysis.",
        "tokens": [
          50448,
          407,
          456,
          366,
          257,
          688,
          295,
          2098,
          281,
          360,
          16149,
          5215,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2115.5,
        "id": 687,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2110.94,
        "temperature": 0,
        "text": " What I mean by sentiment analysis is here's some text, here's some information.",
        "tokens": [
          50560,
          708,
          286,
          914,
          538,
          16149,
          5215,
          307,
          510,
          311,
          512,
          2487,
          11,
          510,
          311,
          512,
          1589,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2117.2599999999998,
        "id": 688,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2115.5,
        "temperature": 0,
        "text": " I want to determine, is it positive?",
        "tokens": [
          50788,
          286,
          528,
          281,
          6997,
          11,
          307,
          309,
          3353,
          30,
          50876
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2118.06,
        "id": 689,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2117.2599999999998,
        "temperature": 0,
        "text": " Is it negative?",
        "tokens": [
          50876,
          1119,
          309,
          3671,
          30,
          50916
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2120.14,
        "id": 690,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2118.7,
        "temperature": 0,
        "text": " And I want to assign it a score.",
        "tokens": [
          50948,
          400,
          286,
          528,
          281,
          6269,
          309,
          257,
          6175,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2122.3,
        "id": 691,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2120.14,
        "temperature": 0,
        "text": " Is it a high number, meaning very positive?",
        "tokens": [
          51020,
          1119,
          309,
          257,
          1090,
          1230,
          11,
          3620,
          588,
          3353,
          30,
          51128
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2124.14,
        "id": 692,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2122.3,
        "temperature": 0,
        "text": " Is it 0, meaning completely neutral?",
        "tokens": [
          51128,
          1119,
          309,
          1958,
          11,
          3620,
          2584,
          10598,
          30,
          51220
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2127.2599999999998,
        "id": 693,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2124.14,
        "temperature": 0,
        "text": " Is it a low negative number, meaning very negative?",
        "tokens": [
          51220,
          1119,
          309,
          257,
          2295,
          3671,
          1230,
          11,
          3620,
          588,
          3671,
          30,
          51376
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2128.54,
        "id": 694,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2127.2599999999998,
        "temperature": 0,
        "text": " And there are different ways you can do this.",
        "tokens": [
          51376,
          400,
          456,
          366,
          819,
          2098,
          291,
          393,
          360,
          341,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.159592122742624,
        "compression_ratio": 1.8482490272373542,
        "end": 2132.86,
        "id": 695,
        "no_speech_prob": 0.000356965116225183,
        "seek": 210702,
        "start": 2128.54,
        "temperature": 0,
        "text": " There are machine learning systems that can be trained.",
        "tokens": [
          51440,
          821,
          366,
          3479,
          2539,
          3652,
          300,
          393,
          312,
          8895,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2137.98,
        "id": 696,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2132.86,
        "temperature": 0,
        "text": " Here's a lot of very positive essays, and here's a lot of really negative essays.",
        "tokens": [
          50364,
          1692,
          311,
          257,
          688,
          295,
          588,
          3353,
          35123,
          11,
          293,
          510,
          311,
          257,
          688,
          295,
          534,
          3671,
          35123,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2138.6200000000003,
        "id": 697,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2137.98,
        "temperature": 0,
        "text": " Learn about them.",
        "tokens": [
          50620,
          17216,
          466,
          552,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2139.34,
        "id": 698,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2138.6200000000003,
        "temperature": 0,
        "text": " Here's an essay.",
        "tokens": [
          50652,
          1692,
          311,
          364,
          16238,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2140.86,
        "id": 699,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2139.34,
        "temperature": 0,
        "text": " Please give it a score.",
        "tokens": [
          50688,
          2555,
          976,
          309,
          257,
          6175,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2143.1800000000003,
        "id": 700,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2140.86,
        "temperature": 0,
        "text": " There's neural networks can do this.",
        "tokens": [
          50764,
          821,
          311,
          18161,
          9590,
          393,
          360,
          341,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2148.1400000000003,
        "id": 701,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2143.1800000000003,
        "temperature": 0,
        "text": " There's a technique known as Bayesian classification that can be trained to look,",
        "tokens": [
          50880,
          821,
          311,
          257,
          6532,
          2570,
          382,
          7840,
          42434,
          21538,
          300,
          393,
          312,
          8895,
          281,
          574,
          11,
          51128
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2150.6200000000003,
        "id": 702,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2148.1400000000003,
        "temperature": 0,
        "text": " also be trained based on positive and negative text.",
        "tokens": [
          51128,
          611,
          312,
          8895,
          2361,
          322,
          3353,
          293,
          3671,
          2487,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2154.38,
        "id": 703,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2151.26,
        "temperature": 0,
        "text": " And there's, I'm sure, a list many other techniques here.",
        "tokens": [
          51284,
          400,
          456,
          311,
          11,
          286,
          478,
          988,
          11,
          257,
          1329,
          867,
          661,
          7512,
          510,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.1798788758574939,
        "compression_ratio": 1.7586206896551724,
        "end": 2158.46,
        "id": 704,
        "no_speech_prob": 0.16234935820102692,
        "seek": 213286,
        "start": 2154.38,
        "temperature": 0,
        "text": " But the technique that I want to look at in this particular video is quite a simple one.",
        "tokens": [
          51440,
          583,
          264,
          6532,
          300,
          286,
          528,
          281,
          574,
          412,
          294,
          341,
          1729,
          960,
          307,
          1596,
          257,
          2199,
          472,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.19871259203144148,
        "compression_ratio": 1.4592274678111588,
        "end": 2164.38,
        "id": 705,
        "no_speech_prob": 0.008187699131667614,
        "seek": 215846,
        "start": 2158.54,
        "temperature": 0,
        "text": " And it involves a pre-made list of words that are assigned a valence,",
        "tokens": [
          50368,
          400,
          309,
          11626,
          257,
          659,
          12,
          10341,
          1329,
          295,
          2283,
          300,
          366,
          13279,
          257,
          1323,
          655,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.19871259203144148,
        "compression_ratio": 1.4592274678111588,
        "end": 2166.62,
        "id": 706,
        "no_speech_prob": 0.008187699131667614,
        "seek": 215846,
        "start": 2164.38,
        "temperature": 0,
        "text": " a positivity or negativity score.",
        "tokens": [
          50660,
          257,
          35198,
          420,
          39297,
          6175,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.19871259203144148,
        "compression_ratio": 1.4592274678111588,
        "end": 2170.2200000000003,
        "id": 707,
        "no_speech_prob": 0.008187699131667614,
        "seek": 215846,
        "start": 2166.62,
        "temperature": 0,
        "text": " And so this list is a well-known list, the AFIN111.",
        "tokens": [
          50772,
          400,
          370,
          341,
          1329,
          307,
          257,
          731,
          12,
          6861,
          1329,
          11,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.19871259203144148,
        "compression_ratio": 1.4592274678111588,
        "end": 2176.54,
        "id": 708,
        "no_speech_prob": 0.008187699131667614,
        "seek": 215846,
        "start": 2171.18,
        "temperature": 0,
        "text": " It is the newest version with 2,477 words and phrases.",
        "tokens": [
          51000,
          467,
          307,
          264,
          17569,
          3037,
          365,
          568,
          11,
          14060,
          22,
          2283,
          293,
          20312,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.19871259203144148,
        "compression_ratio": 1.4592274678111588,
        "end": 2181.1,
        "id": 709,
        "no_speech_prob": 0.008187699131667614,
        "seek": 215846,
        "start": 2176.54,
        "temperature": 0,
        "text": " And these were labeled by Finn Arup Nielsen in 2009, 2011.",
        "tokens": [
          51268,
          400,
          613,
          645,
          21335,
          538,
          21066,
          316,
          11976,
          426,
          1187,
          6748,
          294,
          11453,
          11,
          10154,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.19871259203144148,
        "compression_ratio": 1.4592274678111588,
        "end": 2186.14,
        "id": 710,
        "no_speech_prob": 0.008187699131667614,
        "seek": 215846,
        "start": 2181.1,
        "temperature": 0,
        "text": " So the way this works is you take a body of text, you read through it,",
        "tokens": [
          51496,
          407,
          264,
          636,
          341,
          1985,
          307,
          291,
          747,
          257,
          1772,
          295,
          2487,
          11,
          291,
          1401,
          807,
          309,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2191.3399999999997,
        "id": 711,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2186.14,
        "temperature": 0,
        "text": " you look for any time a word that appears on the AFIN111 list is,",
        "tokens": [
          50364,
          291,
          574,
          337,
          604,
          565,
          257,
          1349,
          300,
          7038,
          322,
          264,
          20389,
          1464,
          5348,
          16,
          1329,
          307,
          11,
          50624
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2194.14,
        "id": 712,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2192.22,
        "temperature": 0,
        "text": " you look for any words that appear on that list,",
        "tokens": [
          50668,
          291,
          574,
          337,
          604,
          2283,
          300,
          4204,
          322,
          300,
          1329,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2196.7799999999997,
        "id": 713,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2194.14,
        "temperature": 0,
        "text": " you look up its score, and you add all the scores together.",
        "tokens": [
          50764,
          291,
          574,
          493,
          1080,
          6175,
          11,
          293,
          291,
          909,
          439,
          264,
          13444,
          1214,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2203.58,
        "id": 714,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2200.8599999999997,
        "temperature": 0,
        "text": " I don't know why I felt like this video is going fine,",
        "tokens": [
          51100,
          286,
          500,
          380,
          458,
          983,
          286,
          2762,
          411,
          341,
          960,
          307,
          516,
          2489,
          11,
          51236
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2205.42,
        "id": 715,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2203.58,
        "temperature": 0,
        "text": " but I just realized I don't have a marker.",
        "tokens": [
          51236,
          457,
          286,
          445,
          5334,
          286,
          500,
          380,
          362,
          257,
          15247,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2208.7,
        "id": 716,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2207.3399999999997,
        "temperature": 0,
        "text": " And I was going to, I was like, kept thinking,",
        "tokens": [
          51424,
          400,
          286,
          390,
          516,
          281,
          11,
          286,
          390,
          411,
          11,
          4305,
          1953,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2210.54,
        "id": 717,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2208.7,
        "temperature": 0,
        "text": " oh, I should just like do this on the whiteboard.",
        "tokens": [
          51492,
          1954,
          11,
          286,
          820,
          445,
          411,
          360,
          341,
          322,
          264,
          2418,
          3787,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.2154534657796224,
        "compression_ratio": 1.8149779735682818,
        "end": 2213.98,
        "id": 718,
        "no_speech_prob": 0.0031236130744218826,
        "seek": 218614,
        "start": 2211.18,
        "temperature": 0,
        "text": " And then I realized I don't have a marker.",
        "tokens": [
          51616,
          400,
          550,
          286,
          5334,
          286,
          500,
          380,
          362,
          257,
          15247,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2217.1,
        "id": 719,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2214.62,
        "temperature": 0,
        "text": " And then I lost my train of thought.",
        "tokens": [
          50396,
          400,
          550,
          286,
          2731,
          452,
          3847,
          295,
          1194,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2219.34,
        "id": 720,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2217.66,
        "temperature": 0,
        "text": " And Denmark.",
        "tokens": [
          50548,
          400,
          28065,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2220.14,
        "id": 721,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2219.34,
        "temperature": 0,
        "text": " Oh, OK.",
        "tokens": [
          50632,
          876,
          11,
          2264,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2221.66,
        "id": 722,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2220.14,
        "temperature": 0,
        "text": " So I'm going to do something a little weird.",
        "tokens": [
          50672,
          407,
          286,
          478,
          516,
          281,
          360,
          746,
          257,
          707,
          3657,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2223.34,
        "id": 723,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2221.66,
        "temperature": 0,
        "text": " Matias seems to be in the chat.",
        "tokens": [
          50748,
          6789,
          4609,
          2544,
          281,
          312,
          294,
          264,
          5081,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2226.78,
        "id": 724,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2223.34,
        "temperature": 0,
        "text": " I'm going to re-explain the AFIN111 thing.",
        "tokens": [
          50832,
          286,
          478,
          516,
          281,
          319,
          12,
          23040,
          491,
          264,
          20389,
          1464,
          5348,
          16,
          551,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2229.9,
        "id": 725,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2227.82,
        "temperature": 0,
        "text": " But I'm going to do it over by the whiteboard.",
        "tokens": [
          51056,
          583,
          286,
          478,
          516,
          281,
          360,
          309,
          670,
          538,
          264,
          2418,
          3787,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2233.5,
        "id": 726,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2230.62,
        "temperature": 0,
        "text": " And so you just have to, I think you can just cut out that quick explanation",
        "tokens": [
          51196,
          400,
          370,
          291,
          445,
          362,
          281,
          11,
          286,
          519,
          291,
          393,
          445,
          1723,
          484,
          300,
          1702,
          10835,
          51340
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2238.22,
        "id": 727,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2234.7,
        "temperature": 0,
        "text": " and splice in this new, better explanation with the whiteboard.",
        "tokens": [
          51400,
          293,
          4732,
          573,
          294,
          341,
          777,
          11,
          1101,
          10835,
          365,
          264,
          2418,
          3787,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2239.02,
        "id": 728,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2238.22,
        "temperature": 0,
        "text": " Then I'll keep going.",
        "tokens": [
          51576,
          1396,
          286,
          603,
          1066,
          516,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2240.4,
        "id": 729,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2239.9,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51660,
          4919,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.22870767620247853,
        "compression_ratio": 1.654275092936803,
        "end": 2242.46,
        "id": 730,
        "no_speech_prob": 0.001116005820222199,
        "seek": 221398,
        "start": 2240.86,
        "temperature": 0,
        "text": " If it doesn't work, whatever, we'll figure it out.",
        "tokens": [
          51708,
          759,
          309,
          1177,
          380,
          589,
          11,
          2035,
          11,
          321,
          603,
          2573,
          309,
          484,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2249.5,
        "id": 731,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2244.78,
        "temperature": 0,
        "text": " Uh, so what, what is the AFIN111 technique?",
        "tokens": [
          50404,
          4019,
          11,
          370,
          437,
          11,
          437,
          307,
          264,
          20389,
          1464,
          5348,
          16,
          6532,
          30,
          50640
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2254.78,
        "id": 732,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2249.5,
        "temperature": 0,
        "text": " The AFIN111 technique involves a pre-assigned list of words.",
        "tokens": [
          50640,
          440,
          20389,
          1464,
          5348,
          16,
          6532,
          11626,
          257,
          659,
          12,
          640,
          16690,
          1329,
          295,
          2283,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2260.22,
        "id": 733,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2255.58,
        "temperature": 0,
        "text": " So if I were to say like happy, this has a score of five.",
        "tokens": [
          50944,
          407,
          498,
          286,
          645,
          281,
          584,
          411,
          2055,
          11,
          341,
          575,
          257,
          6175,
          295,
          1732,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2264.54,
        "id": 734,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2260.22,
        "temperature": 0,
        "text": " Each, each word gets a positive or negative valence score.",
        "tokens": [
          51176,
          6947,
          11,
          1184,
          1349,
          2170,
          257,
          3353,
          420,
          3671,
          1323,
          655,
          6175,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2268.06,
        "id": 735,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2265.18,
        "temperature": 0,
        "text": " Five being very happy, very positive.",
        "tokens": [
          51424,
          9436,
          885,
          588,
          2055,
          11,
          588,
          3353,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2271.58,
        "id": 736,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2268.7,
        "temperature": 0,
        "text": " Sad, very negative.",
        "tokens": [
          51600,
          12269,
          11,
          588,
          3671,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.24063718583848742,
        "compression_ratio": 1.5561497326203209,
        "end": 2273.02,
        "id": 737,
        "no_speech_prob": 0.000005682407845597481,
        "seek": 224398,
        "start": 2272.22,
        "temperature": 0,
        "text": " No rainbow.",
        "tokens": [
          51776,
          883,
          18526,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2275.34,
        "id": 738,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2274.14,
        "temperature": 0,
        "text": " Also very positive.",
        "tokens": [
          50372,
          2743,
          588,
          3353,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2276.54,
        "id": 739,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2275.9,
        "temperature": 0,
        "text": " Five.",
        "tokens": [
          50460,
          9436,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2279.02,
        "id": 740,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2276.54,
        "temperature": 0,
        "text": " I don't want to give rainbow the score of four and happy five.",
        "tokens": [
          50492,
          286,
          500,
          380,
          528,
          281,
          976,
          18526,
          264,
          6175,
          295,
          1451,
          293,
          2055,
          1732,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2283.42,
        "id": 741,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2279.02,
        "temperature": 0,
        "text": " That would be, and I could think of what's like, you know, turtle.",
        "tokens": [
          50616,
          663,
          576,
          312,
          11,
          293,
          286,
          727,
          519,
          295,
          437,
          311,
          411,
          11,
          291,
          458,
          11,
          22866,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2285.42,
        "id": 742,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2283.42,
        "temperature": 0,
        "text": " I mean, turtles are like a little bit sad.",
        "tokens": [
          50836,
          286,
          914,
          11,
          32422,
          366,
          411,
          257,
          707,
          857,
          4227,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2287.34,
        "id": 743,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2285.42,
        "temperature": 0,
        "text": " I don't know, no turtles, turtles are happy.",
        "tokens": [
          50936,
          286,
          500,
          380,
          458,
          11,
          572,
          32422,
          11,
          32422,
          366,
          2055,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2288.14,
        "id": 744,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2287.34,
        "temperature": 0,
        "text": " Turtle too, right?",
        "tokens": [
          51032,
          48406,
          886,
          11,
          558,
          30,
          51072
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2289.34,
        "id": 745,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2288.14,
        "temperature": 0,
        "text": " OK, so you get the idea.",
        "tokens": [
          51072,
          2264,
          11,
          370,
          291,
          483,
          264,
          1558,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2293.34,
        "id": 746,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2289.34,
        "temperature": 0,
        "text": " I'm not going to try to make, clearly I'm not qualified to make up a list of words and scores.",
        "tokens": [
          51132,
          286,
          478,
          406,
          516,
          281,
          853,
          281,
          652,
          11,
          4448,
          286,
          478,
          406,
          15904,
          281,
          652,
          493,
          257,
          1329,
          295,
          2283,
          293,
          13444,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2297.18,
        "id": 747,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2293.34,
        "temperature": 0,
        "text": " So if you have this pre-made list of words, and these could be in any language.",
        "tokens": [
          51332,
          407,
          498,
          291,
          362,
          341,
          659,
          12,
          10341,
          1329,
          295,
          2283,
          11,
          293,
          613,
          727,
          312,
          294,
          604,
          2856,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.23018982831169577,
        "compression_ratio": 1.7568493150684932,
        "end": 2299.5,
        "id": 748,
        "no_speech_prob": 0.00006302675319602713,
        "seek": 227398,
        "start": 2297.18,
        "temperature": 0,
        "text": " This is a particular list in the English language.",
        "tokens": [
          51524,
          639,
          307,
          257,
          1729,
          1329,
          294,
          264,
          3669,
          2856,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2304.86,
        "id": 749,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2300.46,
        "temperature": 0,
        "text": " And if you have thousands and thousands of them, then if you have a particular text",
        "tokens": [
          50412,
          400,
          498,
          291,
          362,
          5383,
          293,
          5383,
          295,
          552,
          11,
          550,
          498,
          291,
          362,
          257,
          1729,
          2487,
          50632
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2311.18,
        "id": 750,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2305.98,
        "temperature": 0,
        "text": " with a lot of words in it, you could write a computer program to just look at each word",
        "tokens": [
          50688,
          365,
          257,
          688,
          295,
          2283,
          294,
          309,
          11,
          291,
          727,
          2464,
          257,
          3820,
          1461,
          281,
          445,
          574,
          412,
          1184,
          1349,
          50948
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2313.18,
        "id": 751,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2311.18,
        "temperature": 0,
        "text": " and ask, is it in the list?",
        "tokens": [
          50948,
          293,
          1029,
          11,
          307,
          309,
          294,
          264,
          1329,
          30,
          51048
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2316.78,
        "id": 752,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2313.18,
        "temperature": 0,
        "text": " If it's in the list, look up its score and add it to a running total.",
        "tokens": [
          51048,
          759,
          309,
          311,
          294,
          264,
          1329,
          11,
          574,
          493,
          1080,
          6175,
          293,
          909,
          309,
          281,
          257,
          2614,
          3217,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2320.22,
        "id": 753,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2316.78,
        "temperature": 0,
        "text": " And at the end, you're going to get some value, like you might get 27.",
        "tokens": [
          51228,
          400,
          412,
          264,
          917,
          11,
          291,
          434,
          516,
          281,
          483,
          512,
          2158,
          11,
          411,
          291,
          1062,
          483,
          7634,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2322.46,
        "id": 754,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2320.22,
        "temperature": 0,
        "text": " And it's going to be, that's going to be a positive.",
        "tokens": [
          51400,
          400,
          309,
          311,
          516,
          281,
          312,
          11,
          300,
          311,
          516,
          281,
          312,
          257,
          3353,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2325.66,
        "id": 755,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2322.46,
        "temperature": 0,
        "text": " This is a positive email, a positive tweet, positive essay.",
        "tokens": [
          51512,
          639,
          307,
          257,
          3353,
          3796,
          11,
          257,
          3353,
          15258,
          11,
          3353,
          16238,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2327.5,
        "id": 756,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2325.66,
        "temperature": 0,
        "text": " Or you might get negative 31.",
        "tokens": [
          51672,
          1610,
          291,
          1062,
          483,
          3671,
          10353,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16295635456941565,
        "compression_ratio": 1.8763636363636365,
        "end": 2329.18,
        "id": 757,
        "no_speech_prob": 0.008711103349924088,
        "seek": 229950,
        "start": 2327.5,
        "temperature": 0,
        "text": " And this is very, very negative.",
        "tokens": [
          51764,
          400,
          341,
          307,
          588,
          11,
          588,
          3671,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2331.2599999999998,
        "id": 758,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2329.4199999999996,
        "temperature": 0,
        "text": " You can get the total score.",
        "tokens": [
          50376,
          509,
          393,
          483,
          264,
          3217,
          6175,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2333.98,
        "id": 759,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2331.2599999999998,
        "temperature": 0,
        "text": " And you can also get what's known as the comparable score.",
        "tokens": [
          50468,
          400,
          291,
          393,
          611,
          483,
          437,
          311,
          2570,
          382,
          264,
          25323,
          6175,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2334.7,
        "id": 760,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2333.98,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          50604,
          286,
          519,
          300,
          311,
          558,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2335.58,
        "id": 761,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2334.7,
        "temperature": 0,
        "text": " Comparable score?",
        "tokens": [
          50640,
          2432,
          42012,
          6175,
          30,
          50684
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2336.46,
        "id": 762,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2335.58,
        "temperature": 0,
        "text": " What is that called?",
        "tokens": [
          50684,
          708,
          307,
          300,
          1219,
          30,
          50728
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2340.8599999999997,
        "id": 763,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2340.22,
        "temperature": 0,
        "text": " OK, wait, wait, wait.",
        "tokens": [
          50916,
          2264,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2341.74,
        "id": 764,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2340.8599999999997,
        "temperature": 0,
        "text": " What's that called?",
        "tokens": [
          50948,
          708,
          311,
          300,
          1219,
          30,
          50992
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2345.4199999999996,
        "id": 765,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2343.1,
        "temperature": 0,
        "text": " AFIN, I don't want to get it wrong.",
        "tokens": [
          51060,
          20389,
          1464,
          11,
          286,
          500,
          380,
          528,
          281,
          483,
          309,
          2085,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2348.94,
        "id": 766,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2345.4199999999996,
        "temperature": 0,
        "text": " 111 comparable, comparable.",
        "tokens": [
          51176,
          2975,
          16,
          25323,
          11,
          25323,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2354.7,
        "id": 767,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2353.58,
        "temperature": 0,
        "text": " Oh, look, I'm going to look at this.",
        "tokens": [
          51584,
          876,
          11,
          574,
          11,
          286,
          478,
          516,
          281,
          574,
          412,
          341,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2356.62,
        "id": 768,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2354.7,
        "temperature": 0,
        "text": " This is exactly, by the way, I've seen this web page before.",
        "tokens": [
          51640,
          639,
          307,
          2293,
          11,
          538,
          264,
          636,
          11,
          286,
          600,
          1612,
          341,
          3670,
          3028,
          949,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.2731843992721203,
        "compression_ratio": 1.738938053097345,
        "end": 2357.8199999999997,
        "id": 769,
        "no_speech_prob": 0.00021318686776794493,
        "seek": 232918,
        "start": 2356.62,
        "temperature": 0,
        "text": " This is exactly what I'm going to build.",
        "tokens": [
          51736,
          639,
          307,
          2293,
          437,
          286,
          478,
          516,
          281,
          1322,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2360.7799999999997,
        "id": 770,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2359.5,
        "temperature": 0,
        "text": " I am happy.",
        "tokens": [
          50380,
          286,
          669,
          2055,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2363.4199999999996,
        "id": 771,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2361.8999999999996,
        "temperature": 0,
        "text": " Comparative, why did I say?",
        "tokens": [
          50500,
          2432,
          2181,
          1166,
          11,
          983,
          630,
          286,
          584,
          30,
          50576
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2371.18,
        "id": 772,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2367.1,
        "temperature": 0,
        "text": " OK, coming back to here.",
        "tokens": [
          50760,
          2264,
          11,
          1348,
          646,
          281,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2376.06,
        "id": 773,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2373.5,
        "temperature": 0,
        "text": " OK, oh, camera's still on the whiteboard.",
        "tokens": [
          51080,
          2264,
          11,
          1954,
          11,
          2799,
          311,
          920,
          322,
          264,
          2418,
          3787,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2377.5,
        "id": 774,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2376.06,
        "temperature": 0,
        "text": " Sorry, everybody, but that's fine.",
        "tokens": [
          51208,
          4919,
          11,
          2201,
          11,
          457,
          300,
          311,
          2489,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2379.02,
        "id": 775,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2377.5,
        "temperature": 0,
        "text": " I was just looking something up.",
        "tokens": [
          51280,
          286,
          390,
          445,
          1237,
          746,
          493,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2381.5,
        "id": 776,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2379.02,
        "temperature": 0,
        "text": " Comparative, I don't know why I said comparable.",
        "tokens": [
          51356,
          2432,
          2181,
          1166,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          848,
          25323,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.222366702172064,
        "compression_ratio": 1.436842105263158,
        "end": 2385.8999999999996,
        "id": 777,
        "no_speech_prob": 0.00034062712802551687,
        "seek": 235918,
        "start": 2382.3799999999997,
        "temperature": 0,
        "text": " So thank you, Mattheo, for being a master editor.",
        "tokens": [
          51524,
          407,
          1309,
          291,
          11,
          6789,
          3322,
          78,
          11,
          337,
          885,
          257,
          4505,
          9839,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2388.62,
        "id": 778,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2386.3,
        "temperature": 0,
        "text": " Don't know if I would basically have to quit doing this",
        "tokens": [
          50384,
          1468,
          380,
          458,
          498,
          286,
          576,
          1936,
          362,
          281,
          10366,
          884,
          341,
          50500
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2389.7400000000002,
        "id": 779,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2388.62,
        "temperature": 0,
        "text": " if it wasn't for you.",
        "tokens": [
          50500,
          498,
          309,
          2067,
          380,
          337,
          291,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2400.06,
        "id": 780,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2389.7400000000002,
        "temperature": 0,
        "text": " OK, so this is what would be known as the total score.",
        "tokens": [
          50556,
          2264,
          11,
          370,
          341,
          307,
          437,
          576,
          312,
          2570,
          382,
          264,
          3217,
          6175,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2402.06,
        "id": 781,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2400.06,
        "temperature": 0,
        "text": " But you can also look at the comparative score,",
        "tokens": [
          51072,
          583,
          291,
          393,
          611,
          574,
          412,
          264,
          39292,
          6175,
          11,
          51172
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2405.1800000000003,
        "id": 782,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2402.06,
        "temperature": 0,
        "text": " meaning just because you have a really long document with the",
        "tokens": [
          51172,
          3620,
          445,
          570,
          291,
          362,
          257,
          534,
          938,
          4166,
          365,
          264,
          51328
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2408.3,
        "id": 783,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2405.1800000000003,
        "temperature": 0,
        "text": " word happy in it a lot of times is that more positive than a",
        "tokens": [
          51328,
          1349,
          2055,
          294,
          309,
          257,
          688,
          295,
          1413,
          307,
          300,
          544,
          3353,
          813,
          257,
          51484
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2411.58,
        "id": 784,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2408.3,
        "temperature": 0,
        "text": " short document with the word happy in it fewer times.",
        "tokens": [
          51484,
          2099,
          4166,
          365,
          264,
          1349,
          2055,
          294,
          309,
          13366,
          1413,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.21062836419968378,
        "compression_ratio": 1.8227272727272728,
        "end": 2415.58,
        "id": 785,
        "no_speech_prob": 0.0003459898289293051,
        "seek": 238590,
        "start": 2411.58,
        "temperature": 0,
        "text": " So the comparative score would be the total",
        "tokens": [
          51648,
          407,
          264,
          39292,
          6175,
          576,
          312,
          264,
          3217,
          51848
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2419.34,
        "id": 786,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2415.58,
        "temperature": 0,
        "text": " score divided by the total number of words.",
        "tokens": [
          50364,
          6175,
          6666,
          538,
          264,
          3217,
          1230,
          295,
          2283,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2423.42,
        "id": 787,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2420.86,
        "temperature": 0,
        "text": " OK, so this is exactly what I want to implement.",
        "tokens": [
          50628,
          2264,
          11,
          370,
          341,
          307,
          2293,
          437,
          286,
          528,
          281,
          4445,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2425.1,
        "id": 788,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2423.42,
        "temperature": 0,
        "text": " So let's look back here.",
        "tokens": [
          50756,
          407,
          718,
          311,
          574,
          646,
          510,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2429.5,
        "id": 789,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2425.1,
        "temperature": 0,
        "text": " Sorry, so the AFIN111 is a particular list of words.",
        "tokens": [
          50840,
          4919,
          11,
          370,
          264,
          20389,
          1464,
          5348,
          16,
          307,
          257,
          1729,
          1329,
          295,
          2283,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2430.54,
        "id": 790,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2429.5,
        "temperature": 0,
        "text": " It was manually made.",
        "tokens": [
          51060,
          467,
          390,
          16945,
          1027,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2433.02,
        "id": 791,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2430.54,
        "temperature": 0,
        "text": " This was manually made by Finn Arup Nielsen.",
        "tokens": [
          51112,
          639,
          390,
          16945,
          1027,
          538,
          21066,
          316,
          11976,
          426,
          1187,
          6748,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2436.38,
        "id": 792,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2433.58,
        "temperature": 0,
        "text": " You can imagine what kind of research and thought went into this.",
        "tokens": [
          51264,
          509,
          393,
          3811,
          437,
          733,
          295,
          2132,
          293,
          1194,
          1437,
          666,
          341,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2439.18,
        "id": 793,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2437.02,
        "temperature": 0,
        "text": " And I encourage you to read the paper.",
        "tokens": [
          51436,
          400,
          286,
          5373,
          291,
          281,
          1401,
          264,
          3035,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.24147230891858118,
        "compression_ratio": 1.5930232558139534,
        "end": 2442.7799999999997,
        "id": 794,
        "no_speech_prob": 0.0003514360578265041,
        "seek": 241558,
        "start": 2439.18,
        "temperature": 0,
        "text": " And also, if you use this list, you should also reference the paper.",
        "tokens": [
          51544,
          400,
          611,
          11,
          498,
          291,
          764,
          341,
          1329,
          11,
          291,
          820,
          611,
          6408,
          264,
          3035,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2446.86,
        "id": 795,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2442.94,
        "temperature": 0,
        "text": " Everything is on this website, which is linked in this video's description.",
        "tokens": [
          50372,
          5471,
          307,
          322,
          341,
          3144,
          11,
          597,
          307,
          9408,
          294,
          341,
          960,
          311,
          3855,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2448.94,
        "id": 796,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2446.86,
        "temperature": 0,
        "text": " OK, so what I'm going to actually do is just download it.",
        "tokens": [
          50568,
          2264,
          11,
          370,
          437,
          286,
          478,
          516,
          281,
          767,
          360,
          307,
          445,
          5484,
          309,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2450.5400000000004,
        "id": 797,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2448.94,
        "temperature": 0,
        "text": " Oh, I've already downloaded it.",
        "tokens": [
          50672,
          876,
          11,
          286,
          600,
          1217,
          21748,
          309,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2452.3,
        "id": 798,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2450.5400000000004,
        "temperature": 0,
        "text": " I did that before it started.",
        "tokens": [
          50752,
          286,
          630,
          300,
          949,
          309,
          1409,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2453.1000000000004,
        "id": 799,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2452.3,
        "temperature": 0,
        "text": " It's like a cooking show.",
        "tokens": [
          50840,
          467,
          311,
          411,
          257,
          6361,
          855,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2456.6200000000003,
        "id": 800,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2453.82,
        "temperature": 0,
        "text": " Here's my AFIN111 list, except this is a fan.",
        "tokens": [
          50916,
          1692,
          311,
          452,
          20389,
          1464,
          5348,
          16,
          1329,
          11,
          3993,
          341,
          307,
          257,
          3429,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2459.26,
        "id": 801,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2456.6200000000003,
        "temperature": 0,
        "text": " By the way, isn't it random that I just like underneath this desk?",
        "tokens": [
          51056,
          3146,
          264,
          636,
          11,
          1943,
          380,
          309,
          4974,
          300,
          286,
          445,
          411,
          7223,
          341,
          10026,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2461.5,
        "id": 802,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2460.6200000000003,
        "temperature": 0,
        "text": " What else do I have?",
        "tokens": [
          51256,
          708,
          1646,
          360,
          286,
          362,
          30,
          51300
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2463.1000000000004,
        "id": 803,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2462.1400000000003,
        "temperature": 0,
        "text": " Nothing is the sad thing.",
        "tokens": [
          51332,
          6693,
          307,
          264,
          4227,
          551,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2463.9,
        "id": 804,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2463.1000000000004,
        "temperature": 0,
        "text": " Oh, watch this, though.",
        "tokens": [
          51380,
          876,
          11,
          1159,
          341,
          11,
          1673,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2465.82,
        "id": 805,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2464.46,
        "temperature": 0,
        "text": " I have another fan.",
        "tokens": [
          51448,
          286,
          362,
          1071,
          3429,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2467.82,
        "id": 806,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2465.82,
        "temperature": 0,
        "text": " It was just like in here.",
        "tokens": [
          51516,
          467,
          390,
          445,
          411,
          294,
          510,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2468.46,
        "id": 807,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2467.82,
        "temperature": 0,
        "text": " I have a magical.",
        "tokens": [
          51616,
          286,
          362,
          257,
          12066,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2468.94,
        "id": 808,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2468.46,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51648,
          876,
          11,
          574,
          412,
          341,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2469.5,
        "id": 809,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2468.94,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51672,
          2053,
          412,
          341,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.2103339301215278,
        "compression_ratio": 1.7207792207792207,
        "end": 2471.1800000000003,
        "id": 810,
        "no_speech_prob": 0.5077080130577087,
        "seek": 244278,
        "start": 2469.5,
        "temperature": 0,
        "text": " Over here, I have a monitor.",
        "tokens": [
          51700,
          4886,
          510,
          11,
          286,
          362,
          257,
          6002,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2473.1,
        "id": 811,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2472.14,
        "temperature": 0,
        "text": " There's lots of stuff.",
        "tokens": [
          50412,
          821,
          311,
          3195,
          295,
          1507,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2478.06,
        "id": 812,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2473.1,
        "temperature": 0,
        "text": " It's like a magical bag of things that people are telling me to concentrate.",
        "tokens": [
          50460,
          467,
          311,
          411,
          257,
          12066,
          3411,
          295,
          721,
          300,
          561,
          366,
          3585,
          385,
          281,
          18089,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2479.4199999999996,
        "id": 813,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2478.06,
        "temperature": 0,
        "text": " I don't do a good job of that.",
        "tokens": [
          50708,
          286,
          500,
          380,
          360,
          257,
          665,
          1691,
          295,
          300,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2481.74,
        "id": 814,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2479.4199999999996,
        "temperature": 0,
        "text": " OK, so I've already downloaded this list.",
        "tokens": [
          50776,
          2264,
          11,
          370,
          286,
          600,
          1217,
          21748,
          341,
          1329,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2482.8599999999997,
        "id": 815,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2481.74,
        "temperature": 0,
        "text": " I can't pull it out.",
        "tokens": [
          50892,
          286,
          393,
          380,
          2235,
          309,
          484,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2484.46,
        "id": 816,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2482.8599999999997,
        "temperature": 0,
        "text": " And let's go take a look at it.",
        "tokens": [
          50948,
          400,
          718,
          311,
          352,
          747,
          257,
          574,
          412,
          309,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2486.22,
        "id": 817,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2484.46,
        "temperature": 0,
        "text": " So where would it be?",
        "tokens": [
          51028,
          407,
          689,
          576,
          309,
          312,
          30,
          51116
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2487.98,
        "id": 818,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2486.22,
        "temperature": 0,
        "text": " It would be in my downloads.",
        "tokens": [
          51116,
          467,
          576,
          312,
          294,
          452,
          36553,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2489.8199999999997,
        "id": 819,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2487.98,
        "temperature": 0,
        "text": " And here it is under AFIN111.",
        "tokens": [
          51204,
          400,
          510,
          309,
          307,
          833,
          20389,
          1464,
          5348,
          16,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2492.46,
        "id": 820,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2489.8199999999997,
        "temperature": 0,
        "text": " So here, I'm going to open this up.",
        "tokens": [
          51296,
          407,
          510,
          11,
          286,
          478,
          516,
          281,
          1269,
          341,
          493,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2494.06,
        "id": 821,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2492.46,
        "temperature": 0,
        "text": " And we can take a look at this list.",
        "tokens": [
          51428,
          400,
          321,
          393,
          747,
          257,
          574,
          412,
          341,
          1329,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.16124347988650095,
        "compression_ratio": 1.6423076923076922,
        "end": 2499.2599999999998,
        "id": 822,
        "no_speech_prob": 0.0010649554897099733,
        "seek": 247118,
        "start": 2496.94,
        "temperature": 0,
        "text": " So you can see this has several thousand words.",
        "tokens": [
          51652,
          407,
          291,
          393,
          536,
          341,
          575,
          2940,
          4714,
          2283,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2503.26,
        "id": 823,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2499.26,
        "temperature": 0,
        "text": " And you can see abandon being negative 2, abandon negative 2, et cetera, et cetera, et",
        "tokens": [
          50364,
          400,
          291,
          393,
          536,
          9072,
          885,
          3671,
          568,
          11,
          410,
          282,
          13966,
          3671,
          568,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          11,
          1030,
          50564
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2508.0600000000004,
        "id": 824,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2503.26,
        "temperature": 0,
        "text": " cetera, compelled 1, congratulations 2, et cetera.",
        "tokens": [
          50564,
          11458,
          11,
          40021,
          502,
          11,
          13568,
          568,
          11,
          1030,
          11458,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2510.0600000000004,
        "id": 825,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2508.0600000000004,
        "temperature": 0,
        "text": " You can see here all the words and all their scores.",
        "tokens": [
          50804,
          509,
          393,
          536,
          510,
          439,
          264,
          2283,
          293,
          439,
          641,
          13444,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2511.5800000000004,
        "id": 826,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2510.0600000000004,
        "temperature": 0,
        "text": " I can scroll through the whole thing.",
        "tokens": [
          50904,
          286,
          393,
          11369,
          807,
          264,
          1379,
          551,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2514.86,
        "id": 827,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2511.5800000000004,
        "temperature": 0,
        "text": " So the first thing that I want to do in this challenge, I think, is it would be so much",
        "tokens": [
          50980,
          407,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          294,
          341,
          3430,
          11,
          286,
          519,
          11,
          307,
          309,
          576,
          312,
          370,
          709,
          51144
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2520.5400000000004,
        "id": 828,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2514.86,
        "temperature": 0,
        "text": " more convenient if this text file was actually a JSON file.",
        "tokens": [
          51144,
          544,
          10851,
          498,
          341,
          2487,
          3991,
          390,
          767,
          257,
          31828,
          3991,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2523.26,
        "id": 829,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2520.5400000000004,
        "temperature": 0,
        "text": " So let's write a little quick program to convert it to JSON.",
        "tokens": [
          51428,
          407,
          718,
          311,
          2464,
          257,
          707,
          1702,
          1461,
          281,
          7620,
          309,
          281,
          31828,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19586533990525107,
        "compression_ratio": 1.7562724014336917,
        "end": 2525.5,
        "id": 830,
        "no_speech_prob": 0.0008969294722191989,
        "seek": 249926,
        "start": 2523.26,
        "temperature": 0,
        "text": " I could do that in like Node or Python or something.",
        "tokens": [
          51564,
          286,
          727,
          360,
          300,
          294,
          411,
          38640,
          420,
          15329,
          420,
          746,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2529.34,
        "id": 831,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2525.5,
        "temperature": 0,
        "text": " But I'm going to somewhat absurdly just do this in the browser.",
        "tokens": [
          50364,
          583,
          286,
          478,
          516,
          281,
          8344,
          19774,
          356,
          445,
          360,
          341,
          294,
          264,
          11185,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2531.9,
        "id": 832,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2529.34,
        "temperature": 0,
        "text": " So first, what I want to do is I need to get this list.",
        "tokens": [
          50556,
          407,
          700,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          643,
          281,
          483,
          341,
          1329,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2535.1,
        "id": 833,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2531.9,
        "temperature": 0,
        "text": " And I need to go to my folder that has my code.",
        "tokens": [
          50684,
          400,
          286,
          643,
          281,
          352,
          281,
          452,
          10820,
          300,
          575,
          452,
          3089,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2538.14,
        "id": 834,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2535.1,
        "temperature": 0,
        "text": " And I'm going to paste it in here.",
        "tokens": [
          50844,
          400,
          286,
          478,
          516,
          281,
          9163,
          309,
          294,
          510,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2540.94,
        "id": 835,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2538.14,
        "temperature": 0,
        "text": " So right now, I have a folder that has an HTML file.",
        "tokens": [
          50996,
          407,
          558,
          586,
          11,
          286,
          362,
          257,
          10820,
          300,
          575,
          364,
          17995,
          3991,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2545.66,
        "id": 836,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2540.94,
        "temperature": 0,
        "text": " I have a libraries folder because I'm using the p5.js and the p5.dom library.",
        "tokens": [
          51136,
          286,
          362,
          257,
          15148,
          10820,
          570,
          286,
          478,
          1228,
          264,
          280,
          20,
          13,
          25530,
          293,
          264,
          280,
          20,
          13,
          4121,
          6405,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2548.86,
        "id": 837,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2545.66,
        "temperature": 0,
        "text": " And sketch.js is where I'm going to have my JavaScript code.",
        "tokens": [
          51372,
          400,
          12325,
          13,
          25530,
          307,
          689,
          286,
          478,
          516,
          281,
          362,
          452,
          15778,
          3089,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.15387167446855185,
        "compression_ratio": 1.7975708502024292,
        "end": 2552.54,
        "id": 838,
        "no_speech_prob": 0.011686887592077255,
        "seek": 252550,
        "start": 2549.42,
        "temperature": 0,
        "text": " OK, so now what I want to do is here's the thing.",
        "tokens": [
          51560,
          2264,
          11,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          510,
          311,
          264,
          551,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.19101957038596826,
        "compression_ratio": 1.5982532751091703,
        "end": 2559.1,
        "id": 839,
        "no_speech_prob": 0.0007321754819713533,
        "seek": 255254,
        "start": 2553.18,
        "temperature": 0,
        "text": " This file, which I can load up here, this is actually, I'm almost certain, is a tab delimited",
        "tokens": [
          50396,
          639,
          3991,
          11,
          597,
          286,
          393,
          3677,
          493,
          510,
          11,
          341,
          307,
          767,
          11,
          286,
          478,
          1920,
          1629,
          11,
          307,
          257,
          4421,
          1103,
          332,
          1226,
          50692
        ]
      },
      {
        "avg_logprob": -0.19101957038596826,
        "compression_ratio": 1.5982532751091703,
        "end": 2565.18,
        "id": 840,
        "no_speech_prob": 0.0007321754819713533,
        "seek": 255254,
        "start": 2559.1,
        "temperature": 0,
        "text": " file, meaning each word, the format of this file is word tab score.",
        "tokens": [
          50692,
          3991,
          11,
          3620,
          1184,
          1349,
          11,
          264,
          7877,
          295,
          341,
          3991,
          307,
          1349,
          4421,
          6175,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.19101957038596826,
        "compression_ratio": 1.5982532751091703,
        "end": 2567.58,
        "id": 841,
        "no_speech_prob": 0.0007321754819713533,
        "seek": 255254,
        "start": 2565.18,
        "temperature": 0,
        "text": " So there's a variety of ways I could parse this.",
        "tokens": [
          50996,
          407,
          456,
          311,
          257,
          5673,
          295,
          2098,
          286,
          727,
          48377,
          341,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.19101957038596826,
        "compression_ratio": 1.5982532751091703,
        "end": 2569.9,
        "id": 842,
        "no_speech_prob": 0.0007321754819713533,
        "seek": 255254,
        "start": 2568.22,
        "temperature": 0,
        "text": " And this may not actually work.",
        "tokens": [
          51148,
          400,
          341,
          815,
          406,
          767,
          589,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.19101957038596826,
        "compression_ratio": 1.5982532751091703,
        "end": 2576.86,
        "id": 843,
        "no_speech_prob": 0.0007321754819713533,
        "seek": 255254,
        "start": 2569.9,
        "temperature": 0,
        "text": " But let's test the p5.js library and see if load table works with this file.",
        "tokens": [
          51232,
          583,
          718,
          311,
          1500,
          264,
          280,
          20,
          13,
          25530,
          6405,
          293,
          536,
          498,
          3677,
          3199,
          1985,
          365,
          341,
          3991,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.19101957038596826,
        "compression_ratio": 1.5982532751091703,
        "end": 2579.9,
        "id": 844,
        "no_speech_prob": 0.0007321754819713533,
        "seek": 255254,
        "start": 2577.5,
        "temperature": 0,
        "text": " So what I'm going to do is go back to my code.",
        "tokens": [
          51612,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          352,
          646,
          281,
          452,
          3089,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2583.26,
        "id": 845,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2579.98,
        "temperature": 0,
        "text": " And I'm going to say var table.",
        "tokens": [
          50368,
          400,
          286,
          478,
          516,
          281,
          584,
          1374,
          3199,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2585.26,
        "id": 846,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2584.54,
        "temperature": 0,
        "text": " Function pre.",
        "tokens": [
          50596,
          11166,
          882,
          659,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2591.42,
        "id": 847,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2585.26,
        "temperature": 0,
        "text": " I'm going to use preload, which is a function that I can use to make sure certain images",
        "tokens": [
          50632,
          286,
          478,
          516,
          281,
          764,
          659,
          2907,
          11,
          597,
          307,
          257,
          2445,
          300,
          286,
          393,
          764,
          281,
          652,
          988,
          1629,
          5267,
          50940
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2596.62,
        "id": 848,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2591.42,
        "temperature": 0,
        "text": " or media or data files are loaded before the page, the sketch even begins.",
        "tokens": [
          50940,
          420,
          3021,
          420,
          1412,
          7098,
          366,
          13210,
          949,
          264,
          3028,
          11,
          264,
          12325,
          754,
          7338,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2598.06,
        "id": 849,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2597.34,
        "temperature": 0,
        "text": " Load table.",
        "tokens": [
          51236,
          48408,
          3199,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2602.7000000000003,
        "id": 850,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2598.7000000000003,
        "temperature": 0,
        "text": " And then I need to give it the file name, afin111.txt.",
        "tokens": [
          51304,
          400,
          550,
          286,
          643,
          281,
          976,
          309,
          264,
          3991,
          1315,
          11,
          257,
          5194,
          5348,
          16,
          13,
          83,
          734,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2607.26,
        "id": 851,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2603.7400000000002,
        "temperature": 0,
        "text": " And then I'm just going to say console.log table.",
        "tokens": [
          51556,
          400,
          550,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          3199,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2288149737436837,
        "compression_ratio": 1.6619718309859155,
        "end": 2609.34,
        "id": 852,
        "no_speech_prob": 0.0021826359443366528,
        "seek": 257990,
        "start": 2608.06,
        "temperature": 0,
        "text": " And let's see what happens.",
        "tokens": [
          51772,
          400,
          718,
          311,
          536,
          437,
          2314,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2613.42,
        "id": 853,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2610.46,
        "temperature": 0,
        "text": " And this is my, so that's good.",
        "tokens": [
          50392,
          400,
          341,
          307,
          452,
          11,
          370,
          300,
          311,
          665,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2614.06,
        "id": 854,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2613.42,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50540,
          2053,
          412,
          341,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2615.42,
        "id": 855,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2614.06,
        "temperature": 0,
        "text": " This is very promising.",
        "tokens": [
          50572,
          639,
          307,
          588,
          20257,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2617.7400000000002,
        "id": 856,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2615.42,
        "temperature": 0,
        "text": " You can see that a table object got loaded.",
        "tokens": [
          50640,
          509,
          393,
          536,
          300,
          257,
          3199,
          2657,
          658,
          13210,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2622.62,
        "id": 857,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2617.7400000000002,
        "temperature": 0,
        "text": " And it includes an array of rows with 2,477.",
        "tokens": [
          50756,
          400,
          309,
          5974,
          364,
          10225,
          295,
          13241,
          365,
          568,
          11,
          14060,
          22,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2627.5,
        "id": 858,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2622.62,
        "temperature": 0,
        "text": " So frankly, there's not really a huge need to turn this into JSON because I have it in",
        "tokens": [
          51000,
          407,
          11939,
          11,
          456,
          311,
          406,
          534,
          257,
          2603,
          643,
          281,
          1261,
          341,
          666,
          31828,
          570,
          286,
          362,
          309,
          294,
          51244
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2629.6600000000003,
        "id": 859,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2627.5,
        "temperature": 0,
        "text": " this nice table object, which makes it very easy to parse.",
        "tokens": [
          51244,
          341,
          1481,
          3199,
          2657,
          11,
          597,
          1669,
          309,
          588,
          1858,
          281,
          48377,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2633.9,
        "id": 860,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2629.6600000000003,
        "temperature": 0,
        "text": " But let's, for lookup, when I want to look up the scores, I'm going to want it as a JavaScript",
        "tokens": [
          51352,
          583,
          718,
          311,
          11,
          337,
          574,
          1010,
          11,
          562,
          286,
          528,
          281,
          574,
          493,
          264,
          13444,
          11,
          286,
          478,
          516,
          281,
          528,
          309,
          382,
          257,
          15778,
          51564
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2634.3,
        "id": 861,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2633.9,
        "temperature": 0,
        "text": " object.",
        "tokens": [
          51564,
          2657,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.18564048711804376,
        "compression_ratio": 1.5724137931034483,
        "end": 2638.3,
        "id": 862,
        "no_speech_prob": 0.000006439033768401714,
        "seek": 260990,
        "start": 2634.3,
        "temperature": 0,
        "text": " So let's see, how do we iterate over this table?",
        "tokens": [
          51584,
          407,
          718,
          311,
          536,
          11,
          577,
          360,
          321,
          44497,
          670,
          341,
          3199,
          30,
          51784
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2644.3,
        "id": 863,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2638.3,
        "temperature": 0,
        "text": " So for var i equals 0, i is less than table.getRowCount.",
        "tokens": [
          50364,
          407,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          3199,
          13,
          847,
          49,
          305,
          34,
          792,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2646.0600000000004,
        "id": 864,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2645.02,
        "temperature": 0,
        "text": " Here's the thing.",
        "tokens": [
          50700,
          1692,
          311,
          264,
          551,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2649.26,
        "id": 865,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2646.0600000000004,
        "temperature": 0,
        "text": " I don't know that the table API off the top of my head.",
        "tokens": [
          50752,
          286,
          500,
          380,
          458,
          300,
          264,
          3199,
          9362,
          766,
          264,
          1192,
          295,
          452,
          1378,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2651.9,
        "id": 866,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2649.26,
        "temperature": 0,
        "text": " So let's go to p5js.org, reference.",
        "tokens": [
          50912,
          407,
          718,
          311,
          352,
          281,
          280,
          20,
          25530,
          13,
          4646,
          11,
          6408,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2656.78,
        "id": 867,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2653.1800000000003,
        "temperature": 0,
        "text": " And then what I'm going to do is look for table.",
        "tokens": [
          51108,
          400,
          550,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          574,
          337,
          3199,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2659.98,
        "id": 868,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2657.34,
        "temperature": 0,
        "text": " And we can see load table, p5 table.",
        "tokens": [
          51316,
          400,
          321,
          393,
          536,
          3677,
          3199,
          11,
          280,
          20,
          3199,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2661.7400000000002,
        "id": 869,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2659.98,
        "temperature": 0,
        "text": " So let's go to p5 table.",
        "tokens": [
          51448,
          407,
          718,
          311,
          352,
          281,
          280,
          20,
          3199,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.2080851086115433,
        "compression_ratio": 1.6502463054187193,
        "end": 2667.98,
        "id": 870,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 263830,
        "start": 2662.38,
        "temperature": 0,
        "text": " And we can see a bunch of the functions like getRowCount.",
        "tokens": [
          51568,
          400,
          321,
          393,
          536,
          257,
          3840,
          295,
          264,
          6828,
          411,
          483,
          49,
          305,
          34,
          792,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2672.38,
        "id": 871,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2668.3,
        "temperature": 0,
        "text": " So this is something I certainly need to that I want to iterate over all the rows.",
        "tokens": [
          50364,
          407,
          341,
          307,
          746,
          286,
          3297,
          643,
          281,
          300,
          286,
          528,
          281,
          44497,
          670,
          439,
          264,
          13241,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2681.34,
        "id": 872,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2672.38,
        "temperature": 0,
        "text": " So I can say for var i equals 0, i is less than table.getRowCount, i plus plus.",
        "tokens": [
          50568,
          407,
          286,
          393,
          584,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          3199,
          13,
          847,
          49,
          305,
          34,
          792,
          11,
          741,
          1804,
          1804,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2686.94,
        "id": 873,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2682.2200000000003,
        "temperature": 0,
        "text": " And then I can get each row probably by saying getRow i.",
        "tokens": [
          51060,
          400,
          550,
          286,
          393,
          483,
          1184,
          5386,
          1391,
          538,
          1566,
          483,
          49,
          305,
          741,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2689.34,
        "id": 874,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2687.5,
        "temperature": 0,
        "text": " That seems probably like it's the case.",
        "tokens": [
          51324,
          663,
          2544,
          1391,
          411,
          309,
          311,
          264,
          1389,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2691.02,
        "id": 875,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2689.34,
        "temperature": 0,
        "text": " Let's say console.log row.",
        "tokens": [
          51416,
          961,
          311,
          584,
          11076,
          13,
          4987,
          5386,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2692.6200000000003,
        "id": 876,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2691.5800000000004,
        "temperature": 0,
        "text": " Let's see if that works.",
        "tokens": [
          51528,
          961,
          311,
          536,
          498,
          300,
          1985,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.20989615828902633,
        "compression_ratio": 1.547085201793722,
        "end": 2695.42,
        "id": 877,
        "no_speech_prob": 0.00011591897055041045,
        "seek": 266830,
        "start": 2693.6600000000003,
        "temperature": 0,
        "text": " Whoops, let me go back over here.",
        "tokens": [
          51632,
          45263,
          11,
          718,
          385,
          352,
          646,
          670,
          510,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2696.94,
        "id": 878,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2696.06,
        "temperature": 0,
        "text": " So this looks good.",
        "tokens": [
          50396,
          407,
          341,
          1542,
          665,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2701.1,
        "id": 879,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2696.94,
        "temperature": 0,
        "text": " Like I'm getting a row object for every row in that table.",
        "tokens": [
          50440,
          1743,
          286,
          478,
          1242,
          257,
          5386,
          2657,
          337,
          633,
          5386,
          294,
          300,
          3199,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2704.54,
        "id": 880,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2701.1,
        "temperature": 0,
        "text": " And I probably can say var word equals table.get0.",
        "tokens": [
          50648,
          400,
          286,
          1391,
          393,
          584,
          1374,
          1349,
          6915,
          3199,
          13,
          847,
          15,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2711.82,
        "id": 881,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2707.58,
        "temperature": 0,
        "text": " And var score equals table.get1.",
        "tokens": [
          50972,
          400,
          1374,
          6175,
          6915,
          3199,
          13,
          847,
          16,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2713.7400000000002,
        "id": 882,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2711.82,
        "temperature": 0,
        "text": " And why am I saying that?",
        "tokens": [
          51184,
          400,
          983,
          669,
          286,
          1566,
          300,
          30,
          51280
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2721.9,
        "id": 883,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2713.7400000000002,
        "temperature": 0,
        "text": " Because if this file is in a table and each line of this text file is a row,",
        "tokens": [
          51280,
          1436,
          498,
          341,
          3991,
          307,
          294,
          257,
          3199,
          293,
          1184,
          1622,
          295,
          341,
          2487,
          3991,
          307,
          257,
          5386,
          11,
          51688
        ]
      },
      {
        "avg_logprob": -0.19424425760904948,
        "compression_ratio": 1.5691489361702127,
        "end": 2723.1,
        "id": 884,
        "no_speech_prob": 0.0001713080273475498,
        "seek": 269542,
        "start": 2721.9,
        "temperature": 0,
        "text": " think of it as a spreadsheet,",
        "tokens": [
          51688,
          519,
          295,
          309,
          382,
          257,
          27733,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2728.94,
        "id": 885,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2723.8199999999997,
        "temperature": 0,
        "text": " a board is in column 0, 1 is in column 1.",
        "tokens": [
          50400,
          257,
          3150,
          307,
          294,
          7738,
          1958,
          11,
          502,
          307,
          294,
          7738,
          502,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2733.58,
        "id": 886,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2728.94,
        "temperature": 0,
        "text": " So this is me saying load that text file into a table,",
        "tokens": [
          50656,
          407,
          341,
          307,
          385,
          1566,
          3677,
          300,
          2487,
          3991,
          666,
          257,
          3199,
          11,
          50888
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2736.62,
        "id": 887,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2734.14,
        "temperature": 0,
        "text": " look at every single row, get every row,",
        "tokens": [
          50916,
          574,
          412,
          633,
          2167,
          5386,
          11,
          483,
          633,
          5386,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2740.7799999999997,
        "id": 888,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2736.62,
        "temperature": 0,
        "text": " and then get the stuff that's in column 0 and get the stuff that's in column 1.",
        "tokens": [
          51040,
          293,
          550,
          483,
          264,
          1507,
          300,
          311,
          294,
          7738,
          1958,
          293,
          483,
          264,
          1507,
          300,
          311,
          294,
          7738,
          502,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2744.22,
        "id": 889,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2740.7799999999997,
        "temperature": 0,
        "text": " And by the way, I could actually label the columns with headers and use that.",
        "tokens": [
          51248,
          400,
          538,
          264,
          636,
          11,
          286,
          727,
          767,
          7645,
          264,
          13766,
          365,
          45101,
          293,
          764,
          300,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2747.5,
        "id": 890,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2744.22,
        "temperature": 0,
        "text": " There's lots of fancier things you can do with tables in p5n processing.",
        "tokens": [
          51420,
          821,
          311,
          3195,
          295,
          3429,
          27674,
          721,
          291,
          393,
          360,
          365,
          8020,
          294,
          280,
          20,
          77,
          9007,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2748.2999999999997,
        "id": 891,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2747.5,
        "temperature": 0,
        "text": " But this should do.",
        "tokens": [
          51584,
          583,
          341,
          820,
          360,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2750.38,
        "id": 892,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2748.2999999999997,
        "temperature": 0,
        "text": " So let's say console.log word score.",
        "tokens": [
          51624,
          407,
          718,
          311,
          584,
          11076,
          13,
          4987,
          1349,
          6175,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.15916465990471118,
        "compression_ratio": 1.7943548387096775,
        "end": 2751.8199999999997,
        "id": 893,
        "no_speech_prob": 0.0002034268545685336,
        "seek": 272310,
        "start": 2750.94,
        "temperature": 0,
        "text": " And let's run this.",
        "tokens": [
          51756,
          400,
          718,
          311,
          1190,
          341,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2754.78,
        "id": 894,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2752.54,
        "temperature": 0,
        "text": " Undefined, undefined, undefined.",
        "tokens": [
          50400,
          2719,
          5666,
          2001,
          11,
          674,
          5666,
          2001,
          11,
          674,
          5666,
          2001,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2759.34,
        "id": 895,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2754.78,
        "temperature": 0,
        "text": " So get, I suppose, is not the actual function.",
        "tokens": [
          50512,
          407,
          483,
          11,
          286,
          7297,
          11,
          307,
          406,
          264,
          3539,
          2445,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2763.02,
        "id": 896,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2760.1400000000003,
        "temperature": 0,
        "text": " Oh, and I said table because I need to say row.",
        "tokens": [
          50780,
          876,
          11,
          293,
          286,
          848,
          3199,
          570,
          286,
          643,
          281,
          584,
          5386,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2764.7000000000003,
        "id": 897,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2763.02,
        "temperature": 0,
        "text": " Probably all of you are noticing this.",
        "tokens": [
          50924,
          9210,
          439,
          295,
          291,
          366,
          21814,
          341,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2767.34,
        "id": 898,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2764.7000000000003,
        "temperature": 0,
        "text": " I see in the chat that everyone noticed this like five minutes ago.",
        "tokens": [
          51008,
          286,
          536,
          294,
          264,
          5081,
          300,
          1518,
          5694,
          341,
          411,
          1732,
          2077,
          2057,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2772.38,
        "id": 899,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2767.98,
        "temperature": 0,
        "text": " So row.get because of course what I want to do is get column 0 from that row,",
        "tokens": [
          51172,
          407,
          5386,
          13,
          847,
          570,
          295,
          1164,
          437,
          286,
          528,
          281,
          360,
          307,
          483,
          7738,
          1958,
          490,
          300,
          5386,
          11,
          51392
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2773.5800000000004,
        "id": 900,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2772.38,
        "temperature": 0,
        "text": " not from the table.",
        "tokens": [
          51392,
          406,
          490,
          264,
          3199,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2774.3,
        "id": 901,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2773.5800000000004,
        "temperature": 0,
        "text": " Sorry about that.",
        "tokens": [
          51452,
          4919,
          466,
          300,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2776.38,
        "id": 902,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2775.1000000000004,
        "temperature": 0,
        "text": " And then we can see.",
        "tokens": [
          51528,
          400,
          550,
          321,
          393,
          536,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2779.02,
        "id": 903,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2776.38,
        "temperature": 0,
        "text": " Now, why do I still see some undefines?",
        "tokens": [
          51592,
          823,
          11,
          983,
          360,
          286,
          920,
          536,
          512,
          674,
          5666,
          1652,
          30,
          51724
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2780.1400000000003,
        "id": 904,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2779.02,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51724,
          876,
          11,
          574,
          412,
          341,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.1766031705416166,
        "compression_ratio": 1.6691449814126393,
        "end": 2781.5,
        "id": 905,
        "no_speech_prob": 0.0005703133065253496,
        "seek": 275182,
        "start": 2780.1400000000003,
        "temperature": 0,
        "text": " It didn't split it.",
        "tokens": [
          51780,
          467,
          994,
          380,
          7472,
          309,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2785.1800000000003,
        "id": 906,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2782.3,
        "temperature": 0,
        "text": " It wasn't able to do it by tabs.",
        "tokens": [
          50388,
          467,
          2067,
          380,
          1075,
          281,
          360,
          309,
          538,
          20743,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2786.3,
        "id": 907,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2785.1800000000003,
        "temperature": 0,
        "text": " That's so sad.",
        "tokens": [
          50532,
          663,
          311,
          370,
          4227,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2787.5800000000004,
        "id": 908,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2787.02,
        "temperature": 0,
        "text": " Load table.",
        "tokens": [
          50624,
          48408,
          3199,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2789.7400000000002,
        "id": 909,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2787.5800000000004,
        "temperature": 0,
        "text": " So this might be a p5.js bug.",
        "tokens": [
          50652,
          407,
          341,
          1062,
          312,
          257,
          280,
          20,
          13,
          25530,
          7426,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2793.9,
        "id": 910,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2790.78,
        "temperature": 0,
        "text": " Or I might just be wrong about how this table is formatted.",
        "tokens": [
          50812,
          1610,
          286,
          1062,
          445,
          312,
          2085,
          466,
          577,
          341,
          3199,
          307,
          1254,
          32509,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2799.26,
        "id": 911,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2793.9,
        "temperature": 0,
        "text": " Or I might need to give it a file extension.",
        "tokens": [
          50968,
          1610,
          286,
          1062,
          643,
          281,
          976,
          309,
          257,
          3991,
          10320,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2799.9,
        "id": 912,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2799.26,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          51236,
          961,
          311,
          853,
          300,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2801.02,
        "id": 913,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2799.9,
        "temperature": 0,
        "text": " Oh, look at that.",
        "tokens": [
          51268,
          876,
          11,
          574,
          412,
          300,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2801.82,
        "id": 914,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2801.02,
        "temperature": 0,
        "text": " That worked.",
        "tokens": [
          51324,
          663,
          2732,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2808.46,
        "id": 915,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2801.82,
        "temperature": 0,
        "text": " So what I needed to do is because it's.txt, p5 couldn't auto detect that it was a tab",
        "tokens": [
          51364,
          407,
          437,
          286,
          2978,
          281,
          360,
          307,
          570,
          309,
          311,
          2411,
          83,
          734,
          11,
          280,
          20,
          2809,
          380,
          8399,
          5531,
          300,
          309,
          390,
          257,
          4421,
          51696
        ]
      },
      {
        "avg_logprob": -0.1551973780647653,
        "compression_ratio": 1.573394495412844,
        "end": 2809.9,
        "id": 916,
        "no_speech_prob": 0.00004469403575058095,
        "seek": 278182,
        "start": 2808.46,
        "temperature": 0,
        "text": " delimited file.",
        "tokens": [
          51696,
          1103,
          332,
          1226,
          3991,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2815.5,
        "id": 917,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2809.9,
        "temperature": 0,
        "text": " So I'm able to give it a second argument and give it an extension tsv to tell it that it",
        "tokens": [
          50364,
          407,
          286,
          478,
          1075,
          281,
          976,
          309,
          257,
          1150,
          6770,
          293,
          976,
          309,
          364,
          10320,
          35492,
          85,
          281,
          980,
          309,
          300,
          309,
          50644
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2816.94,
        "id": 918,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2815.5,
        "temperature": 0,
        "text": " is a tab separated file.",
        "tokens": [
          50644,
          307,
          257,
          4421,
          12005,
          3991,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2820.06,
        "id": 919,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2816.94,
        "temperature": 0,
        "text": " If it were a comma separated file, meaning commas in between instead of tabs,",
        "tokens": [
          50716,
          759,
          309,
          645,
          257,
          22117,
          12005,
          3991,
          11,
          3620,
          800,
          296,
          294,
          1296,
          2602,
          295,
          20743,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2823.9,
        "id": 920,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2821.34,
        "temperature": 0,
        "text": " then that's what I had before.",
        "tokens": [
          50936,
          550,
          300,
          311,
          437,
          286,
          632,
          949,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2826.54,
        "id": 921,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2823.9,
        "temperature": 0,
        "text": " It was getting the whole thing, and then there's no second column.",
        "tokens": [
          51064,
          467,
          390,
          1242,
          264,
          1379,
          551,
          11,
          293,
          550,
          456,
          311,
          572,
          1150,
          7738,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2827.98,
        "id": 922,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2826.54,
        "temperature": 0,
        "text": " OK, so that fixed that.",
        "tokens": [
          51196,
          2264,
          11,
          370,
          300,
          6806,
          300,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2829.5,
        "id": 923,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2827.98,
        "temperature": 0,
        "text": " OK, so tsv.",
        "tokens": [
          51268,
          2264,
          11,
          370,
          35492,
          85,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2829.82,
        "id": 924,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2829.5,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51344,
          3769,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2833.98,
        "id": 925,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2829.82,
        "temperature": 0,
        "text": " So now what I want to do is I'm going to make an object called the afin.",
        "tokens": [
          51360,
          407,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          652,
          364,
          2657,
          1219,
          264,
          257,
          5194,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.1877768523711011,
        "compression_ratio": 1.6870229007633588,
        "end": 2837.34,
        "id": 926,
        "no_speech_prob": 0.00009314579074271023,
        "seek": 280990,
        "start": 2835.02,
        "temperature": 0,
        "text": " And it's an empty JavaScript object.",
        "tokens": [
          51620,
          400,
          309,
          311,
          364,
          6707,
          15778,
          2657,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2842.3,
        "id": 927,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2837.34,
        "temperature": 0,
        "text": " And what I want to do is I want to say I want to put in that object the word as the key,",
        "tokens": [
          50364,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          286,
          528,
          281,
          829,
          294,
          300,
          2657,
          264,
          1349,
          382,
          264,
          2141,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2843.98,
        "id": 928,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2842.94,
        "temperature": 0,
        "text": " the number as the value.",
        "tokens": [
          50644,
          264,
          1230,
          382,
          264,
          2158,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2845.7400000000002,
        "id": 929,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2843.98,
        "temperature": 0,
        "text": " Word is the key, number is the value.",
        "tokens": [
          50696,
          8725,
          307,
          264,
          2141,
          11,
          1230,
          307,
          264,
          2158,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2849.6600000000003,
        "id": 930,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2845.7400000000002,
        "temperature": 0,
        "text": " So I'm going to say afin word equals score.",
        "tokens": [
          50784,
          407,
          286,
          478,
          516,
          281,
          584,
          3238,
          259,
          1349,
          6915,
          6175,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2853.1000000000004,
        "id": 931,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2850.2200000000003,
        "temperature": 0,
        "text": " And then at the very end, I'm going to say console.log afin.",
        "tokens": [
          51008,
          400,
          550,
          412,
          264,
          588,
          917,
          11,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          3238,
          259,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2855.7400000000002,
        "id": 932,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2854.3,
        "temperature": 0,
        "text": " And we're going to look at this.",
        "tokens": [
          51212,
          400,
          321,
          434,
          516,
          281,
          574,
          412,
          341,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2856.7000000000003,
        "id": 933,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2855.7400000000002,
        "temperature": 0,
        "text": " And we can see, look at that.",
        "tokens": [
          51284,
          400,
          321,
          393,
          536,
          11,
          574,
          412,
          300,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2858.3,
        "id": 934,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2857.42,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51368,
          821,
          309,
          307,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2863.6600000000003,
        "id": 935,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2858.3,
        "temperature": 0,
        "text": " There now is that afin list in a JavaScript object.",
        "tokens": [
          51412,
          821,
          586,
          307,
          300,
          3238,
          259,
          1329,
          294,
          257,
          15778,
          2657,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.17684949528087268,
        "compression_ratio": 1.8847926267281105,
        "end": 2864.7000000000003,
        "id": 936,
        "no_speech_prob": 0.0002868533774744719,
        "seek": 283734,
        "start": 2863.6600000000003,
        "temperature": 0,
        "text": " Every word with a score.",
        "tokens": [
          51680,
          2048,
          1349,
          365,
          257,
          6175,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2867.18,
        "id": 937,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2864.7,
        "temperature": 0,
        "text": " And I'm kind of scrolling through it just to see if anything broke,",
        "tokens": [
          50364,
          400,
          286,
          478,
          733,
          295,
          29053,
          807,
          309,
          445,
          281,
          536,
          498,
          1340,
          6902,
          11,
          50488
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2870.2999999999997,
        "id": 938,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2867.18,
        "temperature": 0,
        "text": " like if there was a weird apostrophe or something that broke it.",
        "tokens": [
          50488,
          411,
          498,
          456,
          390,
          257,
          3657,
          19484,
          27194,
          420,
          746,
          300,
          6902,
          309,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2871.66,
        "id": 939,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2870.2999999999997,
        "temperature": 0,
        "text": " But it doesn't look like it did.",
        "tokens": [
          50644,
          583,
          309,
          1177,
          380,
          574,
          411,
          309,
          630,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2878.62,
        "id": 940,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2872.2999999999997,
        "temperature": 0,
        "text": " And just to remind you, remember, if I have an object and I say object something.x equals 100,",
        "tokens": [
          50744,
          400,
          445,
          281,
          4160,
          291,
          11,
          1604,
          11,
          498,
          286,
          362,
          364,
          2657,
          293,
          286,
          584,
          2657,
          746,
          13,
          87,
          6915,
          2319,
          11,
          51060
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2879.66,
        "id": 941,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2878.62,
        "temperature": 0,
        "text": " this is the same.",
        "tokens": [
          51060,
          341,
          307,
          264,
          912,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2881.1,
        "id": 942,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2879.66,
        "temperature": 0,
        "text": " My laptop's about to fall over.",
        "tokens": [
          51112,
          1222,
          10732,
          311,
          466,
          281,
          2100,
          670,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2882.7799999999997,
        "id": 943,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2881.1,
        "temperature": 0,
        "text": " As saying this.",
        "tokens": [
          51184,
          1018,
          1566,
          341,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2889.8199999999997,
        "id": 944,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2884.8599999999997,
        "temperature": 0,
        "text": " So since these words are all strings, and I want those to be the keys,",
        "tokens": [
          51372,
          407,
          1670,
          613,
          2283,
          366,
          439,
          13985,
          11,
          293,
          286,
          528,
          729,
          281,
          312,
          264,
          9317,
          11,
          51620
        ]
      },
      {
        "avg_logprob": -0.21060374288847952,
        "compression_ratio": 1.6369863013698631,
        "end": 2893.98,
        "id": 945,
        "no_speech_prob": 0.18240822851657867,
        "seek": 286470,
        "start": 2889.8199999999997,
        "temperature": 0,
        "text": " the properties of the objects, I need to pass them in using this bracket syntax.",
        "tokens": [
          51620,
          264,
          7221,
          295,
          264,
          6565,
          11,
          286,
          643,
          281,
          1320,
          552,
          294,
          1228,
          341,
          16904,
          28431,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2896.94,
        "id": 946,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2893.98,
        "temperature": 0,
        "text": " I can't do it like this because it's not a variable name at this point.",
        "tokens": [
          50364,
          286,
          393,
          380,
          360,
          309,
          411,
          341,
          570,
          309,
          311,
          406,
          257,
          7006,
          1315,
          412,
          341,
          935,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2898.3,
        "id": 947,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2896.94,
        "temperature": 0,
        "text": " It's coming in as a string.",
        "tokens": [
          50512,
          467,
          311,
          1348,
          294,
          382,
          257,
          6798,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2899.02,
        "id": 948,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2898.3,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50580,
          2264,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2903.26,
        "id": 949,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2899.02,
        "temperature": 0,
        "text": " So now that that's done, one of the lovely things about using p5 is I can just say save",
        "tokens": [
          50616,
          407,
          586,
          300,
          300,
          311,
          1096,
          11,
          472,
          295,
          264,
          7496,
          721,
          466,
          1228,
          280,
          20,
          307,
          286,
          393,
          445,
          584,
          3155,
          50828
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2909.7400000000002,
        "id": 950,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2904.62,
        "temperature": 0,
        "text": " afin111.json afin.",
        "tokens": [
          50896,
          3238,
          259,
          5348,
          16,
          13,
          73,
          3015,
          3238,
          259,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2913.18,
        "id": 951,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2910.78,
        "temperature": 0,
        "text": " And I'm saying it's with two n's, I think, right?",
        "tokens": [
          51204,
          400,
          286,
          478,
          1566,
          309,
          311,
          365,
          732,
          297,
          311,
          11,
          286,
          519,
          11,
          558,
          30,
          51324
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2913.5,
        "id": 952,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2913.18,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51324,
          865,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2918.62,
        "id": 953,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2914.14,
        "temperature": 0,
        "text": " So now I can just save that file, save that data as a JSON file.",
        "tokens": [
          51372,
          407,
          586,
          286,
          393,
          445,
          3155,
          300,
          3991,
          11,
          3155,
          300,
          1412,
          382,
          257,
          31828,
          3991,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2921.18,
        "id": 954,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2918.62,
        "temperature": 0,
        "text": " And it should auto download that to me in the browser.",
        "tokens": [
          51596,
          400,
          309,
          820,
          8399,
          5484,
          300,
          281,
          385,
          294,
          264,
          11185,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.18599768245921416,
        "compression_ratio": 1.59765625,
        "end": 2922.86,
        "id": 955,
        "no_speech_prob": 0.0002002733526751399,
        "seek": 289398,
        "start": 2921.18,
        "temperature": 0,
        "text": " So let's run it again.",
        "tokens": [
          51724,
          407,
          718,
          311,
          1190,
          309,
          797,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2925.02,
        "id": 956,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2922.86,
        "temperature": 0,
        "text": " Oh, file name index of.",
        "tokens": [
          50364,
          876,
          11,
          3991,
          1315,
          8186,
          295,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2925.82,
        "id": 957,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2925.02,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50472,
          2264,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2929.1,
        "id": 958,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2925.82,
        "temperature": 0,
        "text": " So I think maybe I'm supposed to say it the other way around.",
        "tokens": [
          50512,
          407,
          286,
          519,
          1310,
          286,
          478,
          3442,
          281,
          584,
          309,
          264,
          661,
          636,
          926,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2930.94,
        "id": 959,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2929.1,
        "temperature": 0,
        "text": " First, the data and then the file name.",
        "tokens": [
          50676,
          2386,
          11,
          264,
          1412,
          293,
          550,
          264,
          3991,
          1315,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2933.1800000000003,
        "id": 960,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2931.9,
        "temperature": 0,
        "text": " That seems right.",
        "tokens": [
          50816,
          663,
          2544,
          558,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2933.98,
        "id": 961,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2933.1800000000003,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50880,
          821,
          321,
          352,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2935.26,
        "id": 962,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2933.98,
        "temperature": 0,
        "text": " And you can see my browser.",
        "tokens": [
          50920,
          400,
          291,
          393,
          536,
          452,
          11185,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2936.54,
        "id": 963,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2935.26,
        "temperature": 0,
        "text": " I'm standing in front of it.",
        "tokens": [
          50984,
          286,
          478,
          4877,
          294,
          1868,
          295,
          309,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2944.94,
        "id": 964,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2936.54,
        "temperature": 0,
        "text": " But my browser auto downloaded this file called afinb because I must have put that in my code",
        "tokens": [
          51048,
          583,
          452,
          11185,
          8399,
          21748,
          341,
          3991,
          1219,
          3238,
          259,
          65,
          570,
          286,
          1633,
          362,
          829,
          300,
          294,
          452,
          3089,
          51468
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2945.58,
        "id": 965,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2944.94,
        "temperature": 0,
        "text": " by accident.",
        "tokens": [
          51468,
          538,
          6398,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2948.06,
        "id": 966,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2946.86,
        "temperature": 0,
        "text": " Where's my code?",
        "tokens": [
          51564,
          2305,
          311,
          452,
          3089,
          30,
          51624
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2948.3,
        "id": 967,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2948.06,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51624,
          865,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2948.6200000000003,
        "id": 968,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2948.3,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51636,
          45263,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2949.98,
        "id": 969,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2949.26,
        "temperature": 0,
        "text": " Two n's there.",
        "tokens": [
          51684,
          4453,
          297,
          311,
          456,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.21439178007885926,
        "compression_ratio": 1.5461538461538462,
        "end": 2951.02,
        "id": 970,
        "no_speech_prob": 0.0005527758621610701,
        "seek": 292286,
        "start": 2949.98,
        "temperature": 0,
        "text": " But that doesn't really matter.",
        "tokens": [
          51720,
          583,
          300,
          1177,
          380,
          534,
          1871,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2960.62,
        "id": 971,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2951.02,
        "temperature": 0,
        "text": " The point is now I have this file, afin, and I can put that, whoops, I can put that here",
        "tokens": [
          50364,
          440,
          935,
          307,
          586,
          286,
          362,
          341,
          3991,
          11,
          3238,
          259,
          11,
          293,
          286,
          393,
          829,
          300,
          11,
          567,
          3370,
          11,
          286,
          393,
          829,
          300,
          510,
          50844
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2962.54,
        "id": 972,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2961.5,
        "temperature": 0,
        "text": " instead of the text file.",
        "tokens": [
          50888,
          2602,
          295,
          264,
          2487,
          3991,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2964.06,
        "id": 973,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2962.54,
        "temperature": 0,
        "text": " So let me rename it to fix it.",
        "tokens": [
          50940,
          407,
          718,
          385,
          36741,
          309,
          281,
          3191,
          309,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2971.9,
        "id": 974,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2965.18,
        "temperature": 0,
        "text": " So what I did just is now instead of this text file, I now converted that to a JSON file.",
        "tokens": [
          51072,
          407,
          437,
          286,
          630,
          445,
          307,
          586,
          2602,
          295,
          341,
          2487,
          3991,
          11,
          286,
          586,
          16424,
          300,
          281,
          257,
          31828,
          3991,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2973.2599999999998,
        "id": 975,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2971.9,
        "temperature": 0,
        "text": " And of course, it won't.",
        "tokens": [
          51408,
          400,
          295,
          1164,
          11,
          309,
          1582,
          380,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2976.54,
        "id": 976,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2973.9,
        "temperature": 0,
        "text": " Oh, but this is my, I can open it right through here.",
        "tokens": [
          51508,
          876,
          11,
          457,
          341,
          307,
          452,
          11,
          286,
          393,
          1269,
          309,
          558,
          807,
          510,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.21295244043523615,
        "compression_ratio": 1.6521739130434783,
        "end": 2978.78,
        "id": 977,
        "no_speech_prob": 0.0001535619085188955,
        "seek": 295102,
        "start": 2977.5,
        "temperature": 0,
        "text": " And we can see there it is.",
        "tokens": [
          51688,
          400,
          321,
          393,
          536,
          456,
          309,
          307,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 2984.2200000000003,
        "id": 978,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 2978.78,
        "temperature": 0,
        "text": " So this is great because now to do the text analysis, the sentiment analysis, it's going",
        "tokens": [
          50364,
          407,
          341,
          307,
          869,
          570,
          586,
          281,
          360,
          264,
          2487,
          5215,
          11,
          264,
          16149,
          5215,
          11,
          309,
          311,
          516,
          50636
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 2987.42,
        "id": 979,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 2984.2200000000003,
        "temperature": 0,
        "text": " to be so much easier if I already have this data in a JSON file.",
        "tokens": [
          50636,
          281,
          312,
          370,
          709,
          3571,
          498,
          286,
          1217,
          362,
          341,
          1412,
          294,
          257,
          31828,
          3991,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 2991.26,
        "id": 980,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 2987.42,
        "temperature": 0,
        "text": " And by the way, you could probably Google afin111 JSON.",
        "tokens": [
          50796,
          400,
          538,
          264,
          636,
          11,
          291,
          727,
          1391,
          3329,
          3238,
          259,
          5348,
          16,
          31828,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 2995.26,
        "id": 981,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 2992.46,
        "temperature": 0,
        "text": " Countless people all over the world and internet have done this already.",
        "tokens": [
          51048,
          5247,
          1832,
          561,
          439,
          670,
          264,
          1002,
          293,
          4705,
          362,
          1096,
          341,
          1217,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 3001.9,
        "id": 982,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 2995.26,
        "temperature": 0,
        "text": " But I thought it was a useful demonstration to show in p5 how to convert between one format",
        "tokens": [
          51188,
          583,
          286,
          1194,
          309,
          390,
          257,
          4420,
          16520,
          281,
          855,
          294,
          280,
          20,
          577,
          281,
          7620,
          1296,
          472,
          7877,
          51520
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 3002.38,
        "id": 983,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 3001.9,
        "temperature": 0,
        "text": " to another.",
        "tokens": [
          51520,
          281,
          1071,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.20483676011000224,
        "compression_ratio": 1.587248322147651,
        "end": 3007.5,
        "id": 984,
        "no_speech_prob": 0.000010289505553373601,
        "seek": 297878,
        "start": 3003.98,
        "temperature": 0,
        "text": " Let's do the, so all of you who were like, I wanted to watch the video about sentiment",
        "tokens": [
          51624,
          961,
          311,
          360,
          264,
          11,
          370,
          439,
          295,
          291,
          567,
          645,
          411,
          11,
          286,
          1415,
          281,
          1159,
          264,
          960,
          466,
          16149,
          51800
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3008,
        "id": 985,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3007.5,
        "temperature": 0,
        "text": " analysis.",
        "tokens": [
          50364,
          5215,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3013.5,
        "id": 986,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3009.58,
        "temperature": 0,
        "text": " Maybe I can put like a little time code in this challenge of like skip ahead to the sentiment",
        "tokens": [
          50468,
          2704,
          286,
          393,
          829,
          411,
          257,
          707,
          565,
          3089,
          294,
          341,
          3430,
          295,
          411,
          10023,
          2286,
          281,
          264,
          16149,
          50664
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3014.06,
        "id": 987,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3013.5,
        "temperature": 0,
        "text": " analysis part.",
        "tokens": [
          50664,
          5215,
          644,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3017.02,
        "id": 988,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3014.06,
        "temperature": 0,
        "text": " So now we're actually ready to do the sentiment analysis.",
        "tokens": [
          50692,
          407,
          586,
          321,
          434,
          767,
          1919,
          281,
          360,
          264,
          16149,
          5215,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3023.42,
        "id": 989,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3018.3,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to just actually save this as the JavaScript file.",
        "tokens": [
          50904,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          445,
          767,
          3155,
          341,
          382,
          264,
          15778,
          3991,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3025.1,
        "id": 990,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3023.42,
        "temperature": 0,
        "text": " I'm going to call it convert.js.",
        "tokens": [
          51160,
          286,
          478,
          516,
          281,
          818,
          309,
          7620,
          13,
          25530,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2006240530112355,
        "compression_ratio": 1.7488151658767772,
        "end": 3033.74,
        "id": 991,
        "no_speech_prob": 0.00007141881360439584,
        "seek": 300750,
        "start": 3026.94,
        "temperature": 0,
        "text": " And I'm just going to like get rid of everything and start over because",
        "tokens": [
          51336,
          400,
          286,
          478,
          445,
          516,
          281,
          411,
          483,
          3973,
          295,
          1203,
          293,
          722,
          670,
          570,
          51676
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3042.06,
        "id": 992,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3037.98,
        "temperature": 0,
        "text": " I don't, what am I trying to say here?",
        "tokens": [
          50388,
          286,
          500,
          380,
          11,
          437,
          669,
          286,
          1382,
          281,
          584,
          510,
          30,
          50592
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3046.14,
        "id": 993,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3043.18,
        "temperature": 0,
        "text": " I don't need to ever do that again.",
        "tokens": [
          50648,
          286,
          500,
          380,
          643,
          281,
          1562,
          360,
          300,
          797,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3047.82,
        "id": 994,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3046.14,
        "temperature": 0,
        "text": " I've already converted it to JSON.",
        "tokens": [
          50796,
          286,
          600,
          1217,
          16424,
          309,
          281,
          31828,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3050.06,
        "id": 995,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3047.82,
        "temperature": 0,
        "text": " But it's good to save that code if you want to take a look at it.",
        "tokens": [
          50880,
          583,
          309,
          311,
          665,
          281,
          3155,
          300,
          3089,
          498,
          291,
          528,
          281,
          747,
          257,
          574,
          412,
          309,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3051.58,
        "id": 996,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3050.06,
        "temperature": 0,
        "text": " OK, so here we go.",
        "tokens": [
          50992,
          2264,
          11,
          370,
          510,
          321,
          352,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3052.3,
        "id": 997,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3051.58,
        "temperature": 0,
        "text": " Part two.",
        "tokens": [
          51068,
          4100,
          732,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3054.94,
        "id": 998,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3052.3,
        "temperature": 0,
        "text": " I don't know if there should be two videos just in case.",
        "tokens": [
          51104,
          286,
          500,
          380,
          458,
          498,
          456,
          820,
          312,
          732,
          2145,
          445,
          294,
          1389,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3056.46,
        "id": 999,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3055.74,
        "temperature": 0,
        "text": " Where's my bell?",
        "tokens": [
          51276,
          2305,
          311,
          452,
          4549,
          30,
          51312
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3061.82,
        "id": 1000,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3059.1,
        "temperature": 0,
        "text": " Part two of afin111 sentiment analysis.",
        "tokens": [
          51444,
          4100,
          732,
          295,
          3238,
          259,
          5348,
          16,
          16149,
          5215,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.19944214198900306,
        "compression_ratio": 1.5321100917431192,
        "end": 3063.42,
        "id": 1001,
        "no_speech_prob": 0.00026947871083393693,
        "seek": 303750,
        "start": 3062.7,
        "temperature": 0,
        "text": " OK, here we go.",
        "tokens": [
          51624,
          2264,
          11,
          510,
          321,
          352,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3070.7000000000003,
        "id": 1002,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3063.42,
        "temperature": 0,
        "text": " So the first thing that I need to do is I want to load this file.",
        "tokens": [
          50364,
          407,
          264,
          700,
          551,
          300,
          286,
          643,
          281,
          360,
          307,
          286,
          528,
          281,
          3677,
          341,
          3991,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3075.1,
        "id": 1003,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3070.7000000000003,
        "temperature": 0,
        "text": " So let's make a variable.",
        "tokens": [
          50728,
          407,
          718,
          311,
          652,
          257,
          7006,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3076.3,
        "id": 1004,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3075.1,
        "temperature": 0,
        "text": " I'm going to call it afin again.",
        "tokens": [
          50948,
          286,
          478,
          516,
          281,
          818,
          309,
          3238,
          259,
          797,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3082.62,
        "id": 1005,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3077.02,
        "temperature": 0,
        "text": " afin equals load JSON, afin111.json.",
        "tokens": [
          51044,
          3238,
          259,
          6915,
          3677,
          31828,
          11,
          3238,
          259,
          5348,
          16,
          13,
          73,
          3015,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3084.38,
        "id": 1006,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3082.62,
        "temperature": 0,
        "text": " And I just want to see that that worked.",
        "tokens": [
          51324,
          400,
          286,
          445,
          528,
          281,
          536,
          300,
          300,
          2732,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3086.38,
        "id": 1007,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3084.38,
        "temperature": 0,
        "text": " I'm going to say console.log afin.",
        "tokens": [
          51412,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          3238,
          259,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3087.98,
        "id": 1008,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3086.38,
        "temperature": 0,
        "text": " OK, so we're starting up.",
        "tokens": [
          51512,
          2264,
          11,
          370,
          321,
          434,
          2891,
          493,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3089.5,
        "id": 1009,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3087.98,
        "temperature": 0,
        "text": " And I just want to see, great.",
        "tokens": [
          51592,
          400,
          286,
          445,
          528,
          281,
          536,
          11,
          869,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.1678261244592588,
        "compression_ratio": 1.6589861751152073,
        "end": 3092.2200000000003,
        "id": 1010,
        "no_speech_prob": 0.00037998161860741675,
        "seek": 306342,
        "start": 3089.5,
        "temperature": 0,
        "text": " So we can see that that list has been loaded, which is wonderful.",
        "tokens": [
          51668,
          407,
          321,
          393,
          536,
          300,
          300,
          1329,
          575,
          668,
          13210,
          11,
          597,
          307,
          3715,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.22749611183449073,
        "compression_ratio": 1.256,
        "end": 3095.8999999999996,
        "id": 1011,
        "no_speech_prob": 0.00005475956277223304,
        "seek": 309222,
        "start": 3092.22,
        "temperature": 0,
        "text": " Now, the next thing I need is I want to have a place.",
        "tokens": [
          50364,
          823,
          11,
          264,
          958,
          551,
          286,
          643,
          307,
          286,
          528,
          281,
          362,
          257,
          1081,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.22749611183449073,
        "compression_ratio": 1.256,
        "end": 3099.8199999999997,
        "id": 1012,
        "no_speech_prob": 0.00005475956277223304,
        "seek": 309222,
        "start": 3098.06,
        "temperature": 0,
        "text": " So let's add some stuff here.",
        "tokens": [
          50656,
          407,
          718,
          311,
          909,
          512,
          1507,
          510,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.22749611183449073,
        "compression_ratio": 1.256,
        "end": 3102.54,
        "id": 1013,
        "no_speech_prob": 0.00005475956277223304,
        "seek": 309222,
        "start": 3099.8199999999997,
        "temperature": 0,
        "text": " afin sentiment demo.",
        "tokens": [
          50744,
          3238,
          259,
          16149,
          10723,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.22749611183449073,
        "compression_ratio": 1.256,
        "end": 3107.4199999999996,
        "id": 1014,
        "no_speech_prob": 0.00005475956277223304,
        "seek": 309222,
        "start": 3105.18,
        "temperature": 0,
        "text": " Let's say type here.",
        "tokens": [
          51012,
          961,
          311,
          584,
          2010,
          510,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.22749611183449073,
        "compression_ratio": 1.256,
        "end": 3115.74,
        "id": 1015,
        "no_speech_prob": 0.00005475956277223304,
        "seek": 309222,
        "start": 3109.74,
        "temperature": 0,
        "text": " And make a text area like this.",
        "tokens": [
          51240,
          400,
          652,
          257,
          2487,
          1859,
          411,
          341,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.22616843102683484,
        "compression_ratio": 1.5034013605442176,
        "end": 3124.2999999999997,
        "id": 1016,
        "no_speech_prob": 0.01590592786669731,
        "seek": 311574,
        "start": 3115.74,
        "temperature": 0,
        "text": " Text area id equals text, text area.",
        "tokens": [
          50364,
          18643,
          1859,
          4496,
          6915,
          2487,
          11,
          2487,
          1859,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.22616843102683484,
        "compression_ratio": 1.5034013605442176,
        "end": 3133.3399999999997,
        "id": 1017,
        "no_speech_prob": 0.01590592786669731,
        "seek": 311574,
        "start": 3127.66,
        "temperature": 0,
        "text": " OK, so now I should have on the HTML page, we should see, whoops.",
        "tokens": [
          50960,
          2264,
          11,
          370,
          586,
          286,
          820,
          362,
          322,
          264,
          17995,
          3028,
          11,
          321,
          820,
          536,
          11,
          567,
          3370,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.22616843102683484,
        "compression_ratio": 1.5034013605442176,
        "end": 3135.4199999999996,
        "id": 1018,
        "no_speech_prob": 0.01590592786669731,
        "seek": 311574,
        "start": 3133.9799999999996,
        "temperature": 0,
        "text": " I definitely did something wrong.",
        "tokens": [
          51276,
          286,
          2138,
          630,
          746,
          2085,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.22616843102683484,
        "compression_ratio": 1.5034013605442176,
        "end": 3139.74,
        "id": 1019,
        "no_speech_prob": 0.01590592786669731,
        "seek": 311574,
        "start": 3136.2999999999997,
        "temperature": 0,
        "text": " Text area, text area.",
        "tokens": [
          51392,
          18643,
          1859,
          11,
          2487,
          1859,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22616843102683484,
        "compression_ratio": 1.5034013605442176,
        "end": 3141.3399999999997,
        "id": 1020,
        "no_speech_prob": 0.01590592786669731,
        "seek": 311574,
        "start": 3140.54,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51604,
          821,
          321,
          352,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.22616843102683484,
        "compression_ratio": 1.5034013605442176,
        "end": 3145.4199999999996,
        "id": 1021,
        "no_speech_prob": 0.01590592786669731,
        "seek": 311574,
        "start": 3141.3399999999997,
        "temperature": 0,
        "text": " OK, so we should see, oh, a global function text.",
        "tokens": [
          51644,
          2264,
          11,
          370,
          321,
          820,
          536,
          11,
          1954,
          11,
          257,
          4338,
          2445,
          2487,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3147.02,
        "id": 1022,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3145.8199999999997,
        "temperature": 0,
        "text": " Because your code has already used it.",
        "tokens": [
          50368,
          1436,
          428,
          3089,
          575,
          1217,
          1143,
          309,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3150.7799999999997,
        "id": 1023,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3147.02,
        "temperature": 0,
        "text": " So I think it's a bad idea to, so let's call this txt.",
        "tokens": [
          50428,
          407,
          286,
          519,
          309,
          311,
          257,
          1578,
          1558,
          281,
          11,
          370,
          718,
          311,
          818,
          341,
          256,
          734,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3156.3799999999997,
        "id": 1024,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3151.9799999999996,
        "temperature": 0,
        "text": " OK, so we can see here that, now, how do I, by the way, with text area,",
        "tokens": [
          50676,
          2264,
          11,
          370,
          321,
          393,
          536,
          510,
          300,
          11,
          586,
          11,
          577,
          360,
          286,
          11,
          538,
          264,
          636,
          11,
          365,
          2487,
          1859,
          11,
          50896
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3159.2599999999998,
        "id": 1025,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3156.3799999999997,
        "temperature": 0,
        "text": " I kind of just want it to already start as like a slightly bigger thing,",
        "tokens": [
          50896,
          286,
          733,
          295,
          445,
          528,
          309,
          281,
          1217,
          722,
          382,
          411,
          257,
          4748,
          3801,
          551,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3160.22,
        "id": 1026,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3159.2599999999998,
        "temperature": 0,
        "text": " which is kind of unnecessary.",
        "tokens": [
          51040,
          597,
          307,
          733,
          295,
          19350,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3162.06,
        "id": 1027,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3160.22,
        "temperature": 0,
        "text": " I'm going to say columns equals 50.",
        "tokens": [
          51088,
          286,
          478,
          516,
          281,
          584,
          13766,
          6915,
          2625,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3163.8199999999997,
        "id": 1028,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3163.18,
        "temperature": 0,
        "text": " So that's good.",
        "tokens": [
          51236,
          407,
          300,
          311,
          665,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3168.14,
        "id": 1029,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3164.7799999999997,
        "temperature": 0,
        "text": " And rows equals 10.",
        "tokens": [
          51316,
          400,
          13241,
          6915,
          1266,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.19155567342584784,
        "compression_ratio": 1.585551330798479,
        "end": 3174.54,
        "id": 1030,
        "no_speech_prob": 0.00024923193268477917,
        "seek": 314574,
        "start": 3168.9399999999996,
        "temperature": 0,
        "text": " OK, so now I can, the idea here is that what I want to do is as I type here,",
        "tokens": [
          51524,
          2264,
          11,
          370,
          586,
          286,
          393,
          11,
          264,
          1558,
          510,
          307,
          300,
          437,
          286,
          528,
          281,
          360,
          307,
          382,
          286,
          2010,
          510,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3178.8599999999997,
        "id": 1031,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3176.7,
        "temperature": 0,
        "text": " I am happy, how are you?",
        "tokens": [
          50412,
          286,
          669,
          2055,
          11,
          577,
          366,
          291,
          30,
          50520
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3184.2999999999997,
        "id": 1032,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3179.66,
        "temperature": 0,
        "text": " What I want to do is I want to live calculate the sentiment of this text",
        "tokens": [
          50560,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1621,
          8873,
          264,
          16149,
          295,
          341,
          2487,
          50792
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3187.18,
        "id": 1033,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3184.2999999999997,
        "temperature": 0,
        "text": " and have it appear below, as I press every single key.",
        "tokens": [
          50792,
          293,
          362,
          309,
          4204,
          2507,
          11,
          382,
          286,
          1886,
          633,
          2167,
          2141,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3190.7799999999997,
        "id": 1034,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3187.8199999999997,
        "temperature": 0,
        "text": " So first, I need to bind some sort of event.",
        "tokens": [
          50968,
          407,
          700,
          11,
          286,
          643,
          281,
          14786,
          512,
          1333,
          295,
          2280,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3194.2999999999997,
        "id": 1035,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3190.7799999999997,
        "temperature": 0,
        "text": " So I need an event for every time I type into this text area.",
        "tokens": [
          51116,
          407,
          286,
          643,
          364,
          2280,
          337,
          633,
          565,
          286,
          2010,
          666,
          341,
          2487,
          1859,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3197.58,
        "id": 1036,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3194.2999999999997,
        "temperature": 0,
        "text": " So first of all, I need access to this text area in JavaScript.",
        "tokens": [
          51292,
          407,
          700,
          295,
          439,
          11,
          286,
          643,
          2105,
          281,
          341,
          2487,
          1859,
          294,
          15778,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3199.18,
        "id": 1037,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3197.58,
        "temperature": 0,
        "text": " And I can do that with the select function.",
        "tokens": [
          51456,
          400,
          286,
          393,
          360,
          300,
          365,
          264,
          3048,
          2445,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.20696309208869934,
        "compression_ratio": 1.6591760299625469,
        "end": 3203.9799999999996,
        "id": 1038,
        "no_speech_prob": 0.00013765404582954943,
        "seek": 317574,
        "start": 3199.18,
        "temperature": 0,
        "text": " If I were jQuery, I'd use that dollar sign thing or document.getElementById",
        "tokens": [
          51536,
          759,
          286,
          645,
          361,
          35550,
          11,
          286,
          1116,
          764,
          300,
          7241,
          1465,
          551,
          420,
          4166,
          13,
          847,
          36,
          3054,
          27690,
          42739,
          51776
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3205.26,
        "id": 1039,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3204.14,
        "temperature": 0,
        "text": " with regular JavaScript.",
        "tokens": [
          50372,
          365,
          3890,
          15778,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3207.58,
        "id": 1040,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3205.9,
        "temperature": 0,
        "text": " So I called id was txt.",
        "tokens": [
          50460,
          407,
          286,
          1219,
          4496,
          390,
          256,
          734,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3215.66,
        "id": 1041,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3208.22,
        "temperature": 0,
        "text": " So what I need to do is say var txt equals select by the id txt.",
        "tokens": [
          50576,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          1374,
          256,
          734,
          6915,
          3048,
          538,
          264,
          4496,
          256,
          734,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3220.06,
        "id": 1042,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3215.66,
        "temperature": 0,
        "text": " And then the event that I want to track is called an input event.",
        "tokens": [
          50948,
          400,
          550,
          264,
          2280,
          300,
          286,
          528,
          281,
          2837,
          307,
          1219,
          364,
          4846,
          2280,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3221.5,
        "id": 1043,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3220.06,
        "temperature": 0,
        "text": " There's a changed event.",
        "tokens": [
          51168,
          821,
          311,
          257,
          3105,
          2280,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3223.34,
        "id": 1044,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3221.5,
        "temperature": 0,
        "text": " There's a change event and an input event.",
        "tokens": [
          51240,
          821,
          311,
          257,
          1319,
          2280,
          293,
          364,
          4846,
          2280,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3225.42,
        "id": 1045,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3223.34,
        "temperature": 0,
        "text": " It's a little weird in the browser.",
        "tokens": [
          51332,
          467,
          311,
          257,
          707,
          3657,
          294,
          264,
          11185,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3230.38,
        "id": 1046,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3225.42,
        "temperature": 0,
        "text": " The changed event is only if I hit like enter or tab, if I finished my action.",
        "tokens": [
          51436,
          440,
          3105,
          2280,
          307,
          787,
          498,
          286,
          2045,
          411,
          3242,
          420,
          4421,
          11,
          498,
          286,
          4335,
          452,
          3069,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2181099682319455,
        "compression_ratio": 1.7647058823529411,
        "end": 3232.94,
        "id": 1047,
        "no_speech_prob": 0.00004006361268693581,
        "seek": 320398,
        "start": 3230.38,
        "temperature": 0,
        "text": " But the input event happens anytime I press a key at all.",
        "tokens": [
          51684,
          583,
          264,
          4846,
          2280,
          2314,
          13038,
          286,
          1886,
          257,
          2141,
          412,
          439,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3236.86,
        "id": 1048,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3232.94,
        "temperature": 0,
        "text": " So text.input, I'm going to call this event typing.",
        "tokens": [
          50364,
          407,
          2487,
          13,
          259,
          2582,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          2280,
          18444,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3240.38,
        "id": 1049,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3237.58,
        "temperature": 0,
        "text": " And I'm going to say now function typing.",
        "tokens": [
          50596,
          400,
          286,
          478,
          516,
          281,
          584,
          586,
          2445,
          18444,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3245.18,
        "id": 1050,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3241.42,
        "temperature": 0,
        "text": " And I'm just going to say console.log txt.value.",
        "tokens": [
          50788,
          400,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          256,
          734,
          13,
          29155,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3249.66,
        "id": 1051,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3245.18,
        "temperature": 0,
        "text": " So what I want to see is, as I'm typing, I just want to see that I have access",
        "tokens": [
          50976,
          407,
          437,
          286,
          528,
          281,
          536,
          307,
          11,
          382,
          286,
          478,
          18444,
          11,
          286,
          445,
          528,
          281,
          536,
          300,
          286,
          362,
          2105,
          51200
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3252.3,
        "id": 1052,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3249.66,
        "temperature": 0,
        "text": " to the words that are in what I'm typing.",
        "tokens": [
          51200,
          281,
          264,
          2283,
          300,
          366,
          294,
          437,
          286,
          478,
          18444,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3257.5,
        "id": 1053,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3252.3,
        "temperature": 0,
        "text": " OK, so let's refresh this and say, hello, how are you?",
        "tokens": [
          51332,
          2264,
          11,
          370,
          718,
          311,
          15134,
          341,
          293,
          584,
          11,
          7751,
          11,
          577,
          366,
          291,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.16293979109379284,
        "compression_ratio": 1.7198067632850242,
        "end": 3259.58,
        "id": 1054,
        "no_speech_prob": 0.00015118120063561946,
        "seek": 323294,
        "start": 3257.5,
        "temperature": 0,
        "text": " And you can see that this is working.",
        "tokens": [
          51592,
          400,
          291,
          393,
          536,
          300,
          341,
          307,
          1364,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3267.1,
        "id": 1055,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3260.06,
        "temperature": 0,
        "text": " That as I type what I'm typing, every time I hit a key, it comes out in the console there.",
        "tokens": [
          50388,
          663,
          382,
          286,
          2010,
          437,
          286,
          478,
          18444,
          11,
          633,
          565,
          286,
          2045,
          257,
          2141,
          11,
          309,
          1487,
          484,
          294,
          264,
          11076,
          456,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3268.38,
        "id": 1056,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3267.1,
        "temperature": 0,
        "text": " OK, so that's perfect.",
        "tokens": [
          50740,
          2264,
          11,
          370,
          300,
          311,
          2176,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3269.58,
        "id": 1057,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3268.38,
        "temperature": 0,
        "text": " That's what I want.",
        "tokens": [
          50804,
          663,
          311,
          437,
          286,
          528,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3272.46,
        "id": 1058,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3269.58,
        "temperature": 0,
        "text": " Now I can start to calculate the sentiment score.",
        "tokens": [
          50864,
          823,
          286,
          393,
          722,
          281,
          8873,
          264,
          16149,
          6175,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3276.38,
        "id": 1059,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3273.02,
        "temperature": 0,
        "text": " So what should I, how should I calculate the sentiment score?",
        "tokens": [
          51036,
          407,
          437,
          820,
          286,
          11,
          577,
          820,
          286,
          8873,
          264,
          16149,
          6175,
          30,
          51204
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3280.2999999999997,
        "id": 1060,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3276.38,
        "temperature": 0,
        "text": " The first thing I need to do is split up the text by words.",
        "tokens": [
          51204,
          440,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          7472,
          493,
          264,
          2487,
          538,
          2283,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3282.14,
        "id": 1061,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3280.2999999999997,
        "temperature": 0,
        "text": " And I can use a regular expression.",
        "tokens": [
          51400,
          400,
          286,
          393,
          764,
          257,
          3890,
          6114,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3285.8199999999997,
        "id": 1062,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3282.14,
        "temperature": 0,
        "text": " See my videos about regular expressions using the split function.",
        "tokens": [
          51492,
          3008,
          452,
          2145,
          466,
          3890,
          15277,
          1228,
          264,
          7472,
          2445,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.14985021422891057,
        "compression_ratio": 1.8571428571428572,
        "end": 3288.7799999999997,
        "id": 1063,
        "no_speech_prob": 0.14032775163650513,
        "seek": 325958,
        "start": 3285.8199999999997,
        "temperature": 0,
        "text": " So I'm going to say var, I'm going to say tokens, I'm going to say words.",
        "tokens": [
          51676,
          407,
          286,
          478,
          516,
          281,
          584,
          1374,
          11,
          286,
          478,
          516,
          281,
          584,
          22667,
          11,
          286,
          478,
          516,
          281,
          584,
          2283,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3290.7000000000003,
        "id": 1064,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3288.86,
        "temperature": 0,
        "text": " Words equals txt.split.",
        "tokens": [
          50368,
          32857,
          6915,
          256,
          734,
          13,
          46535,
          270,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3293.7400000000002,
        "id": 1065,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3291.5,
        "temperature": 0,
        "text": " And then I want to split by a regular expression.",
        "tokens": [
          50500,
          400,
          550,
          286,
          528,
          281,
          7472,
          538,
          257,
          3890,
          6114,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3298.78,
        "id": 1066,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3293.7400000000002,
        "temperature": 0,
        "text": " And a regular expression in JavaScript is a string, like a sequence of characters,",
        "tokens": [
          50612,
          400,
          257,
          3890,
          6114,
          294,
          15778,
          307,
          257,
          6798,
          11,
          411,
          257,
          8310,
          295,
          4342,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3301.98,
        "id": 1067,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3298.78,
        "temperature": 0,
        "text": " that goes between forward slashes rather than between quotes.",
        "tokens": [
          50864,
          300,
          1709,
          1296,
          2128,
          1061,
          12808,
          2831,
          813,
          1296,
          19963,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3303.9,
        "id": 1068,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3301.98,
        "temperature": 0,
        "text": " And it defines a pattern in the text.",
        "tokens": [
          51024,
          400,
          309,
          23122,
          257,
          5102,
          294,
          264,
          2487,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3305.98,
        "id": 1069,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3303.9,
        "temperature": 0,
        "text": " And I have a whole set of videos all about regular expressions.",
        "tokens": [
          51120,
          400,
          286,
          362,
          257,
          1379,
          992,
          295,
          2145,
          439,
          466,
          3890,
          15277,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3309.7400000000002,
        "id": 1070,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3306.5400000000004,
        "temperature": 0,
        "text": " What the pattern is, what separates the words?",
        "tokens": [
          51252,
          708,
          264,
          5102,
          307,
          11,
          437,
          34149,
          264,
          2283,
          30,
          51412
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3314.94,
        "id": 1071,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3309.7400000000002,
        "temperature": 0,
        "text": " So whitespace, commas, periods, punctuation, whitespace, that sort of thing.",
        "tokens": [
          51412,
          407,
          21909,
          17940,
          11,
          800,
          296,
          11,
          13804,
          11,
          27006,
          16073,
          11,
          21909,
          17940,
          11,
          300,
          1333,
          295,
          551,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.16142542559401432,
        "compression_ratio": 1.7239057239057238,
        "end": 3317.02,
        "id": 1072,
        "no_speech_prob": 0.000027535666959010996,
        "seek": 328878,
        "start": 3314.94,
        "temperature": 0,
        "text": " Basically, I'm going to do something kind of silly and simple here.",
        "tokens": [
          51672,
          8537,
          11,
          286,
          478,
          516,
          281,
          360,
          746,
          733,
          295,
          11774,
          293,
          2199,
          510,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3322.62,
        "id": 1073,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3317.02,
        "temperature": 0,
        "text": " I'm going to say anything that's not a letter or number.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          1340,
          300,
          311,
          406,
          257,
          5063,
          420,
          1230,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3326.94,
        "id": 1074,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3322.62,
        "temperature": 0,
        "text": " And so there's, I can actually just say backslash w.",
        "tokens": [
          50644,
          400,
          370,
          456,
          311,
          11,
          286,
          393,
          767,
          445,
          584,
          646,
          10418,
          1299,
          261,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3331.42,
        "id": 1075,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3326.94,
        "temperature": 0,
        "text": " So this is slash w is any letter or number.",
        "tokens": [
          50860,
          407,
          341,
          307,
          17330,
          261,
          307,
          604,
          5063,
          420,
          1230,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3335.1,
        "id": 1076,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3331.42,
        "temperature": 0,
        "text": " And backslash capital W is any non-letter, non-number.",
        "tokens": [
          51084,
          400,
          646,
          10418,
          1299,
          4238,
          343,
          307,
          604,
          2107,
          12,
          21248,
          11,
          2107,
          12,
          41261,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3338.06,
        "id": 1077,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3335.1,
        "temperature": 0,
        "text": " And I could also say, maybe I should say or an apostrophe.",
        "tokens": [
          51268,
          400,
          286,
          727,
          611,
          584,
          11,
          1310,
          286,
          820,
          584,
          420,
          364,
          19484,
          27194,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3339.2599999999998,
        "id": 1078,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3338.06,
        "temperature": 0,
        "text": " Oh no, but that's included.",
        "tokens": [
          51416,
          876,
          572,
          11,
          457,
          300,
          311,
          5556,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3341.02,
        "id": 1079,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3339.2599999999998,
        "temperature": 0,
        "text": " No, I should have let it be or not.",
        "tokens": [
          51476,
          883,
          11,
          286,
          820,
          362,
          718,
          309,
          312,
          420,
          406,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3341.82,
        "id": 1080,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3341.02,
        "temperature": 0,
        "text": " Anyway, whatever.",
        "tokens": [
          51564,
          5684,
          11,
          2035,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.17956727450011206,
        "compression_ratio": 1.7022222222222223,
        "end": 3343.58,
        "id": 1081,
        "no_speech_prob": 0.014063304290175438,
        "seek": 331702,
        "start": 3342.62,
        "temperature": 0,
        "text": " This will be good enough for now.",
        "tokens": [
          51644,
          639,
          486,
          312,
          665,
          1547,
          337,
          586,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3349.1,
        "id": 1082,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3344.54,
        "temperature": 0,
        "text": " You could spend your life trying to define the best regular expression for splitting,",
        "tokens": [
          50412,
          509,
          727,
          3496,
          428,
          993,
          1382,
          281,
          6964,
          264,
          1151,
          3890,
          6114,
          337,
          30348,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3354.22,
        "id": 1083,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3349.1,
        "temperature": 0,
        "text": " tokenizing a sentence into words or a paragraph into sentences",
        "tokens": [
          50640,
          14862,
          3319,
          257,
          8174,
          666,
          2283,
          420,
          257,
          18865,
          666,
          16579,
          50896
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3356.22,
        "id": 1084,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3354.22,
        "temperature": 0,
        "text": " or essay into paragraphs, all that sort of thing.",
        "tokens": [
          50896,
          420,
          16238,
          666,
          48910,
          11,
          439,
          300,
          1333,
          295,
          551,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3359.34,
        "id": 1085,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3357.34,
        "temperature": 0,
        "text": " OK, so I'm going to do that.",
        "tokens": [
          51052,
          2264,
          11,
          370,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3361.34,
        "id": 1086,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3359.34,
        "temperature": 0,
        "text": " And then I'm just going to see that this works.",
        "tokens": [
          51152,
          400,
          550,
          286,
          478,
          445,
          516,
          281,
          536,
          300,
          341,
          1985,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3364.86,
        "id": 1087,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3361.34,
        "temperature": 0,
        "text": " I'm going to say console.log words just to check that.",
        "tokens": [
          51252,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          2283,
          445,
          281,
          1520,
          300,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3365.34,
        "id": 1088,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3364.86,
        "temperature": 0,
        "text": " Hello?",
        "tokens": [
          51428,
          2425,
          30,
          51452
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3367.9,
        "id": 1089,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3365.34,
        "temperature": 0,
        "text": " Oh, txt.split is not a function.",
        "tokens": [
          51452,
          876,
          11,
          256,
          734,
          13,
          46535,
          270,
          307,
          406,
          257,
          2445,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.2003768761952718,
        "compression_ratio": 1.689516129032258,
        "end": 3373.18,
        "id": 1090,
        "no_speech_prob": 0.057491522282361984,
        "seek": 334358,
        "start": 3367.9,
        "temperature": 0,
        "text": " Well, of course it's not a function because txt,",
        "tokens": [
          51580,
          1042,
          11,
          295,
          1164,
          309,
          311,
          406,
          257,
          2445,
          570,
          256,
          734,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3375.8199999999997,
        "id": 1091,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3373.8999999999996,
        "temperature": 0,
        "text": " I can't come up with variable names.",
        "tokens": [
          50400,
          286,
          393,
          380,
          808,
          493,
          365,
          7006,
          5288,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3383.98,
        "id": 1092,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3379.74,
        "temperature": 0,
        "text": " Word, text input, fine, equals txt.value.",
        "tokens": [
          50692,
          8725,
          11,
          2487,
          4846,
          11,
          2489,
          11,
          6915,
          256,
          734,
          13,
          29155,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3386.7,
        "id": 1093,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3384.8599999999997,
        "temperature": 0,
        "text": " So I want to get the value.",
        "tokens": [
          50948,
          407,
          286,
          528,
          281,
          483,
          264,
          2158,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3387.8999999999996,
        "id": 1094,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3386.7,
        "temperature": 0,
        "text": " That's the contents.",
        "tokens": [
          51040,
          663,
          311,
          264,
          15768,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3389.2599999999998,
        "id": 1095,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3387.8999999999996,
        "temperature": 0,
        "text": " And then I need to split that.",
        "tokens": [
          51100,
          400,
          550,
          286,
          643,
          281,
          7472,
          300,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3390.7799999999997,
        "id": 1096,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3389.2599999999998,
        "temperature": 0,
        "text": " So it's good that I checked that.",
        "tokens": [
          51168,
          407,
          309,
          311,
          665,
          300,
          286,
          10033,
          300,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3396.2999999999997,
        "id": 1097,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3391.8199999999997,
        "temperature": 0,
        "text": " And now I'm going to say, hello, this is a test.",
        "tokens": [
          51296,
          400,
          586,
          286,
          478,
          516,
          281,
          584,
          11,
          7751,
          11,
          341,
          307,
          257,
          1500,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3400.62,
        "id": 1098,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3396.2999999999997,
        "temperature": 0,
        "text": " So you can see as I type, it's splitting up into an array of words.",
        "tokens": [
          51520,
          407,
          291,
          393,
          536,
          382,
          286,
          2010,
          11,
          309,
          311,
          30348,
          493,
          666,
          364,
          10225,
          295,
          2283,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.2031353923761956,
        "compression_ratio": 1.5,
        "end": 3401.18,
        "id": 1099,
        "no_speech_prob": 0.00036258914042264223,
        "seek": 337318,
        "start": 3400.62,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51736,
          10246,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3403.2599999999998,
        "id": 1100,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3401.18,
        "temperature": 0,
        "text": " So now I need to iterate over that array of words.",
        "tokens": [
          50364,
          407,
          586,
          286,
          643,
          281,
          44497,
          670,
          300,
          10225,
          295,
          2283,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3411.58,
        "id": 1101,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3404.2999999999997,
        "temperature": 0,
        "text": " So I need to say for var i equals 0, i is less than words.length, i plus plus.",
        "tokens": [
          50520,
          407,
          286,
          643,
          281,
          584,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          2283,
          13,
          45390,
          11,
          741,
          1804,
          1804,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3412.94,
        "id": 1102,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3411.58,
        "temperature": 0,
        "text": " Now, here's something that's important.",
        "tokens": [
          50884,
          823,
          11,
          510,
          311,
          746,
          300,
          311,
          1021,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3415.8999999999996,
        "id": 1103,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3413.74,
        "temperature": 0,
        "text": " Let's go back to our AFIN111 list.",
        "tokens": [
          50992,
          961,
          311,
          352,
          646,
          281,
          527,
          20389,
          1464,
          5348,
          16,
          1329,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3418.3799999999997,
        "id": 1104,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3416.94,
        "temperature": 0,
        "text": " Notice something here.",
        "tokens": [
          51152,
          13428,
          746,
          510,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3421.8199999999997,
        "id": 1105,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3418.3799999999997,
        "temperature": 0,
        "text": " All of these words are entirely lowercase.",
        "tokens": [
          51224,
          1057,
          295,
          613,
          2283,
          366,
          7696,
          3126,
          9765,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.18689420700073242,
        "compression_ratio": 1.5339366515837105,
        "end": 3427.02,
        "id": 1106,
        "no_speech_prob": 2.0698377056760364e-7,
        "seek": 340118,
        "start": 3421.8199999999997,
        "temperature": 0,
        "text": " There is not a single uppercase letter in this particular word list.",
        "tokens": [
          51396,
          821,
          307,
          406,
          257,
          2167,
          11775,
          2869,
          651,
          5063,
          294,
          341,
          1729,
          1349,
          1329,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.1814483734498541,
        "compression_ratio": 1.6136363636363635,
        "end": 3432.06,
        "id": 1107,
        "no_speech_prob": 0.00019411298853810877,
        "seek": 342702,
        "start": 3427.02,
        "temperature": 0,
        "text": " So one thing I definitely want to do is when I'm in my code,",
        "tokens": [
          50364,
          407,
          472,
          551,
          286,
          2138,
          528,
          281,
          360,
          307,
          562,
          286,
          478,
          294,
          452,
          3089,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.1814483734498541,
        "compression_ratio": 1.6136363636363635,
        "end": 3438.22,
        "id": 1108,
        "no_speech_prob": 0.00019411298853810877,
        "seek": 342702,
        "start": 3432.06,
        "temperature": 0,
        "text": " the first thing I want to do is say word equals words index i dot to lowercase.",
        "tokens": [
          50616,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          307,
          584,
          1349,
          6915,
          2283,
          8186,
          741,
          5893,
          281,
          3126,
          9765,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.1814483734498541,
        "compression_ratio": 1.6136363636363635,
        "end": 3443.18,
        "id": 1109,
        "no_speech_prob": 0.00019411298853810877,
        "seek": 342702,
        "start": 3438.22,
        "temperature": 0,
        "text": " Because when I look up to see what its score is, I need a lowercase word.",
        "tokens": [
          50924,
          1436,
          562,
          286,
          574,
          493,
          281,
          536,
          437,
          1080,
          6175,
          307,
          11,
          286,
          643,
          257,
          3126,
          9765,
          1349,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.1814483734498541,
        "compression_ratio": 1.6136363636363635,
        "end": 3451.74,
        "id": 1110,
        "no_speech_prob": 0.00019411298853810877,
        "seek": 342702,
        "start": 3443.18,
        "temperature": 0,
        "text": " So now that I've done that, then I want to say, does that word exist?",
        "tokens": [
          51172,
          407,
          586,
          300,
          286,
          600,
          1096,
          300,
          11,
          550,
          286,
          528,
          281,
          584,
          11,
          775,
          300,
          1349,
          2514,
          30,
          51600
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3459.2599999999998,
        "id": 1111,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3451.74,
        "temperature": 0,
        "text": " So if AFIN word, does it exist?",
        "tokens": [
          50364,
          407,
          498,
          20389,
          1464,
          1349,
          11,
          775,
          309,
          2514,
          30,
          50740
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3460.9399999999996,
        "id": 1112,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3459.2599999999998,
        "temperature": 0,
        "text": " Now, I could use this has.",
        "tokens": [
          50740,
          823,
          11,
          286,
          727,
          764,
          341,
          575,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3463.4199999999996,
        "id": 1113,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3460.9399999999996,
        "temperature": 0,
        "text": " I should probably use the has own property thing.",
        "tokens": [
          50824,
          286,
          820,
          1391,
          764,
          264,
          575,
          1065,
          4707,
          551,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3467.4199999999996,
        "id": 1114,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3463.4199999999996,
        "temperature": 0,
        "text": " So this is me asking, let's say the word is cat.",
        "tokens": [
          50948,
          407,
          341,
          307,
          385,
          3365,
          11,
          718,
          311,
          584,
          264,
          1349,
          307,
          3857,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3472.54,
        "id": 1115,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3467.4199999999996,
        "temperature": 0,
        "text": " If cat is in the AFIN word list, I'm going to get the score for cat, like 3.",
        "tokens": [
          51148,
          759,
          3857,
          307,
          294,
          264,
          20389,
          1464,
          1349,
          1329,
          11,
          286,
          478,
          516,
          281,
          483,
          264,
          6175,
          337,
          3857,
          11,
          411,
          805,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3474.9399999999996,
        "id": 1116,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3473.3399999999997,
        "temperature": 0,
        "text": " Maybe kitten would be like 4.",
        "tokens": [
          51444,
          2704,
          39696,
          576,
          312,
          411,
          1017,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3475.3399999999997,
        "id": 1117,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3474.9399999999996,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51524,
          286,
          500,
          380,
          458,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3477.1,
        "id": 1118,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3475.9799999999996,
        "temperature": 0,
        "text": " Cats and kittens, they're equal.",
        "tokens": [
          51576,
          40902,
          293,
          47363,
          11,
          436,
          434,
          2681,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3477.58,
        "id": 1119,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3477.1,
        "temperature": 0,
        "text": " I love it.",
        "tokens": [
          51632,
          286,
          959,
          309,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.17132598812840566,
        "compression_ratio": 1.5301724137931034,
        "end": 3478.9399999999996,
        "id": 1120,
        "no_speech_prob": 0.00006709214358124882,
        "seek": 345174,
        "start": 3477.58,
        "temperature": 0,
        "text": " Anyway, what am I talking about?",
        "tokens": [
          51656,
          5684,
          11,
          437,
          669,
          286,
          1417,
          466,
          30,
          51724
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3482.78,
        "id": 1121,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3478.94,
        "temperature": 0,
        "text": " I'm so worried about offending words with their positive negative score.",
        "tokens": [
          50364,
          286,
          478,
          370,
          5804,
          466,
          766,
          2029,
          2283,
          365,
          641,
          3353,
          3671,
          6175,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3486.14,
        "id": 1122,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3482.78,
        "temperature": 0,
        "text": " It's a very strange personality I have.",
        "tokens": [
          50556,
          467,
          311,
          257,
          588,
          5861,
          9033,
          286,
          362,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3488.7000000000003,
        "id": 1123,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3486.14,
        "temperature": 0,
        "text": " OK, but there was a point to what I was saying, which is that,",
        "tokens": [
          50724,
          2264,
          11,
          457,
          456,
          390,
          257,
          935,
          281,
          437,
          286,
          390,
          1566,
          11,
          597,
          307,
          300,
          11,
          50852
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3494.38,
        "id": 1124,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3493.1,
        "temperature": 0,
        "text": " that, ah, right.",
        "tokens": [
          51072,
          300,
          11,
          3716,
          11,
          558,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3496.62,
        "id": 1125,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3494.38,
        "temperature": 0,
        "text": " If cat exists, I'll get the score, like 4.",
        "tokens": [
          51136,
          759,
          3857,
          8198,
          11,
          286,
          603,
          483,
          264,
          6175,
          11,
          411,
          1017,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3499.66,
        "id": 1126,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3496.62,
        "temperature": 0,
        "text": " If it doesn't, I'll get undefined, which will evaluate to false.",
        "tokens": [
          51248,
          759,
          309,
          1177,
          380,
          11,
          286,
          603,
          483,
          674,
          5666,
          2001,
          11,
          597,
          486,
          13059,
          281,
          7908,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3501.34,
        "id": 1127,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3499.66,
        "temperature": 0,
        "text": " But there's a weird sort of issue here.",
        "tokens": [
          51400,
          583,
          456,
          311,
          257,
          3657,
          1333,
          295,
          2734,
          510,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3504.94,
        "id": 1128,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3501.34,
        "temperature": 0,
        "text": " Like sometimes, like there might be like some built-in JavaScript properties",
        "tokens": [
          51484,
          1743,
          2171,
          11,
          411,
          456,
          1062,
          312,
          411,
          512,
          3094,
          12,
          259,
          15778,
          7221,
          51664
        ]
      },
      {
        "avg_logprob": -0.20332845052083334,
        "compression_ratio": 1.6493055555555556,
        "end": 3508.14,
        "id": 1129,
        "no_speech_prob": 0.0018386519514024258,
        "seek": 347894,
        "start": 3504.94,
        "temperature": 0,
        "text": " that happen to have the same word as a word in the essay.",
        "tokens": [
          51664,
          300,
          1051,
          281,
          362,
          264,
          912,
          1349,
          382,
          257,
          1349,
          294,
          264,
          16238,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3513.18,
        "id": 1130,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3508.14,
        "temperature": 0,
        "text": " So to be 100% sure, I can say has own property.",
        "tokens": [
          50364,
          407,
          281,
          312,
          2319,
          4,
          988,
          11,
          286,
          393,
          584,
          575,
          1065,
          4707,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3519.98,
        "id": 1131,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3513.74,
        "temperature": 0,
        "text": " This will evaluate to true or false if word is a particular property of this list",
        "tokens": [
          50644,
          639,
          486,
          13059,
          281,
          2074,
          420,
          7908,
          498,
          1349,
          307,
          257,
          1729,
          4707,
          295,
          341,
          1329,
          50956
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3524.54,
        "id": 1132,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3519.98,
        "temperature": 0,
        "text": " that I've developed that's not part of the sort of JavaScript object thingy language itself,",
        "tokens": [
          50956,
          300,
          286,
          600,
          4743,
          300,
          311,
          406,
          644,
          295,
          264,
          1333,
          295,
          15778,
          2657,
          551,
          88,
          2856,
          2564,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3525.2599999999998,
        "id": 1133,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3524.54,
        "temperature": 0,
        "text": " whatever.",
        "tokens": [
          51184,
          2035,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3530.06,
        "id": 1134,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3525.2599999999998,
        "temperature": 0,
        "text": " OK, so if it does, first of all, I need to say score equals 0.",
        "tokens": [
          51220,
          2264,
          11,
          370,
          498,
          309,
          775,
          11,
          700,
          295,
          439,
          11,
          286,
          643,
          281,
          584,
          6175,
          6915,
          1958,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3535.3399999999997,
        "id": 1135,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3530.06,
        "temperature": 0,
        "text": " I can say score plus equals AFIN word.",
        "tokens": [
          51460,
          286,
          393,
          584,
          6175,
          1804,
          6915,
          20389,
          1464,
          1349,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.16185137077614112,
        "compression_ratio": 1.5578512396694215,
        "end": 3537.66,
        "id": 1136,
        "no_speech_prob": 0.00002627476533234585,
        "seek": 350814,
        "start": 3535.3399999999997,
        "temperature": 0,
        "text": " So now I can look up the score and add it.",
        "tokens": [
          51724,
          407,
          586,
          286,
          393,
          574,
          493,
          264,
          6175,
          293,
          909,
          309,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.1923807633889688,
        "compression_ratio": 1.4491017964071857,
        "end": 3544.62,
        "id": 1137,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 353766,
        "start": 3537.66,
        "temperature": 0,
        "text": " And then what I'm going to do is let's add a little area for results.",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          718,
          311,
          909,
          257,
          707,
          1859,
          337,
          3542,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.1923807633889688,
        "compression_ratio": 1.4491017964071857,
        "end": 3548.94,
        "id": 1138,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 353766,
        "start": 3545.18,
        "temperature": 0,
        "text": " I'm going to say PID equals score.",
        "tokens": [
          50740,
          286,
          478,
          516,
          281,
          584,
          430,
          2777,
          6915,
          6175,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.1923807633889688,
        "compression_ratio": 1.4491017964071857,
        "end": 3552.8599999999997,
        "id": 1139,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 353766,
        "start": 3551.18,
        "temperature": 0,
        "text": " And I'm going to add some things.",
        "tokens": [
          51040,
          400,
          286,
          478,
          516,
          281,
          909,
          512,
          721,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.1923807633889688,
        "compression_ratio": 1.4491017964071857,
        "end": 3559.5,
        "id": 1140,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 353766,
        "start": 3552.8599999999997,
        "temperature": 0,
        "text": " Score, comparative, and what else?",
        "tokens": [
          51124,
          47901,
          11,
          39292,
          11,
          293,
          437,
          1646,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.1923807633889688,
        "compression_ratio": 1.4491017964071857,
        "end": 3564.22,
        "id": 1141,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 353766,
        "start": 3559.5,
        "temperature": 0,
        "text": " Maybe I'll do a word list just so we can see everything on the page.",
        "tokens": [
          51456,
          2704,
          286,
          603,
          360,
          257,
          1349,
          1329,
          445,
          370,
          321,
          393,
          536,
          1203,
          322,
          264,
          3028,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.23298938795067797,
        "compression_ratio": 1.4904761904761905,
        "end": 3569.66,
        "id": 1142,
        "no_speech_prob": 0.012821082957088947,
        "seek": 356422,
        "start": 3564.7799999999997,
        "temperature": 0,
        "text": " So OK, so I added three paragraphs because I want to report some information on the page.",
        "tokens": [
          50392,
          407,
          2264,
          11,
          370,
          286,
          3869,
          1045,
          48910,
          570,
          286,
          528,
          281,
          2275,
          512,
          1589,
          322,
          264,
          3028,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.23298938795067797,
        "compression_ratio": 1.4904761904761905,
        "end": 3579.8199999999997,
        "id": 1143,
        "no_speech_prob": 0.012821082957088947,
        "seek": 356422,
        "start": 3569.66,
        "temperature": 0,
        "text": " So the first thing I can do now in JavaScript here is say, I can say var scoreP equals select",
        "tokens": [
          50636,
          407,
          264,
          700,
          551,
          286,
          393,
          360,
          586,
          294,
          15778,
          510,
          307,
          584,
          11,
          286,
          393,
          584,
          1374,
          6175,
          47,
          6915,
          3048,
          51144
        ]
      },
      {
        "avg_logprob": -0.23298938795067797,
        "compression_ratio": 1.4904761904761905,
        "end": 3581.02,
        "id": 1144,
        "no_speech_prob": 0.012821082957088947,
        "seek": 356422,
        "start": 3580.62,
        "temperature": 0,
        "text": " score.",
        "tokens": [
          51184,
          6175,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.23298938795067797,
        "compression_ratio": 1.4904761904761905,
        "end": 3584.8599999999997,
        "id": 1145,
        "no_speech_prob": 0.012821082957088947,
        "seek": 356422,
        "start": 3581.8999999999996,
        "temperature": 0,
        "text": " And then say scoreP.html is the score.",
        "tokens": [
          51248,
          400,
          550,
          584,
          6175,
          47,
          13,
          357,
          15480,
          307,
          264,
          6175,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.23298938795067797,
        "compression_ratio": 1.4904761904761905,
        "end": 3593.3399999999997,
        "id": 1146,
        "no_speech_prob": 0.012821082957088947,
        "seek": 356422,
        "start": 3589.8999999999996,
        "temperature": 0,
        "text": " This is sort of, there's better ways I could do this, but this will work just fine.",
        "tokens": [
          51648,
          639,
          307,
          1333,
          295,
          11,
          456,
          311,
          1101,
          2098,
          286,
          727,
          360,
          341,
          11,
          457,
          341,
          486,
          589,
          445,
          2489,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.22294081279209682,
        "compression_ratio": 1.695945945945946,
        "end": 3597.18,
        "id": 1147,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 359422,
        "start": 3594.62,
        "temperature": 0,
        "text": " Comparative, select comparative.",
        "tokens": [
          50384,
          2432,
          2181,
          1166,
          11,
          3048,
          39292,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.22294081279209682,
        "compression_ratio": 1.695945945945946,
        "end": 3607.4199999999996,
        "id": 1148,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 359422,
        "start": 3599.5,
        "temperature": 0,
        "text": " And then the comparative is the score divided by words.length.",
        "tokens": [
          50628,
          400,
          550,
          264,
          39292,
          307,
          264,
          6175,
          6666,
          538,
          2283,
          13,
          45390,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.22294081279209682,
        "compression_ratio": 1.695945945945946,
        "end": 3610.2999999999997,
        "id": 1149,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 359422,
        "start": 3607.4199999999996,
        "temperature": 0,
        "text": " So the score divided by the number of words in the file.",
        "tokens": [
          51024,
          407,
          264,
          6175,
          6666,
          538,
          264,
          1230,
          295,
          2283,
          294,
          264,
          3991,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.22294081279209682,
        "compression_ratio": 1.695945945945946,
        "end": 3621.4199999999996,
        "id": 1150,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 359422,
        "start": 3610.8599999999997,
        "temperature": 0,
        "text": " And then also maybe word list, select word list, and word list HTML.",
        "tokens": [
          51196,
          400,
          550,
          611,
          1310,
          1349,
          1329,
          11,
          3048,
          1349,
          1329,
          11,
          293,
          1349,
          1329,
          17995,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.22294081279209682,
        "compression_ratio": 1.695945945945946,
        "end": 3623.1,
        "id": 1151,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 359422,
        "start": 3621.4199999999996,
        "temperature": 0,
        "text": " Oh, I'm not saving the words.",
        "tokens": [
          51724,
          876,
          11,
          286,
          478,
          406,
          6816,
          264,
          2283,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3624.22,
        "id": 1152,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3623.1,
        "temperature": 0,
        "text": " So let's make a list.",
        "tokens": [
          50364,
          407,
          718,
          311,
          652,
          257,
          1329,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3629.42,
        "id": 1153,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3627.18,
        "temperature": 0,
        "text": " So let's make a list.",
        "tokens": [
          50568,
          407,
          718,
          311,
          652,
          257,
          1329,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3632.62,
        "id": 1154,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3629.42,
        "temperature": 0,
        "text": " We'll call it scored words.",
        "tokens": [
          50680,
          492,
          603,
          818,
          309,
          18139,
          2283,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3634.06,
        "id": 1155,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3632.62,
        "temperature": 0,
        "text": " And it's an empty array.",
        "tokens": [
          50840,
          400,
          309,
          311,
          364,
          6707,
          10225,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3639.8199999999997,
        "id": 1156,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3634.06,
        "temperature": 0,
        "text": " And if I ever find one of those, I'm going to say scored words.push the word.",
        "tokens": [
          50912,
          400,
          498,
          286,
          1562,
          915,
          472,
          295,
          729,
          11,
          286,
          478,
          516,
          281,
          584,
          18139,
          2283,
          13,
          79,
          1498,
          264,
          1349,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3647.8199999999997,
        "id": 1157,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3640.54,
        "temperature": 0,
        "text": " Oh, and maybe colon its score, something like that.",
        "tokens": [
          51236,
          876,
          11,
          293,
          1310,
          8255,
          1080,
          6175,
          11,
          746,
          411,
          300,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.19114672884028008,
        "compression_ratio": 1.5906735751295338,
        "end": 3652.22,
        "id": 1158,
        "no_speech_prob": 0.0000231874619203154,
        "seek": 362310,
        "start": 3647.8199999999997,
        "temperature": 0,
        "text": " So I'm not being very thoughtful about the design of the display of the results.",
        "tokens": [
          51600,
          407,
          286,
          478,
          406,
          885,
          588,
          21566,
          466,
          264,
          1715,
          295,
          264,
          4674,
          295,
          264,
          3542,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3655.66,
        "id": 1159,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3654.06,
        "temperature": 0,
        "text": " But comparative.",
        "tokens": [
          50412,
          583,
          39292,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3657.42,
        "id": 1160,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3655.66,
        "temperature": 0,
        "text": " OK, but let's see if this works.",
        "tokens": [
          50492,
          2264,
          11,
          457,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3658.94,
        "id": 1161,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3658.46,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50632,
          2425,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3661.2599999999998,
        "id": 1162,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3659.74,
        "temperature": 0,
        "text": " Oh, uncaught reference error.",
        "tokens": [
          50696,
          876,
          11,
          517,
          496,
          1599,
          6408,
          6713,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3662.94,
        "id": 1163,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3661.2599999999998,
        "temperature": 0,
        "text": " Score words is not defined.",
        "tokens": [
          50772,
          47901,
          2283,
          307,
          406,
          7642,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3666.38,
        "id": 1164,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3663.98,
        "temperature": 0,
        "text": " Scored words, scored words.",
        "tokens": [
          50908,
          2747,
          2769,
          2283,
          11,
          18139,
          2283,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3670.46,
        "id": 1165,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3668.86,
        "temperature": 0,
        "text": " And oh, scored words.",
        "tokens": [
          51152,
          400,
          1954,
          11,
          18139,
          2283,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3671.58,
        "id": 1166,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3670.46,
        "temperature": 0,
        "text": " I don't know what I'm doing here.",
        "tokens": [
          51232,
          286,
          500,
          380,
          458,
          437,
          286,
          478,
          884,
          510,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3672.7799999999997,
        "id": 1167,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3671.58,
        "temperature": 0,
        "text": " OK, let's try this.",
        "tokens": [
          51288,
          2264,
          11,
          718,
          311,
          853,
          341,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3677.02,
        "id": 1168,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3674.62,
        "temperature": 0,
        "text": " So OK, let's try typing.",
        "tokens": [
          51440,
          407,
          2264,
          11,
          718,
          311,
          853,
          18444,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.22421046665736608,
        "compression_ratio": 1.5632183908045978,
        "end": 3680.62,
        "id": 1169,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 365310,
        "start": 3677.02,
        "temperature": 0,
        "text": " I love kittens and rainbows.",
        "tokens": [
          51560,
          286,
          959,
          47363,
          293,
          4830,
          21118,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.2406068305446677,
        "compression_ratio": 1.4493670886075949,
        "end": 3688.94,
        "id": 1170,
        "no_speech_prob": 0.00003883103636326268,
        "seek": 368062,
        "start": 3681.58,
        "temperature": 0,
        "text": " Also, unicorns and the color purple and pink and red and green and blue.",
        "tokens": [
          50412,
          2743,
          11,
          28122,
          82,
          293,
          264,
          2017,
          9656,
          293,
          7022,
          293,
          2182,
          293,
          3092,
          293,
          3344,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.2406068305446677,
        "compression_ratio": 1.4493670886075949,
        "end": 3690.22,
        "id": 1171,
        "no_speech_prob": 0.00003883103636326268,
        "seek": 368062,
        "start": 3688.94,
        "temperature": 0,
        "text": " I am happy.",
        "tokens": [
          50780,
          286,
          669,
          2055,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.2406068305446677,
        "compression_ratio": 1.4493670886075949,
        "end": 3693.9,
        "id": 1172,
        "no_speech_prob": 0.00003883103636326268,
        "seek": 368062,
        "start": 3690.7799999999997,
        "temperature": 0,
        "text": " So, so very, very happy and joyful.",
        "tokens": [
          50872,
          407,
          11,
          370,
          588,
          11,
          588,
          2055,
          293,
          33090,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2406068305446677,
        "compression_ratio": 1.4493670886075949,
        "end": 3699.2599999999998,
        "id": 1173,
        "no_speech_prob": 0.00003883103636326268,
        "seek": 368062,
        "start": 3695.9,
        "temperature": 0,
        "text": " So you can see, oh, a couple of things are wrong here.",
        "tokens": [
          51128,
          407,
          291,
          393,
          536,
          11,
          1954,
          11,
          257,
          1916,
          295,
          721,
          366,
          2085,
          510,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.2406068305446677,
        "compression_ratio": 1.4493670886075949,
        "end": 3701.42,
        "id": 1174,
        "no_speech_prob": 0.00003883103636326268,
        "seek": 368062,
        "start": 3699.9,
        "temperature": 0,
        "text": " This is not at all correct.",
        "tokens": [
          51328,
          639,
          307,
          406,
          412,
          439,
          3006,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.2406068305446677,
        "compression_ratio": 1.4493670886075949,
        "end": 3704.2999999999997,
        "id": 1175,
        "no_speech_prob": 0.00003883103636326268,
        "seek": 368062,
        "start": 3702.7,
        "temperature": 0,
        "text": " So what's happening here?",
        "tokens": [
          51468,
          407,
          437,
          311,
          2737,
          510,
          30,
          51548
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3711.9,
        "id": 1176,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3704.38,
        "temperature": 0,
        "text": " It's getting the information from the JSON file.",
        "tokens": [
          50368,
          467,
          311,
          1242,
          264,
          1589,
          490,
          264,
          31828,
          3991,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3713.5,
        "id": 1177,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3711.9,
        "temperature": 0,
        "text": " And it's adding those numbers together.",
        "tokens": [
          50744,
          400,
          309,
          311,
          5127,
          729,
          3547,
          1214,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3718.86,
        "id": 1178,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3713.5,
        "temperature": 0,
        "text": " It's saying 3 plus 3 plus 3 plus 3 equals 3, 3, 3, 3, 3.",
        "tokens": [
          50824,
          467,
          311,
          1566,
          805,
          1804,
          805,
          1804,
          805,
          1804,
          805,
          6915,
          805,
          11,
          805,
          11,
          805,
          11,
          805,
          11,
          805,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3720.46,
        "id": 1179,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3718.86,
        "temperature": 0,
        "text": " So it's not adding them as numbers.",
        "tokens": [
          51092,
          407,
          309,
          311,
          406,
          5127,
          552,
          382,
          3547,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3724.0600000000004,
        "id": 1180,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3720.46,
        "temperature": 0,
        "text": " It thinks everything is a string, which is also why I'm getting some goofy results here.",
        "tokens": [
          51172,
          467,
          7309,
          1203,
          307,
          257,
          6798,
          11,
          597,
          307,
          611,
          983,
          286,
          478,
          1242,
          512,
          42995,
          3542,
          510,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3731.98,
        "id": 1181,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3724.94,
        "temperature": 0,
        "text": " So one thing that I need to do here is make sure that when I get that score,",
        "tokens": [
          51396,
          407,
          472,
          551,
          300,
          286,
          643,
          281,
          360,
          510,
          307,
          652,
          988,
          300,
          562,
          286,
          483,
          300,
          6175,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.14535376760694715,
        "compression_ratio": 1.6801801801801801,
        "end": 3733.42,
        "id": 1182,
        "no_speech_prob": 0.0002694782451726496,
        "seek": 370430,
        "start": 3731.98,
        "temperature": 0,
        "text": " I convert it to a number.",
        "tokens": [
          51748,
          286,
          7620,
          309,
          281,
          257,
          1230,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.23955775990205652,
        "compression_ratio": 1.5,
        "end": 3735.42,
        "id": 1183,
        "no_speech_prob": 0.00006709209264954552,
        "seek": 373430,
        "start": 3734.3,
        "temperature": 0,
        "text": " So let's fix that.",
        "tokens": [
          50364,
          407,
          718,
          311,
          3191,
          300,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.23955775990205652,
        "compression_ratio": 1.5,
        "end": 3738.78,
        "id": 1184,
        "no_speech_prob": 0.00006709209264954552,
        "seek": 373430,
        "start": 3735.42,
        "temperature": 0,
        "text": " Right, that score that's coming out of the word list, I need to convert it to a number.",
        "tokens": [
          50420,
          1779,
          11,
          300,
          6175,
          300,
          311,
          1348,
          484,
          295,
          264,
          1349,
          1329,
          11,
          286,
          643,
          281,
          7620,
          309,
          281,
          257,
          1230,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.23955775990205652,
        "compression_ratio": 1.5,
        "end": 3747.34,
        "id": 1185,
        "no_speech_prob": 0.00006709209264954552,
        "seek": 373430,
        "start": 3739.9,
        "temperature": 0,
        "text": " I should have just happy, sad, not so sad, but not so happy.",
        "tokens": [
          50644,
          286,
          820,
          362,
          445,
          2055,
          11,
          4227,
          11,
          406,
          370,
          4227,
          11,
          457,
          406,
          370,
          2055,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.23955775990205652,
        "compression_ratio": 1.5,
        "end": 3758.3,
        "id": 1186,
        "no_speech_prob": 0.00006709209264954552,
        "seek": 373430,
        "start": 3748.0600000000004,
        "temperature": 0,
        "text": " Happy and joyful and full of scared, fear for things that scream and monsters.",
        "tokens": [
          51052,
          8277,
          293,
          33090,
          293,
          1577,
          295,
          5338,
          11,
          4240,
          337,
          721,
          300,
          7291,
          293,
          15785,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23955775990205652,
        "compression_ratio": 1.5,
        "end": 3763.02,
        "id": 1187,
        "no_speech_prob": 0.00006709209264954552,
        "seek": 373430,
        "start": 3759.02,
        "temperature": 0,
        "text": " But I like, am I still recording a video tutorial?",
        "tokens": [
          51600,
          583,
          286,
          411,
          11,
          669,
          286,
          920,
          6613,
          257,
          960,
          7073,
          30,
          51800
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3766.3,
        "id": 1188,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3763.1,
        "temperature": 0,
        "text": " Or did I just become hypnotized by my weird nonsensical typing?",
        "tokens": [
          50368,
          1610,
          630,
          286,
          445,
          1813,
          42944,
          1602,
          538,
          452,
          3657,
          297,
          892,
          694,
          804,
          18444,
          30,
          50528
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3771.82,
        "id": 1189,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3766.3,
        "temperature": 0,
        "text": " So you can see, I'm now getting, now, I'm seeing some weird stuff going on here,",
        "tokens": [
          50528,
          407,
          291,
          393,
          536,
          11,
          286,
          478,
          586,
          1242,
          11,
          586,
          11,
          286,
          478,
          2577,
          512,
          3657,
          1507,
          516,
          322,
          510,
          11,
          50804
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3776.7,
        "id": 1190,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3771.82,
        "temperature": 0,
        "text": " which might just be the fact that I'm not being very thoughtful about how I display the information.",
        "tokens": [
          50804,
          597,
          1062,
          445,
          312,
          264,
          1186,
          300,
          286,
          478,
          406,
          885,
          588,
          21566,
          466,
          577,
          286,
          4674,
          264,
          1589,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3779.66,
        "id": 1191,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3777.66,
        "temperature": 0,
        "text": " But let's do some more tests here.",
        "tokens": [
          51096,
          583,
          718,
          311,
          360,
          512,
          544,
          6921,
          510,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3782.46,
        "id": 1192,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3780.22,
        "temperature": 0,
        "text": " If I say sad, OK, that works.",
        "tokens": [
          51224,
          759,
          286,
          584,
          4227,
          11,
          2264,
          11,
          300,
          1985,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3783.42,
        "id": 1193,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3782.46,
        "temperature": 0,
        "text": " Score is negative 2.",
        "tokens": [
          51336,
          47901,
          307,
          3671,
          568,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.20676062657282904,
        "compression_ratio": 1.5063829787234042,
        "end": 3784.54,
        "id": 1194,
        "no_speech_prob": 0.000131351436721161,
        "seek": 376302,
        "start": 3783.42,
        "temperature": 0,
        "text": " Oops, camera went off.",
        "tokens": [
          51384,
          21726,
          11,
          2799,
          1437,
          766,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3787.74,
        "id": 1195,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3784.54,
        "temperature": 0,
        "text": " If I say sad, exactly what I would expect.",
        "tokens": [
          50364,
          759,
          286,
          584,
          4227,
          11,
          2293,
          437,
          286,
          576,
          2066,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3789.18,
        "id": 1196,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3787.74,
        "temperature": 0,
        "text": " Let me move this over here.",
        "tokens": [
          50524,
          961,
          385,
          1286,
          341,
          670,
          510,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3791.58,
        "id": 1197,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3789.18,
        "temperature": 0,
        "text": " Right, I got a total score of negative 2.",
        "tokens": [
          50596,
          1779,
          11,
          286,
          658,
          257,
          3217,
          6175,
          295,
          3671,
          568,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3794.94,
        "id": 1198,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3791.58,
        "temperature": 0,
        "text": " Comparative is negative 2 because it's negative 2 divided by one word total.",
        "tokens": [
          50716,
          2432,
          2181,
          1166,
          307,
          3671,
          568,
          570,
          309,
          311,
          3671,
          568,
          6666,
          538,
          472,
          1349,
          3217,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3798.46,
        "id": 1199,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3794.94,
        "temperature": 0,
        "text": " If I say happy, right, OK, so this is working.",
        "tokens": [
          50884,
          759,
          286,
          584,
          2055,
          11,
          558,
          11,
          2264,
          11,
          370,
          341,
          307,
          1364,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3802.86,
        "id": 1200,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3799.2599999999998,
        "temperature": 0,
        "text": " And abandoned, I remember, was in there, is negative 1.",
        "tokens": [
          51100,
          400,
          13732,
          11,
          286,
          1604,
          11,
          390,
          294,
          456,
          11,
          307,
          3671,
          502,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3803.9,
        "id": 1201,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3802.86,
        "temperature": 0,
        "text": " So it's just the formatting.",
        "tokens": [
          51280,
          407,
          309,
          311,
          445,
          264,
          39366,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3805.5,
        "id": 1202,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3803.9,
        "temperature": 0,
        "text": " So we're really done.",
        "tokens": [
          51332,
          407,
          321,
          434,
          534,
          1096,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3810.38,
        "id": 1203,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3805.5,
        "temperature": 0,
        "text": " I could copy and paste some text, like, I don't know, if I go to kitten.",
        "tokens": [
          51412,
          286,
          727,
          5055,
          293,
          9163,
          512,
          2487,
          11,
          411,
          11,
          286,
          500,
          380,
          458,
          11,
          498,
          286,
          352,
          281,
          39696,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.4127712794712612,
        "compression_ratio": 1.6494464944649447,
        "end": 3811.58,
        "id": 1204,
        "no_speech_prob": 0.002800906077027321,
        "seek": 378454,
        "start": 3810.38,
        "temperature": 0,
        "text": " I don't know if I can do that.",
        "tokens": [
          51656,
          286,
          500,
          380,
          458,
          498,
          286,
          393,
          360,
          300,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.32824746664468346,
        "compression_ratio": 1.4210526315789473,
        "end": 3815.58,
        "id": 1205,
        "no_speech_prob": 0.0008969345944933593,
        "seek": 381158,
        "start": 3812.54,
        "temperature": 0.6000000000000001,
        "text": " I don't know if I go to kittens, Wikipedia.",
        "tokens": [
          50412,
          286,
          500,
          380,
          458,
          498,
          286,
          352,
          281,
          47363,
          11,
          28999,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32824746664468346,
        "compression_ratio": 1.4210526315789473,
        "end": 3827.5,
        "id": 1206,
        "no_speech_prob": 0.0008969345944933593,
        "seek": 381158,
        "start": 3818.86,
        "temperature": 0.6000000000000001,
        "text": " Let's get some text about kittens and see what happens if I paste it in here.",
        "tokens": [
          50728,
          961,
          311,
          483,
          512,
          2487,
          466,
          47363,
          364,
          67,
          536,
          437,
          2314,
          498,
          286,
          9163,
          309,
          294,
          510,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.32824746664468346,
        "compression_ratio": 1.4210526315789473,
        "end": 3831.58,
        "id": 1207,
        "no_speech_prob": 0.0008969345944933593,
        "seek": 381158,
        "start": 3828.54,
        "temperature": 0.6000000000000001,
        "text": " And we can see I got a score of 4.",
        "tokens": [
          51212,
          400,
          321,
          393,
          536,
          286,
          658,
          257,
          6175,
          295,
          1017,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.32824746664468346,
        "compression_ratio": 1.4210526315789473,
        "end": 3834.62,
        "id": 1208,
        "no_speech_prob": 0.0008969345944933593,
        "seek": 381158,
        "start": 3831.58,
        "temperature": 0.6000000000000001,
        "text": " Comparative of 0.04, this is positive text.",
        "tokens": [
          51364,
          2432,
          2181,
          1166,
          295,
          1958,
          13,
          14565,
          11,
          341,
          307,
          3353,
          2487,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.32824746664468346,
        "compression_ratio": 1.4210526315789473,
        "end": 3839.98,
        "id": 1209,
        "no_speech_prob": 0.0008969345944933593,
        "seek": 381158,
        "start": 3835.66,
        "temperature": 0.6000000000000001,
        "text": " The words that I got were solid and enjoy.",
        "tokens": [
          51568,
          440,
          2283,
          300,
          286,
          658,
          645,
          5100,
          293,
          2103,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3841.7400000000002,
        "id": 1210,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3840.06,
        "temperature": 0,
        "text": " I should get a score of 6.",
        "tokens": [
          50368,
          286,
          820,
          483,
          257,
          6175,
          295,
          1386,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3848.78,
        "id": 1211,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3847.34,
        "temperature": 0,
        "text": " So something is wrong here, right?",
        "tokens": [
          50732,
          407,
          746,
          307,
          2085,
          510,
          11,
          558,
          30,
          50804
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3849.5,
        "id": 1212,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3848.78,
        "temperature": 0,
        "text": " What did I forget?",
        "tokens": [
          50804,
          708,
          630,
          286,
          2870,
          30,
          50840
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3851.34,
        "id": 1213,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3849.5,
        "temperature": 0,
        "text": " I made a, there's a bug in my code.",
        "tokens": [
          50840,
          286,
          1027,
          257,
          11,
          456,
          311,
          257,
          7426,
          294,
          452,
          3089,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3853.5,
        "id": 1214,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3851.98,
        "temperature": 0,
        "text": " Score plus equals.",
        "tokens": [
          50964,
          47901,
          1804,
          6915,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3860.46,
        "id": 1215,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3855.66,
        "temperature": 0,
        "text": " Let's say, let's just do console.log word and score.",
        "tokens": [
          51148,
          961,
          311,
          584,
          11,
          718,
          311,
          445,
          360,
          11076,
          13,
          4987,
          1349,
          293,
          6175,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3863.66,
        "id": 1216,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3862.22,
        "temperature": 0,
        "text": " Yeah, something's wrong with the math.",
        "tokens": [
          51476,
          865,
          11,
          746,
          311,
          2085,
          365,
          264,
          5221,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3865.7400000000002,
        "id": 1217,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3865.1,
        "temperature": 0,
        "text": " What did I say?",
        "tokens": [
          51620,
          708,
          630,
          286,
          584,
          30,
          51652
        ]
      },
      {
        "avg_logprob": -0.256421764245194,
        "compression_ratio": 1.44,
        "end": 3866.94,
        "id": 1218,
        "no_speech_prob": 0.0037072303239256144,
        "seek": 383998,
        "start": 3865.7400000000002,
        "temperature": 0,
        "text": " Solid 2.",
        "tokens": [
          51652,
          26664,
          568,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3868.06,
        "id": 1219,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3867.18,
        "temperature": 0,
        "text": " What was the other word?",
        "tokens": [
          50376,
          708,
          390,
          264,
          661,
          1349,
          30,
          50420
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3869.7400000000002,
        "id": 1220,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3868.94,
        "temperature": 0,
        "text": " Whatever, happy.",
        "tokens": [
          50464,
          8541,
          11,
          2055,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3873.82,
        "id": 1221,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3873.18,
        "temperature": 0,
        "text": " 5.",
        "tokens": [
          50676,
          1025,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3875.9,
        "id": 1222,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3873.82,
        "temperature": 0,
        "text": " Solid, ooh, wait.",
        "tokens": [
          50708,
          26664,
          11,
          17024,
          11,
          1699,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3879.02,
        "id": 1223,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3876.86,
        "temperature": 0,
        "text": " Solid 0, happy 2.",
        "tokens": [
          50860,
          26664,
          1958,
          11,
          2055,
          568,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3882,
        "id": 1224,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3881.5,
        "temperature": 0,
        "text": " Huh?",
        "tokens": [
          51092,
          8063,
          30,
          51117
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3884.06,
        "id": 1225,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3883.34,
        "temperature": 0,
        "text": " Debugging time.",
        "tokens": [
          51184,
          27347,
          697,
          3249,
          565,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3884.78,
        "id": 1226,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3884.06,
        "temperature": 0,
        "text": " Hold on, hold on.",
        "tokens": [
          51220,
          6962,
          322,
          11,
          1797,
          322,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3889.98,
        "id": 1227,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3888.78,
        "temperature": 0,
        "text": " Solid has a score of 2.",
        "tokens": [
          51456,
          26664,
          575,
          257,
          6175,
          295,
          568,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.632118886311849,
        "compression_ratio": 1.3037037037037038,
        "end": 3893.18,
        "id": 1228,
        "no_speech_prob": 0.004538409877568483,
        "seek": 386694,
        "start": 3891.34,
        "temperature": 0,
        "text": " But why is that coming out as 0?",
        "tokens": [
          51584,
          583,
          983,
          307,
          300,
          1348,
          484,
          382,
          1958,
          30,
          51676
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3896.22,
        "id": 1229,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3894.14,
        "temperature": 0,
        "text": " Oh, I don't have a variable.",
        "tokens": [
          50412,
          876,
          11,
          286,
          500,
          380,
          362,
          257,
          7006,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3897.18,
        "id": 1230,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3896.22,
        "temperature": 0,
        "text": " Oh, sorry.",
        "tokens": [
          50516,
          876,
          11,
          2597,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3903.8999999999996,
        "id": 1231,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3903.2599999999998,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          50868,
          1033,
          11,
          1797,
          322,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3904.94,
        "id": 1232,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3903.8999999999996,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          50900,
          876,
          11,
          572,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3911.2599999999998,
        "id": 1233,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3906.54,
        "temperature": 0,
        "text": " Did something, you know, sometimes if I have an element named with an, oh, whoops.",
        "tokens": [
          51032,
          2589,
          746,
          11,
          291,
          458,
          11,
          2171,
          498,
          286,
          362,
          364,
          4478,
          4926,
          365,
          364,
          11,
          1954,
          11,
          567,
          3370,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3913.74,
        "id": 1234,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3911.2599999999998,
        "temperature": 0,
        "text": " Oh, sorry, this is, remind me later.",
        "tokens": [
          51268,
          876,
          11,
          2597,
          11,
          341,
          307,
          11,
          4160,
          385,
          1780,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3914.94,
        "id": 1235,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3913.74,
        "temperature": 0,
        "text": " I don't need a software update.",
        "tokens": [
          51392,
          286,
          500,
          380,
          643,
          257,
          4722,
          5623,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.42723766962687176,
        "compression_ratio": 1.6379310344827587,
        "end": 3919.18,
        "id": 1236,
        "no_speech_prob": 0.00041084777330979705,
        "seek": 389318,
        "start": 3914.94,
        "temperature": 0,
        "text": " Sometimes if I have an element, things in JavaScript can be, you know,",
        "tokens": [
          51452,
          4803,
          498,
          286,
          362,
          364,
          4478,
          11,
          721,
          294,
          15778,
          393,
          312,
          11,
          291,
          458,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21805817992598922,
        "compression_ratio": 1.6406926406926408,
        "end": 3924.06,
        "id": 1237,
        "no_speech_prob": 0.0838874876499176,
        "seek": 391918,
        "start": 3919.74,
        "temperature": 0,
        "text": " Sometimes if I have an element, things in JavaScript can be, happen in weird things.",
        "tokens": [
          50392,
          4803,
          498,
          286,
          362,
          364,
          4478,
          11,
          721,
          294,
          15778,
          393,
          312,
          11,
          1051,
          294,
          3657,
          721,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.21805817992598922,
        "compression_ratio": 1.6406926406926408,
        "end": 3928.7,
        "id": 1238,
        "no_speech_prob": 0.0838874876499176,
        "seek": 391918,
        "start": 3924.06,
        "temperature": 0,
        "text": " Like I named this variable score, and I happen to have a DOM element with an ID of score.",
        "tokens": [
          50608,
          1743,
          286,
          4926,
          341,
          7006,
          6175,
          11,
          293,
          286,
          1051,
          281,
          362,
          257,
          35727,
          4478,
          365,
          364,
          7348,
          295,
          6175,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.21805817992598922,
        "compression_ratio": 1.6406926406926408,
        "end": 3931.5,
        "id": 1239,
        "no_speech_prob": 0.0838874876499176,
        "seek": 391918,
        "start": 3928.7,
        "temperature": 0,
        "text": " I wonder if that's causing me a weird sort of problem.",
        "tokens": [
          50840,
          286,
          2441,
          498,
          300,
          311,
          9853,
          385,
          257,
          3657,
          1333,
          295,
          1154,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.21805817992598922,
        "compression_ratio": 1.6406926406926408,
        "end": 3938.46,
        "id": 1240,
        "no_speech_prob": 0.0838874876499176,
        "seek": 391918,
        "start": 3931.5,
        "temperature": 0,
        "text": " So I'm going to go here and say score p, comparative p, word list p.",
        "tokens": [
          50980,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          293,
          584,
          6175,
          280,
          11,
          39292,
          280,
          11,
          1349,
          1329,
          280,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.21805817992598922,
        "compression_ratio": 1.6406926406926408,
        "end": 3941.66,
        "id": 1241,
        "no_speech_prob": 0.0838874876499176,
        "seek": 391918,
        "start": 3939.66,
        "temperature": 0,
        "text": " And I'm going to go back to my sketch.",
        "tokens": [
          51388,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          12325,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.21805817992598922,
        "compression_ratio": 1.6406926406926408,
        "end": 3946.62,
        "id": 1242,
        "no_speech_prob": 0.0838874876499176,
        "seek": 391918,
        "start": 3942.22,
        "temperature": 0,
        "text": " I'm just going to see if that's an issue.",
        "tokens": [
          51516,
          286,
          478,
          445,
          516,
          281,
          536,
          498,
          300,
          311,
          364,
          2734,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3951.18,
        "id": 1243,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3946.7799999999997,
        "temperature": 0,
        "text": " Oh, I also, I'm just not, oh, I'm being score p dot.",
        "tokens": [
          50372,
          876,
          11,
          286,
          611,
          11,
          286,
          478,
          445,
          406,
          11,
          1954,
          11,
          286,
          478,
          885,
          6175,
          280,
          5893,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3953.66,
        "id": 1244,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3952.54,
        "temperature": 0,
        "text": " Oh, no, no, score.",
        "tokens": [
          50660,
          876,
          11,
          572,
          11,
          572,
          11,
          6175,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3954.38,
        "id": 1245,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3953.66,
        "temperature": 0,
        "text": " Yeah, that's right.",
        "tokens": [
          50716,
          865,
          11,
          300,
          311,
          558,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3959.2599999999998,
        "id": 1246,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3956.22,
        "temperature": 0,
        "text": " And comparative word list p.",
        "tokens": [
          50844,
          400,
          39292,
          1349,
          1329,
          280,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3960.7799999999997,
        "id": 1247,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3960.22,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51044,
          961,
          311,
          536,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3966.38,
        "id": 1248,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3963.58,
        "temperature": 0,
        "text": " Let me just make all the variables name different to overdo it.",
        "tokens": [
          51212,
          961,
          385,
          445,
          652,
          439,
          264,
          9102,
          1315,
          819,
          281,
          670,
          2595,
          309,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3969.98,
        "id": 1249,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3968.22,
        "temperature": 0,
        "text": " Solid, happy.",
        "tokens": [
          51444,
          26664,
          11,
          2055,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3974.2999999999997,
        "id": 1250,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3972.2999999999997,
        "temperature": 0,
        "text": " Solid is 2, happy is 3.",
        "tokens": [
          51648,
          26664,
          307,
          568,
          11,
          2055,
          307,
          805,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.49422867765131684,
        "compression_ratio": 1.445054945054945,
        "end": 3975.9,
        "id": 1251,
        "no_speech_prob": 0.0013885204680263996,
        "seek": 394662,
        "start": 3974.2999999999997,
        "temperature": 0,
        "text": " Why am I seeing a score of 2?",
        "tokens": [
          51748,
          1545,
          669,
          286,
          2577,
          257,
          6175,
          295,
          568,
          30,
          51828
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 3981.02,
        "id": 1252,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 3977.5,
        "temperature": 0.8,
        "text": " I'm seeing happy 5 here.",
        "tokens": [
          50408,
          286,
          478,
          2577,
          2055,
          1025,
          510,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 3983.58,
        "id": 1253,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 3981.02,
        "temperature": 0.8,
        "text": " So this is correct, this is correct, and this is wrong.",
        "tokens": [
          50584,
          407,
          341,
          307,
          3006,
          11,
          341,
          307,
          3006,
          11,
          364,
          67,
          341,
          307,
          2085,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 3990.54,
        "id": 1254,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 3985.66,
        "temperature": 0.8,
        "text": " I'm, I'm a little skeptical of, oh, I put the score.",
        "tokens": [
          50816,
          286,
          478,
          11,
          286,
          478,
          257,
          707,
          28601,
          295,
          11,
          1954,
          11,
          286,
          829,
          264,
          38629,
          68,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 3991.58,
        "id": 1255,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 3990.54,
        "temperature": 0.8,
        "text": " Oh, once again.",
        "tokens": [
          51060,
          220,
          3756,
          11,
          1564,
          797,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 3997.74,
        "id": 1256,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 3993.9,
        "temperature": 0.8,
        "text": " I'm conflating the total score and the individual word score.",
        "tokens": [
          51228,
          286,
          478,
          1497,
          75,
          990,
          264,
          3217,
          262,
          1291,
          265,
          293,
          264,
          2609,
          1349,
          6175,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 4000.06,
        "id": 1257,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 3997.74,
        "temperature": 0.8,
        "text": " So I should really if I want to be thoughtful about this.",
        "tokens": [
          51420,
          407,
          286,
          820,
          534,
          498,
          286,
          528,
          281,
          312,
          21566,
          257,
          30722,
          341,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.6635417204636794,
        "compression_ratio": 1.5577889447236182,
        "end": 4002.38,
        "id": 1258,
        "no_speech_prob": 0.004468363244086504,
        "seek": 397662,
        "start": 4000.06,
        "temperature": 0.8,
        "text": " Boy, I'm terrible at this sort of stuff.",
        "tokens": [
          51536,
          9486,
          11,
          286,
          478,
          6237,
          412,
          341,
          9359,
          83,
          295,
          1507,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2445958944467398,
        "compression_ratio": 1.7747252747252746,
        "end": 4005.1,
        "id": 1259,
        "no_speech_prob": 0.008445525541901588,
        "seek": 400238,
        "start": 4003.34,
        "temperature": 0,
        "text": " So I don't think it was that at all.",
        "tokens": [
          50412,
          407,
          286,
          500,
          380,
          519,
          309,
          390,
          300,
          412,
          439,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2445958944467398,
        "compression_ratio": 1.7747252747252746,
        "end": 4008.38,
        "id": 1260,
        "no_speech_prob": 0.008445525541901588,
        "seek": 400238,
        "start": 4006.3,
        "temperature": 0,
        "text": " I think it was, this was my problem all along.",
        "tokens": [
          50560,
          286,
          519,
          309,
          390,
          11,
          341,
          390,
          452,
          1154,
          439,
          2051,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2445958944467398,
        "compression_ratio": 1.7747252747252746,
        "end": 4019.1800000000003,
        "id": 1261,
        "no_speech_prob": 0.008445525541901588,
        "seek": 400238,
        "start": 4010.38,
        "temperature": 0,
        "text": " So I want to make sure I have a difference between the individual word score and the actual",
        "tokens": [
          50764,
          407,
          286,
          528,
          281,
          652,
          988,
          286,
          362,
          257,
          2649,
          1296,
          264,
          2609,
          1349,
          6175,
          293,
          264,
          3539,
          51204
        ]
      },
      {
        "avg_logprob": -0.2445958944467398,
        "compression_ratio": 1.7747252747252746,
        "end": 4021.42,
        "id": 1262,
        "no_speech_prob": 0.008445525541901588,
        "seek": 400238,
        "start": 4019.1800000000003,
        "temperature": 0,
        "text": " total score that I'm adding up.",
        "tokens": [
          51204,
          3217,
          6175,
          300,
          286,
          478,
          5127,
          493,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2445958944467398,
        "compression_ratio": 1.7747252747252746,
        "end": 4026.62,
        "id": 1263,
        "no_speech_prob": 0.008445525541901588,
        "seek": 400238,
        "start": 4021.42,
        "temperature": 0,
        "text": " And so this is the total score, and this is the total score, and the in,",
        "tokens": [
          51316,
          400,
          370,
          341,
          307,
          264,
          3217,
          6175,
          11,
          293,
          341,
          307,
          264,
          3217,
          6175,
          11,
          293,
          264,
          294,
          11,
          51576
        ]
      },
      {
        "avg_logprob": -0.2445958944467398,
        "compression_ratio": 1.7747252747252746,
        "end": 4028.86,
        "id": 1264,
        "no_speech_prob": 0.008445525541901588,
        "seek": 400238,
        "start": 4026.62,
        "temperature": 0,
        "text": " the things that I'm putting into the list.",
        "tokens": [
          51576,
          264,
          721,
          300,
          286,
          478,
          3372,
          666,
          264,
          1329,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.25474950379016353,
        "compression_ratio": 1.671875,
        "end": 4037.26,
        "id": 1265,
        "no_speech_prob": 0.000687845575157553,
        "seek": 403238,
        "start": 4032.94,
        "temperature": 0,
        "text": " So I'm going to just add some padding here for formatting.",
        "tokens": [
          50392,
          407,
          286,
          478,
          516,
          281,
          445,
          909,
          512,
          39562,
          510,
          337,
          39366,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.25474950379016353,
        "compression_ratio": 1.671875,
        "end": 4050.38,
        "id": 1266,
        "no_speech_prob": 0.000687845575157553,
        "seek": 403238,
        "start": 4038.86,
        "temperature": 0,
        "text": " Now, happy, sad, this is better, yes, no, no, no, no, no, no, no, no, no, no, no.",
        "tokens": [
          50688,
          823,
          11,
          2055,
          11,
          4227,
          11,
          341,
          307,
          1101,
          11,
          2086,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25474950379016353,
        "compression_ratio": 1.671875,
        "end": 4053.82,
        "id": 1267,
        "no_speech_prob": 0.000687845575157553,
        "seek": 403238,
        "start": 4052.1400000000003,
        "temperature": 0,
        "text": " OK, so there we go.",
        "tokens": [
          51352,
          2264,
          11,
          370,
          456,
          321,
          352,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.25474950379016353,
        "compression_ratio": 1.671875,
        "end": 4059.1800000000003,
        "id": 1268,
        "no_speech_prob": 0.000687845575157553,
        "seek": 403238,
        "start": 4053.82,
        "temperature": 0,
        "text": " You can see now I have real time sentiment analysis where I could be much,",
        "tokens": [
          51436,
          509,
          393,
          536,
          586,
          286,
          362,
          957,
          565,
          16149,
          5215,
          689,
          286,
          727,
          312,
          709,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.25474950379016353,
        "compression_ratio": 1.671875,
        "end": 4061.82,
        "id": 1269,
        "no_speech_prob": 0.000687845575157553,
        "seek": 403238,
        "start": 4059.1800000000003,
        "temperature": 0,
        "text": " you know, if you're watching this video, if you're going to make something with this,",
        "tokens": [
          51704,
          291,
          458,
          11,
          498,
          291,
          434,
          1976,
          341,
          960,
          11,
          498,
          291,
          434,
          516,
          281,
          652,
          746,
          365,
          341,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4065.98,
        "id": 1270,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4061.82,
        "temperature": 0,
        "text": " you could be so much more thoughtful in terms of how you display the results,",
        "tokens": [
          50364,
          291,
          727,
          312,
          370,
          709,
          544,
          21566,
          294,
          2115,
          295,
          577,
          291,
          4674,
          264,
          3542,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4070.06,
        "id": 1271,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4065.98,
        "temperature": 0,
        "text": " whether it's color or visualization, formatting the numbers nicely,",
        "tokens": [
          50572,
          1968,
          309,
          311,
          2017,
          420,
          25801,
          11,
          39366,
          264,
          3547,
          9594,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4072.38,
        "id": 1272,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4070.06,
        "temperature": 0,
        "text": " formatting the list of words in a different way.",
        "tokens": [
          50776,
          39366,
          264,
          1329,
          295,
          2283,
          294,
          257,
          819,
          636,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4074.86,
        "id": 1273,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4072.38,
        "temperature": 0,
        "text": " But you have the basic framework for it here.",
        "tokens": [
          50892,
          583,
          291,
          362,
          264,
          3875,
          8388,
          337,
          309,
          510,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4079.02,
        "id": 1274,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4074.86,
        "temperature": 0,
        "text": " I will show you that there is a major issue with this particular approach.",
        "tokens": [
          51016,
          286,
          486,
          855,
          291,
          300,
          456,
          307,
          257,
          2563,
          2734,
          365,
          341,
          1729,
          3109,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4083.7400000000002,
        "id": 1275,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4081.26,
        "temperature": 0,
        "text": " OK, so here's a particular issue.",
        "tokens": [
          51336,
          2264,
          11,
          370,
          510,
          311,
          257,
          1729,
          2734,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4086.78,
        "id": 1276,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4083.7400000000002,
        "temperature": 0,
        "text": " Here is my text that I am going to type right now.",
        "tokens": [
          51460,
          1692,
          307,
          452,
          2487,
          300,
          286,
          669,
          516,
          281,
          2010,
          558,
          586,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.14855390124850804,
        "compression_ratio": 1.6046511627906976,
        "end": 4090.2200000000003,
        "id": 1277,
        "no_speech_prob": 0.00005475951547850855,
        "seek": 406182,
        "start": 4088.7000000000003,
        "temperature": 0,
        "text": " I am not sad.",
        "tokens": [
          51708,
          286,
          669,
          406,
          4227,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.16830273264462187,
        "compression_ratio": 1.7156398104265402,
        "end": 4092.22,
        "id": 1278,
        "no_speech_prob": 0.00009314569615526125,
        "seek": 409022,
        "start": 4090.22,
        "temperature": 0,
        "text": " I am not at all unhappy.",
        "tokens": [
          50364,
          286,
          669,
          406,
          412,
          439,
          22172,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16830273264462187,
        "compression_ratio": 1.7156398104265402,
        "end": 4098.38,
        "id": 1279,
        "no_speech_prob": 0.00009314569615526125,
        "seek": 409022,
        "start": 4094.54,
        "temperature": 0,
        "text": " I am not feeling worse today.",
        "tokens": [
          50580,
          286,
          669,
          406,
          2633,
          5324,
          965,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.16830273264462187,
        "compression_ratio": 1.7156398104265402,
        "end": 4103.42,
        "id": 1280,
        "no_speech_prob": 0.00009314569615526125,
        "seek": 409022,
        "start": 4099.0199999999995,
        "temperature": 0,
        "text": " So you can see I've got a really, really negative score of negative 6,",
        "tokens": [
          50804,
          407,
          291,
          393,
          536,
          286,
          600,
          658,
          257,
          534,
          11,
          534,
          3671,
          6175,
          295,
          3671,
          1386,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.16830273264462187,
        "compression_ratio": 1.7156398104265402,
        "end": 4107.58,
        "id": 1281,
        "no_speech_prob": 0.00009314569615526125,
        "seek": 409022,
        "start": 4103.42,
        "temperature": 0,
        "text": " even though I said I'm not sad, I am not at all unhappy, I am not feeling worse today.",
        "tokens": [
          51024,
          754,
          1673,
          286,
          848,
          286,
          478,
          406,
          4227,
          11,
          286,
          669,
          406,
          412,
          439,
          22172,
          11,
          286,
          669,
          406,
          2633,
          5324,
          965,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.16830273264462187,
        "compression_ratio": 1.7156398104265402,
        "end": 4114.78,
        "id": 1282,
        "no_speech_prob": 0.00009314569615526125,
        "seek": 409022,
        "start": 4107.58,
        "temperature": 0,
        "text": " Because this particular technique is only looking at the raw counts of words and those scores.",
        "tokens": [
          51232,
          1436,
          341,
          1729,
          6532,
          307,
          787,
          1237,
          412,
          264,
          8936,
          14893,
          295,
          2283,
          293,
          729,
          13444,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.16830273264462187,
        "compression_ratio": 1.7156398104265402,
        "end": 4118.3,
        "id": 1283,
        "no_speech_prob": 0.00009314569615526125,
        "seek": 409022,
        "start": 4115.66,
        "temperature": 0,
        "text": " If I wanted to be a little more thoughtful about this,",
        "tokens": [
          51636,
          759,
          286,
          1415,
          281,
          312,
          257,
          707,
          544,
          21566,
          466,
          341,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4121.34,
        "id": 1284,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4118.3,
        "temperature": 0,
        "text": " I could try to add a little bit of natural language processing.",
        "tokens": [
          50364,
          286,
          727,
          853,
          281,
          909,
          257,
          707,
          857,
          295,
          3303,
          2856,
          9007,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4125.26,
        "id": 1285,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4121.34,
        "temperature": 0,
        "text": " For example, the JavaScript library NLP compromise that I demonstrated",
        "tokens": [
          50516,
          1171,
          1365,
          11,
          264,
          15778,
          6405,
          426,
          45196,
          18577,
          300,
          286,
          18772,
          50712
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4130.860000000001,
        "id": 1286,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4125.900000000001,
        "temperature": 0,
        "text": " can look for if a statement is a negation and you could perhaps invert the score.",
        "tokens": [
          50744,
          393,
          574,
          337,
          498,
          257,
          5629,
          307,
          257,
          2485,
          399,
          293,
          291,
          727,
          4317,
          33966,
          264,
          6175,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4135.26,
        "id": 1287,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4130.860000000001,
        "temperature": 0,
        "text": " And then, of course, I could use a more sophisticated training methodology",
        "tokens": [
          50992,
          400,
          550,
          11,
          295,
          1164,
          11,
          286,
          727,
          764,
          257,
          544,
          16950,
          3097,
          24850,
          51212
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4138.78,
        "id": 1288,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4135.26,
        "temperature": 0,
        "text": " of actually not using a word list, but having a machine learning system",
        "tokens": [
          51212,
          295,
          767,
          406,
          1228,
          257,
          1349,
          1329,
          11,
          457,
          1419,
          257,
          3479,
          2539,
          1185,
          51388
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4143.34,
        "id": 1289,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4138.78,
        "temperature": 0,
        "text": " learn about positive text, learn about negative text based on just word frequencies",
        "tokens": [
          51388,
          1466,
          466,
          3353,
          2487,
          11,
          1466,
          466,
          3671,
          2487,
          2361,
          322,
          445,
          1349,
          20250,
          51616
        ]
      },
      {
        "avg_logprob": -0.17177677154541016,
        "compression_ratio": 1.6492307692307693,
        "end": 4146.7,
        "id": 1290,
        "no_speech_prob": 0.00006709135777782649,
        "seek": 411830,
        "start": 4143.34,
        "temperature": 0,
        "text": " and words being next to each other and that sort of thing in a much more open-ended way.",
        "tokens": [
          51616,
          293,
          2283,
          885,
          958,
          281,
          1184,
          661,
          293,
          300,
          1333,
          295,
          551,
          294,
          257,
          709,
          544,
          1269,
          12,
          3502,
          636,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4149.98,
        "id": 1291,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4146.7,
        "temperature": 0,
        "text": " But this hopefully should get you started on something",
        "tokens": [
          50364,
          583,
          341,
          4696,
          820,
          483,
          291,
          1409,
          322,
          746,
          50528
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4155.0199999999995,
        "id": 1292,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4149.98,
        "temperature": 0,
        "text": " if you're interested in text analysis and how you might apply this to what type of data source",
        "tokens": [
          50528,
          498,
          291,
          434,
          3102,
          294,
          2487,
          5215,
          293,
          577,
          291,
          1062,
          3079,
          341,
          281,
          437,
          2010,
          295,
          1412,
          4009,
          50780
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4158.78,
        "id": 1293,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4155.0199999999995,
        "temperature": 0,
        "text": " and how you might show the result or how you might create an interface for people to type into",
        "tokens": [
          50780,
          293,
          577,
          291,
          1062,
          855,
          264,
          1874,
          420,
          577,
          291,
          1062,
          1884,
          364,
          9226,
          337,
          561,
          281,
          2010,
          666,
          50968
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4160.7,
        "id": 1294,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4158.78,
        "temperature": 0,
        "text": " and give us some information back.",
        "tokens": [
          50968,
          293,
          976,
          505,
          512,
          1589,
          646,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4166.7,
        "id": 1295,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4161.179999999999,
        "temperature": 0,
        "text": " Okay, so in the chat, Gaurav writes,",
        "tokens": [
          51088,
          1033,
          11,
          370,
          294,
          264,
          5081,
          11,
          460,
          3463,
          706,
          13657,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4169.42,
        "id": 1296,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4166.7,
        "temperature": 0,
        "text": " you must be sad, that's why you were insisting on it very much.",
        "tokens": [
          51364,
          291,
          1633,
          312,
          4227,
          11,
          300,
          311,
          983,
          291,
          645,
          13466,
          278,
          322,
          309,
          588,
          709,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4169.98,
        "id": 1297,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4169.42,
        "temperature": 0,
        "text": " And you know what?",
        "tokens": [
          51500,
          400,
          291,
          458,
          437,
          30,
          51528
        ]
      },
      {
        "avg_logprob": -0.21177434520561153,
        "compression_ratio": 1.6917562724014337,
        "end": 4174.94,
        "id": 1298,
        "no_speech_prob": 0.00023050331219565123,
        "seek": 414670,
        "start": 4169.98,
        "temperature": 0,
        "text": " I think maybe this is a smarter sentiment analysis technique than I knew",
        "tokens": [
          51528,
          286,
          519,
          1310,
          341,
          307,
          257,
          20294,
          16149,
          5215,
          6532,
          813,
          286,
          2586,
          51776
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4176.78,
        "id": 1299,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4174.94,
        "temperature": 0,
        "text": " because maybe it can read in between the lines.",
        "tokens": [
          50364,
          570,
          1310,
          309,
          393,
          1401,
          294,
          1296,
          264,
          3876,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4180.54,
        "id": 1300,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4176.78,
        "temperature": 0,
        "text": " Okay, thanks very much for watching this sentiment analysis video",
        "tokens": [
          50456,
          1033,
          11,
          3231,
          588,
          709,
          337,
          1976,
          341,
          16149,
          5215,
          960,
          50644
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4184.219999999999,
        "id": 1301,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4180.54,
        "temperature": 0,
        "text": " and I'll see you in other videos in the future perhaps.",
        "tokens": [
          50644,
          293,
          286,
          603,
          536,
          291,
          294,
          661,
          2145,
          294,
          264,
          2027,
          4317,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4191.9,
        "id": 1302,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4186.86,
        "temperature": 0,
        "text": " Okay, she's doing cycle analysis too.",
        "tokens": [
          50960,
          1033,
          11,
          750,
          311,
          884,
          6586,
          5215,
          886,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4194.299999999999,
        "id": 1303,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4191.9,
        "temperature": 0,
        "text": " Okay, it is now 4.30.",
        "tokens": [
          51212,
          1033,
          11,
          309,
          307,
          586,
          1017,
          13,
          3446,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4196.299999999999,
        "id": 1304,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4194.299999999999,
        "temperature": 0,
        "text": " Ah, wow, this took me...",
        "tokens": [
          51332,
          2438,
          11,
          6076,
          11,
          341,
          1890,
          385,
          485,
          51432
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4197.58,
        "id": 1305,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4196.299999999999,
        "temperature": 0,
        "text": " How long was this?",
        "tokens": [
          51432,
          1012,
          938,
          390,
          341,
          30,
          51496
        ]
      },
      {
        "avg_logprob": -0.22029119989146356,
        "compression_ratio": 1.4813084112149533,
        "end": 4200.62,
        "id": 1306,
        "no_speech_prob": 0.005139500834047794,
        "seek": 417494,
        "start": 4197.58,
        "temperature": 0,
        "text": " Did I really spend like 45 minutes on this?",
        "tokens": [
          51496,
          2589,
          286,
          534,
          3496,
          411,
          6905,
          2077,
          322,
          341,
          30,
          51648
        ]
      },
      {
        "avg_logprob": -0.24626882974203532,
        "compression_ratio": 1.3977272727272727,
        "end": 4206.0599999999995,
        "id": 1307,
        "no_speech_prob": 0.0074604167602956295,
        "seek": 420494,
        "start": 4204.94,
        "temperature": 0,
        "text": " Wow, that's crazy if I did.",
        "tokens": [
          50364,
          3153,
          11,
          300,
          311,
          3219,
          498,
          286,
          630,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.24626882974203532,
        "compression_ratio": 1.3977272727272727,
        "end": 4217.259999999999,
        "id": 1308,
        "no_speech_prob": 0.0074604167602956295,
        "seek": 420494,
        "start": 4211.5,
        "temperature": 0,
        "text": " Okay, let's think about what I have time for because there isn't a ton of time left.",
        "tokens": [
          50692,
          1033,
          11,
          718,
          311,
          519,
          466,
          437,
          286,
          362,
          565,
          337,
          570,
          456,
          1943,
          380,
          257,
          2952,
          295,
          565,
          1411,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.24626882974203532,
        "compression_ratio": 1.3977272727272727,
        "end": 4220.78,
        "id": 1309,
        "no_speech_prob": 0.0074604167602956295,
        "seek": 420494,
        "start": 4219.419999999999,
        "temperature": 0,
        "text": " 35 minutes, okay.",
        "tokens": [
          51088,
          6976,
          2077,
          11,
          1392,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.24626882974203532,
        "compression_ratio": 1.3977272727272727,
        "end": 4221.5,
        "id": 1310,
        "no_speech_prob": 0.0074604167602956295,
        "seek": 420494,
        "start": 4220.78,
        "temperature": 0,
        "text": " Maybe that could be...",
        "tokens": [
          51156,
          2704,
          300,
          727,
          312,
          485,
          51192
        ]
      },
      {
        "avg_logprob": -0.24626882974203532,
        "compression_ratio": 1.3977272727272727,
        "end": 4224.46,
        "id": 1311,
        "no_speech_prob": 0.0074604167602956295,
        "seek": 420494,
        "start": 4221.5,
        "temperature": 0,
        "text": " Maybe some of the debugging can be edited out.",
        "tokens": [
          51192,
          2704,
          512,
          295,
          264,
          45592,
          393,
          312,
          23016,
          484,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.24626882974203532,
        "compression_ratio": 1.3977272727272727,
        "end": 4230.62,
        "id": 1312,
        "no_speech_prob": 0.0074604167602956295,
        "seek": 420494,
        "start": 4226.86,
        "temperature": 0,
        "text": " All right, so what do I want to look at next?",
        "tokens": [
          51460,
          1057,
          558,
          11,
          370,
          437,
          360,
          286,
          528,
          281,
          574,
          412,
          958,
          30,
          51648
        ]
      },
      {
        "avg_logprob": -0.384331415934735,
        "compression_ratio": 1.408839779005525,
        "end": 4236.38,
        "id": 1313,
        "no_speech_prob": 0.0009253675816580653,
        "seek": 423062,
        "start": 4231.5,
        "temperature": 0,
        "text": " Let's see if we have time to go back to the...",
        "tokens": [
          50408,
          961,
          311,
          536,
          498,
          321,
          362,
          565,
          281,
          352,
          646,
          281,
          264,
          485,
          50652
        ]
      },
      {
        "avg_logprob": -0.384331415934735,
        "compression_ratio": 1.408839779005525,
        "end": 4243.099999999999,
        "id": 1314,
        "no_speech_prob": 0.0009253675816580653,
        "seek": 423062,
        "start": 4241.98,
        "temperature": 0,
        "text": " I'm sorry, I'm just thinking here.",
        "tokens": [
          50932,
          286,
          478,
          2597,
          11,
          286,
          478,
          445,
          1953,
          510,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.384331415934735,
        "compression_ratio": 1.408839779005525,
        "end": 4248.0599999999995,
        "id": 1315,
        "no_speech_prob": 0.0009253675816580653,
        "seek": 423062,
        "start": 4243.099999999999,
        "temperature": 0,
        "text": " Let's go back to the Node program.",
        "tokens": [
          50988,
          961,
          311,
          352,
          646,
          281,
          264,
          38640,
          1461,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.384331415934735,
        "compression_ratio": 1.408839779005525,
        "end": 4248.86,
        "id": 1316,
        "no_speech_prob": 0.0009253675816580653,
        "seek": 423062,
        "start": 4248.0599999999995,
        "temperature": 0,
        "text": " Let me pull that up.",
        "tokens": [
          51236,
          961,
          385,
          2235,
          300,
          493,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.384331415934735,
        "compression_ratio": 1.408839779005525,
        "end": 4255.42,
        "id": 1317,
        "no_speech_prob": 0.0009253675816580653,
        "seek": 423062,
        "start": 4253.34,
        "temperature": 0,
        "text": " So I'm going to copy this and say API 3.",
        "tokens": [
          51500,
          407,
          286,
          478,
          516,
          281,
          5055,
          341,
          293,
          584,
          9362,
          805,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.384331415934735,
        "compression_ratio": 1.408839779005525,
        "end": 4258.46,
        "id": 1318,
        "no_speech_prob": 0.0009253675816580653,
        "seek": 423062,
        "start": 4255.42,
        "temperature": 0,
        "text": " You know, I realized I haven't posted any of this code on GitHub in so long.",
        "tokens": [
          51604,
          509,
          458,
          11,
          286,
          5334,
          286,
          2378,
          380,
          9437,
          604,
          295,
          341,
          3089,
          322,
          23331,
          294,
          370,
          938,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.5234754268939679,
        "compression_ratio": 1.2462686567164178,
        "end": 4260.54,
        "id": 1319,
        "no_speech_prob": 0.0006563692004419863,
        "seek": 425846,
        "start": 4258.54,
        "temperature": 0,
        "text": " Let's go make API 3.",
        "tokens": [
          50368,
          961,
          311,
          352,
          652,
          9362,
          805,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.5234754268939679,
        "compression_ratio": 1.2462686567164178,
        "end": 4271.9,
        "id": 1320,
        "no_speech_prob": 0.0006563692004419863,
        "seek": 425846,
        "start": 4269.5,
        "temperature": 0,
        "text": " And let's go to...",
        "tokens": [
          50916,
          400,
          718,
          311,
          352,
          281,
          485,
          51036
        ]
      },
      {
        "avg_logprob": -0.5234754268939679,
        "compression_ratio": 1.2462686567164178,
        "end": 4279.42,
        "id": 1321,
        "no_speech_prob": 0.0006563692004419863,
        "seek": 425846,
        "start": 4272.7,
        "temperature": 0,
        "text": " I will be doing tutorials about machine learning in 2017.",
        "tokens": [
          51076,
          286,
          486,
          312,
          884,
          17616,
          466,
          3479,
          2539,
          294,
          6591,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.5234754268939679,
        "compression_ratio": 1.2462686567164178,
        "end": 4284.06,
        "id": 1322,
        "no_speech_prob": 0.0006563692004419863,
        "seek": 425846,
        "start": 4279.42,
        "temperature": 0,
        "text": " Maybe I'll do some on this all-day adventure that I would like to do.",
        "tokens": [
          51412,
          2704,
          286,
          603,
          360,
          512,
          322,
          341,
          439,
          12,
          810,
          9868,
          300,
          286,
          576,
          411,
          281,
          360,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4287.820000000001,
        "id": 1323,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4284.3,
        "temperature": 0,
        "text": " I'm trying to finish up this other list that I have first.",
        "tokens": [
          50376,
          286,
          478,
          1382,
          281,
          2413,
          493,
          341,
          661,
          1329,
          300,
          286,
          362,
          700,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4290.780000000001,
        "id": 1324,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4288.860000000001,
        "temperature": 0,
        "text": " So let's just say Node server.",
        "tokens": [
          50604,
          407,
          718,
          311,
          445,
          584,
          38640,
          7154,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4292.860000000001,
        "id": 1325,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4291.34,
        "temperature": 0,
        "text": " Let's see what this is doing.",
        "tokens": [
          50728,
          961,
          311,
          536,
          437,
          341,
          307,
          884,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4300.46,
        "id": 1326,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4296.46,
        "temperature": 0,
        "text": " Oops, I'm sorry, localhost 3000.",
        "tokens": [
          50984,
          21726,
          11,
          286,
          478,
          2597,
          11,
          2654,
          6037,
          20984,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4302.14,
        "id": 1327,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4301.5,
        "temperature": 0,
        "text": " Okay, right.",
        "tokens": [
          51236,
          1033,
          11,
          558,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4308.06,
        "id": 1328,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4303.02,
        "temperature": 0,
        "text": " So now I remember that this, if you recall where I was last,",
        "tokens": [
          51312,
          407,
          586,
          286,
          1604,
          300,
          341,
          11,
          498,
          291,
          9901,
          689,
          286,
          390,
          1036,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.6100196838378906,
        "compression_ratio": 1.417989417989418,
        "end": 4311.42,
        "id": 1329,
        "no_speech_prob": 0.001700701774097979,
        "seek": 428406,
        "start": 4308.620000000001,
        "temperature": 0,
        "text": " is I made a simple list of all the nodes.",
        "tokens": [
          51592,
          307,
          286,
          1027,
          257,
          2199,
          1329,
          295,
          439,
          264,
          13891,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.8168471336364747,
        "compression_ratio": 1.1938775510204083,
        "end": 4313.5,
        "id": 1330,
        "no_speech_prob": 0.006692738272249699,
        "seek": 431142,
        "start": 4311.42,
        "temperature": 0,
        "text": " And let me open this one up too.",
        "tokens": [
          50364,
          400,
          718,
          385,
          1269,
          341,
          472,
          493,
          886,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.8168471336364747,
        "compression_ratio": 1.1938775510204083,
        "end": 4314,
        "id": 1331,
        "no_speech_prob": 0.006692738272249699,
        "seek": 431142,
        "start": 4313.5,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50468,
          4919,
          13,
          50493
        ]
      },
      {
        "avg_logprob": -0.8168471336364747,
        "compression_ratio": 1.1938775510204083,
        "end": 4326.38,
        "id": 1332,
        "no_speech_prob": 0.006692738272249699,
        "seek": 431142,
        "start": 4318.38,
        "temperature": 0,
        "text": " I made a simple API that allows you to",
        "tokens": [
          50712,
          286,
          1027,
          257,
          2199,
          9362,
          300,
          4045,
          291,
          281,
          51112
        ]
      },
      {
        "avg_logprob": -0.8168471336364747,
        "compression_ratio": 1.1938775510204083,
        "end": 4336.78,
        "id": 1333,
        "no_speech_prob": 0.006692738272249699,
        "seek": 431142,
        "start": 4330.78,
        "temperature": 0,
        "text": " add a word with a score to a database.",
        "tokens": [
          51332,
          909,
          257,
          1349,
          365,
          257,
          6175,
          281,
          257,
          8149,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.27499174460386616,
        "compression_ratio": 1.461111111111111,
        "end": 4341.74,
        "id": 1334,
        "no_speech_prob": 0.0002131867513526231,
        "seek": 433678,
        "start": 4337.099999999999,
        "temperature": 0,
        "text": " Add a word with a score to a database.",
        "tokens": [
          50380,
          5349,
          257,
          1349,
          365,
          257,
          6175,
          281,
          257,
          8149,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.27499174460386616,
        "compression_ratio": 1.461111111111111,
        "end": 4354.94,
        "id": 1335,
        "no_speech_prob": 0.0002131867513526231,
        "seek": 433678,
        "start": 4343.42,
        "temperature": 0,
        "text": " And so you could build, you could have a crowdsourced AFIN111 style list.",
        "tokens": [
          50696,
          400,
          370,
          291,
          727,
          1322,
          11,
          291,
          727,
          362,
          257,
          26070,
          396,
          1232,
          20389,
          1464,
          5348,
          16,
          3758,
          1329,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.27499174460386616,
        "compression_ratio": 1.461111111111111,
        "end": 4361.66,
        "id": 1336,
        "no_speech_prob": 0.0002131867513526231,
        "seek": 433678,
        "start": 4355.5,
        "temperature": 0,
        "text": " And you can see this is a front end to this that shows you everything that's been in there so far.",
        "tokens": [
          51300,
          400,
          291,
          393,
          536,
          341,
          307,
          257,
          1868,
          917,
          281,
          341,
          300,
          3110,
          291,
          1203,
          300,
          311,
          668,
          294,
          456,
          370,
          1400,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.27499174460386616,
        "compression_ratio": 1.461111111111111,
        "end": 4364.3,
        "id": 1337,
        "no_speech_prob": 0.0002131867513526231,
        "seek": 433678,
        "start": 4361.66,
        "temperature": 0,
        "text": " So if I were to add happy and give it a score of 5,",
        "tokens": [
          51608,
          407,
          498,
          286,
          645,
          281,
          909,
          2055,
          293,
          976,
          309,
          257,
          6175,
          295,
          1025,
          11,
          51740
        ]
      },
      {
        "avg_logprob": -0.21133210442282938,
        "compression_ratio": 1.4927536231884058,
        "end": 4370.22,
        "id": 1338,
        "no_speech_prob": 0.00006205028330441564,
        "seek": 436430,
        "start": 4365.1,
        "temperature": 0,
        "text": " if I were to add sad and give it a score of negative 3, you can see those show up.",
        "tokens": [
          50404,
          498,
          286,
          645,
          281,
          909,
          4227,
          293,
          976,
          309,
          257,
          6175,
          295,
          3671,
          805,
          11,
          291,
          393,
          536,
          729,
          855,
          493,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.21133210442282938,
        "compression_ratio": 1.4927536231884058,
        "end": 4375.1,
        "id": 1339,
        "no_speech_prob": 0.00006205028330441564,
        "seek": 436430,
        "start": 4370.22,
        "temperature": 0,
        "text": " And the API also, if I go to this particular route slash all,",
        "tokens": [
          50660,
          400,
          264,
          9362,
          611,
          11,
          498,
          286,
          352,
          281,
          341,
          1729,
          7955,
          17330,
          439,
          11,
          50904
        ]
      },
      {
        "avg_logprob": -0.21133210442282938,
        "compression_ratio": 1.4927536231884058,
        "end": 4379.26,
        "id": 1340,
        "no_speech_prob": 0.00006205028330441564,
        "seek": 436430,
        "start": 4376.46,
        "temperature": 0,
        "text": " shows me everything that's currently in the database.",
        "tokens": [
          50972,
          3110,
          385,
          1203,
          300,
          311,
          4362,
          294,
          264,
          8149,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.21133210442282938,
        "compression_ratio": 1.4927536231884058,
        "end": 4383.74,
        "id": 1341,
        "no_speech_prob": 0.00006205028330441564,
        "seek": 436430,
        "start": 4379.26,
        "temperature": 0,
        "text": " It's not really a database, it's just a text file and their scores.",
        "tokens": [
          51112,
          467,
          311,
          406,
          534,
          257,
          8149,
          11,
          309,
          311,
          445,
          257,
          2487,
          3991,
          293,
          641,
          13444,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.21133210442282938,
        "compression_ratio": 1.4927536231884058,
        "end": 4387.26,
        "id": 1342,
        "no_speech_prob": 0.00006205028330441564,
        "seek": 436430,
        "start": 4383.74,
        "temperature": 0,
        "text": " So what I think I would like to do now is,",
        "tokens": [
          51336,
          407,
          437,
          286,
          519,
          286,
          576,
          411,
          281,
          360,
          586,
          307,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.2597514833722796,
        "compression_ratio": 1.4727272727272727,
        "end": 4388.72,
        "id": 1343,
        "no_speech_prob": 0.0019569899886846542,
        "seek": 438726,
        "start": 4388.22,
        "temperature": 0,
        "text": " is,",
        "tokens": [
          50412,
          307,
          11,
          50437
        ]
      },
      {
        "avg_logprob": -0.2597514833722796,
        "compression_ratio": 1.4727272727272727,
        "end": 4395.42,
        "id": 1344,
        "no_speech_prob": 0.0019569899886846542,
        "seek": 438726,
        "start": 4391.26,
        "temperature": 0,
        "text": " is, I'm sorry, I'm reading the chat's interesting suggestions there.",
        "tokens": [
          50564,
          307,
          11,
          286,
          478,
          2597,
          11,
          286,
          478,
          3760,
          264,
          5081,
          311,
          1880,
          13396,
          456,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.2597514833722796,
        "compression_ratio": 1.4727272727272727,
        "end": 4401.26,
        "id": 1345,
        "no_speech_prob": 0.0019569899886846542,
        "seek": 438726,
        "start": 4395.42,
        "temperature": 0,
        "text": " What I would like to do now is finally finish off this example by adding,",
        "tokens": [
          50772,
          708,
          286,
          576,
          411,
          281,
          360,
          586,
          307,
          2721,
          2413,
          766,
          341,
          1365,
          538,
          5127,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2597514833722796,
        "compression_ratio": 1.4727272727272727,
        "end": 4411.74,
        "id": 1346,
        "no_speech_prob": 0.0019569899886846542,
        "seek": 438726,
        "start": 4404.22,
        "temperature": 0,
        "text": " adding the ability to put text into a text field, post it to the API,",
        "tokens": [
          51212,
          5127,
          264,
          3485,
          281,
          829,
          2487,
          666,
          257,
          2487,
          2519,
          11,
          2183,
          309,
          281,
          264,
          9362,
          11,
          51588
        ]
      },
      {
        "avg_logprob": -0.2597514833722796,
        "compression_ratio": 1.4727272727272727,
        "end": 4415.18,
        "id": 1347,
        "no_speech_prob": 0.0019569899886846542,
        "seek": 438726,
        "start": 4413.26,
        "temperature": 0,
        "text": " and then get a score back.",
        "tokens": [
          51664,
          293,
          550,
          483,
          257,
          6175,
          646,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4422.700000000001,
        "id": 1348,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4416.14,
        "temperature": 0,
        "text": " And then also combine this list with the AFIN111 list.",
        "tokens": [
          50412,
          400,
          550,
          611,
          10432,
          341,
          1329,
          365,
          264,
          20389,
          1464,
          5348,
          16,
          1329,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4423.200000000001,
        "id": 1349,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4422.700000000001,
        "temperature": 0,
        "text": " OK?",
        "tokens": [
          50740,
          2264,
          30,
          50765
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4425.12,
        "id": 1350,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4424.62,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50836,
          2264,
          13,
          50861
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4427.18,
        "id": 1351,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4426.3,
        "temperature": 0,
        "text": " So I'm going to do that.",
        "tokens": [
          50920,
          407,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4429.26,
        "id": 1352,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4427.18,
        "temperature": 0,
        "text": " That'll be, unfortunately, the last thing I'm going to do today.",
        "tokens": [
          50964,
          663,
          603,
          312,
          11,
          7015,
          11,
          264,
          1036,
          551,
          286,
          478,
          516,
          281,
          360,
          965,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4431.1,
        "id": 1353,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4429.26,
        "temperature": 0,
        "text": " I had ambitions of getting further.",
        "tokens": [
          51068,
          286,
          632,
          34475,
          295,
          1242,
          3052,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4439.26,
        "id": 1354,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4434.22,
        "temperature": 0,
        "text": " But I do really want to finish this playlist about building your own API in Node.",
        "tokens": [
          51316,
          583,
          286,
          360,
          534,
          528,
          281,
          2413,
          341,
          16788,
          466,
          2390,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4440.780000000001,
        "id": 1355,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4440.54,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51632,
          2264,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4441.9800000000005,
        "id": 1356,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4440.780000000001,
        "temperature": 0,
        "text": " Ah, it's 3 a.m. in India.",
        "tokens": [
          51644,
          2438,
          11,
          309,
          311,
          805,
          257,
          13,
          76,
          13,
          294,
          5282,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.20722241061074392,
        "compression_ratio": 1.478448275862069,
        "end": 4443.5,
        "id": 1357,
        "no_speech_prob": 0.00000350084474121104,
        "seek": 441518,
        "start": 4441.9800000000005,
        "temperature": 0,
        "text": " I'm impressed that you're up and watching.",
        "tokens": [
          51704,
          286,
          478,
          11679,
          300,
          291,
          434,
          493,
          293,
          1976,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.34562387466430666,
        "compression_ratio": 0.8888888888888888,
        "end": 4444.94,
        "id": 1358,
        "no_speech_prob": 0.003592108841985464,
        "seek": 444350,
        "start": 4444.22,
        "temperature": 0.2,
        "text": " OK.",
        "tokens": [
          50400,
          2264,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.34562387466430666,
        "compression_ratio": 0.8888888888888888,
        "end": 4447.98,
        "id": 1359,
        "no_speech_prob": 0.003592108841985464,
        "seek": 444350,
        "start": 4444.94,
        "temperature": 0.2,
        "text": " So let me get myself organized here.",
        "tokens": [
          50436,
          407,
          718,
          385,
          483,
          2059,
          9983,
          510,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4479.58,
        "id": 1360,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4473.5,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4480.62,
        "id": 1361,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4479.58,
        "temperature": 0,
        "text": " I think I'm ready.",
        "tokens": [
          50668,
          286,
          519,
          286,
          478,
          1919,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4486.38,
        "id": 1362,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4480.62,
        "temperature": 0,
        "text": " Let me cycle these cameras.",
        "tokens": [
          50720,
          961,
          385,
          6586,
          613,
          8622,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4493.82,
        "id": 1363,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4491.42,
        "temperature": 0,
        "text": " And let me make sure I have my pen and eraser.",
        "tokens": [
          51260,
          400,
          718,
          385,
          652,
          988,
          286,
          362,
          452,
          3435,
          293,
          46018,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4496.3,
        "id": 1364,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4494.7,
        "temperature": 0,
        "text": " Hey, somebody's in Bushwick watching.",
        "tokens": [
          51424,
          1911,
          11,
          2618,
          311,
          294,
          15782,
          16038,
          1976,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4497.26,
        "id": 1365,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4496.3,
        "temperature": 0,
        "text": " That's not too far away.",
        "tokens": [
          51504,
          663,
          311,
          406,
          886,
          1400,
          1314,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4498.54,
        "id": 1366,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4497.26,
        "temperature": 0,
        "text": " I'm impressed and amazed.",
        "tokens": [
          51552,
          286,
          478,
          11679,
          293,
          20507,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4500.72,
        "id": 1367,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4500.22,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51700,
          2264,
          13,
          51725
        ]
      },
      {
        "avg_logprob": -0.2414527841516443,
        "compression_ratio": 1.30625,
        "end": 4501.82,
        "id": 1368,
        "no_speech_prob": 0.0036498364061117172,
        "seek": 447350,
        "start": 4501.34,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51756,
          1692,
          321,
          352,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4504.56,
        "id": 1369,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4504.06,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50392,
          1057,
          558,
          13,
          50417
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4510.38,
        "id": 1370,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4508.62,
        "temperature": 0,
        "text": " Welcome to another.",
        "tokens": [
          50620,
          4027,
          281,
          1071,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4513.9,
        "id": 1371,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4512.86,
        "temperature": 0,
        "text": " We started that over.",
        "tokens": [
          50832,
          492,
          1409,
          300,
          670,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4521.42,
        "id": 1372,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4518.3,
        "temperature": 0,
        "text": " My throat has really never recovered from that illness I had a month ago.",
        "tokens": [
          51104,
          1222,
          12394,
          575,
          534,
          1128,
          19542,
          490,
          300,
          10152,
          286,
          632,
          257,
          1618,
          2057,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4521.92,
        "id": 1373,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4521.42,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51260,
          2264,
          13,
          51285
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4526.38,
        "id": 1374,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4524.06,
        "temperature": 0,
        "text": " Welcome to yet another.",
        "tokens": [
          51392,
          4027,
          281,
          1939,
          1071,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.35526613603558455,
        "compression_ratio": 1.4206349206349207,
        "end": 4529.1,
        "id": 1375,
        "no_speech_prob": 0.0033765279222279787,
        "seek": 450350,
        "start": 4527.98,
        "temperature": 0,
        "text": " I'm losing my mind here.",
        "tokens": [
          51588,
          286,
          478,
          7027,
          452,
          1575,
          510,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4533.9800000000005,
        "id": 1376,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4529.58,
        "temperature": 0,
        "text": " Welcome to another and what might possibly actually be the last video in this",
        "tokens": [
          50388,
          4027,
          281,
          1071,
          293,
          437,
          1062,
          6264,
          767,
          312,
          264,
          1036,
          960,
          294,
          341,
          50608
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4538.06,
        "id": 1377,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4533.9800000000005,
        "temperature": 0,
        "text": " playlist about how to build your own API in Node.",
        "tokens": [
          50608,
          16788,
          466,
          577,
          281,
          1322,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4541.58,
        "id": 1378,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4538.06,
        "temperature": 0,
        "text": " So if you remember, you might have just watched the last video.",
        "tokens": [
          50812,
          407,
          498,
          291,
          1604,
          11,
          291,
          1062,
          362,
          445,
          6337,
          264,
          1036,
          960,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4543.1,
        "id": 1379,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4541.58,
        "temperature": 0,
        "text": " But it's been a while since I made it.",
        "tokens": [
          50988,
          583,
          309,
          311,
          668,
          257,
          1339,
          1670,
          286,
          1027,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4545.9800000000005,
        "id": 1380,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4543.1,
        "temperature": 0,
        "text": " So I'm going to just kind of set the stage here very, very briefly.",
        "tokens": [
          51064,
          407,
          286,
          478,
          516,
          281,
          445,
          733,
          295,
          992,
          264,
          3233,
          510,
          588,
          11,
          588,
          10515,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4554.780000000001,
        "id": 1381,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4547.02,
        "temperature": 0,
        "text": " We have so far an API made in Node that saves words and a score, a kind of positive or negative",
        "tokens": [
          51260,
          492,
          362,
          370,
          1400,
          364,
          9362,
          1027,
          294,
          38640,
          300,
          19155,
          2283,
          293,
          257,
          6175,
          11,
          257,
          733,
          295,
          3353,
          420,
          3671,
          51648
        ]
      },
      {
        "avg_logprob": -0.3254638421730917,
        "compression_ratio": 1.644927536231884,
        "end": 4557.42,
        "id": 1382,
        "no_speech_prob": 0.000597663049120456,
        "seek": 452910,
        "start": 4554.780000000001,
        "temperature": 0,
        "text": " valence, the idea that we're going to do a sentimental API.",
        "tokens": [
          51648,
          1323,
          655,
          11,
          264,
          1558,
          300,
          321,
          434,
          516,
          281,
          360,
          257,
          2279,
          332,
          14533,
          9362,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4564.3,
        "id": 1383,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4557.9800000000005,
        "temperature": 0,
        "text": " We have a particular route where if I go to the server slash all, I can see all the words",
        "tokens": [
          50392,
          492,
          362,
          257,
          1729,
          7955,
          689,
          498,
          286,
          352,
          281,
          264,
          7154,
          17330,
          439,
          11,
          286,
          393,
          536,
          439,
          264,
          2283,
          50708
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4566.46,
        "id": 1384,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4564.3,
        "temperature": 0,
        "text": " that are in a particular in that database.",
        "tokens": [
          50708,
          300,
          366,
          294,
          257,
          1729,
          294,
          300,
          8149,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4573.58,
        "id": 1385,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4566.46,
        "temperature": 0,
        "text": " I also made a little front end that if I add a word like kitten and I give it a score like",
        "tokens": [
          50816,
          286,
          611,
          1027,
          257,
          707,
          1868,
          917,
          300,
          498,
          286,
          909,
          257,
          1349,
          411,
          39696,
          293,
          286,
          976,
          309,
          257,
          6175,
          411,
          51172
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4579.5,
        "id": 1386,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4573.58,
        "temperature": 0,
        "text": " four and I hit submit and then I can hit refresh here and we can see now kitten has now been",
        "tokens": [
          51172,
          1451,
          293,
          286,
          2045,
          10315,
          293,
          550,
          286,
          393,
          2045,
          15134,
          510,
          293,
          321,
          393,
          536,
          586,
          39696,
          575,
          586,
          668,
          51468
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4580.78,
        "id": 1387,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4579.5,
        "temperature": 0,
        "text": " added to that database.",
        "tokens": [
          51468,
          3869,
          281,
          300,
          8149,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4582.62,
        "id": 1388,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4580.78,
        "temperature": 0,
        "text": " Now it's a little bit more complicated than that.",
        "tokens": [
          51532,
          823,
          309,
          311,
          257,
          707,
          857,
          544,
          6179,
          813,
          300,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.5517199666876542,
        "compression_ratio": 1.852813852813853,
        "end": 4583.9800000000005,
        "id": 1389,
        "no_speech_prob": 0.02002282813191414,
        "seek": 455742,
        "start": 4582.62,
        "temperature": 0,
        "text": " But it's a little bit more intuitive.",
        "tokens": [
          51624,
          583,
          309,
          311,
          257,
          707,
          857,
          544,
          21769,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.1824605962732336,
        "compression_ratio": 1.5909090909090908,
        "end": 4587.099999999999,
        "id": 1390,
        "no_speech_prob": 0.16235964000225067,
        "seek": 458398,
        "start": 4584.0599999999995,
        "temperature": 0,
        "text": " We can see now kitten has now been added to that database.",
        "tokens": [
          50368,
          492,
          393,
          536,
          586,
          39696,
          575,
          586,
          668,
          3869,
          281,
          300,
          8149,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.1824605962732336,
        "compression_ratio": 1.5909090909090908,
        "end": 4589.099999999999,
        "id": 1391,
        "no_speech_prob": 0.16235964000225067,
        "seek": 458398,
        "start": 4587.099999999999,
        "temperature": 0,
        "text": " Now it's not actually a database.",
        "tokens": [
          50520,
          823,
          309,
          311,
          406,
          767,
          257,
          8149,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.1824605962732336,
        "compression_ratio": 1.5909090909090908,
        "end": 4594.139999999999,
        "id": 1392,
        "no_speech_prob": 0.16235964000225067,
        "seek": 458398,
        "start": 4589.099999999999,
        "temperature": 0,
        "text": " It is simply just a list, a JSON file.",
        "tokens": [
          50620,
          467,
          307,
          2935,
          445,
          257,
          1329,
          11,
          257,
          31828,
          3991,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.1824605962732336,
        "compression_ratio": 1.5909090909090908,
        "end": 4599.0199999999995,
        "id": 1393,
        "no_speech_prob": 0.16235964000225067,
        "seek": 458398,
        "start": 4594.139999999999,
        "temperature": 0,
        "text": " But the Node program is receiving the word and score from the client, saving it to the",
        "tokens": [
          50872,
          583,
          264,
          38640,
          1461,
          307,
          10040,
          264,
          1349,
          293,
          6175,
          490,
          264,
          6423,
          11,
          6816,
          309,
          281,
          264,
          51116
        ]
      },
      {
        "avg_logprob": -0.1824605962732336,
        "compression_ratio": 1.5909090909090908,
        "end": 4601.419999999999,
        "id": 1394,
        "no_speech_prob": 0.16235964000225067,
        "seek": 458398,
        "start": 4599.0199999999995,
        "temperature": 0,
        "text": " JSON file and loading again for later use.",
        "tokens": [
          51116,
          31828,
          3991,
          293,
          15114,
          797,
          337,
          1780,
          764,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.1824605962732336,
        "compression_ratio": 1.5909090909090908,
        "end": 4606.139999999999,
        "id": 1395,
        "no_speech_prob": 0.16235964000225067,
        "seek": 458398,
        "start": 4601.419999999999,
        "temperature": 0,
        "text": " So there are two things in this video that I want to add to this particular application.",
        "tokens": [
          51236,
          407,
          456,
          366,
          732,
          721,
          294,
          341,
          960,
          300,
          286,
          528,
          281,
          909,
          281,
          341,
          1729,
          3861,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4614.3,
        "id": 1396,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4606.14,
        "temperature": 0,
        "text": " Number one, I want to add a pre-existing list of words and valence scores.",
        "tokens": [
          50364,
          5118,
          472,
          11,
          286,
          528,
          281,
          909,
          257,
          659,
          12,
          36447,
          1329,
          295,
          2283,
          293,
          1323,
          655,
          13444,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4617.02,
        "id": 1397,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4614.3,
        "temperature": 0,
        "text": " And this list is known as the AFIN111.",
        "tokens": [
          50772,
          400,
          341,
          1329,
          307,
          2570,
          382,
          264,
          20389,
          1464,
          5348,
          16,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4620.860000000001,
        "id": 1398,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4617.02,
        "temperature": 0,
        "text": " So this will just make the sentiment analysis work a little better by giving us seeding",
        "tokens": [
          50908,
          407,
          341,
          486,
          445,
          652,
          264,
          16149,
          5215,
          589,
          257,
          707,
          1101,
          538,
          2902,
          505,
          8871,
          278,
          51100
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4623.18,
        "id": 1399,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4620.860000000001,
        "temperature": 0,
        "text": " it with a pre-existing list of words.",
        "tokens": [
          51100,
          309,
          365,
          257,
          659,
          12,
          36447,
          1329,
          295,
          2283,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4627.34,
        "id": 1400,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4623.18,
        "temperature": 0,
        "text": " I made a separate video where I went over this in more detail, which I'll link to in",
        "tokens": [
          51216,
          286,
          1027,
          257,
          4994,
          960,
          689,
          286,
          1437,
          670,
          341,
          294,
          544,
          2607,
          11,
          597,
          286,
          603,
          2113,
          281,
          294,
          51424
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4627.820000000001,
        "id": 1401,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4627.34,
        "temperature": 0,
        "text": " this.",
        "tokens": [
          51424,
          341,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4632.22,
        "id": 1402,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4627.820000000001,
        "temperature": 0,
        "text": " But this list comes from this particular website.",
        "tokens": [
          51448,
          583,
          341,
          1329,
          1487,
          490,
          341,
          1729,
          3144,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.19455347061157227,
        "compression_ratio": 1.6145038167938932,
        "end": 4634.46,
        "id": 1403,
        "no_speech_prob": 0.013847974129021168,
        "seek": 460614,
        "start": 4632.22,
        "temperature": 0,
        "text": " And it was developed by Finn Arup-Nielsen.",
        "tokens": [
          51668,
          400,
          309,
          390,
          4743,
          538,
          21066,
          316,
          11976,
          12,
          45,
          1187,
          6748,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4636.62,
        "id": 1404,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4634.46,
        "temperature": 0,
        "text": " And if you use it, you should credit it.",
        "tokens": [
          50364,
          400,
          498,
          291,
          764,
          309,
          11,
          291,
          820,
          5397,
          309,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4639.1,
        "id": 1405,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4636.62,
        "temperature": 0,
        "text": " And there's links and information about how to do that here.",
        "tokens": [
          50472,
          400,
          456,
          311,
          6123,
          293,
          1589,
          466,
          577,
          281,
          360,
          300,
          510,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4641.66,
        "id": 1406,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4640.46,
        "temperature": 0,
        "text": " OK, so that exists.",
        "tokens": [
          50664,
          2264,
          11,
          370,
          300,
          8198,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4642.46,
        "id": 1407,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4641.66,
        "temperature": 0,
        "text": " That's number one.",
        "tokens": [
          50724,
          663,
          311,
          1230,
          472,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4643.58,
        "id": 1408,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4642.46,
        "temperature": 0,
        "text": " I want to bring that list over.",
        "tokens": [
          50764,
          286,
          528,
          281,
          1565,
          300,
          1329,
          670,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4645.1,
        "id": 1409,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4643.58,
        "temperature": 0,
        "text": " Let's actually do that first.",
        "tokens": [
          50820,
          961,
          311,
          767,
          360,
          300,
          700,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4646.94,
        "id": 1410,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4645.1,
        "temperature": 0,
        "text": " I'll say what the number two is in a second.",
        "tokens": [
          50896,
          286,
          603,
          584,
          437,
          264,
          1230,
          732,
          307,
          294,
          257,
          1150,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4649.66,
        "id": 1411,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4646.94,
        "temperature": 0,
        "text": " Number two is I want to look at a post to the API.",
        "tokens": [
          50988,
          5118,
          732,
          307,
          286,
          528,
          281,
          574,
          412,
          257,
          2183,
          281,
          264,
          9362,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4650.94,
        "id": 1412,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4649.66,
        "temperature": 0,
        "text": " What's the difference between get and post?",
        "tokens": [
          51124,
          708,
          311,
          264,
          2649,
          1296,
          483,
          293,
          2183,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4652.54,
        "id": 1413,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4650.94,
        "temperature": 0,
        "text": " That's going to be part of this video too.",
        "tokens": [
          51188,
          663,
          311,
          516,
          281,
          312,
          644,
          295,
          341,
          960,
          886,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4655.9,
        "id": 1414,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4652.54,
        "temperature": 0,
        "text": " So I'm actually just going to absurdly just do save as.",
        "tokens": [
          51268,
          407,
          286,
          478,
          767,
          445,
          516,
          281,
          19774,
          356,
          445,
          360,
          3155,
          382,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4659.34,
        "id": 1415,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4655.9,
        "temperature": 0,
        "text": " And I'm going to go to my Node folder.",
        "tokens": [
          51436,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          452,
          38640,
          10820,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.1574474103523023,
        "compression_ratio": 1.73421926910299,
        "end": 4662.78,
        "id": 1416,
        "no_speech_prob": 0.0002959541161544621,
        "seek": 463446,
        "start": 4659.34,
        "temperature": 0,
        "text": " And I'm going to save it as AFIN111.json.",
        "tokens": [
          51608,
          400,
          286,
          478,
          516,
          281,
          3155,
          309,
          382,
          20389,
          1464,
          5348,
          16,
          13,
          73,
          3015,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4664.86,
        "id": 1417,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4662.78,
        "temperature": 0,
        "text": " And then I'm going to go to the server.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          7154,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4669.66,
        "id": 1418,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4664.86,
        "temperature": 0,
        "text": " And we're going to look at where the server loads.",
        "tokens": [
          50468,
          400,
          321,
          434,
          516,
          281,
          574,
          412,
          689,
          264,
          7154,
          12668,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4673.34,
        "id": 1419,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4671.58,
        "temperature": 0,
        "text": " Where does the server load that file?",
        "tokens": [
          50804,
          2305,
          775,
          264,
          7154,
          3677,
          300,
          3991,
          30,
          50892
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4673.9,
        "id": 1420,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4673.34,
        "temperature": 0,
        "text": " Right here.",
        "tokens": [
          50892,
          1779,
          510,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4677.5,
        "id": 1421,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4674.54,
        "temperature": 0,
        "text": " var data equals readFileSyncWords.json.",
        "tokens": [
          50952,
          1374,
          1412,
          6915,
          1401,
          37,
          794,
          50,
          34015,
          54,
          5703,
          13,
          73,
          3015,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4687.58,
        "id": 1422,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4677.5,
        "temperature": 0,
        "text": " So I also want to load AFIN111.json into a variable called AFIN.",
        "tokens": [
          51100,
          407,
          286,
          611,
          528,
          281,
          3677,
          20389,
          1464,
          5348,
          16,
          13,
          73,
          3015,
          666,
          257,
          7006,
          1219,
          20389,
          1464,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.19373272834940158,
        "compression_ratio": 1.4973262032085561,
        "end": 4691.98,
        "id": 1423,
        "no_speech_prob": 0.0008040760294534266,
        "seek": 466278,
        "start": 4688.54,
        "temperature": 0,
        "text": " Actually, I'll call this AFINData.",
        "tokens": [
          51652,
          5135,
          11,
          286,
          603,
          818,
          341,
          20389,
          1464,
          35,
          3274,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4700.38,
        "id": 1424,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4693.5,
        "temperature": 0,
        "text": " And then I want to say var data equals json.parse AFINData.",
        "tokens": [
          50400,
          400,
          550,
          286,
          528,
          281,
          584,
          1374,
          1412,
          6915,
          361,
          3015,
          13,
          2181,
          405,
          20389,
          18323,
          3274,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4701.099999999999,
        "id": 1425,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4700.38,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          50744,
          876,
          11,
          572,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4701.34,
        "id": 1426,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4701.099999999999,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50780,
          4919,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4702.46,
        "id": 1427,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4701.34,
        "temperature": 0,
        "text": " Var AFIN.",
        "tokens": [
          50792,
          14662,
          20389,
          1464,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4708.7,
        "id": 1428,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4702.46,
        "temperature": 0,
        "text": " So now my Node server has both the word list that's being saved",
        "tokens": [
          50848,
          407,
          586,
          452,
          38640,
          7154,
          575,
          1293,
          264,
          1349,
          1329,
          300,
          311,
          885,
          6624,
          51160
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4710.94,
        "id": 1429,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4709.259999999999,
        "temperature": 0,
        "text": " and the AFIN list.",
        "tokens": [
          51188,
          293,
          264,
          20389,
          1464,
          1329,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4712.0599999999995,
        "id": 1430,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4710.94,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          51272,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4716.3,
        "id": 1431,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4714.0599999999995,
        "temperature": 0,
        "text": " So I think what I want to do is just change this.",
        "tokens": [
          51428,
          407,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          307,
          445,
          1319,
          341,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4718.219999999999,
        "id": 1432,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4716.3,
        "temperature": 0,
        "text": " I'm going to change this to additional.",
        "tokens": [
          51540,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          4497,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.20002802068536932,
        "compression_ratio": 1.5714285714285714,
        "end": 4720.219999999999,
        "id": 1433,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 469278,
        "start": 4718.219999999999,
        "temperature": 0,
        "text": " I think I'm going to keep these in separate files",
        "tokens": [
          51636,
          286,
          519,
          286,
          478,
          516,
          281,
          1066,
          613,
          294,
          4994,
          7098,
          51736
        ]
      },
      {
        "avg_logprob": -0.22526452480218348,
        "compression_ratio": 1.5562130177514792,
        "end": 4723.5,
        "id": 1434,
        "no_speech_prob": 0.00008481073746224865,
        "seek": 472022,
        "start": 4720.22,
        "temperature": 0,
        "text": " because this AFIN111 is never going to change.",
        "tokens": [
          50364,
          570,
          341,
          20389,
          1464,
          5348,
          16,
          307,
          1128,
          516,
          281,
          1319,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.22526452480218348,
        "compression_ratio": 1.5562130177514792,
        "end": 4733.5,
        "id": 1435,
        "no_speech_prob": 0.00008481073746224865,
        "seek": 472022,
        "start": 4724.3,
        "temperature": 0,
        "text": " And what I want to do is, but I'm going to call that file additional just for clarification.",
        "tokens": [
          50568,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          457,
          286,
          478,
          516,
          281,
          818,
          300,
          3991,
          4497,
          445,
          337,
          34449,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.22526452480218348,
        "compression_ratio": 1.5562130177514792,
        "end": 4735.18,
        "id": 1436,
        "no_speech_prob": 0.00008481073746224865,
        "seek": 472022,
        "start": 4734.62,
        "temperature": 0,
        "text": " Additional.",
        "tokens": [
          51084,
          44272,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.22526452480218348,
        "compression_ratio": 1.5562130177514792,
        "end": 4741.9800000000005,
        "id": 1437,
        "no_speech_prob": 0.00008481073746224865,
        "seek": 472022,
        "start": 4736.780000000001,
        "temperature": 0,
        "text": " And what I want to do now is in the server.",
        "tokens": [
          51192,
          400,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          294,
          264,
          7154,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.22526452480218348,
        "compression_ratio": 1.5562130177514792,
        "end": 4743.740000000001,
        "id": 1438,
        "no_speech_prob": 0.00008481073746224865,
        "seek": 472022,
        "start": 4741.9800000000005,
        "temperature": 0,
        "text": " So I have them as two.",
        "tokens": [
          51452,
          407,
          286,
          362,
          552,
          382,
          732,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.22526452480218348,
        "compression_ratio": 1.5562130177514792,
        "end": 4747.740000000001,
        "id": 1439,
        "no_speech_prob": 0.00008481073746224865,
        "seek": 472022,
        "start": 4743.740000000001,
        "temperature": 0,
        "text": " And I must have a save place somewhere else.",
        "tokens": [
          51540,
          400,
          286,
          1633,
          362,
          257,
          3155,
          1081,
          4079,
          1646,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4751.0199999999995,
        "id": 1440,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4747.74,
        "temperature": 0,
        "text": " So I need to change this to additional as well where I save that file.",
        "tokens": [
          50364,
          407,
          286,
          643,
          281,
          1319,
          341,
          281,
          4497,
          382,
          731,
          689,
          286,
          3155,
          300,
          3991,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4755.5,
        "id": 1441,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4751.0199999999995,
        "temperature": 0,
        "text": " Because what I want to do is when it comes time to do this sentiment analysis,",
        "tokens": [
          50528,
          1436,
          437,
          286,
          528,
          281,
          360,
          307,
          562,
          309,
          1487,
          565,
          281,
          360,
          341,
          16149,
          5215,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4757.9,
        "id": 1442,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4755.5,
        "temperature": 0,
        "text": " I need to look in both of those.",
        "tokens": [
          50752,
          286,
          643,
          281,
          574,
          294,
          1293,
          295,
          729,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4760.139999999999,
        "id": 1443,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4757.9,
        "temperature": 0,
        "text": " I need to look in the AFIN word list.",
        "tokens": [
          50872,
          286,
          643,
          281,
          574,
          294,
          264,
          20389,
          1464,
          1349,
          1329,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4761.0199999999995,
        "id": 1444,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4760.139999999999,
        "temperature": 0,
        "text": " Is it there?",
        "tokens": [
          50984,
          1119,
          309,
          456,
          30,
          51028
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4763.74,
        "id": 1445,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4761.0199999999995,
        "temperature": 0,
        "text": " If not, look in the additional word list.",
        "tokens": [
          51028,
          759,
          406,
          11,
          574,
          294,
          264,
          4497,
          1349,
          1329,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4766.62,
        "id": 1446,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4763.74,
        "temperature": 0,
        "text": " And I should decide if one overrides the other.",
        "tokens": [
          51164,
          400,
          286,
          820,
          4536,
          498,
          472,
          670,
          81,
          1875,
          264,
          661,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4769.82,
        "id": 1447,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4766.62,
        "temperature": 0,
        "text": " In this case, probably the additional should override the AFIN.",
        "tokens": [
          51308,
          682,
          341,
          1389,
          11,
          1391,
          264,
          4497,
          820,
          42321,
          264,
          20389,
          1464,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4771.26,
        "id": 1448,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4769.82,
        "temperature": 0,
        "text": " So I'll look in additional first.",
        "tokens": [
          51468,
          407,
          286,
          603,
          574,
          294,
          4497,
          700,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4771.9,
        "id": 1449,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4771.26,
        "temperature": 0,
        "text": " OK, great.",
        "tokens": [
          51540,
          2264,
          11,
          869,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4773.179999999999,
        "id": 1450,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4771.9,
        "temperature": 0,
        "text": " So actually, done.",
        "tokens": [
          51572,
          407,
          767,
          11,
          1096,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4775.26,
        "id": 1451,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4774.54,
        "temperature": 0,
        "text": " We did it.",
        "tokens": [
          51704,
          492,
          630,
          309,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.1404455491712877,
        "compression_ratio": 1.803088803088803,
        "end": 4775.74,
        "id": 1452,
        "no_speech_prob": 0.035143863409757614,
        "seek": 474774,
        "start": 4775.26,
        "temperature": 0,
        "text": " Yay.",
        "tokens": [
          51740,
          13268,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.214389539744756,
        "compression_ratio": 1.4539473684210527,
        "end": 4777.42,
        "id": 1453,
        "no_speech_prob": 0.00012148163659730926,
        "seek": 477574,
        "start": 4775.74,
        "temperature": 0,
        "text": " But I guess I could in all.",
        "tokens": [
          50364,
          583,
          286,
          2041,
          286,
          727,
          294,
          439,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.214389539744756,
        "compression_ratio": 1.4539473684210527,
        "end": 4780.3,
        "id": 1454,
        "no_speech_prob": 0.00012148163659730926,
        "seek": 477574,
        "start": 4778.38,
        "temperature": 0,
        "text": " Let's look at that all route again.",
        "tokens": [
          50496,
          961,
          311,
          574,
          412,
          300,
          439,
          7955,
          797,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.214389539744756,
        "compression_ratio": 1.4539473684210527,
        "end": 4782.54,
        "id": 1455,
        "no_speech_prob": 0.00012148163659730926,
        "seek": 477574,
        "start": 4781.42,
        "temperature": 0,
        "text": " Let's here.",
        "tokens": [
          50648,
          961,
          311,
          510,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.214389539744756,
        "compression_ratio": 1.4539473684210527,
        "end": 4785.26,
        "id": 1456,
        "no_speech_prob": 0.00012148163659730926,
        "seek": 477574,
        "start": 4782.54,
        "temperature": 0,
        "text": " Let's actually do something kind of a little goofy.",
        "tokens": [
          50704,
          961,
          311,
          767,
          360,
          746,
          733,
          295,
          257,
          707,
          42995,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.214389539744756,
        "compression_ratio": 1.4539473684210527,
        "end": 4793.98,
        "id": 1457,
        "no_speech_prob": 0.00012148163659730926,
        "seek": 477574,
        "start": 4785.26,
        "temperature": 0,
        "text": " I'm going to do, I'm going to say the data is additional is words.",
        "tokens": [
          50840,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          478,
          516,
          281,
          584,
          264,
          1412,
          307,
          4497,
          307,
          2283,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.214389539744756,
        "compression_ratio": 1.4539473684210527,
        "end": 4799.26,
        "id": 1458,
        "no_speech_prob": 0.00012148163659730926,
        "seek": 477574,
        "start": 4793.98,
        "temperature": 0,
        "text": " And AFIN is the AFIN list.",
        "tokens": [
          51276,
          400,
          20389,
          1464,
          307,
          264,
          20389,
          1464,
          1329,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4808.38,
        "id": 1459,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4800.22,
        "temperature": 0,
        "text": " So then, so I'm changing the server when you ask for all to not just give you the words that are",
        "tokens": [
          50412,
          407,
          550,
          11,
          370,
          286,
          478,
          4473,
          264,
          7154,
          562,
          291,
          1029,
          337,
          439,
          281,
          406,
          445,
          976,
          291,
          264,
          2283,
          300,
          366,
          50820
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4809.74,
        "id": 1460,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4808.38,
        "temperature": 0,
        "text": " in the database, but look at both of them.",
        "tokens": [
          50820,
          294,
          264,
          8149,
          11,
          457,
          574,
          412,
          1293,
          295,
          552,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4812.06,
        "id": 1461,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4809.74,
        "temperature": 0,
        "text": " So this is just changing the response of the server.",
        "tokens": [
          50888,
          407,
          341,
          307,
          445,
          4473,
          264,
          4134,
          295,
          264,
          7154,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4816.9400000000005,
        "id": 1462,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4813.26,
        "temperature": 0,
        "text": " And what I'm going to do here, if you go here now, I have to restart the server.",
        "tokens": [
          51064,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          11,
          498,
          291,
          352,
          510,
          586,
          11,
          286,
          362,
          281,
          21022,
          264,
          7154,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4819.9800000000005,
        "id": 1463,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4818.14,
        "temperature": 0,
        "text": " Where, oops, sorry, everybody.",
        "tokens": [
          51308,
          2305,
          11,
          34166,
          11,
          2597,
          11,
          2201,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4821.58,
        "id": 1464,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4819.9800000000005,
        "temperature": 0,
        "text": " I'm going to restart the server.",
        "tokens": [
          51400,
          286,
          478,
          516,
          281,
          21022,
          264,
          7154,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2234998863434123,
        "compression_ratio": 1.797029702970297,
        "end": 4824.06,
        "id": 1465,
        "no_speech_prob": 0.0335889495909214,
        "seek": 479926,
        "start": 4822.780000000001,
        "temperature": 0,
        "text": " And I'm going to do this.",
        "tokens": [
          51540,
          400,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4831.42,
        "id": 1466,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4825.02,
        "temperature": 0,
        "text": " And we can see now I have both the additional list and the AFIN list.",
        "tokens": [
          50412,
          400,
          321,
          393,
          536,
          586,
          286,
          362,
          1293,
          264,
          4497,
          1329,
          293,
          264,
          20389,
          1464,
          1329,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4832.22,
        "id": 1467,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4831.42,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          50732,
          22768,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4840.700000000001,
        "id": 1468,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4832.22,
        "temperature": 0,
        "text": " OK, so now, but this probably broke this part because the way I was parsing, I was using that",
        "tokens": [
          50772,
          2264,
          11,
          370,
          586,
          11,
          457,
          341,
          1391,
          6902,
          341,
          644,
          570,
          264,
          636,
          286,
          390,
          21156,
          278,
          11,
          286,
          390,
          1228,
          300,
          51196
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4841.18,
        "id": 1469,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4840.700000000001,
        "temperature": 0,
        "text": " all route.",
        "tokens": [
          51196,
          439,
          7955,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4841.9800000000005,
        "id": 1470,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4841.18,
        "temperature": 0,
        "text": " But you know what?",
        "tokens": [
          51220,
          583,
          291,
          458,
          437,
          30,
          51260
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4843.900000000001,
        "id": 1471,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4841.9800000000005,
        "temperature": 0,
        "text": " I'm going to get rid of this drawing thing.",
        "tokens": [
          51260,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          341,
          6316,
          551,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4845.18,
        "id": 1472,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4843.900000000001,
        "temperature": 0,
        "text": " It's sort of unnecessary right now.",
        "tokens": [
          51356,
          467,
          311,
          1333,
          295,
          19350,
          558,
          586,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4848.22,
        "id": 1473,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4845.18,
        "temperature": 0,
        "text": " I just want to have this word score interface.",
        "tokens": [
          51420,
          286,
          445,
          528,
          281,
          362,
          341,
          1349,
          6175,
          9226,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.1749000379017421,
        "compression_ratio": 1.5241935483870968,
        "end": 4851.740000000001,
        "id": 1474,
        "no_speech_prob": 0.0005112561630085111,
        "seek": 482406,
        "start": 4848.22,
        "temperature": 0,
        "text": " So let's go back to the client, which is here.",
        "tokens": [
          51572,
          407,
          718,
          311,
          352,
          646,
          281,
          264,
          6423,
          11,
          597,
          307,
          510,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4859.099999999999,
        "id": 1475,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4851.74,
        "temperature": 0,
        "text": " And let's get rid of the draw data thing, which we don't need to do anymore.",
        "tokens": [
          50364,
          400,
          718,
          311,
          483,
          3973,
          295,
          264,
          2642,
          1412,
          551,
          11,
          597,
          321,
          500,
          380,
          643,
          281,
          360,
          3602,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4863.099999999999,
        "id": 1476,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4860.46,
        "temperature": 0,
        "text": " Because we're going to do some different stuff here.",
        "tokens": [
          50800,
          1436,
          321,
          434,
          516,
          281,
          360,
          512,
          819,
          1507,
          510,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4868.38,
        "id": 1477,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4863.98,
        "temperature": 0,
        "text": " So I just want to see that this, I don't need draw data anymore.",
        "tokens": [
          50976,
          407,
          286,
          445,
          528,
          281,
          536,
          300,
          341,
          11,
          286,
          500,
          380,
          643,
          2642,
          1412,
          3602,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4869.5,
        "id": 1478,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4868.38,
        "temperature": 0,
        "text": " I want to see that this works.",
        "tokens": [
          51196,
          286,
          528,
          281,
          536,
          300,
          341,
          1985,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4872.54,
        "id": 1479,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4870.3,
        "temperature": 0,
        "text": " So I want to see what's another word that I could add.",
        "tokens": [
          51292,
          407,
          286,
          528,
          281,
          536,
          437,
          311,
          1071,
          1349,
          300,
          286,
          727,
          909,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4874.7,
        "id": 1480,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4874.3,
        "temperature": 0,
        "text": " Puppy.",
        "tokens": [
          51492,
          13605,
          7966,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4877.9,
        "id": 1481,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4875.66,
        "temperature": 0,
        "text": " And three, hit submit.",
        "tokens": [
          51560,
          400,
          1045,
          11,
          2045,
          10315,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.20021494910830542,
        "compression_ratio": 1.715,
        "end": 4881.58,
        "id": 1482,
        "no_speech_prob": 0.0001355200947728008,
        "seek": 485174,
        "start": 4878.46,
        "temperature": 0,
        "text": " And we can see that that worked.",
        "tokens": [
          51700,
          400,
          321,
          393,
          536,
          300,
          300,
          2732,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4882.22,
        "id": 1483,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4881.66,
        "temperature": 0,
        "text": " Success.",
        "tokens": [
          50368,
          23669,
          13,
          50396
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4885.74,
        "id": 1484,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4882.22,
        "temperature": 0,
        "text": " Although I probably, again, should add something to this page that says, thank you.",
        "tokens": [
          50396,
          5780,
          286,
          1391,
          11,
          797,
          11,
          820,
          909,
          746,
          281,
          341,
          3028,
          300,
          1619,
          11,
          1309,
          291,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4887.18,
        "id": 1485,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4885.74,
        "temperature": 0,
        "text": " I added that word to the list.",
        "tokens": [
          50572,
          286,
          3869,
          300,
          1349,
          281,
          264,
          1329,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4889.58,
        "id": 1486,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4887.9,
        "temperature": 0,
        "text": " That's a great exercise for you.",
        "tokens": [
          50680,
          663,
          311,
          257,
          869,
          5380,
          337,
          291,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4894.62,
        "id": 1487,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4889.58,
        "temperature": 0,
        "text": " But we can just confirm now that if I go back to here, under additional, puppy is there.",
        "tokens": [
          50764,
          583,
          321,
          393,
          445,
          9064,
          586,
          300,
          498,
          286,
          352,
          646,
          281,
          510,
          11,
          833,
          4497,
          11,
          18196,
          307,
          456,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4896.22,
        "id": 1488,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4894.62,
        "temperature": 0,
        "text": " OK, so everything is working.",
        "tokens": [
          51016,
          2264,
          11,
          370,
          1203,
          307,
          1364,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4901.82,
        "id": 1489,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4896.22,
        "temperature": 0,
        "text": " But my API behind the scenes has access to both the full AFIN list and any additional",
        "tokens": [
          51096,
          583,
          452,
          9362,
          2261,
          264,
          8026,
          575,
          2105,
          281,
          1293,
          264,
          1577,
          20389,
          1464,
          1329,
          293,
          604,
          4497,
          51376
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4903.26,
        "id": 1490,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4901.82,
        "temperature": 0,
        "text": " words that have been added.",
        "tokens": [
          51376,
          2283,
          300,
          362,
          668,
          3869,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4905.5,
        "id": 1491,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4903.26,
        "temperature": 0,
        "text": " Notice how things are a little bit different here.",
        "tokens": [
          51448,
          13428,
          577,
          721,
          366,
          257,
          707,
          857,
          819,
          510,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4910.0599999999995,
        "id": 1492,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4905.5,
        "temperature": 0,
        "text": " I probably should have been more thoughtful about fixing this up so that these are actually",
        "tokens": [
          51560,
          286,
          1391,
          820,
          362,
          668,
          544,
          21566,
          466,
          19442,
          341,
          493,
          370,
          300,
          613,
          366,
          767,
          51788
        ]
      },
      {
        "avg_logprob": -0.16009548160579654,
        "compression_ratio": 1.687878787878788,
        "end": 4911.1,
        "id": 1493,
        "no_speech_prob": 0.00011959802213823423,
        "seek": 488158,
        "start": 4910.0599999999995,
        "temperature": 0,
        "text": " numbers and not strings.",
        "tokens": [
          51788,
          3547,
          293,
          406,
          13985,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.2078677217165629,
        "compression_ratio": 1.5507246376811594,
        "end": 4912.46,
        "id": 1494,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 491110,
        "start": 4911.18,
        "temperature": 0,
        "text": " But I can deal with that later.",
        "tokens": [
          50368,
          583,
          286,
          393,
          2028,
          365,
          300,
          1780,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2078677217165629,
        "compression_ratio": 1.5507246376811594,
        "end": 4922.46,
        "id": 1495,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 491110,
        "start": 4913.26,
        "temperature": 0,
        "text": " So OK, now the thing we need to change now is how do we send a large body of text from",
        "tokens": [
          50472,
          407,
          2264,
          11,
          586,
          264,
          551,
          321,
          643,
          281,
          1319,
          586,
          307,
          577,
          360,
          321,
          2845,
          257,
          2416,
          1772,
          295,
          2487,
          490,
          50932
        ]
      },
      {
        "avg_logprob": -0.2078677217165629,
        "compression_ratio": 1.5507246376811594,
        "end": 4926.860000000001,
        "id": 1496,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 491110,
        "start": 4922.46,
        "temperature": 0,
        "text": " the client to the server?",
        "tokens": [
          50932,
          264,
          6423,
          281,
          264,
          7154,
          30,
          51152
        ]
      },
      {
        "avg_logprob": -0.2078677217165629,
        "compression_ratio": 1.5507246376811594,
        "end": 4930.700000000001,
        "id": 1497,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 491110,
        "start": 4926.860000000001,
        "temperature": 0,
        "text": " And so I'm going to come over here for a second to, oh boy, this camera is off.",
        "tokens": [
          51152,
          400,
          370,
          286,
          478,
          516,
          281,
          808,
          670,
          510,
          337,
          257,
          1150,
          281,
          11,
          1954,
          3237,
          11,
          341,
          2799,
          307,
          766,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2078677217165629,
        "compression_ratio": 1.5507246376811594,
        "end": 4932.06,
        "id": 1498,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 491110,
        "start": 4930.700000000001,
        "temperature": 0,
        "text": " I'm going to come to the void.",
        "tokens": [
          51344,
          286,
          478,
          516,
          281,
          808,
          281,
          264,
          22009,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2078677217165629,
        "compression_ratio": 1.5507246376811594,
        "end": 4936.860000000001,
        "id": 1499,
        "no_speech_prob": 0.000044694017560686916,
        "seek": 491110,
        "start": 4932.9400000000005,
        "temperature": 0,
        "text": " And I want to talk about the difference between a get and a post.",
        "tokens": [
          51456,
          400,
          286,
          528,
          281,
          751,
          466,
          264,
          2649,
          1296,
          257,
          483,
          293,
          257,
          2183,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4945.259999999999,
        "id": 1500,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4937.259999999999,
        "temperature": 0,
        "text": " So HTTP, which stands for Hyper Text Transfer Protocol, I don't know if that's right.",
        "tokens": [
          50384,
          407,
          33283,
          11,
          597,
          7382,
          337,
          29592,
          18643,
          35025,
          48753,
          11,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          558,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4945.9,
        "id": 1501,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4945.259999999999,
        "temperature": 0,
        "text": " It's probably right.",
        "tokens": [
          50784,
          467,
          311,
          1391,
          558,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4951.099999999999,
        "id": 1502,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4947.42,
        "temperature": 0,
        "text": " There is a request and response protocol.",
        "tokens": [
          50892,
          821,
          307,
          257,
          5308,
          293,
          4134,
          10336,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4953.82,
        "id": 1503,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4951.74,
        "temperature": 0,
        "text": " Hi, I'm a web browser.",
        "tokens": [
          51108,
          2421,
          11,
          286,
          478,
          257,
          3670,
          11185,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4959.9,
        "id": 1504,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4954.38,
        "temperature": 0,
        "text": " Could I please, I'm making a request, have some information about where I could get some",
        "tokens": [
          51240,
          7497,
          286,
          1767,
          11,
          286,
          478,
          1455,
          257,
          5308,
          11,
          362,
          512,
          1589,
          466,
          689,
          286,
          727,
          483,
          512,
          51516
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4961.5,
        "id": 1505,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4959.9,
        "temperature": 0,
        "text": " nice apples this time of year?",
        "tokens": [
          51516,
          1481,
          16814,
          341,
          565,
          295,
          1064,
          30,
          51596
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4962.78,
        "id": 1506,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4961.5,
        "temperature": 0,
        "text": " And maybe I would ask that to Google.",
        "tokens": [
          51596,
          400,
          1310,
          286,
          576,
          1029,
          300,
          281,
          3329,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.37091067921031606,
        "compression_ratio": 1.5934959349593496,
        "end": 4965.259999999999,
        "id": 1507,
        "no_speech_prob": 0.0001442590291844681,
        "seek": 493686,
        "start": 4962.78,
        "temperature": 0,
        "text": " And Google being the server would say, hey, I'm a web browser.",
        "tokens": [
          51660,
          400,
          3329,
          885,
          264,
          7154,
          576,
          584,
          11,
          4177,
          11,
          286,
          478,
          257,
          3670,
          11185,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4968.860000000001,
        "id": 1508,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4965.26,
        "temperature": 0,
        "text": " And Google being the server would say, hey, here's a response.",
        "tokens": [
          50364,
          400,
          3329,
          885,
          264,
          7154,
          576,
          584,
          11,
          4177,
          11,
          510,
          311,
          257,
          4134,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4970.38,
        "id": 1509,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4968.860000000001,
        "temperature": 0,
        "text": " Here's some information.",
        "tokens": [
          50544,
          1692,
          311,
          512,
          1589,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4976.14,
        "id": 1510,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4970.38,
        "temperature": 0,
        "text": " And the way that I can talk to that server in this request and response protocol, if",
        "tokens": [
          50620,
          400,
          264,
          636,
          300,
          286,
          393,
          751,
          281,
          300,
          7154,
          294,
          341,
          5308,
          293,
          4134,
          10336,
          11,
          498,
          50908
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4984.22,
        "id": 1511,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4976.14,
        "temperature": 0,
        "text": " we have server and we have client, is I can make a get request, which is like, could you",
        "tokens": [
          50908,
          321,
          362,
          7154,
          293,
          321,
          362,
          6423,
          11,
          307,
          286,
          393,
          652,
          257,
          483,
          5308,
          11,
          597,
          307,
          411,
          11,
          727,
          291,
          51312
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4986.3,
        "id": 1512,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4984.22,
        "temperature": 0,
        "text": " please give me some information back?",
        "tokens": [
          51312,
          1767,
          976,
          385,
          512,
          1589,
          646,
          30,
          51416
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4992.7,
        "id": 1513,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4987.26,
        "temperature": 0,
        "text": " Or I could make a post request, which is, would you please take this information and",
        "tokens": [
          51464,
          1610,
          286,
          727,
          652,
          257,
          2183,
          5308,
          11,
          597,
          307,
          11,
          576,
          291,
          1767,
          747,
          341,
          1589,
          293,
          51736
        ]
      },
      {
        "avg_logprob": -0.15846637317112514,
        "compression_ratio": 1.8235294117647058,
        "end": 4995.1,
        "id": 1514,
        "no_speech_prob": 0.0005884052370674908,
        "seek": 496526,
        "start": 4992.7,
        "temperature": 0,
        "text": " save it onto your server or do something with it?",
        "tokens": [
          51736,
          3155,
          309,
          3911,
          428,
          7154,
          420,
          360,
          746,
          365,
          309,
          30,
          51856
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5001.740000000001,
        "id": 1515,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 4995.18,
        "temperature": 0,
        "text": " So if I'm logging in with my username and password, that would be something I would",
        "tokens": [
          50368,
          407,
          498,
          286,
          478,
          27991,
          294,
          365,
          452,
          30351,
          293,
          11524,
          11,
          300,
          576,
          312,
          746,
          286,
          576,
          50696
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5004.06,
        "id": 1516,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 5001.740000000001,
        "temperature": 0,
        "text": " want to send with a post request.",
        "tokens": [
          50696,
          528,
          281,
          2845,
          365,
          257,
          2183,
          5308,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5009.820000000001,
        "id": 1517,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 5004.06,
        "temperature": 0,
        "text": " If I want the results of a search, I might ask, use a get request to get the results",
        "tokens": [
          50812,
          759,
          286,
          528,
          264,
          3542,
          295,
          257,
          3164,
          11,
          286,
          1062,
          1029,
          11,
          764,
          257,
          483,
          5308,
          281,
          483,
          264,
          3542,
          51100
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5010.06,
        "id": 1518,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 5009.820000000001,
        "temperature": 0,
        "text": " back.",
        "tokens": [
          51100,
          646,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5011.5,
        "id": 1519,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 5010.860000000001,
        "temperature": 0,
        "text": " Here's the thing.",
        "tokens": [
          51152,
          1692,
          311,
          264,
          551,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5018.06,
        "id": 1520,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 5012.780000000001,
        "temperature": 0,
        "text": " Even though this is how this protocol is designed and how it works, you'll notice something",
        "tokens": [
          51248,
          2754,
          1673,
          341,
          307,
          577,
          341,
          10336,
          307,
          4761,
          293,
          577,
          309,
          1985,
          11,
          291,
          603,
          3449,
          746,
          51512
        ]
      },
      {
        "avg_logprob": -0.1845533847808838,
        "compression_ratio": 1.6136363636363635,
        "end": 5019.820000000001,
        "id": 1521,
        "no_speech_prob": 0.000006339196261251345,
        "seek": 499510,
        "start": 5018.06,
        "temperature": 0,
        "text": " in our program a little bit strange.",
        "tokens": [
          51512,
          294,
          527,
          1461,
          257,
          707,
          857,
          5861,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5024.219999999999,
        "id": 1522,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5020.219999999999,
        "temperature": 0,
        "text": " So if I go back to the code for a second and I look in the server, I can say, well, where",
        "tokens": [
          50384,
          407,
          498,
          286,
          352,
          646,
          281,
          264,
          3089,
          337,
          257,
          1150,
          293,
          286,
          574,
          294,
          264,
          7154,
          11,
          286,
          393,
          584,
          11,
          731,
          11,
          689,
          50584
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5025.259999999999,
        "id": 1523,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5024.219999999999,
        "temperature": 0,
        "text": " are these happening?",
        "tokens": [
          50584,
          366,
          613,
          2737,
          30,
          50636
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5026.54,
        "id": 1524,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5025.259999999999,
        "temperature": 0,
        "text": " This is a get.",
        "tokens": [
          50636,
          639,
          307,
          257,
          483,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5027.58,
        "id": 1525,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5026.54,
        "temperature": 0,
        "text": " Oh, I'm in the wrong place.",
        "tokens": [
          50700,
          876,
          11,
          286,
          478,
          294,
          264,
          2085,
          1081,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5029.5,
        "id": 1526,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5027.58,
        "temperature": 0,
        "text": " If I go, we do that again.",
        "tokens": [
          50752,
          759,
          286,
          352,
          11,
          321,
          360,
          300,
          797,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5036.299999999999,
        "id": 1527,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5031.099999999999,
        "temperature": 0,
        "text": " If I go back to the code for a second, you might ask, where are these happening?",
        "tokens": [
          50928,
          759,
          286,
          352,
          646,
          281,
          264,
          3089,
          337,
          257,
          1150,
          11,
          291,
          1062,
          1029,
          11,
          689,
          366,
          613,
          2737,
          30,
          51188
        ]
      },
      {
        "avg_logprob": -0.2721092464687588,
        "compression_ratio": 1.778894472361809,
        "end": 5043.58,
        "id": 1528,
        "no_speech_prob": 0.004905382636934519,
        "seek": 501982,
        "start": 5036.299999999999,
        "temperature": 0,
        "text": " Well, right here, when I set up a route, I'm actually saying this is handling a get request.",
        "tokens": [
          51188,
          1042,
          11,
          558,
          510,
          11,
          562,
          286,
          992,
          493,
          257,
          7955,
          11,
          286,
          478,
          767,
          1566,
          341,
          307,
          13175,
          257,
          483,
          5308,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5051.74,
        "id": 1529,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5044.14,
        "temperature": 0,
        "text": " If the browser asks with a get request for slash all, send this information back as the",
        "tokens": [
          50392,
          759,
          264,
          11185,
          8962,
          365,
          257,
          483,
          5308,
          337,
          17330,
          439,
          11,
          2845,
          341,
          1589,
          646,
          382,
          264,
          50772
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5052.3,
        "id": 1530,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5051.74,
        "temperature": 0,
        "text": " response.",
        "tokens": [
          50772,
          4134,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5055.58,
        "id": 1531,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5052.3,
        "temperature": 0,
        "text": " Information that comes with the request is in this variable.",
        "tokens": [
          50800,
          15357,
          300,
          1487,
          365,
          264,
          5308,
          307,
          294,
          341,
          7006,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5058.78,
        "id": 1532,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5056.22,
        "temperature": 0,
        "text": " Stuff that I want to do to respond is in this variable.",
        "tokens": [
          50996,
          31347,
          300,
          286,
          528,
          281,
          360,
          281,
          4196,
          307,
          294,
          341,
          7006,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5059.98,
        "id": 1533,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5058.78,
        "temperature": 0,
        "text": " This is a get request.",
        "tokens": [
          51124,
          639,
          307,
          257,
          483,
          5308,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5060.86,
        "id": 1534,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5059.98,
        "temperature": 0,
        "text": " And it makes sense.",
        "tokens": [
          51184,
          400,
          309,
          1669,
          2020,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5063.34,
        "id": 1535,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5060.86,
        "temperature": 0,
        "text": " I would like all of the data in the database, please.",
        "tokens": [
          51228,
          286,
          576,
          411,
          439,
          295,
          264,
          1412,
          294,
          264,
          8149,
          11,
          1767,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5064.22,
        "id": 1536,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5063.34,
        "temperature": 0,
        "text": " Could I please have that?",
        "tokens": [
          51352,
          7497,
          286,
          1767,
          362,
          300,
          30,
          51396
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5064.78,
        "id": 1537,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5064.22,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51396,
          1044,
          291,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5066.62,
        "id": 1538,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5065.58,
        "temperature": 0,
        "text": " I really wish it was this.",
        "tokens": [
          51464,
          286,
          534,
          3172,
          309,
          390,
          341,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5067.18,
        "id": 1539,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5066.62,
        "temperature": 0,
        "text": " Get, please.",
        "tokens": [
          51516,
          3240,
          11,
          1767,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5069.5,
        "id": 1540,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5068.22,
        "temperature": 0,
        "text": " But it's just get.",
        "tokens": [
          51596,
          583,
          309,
          311,
          445,
          483,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.3260772762013905,
        "compression_ratio": 1.7884615384615385,
        "end": 5071.5,
        "id": 1541,
        "no_speech_prob": 0.16450412571430206,
        "seek": 504358,
        "start": 5069.5,
        "temperature": 0,
        "text": " I guess there's no need for politeness between computers.",
        "tokens": [
          51660,
          286,
          2041,
          456,
          311,
          572,
          643,
          337,
          2453,
          15264,
          1296,
          10807,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5072.14,
        "id": 1542,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5071.58,
        "temperature": 0,
        "text": " Kindness.",
        "tokens": [
          50368,
          9242,
          1287,
          13,
          50396
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5075.5,
        "id": 1543,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5072.14,
        "temperature": 0,
        "text": " There's nothing that needs to be said for kindness between computers, though, and people.",
        "tokens": [
          50396,
          821,
          311,
          1825,
          300,
          2203,
          281,
          312,
          848,
          337,
          18171,
          1296,
          10807,
          11,
          1673,
          11,
          293,
          561,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5077.02,
        "id": 1544,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5075.5,
        "temperature": 0,
        "text": " Anyway, I'm off track here.",
        "tokens": [
          50564,
          5684,
          11,
          286,
          478,
          766,
          2837,
          510,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5078.3,
        "id": 1545,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5077.02,
        "temperature": 0,
        "text": " But you'll notice something.",
        "tokens": [
          50640,
          583,
          291,
          603,
          3449,
          746,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5081.02,
        "id": 1546,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5078.86,
        "temperature": 0,
        "text": " This is also a get request.",
        "tokens": [
          50732,
          639,
          307,
          611,
          257,
          483,
          5308,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5084.86,
        "id": 1547,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5082.86,
        "temperature": 0,
        "text": " Get add word score.",
        "tokens": [
          50932,
          3240,
          909,
          1349,
          6175,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5091.34,
        "id": 1548,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5085.9,
        "temperature": 0,
        "text": " Now, it makes sense that you would have parameters for a get request like search.",
        "tokens": [
          51084,
          823,
          11,
          309,
          1669,
          2020,
          300,
          291,
          576,
          362,
          9834,
          337,
          257,
          483,
          5308,
          411,
          3164,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5092.54,
        "id": 1549,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5091.34,
        "temperature": 0,
        "text": " So this is a get request.",
        "tokens": [
          51356,
          407,
          341,
          307,
          257,
          483,
          5308,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5093.66,
        "id": 1550,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5093.1,
        "temperature": 0,
        "text": " Search.",
        "tokens": [
          51444,
          17180,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5096.38,
        "id": 1551,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5093.66,
        "temperature": 0,
        "text": " Do you have the word kitten in your database?",
        "tokens": [
          51472,
          1144,
          291,
          362,
          264,
          1349,
          39696,
          294,
          428,
          8149,
          30,
          51608
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5098.62,
        "id": 1552,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5096.38,
        "temperature": 0,
        "text": " If so, could you please tell me its score?",
        "tokens": [
          51608,
          759,
          370,
          11,
          727,
          291,
          1767,
          980,
          385,
          1080,
          6175,
          30,
          51720
        ]
      },
      {
        "avg_logprob": -0.3464458495613158,
        "compression_ratio": 1.6139705882352942,
        "end": 5099.9,
        "id": 1553,
        "no_speech_prob": 0.0003053483087569475,
        "seek": 507150,
        "start": 5098.62,
        "temperature": 0,
        "text": " That's what's happening here.",
        "tokens": [
          51720,
          663,
          311,
          437,
          311,
          2737,
          510,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5101.42,
        "id": 1554,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5100.139999999999,
        "temperature": 0,
        "text": " That's what's happening here.",
        "tokens": [
          50376,
          663,
          311,
          437,
          311,
          2737,
          510,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5107.099999999999,
        "id": 1555,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5102.78,
        "temperature": 0,
        "text": " But in this particular route, this is a get request.",
        "tokens": [
          50508,
          583,
          294,
          341,
          1729,
          7955,
          11,
          341,
          307,
          257,
          483,
          5308,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5111.82,
        "id": 1556,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5107.099999999999,
        "temperature": 0,
        "text": " And my get request is saying, here are this word and this score.",
        "tokens": [
          50724,
          400,
          452,
          483,
          5308,
          307,
          1566,
          11,
          510,
          366,
          341,
          1349,
          293,
          341,
          6175,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5114.139999999999,
        "id": 1557,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5111.82,
        "temperature": 0,
        "text": " Will you please add those to your database?",
        "tokens": [
          50960,
          3099,
          291,
          1767,
          909,
          729,
          281,
          428,
          8149,
          30,
          51076
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5118.379999999999,
        "id": 1558,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5114.139999999999,
        "temperature": 0,
        "text": " And according to my discussion over here, that should really be a post, right?",
        "tokens": [
          51076,
          400,
          4650,
          281,
          452,
          5017,
          670,
          510,
          11,
          300,
          820,
          534,
          312,
          257,
          2183,
          11,
          558,
          30,
          51288
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5123.179999999999,
        "id": 1559,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5118.379999999999,
        "temperature": 0,
        "text": " If you're sending data to the server for the server to save, that's really a post and not a get.",
        "tokens": [
          51288,
          759,
          291,
          434,
          7750,
          1412,
          281,
          264,
          7154,
          337,
          264,
          7154,
          281,
          3155,
          11,
          300,
          311,
          534,
          257,
          2183,
          293,
          406,
          257,
          483,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.15282428774059328,
        "compression_ratio": 1.7007874015748032,
        "end": 5129.82,
        "id": 1560,
        "no_speech_prob": 0.00004539784276857972,
        "seek": 509990,
        "start": 5123.74,
        "temperature": 0,
        "text": " The thing is, though, it's just so darn convenient to use a get.",
        "tokens": [
          51556,
          440,
          551,
          307,
          11,
          1673,
          11,
          309,
          311,
          445,
          370,
          29063,
          10851,
          281,
          764,
          257,
          483,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5131.099999999999,
        "id": 1561,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5129.98,
        "temperature": 0,
        "text": " Why is it so convenient?",
        "tokens": [
          50372,
          1545,
          307,
          309,
          370,
          10851,
          30,
          50428
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5133.82,
        "id": 1562,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5131.099999999999,
        "temperature": 0,
        "text": " Because that's what the browser does natively on its own.",
        "tokens": [
          50428,
          1436,
          300,
          311,
          437,
          264,
          11185,
          775,
          8470,
          356,
          322,
          1080,
          1065,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5142.299999999999,
        "id": 1563,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5133.82,
        "temperature": 0,
        "text": " I can actually now just make a get request by saying, localhost 3000, add yellow,",
        "tokens": [
          50564,
          286,
          393,
          767,
          586,
          445,
          652,
          257,
          483,
          5308,
          538,
          1566,
          11,
          2654,
          6037,
          20984,
          11,
          909,
          5566,
          11,
          50988
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5144.54,
        "id": 1564,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5142.299999999999,
        "temperature": 0,
        "text": " which is maybe a neutral color or slightly positive.",
        "tokens": [
          50988,
          597,
          307,
          1310,
          257,
          10598,
          2017,
          420,
          4748,
          3353,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5147.179999999999,
        "id": 1565,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5145.179999999999,
        "temperature": 0,
        "text": " So this is me now making a get request.",
        "tokens": [
          51132,
          407,
          341,
          307,
          385,
          586,
          1455,
          257,
          483,
          5308,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5148.38,
        "id": 1566,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5147.179999999999,
        "temperature": 0,
        "text": " That get request is done.",
        "tokens": [
          51232,
          663,
          483,
          5308,
          307,
          1096,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5149.5,
        "id": 1567,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5148.38,
        "temperature": 0,
        "text": " It's saved into the database.",
        "tokens": [
          51292,
          467,
          311,
          6624,
          666,
          264,
          8149,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5155.82,
        "id": 1568,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5149.5,
        "temperature": 0,
        "text": " I can use the fact that I can add parameters to a get request through the route or a query string.",
        "tokens": [
          51348,
          286,
          393,
          764,
          264,
          1186,
          300,
          286,
          393,
          909,
          9834,
          281,
          257,
          483,
          5308,
          807,
          264,
          7955,
          420,
          257,
          14581,
          6798,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2382001131772995,
        "compression_ratio": 1.6713286713286712,
        "end": 5159.099999999999,
        "id": 1569,
        "no_speech_prob": 0.00021318717335816473,
        "seek": 512982,
        "start": 5155.82,
        "temperature": 0,
        "text": " There are lots of ways to do it to actually have the server save,",
        "tokens": [
          51664,
          821,
          366,
          3195,
          295,
          2098,
          281,
          360,
          309,
          281,
          767,
          362,
          264,
          7154,
          3155,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.19794419503981067,
        "compression_ratio": 1.7545787545787546,
        "end": 5161.740000000001,
        "id": 1570,
        "no_speech_prob": 0.00010720832506194711,
        "seek": 515910,
        "start": 5159.1,
        "temperature": 0,
        "text": " to send stuff to the server for it to do stuff with as well.",
        "tokens": [
          50364,
          281,
          2845,
          1507,
          281,
          264,
          7154,
          337,
          309,
          281,
          360,
          1507,
          365,
          382,
          731,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.19794419503981067,
        "compression_ratio": 1.7545787545787546,
        "end": 5167.26,
        "id": 1571,
        "no_speech_prob": 0.00010720832506194711,
        "seek": 515910,
        "start": 5161.740000000001,
        "temperature": 0,
        "text": " And because it's just a little bit of data, it's just so easy to do it in the route with a get request, why not?",
        "tokens": [
          50496,
          400,
          570,
          309,
          311,
          445,
          257,
          707,
          857,
          295,
          1412,
          11,
          309,
          311,
          445,
          370,
          1858,
          281,
          360,
          309,
          294,
          264,
          7955,
          365,
          257,
          483,
          5308,
          11,
          983,
          406,
          30,
          50772
        ]
      },
      {
        "avg_logprob": -0.19794419503981067,
        "compression_ratio": 1.7545787545787546,
        "end": 5173.820000000001,
        "id": 1572,
        "no_speech_prob": 0.00010720832506194711,
        "seek": 515910,
        "start": 5167.26,
        "temperature": 0,
        "text": " But there are times where this get request isn't sufficient, and you really need to use a post.",
        "tokens": [
          50772,
          583,
          456,
          366,
          1413,
          689,
          341,
          483,
          5308,
          1943,
          380,
          11563,
          11,
          293,
          291,
          534,
          643,
          281,
          764,
          257,
          2183,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.19794419503981067,
        "compression_ratio": 1.7545787545787546,
        "end": 5177.1,
        "id": 1573,
        "no_speech_prob": 0.00010720832506194711,
        "seek": 515910,
        "start": 5174.38,
        "temperature": 0,
        "text": " Well, one is username and password.",
        "tokens": [
          51128,
          1042,
          11,
          472,
          307,
          30351,
          293,
          11524,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19794419503981067,
        "compression_ratio": 1.7545787545787546,
        "end": 5182.780000000001,
        "id": 1574,
        "no_speech_prob": 0.00010720832506194711,
        "seek": 515910,
        "start": 5177.1,
        "temperature": 0,
        "text": " So if security matters, you don't want to have the username and password just in the URL path",
        "tokens": [
          51264,
          407,
          498,
          3825,
          7001,
          11,
          291,
          500,
          380,
          528,
          281,
          362,
          264,
          30351,
          293,
          11524,
          445,
          294,
          264,
          12905,
          3100,
          51548
        ]
      },
      {
        "avg_logprob": -0.19794419503981067,
        "compression_ratio": 1.7545787545787546,
        "end": 5186.780000000001,
        "id": 1575,
        "no_speech_prob": 0.00010720832506194711,
        "seek": 515910,
        "start": 5182.780000000001,
        "temperature": 0,
        "text": " as part of a get request that anybody could potentially hack and get access to.",
        "tokens": [
          51548,
          382,
          644,
          295,
          257,
          483,
          5308,
          300,
          4472,
          727,
          7263,
          10339,
          293,
          483,
          2105,
          281,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.23105563948639726,
        "compression_ratio": 1.6452830188679246,
        "end": 5190.0599999999995,
        "id": 1576,
        "no_speech_prob": 0.000036478439142229035,
        "seek": 518678,
        "start": 5186.78,
        "temperature": 0,
        "text": " So this is really where for hidden data, it really needs to be a post.",
        "tokens": [
          50364,
          407,
          341,
          307,
          534,
          689,
          337,
          7633,
          1412,
          11,
          309,
          534,
          2203,
          281,
          312,
          257,
          2183,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.23105563948639726,
        "compression_ratio": 1.6452830188679246,
        "end": 5192.3,
        "id": 1577,
        "no_speech_prob": 0.000036478439142229035,
        "seek": 518678,
        "start": 5190.86,
        "temperature": 0,
        "text": " The other thing is like media.",
        "tokens": [
          50568,
          440,
          661,
          551,
          307,
          411,
          3021,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.23105563948639726,
        "compression_ratio": 1.6452830188679246,
        "end": 5198.78,
        "id": 1578,
        "no_speech_prob": 0.000036478439142229035,
        "seek": 518678,
        "start": 5192.94,
        "temperature": 0,
        "text": " If you want to upload an image to a server or upload a sound file, you can't do that through a get request.",
        "tokens": [
          50672,
          759,
          291,
          528,
          281,
          6580,
          364,
          3256,
          281,
          257,
          7154,
          420,
          6580,
          257,
          1626,
          3991,
          11,
          291,
          393,
          380,
          360,
          300,
          807,
          257,
          483,
          5308,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23105563948639726,
        "compression_ratio": 1.6452830188679246,
        "end": 5205.34,
        "id": 1579,
        "no_speech_prob": 0.000036478439142229035,
        "seek": 518678,
        "start": 5198.78,
        "temperature": 0,
        "text": " You can't easily, although there's some tricky ways you could like base64 encode your image into like a number string that goes into the URL.",
        "tokens": [
          50964,
          509,
          393,
          380,
          3612,
          11,
          4878,
          456,
          311,
          512,
          12414,
          2098,
          291,
          727,
          411,
          3096,
          19395,
          2058,
          1429,
          428,
          3256,
          666,
          411,
          257,
          1230,
          6798,
          300,
          1709,
          666,
          264,
          12905,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.23105563948639726,
        "compression_ratio": 1.6452830188679246,
        "end": 5211.0199999999995,
        "id": 1580,
        "no_speech_prob": 0.000036478439142229035,
        "seek": 518678,
        "start": 5205.34,
        "temperature": 0,
        "text": " But basically for media, but really what I mean in a lot of ways is like large data.",
        "tokens": [
          51292,
          583,
          1936,
          337,
          3021,
          11,
          457,
          534,
          437,
          286,
          914,
          294,
          257,
          688,
          295,
          2098,
          307,
          411,
          2416,
          1412,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.2272036870320638,
        "compression_ratio": 1.6798561151079137,
        "end": 5219.9800000000005,
        "id": 1581,
        "no_speech_prob": 0.0004802911716978997,
        "seek": 521102,
        "start": 5211.02,
        "temperature": 0,
        "text": " So if I want to send a full paragraph to be our full many paragraphs, a thousand words to be analyzed and have the server send me a result back,",
        "tokens": [
          50364,
          407,
          498,
          286,
          528,
          281,
          2845,
          257,
          1577,
          18865,
          281,
          312,
          527,
          1577,
          867,
          48910,
          11,
          257,
          4714,
          2283,
          281,
          312,
          28181,
          293,
          362,
          264,
          7154,
          2845,
          385,
          257,
          1874,
          646,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.2272036870320638,
        "compression_ratio": 1.6798561151079137,
        "end": 5231.1,
        "id": 1582,
        "no_speech_prob": 0.0004802911716978997,
        "seek": 521102,
        "start": 5219.9800000000005,
        "temperature": 0,
        "text": " I want to send that data through a post rather than a get because it's going to be much too awkward to try to like encode a full paragraph of text into some sort of route or URL query string.",
        "tokens": [
          50812,
          286,
          528,
          281,
          2845,
          300,
          1412,
          807,
          257,
          2183,
          2831,
          813,
          257,
          483,
          570,
          309,
          311,
          516,
          281,
          312,
          709,
          886,
          11411,
          281,
          853,
          281,
          411,
          2058,
          1429,
          257,
          1577,
          18865,
          295,
          2487,
          666,
          512,
          1333,
          295,
          7955,
          420,
          12905,
          14581,
          6798,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2272036870320638,
        "compression_ratio": 1.6798561151079137,
        "end": 5233.42,
        "id": 1583,
        "no_speech_prob": 0.0004802911716978997,
        "seek": 521102,
        "start": 5231.1,
        "temperature": 0,
        "text": " So this is really the difference between get and post.",
        "tokens": [
          51368,
          407,
          341,
          307,
          534,
          264,
          2649,
          1296,
          483,
          293,
          2183,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2272036870320638,
        "compression_ratio": 1.6798561151079137,
        "end": 5234.700000000001,
        "id": 1584,
        "no_speech_prob": 0.0004802911716978997,
        "seek": 521102,
        "start": 5233.42,
        "temperature": 0,
        "text": " Post is for sending data.",
        "tokens": [
          51484,
          10223,
          307,
          337,
          7750,
          1412,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2272036870320638,
        "compression_ratio": 1.6798561151079137,
        "end": 5237.02,
        "id": 1585,
        "no_speech_prob": 0.0004802911716978997,
        "seek": 521102,
        "start": 5234.700000000001,
        "temperature": 0,
        "text": " It happens behind the scenes in an invisible way.",
        "tokens": [
          51548,
          467,
          2314,
          2261,
          264,
          8026,
          294,
          364,
          14603,
          636,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23381391561256265,
        "compression_ratio": 1.5714285714285714,
        "end": 5246.700000000001,
        "id": 1586,
        "no_speech_prob": 0.014728443697094917,
        "seek": 523702,
        "start": 5237.580000000001,
        "temperature": 0,
        "text": " Get is for making a request and it happens right in a visible way because it's really basically the same as what you would be doing to type in a URL into the address bar.",
        "tokens": [
          50392,
          3240,
          307,
          337,
          1455,
          257,
          5308,
          293,
          309,
          2314,
          558,
          294,
          257,
          8974,
          636,
          570,
          309,
          311,
          534,
          1936,
          264,
          912,
          382,
          437,
          291,
          576,
          312,
          884,
          281,
          2010,
          294,
          257,
          12905,
          666,
          264,
          2985,
          2159,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.23381391561256265,
        "compression_ratio": 1.5714285714285714,
        "end": 5251.02,
        "id": 1587,
        "no_speech_prob": 0.014728443697094917,
        "seek": 523702,
        "start": 5246.700000000001,
        "temperature": 0,
        "text": " Okay, so now that we've covered that, how do I, there's two things I need to figure out.",
        "tokens": [
          50848,
          1033,
          11,
          370,
          586,
          300,
          321,
          600,
          5343,
          300,
          11,
          577,
          360,
          286,
          11,
          456,
          311,
          732,
          721,
          286,
          643,
          281,
          2573,
          484,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23381391561256265,
        "compression_ratio": 1.5714285714285714,
        "end": 5253.740000000001,
        "id": 1588,
        "no_speech_prob": 0.014728443697094917,
        "seek": 523702,
        "start": 5251.02,
        "temperature": 0,
        "text": " One is how do I handle a post in the server?",
        "tokens": [
          51064,
          1485,
          307,
          577,
          360,
          286,
          4813,
          257,
          2183,
          294,
          264,
          7154,
          30,
          51200
        ]
      },
      {
        "avg_logprob": -0.23381391561256265,
        "compression_ratio": 1.5714285714285714,
        "end": 5264.22,
        "id": 1589,
        "no_speech_prob": 0.014728443697094917,
        "seek": 523702,
        "start": 5254.38,
        "temperature": 0,
        "text": " The nice thing is you could imagine that it might be something like this, app.post.analyze.",
        "tokens": [
          51232,
          440,
          1481,
          551,
          307,
          291,
          727,
          3811,
          300,
          309,
          1062,
          312,
          746,
          411,
          341,
          11,
          724,
          13,
          23744,
          13,
          282,
          5222,
          1381,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.3061512817036022,
        "compression_ratio": 1.620879120879121,
        "end": 5269.34,
        "id": 1590,
        "no_speech_prob": 0.0022518381010740995,
        "seek": 526422,
        "start": 5264.7,
        "temperature": 0,
        "text": " Analyze and analyze this, right?",
        "tokens": [
          50388,
          1107,
          5222,
          1381,
          293,
          12477,
          341,
          11,
          558,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.3061512817036022,
        "compression_ratio": 1.620879120879121,
        "end": 5276.860000000001,
        "id": 1591,
        "no_speech_prob": 0.0022518381010740995,
        "seek": 526422,
        "start": 5269.34,
        "temperature": 0,
        "text": " So this is now, I'm going to write and I have a function to handle that post request.",
        "tokens": [
          50620,
          407,
          341,
          307,
          586,
          11,
          286,
          478,
          516,
          281,
          2464,
          293,
          286,
          362,
          257,
          2445,
          281,
          4813,
          300,
          2183,
          5308,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.3061512817036022,
        "compression_ratio": 1.620879120879121,
        "end": 5287.26,
        "id": 1592,
        "no_speech_prob": 0.0022518381010740995,
        "seek": 526422,
        "start": 5278.860000000001,
        "temperature": 0,
        "text": " So this is now how instead of a get request in a node program I can handle a post by saying app.post.analyze this.",
        "tokens": [
          51096,
          407,
          341,
          307,
          586,
          577,
          2602,
          295,
          257,
          483,
          5308,
          294,
          257,
          9984,
          1461,
          286,
          393,
          4813,
          257,
          2183,
          538,
          1566,
          724,
          13,
          23744,
          13,
          282,
          5222,
          1381,
          341,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.3061512817036022,
        "compression_ratio": 1.620879120879121,
        "end": 5290.14,
        "id": 1593,
        "no_speech_prob": 0.0022518381010740995,
        "seek": 526422,
        "start": 5287.26,
        "temperature": 0,
        "text": " And then what's the other part?",
        "tokens": [
          51516,
          400,
          550,
          437,
          311,
          264,
          661,
          644,
          30,
          51660
        ]
      },
      {
        "avg_logprob": -0.3061512817036022,
        "compression_ratio": 1.620879120879121,
        "end": 5292.54,
        "id": 1594,
        "no_speech_prob": 0.0022518381010740995,
        "seek": 526422,
        "start": 5290.14,
        "temperature": 0,
        "text": " How do I make a post request?",
        "tokens": [
          51660,
          1012,
          360,
          286,
          652,
          257,
          2183,
          5308,
          30,
          51780
        ]
      },
      {
        "avg_logprob": -0.260571038851174,
        "compression_ratio": 1.7135922330097086,
        "end": 5302.3,
        "id": 1595,
        "no_speech_prob": 0.001133558340370655,
        "seek": 529254,
        "start": 5292.7,
        "temperature": 0,
        "text": " Well, there are countless ways you could do it because you could look at jQuery and you could look at native JavaScript and you could look at any JavaScript framework you want.",
        "tokens": [
          50372,
          1042,
          11,
          456,
          366,
          19223,
          2098,
          291,
          727,
          360,
          309,
          570,
          291,
          727,
          574,
          412,
          361,
          35550,
          293,
          291,
          727,
          574,
          412,
          8470,
          15778,
          293,
          291,
          727,
          574,
          412,
          604,
          15778,
          8388,
          291,
          528,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.260571038851174,
        "compression_ratio": 1.7135922330097086,
        "end": 5308.46,
        "id": 1596,
        "no_speech_prob": 0.001133558340370655,
        "seek": 529254,
        "start": 5302.3,
        "temperature": 0,
        "text": " In p5 there's a very nice lovely little function called HTTP post.",
        "tokens": [
          50852,
          682,
          280,
          20,
          456,
          311,
          257,
          588,
          1481,
          7496,
          707,
          2445,
          1219,
          33283,
          2183,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.260571038851174,
        "compression_ratio": 1.7135922330097086,
        "end": 5310.38,
        "id": 1597,
        "no_speech_prob": 0.001133558340370655,
        "seek": 529254,
        "start": 5308.46,
        "temperature": 0,
        "text": " And so let's, I'm going to add something.",
        "tokens": [
          51160,
          400,
          370,
          718,
          311,
          11,
          286,
          478,
          516,
          281,
          909,
          746,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.260571038851174,
        "compression_ratio": 1.7135922330097086,
        "end": 5318.22,
        "id": 1598,
        "no_speech_prob": 0.001133558340370655,
        "seek": 529254,
        "start": 5311.34,
        "temperature": 0,
        "text": " What I'm going to do is in the, here, I'm going to add a text area.",
        "tokens": [
          51304,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          294,
          264,
          11,
          510,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          2487,
          1859,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.23851399878933005,
        "compression_ratio": 1.62987012987013,
        "end": 5331.02,
        "id": 1599,
        "no_speech_prob": 0.0074603077955543995,
        "seek": 531822,
        "start": 5319.02,
        "temperature": 0,
        "text": " So I'm going to say, I'm going to make another paragraph and I'm going to say text area id equals text input.",
        "tokens": [
          50404,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          652,
          1071,
          18865,
          293,
          286,
          478,
          516,
          281,
          584,
          2487,
          1859,
          4496,
          6915,
          2487,
          4846,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.23851399878933005,
        "compression_ratio": 1.62987012987013,
        "end": 5340.22,
        "id": 1600,
        "no_speech_prob": 0.0074603077955543995,
        "seek": 531822,
        "start": 5334.46,
        "temperature": 0,
        "text": " Text area, let's just do columns equals 40 and rows equals 5.",
        "tokens": [
          51176,
          18643,
          1859,
          11,
          718,
          311,
          445,
          360,
          13766,
          6915,
          3356,
          293,
          13241,
          6915,
          1025,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23851399878933005,
        "compression_ratio": 1.62987012987013,
        "end": 5346.22,
        "id": 1601,
        "no_speech_prob": 0.0074603077955543995,
        "seek": 531822,
        "start": 5340.22,
        "temperature": 0,
        "text": " So we can, and so if I go now to here, we should see there's a text area there.",
        "tokens": [
          51464,
          407,
          321,
          393,
          11,
          293,
          370,
          498,
          286,
          352,
          586,
          281,
          510,
          11,
          321,
          820,
          536,
          456,
          311,
          257,
          2487,
          1859,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21836064501506527,
        "compression_ratio": 1.7409638554216869,
        "end": 5349.820000000001,
        "id": 1602,
        "no_speech_prob": 0.001896906876936555,
        "seek": 534622,
        "start": 5346.22,
        "temperature": 0,
        "text": " So what I want to do is when I, and I'll add another submit button.",
        "tokens": [
          50364,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          562,
          286,
          11,
          293,
          286,
          603,
          909,
          1071,
          10315,
          2960,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.21836064501506527,
        "compression_ratio": 1.7409638554216869,
        "end": 5353.18,
        "id": 1603,
        "no_speech_prob": 0.001896906876936555,
        "seek": 534622,
        "start": 5351.26,
        "temperature": 0,
        "text": " I'll call it analyze.",
        "tokens": [
          50616,
          286,
          603,
          818,
          309,
          12477,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.21836064501506527,
        "compression_ratio": 1.7409638554216869,
        "end": 5358.62,
        "id": 1604,
        "no_speech_prob": 0.001896906876936555,
        "seek": 534622,
        "start": 5357.26,
        "temperature": 0,
        "text": " So now I have an analyze button.",
        "tokens": [
          50916,
          407,
          586,
          286,
          362,
          364,
          12477,
          2960,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.21836064501506527,
        "compression_ratio": 1.7409638554216869,
        "end": 5363.42,
        "id": 1605,
        "no_speech_prob": 0.001896906876936555,
        "seek": 534622,
        "start": 5358.62,
        "temperature": 0,
        "text": " What I want is when I analyze this button to make a post request to the server.",
        "tokens": [
          50984,
          708,
          286,
          528,
          307,
          562,
          286,
          12477,
          341,
          2960,
          281,
          652,
          257,
          2183,
          5308,
          281,
          264,
          7154,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.21836064501506527,
        "compression_ratio": 1.7409638554216869,
        "end": 5371.26,
        "id": 1606,
        "no_speech_prob": 0.001896906876936555,
        "seek": 534622,
        "start": 5364.780000000001,
        "temperature": 0,
        "text": " So what I need to do is I need to also in JavaScript get access to the analyze button.",
        "tokens": [
          51292,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          611,
          294,
          15778,
          483,
          2105,
          281,
          264,
          12477,
          2960,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.9403238892555237,
        "compression_ratio": 2.182795698924731,
        "end": 5373.74,
        "id": 1607,
        "no_speech_prob": 0.0008295783773064613,
        "seek": 537126,
        "start": 5371.74,
        "temperature": 0,
        "text": " So I'm going to go to the analyze button.",
        "tokens": [
          50388,
          407,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          12477,
          2960,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.9403238892555237,
        "compression_ratio": 2.182795698924731,
        "end": 5377.74,
        "id": 1608,
        "no_speech_prob": 0.0008295783773064613,
        "seek": 537126,
        "start": 5375.74,
        "temperature": 0,
        "text": " I'm going to go to the analyze button.",
        "tokens": [
          50588,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          12477,
          2960,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.9403238892555237,
        "compression_ratio": 2.182795698924731,
        "end": 5381.74,
        "id": 1609,
        "no_speech_prob": 0.0008295783773064613,
        "seek": 537126,
        "start": 5379.74,
        "temperature": 0,
        "text": " I'm going to go to the analyze button.",
        "tokens": [
          50788,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          12477,
          2960,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.9403238892555237,
        "compression_ratio": 2.182795698924731,
        "end": 5387.74,
        "id": 1610,
        "no_speech_prob": 0.0008295783773064613,
        "seek": 537126,
        "start": 5383.74,
        "temperature": 0,
        "text": " Button A for analyze and analyze.",
        "tokens": [
          50988,
          38435,
          316,
          337,
          12477,
          293,
          12477,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.9403238892555237,
        "compression_ratio": 2.182795698924731,
        "end": 5392.54,
        "id": 1611,
        "no_speech_prob": 0.0008295783773064613,
        "seek": 537126,
        "start": 5390.14,
        "temperature": 0,
        "text": " And analyze this I'll say.",
        "tokens": [
          51308,
          400,
          12477,
          341,
          286,
          603,
          584,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.9403238892555237,
        "compression_ratio": 2.182795698924731,
        "end": 5396.46,
        "id": 1612,
        "no_speech_prob": 0.0008295783773064613,
        "seek": 537126,
        "start": 5393.9800000000005,
        "temperature": 0,
        "text": " Function analyze this.",
        "tokens": [
          51500,
          11166,
          882,
          12477,
          341,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5400.7,
        "id": 1613,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5396.46,
        "temperature": 0,
        "text": " And say dot value and then I want to make a post.",
        "tokens": [
          50364,
          400,
          584,
          5893,
          2158,
          293,
          550,
          286,
          528,
          281,
          652,
          257,
          2183,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5406.78,
        "id": 1614,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5400.7,
        "temperature": 0,
        "text": " And the way I make a post is with the p5 function HTTP post.",
        "tokens": [
          50576,
          400,
          264,
          636,
          286,
          652,
          257,
          2183,
          307,
          365,
          264,
          280,
          20,
          2445,
          33283,
          2183,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5411.18,
        "id": 1615,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5406.78,
        "temperature": 0,
        "text": " So when I wanted to make a get request, load JSON was all I needed to do.",
        "tokens": [
          50880,
          407,
          562,
          286,
          1415,
          281,
          652,
          257,
          483,
          5308,
          11,
          3677,
          31828,
          390,
          439,
          286,
          2978,
          281,
          360,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5415.1,
        "id": 1616,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5411.18,
        "temperature": 0,
        "text": " Because load JSON by default is a get request just like load image or load.",
        "tokens": [
          51100,
          1436,
          3677,
          31828,
          538,
          7576,
          307,
          257,
          483,
          5308,
          445,
          411,
          3677,
          3256,
          420,
          3677,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5418.06,
        "id": 1617,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5416.94,
        "temperature": 0,
        "text": " Any of the load functions.",
        "tokens": [
          51388,
          2639,
          295,
          264,
          3677,
          6828,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5424.86,
        "id": 1618,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5418.06,
        "temperature": 0,
        "text": " There is by the way an HTTP get method which allows you to have more control over that get request.",
        "tokens": [
          51444,
          821,
          307,
          538,
          264,
          636,
          364,
          33283,
          483,
          3170,
          597,
          4045,
          291,
          281,
          362,
          544,
          1969,
          670,
          300,
          483,
          5308,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.22437914008768195,
        "compression_ratio": 1.811965811965812,
        "end": 5426.38,
        "id": 1619,
        "no_speech_prob": 0.0009697486530058086,
        "seek": 539646,
        "start": 5424.86,
        "temperature": 0,
        "text": " But here I just want to make a post.",
        "tokens": [
          51784,
          583,
          510,
          286,
          445,
          528,
          281,
          652,
          257,
          2183,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5428.9400000000005,
        "id": 1620,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5426.46,
        "temperature": 0,
        "text": " So okay.",
        "tokens": [
          50368,
          407,
          1392,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5431.42,
        "id": 1621,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5428.9400000000005,
        "temperature": 0,
        "text": " So I'm going to do p5.js reference.",
        "tokens": [
          50492,
          407,
          286,
          478,
          516,
          281,
          360,
          280,
          20,
          13,
          25530,
          6408,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5436.3,
        "id": 1622,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5432.22,
        "temperature": 0,
        "text": " And I'm going to look at HTTP post.",
        "tokens": [
          50656,
          400,
          286,
          478,
          516,
          281,
          574,
          412,
          33283,
          2183,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5437.82,
        "id": 1623,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5436.3,
        "temperature": 0,
        "text": " And let's look at this page.",
        "tokens": [
          50860,
          400,
          718,
          311,
          574,
          412,
          341,
          3028,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5440.06,
        "id": 1624,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5437.82,
        "temperature": 0,
        "text": " The difference is and boy does this look confusing.",
        "tokens": [
          50936,
          440,
          2649,
          307,
          293,
          3237,
          775,
          341,
          574,
          13181,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5449.1,
        "id": 1625,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5440.86,
        "temperature": 0,
        "text": " The difference is when I make a post I need to send it a whole object which is all the data that I want included as part of the post.",
        "tokens": [
          51088,
          440,
          2649,
          307,
          562,
          286,
          652,
          257,
          2183,
          286,
          643,
          281,
          2845,
          309,
          257,
          1379,
          2657,
          597,
          307,
          439,
          264,
          1412,
          300,
          286,
          528,
          5556,
          382,
          644,
          295,
          264,
          2183,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.22777908188956125,
        "compression_ratio": 1.7172995780590716,
        "end": 5454.38,
        "id": 1626,
        "no_speech_prob": 0.000012606889868038706,
        "seek": 542638,
        "start": 5449.1,
        "temperature": 0,
        "text": " So this allows for a lot of possibilities because I can have multiple fields and I have multiple kinds of data.",
        "tokens": [
          51500,
          407,
          341,
          4045,
          337,
          257,
          688,
          295,
          12178,
          570,
          286,
          393,
          362,
          3866,
          7909,
          293,
          286,
          362,
          3866,
          3685,
          295,
          1412,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5456.46,
        "id": 1627,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5454.38,
        "temperature": 0,
        "text": " So really there's a bunch of stuff I need here.",
        "tokens": [
          50364,
          407,
          534,
          456,
          311,
          257,
          3840,
          295,
          1507,
          286,
          643,
          510,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5463.9800000000005,
        "id": 1628,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5456.46,
        "temperature": 0,
        "text": " But what I care about most right now is the is I need to give it the path which is the route.",
        "tokens": [
          50468,
          583,
          437,
          286,
          1127,
          466,
          881,
          558,
          586,
          307,
          264,
          307,
          286,
          643,
          281,
          976,
          309,
          264,
          3100,
          597,
          307,
          264,
          7955,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5465.66,
        "id": 1629,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5463.9800000000005,
        "temperature": 0,
        "text": " The data that I want to send.",
        "tokens": [
          50844,
          440,
          1412,
          300,
          286,
          528,
          281,
          2845,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5469.900000000001,
        "id": 1630,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5465.66,
        "temperature": 0,
        "text": " I guess what kind of data it is which I'm going to make it JSON based data.",
        "tokens": [
          50928,
          286,
          2041,
          437,
          733,
          295,
          1412,
          309,
          307,
          597,
          286,
          478,
          516,
          281,
          652,
          309,
          31828,
          2361,
          1412,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5472.14,
        "id": 1631,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5469.900000000001,
        "temperature": 0,
        "text": " And then a callback for when it's finished.",
        "tokens": [
          51140,
          400,
          550,
          257,
          818,
          3207,
          337,
          562,
          309,
          311,
          4335,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5473.26,
        "id": 1632,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5472.14,
        "temperature": 0,
        "text": " So let's do all of that.",
        "tokens": [
          51252,
          407,
          718,
          311,
          360,
          439,
          295,
          300,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5476.54,
        "id": 1633,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5474.06,
        "temperature": 0,
        "text": " And I'm going to say where was that?",
        "tokens": [
          51348,
          400,
          286,
          478,
          516,
          281,
          584,
          689,
          390,
          300,
          30,
          51472
        ]
      },
      {
        "avg_logprob": -0.20249026162283762,
        "compression_ratio": 1.5826086956521739,
        "end": 5477.5,
        "id": 1634,
        "no_speech_prob": 0.00002627466164994985,
        "seek": 545438,
        "start": 5476.54,
        "temperature": 0,
        "text": " HTTP post.",
        "tokens": [
          51472,
          33283,
          2183,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5485.66,
        "id": 1635,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5477.5,
        "temperature": 0,
        "text": " So first I need to say data is the text is the text.",
        "tokens": [
          50364,
          407,
          700,
          286,
          643,
          281,
          584,
          1412,
          307,
          264,
          2487,
          307,
          264,
          2487,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5490.14,
        "id": 1636,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5486.7,
        "temperature": 0,
        "text": " And that's actually all I need to post is just what's in there.",
        "tokens": [
          50824,
          400,
          300,
          311,
          767,
          439,
          286,
          643,
          281,
          2183,
          307,
          445,
          437,
          311,
          294,
          456,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5493.66,
        "id": 1637,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5490.78,
        "temperature": 0,
        "text": " So but I could add a lot more things into this object.",
        "tokens": [
          51028,
          407,
          457,
          286,
          727,
          909,
          257,
          688,
          544,
          721,
          666,
          341,
          2657,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5497.1,
        "id": 1638,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5493.66,
        "temperature": 0,
        "text": " And I want to go to slash analyze.",
        "tokens": [
          51172,
          400,
          286,
          528,
          281,
          352,
          281,
          17330,
          12477,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5502.62,
        "id": 1639,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5498.22,
        "temperature": 0,
        "text": " Is that how I did it in like the load JSON at I don't need a slash in front.",
        "tokens": [
          51400,
          1119,
          300,
          577,
          286,
          630,
          309,
          294,
          411,
          264,
          3677,
          31828,
          412,
          286,
          500,
          380,
          643,
          257,
          17330,
          294,
          1868,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5502.94,
        "id": 1640,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5502.62,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51620,
          4919,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.21942022223221627,
        "compression_ratio": 1.60752688172043,
        "end": 5504.3,
        "id": 1641,
        "no_speech_prob": 0.20178626477718353,
        "seek": 547750,
        "start": 5503.74,
        "temperature": 0,
        "text": " Analyze.",
        "tokens": [
          51676,
          1107,
          5222,
          1381,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5508.14,
        "id": 1642,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5505.02,
        "temperature": 0,
        "text": " And then I need to say it's going to be JSON.",
        "tokens": [
          50400,
          400,
          550,
          286,
          643,
          281,
          584,
          309,
          311,
          516,
          281,
          312,
          31828,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5513.900000000001,
        "id": 1643,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5509.18,
        "temperature": 0,
        "text": " And then I need to say data posted.",
        "tokens": [
          50608,
          400,
          550,
          286,
          643,
          281,
          584,
          1412,
          9437,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5516.38,
        "id": 1644,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5514.62,
        "temperature": 0,
        "text": " And then I could also say data error.",
        "tokens": [
          50880,
          400,
          550,
          286,
          727,
          611,
          584,
          1412,
          6713,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5518.62,
        "id": 1645,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5516.38,
        "temperature": 0,
        "text": " But let's let's skip the error right now.",
        "tokens": [
          50968,
          583,
          718,
          311,
          718,
          311,
          10023,
          264,
          6713,
          558,
          586,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5522.62,
        "id": 1646,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5518.62,
        "temperature": 0,
        "text": " I should actually probably data post error.",
        "tokens": [
          51080,
          286,
          820,
          767,
          1391,
          1412,
          2183,
          6713,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5524.860000000001,
        "id": 1647,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5523.26,
        "temperature": 0,
        "text": " So let's write those functions.",
        "tokens": [
          51312,
          407,
          718,
          311,
          2464,
          729,
          6828,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5527.9800000000005,
        "id": 1648,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5526.22,
        "temperature": 0,
        "text": " Function data posted.",
        "tokens": [
          51460,
          11166,
          882,
          1412,
          9437,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5529.9800000000005,
        "id": 1649,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5529.42,
        "temperature": 0,
        "text": " Result.",
        "tokens": [
          51620,
          5015,
          723,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.22869204470985813,
        "compression_ratio": 1.75,
        "end": 5532.46,
        "id": 1650,
        "no_speech_prob": 0.0013670182088389993,
        "seek": 550430,
        "start": 5530.54,
        "temperature": 0,
        "text": " I'm going to say console dot log result.",
        "tokens": [
          51676,
          286,
          478,
          516,
          281,
          584,
          11076,
          5893,
          3565,
          1874,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.17185870083895596,
        "compression_ratio": 1.5680473372781065,
        "end": 5534.94,
        "id": 1651,
        "no_speech_prob": 0.0005193038959987462,
        "seek": 553246,
        "start": 5533.42,
        "temperature": 0,
        "text": " And in the server now.",
        "tokens": [
          50412,
          400,
          294,
          264,
          7154,
          586,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.17185870083895596,
        "compression_ratio": 1.5680473372781065,
        "end": 5538.62,
        "id": 1652,
        "no_speech_prob": 0.0005193038959987462,
        "seek": 553246,
        "start": 5534.94,
        "temperature": 0,
        "text": " So now I've posted this data to the server.",
        "tokens": [
          50488,
          407,
          586,
          286,
          600,
          9437,
          341,
          1412,
          281,
          264,
          7154,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.17185870083895596,
        "compression_ratio": 1.5680473372781065,
        "end": 5541.82,
        "id": 1653,
        "no_speech_prob": 0.0005193038959987462,
        "seek": 553246,
        "start": 5538.62,
        "temperature": 0,
        "text": " And again, this could be a lot more stuff than just that text.",
        "tokens": [
          50672,
          400,
          797,
          11,
          341,
          727,
          312,
          257,
          688,
          544,
          1507,
          813,
          445,
          300,
          2487,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.17185870083895596,
        "compression_ratio": 1.5680473372781065,
        "end": 5553.58,
        "id": 1654,
        "no_speech_prob": 0.0005193038959987462,
        "seek": 553246,
        "start": 5543.1,
        "temperature": 0,
        "text": " And in this function and post, I should have a callback for error.",
        "tokens": [
          50896,
          400,
          294,
          341,
          2445,
          293,
          2183,
          11,
          286,
          820,
          362,
          257,
          818,
          3207,
          337,
          6713,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.17185870083895596,
        "compression_ratio": 1.5680473372781065,
        "end": 5558.46,
        "id": 1655,
        "no_speech_prob": 0.0005193038959987462,
        "seek": 553246,
        "start": 5554.54,
        "temperature": 0,
        "text": " And so now I just want to look at what comes back after it's posted.",
        "tokens": [
          51468,
          400,
          370,
          586,
          286,
          445,
          528,
          281,
          574,
          412,
          437,
          1487,
          646,
          934,
          309,
          311,
          9437,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5558.96,
        "id": 1656,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5558.46,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5565.9800000000005,
        "id": 1657,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5559.34,
        "temperature": 0,
        "text": " So now in the server, I'm just going to say response dot send.",
        "tokens": [
          50408,
          407,
          586,
          294,
          264,
          7154,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          4134,
          5893,
          2845,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5567.34,
        "id": 1658,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5566.86,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50784,
          1044,
          291,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5574.7,
        "id": 1659,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5571.1,
        "temperature": 0,
        "text": " And actually, let's make this a reply message.",
        "tokens": [
          50996,
          400,
          767,
          11,
          718,
          311,
          652,
          341,
          257,
          16972,
          3636,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5575.18,
        "id": 1660,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5574.7,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51176,
          1044,
          291,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5578.06,
        "id": 1661,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5576.7,
        "temperature": 0,
        "text": " And send that reply.",
        "tokens": [
          51276,
          400,
          2845,
          300,
          16972,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.24324425654624826,
        "compression_ratio": 1.4265734265734267,
        "end": 5583.82,
        "id": 1662,
        "no_speech_prob": 0.000017231555830221623,
        "seek": 555846,
        "start": 5579.26,
        "temperature": 0,
        "text": " And let's just look at console dot log request.",
        "tokens": [
          51404,
          400,
          718,
          311,
          445,
          574,
          412,
          11076,
          5893,
          3565,
          5308,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5588.94,
        "id": 1663,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5584.0599999999995,
        "temperature": 0,
        "text": " So we're going to figure out how do we get the stuff that was posted right here in the request.",
        "tokens": [
          50376,
          407,
          321,
          434,
          516,
          281,
          2573,
          484,
          577,
          360,
          321,
          483,
          264,
          1507,
          300,
          390,
          9437,
          558,
          510,
          294,
          264,
          5308,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5589.44,
        "id": 1664,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5588.94,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50620,
          2264,
          13,
          50645
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5591.58,
        "id": 1665,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5589.58,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50652,
          1692,
          321,
          352,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5594.38,
        "id": 1666,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5592.78,
        "temperature": 0,
        "text": " So let's see how far did we get here.",
        "tokens": [
          50812,
          407,
          718,
          311,
          536,
          577,
          1400,
          630,
          321,
          483,
          510,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5595.98,
        "id": 1667,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5594.38,
        "temperature": 0,
        "text": " First, I need to restart the server.",
        "tokens": [
          50892,
          2386,
          11,
          286,
          643,
          281,
          21022,
          264,
          7154,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5601.0199999999995,
        "id": 1668,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5597.9,
        "temperature": 0,
        "text": " And I want to go to this page here.",
        "tokens": [
          51068,
          400,
          286,
          528,
          281,
          352,
          281,
          341,
          3028,
          510,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5604.54,
        "id": 1669,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5601.9,
        "temperature": 0,
        "text": " The here, which I should see this.",
        "tokens": [
          51268,
          440,
          510,
          11,
          597,
          286,
          820,
          536,
          341,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5606.38,
        "id": 1670,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5604.54,
        "temperature": 0,
        "text": " I want to look at the console.",
        "tokens": [
          51400,
          286,
          528,
          281,
          574,
          412,
          264,
          11076,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2925229658160293,
        "compression_ratio": 1.609865470852018,
        "end": 5611.9,
        "id": 1671,
        "no_speech_prob": 0.0028448840603232384,
        "seek": 558382,
        "start": 5606.38,
        "temperature": 0,
        "text": " And now if I this is a test and I hit analyze, I got the message back.",
        "tokens": [
          51492,
          400,
          586,
          498,
          286,
          341,
          307,
          257,
          1500,
          293,
          286,
          2045,
          12477,
          11,
          286,
          658,
          264,
          3636,
          646,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5613.98,
        "id": 1672,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5611.98,
        "temperature": 0,
        "text": " So the round trip happened.",
        "tokens": [
          50368,
          407,
          264,
          3098,
          4931,
          2011,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5618.139999999999,
        "id": 1673,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5614.86,
        "temperature": 0,
        "text": " The question now is let's look at what's in the request.",
        "tokens": [
          50512,
          440,
          1168,
          586,
          307,
          718,
          311,
          574,
          412,
          437,
          311,
          294,
          264,
          5308,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5619.259999999999,
        "id": 1674,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5618.139999999999,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          50676,
          876,
          452,
          8387,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5623.099999999999,
        "id": 1675,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5619.259999999999,
        "temperature": 0,
        "text": " How am I ever going to look through all this and find the data that was posted?",
        "tokens": [
          50732,
          1012,
          669,
          286,
          1562,
          516,
          281,
          574,
          807,
          439,
          341,
          293,
          915,
          264,
          1412,
          300,
          390,
          9437,
          30,
          50924
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5624.219999999999,
        "id": 1676,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5623.099999999999,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50924,
          407,
          510,
          311,
          264,
          551,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5627.5,
        "id": 1677,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5626.78,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          51108,
          31973,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5628.139999999999,
        "id": 1678,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5627.5,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          51144,
          6161,
          484,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5634.46,
        "id": 1679,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5631.42,
        "temperature": 0,
        "text": " Oh, by so if somebody in the chat by the way, so this part's going to have to get edited out.",
        "tokens": [
          51340,
          876,
          11,
          538,
          370,
          498,
          2618,
          294,
          264,
          5081,
          538,
          264,
          636,
          11,
          370,
          341,
          644,
          311,
          516,
          281,
          362,
          281,
          483,
          23016,
          484,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5635.339999999999,
        "id": 1680,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5634.46,
        "temperature": 0,
        "text": " Thank you, Matia.",
        "tokens": [
          51492,
          1044,
          291,
          11,
          6789,
          654,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5637.82,
        "id": 1681,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5635.339999999999,
        "temperature": 0,
        "text": " Somebody in the chat says I keep changing my localhost port.",
        "tokens": [
          51536,
          13463,
          294,
          264,
          5081,
          1619,
          286,
          1066,
          4473,
          452,
          2654,
          6037,
          2436,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.4173652045160746,
        "compression_ratio": 1.6702898550724639,
        "end": 5641.42,
        "id": 1682,
        "no_speech_prob": 0.0002034263889072463,
        "seek": 561190,
        "start": 5637.82,
        "temperature": 0,
        "text": " So I'm using a different port for the node stuff as a one-time thing.",
        "tokens": [
          51660,
          407,
          286,
          478,
          1228,
          257,
          819,
          2436,
          337,
          264,
          9984,
          1507,
          382,
          257,
          472,
          12,
          3766,
          551,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5645.18,
        "id": 1683,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5641.5,
        "temperature": 0,
        "text": " I'm using a different port for the node stuff as a when I run like a Python server.",
        "tokens": [
          50368,
          286,
          478,
          1228,
          257,
          819,
          2436,
          337,
          264,
          9984,
          1507,
          382,
          257,
          562,
          286,
          1190,
          411,
          257,
          15329,
          7154,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5646.54,
        "id": 1684,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5645.18,
        "temperature": 0,
        "text": " But yes, I do keep changing that.",
        "tokens": [
          50552,
          583,
          2086,
          11,
          286,
          360,
          1066,
          4473,
          300,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5649.9,
        "id": 1685,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5646.54,
        "temperature": 0,
        "text": " So I need to look something up because I forgot what it is.",
        "tokens": [
          50620,
          407,
          286,
          643,
          281,
          574,
          746,
          493,
          570,
          286,
          5298,
          437,
          309,
          307,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5654.46,
        "id": 1686,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5651.1,
        "temperature": 0,
        "text": " And I just want to not look it up in the video tutorial.",
        "tokens": [
          50848,
          400,
          286,
          445,
          528,
          281,
          406,
          574,
          309,
          493,
          294,
          264,
          960,
          7073,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5656.06,
        "id": 1687,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5654.46,
        "temperature": 0,
        "text": " I want to act like I know what I'm doing.",
        "tokens": [
          51016,
          286,
          528,
          281,
          605,
          411,
          286,
          458,
          437,
          286,
          478,
          884,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5657.74,
        "id": 1688,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5656.06,
        "temperature": 0,
        "text": " I particularly do not.",
        "tokens": [
          51096,
          286,
          4098,
          360,
          406,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5662.7,
        "id": 1689,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5658.62,
        "temperature": 0,
        "text": " And I'm going to go to node API.",
        "tokens": [
          51224,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          9984,
          9362,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5664.9400000000005,
        "id": 1690,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5662.7,
        "temperature": 0,
        "text": " Maybe this one's actually going to have a simpler one.",
        "tokens": [
          51428,
          2704,
          341,
          472,
          311,
          767,
          516,
          281,
          362,
          257,
          18587,
          472,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5667.66,
        "id": 1691,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5666.22,
        "temperature": 0,
        "text": " No, this one won't have the post.",
        "tokens": [
          51604,
          883,
          11,
          341,
          472,
          1582,
          380,
          362,
          264,
          2183,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.40063049201678513,
        "compression_ratio": 1.6094890510948905,
        "end": 5669.58,
        "id": 1692,
        "no_speech_prob": 0.0006361869163811207,
        "seek": 564142,
        "start": 5668.46,
        "temperature": 0,
        "text": " This is an example.",
        "tokens": [
          51716,
          639,
          307,
          364,
          1365,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.2565879821777344,
        "compression_ratio": 1.4527027027027026,
        "end": 5671.58,
        "id": 1693,
        "no_speech_prob": 0.0021826724987477064,
        "seek": 566958,
        "start": 5670.14,
        "temperature": 0,
        "text": " Uh that I made.",
        "tokens": [
          50392,
          4019,
          300,
          286,
          1027,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2565879821777344,
        "compression_ratio": 1.4527027027027026,
        "end": 5673.98,
        "id": 1694,
        "no_speech_prob": 0.0021826724987477064,
        "seek": 566958,
        "start": 5671.58,
        "temperature": 0,
        "text": " Ah yeah, so I need this.",
        "tokens": [
          50464,
          2438,
          1338,
          11,
          370,
          286,
          643,
          341,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.2565879821777344,
        "compression_ratio": 1.4527027027027026,
        "end": 5677.74,
        "id": 1695,
        "no_speech_prob": 0.0021826724987477064,
        "seek": 566958,
        "start": 5675.58,
        "temperature": 0,
        "text": " I need the body parser package.",
        "tokens": [
          50664,
          286,
          643,
          264,
          1772,
          21156,
          260,
          7372,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.2565879821777344,
        "compression_ratio": 1.4527027027027026,
        "end": 5680.94,
        "id": 1696,
        "no_speech_prob": 0.0021826724987477064,
        "seek": 566958,
        "start": 5678.38,
        "temperature": 0,
        "text": " So let's look for that body parser.",
        "tokens": [
          50804,
          407,
          718,
          311,
          574,
          337,
          300,
          1772,
          21156,
          260,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2565879821777344,
        "compression_ratio": 1.4527027027027026,
        "end": 5685.5,
        "id": 1697,
        "no_speech_prob": 0.0021826724987477064,
        "seek": 566958,
        "start": 5684.54,
        "temperature": 0,
        "text": " Node package.",
        "tokens": [
          51112,
          38640,
          7372,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2565879821777344,
        "compression_ratio": 1.4527027027027026,
        "end": 5697.0199999999995,
        "id": 1698,
        "no_speech_prob": 0.0021826724987477064,
        "seek": 566958,
        "start": 5689.58,
        "temperature": 0,
        "text": " And I just want to look it up on GitHub because let's see if there is a very simple example.",
        "tokens": [
          51364,
          400,
          286,
          445,
          528,
          281,
          574,
          309,
          493,
          322,
          23331,
          570,
          718,
          311,
          536,
          498,
          456,
          307,
          257,
          588,
          2199,
          1365,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5699.18,
        "id": 1699,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5697.580000000001,
        "temperature": 0,
        "text": " Oh, why isn't there like a... there we go.",
        "tokens": [
          50392,
          876,
          11,
          983,
          1943,
          380,
          456,
          411,
          257,
          485,
          456,
          321,
          352,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5705.18,
        "id": 1700,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5703.660000000001,
        "temperature": 0,
        "text": " So I'm just looking at this.",
        "tokens": [
          50696,
          407,
          286,
          478,
          445,
          1237,
          412,
          341,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5709.34,
        "id": 1701,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5707.820000000001,
        "temperature": 0,
        "text": " So this is the example.",
        "tokens": [
          50904,
          407,
          341,
          307,
          264,
          1365,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5714.46,
        "id": 1702,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5709.34,
        "temperature": 0,
        "text": " And then in my example, is that the same body parser.json?",
        "tokens": [
          50980,
          400,
          550,
          294,
          452,
          1365,
          11,
          307,
          300,
          264,
          912,
          1772,
          21156,
          260,
          13,
          73,
          3015,
          30,
          51236
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5715.900000000001,
        "id": 1703,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5715.34,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51280,
          1079,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5720.780000000001,
        "id": 1704,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5716.780000000001,
        "temperature": 0,
        "text": " And app.usebodyparser URL encoded extended true.",
        "tokens": [
          51352,
          400,
          724,
          13,
          438,
          1067,
          79,
          685,
          260,
          12905,
          2058,
          12340,
          10913,
          2074,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.40544109809689405,
        "compression_ratio": 1.4268292682926829,
        "end": 5723.18,
        "id": 1705,
        "no_speech_prob": 0.001206577057018876,
        "seek": 569702,
        "start": 5721.820000000001,
        "temperature": 0,
        "text": " Extended false, whatever.",
        "tokens": [
          51604,
          9881,
          3502,
          7908,
          11,
          2035,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5726.38,
        "id": 1706,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5723.18,
        "temperature": 0,
        "text": " And then what I did is...",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          630,
          307,
          485,
          50524
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5728.22,
        "id": 1707,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5726.38,
        "temperature": 0,
        "text": " I know you probably can't see this.",
        "tokens": [
          50524,
          286,
          458,
          291,
          1391,
          393,
          380,
          536,
          341,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5729.26,
        "id": 1708,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5728.22,
        "temperature": 0,
        "text": " I'm just looking this up.",
        "tokens": [
          50616,
          286,
          478,
          445,
          1237,
          341,
          493,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5731.02,
        "id": 1709,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5729.26,
        "temperature": 0,
        "text": " Request.body.text.",
        "tokens": [
          50668,
          1300,
          20343,
          13,
          1067,
          13,
          25111,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5733.58,
        "id": 1710,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5731.02,
        "temperature": 0,
        "text": " Okay, so that should do it.",
        "tokens": [
          50756,
          1033,
          11,
          370,
          300,
          820,
          360,
          309,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5734.08,
        "id": 1711,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5733.58,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50884,
          1033,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5741.740000000001,
        "id": 1712,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5737.58,
        "temperature": 0,
        "text": " Okay, so I am good here.",
        "tokens": [
          51084,
          1033,
          11,
          370,
          286,
          669,
          665,
          510,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5745.66,
        "id": 1713,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5743.740000000001,
        "temperature": 0,
        "text": " Okay, so where was I?",
        "tokens": [
          51392,
          1033,
          11,
          370,
          689,
          390,
          286,
          30,
          51488
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5746.22,
        "id": 1714,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5745.66,
        "temperature": 0,
        "text": " Ah, yes.",
        "tokens": [
          51488,
          2438,
          11,
          2086,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.47019287477056665,
        "compression_ratio": 1.4027777777777777,
        "end": 5748.320000000001,
        "id": 1715,
        "no_speech_prob": 0.0010162335820496082,
        "seek": 572318,
        "start": 5747.820000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51596,
          1033,
          13,
          51621
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5752.08,
        "id": 1716,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5749.12,
        "temperature": 0,
        "text": " How do I bind that text?",
        "tokens": [
          50404,
          1012,
          360,
          286,
          14786,
          300,
          2487,
          30,
          50552
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5755.2,
        "id": 1717,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5752.639999999999,
        "temperature": 0,
        "text": " This is a mess of data that comes in with the request.",
        "tokens": [
          50580,
          639,
          307,
          257,
          2082,
          295,
          1412,
          300,
          1487,
          294,
          365,
          264,
          5308,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5761.44,
        "id": 1718,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5755.2,
        "temperature": 0,
        "text": " Now we know if you go back to the server when I had a get request, I can simply just look",
        "tokens": [
          50708,
          823,
          321,
          458,
          498,
          291,
          352,
          646,
          281,
          264,
          7154,
          562,
          286,
          632,
          257,
          483,
          5308,
          11,
          286,
          393,
          2935,
          445,
          574,
          51020
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5763.92,
        "id": 1719,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5761.44,
        "temperature": 0,
        "text": " at the request's parameters.",
        "tokens": [
          51020,
          412,
          264,
          5308,
          311,
          9834,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5767.28,
        "id": 1720,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5763.92,
        "temperature": 0,
        "text": " Because these are the parameters that come in with the request with a get.",
        "tokens": [
          51144,
          1436,
          613,
          366,
          264,
          9834,
          300,
          808,
          294,
          365,
          264,
          5308,
          365,
          257,
          483,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5770.08,
        "id": 1721,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5767.28,
        "temperature": 0,
        "text": " With a post request, it's not so simple.",
        "tokens": [
          51312,
          2022,
          257,
          2183,
          5308,
          11,
          309,
          311,
          406,
          370,
          2199,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5772.08,
        "id": 1722,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5770.08,
        "temperature": 0,
        "text": " There isn't just the parameters.",
        "tokens": [
          51452,
          821,
          1943,
          380,
          445,
          264,
          9834,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5773.5199999999995,
        "id": 1723,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5772.08,
        "temperature": 0,
        "text": " There's a get request.",
        "tokens": [
          51552,
          821,
          311,
          257,
          483,
          5308,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.44848934671153196,
        "compression_ratio": 1.869767441860465,
        "end": 5775.28,
        "id": 1724,
        "no_speech_prob": 0.00004198625902063213,
        "seek": 574832,
        "start": 5773.5199999999995,
        "temperature": 0,
        "text": " And then there's a get request.",
        "tokens": [
          51624,
          400,
          550,
          456,
          311,
          257,
          483,
          5308,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5776.32,
        "id": 1725,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5775.28,
        "temperature": 0,
        "text": " It's not so simple.",
        "tokens": [
          50364,
          467,
          311,
          406,
          370,
          2199,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5778.24,
        "id": 1726,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5776.32,
        "temperature": 0,
        "text": " There isn't just the parameters.",
        "tokens": [
          50416,
          821,
          1943,
          380,
          445,
          264,
          9834,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5782.639999999999,
        "id": 1727,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5778.24,
        "temperature": 0,
        "text": " There's this part of it called the body, which has all this information in it.",
        "tokens": [
          50512,
          821,
          311,
          341,
          644,
          295,
          309,
          1219,
          264,
          1772,
          11,
          597,
          575,
          439,
          341,
          1589,
          294,
          309,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5783.679999999999,
        "id": 1728,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5782.639999999999,
        "temperature": 0,
        "text": " And I actually...",
        "tokens": [
          50732,
          400,
          286,
          767,
          485,
          50784
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5785.2,
        "id": 1729,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5784.24,
        "temperature": 0,
        "text": " And I have to parse it.",
        "tokens": [
          50812,
          400,
          286,
          362,
          281,
          48377,
          309,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5790.4,
        "id": 1730,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5786.24,
        "temperature": 0,
        "text": " Luckily for us, there's a node package which will do this parsing for us.",
        "tokens": [
          50912,
          19726,
          337,
          505,
          11,
          456,
          311,
          257,
          9984,
          7372,
          597,
          486,
          360,
          341,
          21156,
          278,
          337,
          505,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5791.36,
        "id": 1731,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5790.4,
        "temperature": 0,
        "text": " And this parsing...",
        "tokens": [
          51120,
          400,
          341,
          21156,
          278,
          485,
          51168
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5794.24,
        "id": 1732,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5792,
        "temperature": 0,
        "text": " This package is called body parser.",
        "tokens": [
          51200,
          639,
          7372,
          307,
          1219,
          1772,
          21156,
          260,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5800.24,
        "id": 1733,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5794.24,
        "temperature": 0,
        "text": " So what I need to do is I need to install that package, body parser.",
        "tokens": [
          51312,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          3625,
          300,
          7372,
          11,
          1772,
          21156,
          260,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5804.16,
        "id": 1734,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5801.679999999999,
        "temperature": 0,
        "text": " And I want to save that as part of this project.",
        "tokens": [
          51684,
          400,
          286,
          528,
          281,
          3155,
          300,
          382,
          644,
          295,
          341,
          1716,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.1899794098129846,
        "compression_ratio": 1.8523206751054853,
        "end": 5804.96,
        "id": 1735,
        "no_speech_prob": 0.16450601816177368,
        "seek": 577528,
        "start": 5804.16,
        "temperature": 0,
        "text": " So I'm saving it.",
        "tokens": [
          51808,
          407,
          286,
          478,
          6816,
          309,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5806.88,
        "id": 1736,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5805.2,
        "temperature": 0,
        "text": " I have the body parser package.",
        "tokens": [
          50376,
          286,
          362,
          264,
          1772,
          21156,
          260,
          7372,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5808.24,
        "id": 1737,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5806.88,
        "temperature": 0,
        "text": " And then what I want to do...",
        "tokens": [
          50460,
          400,
          550,
          437,
          286,
          528,
          281,
          360,
          485,
          50528
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5808.88,
        "id": 1738,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5808.24,
        "temperature": 0,
        "text": " And I'm on...",
        "tokens": [
          50528,
          400,
          286,
          478,
          322,
          485,
          50560
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5811.12,
        "id": 1739,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5809.44,
        "temperature": 0,
        "text": " I'll include a link in this video's description.",
        "tokens": [
          50588,
          286,
          603,
          4090,
          257,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5812.56,
        "id": 1740,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5811.12,
        "temperature": 0,
        "text": " But I'm on the GitHub repository.",
        "tokens": [
          50672,
          583,
          286,
          478,
          322,
          264,
          23331,
          25841,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5813.6,
        "id": 1741,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5812.56,
        "temperature": 0,
        "text": " I just want to look at...",
        "tokens": [
          50744,
          286,
          445,
          528,
          281,
          574,
          412,
          485,
          50796
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5814.64,
        "id": 1742,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5814.16,
        "temperature": 0,
        "text": " I just want to...",
        "tokens": [
          50824,
          286,
          445,
          528,
          281,
          485,
          50848
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5815.6,
        "id": 1743,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5814.64,
        "temperature": 0,
        "text": " I need to require it.",
        "tokens": [
          50848,
          286,
          643,
          281,
          3651,
          309,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5820.72,
        "id": 1744,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5818,
        "temperature": 0,
        "text": " So I need to add it to my code at the top.",
        "tokens": [
          51016,
          407,
          286,
          643,
          281,
          909,
          309,
          281,
          452,
          3089,
          412,
          264,
          1192,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5821.28,
        "id": 1745,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5820.72,
        "temperature": 0,
        "text": " Or it doesn't really...",
        "tokens": [
          51152,
          1610,
          309,
          1177,
          380,
          534,
          485,
          51180
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5824.16,
        "id": 1746,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5821.28,
        "temperature": 0,
        "text": " I'm going to add it here where I require express.",
        "tokens": [
          51180,
          286,
          478,
          516,
          281,
          909,
          309,
          510,
          689,
          286,
          3651,
          5109,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5829.44,
        "id": 1747,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5824.8,
        "temperature": 0,
        "text": " And then after I create the app, this is serving static files.",
        "tokens": [
          51356,
          400,
          550,
          934,
          286,
          1884,
          264,
          724,
          11,
          341,
          307,
          8148,
          13437,
          7098,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.19674583220146072,
        "compression_ratio": 1.7777777777777777,
        "end": 5832,
        "id": 1748,
        "no_speech_prob": 0.000458305497886613,
        "seek": 580496,
        "start": 5829.44,
        "temperature": 0,
        "text": " I now want to use this body parser package.",
        "tokens": [
          51588,
          286,
          586,
          528,
          281,
          764,
          341,
          1772,
          21156,
          260,
          7372,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5835.76,
        "id": 1749,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5832.24,
        "temperature": 0,
        "text": " I'm going to just scroll all the way down here on this documentation page",
        "tokens": [
          50376,
          286,
          478,
          516,
          281,
          445,
          11369,
          439,
          264,
          636,
          760,
          510,
          322,
          341,
          14333,
          3028,
          50552
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5837.6,
        "id": 1750,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5835.76,
        "temperature": 0,
        "text": " where I know there's a quick example.",
        "tokens": [
          50552,
          689,
          286,
          458,
          456,
          311,
          257,
          1702,
          1365,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5838.96,
        "id": 1751,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5837.6,
        "temperature": 0,
        "text": " And I can grab this code.",
        "tokens": [
          50644,
          400,
          286,
          393,
          4444,
          341,
          3089,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5841.44,
        "id": 1752,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5840.32,
        "temperature": 0,
        "text": " And I can add it in.",
        "tokens": [
          50780,
          400,
          286,
          393,
          909,
          309,
          294,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5845.92,
        "id": 1753,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5842.08,
        "temperature": 0,
        "text": " So I now am telling this app, this web application,",
        "tokens": [
          50868,
          407,
          286,
          586,
          669,
          3585,
          341,
          724,
          11,
          341,
          3670,
          3861,
          11,
          51060
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5849.44,
        "id": 1754,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5845.92,
        "temperature": 0,
        "text": " which is an express application that's listening on this port,",
        "tokens": [
          51060,
          597,
          307,
          364,
          5109,
          3861,
          300,
          311,
          4764,
          322,
          341,
          2436,
          11,
          51236
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5852.8,
        "id": 1755,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5849.44,
        "temperature": 0,
        "text": " which uses static hosting for the stuff in the website folder,",
        "tokens": [
          51236,
          597,
          4960,
          13437,
          16058,
          337,
          264,
          1507,
          294,
          264,
          3144,
          10820,
          11,
          51404
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5854.96,
        "id": 1756,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5852.8,
        "temperature": 0,
        "text": " now also has the body parser.",
        "tokens": [
          51404,
          586,
          611,
          575,
          264,
          1772,
          21156,
          260,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5858.48,
        "id": 1757,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5854.96,
        "temperature": 0,
        "text": " And I want to use JSON because I want to get the stuff...",
        "tokens": [
          51512,
          400,
          286,
          528,
          281,
          764,
          31828,
          570,
          286,
          528,
          281,
          483,
          264,
          1507,
          485,
          51688
        ]
      },
      {
        "avg_logprob": -0.1862810528467572,
        "compression_ratio": 1.7424242424242424,
        "end": 5861.04,
        "id": 1758,
        "no_speech_prob": 0.0003625876270234585,
        "seek": 583200,
        "start": 5859.2,
        "temperature": 0,
        "text": " I want to parse everything as JSON.",
        "tokens": [
          51724,
          286,
          528,
          281,
          48377,
          1203,
          382,
          31828,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5861.6,
        "id": 1759,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5861.04,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50392
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5864.56,
        "id": 1760,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5861.6,
        "temperature": 0,
        "text": " So now that I have that, I should be able to say...",
        "tokens": [
          50392,
          407,
          586,
          300,
          286,
          362,
          300,
          11,
          286,
          820,
          312,
          1075,
          281,
          584,
          485,
          50540
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5866.24,
        "id": 1761,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5864.56,
        "temperature": 0,
        "text": " Oh boy, do I hope that that's true.",
        "tokens": [
          50540,
          876,
          3237,
          11,
          360,
          286,
          1454,
          300,
          300,
          311,
          2074,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5868.9,
        "id": 1762,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5868.4,
        "temperature": 0,
        "text": " In the...",
        "tokens": [
          50732,
          682,
          264,
          485,
          50757
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5873.2,
        "id": 1763,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5869.76,
        "temperature": 0,
        "text": " In the post, where I'm handling the post, I've already lost it right here.",
        "tokens": [
          50800,
          682,
          264,
          2183,
          11,
          689,
          286,
          478,
          13175,
          264,
          2183,
          11,
          286,
          600,
          1217,
          2731,
          309,
          558,
          510,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5875.92,
        "id": 1764,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5873.2,
        "temperature": 0,
        "text": " Let's say console.log request.body.",
        "tokens": [
          50972,
          961,
          311,
          584,
          11076,
          13,
          4987,
          5308,
          13,
          1067,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5880.08,
        "id": 1765,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5877.12,
        "temperature": 0,
        "text": " And so I'm going to restart the server.",
        "tokens": [
          51168,
          400,
          370,
          286,
          478,
          516,
          281,
          21022,
          264,
          7154,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5881.22,
        "id": 1766,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5880.72,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51348,
          45263,
          13,
          51373
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5886.48,
        "id": 1767,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5882.72,
        "temperature": 0,
        "text": " And I'm going to refresh this page.",
        "tokens": [
          51448,
          400,
          286,
          478,
          516,
          281,
          15134,
          341,
          3028,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5888.4,
        "id": 1768,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5886.48,
        "temperature": 0,
        "text": " I'm going to say this is a test.",
        "tokens": [
          51636,
          286,
          478,
          516,
          281,
          584,
          341,
          307,
          257,
          1500,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2136546994043776,
        "compression_ratio": 1.6682242990654206,
        "end": 5889.92,
        "id": 1769,
        "no_speech_prob": 0.000006144136023067404,
        "seek": 586104,
        "start": 5888.4,
        "temperature": 0,
        "text": " I'm going to hit analyze.",
        "tokens": [
          51732,
          286,
          478,
          516,
          281,
          2045,
          12477,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5891.36,
        "id": 1770,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5889.92,
        "temperature": 0,
        "text": " I got the message back.",
        "tokens": [
          50364,
          286,
          658,
          264,
          3636,
          646,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5892,
        "id": 1771,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5891.36,
        "temperature": 0,
        "text": " And oops.",
        "tokens": [
          50436,
          400,
          34166,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5894.08,
        "id": 1772,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5892.88,
        "temperature": 0,
        "text": " I got an empty object.",
        "tokens": [
          50512,
          286,
          658,
          364,
          6707,
          2657,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5895.28,
        "id": 1773,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5894.08,
        "temperature": 0,
        "text": " But I think maybe just the...",
        "tokens": [
          50572,
          583,
          286,
          519,
          1310,
          445,
          264,
          485,
          50632
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5897.12,
        "id": 1774,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5895.92,
        "temperature": 0,
        "text": " I think maybe just the...",
        "tokens": [
          50664,
          286,
          519,
          1310,
          445,
          264,
          485,
          50724
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5901.4400000000005,
        "id": 1775,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5899.52,
        "temperature": 0,
        "text": " The console isn't like logging it properly.",
        "tokens": [
          50844,
          440,
          11076,
          1943,
          380,
          411,
          27991,
          309,
          6108,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5904.24,
        "id": 1776,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5902,
        "temperature": 0,
        "text": " And so at some point, I want to show other ways of debugging",
        "tokens": [
          50968,
          400,
          370,
          412,
          512,
          935,
          11,
          286,
          528,
          281,
          855,
          661,
          2098,
          295,
          45592,
          51080
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5906.16,
        "id": 1777,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5904.24,
        "temperature": 0,
        "text": " and know where you can get a nice JavaScript console.",
        "tokens": [
          51080,
          293,
          458,
          689,
          291,
          393,
          483,
          257,
          1481,
          15778,
          11076,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5907.92,
        "id": 1778,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5906.16,
        "temperature": 0,
        "text": " But I'll have to do that in another video.",
        "tokens": [
          51176,
          583,
          286,
          603,
          362,
          281,
          360,
          300,
          294,
          1071,
          960,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5909.6,
        "id": 1779,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5907.92,
        "temperature": 0,
        "text": " Let's look if I can say...",
        "tokens": [
          51264,
          961,
          311,
          574,
          498,
          286,
          393,
          584,
          485,
          51348
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5911.2,
        "id": 1780,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5910.16,
        "temperature": 0,
        "text": " Where am I here?",
        "tokens": [
          51376,
          2305,
          669,
          286,
          510,
          30,
          51428
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5912.8,
        "id": 1781,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5911.2,
        "temperature": 0,
        "text": " A body.",
        "tokens": [
          51428,
          316,
          1772,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.24212216222008995,
        "compression_ratio": 1.5862068965517242,
        "end": 5917.36,
        "id": 1782,
        "no_speech_prob": 0.00009314573981100693,
        "seek": 588992,
        "start": 5913.92,
        "temperature": 0,
        "text": " In Sketch.js, boy, this is getting complicated.",
        "tokens": [
          51564,
          682,
          49245,
          13,
          25530,
          11,
          3237,
          11,
          341,
          307,
          1242,
          6179,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5920.48,
        "id": 1783,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5917.36,
        "temperature": 0,
        "text": " I sent it as data with a text property.",
        "tokens": [
          50364,
          286,
          2279,
          309,
          382,
          1412,
          365,
          257,
          2487,
          4707,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5922.88,
        "id": 1784,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5920.48,
        "temperature": 0,
        "text": " So I should be able to say body.text.",
        "tokens": [
          50520,
          407,
          286,
          820,
          312,
          1075,
          281,
          584,
          1772,
          13,
          25111,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5924.639999999999,
        "id": 1785,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5922.88,
        "temperature": 0,
        "text": " And I should see what was sent.",
        "tokens": [
          50640,
          400,
          286,
          820,
          536,
          437,
          390,
          2279,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5928.88,
        "id": 1786,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5924.639999999999,
        "temperature": 0,
        "text": " So let me try doing this one more time and hitting refresh.",
        "tokens": [
          50728,
          407,
          718,
          385,
          853,
          884,
          341,
          472,
          544,
          565,
          293,
          8850,
          15134,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5930.719999999999,
        "id": 1787,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5929.44,
        "temperature": 0,
        "text": " And this is a test.",
        "tokens": [
          50968,
          400,
          341,
          307,
          257,
          1500,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5933.92,
        "id": 1788,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5932.5599999999995,
        "temperature": 0,
        "text": " And I look in here.",
        "tokens": [
          51124,
          400,
          286,
          574,
          294,
          510,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5934.639999999999,
        "id": 1789,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5933.92,
        "temperature": 0,
        "text": " Undefined.",
        "tokens": [
          51192,
          2719,
          5666,
          2001,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5936.24,
        "id": 1790,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5935.599999999999,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          51276,
          6161,
          484,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5938.24,
        "id": 1791,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5936.88,
        "temperature": 0,
        "text": " I have to debug this.",
        "tokens": [
          51340,
          286,
          362,
          281,
          24083,
          341,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5939.44,
        "id": 1792,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5938.24,
        "temperature": 0,
        "text": " I forgot what I did wrong.",
        "tokens": [
          51408,
          286,
          5298,
          437,
          286,
          630,
          2085,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5945.599999999999,
        "id": 1793,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5944.24,
        "temperature": 0,
        "text": " OK, let's see here.",
        "tokens": [
          51708,
          2264,
          11,
          718,
          311,
          536,
          510,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.17282858992044905,
        "compression_ratio": 1.5763546798029557,
        "end": 5946.96,
        "id": 1794,
        "no_speech_prob": 0.0008693636045791209,
        "seek": 591736,
        "start": 5945.599999999999,
        "temperature": 0,
        "text": " What did I do wrong?",
        "tokens": [
          51776,
          708,
          630,
          286,
          360,
          2085,
          30,
          51844
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5949.68,
        "id": 1795,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5946.96,
        "temperature": 0,
        "text": " Let's look at my existing example.",
        "tokens": [
          50364,
          961,
          311,
          574,
          412,
          452,
          6741,
          1365,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5954.8,
        "id": 1796,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5953.52,
        "temperature": 0,
        "text": " Do I need this?",
        "tokens": [
          50692,
          1144,
          286,
          643,
          341,
          30,
          50756
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5958.16,
        "id": 1797,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5956.56,
        "temperature": 0,
        "text": " No, no, use function.",
        "tokens": [
          50844,
          883,
          11,
          572,
          11,
          764,
          2445,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5961.36,
        "id": 1798,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5958.16,
        "temperature": 0,
        "text": " OK, let me see if there was something I missed in my other example.",
        "tokens": [
          50924,
          2264,
          11,
          718,
          385,
          536,
          498,
          456,
          390,
          746,
          286,
          6721,
          294,
          452,
          661,
          1365,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5964.72,
        "id": 1799,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5963.12,
        "temperature": 0,
        "text": " Oh, boy, it's already five o'clock.",
        "tokens": [
          51172,
          876,
          11,
          3237,
          11,
          309,
          311,
          1217,
          1732,
          277,
          6,
          9023,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5965.22,
        "id": 1800,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5964.72,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          51252,
          3153,
          13,
          51277
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5970.4,
        "id": 1801,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5966.4800000000005,
        "temperature": 0,
        "text": " This stuff always takes twice as long, if not four times as long as I think.",
        "tokens": [
          51340,
          639,
          1507,
          1009,
          2516,
          6091,
          382,
          938,
          11,
          498,
          406,
          1451,
          1413,
          382,
          938,
          382,
          286,
          519,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5972,
        "id": 1802,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5970.4,
        "temperature": 0,
        "text": " But I'm close to the end of this.",
        "tokens": [
          51536,
          583,
          286,
          478,
          1998,
          281,
          264,
          917,
          295,
          341,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5975.84,
        "id": 1803,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5974.4800000000005,
        "temperature": 0,
        "text": " I made an example that does this.",
        "tokens": [
          51740,
          286,
          1027,
          364,
          1365,
          300,
          775,
          341,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.17924594019984338,
        "compression_ratio": 1.5022222222222221,
        "end": 5976.56,
        "id": 1804,
        "no_speech_prob": 0.0000875028854352422,
        "seek": 594696,
        "start": 5975.84,
        "temperature": 0,
        "text": " Let's look.",
        "tokens": [
          51808,
          961,
          311,
          574,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 5978.08,
        "id": 1805,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 5977.12,
        "temperature": 0,
        "text": " And I want to mention cores.",
        "tokens": [
          50372,
          400,
          286,
          528,
          281,
          2152,
          24826,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 5982.96,
        "id": 1806,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 5980.8,
        "temperature": 0,
        "text": " I mean, could extended true matter?",
        "tokens": [
          50556,
          286,
          914,
          11,
          727,
          10913,
          2074,
          1871,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 5984.08,
        "id": 1807,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 5982.96,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          50664,
          286,
          500,
          380,
          519,
          370,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 5989.12,
        "id": 1808,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 5985.12,
        "temperature": 0,
        "text": " Let's just let me grab this.",
        "tokens": [
          50772,
          961,
          311,
          445,
          718,
          385,
          4444,
          341,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 5995.2,
        "id": 1809,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 5994.24,
        "temperature": 0,
        "text": " Let me just make sure.",
        "tokens": [
          51228,
          961,
          385,
          445,
          652,
          988,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 5997.52,
        "id": 1810,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 5996.24,
        "temperature": 0,
        "text": " This is the same, really.",
        "tokens": [
          51328,
          639,
          307,
          264,
          912,
          11,
          534,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2865170478820801,
        "compression_ratio": 1.2713178294573644,
        "end": 6005.68,
        "id": 1811,
        "no_speech_prob": 0.000023187449187389575,
        "seek": 597696,
        "start": 6004.88,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51760,
          2264,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2421091591439596,
        "compression_ratio": 1.5485714285714285,
        "end": 6007.52,
        "id": 1812,
        "no_speech_prob": 0.000020462901375140063,
        "seek": 600568,
        "start": 6005.76,
        "temperature": 0,
        "text": " So this is what I have.",
        "tokens": [
          50368,
          407,
          341,
          307,
          437,
          286,
          362,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.2421091591439596,
        "compression_ratio": 1.5485714285714285,
        "end": 6017.280000000001,
        "id": 1813,
        "no_speech_prob": 0.000020462901375140063,
        "seek": 600568,
        "start": 6008.240000000001,
        "temperature": 0,
        "text": " And then when I handle the post, analyze, analyze, request, response, request body text.",
        "tokens": [
          50492,
          400,
          550,
          562,
          286,
          4813,
          264,
          2183,
          11,
          12477,
          11,
          12477,
          11,
          5308,
          11,
          4134,
          11,
          5308,
          1772,
          2487,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.2421091591439596,
        "compression_ratio": 1.5485714285714285,
        "end": 6020.16,
        "id": 1814,
        "no_speech_prob": 0.000020462901375140063,
        "seek": 600568,
        "start": 6018.72,
        "temperature": 0,
        "text": " This looks the same, right?",
        "tokens": [
          51016,
          639,
          1542,
          264,
          912,
          11,
          558,
          30,
          51088
        ]
      },
      {
        "avg_logprob": -0.2421091591439596,
        "compression_ratio": 1.5485714285714285,
        "end": 6027.76,
        "id": 1815,
        "no_speech_prob": 0.000020462901375140063,
        "seek": 600568,
        "start": 6021.76,
        "temperature": 0,
        "text": " All right, I'm going to have to look at the client, obviously, to see if that's where it's",
        "tokens": [
          51168,
          1057,
          558,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          574,
          412,
          264,
          6423,
          11,
          2745,
          11,
          281,
          536,
          498,
          300,
          311,
          689,
          309,
          311,
          51468
        ]
      },
      {
        "avg_logprob": -0.2421091591439596,
        "compression_ratio": 1.5485714285714285,
        "end": 6028.320000000001,
        "id": 1816,
        "no_speech_prob": 0.000020462901375140063,
        "seek": 600568,
        "start": 6027.76,
        "temperature": 0,
        "text": " different.",
        "tokens": [
          51468,
          819,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2421091591439596,
        "compression_ratio": 1.5485714285714285,
        "end": 6030.96,
        "id": 1817,
        "no_speech_prob": 0.000020462901375140063,
        "seek": 600568,
        "start": 6028.320000000001,
        "temperature": 0,
        "text": " Let's also go to the client.",
        "tokens": [
          51496,
          961,
          311,
          611,
          352,
          281,
          264,
          6423,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.16447535157203674,
        "compression_ratio": 1.3838383838383839,
        "end": 6043.52,
        "id": 1818,
        "no_speech_prob": 0.03358916938304901,
        "seek": 603096,
        "start": 6031.6,
        "temperature": 0,
        "text": " I don't know if anybody in the data is not in the post request.",
        "tokens": [
          50396,
          286,
          500,
          380,
          458,
          498,
          4472,
          294,
          264,
          1412,
          307,
          406,
          294,
          264,
          2183,
          5308,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.16447535157203674,
        "compression_ratio": 1.3838383838383839,
        "end": 6047.6,
        "id": 1819,
        "no_speech_prob": 0.03358916938304901,
        "seek": 603096,
        "start": 6045.92,
        "temperature": 0,
        "text": " Oh, I forgot to put data.",
        "tokens": [
          51112,
          876,
          11,
          286,
          5298,
          281,
          829,
          1412,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.16447535157203674,
        "compression_ratio": 1.3838383838383839,
        "end": 6052.64,
        "id": 1820,
        "no_speech_prob": 0.03358916938304901,
        "seek": 603096,
        "start": 6050.96,
        "temperature": 0,
        "text": " I forgot to post the data.",
        "tokens": [
          51364,
          286,
          5298,
          281,
          2183,
          264,
          1412,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.16447535157203674,
        "compression_ratio": 1.3838383838383839,
        "end": 6054.32,
        "id": 1821,
        "no_speech_prob": 0.03358916938304901,
        "seek": 603096,
        "start": 6053.36,
        "temperature": 0,
        "text": " I bet you that's it.",
        "tokens": [
          51484,
          286,
          778,
          291,
          300,
          311,
          309,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6059.5199999999995,
        "id": 1822,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6055.28,
        "temperature": 0,
        "text": " How many subscribers have I lost during the course of this making of this video?",
        "tokens": [
          50412,
          1012,
          867,
          11092,
          362,
          286,
          2731,
          1830,
          264,
          1164,
          295,
          341,
          1455,
          295,
          341,
          960,
          30,
          50624
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6064.5599999999995,
        "id": 1823,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6060.4,
        "temperature": 0,
        "text": " A test, analyze, thank you.",
        "tokens": [
          50668,
          316,
          1500,
          11,
          12477,
          11,
          1309,
          291,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6067.599999999999,
        "id": 1824,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6065.28,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50912,
          400,
          456,
          321,
          352,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6068.08,
        "id": 1825,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6067.599999999999,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51028,
          2264,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6076.4,
        "id": 1826,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6070.719999999999,
        "temperature": 0,
        "text": " Thank you to David in the chat who helped me solve this problem.",
        "tokens": [
          51184,
          1044,
          291,
          281,
          4389,
          294,
          264,
          5081,
          567,
          4254,
          385,
          5039,
          341,
          1154,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6078.719999999999,
        "id": 1827,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6077.04,
        "temperature": 0,
        "text": " Hopefully, I would have noticed it eventually.",
        "tokens": [
          51500,
          10429,
          11,
          286,
          576,
          362,
          5694,
          309,
          4728,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6080.24,
        "id": 1828,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6078.719999999999,
        "temperature": 0,
        "text": " But I just completely forgot this.",
        "tokens": [
          51584,
          583,
          286,
          445,
          2584,
          5298,
          341,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.4608202202375545,
        "compression_ratio": 1.4682926829268292,
        "end": 6081.36,
        "id": 1829,
        "no_speech_prob": 0.005819917656481266,
        "seek": 605432,
        "start": 6080.24,
        "temperature": 0,
        "text": " I need to take this out.",
        "tokens": [
          51660,
          286,
          643,
          281,
          747,
          341,
          484,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6085.12,
        "id": 1830,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6081.44,
        "temperature": 0,
        "text": " I need to back up to here.",
        "tokens": [
          50368,
          286,
          643,
          281,
          646,
          493,
          281,
          510,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6085.839999999999,
        "id": 1831,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6085.12,
        "temperature": 0,
        "text": " This is the same.",
        "tokens": [
          50552,
          639,
          307,
          264,
          912,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6086.88,
        "id": 1832,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6085.839999999999,
        "temperature": 0,
        "text": " I just had this as false.",
        "tokens": [
          50588,
          286,
          445,
          632,
          341,
          382,
          7908,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6087.92,
        "id": 1833,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6086.88,
        "temperature": 0,
        "text": " I don't think that matters.",
        "tokens": [
          50640,
          286,
          500,
          380,
          519,
          300,
          7001,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6090.4,
        "id": 1834,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6088.799999999999,
        "temperature": 0,
        "text": " Let me go down to here.",
        "tokens": [
          50736,
          961,
          385,
          352,
          760,
          281,
          510,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6103.28,
        "id": 1835,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6091.12,
        "temperature": 0,
        "text": " And let me go to back to here, console.log.",
        "tokens": [
          50852,
          400,
          718,
          385,
          352,
          281,
          646,
          281,
          510,
          11,
          11076,
          13,
          4987,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.5088707084086403,
        "compression_ratio": 1.4435483870967742,
        "end": 6107.2,
        "id": 1836,
        "no_speech_prob": 0.017711928114295006,
        "seek": 608136,
        "start": 6106.639999999999,
        "temperature": 0,
        "text": " Console.log.",
        "tokens": [
          51628,
          44152,
          13,
          4987,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6109.76,
        "id": 1837,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6108.16,
        "temperature": 0.6000000000000001,
        "text": " Where, where, where, where, where, where?",
        "tokens": [
          50412,
          2305,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          11,
          689,
          30,
          50492
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6111.679999999999,
        "id": 1838,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6109.76,
        "temperature": 0.6000000000000001,
        "text": " For when it's finished or if there's an error.",
        "tokens": [
          50492,
          1171,
          562,
          309,
          311,
          4335,
          420,
          498,
          258,
          260,
          68,
          311,
          364,
          6713,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6112.32,
        "id": 1839,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6111.679999999999,
        "temperature": 0.6000000000000001,
        "text": " What's missing?",
        "tokens": [
          50588,
          708,
          311,
          5361,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6113.679999999999,
        "id": 1840,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6112.32,
        "temperature": 0.6000000000000001,
        "text": " I just listed five things.",
        "tokens": [
          50620,
          286,
          445,
          10052,
          1732,
          721,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6115.36,
        "id": 1841,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6113.679999999999,
        "temperature": 0.6000000000000001,
        "text": " I forgot to actually send the data.",
        "tokens": [
          50688,
          286,
          5298,
          281,
          767,
          2845,
          264,
          1412,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6116.5599999999995,
        "id": 1842,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6115.36,
        "temperature": 0.6000000000000001,
        "text": " Data goes here.",
        "tokens": [
          50772,
          11888,
          1709,
          510,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6117.92,
        "id": 1843,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6116.5599999999995,
        "temperature": 0.6000000000000001,
        "text": " So I forgot to post the data.",
        "tokens": [
          50832,
          407,
          286,
          5298,
          281,
          2183,
          264,
          1412,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6121.12,
        "id": 1844,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6117.92,
        "temperature": 0.6000000000000001,
        "text": " So there's no way for me to read or receive the data if I didn't post it.",
        "tokens": [
          50900,
          407,
          456,
          311,
          572,
          636,
          337,
          385,
          281,
          1401,
          420,
          4774,
          264,
          1412,
          498,
          286,
          994,
          380,
          2183,
          309,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6122.4,
        "id": 1845,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6121.12,
        "temperature": 0.6000000000000001,
        "text": " So that's done now.",
        "tokens": [
          51060,
          407,
          300,
          311,
          1096,
          586,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6124.88,
        "id": 1846,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6122.96,
        "temperature": 0.6000000000000001,
        "text": " And I think it's going to work.",
        "tokens": [
          51152,
          400,
          286,
          519,
          309,
          311,
          516,
          281,
          589,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6129.76,
        "id": 1847,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6124.88,
        "temperature": 0.6000000000000001,
        "text": " So let me, oh, I actually don't have to restart the server because I just changed the client",
        "tokens": [
          51248,
          220,
          6455,
          718,
          385,
          11,
          1954,
          11,
          286,
          767,
          500,
          380,
          362,
          281,
          21022,
          264,
          7154,
          570,
          286,
          445,
          3105,
          264,
          6423,
          51492
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6130.24,
        "id": 1848,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6129.76,
        "temperature": 0.6000000000000001,
        "text": " code.",
        "tokens": [
          51492,
          3089,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6130.8,
        "id": 1849,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6130.24,
        "temperature": 0.6000000000000001,
        "text": " And you know what?",
        "tokens": [
          51516,
          400,
          291,
          458,
          437,
          30,
          51544
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6132,
        "id": 1850,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6130.8,
        "temperature": 0.6000000000000001,
        "text": " This is driving me crazy.",
        "tokens": [
          51544,
          639,
          307,
          4840,
          385,
          3219,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.4098119156136697,
        "compression_ratio": 1.8963210702341138,
        "end": 6136.96,
        "id": 1851,
        "no_speech_prob": 0.0007208349998109043,
        "seek": 610720,
        "start": 6132,
        "temperature": 0.6000000000000001,
        "text": " I just want to in the client, I just want to say, oh, this is not the right server.",
        "tokens": [
          51604,
          286,
          445,
          528,
          281,
          294,
          264,
          6423,
          11,
          286,
          445,
          528,
          281,
          584,
          11,
          1954,
          11,
          341,
          307,
          406,
          264,
          558,
          7154,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6140,
        "id": 1852,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6137.28,
        "temperature": 0,
        "text": " I'm going to say, just add something here.",
        "tokens": [
          50380,
          286,
          478,
          516,
          281,
          584,
          11,
          445,
          909,
          746,
          510,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6149.28,
        "id": 1853,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6140,
        "temperature": 0,
        "text": " Like, I am happy today because I saw a rainbow and some kittens.",
        "tokens": [
          50516,
          1743,
          11,
          286,
          669,
          2055,
          965,
          570,
          286,
          1866,
          257,
          18526,
          293,
          512,
          47363,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6154.72,
        "id": 1854,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6149.84,
        "temperature": 0,
        "text": " OK, so now I have some text pre-filled in.",
        "tokens": [
          51008,
          2264,
          11,
          370,
          586,
          286,
          362,
          512,
          2487,
          659,
          12,
          35596,
          294,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6155.84,
        "id": 1855,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6154.72,
        "temperature": 0,
        "text": " I can hit analyze.",
        "tokens": [
          51252,
          286,
          393,
          2045,
          12477,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6157.92,
        "id": 1856,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6156.4800000000005,
        "temperature": 0,
        "text": " I got a message saying thank you.",
        "tokens": [
          51340,
          286,
          658,
          257,
          3636,
          1566,
          1309,
          291,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6162.88,
        "id": 1857,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6158.64,
        "temperature": 0,
        "text": " And I can go look at the server and I can see that that data came into the server via",
        "tokens": [
          51448,
          400,
          286,
          393,
          352,
          574,
          412,
          264,
          7154,
          293,
          286,
          393,
          536,
          300,
          300,
          1412,
          1361,
          666,
          264,
          7154,
          5766,
          51660
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6163.38,
        "id": 1858,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6162.88,
        "temperature": 0,
        "text": " the post.",
        "tokens": [
          51660,
          264,
          2183,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.28197597970767896,
        "compression_ratio": 1.5441176470588236,
        "end": 6166.08,
        "id": 1859,
        "no_speech_prob": 0.0000468384096166119,
        "seek": 613696,
        "start": 6164.88,
        "temperature": 0,
        "text": " We have a post.",
        "tokens": [
          51760,
          492,
          362,
          257,
          2183,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6167.44,
        "id": 1860,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6166.08,
        "temperature": 0,
        "text": " We have a post working.",
        "tokens": [
          50364,
          492,
          362,
          257,
          2183,
          1364,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6168.4,
        "id": 1861,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6167.44,
        "temperature": 0,
        "text": " That is awesome.",
        "tokens": [
          50432,
          663,
          307,
          3476,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6171.12,
        "id": 1862,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6168.4,
        "temperature": 0,
        "text": " OK, so now all I need to do is do sentiment analysis.",
        "tokens": [
          50480,
          2264,
          11,
          370,
          586,
          439,
          286,
          643,
          281,
          360,
          307,
          360,
          16149,
          5215,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6174,
        "id": 1863,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6171.12,
        "temperature": 0,
        "text": " I really should just give this to you as an exercise and end this video now.",
        "tokens": [
          50616,
          286,
          534,
          820,
          445,
          976,
          341,
          281,
          291,
          382,
          364,
          5380,
          293,
          917,
          341,
          960,
          586,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6176.8,
        "id": 1864,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6174,
        "temperature": 0,
        "text": " But I'm going to finish it up myself.",
        "tokens": [
          50760,
          583,
          286,
          478,
          516,
          281,
          2413,
          309,
          493,
          2059,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6183.68,
        "id": 1865,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6176.8,
        "temperature": 0,
        "text": " So the nice thing is I, all I can, this isn't too hard for me to do now in the server.",
        "tokens": [
          50900,
          407,
          264,
          1481,
          551,
          307,
          286,
          11,
          439,
          286,
          393,
          11,
          341,
          1943,
          380,
          886,
          1152,
          337,
          385,
          281,
          360,
          586,
          294,
          264,
          7154,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6186.08,
        "id": 1866,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6183.68,
        "temperature": 0,
        "text": " I'm going to go to the server code.",
        "tokens": [
          51244,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          7154,
          3089,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18178468409592544,
        "compression_ratio": 1.5893536121673004,
        "end": 6194.16,
        "id": 1867,
        "no_speech_prob": 0.00005562193473451771,
        "seek": 616608,
        "start": 6186.08,
        "temperature": 0,
        "text": " And right here, instead of console logging, I want to look at and say var text equals",
        "tokens": [
          51364,
          400,
          558,
          510,
          11,
          2602,
          295,
          11076,
          27991,
          11,
          286,
          528,
          281,
          574,
          412,
          293,
          584,
          1374,
          2487,
          6915,
          51768
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6196.5599999999995,
        "id": 1868,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6194.16,
        "temperature": 0,
        "text": " request.body text.",
        "tokens": [
          50364,
          5308,
          13,
          1067,
          2487,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6199.84,
        "id": 1869,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6196.5599999999995,
        "temperature": 0,
        "text": " Then I want to split it up, text.split.",
        "tokens": [
          50484,
          1396,
          286,
          528,
          281,
          7472,
          309,
          493,
          11,
          2487,
          13,
          46535,
          270,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6205.44,
        "id": 1870,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6199.84,
        "temperature": 0,
        "text": " And I'm going to use just a regular expression here to split it up into words by anything",
        "tokens": [
          50648,
          400,
          286,
          478,
          516,
          281,
          764,
          445,
          257,
          3890,
          6114,
          510,
          281,
          7472,
          309,
          493,
          666,
          2283,
          538,
          1340,
          50928
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6208,
        "id": 1871,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6205.44,
        "temperature": 0,
        "text": " that's not a letter or number.",
        "tokens": [
          50928,
          300,
          311,
          406,
          257,
          5063,
          420,
          1230,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6211.12,
        "id": 1872,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6209.2,
        "temperature": 0,
        "text": " I explain this in so many videos.",
        "tokens": [
          51116,
          286,
          2903,
          341,
          294,
          370,
          867,
          2145,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6217.68,
        "id": 1873,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6211.12,
        "temperature": 0,
        "text": " But this is pattern matching and backslash capital W is anything that's not a to z or",
        "tokens": [
          51212,
          583,
          341,
          307,
          5102,
          14324,
          293,
          646,
          10418,
          1299,
          4238,
          343,
          307,
          1340,
          300,
          311,
          406,
          257,
          281,
          710,
          420,
          51540
        ]
      },
      {
        "avg_logprob": -0.20608719446325816,
        "compression_ratio": 1.59,
        "end": 6218.88,
        "id": 1874,
        "no_speech_prob": 0.001325017772614956,
        "seek": 619416,
        "start": 6217.68,
        "temperature": 0,
        "text": " zero through nine.",
        "tokens": [
          51540,
          4018,
          807,
          4949,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.1933491318314164,
        "compression_ratio": 1.4274193548387097,
        "end": 6222.88,
        "id": 1875,
        "no_speech_prob": 0.0010649578180164099,
        "seek": 621888,
        "start": 6218.96,
        "temperature": 0,
        "text": " And so now I can loop through those words.",
        "tokens": [
          50368,
          400,
          370,
          586,
          286,
          393,
          6367,
          807,
          729,
          2283,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1933491318314164,
        "compression_ratio": 1.4274193548387097,
        "end": 6234.56,
        "id": 1876,
        "no_speech_prob": 0.0010649578180164099,
        "seek": 621888,
        "start": 6227.36,
        "temperature": 0,
        "text": " And I can say now what I want to do is I want to first look, I need a total score.",
        "tokens": [
          50788,
          400,
          286,
          393,
          584,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          700,
          574,
          11,
          286,
          643,
          257,
          3217,
          6175,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.1933491318314164,
        "compression_ratio": 1.4274193548387097,
        "end": 6238.64,
        "id": 1877,
        "no_speech_prob": 0.0010649578180164099,
        "seek": 621888,
        "start": 6235.12,
        "temperature": 0,
        "text": " So I'm going to have a total score started at zero.",
        "tokens": [
          51176,
          407,
          286,
          478,
          516,
          281,
          362,
          257,
          3217,
          6175,
          1409,
          412,
          4018,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.3609793289847996,
        "compression_ratio": 1.44,
        "end": 6247.52,
        "id": 1878,
        "no_speech_prob": 0.11594700068235397,
        "seek": 623864,
        "start": 6238.64,
        "temperature": 0,
        "text": " I need to say if the, if, what's it called?",
        "tokens": [
          50364,
          286,
          643,
          281,
          584,
          498,
          264,
          11,
          498,
          11,
          437,
          311,
          309,
          1219,
          30,
          50808
        ]
      },
      {
        "avg_logprob": -0.3609793289847996,
        "compression_ratio": 1.44,
        "end": 6249.360000000001,
        "id": 1879,
        "no_speech_prob": 0.11594700068235397,
        "seek": 623864,
        "start": 6247.52,
        "temperature": 0,
        "text": " Additional, pause.",
        "tokens": [
          50808,
          44272,
          11,
          10465,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.3609793289847996,
        "compression_ratio": 1.44,
        "end": 6263.68,
        "id": 1880,
        "no_speech_prob": 0.11594700068235397,
        "seek": 623864,
        "start": 6254.400000000001,
        "temperature": 0,
        "text": " My two word lists are called words, my two word lists are called words and aphan.",
        "tokens": [
          51152,
          1222,
          732,
          1349,
          14511,
          366,
          1219,
          2283,
          11,
          452,
          732,
          1349,
          14511,
          366,
          1219,
          2283,
          293,
          257,
          950,
          282,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.21722636904035295,
        "compression_ratio": 1.6598639455782314,
        "end": 6272.240000000001,
        "id": 1881,
        "no_speech_prob": 0.0020829588174819946,
        "seek": 626368,
        "start": 6264.240000000001,
        "temperature": 0,
        "text": " So what I want to do here is do if, if words, oh boy, I should call this, I need to call",
        "tokens": [
          50392,
          407,
          437,
          286,
          528,
          281,
          360,
          510,
          307,
          360,
          498,
          11,
          498,
          2283,
          11,
          1954,
          3237,
          11,
          286,
          820,
          818,
          341,
          11,
          286,
          643,
          281,
          818,
          50792
        ]
      },
      {
        "avg_logprob": -0.21722636904035295,
        "compression_ratio": 1.6598639455782314,
        "end": 6274,
        "id": 1882,
        "no_speech_prob": 0.0020829588174819946,
        "seek": 626368,
        "start": 6272.240000000001,
        "temperature": 0,
        "text": " this additional.",
        "tokens": [
          50792,
          341,
          4497,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.21722636904035295,
        "compression_ratio": 1.6598639455782314,
        "end": 6277.92,
        "id": 1883,
        "no_speech_prob": 0.0020829588174819946,
        "seek": 626368,
        "start": 6275.76,
        "temperature": 0,
        "text": " So because that's going to be a problem.",
        "tokens": [
          50968,
          407,
          570,
          300,
          311,
          516,
          281,
          312,
          257,
          1154,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.21722636904035295,
        "compression_ratio": 1.6598639455782314,
        "end": 6290.64,
        "id": 1884,
        "no_speech_prob": 0.0020829588174819946,
        "seek": 626368,
        "start": 6277.92,
        "temperature": 0,
        "text": " Let's look everywhere I use words because additional, additional, additional, oh boy,",
        "tokens": [
          51076,
          961,
          311,
          574,
          5315,
          286,
          764,
          2283,
          570,
          4497,
          11,
          4497,
          11,
          4497,
          11,
          1954,
          3237,
          11,
          51712
        ]
      },
      {
        "avg_logprob": -0.21722636904035295,
        "compression_ratio": 1.6598639455782314,
        "end": 6292.08,
        "id": 1885,
        "no_speech_prob": 0.0020829588174819946,
        "seek": 626368,
        "start": 6291.360000000001,
        "temperature": 0,
        "text": " additional.",
        "tokens": [
          51748,
          4497,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.24282640026461694,
        "compression_ratio": 1.4935897435897436,
        "end": 6295.36,
        "id": 1886,
        "no_speech_prob": 0.00006814861262682825,
        "seek": 629208,
        "start": 6292.08,
        "temperature": 0,
        "text": " Okay, I just don't want to confuse my variable names.",
        "tokens": [
          50364,
          1033,
          11,
          286,
          445,
          500,
          380,
          528,
          281,
          28584,
          452,
          7006,
          5288,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.24282640026461694,
        "compression_ratio": 1.4935897435897436,
        "end": 6301.92,
        "id": 1887,
        "no_speech_prob": 0.00006814861262682825,
        "seek": 629208,
        "start": 6298,
        "temperature": 0,
        "text": " So here I should just call that tokens that I wouldn't have that problem.",
        "tokens": [
          50660,
          407,
          510,
          286,
          820,
          445,
          818,
          300,
          22667,
          300,
          286,
          2759,
          380,
          362,
          300,
          1154,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.24282640026461694,
        "compression_ratio": 1.4935897435897436,
        "end": 6305.76,
        "id": 1888,
        "no_speech_prob": 0.00006814861262682825,
        "seek": 629208,
        "start": 6301.92,
        "temperature": 0,
        "text": " But if additional has own property.",
        "tokens": [
          50856,
          583,
          498,
          4497,
          575,
          1065,
          4707,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.24282640026461694,
        "compression_ratio": 1.4935897435897436,
        "end": 6313.68,
        "id": 1889,
        "no_speech_prob": 0.00006814861262682825,
        "seek": 629208,
        "start": 6307.28,
        "temperature": 0,
        "text": " And I want to see if word equals words index I has own property word.",
        "tokens": [
          51124,
          400,
          286,
          528,
          281,
          536,
          498,
          1349,
          6915,
          2283,
          8186,
          286,
          575,
          1065,
          4707,
          1349,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6317.4400000000005,
        "id": 1890,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6313.92,
        "temperature": 0,
        "text": " Then total score plus equal additional.",
        "tokens": [
          50376,
          1396,
          3217,
          6175,
          1804,
          2681,
          4497,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6322.16,
        "id": 1891,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6319.4400000000005,
        "temperature": 0,
        "text": " That word, the value and a number.",
        "tokens": [
          50652,
          663,
          1349,
          11,
          264,
          2158,
          293,
          257,
          1230,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6323.200000000001,
        "id": 1892,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6322.16,
        "temperature": 0,
        "text": " I'm doing this kind of fast.",
        "tokens": [
          50788,
          286,
          478,
          884,
          341,
          733,
          295,
          2370,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6324.64,
        "id": 1893,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6323.200000000001,
        "temperature": 0,
        "text": " I should reference you.",
        "tokens": [
          50840,
          286,
          820,
          6408,
          291,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6329.76,
        "id": 1894,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6324.64,
        "temperature": 0,
        "text": " I did this exact sentiment analysis entirely in a separate coding challenge, which I went",
        "tokens": [
          50912,
          286,
          630,
          341,
          1900,
          16149,
          5215,
          7696,
          294,
          257,
          4994,
          17720,
          3430,
          11,
          597,
          286,
          1437,
          51168
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6330.96,
        "id": 1895,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6329.76,
        "temperature": 0,
        "text": " through in a little more detail.",
        "tokens": [
          51168,
          807,
          294,
          257,
          707,
          544,
          2607,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.37544015166047334,
        "compression_ratio": 1.4659685863874345,
        "end": 6333.280000000001,
        "id": 1896,
        "no_speech_prob": 0.07585516571998596,
        "seek": 631368,
        "start": 6331.76,
        "temperature": 0,
        "text": " So I can check if it's there.",
        "tokens": [
          51268,
          407,
          286,
          393,
          1520,
          498,
          309,
          311,
          456,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2053290907158909,
        "compression_ratio": 1.6875,
        "end": 6334.719999999999,
        "id": 1897,
        "no_speech_prob": 0.10818427056074142,
        "seek": 633328,
        "start": 6333.36,
        "temperature": 0,
        "text": " So I can check if it's there.",
        "tokens": [
          50368,
          407,
          286,
          393,
          1520,
          498,
          309,
          311,
          456,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.2053290907158909,
        "compression_ratio": 1.6875,
        "end": 6337.44,
        "id": 1898,
        "no_speech_prob": 0.10818427056074142,
        "seek": 633328,
        "start": 6336.32,
        "temperature": 0,
        "text": " If it's not there.",
        "tokens": [
          50516,
          759,
          309,
          311,
          406,
          456,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2053290907158909,
        "compression_ratio": 1.6875,
        "end": 6345.759999999999,
        "id": 1899,
        "no_speech_prob": 0.10818427056074142,
        "seek": 633328,
        "start": 6340.4,
        "temperature": 0,
        "text": " Then I should also check if it is in the aphan list.",
        "tokens": [
          50720,
          1396,
          286,
          820,
          611,
          1520,
          498,
          309,
          307,
          294,
          264,
          257,
          950,
          282,
          1329,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.2053290907158909,
        "compression_ratio": 1.6875,
        "end": 6353.12,
        "id": 1900,
        "no_speech_prob": 0.10818427056074142,
        "seek": 633328,
        "start": 6349.12,
        "temperature": 0,
        "text": " And if it's in either one of those, I also let's get make a word list.",
        "tokens": [
          51156,
          400,
          498,
          309,
          311,
          294,
          2139,
          472,
          295,
          729,
          11,
          286,
          611,
          718,
          311,
          483,
          652,
          257,
          1349,
          1329,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.2053290907158909,
        "compression_ratio": 1.6875,
        "end": 6359.2,
        "id": 1901,
        "no_speech_prob": 0.10818427056074142,
        "seek": 633328,
        "start": 6357.36,
        "temperature": 0,
        "text": " We'll just make it a word list.",
        "tokens": [
          51568,
          492,
          603,
          445,
          652,
          309,
          257,
          1349,
          1329,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.2053290907158909,
        "compression_ratio": 1.6875,
        "end": 6362.96,
        "id": 1902,
        "no_speech_prob": 0.10818427056074142,
        "seek": 633328,
        "start": 6360.16,
        "temperature": 0,
        "text": " So we'll actually make it a word list.",
        "tokens": [
          51708,
          407,
          321,
          603,
          767,
          652,
          309,
          257,
          1349,
          1329,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.36392860981955455,
        "compression_ratio": 1.4532374100719425,
        "end": 6363.68,
        "id": 1903,
        "no_speech_prob": 0.00041731316014193,
        "seek": 636296,
        "start": 6363.2,
        "temperature": 0,
        "text": " An array.",
        "tokens": [
          50376,
          1107,
          10225,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.36392860981955455,
        "compression_ratio": 1.4532374100719425,
        "end": 6373.36,
        "id": 1904,
        "no_speech_prob": 0.00041731316014193,
        "seek": 636296,
        "start": 6364.32,
        "temperature": 0,
        "text": " I could say in either of these cases, word list dot push an object that has word, word,",
        "tokens": [
          50432,
          286,
          727,
          584,
          294,
          2139,
          295,
          613,
          3331,
          11,
          1349,
          1329,
          5893,
          2944,
          364,
          2657,
          300,
          575,
          1349,
          11,
          1349,
          11,
          50884
        ]
      },
      {
        "avg_logprob": -0.36392860981955455,
        "compression_ratio": 1.4532374100719425,
        "end": 6378.08,
        "id": 1905,
        "no_speech_prob": 0.00041731316014193,
        "seek": 636296,
        "start": 6373.92,
        "temperature": 0,
        "text": " score, and then and the score is var.",
        "tokens": [
          50912,
          6175,
          11,
          293,
          550,
          293,
          264,
          6175,
          307,
          1374,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.36392860981955455,
        "compression_ratio": 1.4532374100719425,
        "end": 6379.2,
        "id": 1906,
        "no_speech_prob": 0.00041731316014193,
        "seek": 636296,
        "start": 6378.08,
        "temperature": 0,
        "text": " The score is.",
        "tokens": [
          51120,
          440,
          6175,
          307,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.36392860981955455,
        "compression_ratio": 1.4532374100719425,
        "end": 6385.12,
        "id": 1907,
        "no_speech_prob": 0.00041731316014193,
        "seek": 636296,
        "start": 6381.36,
        "temperature": 0,
        "text": " I can say var score if it's in additional.",
        "tokens": [
          51284,
          286,
          393,
          584,
          1374,
          6175,
          498,
          309,
          311,
          294,
          4497,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.36392860981955455,
        "compression_ratio": 1.4532374100719425,
        "end": 6385.6,
        "id": 1908,
        "no_speech_prob": 0.00041731316014193,
        "seek": 636296,
        "start": 6385.12,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51472,
          876,
          11,
          1338,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.559384507952996,
        "compression_ratio": 1.3252032520325203,
        "end": 6391.84,
        "id": 1909,
        "no_speech_prob": 0.010818288661539555,
        "seek": 638560,
        "start": 6386.240000000001,
        "temperature": 0,
        "text": " Score equals number additional and then add that.",
        "tokens": [
          50396,
          47901,
          6915,
          1230,
          4497,
          293,
          550,
          909,
          300,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.559384507952996,
        "compression_ratio": 1.3252032520325203,
        "end": 6396,
        "id": 1910,
        "no_speech_prob": 0.010818288661539555,
        "seek": 638560,
        "start": 6393.84,
        "temperature": 0,
        "text": " This is not interesting to watch anymore.",
        "tokens": [
          50776,
          639,
          307,
          406,
          1880,
          281,
          1159,
          3602,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.559384507952996,
        "compression_ratio": 1.3252032520325203,
        "end": 6401.200000000001,
        "id": 1911,
        "no_speech_prob": 0.010818288661539555,
        "seek": 638560,
        "start": 6396.96,
        "temperature": 0,
        "text": " And otherwise, if it's in aphan.",
        "tokens": [
          50932,
          400,
          5911,
          11,
          498,
          309,
          311,
          294,
          257,
          950,
          282,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.559384507952996,
        "compression_ratio": 1.3252032520325203,
        "end": 6404.08,
        "id": 1912,
        "no_speech_prob": 0.010818288661539555,
        "seek": 638560,
        "start": 6403.04,
        "temperature": 0,
        "text": " That's the score.",
        "tokens": [
          51236,
          663,
          311,
          264,
          6175,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.559384507952996,
        "compression_ratio": 1.3252032520325203,
        "end": 6405.860000000001,
        "id": 1913,
        "no_speech_prob": 0.010818288661539555,
        "seek": 638560,
        "start": 6405.360000000001,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51352,
          400,
          13,
          51377
        ]
      },
      {
        "avg_logprob": -0.559384507952996,
        "compression_ratio": 1.3252032520325203,
        "end": 6412.8,
        "id": 1914,
        "no_speech_prob": 0.010818288661539555,
        "seek": 638560,
        "start": 6410.88,
        "temperature": 0,
        "text": " And then sorry.",
        "tokens": [
          51628,
          400,
          550,
          2597,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6417.68,
        "id": 1915,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6413.52,
        "temperature": 0,
        "text": " If I and so.",
        "tokens": [
          50400,
          759,
          286,
          293,
          370,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6419.84,
        "id": 1916,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6419.28,
        "temperature": 0,
        "text": " Number.",
        "tokens": [
          50688,
          5118,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6424.8,
        "id": 1917,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6419.84,
        "temperature": 0,
        "text": " OK, so I'm just cleaning this up because now I can say total score plus equal.",
        "tokens": [
          50716,
          2264,
          11,
          370,
          286,
          478,
          445,
          8924,
          341,
          493,
          570,
          586,
          286,
          393,
          584,
          3217,
          6175,
          1804,
          2681,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6427.52,
        "id": 1918,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6426,
        "temperature": 0,
        "text": " Plus equal the score.",
        "tokens": [
          51024,
          7721,
          2681,
          264,
          6175,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6431.52,
        "id": 1919,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6427.52,
        "temperature": 0,
        "text": " So the score can start for every word can be assumed to be zero.",
        "tokens": [
          51100,
          407,
          264,
          6175,
          393,
          722,
          337,
          633,
          1349,
          393,
          312,
          15895,
          281,
          312,
          4018,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6435.6,
        "id": 1920,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6432.08,
        "temperature": 0,
        "text": " And if it's in additional, add the score.",
        "tokens": [
          51328,
          400,
          498,
          309,
          311,
          294,
          4497,
          11,
          909,
          264,
          6175,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6439.12,
        "id": 1921,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6436.56,
        "temperature": 0,
        "text": " You know, actually, so I don't need this here anymore.",
        "tokens": [
          51552,
          509,
          458,
          11,
          767,
          11,
          370,
          286,
          500,
          380,
          643,
          341,
          510,
          3602,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2369415283203125,
        "compression_ratio": 1.5621890547263682,
        "end": 6440.8,
        "id": 1922,
        "no_speech_prob": 0.0002868520678021014,
        "seek": 641280,
        "start": 6439.12,
        "temperature": 0,
        "text": " Get the score from additional.",
        "tokens": [
          51680,
          3240,
          264,
          6175,
          490,
          4497,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6443.6,
        "id": 1923,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6440.8,
        "temperature": 0,
        "text": " If it's in aphan, get the score from aphan.",
        "tokens": [
          50364,
          759,
          309,
          311,
          294,
          257,
          950,
          282,
          11,
          483,
          264,
          6175,
          490,
          257,
          950,
          282,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6446.400000000001,
        "id": 1924,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6443.6,
        "temperature": 0,
        "text": " And now what I could do, let's just get this working.",
        "tokens": [
          50504,
          400,
          586,
          437,
          286,
          727,
          360,
          11,
          718,
          311,
          445,
          483,
          341,
          1364,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6448.8,
        "id": 1925,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6446.400000000001,
        "temperature": 0,
        "text": " I could say reply is score.",
        "tokens": [
          50644,
          286,
          727,
          584,
          16972,
          307,
          6175,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6451.6,
        "id": 1926,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6450.8,
        "temperature": 0,
        "text": " Total score.",
        "tokens": [
          50864,
          23170,
          6175,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6455.52,
        "id": 1927,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6454.4800000000005,
        "temperature": 0,
        "text": " And comparative.",
        "tokens": [
          51048,
          400,
          39292,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6458.64,
        "id": 1928,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6457.92,
        "temperature": 0,
        "text": " Comparative.",
        "tokens": [
          51220,
          2432,
          2181,
          1166,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6460.88,
        "id": 1929,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6459.92,
        "temperature": 0,
        "text": " Comparative.",
        "tokens": [
          51320,
          2432,
          2181,
          1166,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.26378072694290516,
        "compression_ratio": 1.6666666666666667,
        "end": 6466.72,
        "id": 1930,
        "no_speech_prob": 0.00004611264375853352,
        "seek": 644080,
        "start": 6461.68,
        "temperature": 0,
        "text": " Comparative in the aphan one eleven sentiment analysis, the comparative value.",
        "tokens": [
          51408,
          2432,
          2181,
          1166,
          294,
          264,
          257,
          950,
          282,
          472,
          21090,
          16149,
          5215,
          11,
          264,
          39292,
          2158,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6468.96,
        "id": 1931,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6467.68,
        "temperature": 0,
        "text": " Is the total score.",
        "tokens": [
          50412,
          1119,
          264,
          3217,
          6175,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6473.84,
        "id": 1932,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6470.240000000001,
        "temperature": 0,
        "text": " Divided by how many words are in the text words dot link.",
        "tokens": [
          50540,
          413,
          1843,
          292,
          538,
          577,
          867,
          2283,
          366,
          294,
          264,
          2487,
          2283,
          5893,
          2113,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6477.92,
        "id": 1933,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6474.96,
        "temperature": 0,
        "text": " So now we should see that I'm getting the text.",
        "tokens": [
          50776,
          407,
          586,
          321,
          820,
          536,
          300,
          286,
          478,
          1242,
          264,
          2487,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6483.360000000001,
        "id": 1934,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6478.64,
        "temperature": 0,
        "text": " So my server is now receiving the text as the post request chopping up into words,",
        "tokens": [
          50960,
          407,
          452,
          7154,
          307,
          586,
          10040,
          264,
          2487,
          382,
          264,
          2183,
          5308,
          35205,
          493,
          666,
          2283,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6487.76,
        "id": 1935,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6483.360000000001,
        "temperature": 0,
        "text": " looking at every single word, seeing if it's in one of the lists and then spitting back.",
        "tokens": [
          51196,
          1237,
          412,
          633,
          2167,
          1349,
          11,
          2577,
          498,
          309,
          311,
          294,
          472,
          295,
          264,
          14511,
          293,
          550,
          637,
          2414,
          646,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6490.4800000000005,
        "id": 1936,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6488.8,
        "temperature": 0,
        "text": " So let's run this.",
        "tokens": [
          51468,
          407,
          718,
          311,
          1190,
          341,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6494.08,
        "id": 1937,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6492.320000000001,
        "temperature": 0,
        "text": " Oh, I need to restart the server.",
        "tokens": [
          51644,
          876,
          11,
          286,
          643,
          281,
          21022,
          264,
          7154,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.25418337041681466,
        "compression_ratio": 1.6415929203539823,
        "end": 6495.52,
        "id": 1938,
        "no_speech_prob": 0.000552775920368731,
        "seek": 646672,
        "start": 6494.64,
        "temperature": 0,
        "text": " Oh, I have an error.",
        "tokens": [
          51760,
          876,
          11,
          286,
          362,
          364,
          6713,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6501.040000000001,
        "id": 1939,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6495.6,
        "temperature": 0,
        "text": " Words is not defined where in line number six, which is here.",
        "tokens": [
          50368,
          32857,
          307,
          406,
          7642,
          689,
          294,
          1622,
          1230,
          2309,
          11,
          597,
          307,
          510,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6504.400000000001,
        "id": 1940,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6501.6,
        "temperature": 0,
        "text": " I don't actually need this console log was just for debugging earlier.",
        "tokens": [
          50668,
          286,
          500,
          380,
          767,
          643,
          341,
          11076,
          3565,
          390,
          445,
          337,
          45592,
          3071,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6508.88,
        "id": 1941,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6506.96,
        "temperature": 0,
        "text": " So let's run the server again.",
        "tokens": [
          50936,
          407,
          718,
          311,
          1190,
          264,
          7154,
          797,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6514.240000000001,
        "id": 1942,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6511.280000000001,
        "temperature": 0,
        "text": " Refresh and hit analyze.",
        "tokens": [
          51152,
          16957,
          3644,
          293,
          2045,
          12477,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6515.76,
        "id": 1943,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6514.240000000001,
        "temperature": 0,
        "text": " And we got an error.",
        "tokens": [
          51300,
          400,
          321,
          658,
          364,
          6713,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6517.4400000000005,
        "id": 1944,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6517.040000000001,
        "temperature": 0,
        "text": " False.",
        "tokens": [
          51440,
          50040,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6518.4800000000005,
        "id": 1945,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6517.4400000000005,
        "temperature": 0,
        "text": " I got some error.",
        "tokens": [
          51460,
          286,
          658,
          512,
          6713,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6519.6,
        "id": 1946,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6519.040000000001,
        "temperature": 0,
        "text": " So what happened?",
        "tokens": [
          51540,
          407,
          437,
          2011,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6521.120000000001,
        "id": 1947,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6519.6,
        "temperature": 0,
        "text": " Let's look at the console.",
        "tokens": [
          51568,
          961,
          311,
          574,
          412,
          264,
          11076,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6522.080000000001,
        "id": 1948,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6521.120000000001,
        "temperature": 0,
        "text": " Oh, yeah, I got an error.",
        "tokens": [
          51644,
          876,
          11,
          1338,
          11,
          286,
          658,
          364,
          6713,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.18378965137074293,
        "compression_ratio": 1.5092592592592593,
        "end": 6524.56,
        "id": 1949,
        "no_speech_prob": 0.0009399356204085052,
        "seek": 649552,
        "start": 6523.360000000001,
        "temperature": 0,
        "text": " Comp is not defined.",
        "tokens": [
          51756,
          6620,
          307,
          406,
          7642,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6530.72,
        "id": 1950,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6526.080000000001,
        "temperature": 0,
        "text": " So I made a mistake because I'm trying to do this so quickly and I'm not being careful.",
        "tokens": [
          50392,
          407,
          286,
          1027,
          257,
          6146,
          570,
          286,
          478,
          1382,
          281,
          360,
          341,
          370,
          2661,
          293,
          286,
          478,
          406,
          885,
          5026,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6533.92,
        "id": 1951,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6530.72,
        "temperature": 0,
        "text": " And where is where I have lost where the code this is.",
        "tokens": [
          50624,
          400,
          689,
          307,
          689,
          286,
          362,
          2731,
          689,
          264,
          3089,
          341,
          307,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6535.76,
        "id": 1952,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6533.92,
        "temperature": 0,
        "text": " Oh, comp.",
        "tokens": [
          50784,
          876,
          11,
          715,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6538,
        "id": 1953,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6536.8,
        "temperature": 0,
        "text": " Oh, wait, comp.",
        "tokens": [
          50928,
          876,
          11,
          1699,
          11,
          715,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6540.88,
        "id": 1954,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6539.4400000000005,
        "temperature": 0,
        "text": " And then this could be comparative.",
        "tokens": [
          51060,
          400,
          550,
          341,
          727,
          312,
          39292,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6543.4400000000005,
        "id": 1955,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6541.52,
        "temperature": 0,
        "text": " I'm just not naming things carefully.",
        "tokens": [
          51164,
          286,
          478,
          445,
          406,
          25290,
          721,
          7500,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6545.280000000001,
        "id": 1956,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6543.4400000000005,
        "temperature": 0,
        "text": " So this is the reply that I want to send back.",
        "tokens": [
          51260,
          407,
          341,
          307,
          264,
          16972,
          300,
          286,
          528,
          281,
          2845,
          646,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.22224819537290594,
        "compression_ratio": 1.6009852216748768,
        "end": 6550.96,
        "id": 1957,
        "no_speech_prob": 0.00007141788228182122,
        "seek": 652552,
        "start": 6549.52,
        "temperature": 0,
        "text": " Oops, I have to restart the server.",
        "tokens": [
          51564,
          21726,
          11,
          286,
          362,
          281,
          21022,
          264,
          7154,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6556.4800000000005,
        "id": 1958,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6555.68,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50372,
          821,
          321,
          352,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6557.6,
        "id": 1959,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6556.4800000000005,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          50412,
          400,
          574,
          412,
          341,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6561.360000000001,
        "id": 1960,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6557.6,
        "temperature": 0,
        "text": " Every time I analyze, I get both the comparative score and the score.",
        "tokens": [
          50468,
          2048,
          565,
          286,
          12477,
          11,
          286,
          483,
          1293,
          264,
          39292,
          6175,
          293,
          264,
          6175,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6563.6,
        "id": 1961,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6561.360000000001,
        "temperature": 0,
        "text": " Now, I really want to also send back a list of words.",
        "tokens": [
          50656,
          823,
          11,
          286,
          534,
          528,
          281,
          611,
          2845,
          646,
          257,
          1329,
          295,
          2283,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6565.6,
        "id": 1962,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6563.6,
        "temperature": 0,
        "text": " And I want this to be an exercise.",
        "tokens": [
          50768,
          400,
          286,
          528,
          341,
          281,
          312,
          364,
          5380,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6567.68,
        "id": 1963,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6565.6,
        "temperature": 0,
        "text": " I'm going to do it anyway because I want to see it here.",
        "tokens": [
          50868,
          286,
          478,
          516,
          281,
          360,
          309,
          4033,
          570,
          286,
          528,
          281,
          536,
          309,
          510,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6573.360000000001,
        "id": 1964,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6567.68,
        "temperature": 0,
        "text": " So what I'm going to do is I am going to also say I'm going to make a variable called found.",
        "tokens": [
          50972,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          669,
          516,
          281,
          611,
          584,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          1352,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6580.240000000001,
        "id": 1965,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6573.92,
        "temperature": 0,
        "text": " Just add into an I'm going to make an array of objects with word, word, score, score,",
        "tokens": [
          51284,
          1449,
          909,
          666,
          364,
          286,
          478,
          516,
          281,
          652,
          364,
          10225,
          295,
          6565,
          365,
          1349,
          11,
          1349,
          11,
          6175,
          11,
          6175,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.17968731495871473,
        "compression_ratio": 1.7318007662835249,
        "end": 6581.52,
        "id": 1966,
        "no_speech_prob": 0.0005274697905406356,
        "seek": 655552,
        "start": 6580.240000000001,
        "temperature": 0,
        "text": " which is a little awkward.",
        "tokens": [
          51600,
          597,
          307,
          257,
          707,
          11411,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2059095533270585,
        "compression_ratio": 1.502857142857143,
        "end": 6588.160000000001,
        "id": 1967,
        "no_speech_prob": 0.0014550553169101477,
        "seek": 658152,
        "start": 6581.52,
        "temperature": 0,
        "text": " But now what I can do is I can also send back the list of words.",
        "tokens": [
          50364,
          583,
          586,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          611,
          2845,
          646,
          264,
          1329,
          295,
          2283,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.2059095533270585,
        "compression_ratio": 1.502857142857143,
        "end": 6594.4800000000005,
        "id": 1968,
        "no_speech_prob": 0.0014550553169101477,
        "seek": 658152,
        "start": 6589.92,
        "temperature": 0,
        "text": " So I'm just saving every word and its score if it was found in one of those lists.",
        "tokens": [
          50784,
          407,
          286,
          478,
          445,
          6816,
          633,
          1349,
          293,
          1080,
          6175,
          498,
          309,
          390,
          1352,
          294,
          472,
          295,
          729,
          14511,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.2059095533270585,
        "compression_ratio": 1.502857142857143,
        "end": 6601.4400000000005,
        "id": 1969,
        "no_speech_prob": 0.0014550553169101477,
        "seek": 658152,
        "start": 6594.4800000000005,
        "temperature": 0,
        "text": " Because now if I run this again and it hits analyze array zero.",
        "tokens": [
          51012,
          1436,
          586,
          498,
          286,
          1190,
          341,
          797,
          293,
          309,
          8664,
          12477,
          10225,
          4018,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.2059095533270585,
        "compression_ratio": 1.502857142857143,
        "end": 6603.040000000001,
        "id": 1970,
        "no_speech_prob": 0.0014550553169101477,
        "seek": 658152,
        "start": 6601.4400000000005,
        "temperature": 0,
        "text": " So I did something wrong.",
        "tokens": [
          51360,
          407,
          286,
          630,
          746,
          2085,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2059095533270585,
        "compression_ratio": 1.502857142857143,
        "end": 6604.240000000001,
        "id": 1971,
        "no_speech_prob": 0.0014550553169101477,
        "seek": 658152,
        "start": 6603.040000000001,
        "temperature": 0,
        "text": " Let's look at this again.",
        "tokens": [
          51440,
          961,
          311,
          574,
          412,
          341,
          797,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6605.2,
        "id": 1972,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6604.4,
        "temperature": 0,
        "text": " Found is false.",
        "tokens": [
          50372,
          8207,
          307,
          7908,
          13,
          50412
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6609.36,
        "id": 1973,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6605.2,
        "temperature": 0,
        "text": " If found, word list dot push.",
        "tokens": [
          50412,
          759,
          1352,
          11,
          1349,
          1329,
          5893,
          2944,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6616.8,
        "id": 1974,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6613.36,
        "temperature": 0,
        "text": " So why would the list have nothing in it?",
        "tokens": [
          50820,
          407,
          983,
          576,
          264,
          1329,
          362,
          1825,
          294,
          309,
          30,
          50992
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6623.599999999999,
        "id": 1975,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6622.8,
        "temperature": 0,
        "text": " Edit this part out.",
        "tokens": [
          51292,
          33241,
          341,
          644,
          484,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6624.4,
        "id": 1976,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6623.599999999999,
        "temperature": 0,
        "text": " La la la la la.",
        "tokens": [
          51332,
          2369,
          635,
          635,
          635,
          635,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6625.599999999999,
        "id": 1977,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6624.4,
        "temperature": 0,
        "text": " Thinking, thinking, thinking.",
        "tokens": [
          51372,
          24460,
          11,
          1953,
          11,
          1953,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6627.28,
        "id": 1978,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6626.24,
        "temperature": 0,
        "text": " Word list push.",
        "tokens": [
          51464,
          8725,
          1329,
          2944,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6630,
        "id": 1979,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6627.84,
        "temperature": 0,
        "text": " I made a word list with an empty.",
        "tokens": [
          51544,
          286,
          1027,
          257,
          1349,
          1329,
          365,
          364,
          6707,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.5641920453026181,
        "compression_ratio": 1.51875,
        "end": 6632.24,
        "id": 1980,
        "no_speech_prob": 0.09008606523275375,
        "seek": 660424,
        "start": 6630,
        "temperature": 0,
        "text": " And then I say if it's in there, found.",
        "tokens": [
          51652,
          400,
          550,
          286,
          584,
          498,
          309,
          311,
          294,
          456,
          11,
          1352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6634.08,
        "id": 1981,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6632.24,
        "temperature": 0,
        "text": " I say if it's in there, found.",
        "tokens": [
          50364,
          286,
          584,
          498,
          309,
          311,
          294,
          456,
          11,
          1352,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6636.5599999999995,
        "id": 1982,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6634.08,
        "temperature": 0,
        "text": " If it's in there, found.",
        "tokens": [
          50456,
          759,
          309,
          311,
          294,
          456,
          11,
          1352,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6638.719999999999,
        "id": 1983,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6636.5599999999995,
        "temperature": 0,
        "text": " If found, push it in the list.",
        "tokens": [
          50580,
          759,
          1352,
          11,
          2944,
          309,
          294,
          264,
          1329,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6639.36,
        "id": 1984,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6638.719999999999,
        "temperature": 0,
        "text": " All right, well, let's.",
        "tokens": [
          50688,
          1057,
          558,
          11,
          731,
          11,
          718,
          311,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6643.2,
        "id": 1985,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6641.76,
        "temperature": 0,
        "text": " Oh, whoa.",
        "tokens": [
          50840,
          876,
          11,
          13310,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6645.12,
        "id": 1986,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6643.84,
        "temperature": 0,
        "text": " The word list has to be out here.",
        "tokens": [
          50944,
          440,
          1349,
          1329,
          575,
          281,
          312,
          484,
          510,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6646.5599999999995,
        "id": 1987,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6645.12,
        "temperature": 0,
        "text": " I initialized the array.",
        "tokens": [
          51008,
          286,
          5883,
          1602,
          264,
          10225,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6649.12,
        "id": 1988,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6646.5599999999995,
        "temperature": 0,
        "text": " Oh, I reinitialized the array in there.",
        "tokens": [
          51080,
          876,
          11,
          286,
          6561,
          270,
          831,
          1602,
          264,
          10225,
          294,
          456,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6649.5199999999995,
        "id": 1989,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6649.12,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51208,
          6962,
          322,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6654.08,
        "id": 1990,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6653.599999999999,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51432,
          45263,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6656.8,
        "id": 1991,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6654.08,
        "temperature": 0,
        "text": " I initialized the array in the loop, which means I kept clearing it out.",
        "tokens": [
          51456,
          286,
          5883,
          1602,
          264,
          10225,
          294,
          264,
          6367,
          11,
          597,
          1355,
          286,
          4305,
          23937,
          309,
          484,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6658.5599999999995,
        "id": 1992,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6656.8,
        "temperature": 0,
        "text": " So of course, there's nothing in the array.",
        "tokens": [
          51592,
          407,
          295,
          1164,
          11,
          456,
          311,
          1825,
          294,
          264,
          10225,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.23591304892924295,
        "compression_ratio": 1.8229665071770336,
        "end": 6659.76,
        "id": 1993,
        "no_speech_prob": 0.0010004994692280889,
        "seek": 663224,
        "start": 6658.5599999999995,
        "temperature": 0,
        "text": " Let me take that out there.",
        "tokens": [
          51680,
          961,
          385,
          747,
          300,
          484,
          456,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6660.96,
        "id": 1994,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6660.16,
        "temperature": 0,
        "text": " Run this again.",
        "tokens": [
          50384,
          8950,
          341,
          797,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6662.08,
        "id": 1995,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6661.52,
        "temperature": 0,
        "text": " Refresh.",
        "tokens": [
          50452,
          16957,
          3644,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6663.280000000001,
        "id": 1996,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6662.64,
        "temperature": 0,
        "text": " Analyze.",
        "tokens": [
          50508,
          1107,
          5222,
          1381,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6667.280000000001,
        "id": 1997,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6663.280000000001,
        "temperature": 0,
        "text": " And now we can see this is what it got.",
        "tokens": [
          50540,
          400,
          586,
          321,
          393,
          536,
          341,
          307,
          437,
          309,
          658,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6668.56,
        "id": 1998,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6667.280000000001,
        "temperature": 0,
        "text": " This is the comparative.",
        "tokens": [
          50740,
          639,
          307,
          264,
          39292,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6670.24,
        "id": 1999,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6668.56,
        "temperature": 0,
        "text": " Oh, this is very small for you to read.",
        "tokens": [
          50804,
          876,
          11,
          341,
          307,
          588,
          1359,
          337,
          291,
          281,
          1401,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6672.8,
        "id": 2000,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6672.24,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50988,
          45263,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6675.76,
        "id": 2001,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6673.6,
        "temperature": 0,
        "text": " You can see here that this is the comparative.",
        "tokens": [
          51056,
          509,
          393,
          536,
          510,
          300,
          341,
          307,
          264,
          39292,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6676.96,
        "id": 2002,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6675.76,
        "temperature": 0,
        "text": " That's the score.",
        "tokens": [
          51164,
          663,
          311,
          264,
          6175,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6678.72,
        "id": 2003,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6676.96,
        "temperature": 0,
        "text": " And this is the list, happy and rainbow.",
        "tokens": [
          51224,
          400,
          341,
          307,
          264,
          1329,
          11,
          2055,
          293,
          18526,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6682.16,
        "id": 2004,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6678.72,
        "temperature": 0,
        "text": " So what I could say is, hmm, why didn't it get kittens?",
        "tokens": [
          51312,
          407,
          437,
          286,
          727,
          584,
          307,
          11,
          16478,
          11,
          983,
          994,
          380,
          309,
          483,
          47363,
          30,
          51484
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6684.8,
        "id": 2005,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6682.16,
        "temperature": 0,
        "text": " So what I would like to do is add kittens.",
        "tokens": [
          51484,
          407,
          437,
          286,
          576,
          411,
          281,
          360,
          307,
          909,
          47363,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6686.400000000001,
        "id": 2006,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6684.8,
        "temperature": 0,
        "text": " And kittens should have a score of four.",
        "tokens": [
          51616,
          400,
          47363,
          820,
          362,
          257,
          6175,
          295,
          1451,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.32787862505231585,
        "compression_ratio": 1.7306122448979593,
        "end": 6688.320000000001,
        "id": 2007,
        "no_speech_prob": 0.0002737209724728018,
        "seek": 665976,
        "start": 6687.04,
        "temperature": 0,
        "text": " So I'm now going to hit submit.",
        "tokens": [
          51728,
          407,
          286,
          478,
          586,
          516,
          281,
          2045,
          10315,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6695.2,
        "id": 2008,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6688.4,
        "temperature": 0,
        "text": " And now when I analyze it again, whoops, we can see that I got a score of 14.",
        "tokens": [
          50368,
          400,
          586,
          562,
          286,
          12477,
          309,
          797,
          11,
          567,
          3370,
          11,
          321,
          393,
          536,
          300,
          286,
          658,
          257,
          6175,
          295,
          3499,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6700.16,
        "id": 2009,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6695.92,
        "temperature": 0,
        "text": " And let's say today is really positive with a number 100.",
        "tokens": [
          50744,
          400,
          718,
          311,
          584,
          965,
          307,
          534,
          3353,
          365,
          257,
          1230,
          2319,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6702.799999999999,
        "id": 2010,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6700.16,
        "temperature": 0,
        "text": " I can add that to the database and analyze again.",
        "tokens": [
          50956,
          286,
          393,
          909,
          300,
          281,
          264,
          8149,
          293,
          12477,
          797,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6705.04,
        "id": 2011,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6702.799999999999,
        "temperature": 0,
        "text": " And now I have a score of 114.",
        "tokens": [
          51088,
          400,
          586,
          286,
          362,
          257,
          6175,
          295,
          2975,
          19,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6707.04,
        "id": 2012,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6705.04,
        "temperature": 0,
        "text": " So now I have both.",
        "tokens": [
          51200,
          407,
          586,
          286,
          362,
          1293,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6709.599999999999,
        "id": 2013,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6707.04,
        "temperature": 0,
        "text": " And on one page, I have both a system.",
        "tokens": [
          51300,
          400,
          322,
          472,
          3028,
          11,
          286,
          362,
          1293,
          257,
          1185,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.27281424782492897,
        "compression_ratio": 1.6681614349775784,
        "end": 6715.04,
        "id": 2014,
        "no_speech_prob": 0.0001420233165845275,
        "seek": 668832,
        "start": 6709.599999999999,
        "temperature": 0,
        "text": " Wow, we've really finished this example, where I can submit to the database using a get request.",
        "tokens": [
          51428,
          3153,
          11,
          321,
          600,
          534,
          4335,
          341,
          1365,
          11,
          689,
          286,
          393,
          10315,
          281,
          264,
          8149,
          1228,
          257,
          483,
          5308,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6717.68,
        "id": 2015,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6715.04,
        "temperature": 0,
        "text": " I can post to have text analyzed.",
        "tokens": [
          50364,
          286,
          393,
          2183,
          281,
          362,
          2487,
          28181,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6722.16,
        "id": 2016,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6717.68,
        "temperature": 0,
        "text": " I can submit to the API with a post.",
        "tokens": [
          50496,
          286,
          393,
          10315,
          281,
          264,
          9362,
          365,
          257,
          2183,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6723.76,
        "id": 2017,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6722.16,
        "temperature": 0,
        "text": " And I can get back the results.",
        "tokens": [
          50720,
          400,
          286,
          393,
          483,
          646,
          264,
          3542,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6724.96,
        "id": 2018,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6723.76,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          50800,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6733.12,
        "id": 2019,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6724.96,
        "temperature": 0,
        "text": " As a challenge, as an exercise, take this exact code and really work on the interaction here and how this works.",
        "tokens": [
          50860,
          1018,
          257,
          3430,
          11,
          382,
          364,
          5380,
          11,
          747,
          341,
          1900,
          3089,
          293,
          534,
          589,
          322,
          264,
          9285,
          510,
          293,
          577,
          341,
          1985,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6737.6,
        "id": 2020,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6733.12,
        "temperature": 0,
        "text": " How could you actually effectively crowdsource a full word list?",
        "tokens": [
          51268,
          1012,
          727,
          291,
          767,
          8659,
          26070,
          2948,
          257,
          1577,
          1349,
          1329,
          30,
          51492
        ]
      },
      {
        "avg_logprob": -0.28709276440074144,
        "compression_ratio": 1.6566523605150214,
        "end": 6743.12,
        "id": 2021,
        "no_speech_prob": 0.0003514355921652168,
        "seek": 671504,
        "start": 6737.6,
        "temperature": 0,
        "text": " How could you use an animation or use design to show the results in the word list?",
        "tokens": [
          51492,
          1012,
          727,
          291,
          764,
          364,
          9603,
          420,
          764,
          1715,
          281,
          855,
          264,
          3542,
          294,
          264,
          1349,
          1329,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6744.16,
        "id": 2022,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6743.2,
        "temperature": 0,
        "text": " You could click on them.",
        "tokens": [
          50368,
          509,
          727,
          2052,
          322,
          552,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6746.64,
        "id": 2023,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6744.16,
        "temperature": 0,
        "text": " And what if it showed you all the words here and the ones that are missing?",
        "tokens": [
          50416,
          400,
          437,
          498,
          309,
          4712,
          291,
          439,
          264,
          2283,
          510,
          293,
          264,
          2306,
          300,
          366,
          5361,
          30,
          50540
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6748.4,
        "id": 2024,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6746.64,
        "temperature": 0,
        "text": " And it let you type them in and hit submit.",
        "tokens": [
          50540,
          400,
          309,
          718,
          291,
          2010,
          552,
          294,
          293,
          2045,
          10315,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6754.96,
        "id": 2025,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6748.4,
        "temperature": 0,
        "text": " So you could kind of like, how could you train this to have a larger database of words for more sophisticated sentiment analysis?",
        "tokens": [
          50628,
          407,
          291,
          727,
          733,
          295,
          411,
          11,
          577,
          727,
          291,
          3847,
          341,
          281,
          362,
          257,
          4833,
          8149,
          295,
          2283,
          337,
          544,
          16950,
          16149,
          5215,
          30,
          50956
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6758.16,
        "id": 2026,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6754.96,
        "temperature": 0,
        "text": " This would be, I think, a challenge for you to take this and take it further.",
        "tokens": [
          50956,
          639,
          576,
          312,
          11,
          286,
          519,
          11,
          257,
          3430,
          337,
          291,
          281,
          747,
          341,
          293,
          747,
          309,
          3052,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6759.92,
        "id": 2027,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6758.16,
        "temperature": 0,
        "text": " But this is a fully functioning API.",
        "tokens": [
          51116,
          583,
          341,
          307,
          257,
          4498,
          18483,
          9362,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6762.24,
        "id": 2028,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6759.92,
        "temperature": 0,
        "text": " There's one piece of this that I think I should mention.",
        "tokens": [
          51204,
          821,
          311,
          472,
          2522,
          295,
          341,
          300,
          286,
          519,
          286,
          820,
          2152,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.3301439020368788,
        "compression_ratio": 1.7670807453416149,
        "end": 6773.04,
        "id": 2029,
        "no_speech_prob": 0.007815618067979813,
        "seek": 674312,
        "start": 6764.24,
        "temperature": 0,
        "text": " This API can be accessed by my, so the server, the Node server, the thing running right here can be accessed by my server.",
        "tokens": [
          51420,
          639,
          9362,
          393,
          312,
          34211,
          538,
          452,
          11,
          370,
          264,
          7154,
          11,
          264,
          38640,
          7154,
          11,
          264,
          551,
          2614,
          558,
          510,
          393,
          312,
          34211,
          538,
          452,
          7154,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.5987281473273904,
        "compression_ratio": 1.8661710037174721,
        "end": 6776.72,
        "id": 2030,
        "no_speech_prob": 0.03621746972203255,
        "seek": 677312,
        "start": 6773.44,
        "temperature": 0.2,
        "text": " And I can also access it from my own web page.",
        "tokens": [
          50380,
          400,
          286,
          393,
          611,
          2105,
          309,
          490,
          452,
          1065,
          3670,
          3028,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.5987281473273904,
        "compression_ratio": 1.8661710037174721,
        "end": 6778.64,
        "id": 2031,
        "no_speech_prob": 0.03621746972203255,
        "seek": 677312,
        "start": 6776.72,
        "temperature": 0.2,
        "text": " So I can access it from my own web page.",
        "tokens": [
          50544,
          407,
          286,
          393,
          2105,
          309,
          490,
          452,
          1065,
          3670,
          3028,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.5987281473273904,
        "compression_ratio": 1.8661710037174721,
        "end": 6785.28,
        "id": 2032,
        "no_speech_prob": 0.03621746972203255,
        "seek": 677312,
        "start": 6778.64,
        "temperature": 0.2,
        "text": " And I can actually get requests by this web page because this web page is hosted on this server.",
        "tokens": [
          50640,
          400,
          286,
          393,
          767,
          483,
          12475,
          538,
          341,
          3670,
          3028,
          570,
          341,
          3670,
          3028,
          307,
          19204,
          322,
          341,
          7154,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.5987281473273904,
        "compression_ratio": 1.8661710037174721,
        "end": 6795.68,
        "id": 2033,
        "no_speech_prob": 0.03621746972203255,
        "seek": 677312,
        "start": 6785.28,
        "temperature": 0.2,
        "text": " But what if you wanted to make a sentiment analysis API that is running somewhere, but anybody could access it from their own web pages and their own programming without being the programmer of the server?",
        "tokens": [
          50972,
          583,
          437,
          498,
          291,
          1415,
          281,
          652,
          257,
          16149,
          5215,
          9362,
          300,
          307,
          2614,
          4079,
          11,
          457,
          4472,
          727,
          2105,
          309,
          490,
          641,
          1065,
          3670,
          7183,
          293,
          641,
          1065,
          9410,
          1553,
          885,
          264,
          32116,
          295,
          264,
          7154,
          30,
          51492
        ]
      },
      {
        "avg_logprob": -0.5987281473273904,
        "compression_ratio": 1.8661710037174721,
        "end": 6802.4,
        "id": 2034,
        "no_speech_prob": 0.03621746972203255,
        "seek": 677312,
        "start": 6795.68,
        "temperature": 0.2,
        "text": " Well, to do that, what you want to do is open up on your server something called cross origin resource sharing.",
        "tokens": [
          51492,
          1042,
          11,
          281,
          360,
          300,
          11,
          437,
          291,
          528,
          281,
          360,
          307,
          1269,
          493,
          322,
          428,
          7154,
          746,
          1219,
          3278,
          4957,
          7684,
          5414,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.457291267031715,
        "compression_ratio": 1.696969696969697,
        "end": 6807.759999999999,
        "id": 2035,
        "no_speech_prob": 0.14032796025276184,
        "seek": 680240,
        "start": 6802.48,
        "temperature": 0.4,
        "text": " So you have a programmer of the server who also is hosting HTML files packaged with it.",
        "tokens": [
          50368,
          407,
          291,
          362,
          257,
          32116,
          295,
          264,
          7154,
          567,
          611,
          307,
          16058,
          17995,
          7098,
          38162,
          365,
          309,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.457291267031715,
        "compression_ratio": 1.696969696969697,
        "end": 6811.599999999999,
        "id": 2036,
        "no_speech_prob": 0.14032796025276184,
        "seek": 680240,
        "start": 6807.759999999999,
        "temperature": 0.4,
        "text": " And to do that, you need to enable cores, which stands for cross origin resource sharing.",
        "tokens": [
          50632,
          400,
          281,
          360,
          300,
          11,
          291,
          643,
          281,
          9528,
          24826,
          11,
          597,
          7382,
          337,
          3278,
          4957,
          7684,
          5414,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.457291267031715,
        "compression_ratio": 1.696969696969697,
        "end": 6813.92,
        "id": 2037,
        "no_speech_prob": 0.14032796025276184,
        "seek": 680240,
        "start": 6811.599999999999,
        "temperature": 0.4,
        "text": " You've probably encountered the flip side of this error.",
        "tokens": [
          50824,
          509,
          600,
          1391,
          20381,
          264,
          7929,
          1252,
          295,
          341,
          6713,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.457291267031715,
        "compression_ratio": 1.696969696969697,
        "end": 6820.96,
        "id": 2038,
        "no_speech_prob": 0.14032796025276184,
        "seek": 680240,
        "start": 6813.92,
        "temperature": 0.4,
        "text": " Anytime you've tried to request something from a server and you've got this XML request, not allowed, cross origin resources, not enabled.",
        "tokens": [
          50940,
          39401,
          291,
          600,
          3031,
          281,
          5308,
          746,
          490,
          257,
          7154,
          293,
          291,
          600,
          658,
          341,
          43484,
          5308,
          11,
          406,
          4350,
          11,
          3278,
          4957,
          3593,
          11,
          406,
          15172,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.457291267031715,
        "compression_ratio": 1.696969696969697,
        "end": 6826.4,
        "id": 2039,
        "no_speech_prob": 0.14032796025276184,
        "seek": 680240,
        "start": 6820.96,
        "temperature": 0.4,
        "text": " So if I want to enable cores, I can search for cores node package express.",
        "tokens": [
          51292,
          407,
          498,
          286,
          528,
          281,
          9528,
          24826,
          11,
          286,
          393,
          3164,
          337,
          24826,
          9984,
          7372,
          5109,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23453787753456518,
        "compression_ratio": 1.654320987654321,
        "end": 6829.28,
        "id": 2040,
        "no_speech_prob": 0.16449759900569916,
        "seek": 682640,
        "start": 6826.879999999999,
        "temperature": 0,
        "text": " This is something I can enable with express.",
        "tokens": [
          50388,
          639,
          307,
          746,
          286,
          393,
          9528,
          365,
          5109,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.23453787753456518,
        "compression_ratio": 1.654320987654321,
        "end": 6835.04,
        "id": 2041,
        "no_speech_prob": 0.16449759900569916,
        "seek": 682640,
        "start": 6829.28,
        "temperature": 0,
        "text": " And I can actually just install this cores package.",
        "tokens": [
          50508,
          400,
          286,
          393,
          767,
          445,
          3625,
          341,
          24826,
          7372,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.23453787753456518,
        "compression_ratio": 1.654320987654321,
        "end": 6842.4,
        "id": 2042,
        "no_speech_prob": 0.16449759900569916,
        "seek": 682640,
        "start": 6836.799999999999,
        "temperature": 0,
        "text": " And I can say npm install cores dash dash save.",
        "tokens": [
          50884,
          400,
          286,
          393,
          584,
          297,
          14395,
          3625,
          24826,
          8240,
          8240,
          3155,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23453787753456518,
        "compression_ratio": 1.654320987654321,
        "end": 6846.32,
        "id": 2043,
        "no_speech_prob": 0.16449759900569916,
        "seek": 682640,
        "start": 6843.5199999999995,
        "temperature": 0,
        "text": " Now I've installed that node package.",
        "tokens": [
          51220,
          823,
          286,
          600,
          8899,
          300,
          9984,
          7372,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.23453787753456518,
        "compression_ratio": 1.654320987654321,
        "end": 6850.48,
        "id": 2044,
        "no_speech_prob": 0.16449759900569916,
        "seek": 682640,
        "start": 6846.32,
        "temperature": 0,
        "text": " And I can go here and I can just grab app dot use.",
        "tokens": [
          51360,
          400,
          286,
          393,
          352,
          510,
          293,
          286,
          393,
          445,
          4444,
          724,
          5893,
          764,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.23453787753456518,
        "compression_ratio": 1.654320987654321,
        "end": 6852.719999999999,
        "id": 2045,
        "no_speech_prob": 0.16449759900569916,
        "seek": 682640,
        "start": 6850.48,
        "temperature": 0,
        "text": " Oh, I can say cores require cores.",
        "tokens": [
          51568,
          876,
          11,
          286,
          393,
          584,
          24826,
          3651,
          24826,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.35099860600062777,
        "compression_ratio": 1.6525096525096525,
        "end": 6858.96,
        "id": 2046,
        "no_speech_prob": 0.006692716386169195,
        "seek": 685272,
        "start": 6853.280000000001,
        "temperature": 0,
        "text": " Right up here, the same place that I used body parser, var cores equals require cores.",
        "tokens": [
          50392,
          1779,
          493,
          510,
          11,
          264,
          912,
          1081,
          300,
          286,
          1143,
          1772,
          21156,
          260,
          11,
          1374,
          24826,
          6915,
          3651,
          24826,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.35099860600062777,
        "compression_ratio": 1.6525096525096525,
        "end": 6865.04,
        "id": 2047,
        "no_speech_prob": 0.006692716386169195,
        "seek": 685272,
        "start": 6858.96,
        "temperature": 0,
        "text": " And app use body parser, app use et cetera, app use cores.",
        "tokens": [
          50676,
          400,
          724,
          764,
          1772,
          21156,
          260,
          11,
          724,
          764,
          1030,
          11458,
          11,
          724,
          764,
          24826,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.35099860600062777,
        "compression_ratio": 1.6525096525096525,
        "end": 6867.4400000000005,
        "id": 2048,
        "no_speech_prob": 0.006692716386169195,
        "seek": 685272,
        "start": 6865.04,
        "temperature": 0,
        "text": " So now I now have enabled cores.",
        "tokens": [
          50980,
          407,
          586,
          286,
          586,
          362,
          15172,
          24826,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.35099860600062777,
        "compression_ratio": 1.6525096525096525,
        "end": 6873.84,
        "id": 2049,
        "no_speech_prob": 0.006692716386169195,
        "seek": 685272,
        "start": 6867.4400000000005,
        "temperature": 0,
        "text": " So if I put this, if I deploy this to Heroku or Digital Ocean or whatever web server hosting environment, my wherever my server is.",
        "tokens": [
          51100,
          407,
          498,
          286,
          829,
          341,
          11,
          498,
          286,
          7274,
          341,
          281,
          3204,
          13275,
          420,
          15522,
          18101,
          420,
          2035,
          3670,
          7154,
          16058,
          2823,
          11,
          452,
          8660,
          452,
          7154,
          307,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.35099860600062777,
        "compression_ratio": 1.6525096525096525,
        "end": 6882.64,
        "id": 2050,
        "no_speech_prob": 0.006692716386169195,
        "seek": 685272,
        "start": 6873.84,
        "temperature": 0,
        "text": " Now, if I handed out the IP address or the URL, other people could call load JSON or HTTP post from their own server.",
        "tokens": [
          51420,
          823,
          11,
          498,
          286,
          16013,
          484,
          264,
          8671,
          2985,
          420,
          264,
          12905,
          11,
          661,
          561,
          727,
          818,
          3677,
          31828,
          420,
          33283,
          2183,
          490,
          641,
          1065,
          7154,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -2.9565190854279892,
        "compression_ratio": 1.7058823529411764,
        "end": 6886.02,
        "id": 2051,
        "no_speech_prob": 0.006192812696099281,
        "seek": 688264,
        "start": 6883.46,
        "temperature": 1,
        "text": " So there is no really much to the API here.",
        "tokens": [
          50405,
          407,
          264,
          265,
          307,
          572,
          534,
          709,
          281,
          264,
          9362,
          510,
          13,
          50533
        ]
      },
      {
        "avg_logprob": -2.9565190854279892,
        "compression_ratio": 1.7058823529411764,
        "end": 6890.06,
        "id": 2052,
        "no_speech_prob": 0.006192812696099281,
        "seek": 688264,
        "start": 6886.02,
        "temperature": 1,
        "text": " So the core we're going to need is something to issue PFCs.",
        "tokens": [
          50533,
          407,
          264,
          4965,
          321,
          434,
          516,
          281,
          643,
          307,
          512,
          825,
          281,
          2734,
          430,
          18671,
          82,
          13,
          50735
        ]
      },
      {
        "avg_logprob": -2.9565190854279892,
        "compression_ratio": 1.7058823529411764,
        "end": 6898.9400000000005,
        "id": 2053,
        "no_speech_prob": 0.006192812696099281,
        "seek": 688264,
        "start": 6890.8,
        "temperature": 1,
        "text": " So we're going to make sure we've got an IP address owner, someone who one to protect the identity of an IP address holder,",
        "tokens": [
          50772,
          407,
          321,
          434,
          516,
          220,
          1353,
          652,
          988,
          321,
          600,
          658,
          364,
          8671,
          2985,
          7289,
          11,
          1580,
          567,
          472,
          220,
          1353,
          582,
          310,
          557,
          264,
          6575,
          295,
          364,
          8671,
          2985,
          20349,
          11,
          51179
        ]
      },
      {
        "avg_logprob": -2.9565190854279892,
        "compression_ratio": 1.7058823529411764,
        "end": 6901.52,
        "id": 2054,
        "no_speech_prob": 0.006192812696099281,
        "seek": 688264,
        "start": 6898.9400000000005,
        "temperature": 1,
        "text": " of some sort, relatively recently.",
        "tokens": [
          51179,
          295,
          512,
          1333,
          11,
          7226,
          3938,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -2.9565190854279892,
        "compression_ratio": 1.7058823529411764,
        "end": 6906.6,
        "id": 2055,
        "no_speech_prob": 0.006192812696099281,
        "seek": 688264,
        "start": 6901.52,
        "temperature": 1,
        "text": " And I'm going to give this IP address holder the IP address that has been given.",
        "tokens": [
          51308,
          400,
          286,
          478,
          516,
          281,
          290,
          592,
          68,
          341,
          8671,
          2985,
          20349,
          220,
          3322,
          8671,
          2985,
          300,
          324,
          82,
          668,
          2212,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -2.9565190854279892,
        "compression_ratio": 1.7058823529411764,
        "end": 6909.06,
        "id": 2056,
        "no_speech_prob": 0.006192812696099281,
        "seek": 688264,
        "start": 6907.5,
        "temperature": 1,
        "text": " Let's switch back to our notepad.",
        "tokens": [
          51607,
          961,
          311,
          3679,
          4773,
          547,
          281,
          527,
          406,
          595,
          345,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6910.06,
        "id": 2057,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6909.06,
        "temperature": 0,
        "text": " How does that work?",
        "tokens": [
          50364,
          1012,
          775,
          300,
          589,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6917.06,
        "id": 2058,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6916.06,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          50714,
          31973,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6921.06,
        "id": 2059,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6919.06,
        "temperature": 0,
        "text": " Does it not override today?",
        "tokens": [
          50864,
          4402,
          309,
          406,
          42321,
          965,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6922.06,
        "id": 2060,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6921.06,
        "temperature": 0,
        "text": " It still has 100.",
        "tokens": [
          50964,
          467,
          920,
          575,
          2319,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6925.06,
        "id": 2061,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6922.06,
        "temperature": 0,
        "text": " It should override it, right, if it's already in there?",
        "tokens": [
          51014,
          467,
          820,
          42321,
          309,
          11,
          558,
          11,
          498,
          309,
          311,
          1217,
          294,
          456,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6930.06,
        "id": 2062,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6926.06,
        "temperature": 0,
        "text": " I don't know why I attempted to do something in this last minute of this video.",
        "tokens": [
          51214,
          286,
          500,
          380,
          458,
          983,
          286,
          18997,
          281,
          360,
          746,
          294,
          341,
          1036,
          3456,
          295,
          341,
          960,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6932.06,
        "id": 2063,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6930.06,
        "temperature": 0,
        "text": " I was done.",
        "tokens": [
          51414,
          286,
          390,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6934.06,
        "id": 2064,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6932.06,
        "temperature": 0,
        "text": " Oh, score is required.",
        "tokens": [
          51514,
          876,
          11,
          6175,
          307,
          4739,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6935.06,
        "id": 2065,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6934.06,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51614,
          7951,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6937.06,
        "id": 2066,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6936.06,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51714,
          45263,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.40401384907384075,
        "compression_ratio": 1.422680412371134,
        "end": 6938.06,
        "id": 2067,
        "no_speech_prob": 0.1800806075334549,
        "seek": 690906,
        "start": 6937.06,
        "temperature": 0,
        "text": " What did I mess up?",
        "tokens": [
          51764,
          708,
          630,
          286,
          2082,
          493,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6943.06,
        "id": 2068,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6940.06,
        "temperature": 0,
        "text": " Sorry, something got broken.",
        "tokens": [
          50414,
          4919,
          11,
          746,
          658,
          5463,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6946.06,
        "id": 2069,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6943.06,
        "temperature": 0,
        "text": " I'm debugging, I'm debugging.",
        "tokens": [
          50564,
          286,
          478,
          45592,
          11,
          286,
          478,
          45592,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6947.06,
        "id": 2070,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6946.06,
        "temperature": 0,
        "text": " Submit word.",
        "tokens": [
          50714,
          8511,
          3508,
          1349,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6950.06,
        "id": 2071,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6949.06,
        "temperature": 0,
        "text": " Word.",
        "tokens": [
          50864,
          8725,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6951.06,
        "id": 2072,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6950.06,
        "temperature": 0,
        "text": " Score.",
        "tokens": [
          50914,
          47901,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6953.06,
        "id": 2073,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6951.06,
        "temperature": 0,
        "text": " Oh, I'm probably...",
        "tokens": [
          50964,
          876,
          11,
          286,
          478,
          1391,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6958.06,
        "id": 2074,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6953.06,
        "temperature": 0,
        "text": " Once again, I have this score variable too many different places thing, probably.",
        "tokens": [
          51064,
          3443,
          797,
          11,
          286,
          362,
          341,
          6175,
          7006,
          886,
          867,
          819,
          3190,
          551,
          11,
          1391,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6962.06,
        "id": 2075,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6959.06,
        "temperature": 0,
        "text": " Score input.",
        "tokens": [
          51364,
          47901,
          4846,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6965.06,
        "id": 2076,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6963.06,
        "temperature": 0,
        "text": " Let's just change that.",
        "tokens": [
          51564,
          961,
          311,
          445,
          1319,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25161138757482754,
        "compression_ratio": 1.4197530864197532,
        "end": 6966.06,
        "id": 2077,
        "no_speech_prob": 0.00009761538967723027,
        "seek": 693906,
        "start": 6965.06,
        "temperature": 0,
        "text": " I bet.",
        "tokens": [
          51664,
          286,
          778,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6971.06,
        "id": 2078,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6969.06,
        "temperature": 0,
        "text": " Let's see if that's the problem.",
        "tokens": [
          50364,
          961,
          311,
          536,
          498,
          300,
          311,
          264,
          1154,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6979.06,
        "id": 2079,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6975.06,
        "temperature": 0,
        "text": " Add word plus score.",
        "tokens": [
          50664,
          5349,
          1349,
          1804,
          6175,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6980.06,
        "id": 2080,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6979.06,
        "temperature": 0,
        "text": " Let's try that again.",
        "tokens": [
          50864,
          961,
          311,
          853,
          300,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6986.06,
        "id": 2081,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6983.06,
        "temperature": 0,
        "text": " Oh, I wonder if you send it zero.",
        "tokens": [
          51064,
          876,
          11,
          286,
          2441,
          498,
          291,
          2845,
          309,
          4018,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6987.06,
        "id": 2082,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6986.06,
        "temperature": 0,
        "text": " You can't give it a score of...",
        "tokens": [
          51214,
          509,
          393,
          380,
          976,
          309,
          257,
          6175,
          295,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6989.06,
        "id": 2083,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6987.06,
        "temperature": 0,
        "text": " Oh, you can't give it a score of zero.",
        "tokens": [
          51264,
          876,
          11,
          291,
          393,
          380,
          976,
          309,
          257,
          6175,
          295,
          4018,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6994.06,
        "id": 2084,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6991.06,
        "temperature": 0,
        "text": " Because zero must be like false or something.",
        "tokens": [
          51464,
          1436,
          4018,
          1633,
          312,
          411,
          7908,
          420,
          746,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18527700684287332,
        "compression_ratio": 1.6,
        "end": 6996.06,
        "id": 2085,
        "no_speech_prob": 0.000010953099263133481,
        "seek": 696906,
        "start": 6994.06,
        "temperature": 0,
        "text": " Oh, yeah, zero is evaluated as false.",
        "tokens": [
          51614,
          876,
          11,
          1338,
          11,
          4018,
          307,
          25509,
          382,
          7908,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7001.06,
        "id": 2086,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 6996.06,
        "temperature": 0,
        "text": " Oh, that's just a little mistake that I have in mind.",
        "tokens": [
          50364,
          876,
          11,
          300,
          311,
          445,
          257,
          707,
          6146,
          300,
          286,
          362,
          294,
          1575,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7004.06,
        "id": 2087,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7002.06,
        "temperature": 0,
        "text": " Now that I gave it...",
        "tokens": [
          50664,
          823,
          300,
          286,
          2729,
          309,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7007.06,
        "id": 2088,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7005.06,
        "temperature": 0,
        "text": " I don't know what this...",
        "tokens": [
          50814,
          286,
          500,
          380,
          458,
          437,
          341,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7009.06,
        "id": 2089,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7007.06,
        "temperature": 0,
        "text": " Cut this part out.",
        "tokens": [
          50914,
          9431,
          341,
          644,
          484,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7012.06,
        "id": 2090,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7009.06,
        "temperature": 0,
        "text": " I don't know why I was just fixing that.",
        "tokens": [
          51014,
          286,
          500,
          380,
          458,
          983,
          286,
          390,
          445,
          19442,
          300,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7013.06,
        "id": 2091,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7012.06,
        "temperature": 0,
        "text": " Where was I in this video?",
        "tokens": [
          51164,
          2305,
          390,
          286,
          294,
          341,
          960,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7016.06,
        "id": 2092,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7013.06,
        "temperature": 0,
        "text": " Cut back, rewind, rewind.",
        "tokens": [
          51214,
          9431,
          646,
          11,
          41458,
          11,
          41458,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7017.06,
        "id": 2093,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7016.06,
        "temperature": 0,
        "text": " Let me finish this video off.",
        "tokens": [
          51364,
          961,
          385,
          2413,
          341,
          960,
          766,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7019.06,
        "id": 2094,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7017.06,
        "temperature": 0,
        "text": " I don't know, it'll cut at some point.",
        "tokens": [
          51414,
          286,
          500,
          380,
          458,
          11,
          309,
          603,
          1723,
          412,
          512,
          935,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7022.06,
        "id": 2095,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7020.06,
        "temperature": 0,
        "text": " I just wanted to make sure it was still working.",
        "tokens": [
          51564,
          286,
          445,
          1415,
          281,
          652,
          988,
          309,
          390,
          920,
          1364,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7023.06,
        "id": 2096,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7022.06,
        "temperature": 0,
        "text": " It's still working, but I'll fix that.",
        "tokens": [
          51664,
          467,
          311,
          920,
          1364,
          11,
          457,
          286,
          603,
          3191,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17593759390024039,
        "compression_ratio": 1.7723214285714286,
        "end": 7024.06,
        "id": 2097,
        "no_speech_prob": 0.0053016431629657745,
        "seek": 699606,
        "start": 7023.06,
        "temperature": 0,
        "text": " Let me actually fix that.",
        "tokens": [
          51714,
          961,
          385,
          767,
          3191,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7026.06,
        "id": 2098,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7024.06,
        "temperature": 0,
        "text": " Let me show you what I mean in case you're wondering.",
        "tokens": [
          50364,
          961,
          385,
          855,
          291,
          437,
          286,
          914,
          294,
          1389,
          291,
          434,
          6359,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7029.06,
        "id": 2099,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7026.06,
        "temperature": 0,
        "text": " This doesn't need to make it into the actual published version,",
        "tokens": [
          50464,
          639,
          1177,
          380,
          643,
          281,
          652,
          309,
          666,
          264,
          3539,
          6572,
          3037,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7031.06,
        "id": 2100,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7029.06,
        "temperature": 0,
        "text": " the edited version of this tutorial.",
        "tokens": [
          50614,
          264,
          23016,
          3037,
          295,
          341,
          7073,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7038.06,
        "id": 2101,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7033.06,
        "temperature": 0,
        "text": " If I go to the get request for add...",
        "tokens": [
          50814,
          759,
          286,
          352,
          281,
          264,
          483,
          5308,
          337,
          909,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7041.06,
        "id": 2102,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7038.06,
        "temperature": 0,
        "text": " I'm doing so much scrolling, it's crazy.",
        "tokens": [
          51064,
          286,
          478,
          884,
          370,
          709,
          29053,
          11,
          309,
          311,
          3219,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7047.06,
        "id": 2103,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7044.06,
        "temperature": 0,
        "text": " What I'm doing is I'm saying if there is no score,",
        "tokens": [
          51364,
          708,
          286,
          478,
          884,
          307,
          286,
          478,
          1566,
          498,
          456,
          307,
          572,
          6175,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7049.06,
        "id": 2104,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7047.06,
        "temperature": 0,
        "text": " score is required.",
        "tokens": [
          51514,
          6175,
          307,
          4739,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21945828730517095,
        "compression_ratio": 1.5844748858447488,
        "end": 7052.06,
        "id": 2105,
        "no_speech_prob": 0.011331277899444103,
        "seek": 702406,
        "start": 7049.06,
        "temperature": 0,
        "text": " But if the score is zero, that'll evaluate.",
        "tokens": [
          51614,
          583,
          498,
          264,
          6175,
          307,
          4018,
          11,
          300,
          603,
          13059,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7061.06,
        "id": 2106,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7053.06,
        "temperature": 0,
        "text": " I want to say if score does not equal zero...",
        "tokens": [
          50414,
          286,
          528,
          281,
          584,
          498,
          6175,
          775,
          406,
          2681,
          4018,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7065.06,
        "id": 2107,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7064.06,
        "temperature": 0,
        "text": " If score...",
        "tokens": [
          50964,
          759,
          6175,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7073.06,
        "id": 2108,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7067.06,
        "temperature": 0,
        "text": " If no score and score does not equal zero.",
        "tokens": [
          51114,
          759,
          572,
          6175,
          293,
          6175,
          775,
          406,
          2681,
          4018,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7075.06,
        "id": 2109,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7073.06,
        "temperature": 0,
        "text": " This is me just checking.",
        "tokens": [
          51414,
          639,
          307,
          385,
          445,
          8568,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7077.06,
        "id": 2110,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7075.06,
        "temperature": 0,
        "text": " I could also say if score equals undefined,",
        "tokens": [
          51514,
          286,
          727,
          611,
          584,
          498,
          6175,
          6915,
          674,
          5666,
          2001,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7079.06,
        "id": 2111,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7077.06,
        "temperature": 0,
        "text": " because I think that's what it would be.",
        "tokens": [
          51614,
          570,
          286,
          519,
          300,
          311,
          437,
          309,
          576,
          312,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21665413315231735,
        "compression_ratio": 1.643835616438356,
        "end": 7081.06,
        "id": 2112,
        "no_speech_prob": 0.0001660378184169531,
        "seek": 705206,
        "start": 7079.06,
        "temperature": 0,
        "text": " But I could just say here...",
        "tokens": [
          51714,
          583,
          286,
          727,
          445,
          584,
          510,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7084.06,
        "id": 2113,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7081.06,
        "temperature": 0,
        "text": " Let me just double check and make sure that...",
        "tokens": [
          50364,
          961,
          385,
          445,
          3834,
          1520,
          293,
          652,
          988,
          300,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7088.06,
        "id": 2114,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7086.06,
        "temperature": 0,
        "text": " This is for things that are invalid,",
        "tokens": [
          50614,
          639,
          307,
          337,
          721,
          300,
          366,
          34702,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7089.06,
        "id": 2115,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7088.06,
        "temperature": 0,
        "text": " and I want zero to be valid.",
        "tokens": [
          50714,
          293,
          286,
          528,
          4018,
          281,
          312,
          7363,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7092.06,
        "id": 2116,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7089.06,
        "temperature": 0,
        "text": " It's only invalid if it's something like null or undefined",
        "tokens": [
          50764,
          467,
          311,
          787,
          34702,
          498,
          309,
          311,
          746,
          411,
          18184,
          420,
          674,
          5666,
          2001,
          50914
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7096.06,
        "id": 2117,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7092.06,
        "temperature": 0,
        "text": " or hello, some text, but not zero.",
        "tokens": [
          50914,
          420,
          7751,
          11,
          512,
          2487,
          11,
          457,
          406,
          4018,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7098.06,
        "id": 2118,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7096.06,
        "temperature": 0,
        "text": " I need better error checking here.",
        "tokens": [
          51114,
          286,
          643,
          1101,
          6713,
          8568,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7100.06,
        "id": 2119,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7098.06,
        "temperature": 0,
        "text": " Let me just see that that works.",
        "tokens": [
          51214,
          961,
          385,
          445,
          536,
          300,
          300,
          1985,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7103.06,
        "id": 2120,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7101.06,
        "temperature": 0,
        "text": " And then today, zero.",
        "tokens": [
          51364,
          400,
          550,
          965,
          11,
          4018,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7106.06,
        "id": 2121,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7104.06,
        "temperature": 0,
        "text": " It added a sign, so that fixed it.",
        "tokens": [
          51514,
          467,
          3869,
          257,
          1465,
          11,
          370,
          300,
          6806,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7108.06,
        "id": 2122,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7107.06,
        "temperature": 0,
        "text": " I don't know where I was.",
        "tokens": [
          51664,
          286,
          500,
          380,
          458,
          689,
          286,
          390,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21794164673355984,
        "compression_ratio": 1.6965811965811965,
        "end": 7110.06,
        "id": 2123,
        "no_speech_prob": 0.0002415642811683938,
        "seek": 708106,
        "start": 7108.06,
        "temperature": 0,
        "text": " I was checking to make sure this works.",
        "tokens": [
          51714,
          286,
          390,
          8568,
          281,
          652,
          988,
          341,
          1985,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7113.06,
        "id": 2124,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7112.06,
        "temperature": 0,
        "text": " So, and then...",
        "tokens": [
          50414,
          407,
          11,
          293,
          550,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7115.06,
        "id": 2125,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7113.06,
        "temperature": 0,
        "text": " But I'm just going to finish off this video.",
        "tokens": [
          50464,
          583,
          286,
          478,
          445,
          516,
          281,
          2413,
          766,
          341,
          960,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7118.06,
        "id": 2126,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7116.06,
        "temperature": 0,
        "text": " I'll just say some wrap-up words.",
        "tokens": [
          50614,
          286,
          603,
          445,
          584,
          512,
          7019,
          12,
          1010,
          2283,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7125.06,
        "id": 2127,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7120.06,
        "temperature": 0,
        "text": " So, this concludes my series about how to build an API",
        "tokens": [
          50814,
          407,
          11,
          341,
          24643,
          452,
          2638,
          466,
          577,
          281,
          1322,
          364,
          9362,
          51064
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7128.06,
        "id": 2128,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7125.06,
        "temperature": 0,
        "text": " from scratch using Node and a front end to that API",
        "tokens": [
          51064,
          490,
          8459,
          1228,
          38640,
          293,
          257,
          1868,
          917,
          281,
          300,
          9362,
          51214
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7129.06,
        "id": 2129,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7128.06,
        "temperature": 0,
        "text": " using p5.js.",
        "tokens": [
          51214,
          1228,
          280,
          20,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7131.06,
        "id": 2130,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7129.06,
        "temperature": 0,
        "text": " Hopefully, you found this useful.",
        "tokens": [
          51264,
          10429,
          11,
          291,
          1352,
          341,
          4420,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7133.06,
        "id": 2131,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7131.06,
        "temperature": 0,
        "text": " If you make an API, if you build something,",
        "tokens": [
          51364,
          759,
          291,
          652,
          364,
          9362,
          11,
          498,
          291,
          1322,
          746,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7134.06,
        "id": 2132,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7133.06,
        "temperature": 0,
        "text": " share it with me.",
        "tokens": [
          51464,
          2073,
          309,
          365,
          385,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7135.06,
        "id": 2133,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7134.06,
        "temperature": 0,
        "text": " Ask in the comments.",
        "tokens": [
          51514,
          12320,
          294,
          264,
          3053,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7136.06,
        "id": 2134,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7135.06,
        "temperature": 0,
        "text": " Like, share this video.",
        "tokens": [
          51564,
          1743,
          11,
          2073,
          341,
          960,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7138.06,
        "id": 2135,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7136.06,
        "temperature": 0,
        "text": " I guess those are the things I'm supposed to say.",
        "tokens": [
          51614,
          286,
          2041,
          729,
          366,
          264,
          721,
          286,
          478,
          3442,
          281,
          584,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18163974789807397,
        "compression_ratio": 1.6139705882352942,
        "end": 7139.06,
        "id": 2136,
        "no_speech_prob": 0.0004955145413987339,
        "seek": 711106,
        "start": 7138.06,
        "temperature": 0,
        "text": " And I look forward to seeing you.",
        "tokens": [
          51714,
          400,
          286,
          574,
          2128,
          281,
          2577,
          291,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7141.06,
        "id": 2137,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7139.06,
        "temperature": 0,
        "text": " I'll do some follow-up videos as part of this playlist",
        "tokens": [
          50364,
          286,
          603,
          360,
          512,
          1524,
          12,
          1010,
          2145,
          382,
          644,
          295,
          341,
          16788,
          50464
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7143.06,
        "id": 2138,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7141.06,
        "temperature": 0,
        "text": " if there are some good questions or other features",
        "tokens": [
          50464,
          498,
          456,
          366,
          512,
          665,
          1651,
          420,
          661,
          4122,
          50564
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7144.06,
        "id": 2139,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7143.06,
        "temperature": 0,
        "text": " that I think of adding.",
        "tokens": [
          50564,
          300,
          286,
          519,
          295,
          5127,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7145.06,
        "id": 2140,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7144.06,
        "temperature": 0,
        "text": " Okay?",
        "tokens": [
          50614,
          1033,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7146.06,
        "id": 2141,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7145.06,
        "temperature": 0,
        "text": " See you soon.",
        "tokens": [
          50664,
          3008,
          291,
          2321,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7147.06,
        "id": 2142,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7146.06,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          50714,
          15528,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7153.06,
        "id": 2143,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7148.06,
        "temperature": 0,
        "text": " Yes, Lordius, I could say score does not equal undefined.",
        "tokens": [
          50814,
          1079,
          11,
          3257,
          4872,
          11,
          286,
          727,
          584,
          6175,
          775,
          406,
          2681,
          674,
          5666,
          2001,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7154.06,
        "id": 2144,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7153.06,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51064,
          1057,
          558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7157.06,
        "id": 2145,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7154.06,
        "temperature": 0,
        "text": " So, thank you, everybody, for watching today.",
        "tokens": [
          51114,
          407,
          11,
          1309,
          291,
          11,
          2201,
          11,
          337,
          1976,
          965,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7158.06,
        "id": 2146,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7157.06,
        "temperature": 0,
        "text": " It is 5.20.",
        "tokens": [
          51264,
          467,
          307,
          1025,
          13,
          2009,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7159.06,
        "id": 2147,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7158.06,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51314,
          876,
          11,
          452,
          8387,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7160.06,
        "id": 2148,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7159.06,
        "temperature": 0,
        "text": " This has been a...",
        "tokens": [
          51364,
          639,
          575,
          668,
          257,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7167.06,
        "id": 2149,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7164.06,
        "temperature": 0,
        "text": " Weirdly, the live stream says it's only been going",
        "tokens": [
          51614,
          32033,
          356,
          11,
          264,
          1621,
          4309,
          1619,
          309,
          311,
          787,
          668,
          516,
          51764
        ]
      },
      {
        "avg_logprob": -0.20111751556396484,
        "compression_ratio": 1.4423791821561338,
        "end": 7168.06,
        "id": 2150,
        "no_speech_prob": 0.026351604610681534,
        "seek": 713906,
        "start": 7167.06,
        "temperature": 0,
        "text": " for 10 minutes.",
        "tokens": [
          51764,
          337,
          1266,
          2077,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7170.06,
        "id": 2151,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7168.06,
        "temperature": 0,
        "text": " Did it, like, stop and restart?",
        "tokens": [
          50364,
          2589,
          309,
          11,
          411,
          11,
          1590,
          293,
          21022,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7171.06,
        "id": 2152,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7170.06,
        "temperature": 0,
        "text": " I don't know why it's saying that.",
        "tokens": [
          50464,
          286,
          500,
          380,
          458,
          983,
          309,
          311,
          1566,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7173.06,
        "id": 2153,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7171.06,
        "temperature": 0,
        "text": " But this has been two hours.",
        "tokens": [
          50514,
          583,
          341,
          575,
          668,
          732,
          2496,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7175.06,
        "id": 2154,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7173.06,
        "temperature": 0,
        "text": " Hopefully, the live stream archive is okay,",
        "tokens": [
          50614,
          10429,
          11,
          264,
          1621,
          4309,
          23507,
          307,
          1392,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7177.06,
        "id": 2155,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7175.06,
        "temperature": 0,
        "text": " but I've been recording this.",
        "tokens": [
          50714,
          457,
          286,
          600,
          668,
          6613,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7178.06,
        "id": 2156,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7177.06,
        "temperature": 0,
        "text": " I lost...",
        "tokens": [
          50814,
          286,
          2731,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7180.06,
        "id": 2157,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7178.06,
        "temperature": 0,
        "text": " When did I lose all those viewers?",
        "tokens": [
          50864,
          1133,
          630,
          286,
          3624,
          439,
          729,
          8499,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7184.06,
        "id": 2158,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7180.06,
        "temperature": 0,
        "text": " There was some point where I went from 112 to 88.",
        "tokens": [
          50964,
          821,
          390,
          512,
          935,
          689,
          286,
          1437,
          490,
          45835,
          281,
          24587,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7185.06,
        "id": 2159,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7184.06,
        "temperature": 0,
        "text": " I have this, like, graph.",
        "tokens": [
          51164,
          286,
          362,
          341,
          11,
          411,
          11,
          4295,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7186.06,
        "id": 2160,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7185.06,
        "temperature": 0,
        "text": " You guys can't see this.",
        "tokens": [
          51214,
          509,
          1074,
          393,
          380,
          536,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7187.06,
        "id": 2161,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7186.06,
        "temperature": 0,
        "text": " I should show this to you.",
        "tokens": [
          51264,
          286,
          820,
          855,
          341,
          281,
          291,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7188.06,
        "id": 2162,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7187.06,
        "temperature": 0,
        "text": " I have this graph of viewers.",
        "tokens": [
          51314,
          286,
          362,
          341,
          4295,
          295,
          8499,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7190.06,
        "id": 2163,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7188.06,
        "temperature": 0,
        "text": " I don't know what I was doing a little after 5",
        "tokens": [
          51364,
          286,
          500,
          380,
          458,
          437,
          286,
          390,
          884,
          257,
          707,
          934,
          1025,
          51464
        ]
      },
      {
        "avg_logprob": -0.14112545581574135,
        "compression_ratio": 1.6286764705882353,
        "end": 7192.06,
        "id": 2164,
        "no_speech_prob": 0.030672898516058922,
        "seek": 716806,
        "start": 7190.06,
        "temperature": 0,
        "text": " where I lost everybody.",
        "tokens": [
          51464,
          689,
          286,
          2731,
          2201,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7195.06,
        "id": 2165,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7193.06,
        "temperature": 0,
        "text": " Oh, it restarted a few times.",
        "tokens": [
          50414,
          876,
          11,
          309,
          21022,
          292,
          257,
          1326,
          1413,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7198.06,
        "id": 2166,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7195.06,
        "temperature": 0,
        "text": " I wonder why it did that, because it didn't on my end.",
        "tokens": [
          50514,
          286,
          2441,
          983,
          309,
          630,
          300,
          11,
          570,
          309,
          994,
          380,
          322,
          452,
          917,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7199.06,
        "id": 2167,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7198.06,
        "temperature": 0,
        "text": " So, hopefully, it didn't...",
        "tokens": [
          50664,
          407,
          11,
          4696,
          11,
          309,
          994,
          380,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7206.06,
        "id": 2168,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7199.06,
        "temperature": 0,
        "text": " I don't know if it's chopped it up into multiple videos,",
        "tokens": [
          50714,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          16497,
          309,
          493,
          666,
          3866,
          2145,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7208.06,
        "id": 2169,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7206.06,
        "temperature": 0,
        "text": " but we'll have to fix that later.",
        "tokens": [
          51064,
          457,
          321,
          603,
          362,
          281,
          3191,
          300,
          1780,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7209.06,
        "id": 2170,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7208.06,
        "temperature": 0,
        "text": " I had 200 at one time.",
        "tokens": [
          51164,
          286,
          632,
          2331,
          412,
          472,
          565,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7210.06,
        "id": 2171,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7209.06,
        "temperature": 0,
        "text": " That's crazy.",
        "tokens": [
          51214,
          663,
          311,
          3219,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7213.06,
        "id": 2172,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7210.06,
        "temperature": 0,
        "text": " But I can understand why not everybody wanted",
        "tokens": [
          51264,
          583,
          286,
          393,
          1223,
          983,
          406,
          2201,
          1415,
          51414
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7215.06,
        "id": 2173,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7213.06,
        "temperature": 0,
        "text": " to watch it this whole time.",
        "tokens": [
          51414,
          281,
          1159,
          309,
          341,
          1379,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7217.06,
        "id": 2174,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7215.06,
        "temperature": 0,
        "text": " So, thank you, guys, for tuning in.",
        "tokens": [
          51514,
          407,
          11,
          1309,
          291,
          11,
          1074,
          11,
          337,
          15164,
          294,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17422468154156795,
        "compression_ratio": 1.5473251028806585,
        "end": 7219.06,
        "id": 2175,
        "no_speech_prob": 0.05183084309101105,
        "seek": 719206,
        "start": 7217.06,
        "temperature": 0,
        "text": " I definitely have to go.",
        "tokens": [
          51614,
          286,
          2138,
          362,
          281,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7222.06,
        "id": 2176,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7219.06,
        "temperature": 0,
        "text": " But I will stay here for five minutes",
        "tokens": [
          50364,
          583,
          286,
          486,
          1754,
          510,
          337,
          1732,
          2077,
          50514
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7225.06,
        "id": 2177,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7222.06,
        "temperature": 0,
        "text": " to see if there are any last questions in the chat.",
        "tokens": [
          50514,
          281,
          536,
          498,
          456,
          366,
          604,
          1036,
          1651,
          294,
          264,
          5081,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7229.06,
        "id": 2178,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7225.06,
        "temperature": 0,
        "text": " Next week, I will be back.",
        "tokens": [
          50664,
          3087,
          1243,
          11,
          286,
          486,
          312,
          646,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7233.06,
        "id": 2179,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7229.06,
        "temperature": 0,
        "text": " And the things that I have not gotten to are",
        "tokens": [
          50864,
          400,
          264,
          721,
          300,
          286,
          362,
          406,
          5768,
          281,
          366,
          51064
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7236.06,
        "id": 2180,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7233.06,
        "temperature": 0,
        "text": " how to build a Chrome extension.",
        "tokens": [
          51064,
          577,
          281,
          1322,
          257,
          15327,
          10320,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7238.06,
        "id": 2181,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7236.06,
        "temperature": 0,
        "text": " That's going to be a full-fledged video.",
        "tokens": [
          51214,
          663,
          311,
          516,
          281,
          312,
          257,
          1577,
          12,
          69,
          1493,
          3004,
          960,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7240.06,
        "id": 2182,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7238.06,
        "temperature": 0,
        "text": " I'm going to be doing a lot of stuff.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          1507,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7242.06,
        "id": 2183,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7240.06,
        "temperature": 0,
        "text": " I'm going to be doing a lot of stuff.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          1507,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7244.06,
        "id": 2184,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7242.06,
        "temperature": 0,
        "text": " I'm going to be doing a lot of stuff.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.4692729826896421,
        "compression_ratio": 2.036842105263158,
        "end": 7246.06,
        "id": 2185,
        "no_speech_prob": 0.0440102219581604,
        "seek": 721906,
        "start": 7244.06,
        "temperature": 0,
        "text": " I'm going to be doing a lot of stuff.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          312,
          884,
          257,
          688,
          295,
          1507,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7248.06,
        "id": 2186,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7246.06,
        "temperature": 0,
        "text": " How to build a Chrome extension.",
        "tokens": [
          50364,
          1012,
          281,
          1322,
          257,
          15327,
          10320,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7250.06,
        "id": 2187,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7248.06,
        "temperature": 0,
        "text": " That's going to be a full set of tutorials.",
        "tokens": [
          50464,
          663,
          311,
          516,
          281,
          312,
          257,
          1577,
          992,
          295,
          17616,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7251.06,
        "id": 2188,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7250.06,
        "temperature": 0,
        "text": " Maybe I'll do that next week.",
        "tokens": [
          50564,
          2704,
          286,
          603,
          360,
          300,
          958,
          1243,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7258.06,
        "id": 2189,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7251.06,
        "temperature": 0,
        "text": " I wanted to do videos on using Sheetsu,",
        "tokens": [
          50614,
          286,
          1415,
          281,
          360,
          2145,
          322,
          1228,
          1240,
          1385,
          84,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7260.06,
        "id": 2190,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7258.06,
        "temperature": 0,
        "text": " which is an API for...",
        "tokens": [
          50964,
          597,
          307,
          364,
          9362,
          337,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7262.06,
        "id": 2191,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7260.06,
        "temperature": 0,
        "text": " Basically, turn a Google Sheet into an API,",
        "tokens": [
          51064,
          8537,
          11,
          1261,
          257,
          3329,
          1240,
          302,
          666,
          364,
          9362,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7264.06,
        "id": 2192,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7262.06,
        "temperature": 0,
        "text": " which is very useful, as well as Firebase.",
        "tokens": [
          51164,
          597,
          307,
          588,
          4420,
          11,
          382,
          731,
          382,
          35173,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7265.06,
        "id": 2193,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7264.06,
        "temperature": 0,
        "text": " So, I wanted to look at...",
        "tokens": [
          51264,
          407,
          11,
          286,
          1415,
          281,
          574,
          412,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7267.06,
        "id": 2194,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7265.06,
        "temperature": 0,
        "text": " Oh, did I win the Hamilton Lottery?",
        "tokens": [
          51314,
          876,
          11,
          630,
          286,
          1942,
          264,
          18484,
          20131,
          12733,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7268.06,
        "id": 2195,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7267.06,
        "temperature": 0,
        "text": " Thank you, guys.",
        "tokens": [
          51414,
          1044,
          291,
          11,
          1074,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7270.06,
        "id": 2196,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7268.06,
        "temperature": 0,
        "text": " Thank you for asking.",
        "tokens": [
          51464,
          1044,
          291,
          337,
          3365,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19118821816366227,
        "compression_ratio": 1.5121951219512195,
        "end": 7273.06,
        "id": 2197,
        "no_speech_prob": 0.48358622193336487,
        "seek": 724606,
        "start": 7270.06,
        "temperature": 0,
        "text": " Let me check.",
        "tokens": [
          51564,
          961,
          385,
          1520,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7276.06,
        "id": 2198,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7273.06,
        "temperature": 0,
        "text": " Because, you know, you have to claim the tickets by, like...",
        "tokens": [
          50364,
          1436,
          11,
          291,
          458,
          11,
          291,
          362,
          281,
          3932,
          264,
          12628,
          538,
          11,
          411,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7278.06,
        "id": 2199,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7276.06,
        "temperature": 0,
        "text": " Oh, shoot. I think I already missed claiming the tickets.",
        "tokens": [
          50514,
          876,
          11,
          3076,
          13,
          286,
          519,
          286,
          1217,
          6721,
          19232,
          264,
          12628,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7279.06,
        "id": 2200,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7278.06,
        "temperature": 0,
        "text": " I think I have to do it within an hour.",
        "tokens": [
          50614,
          286,
          519,
          286,
          362,
          281,
          360,
          309,
          1951,
          364,
          1773,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7281.06,
        "id": 2201,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7279.06,
        "temperature": 0,
        "text": " I really hope I didn't win.",
        "tokens": [
          50664,
          286,
          534,
          1454,
          286,
          994,
          380,
          1942,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7286.06,
        "id": 2202,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7283.06,
        "temperature": 0,
        "text": " Boy, wouldn't that be crazy if I won?",
        "tokens": [
          50864,
          9486,
          11,
          2759,
          380,
          300,
          312,
          3219,
          498,
          286,
          1582,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7290.06,
        "id": 2203,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7287.06,
        "temperature": 0,
        "text": " Hamilton Lottery, Hamilton Lottery.",
        "tokens": [
          51064,
          18484,
          20131,
          12733,
          11,
          18484,
          20131,
          12733,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7293.06,
        "id": 2204,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7290.06,
        "temperature": 0,
        "text": " Unfortunately, you were not selected.",
        "tokens": [
          51214,
          8590,
          11,
          291,
          645,
          406,
          8209,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7295.06,
        "id": 2205,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7293.06,
        "temperature": 0,
        "text": " So, not to worry.",
        "tokens": [
          51364,
          407,
          11,
          406,
          281,
          3292,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7297.06,
        "id": 2206,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7295.06,
        "temperature": 0,
        "text": " I didn't win.",
        "tokens": [
          51464,
          286,
          994,
          380,
          1942,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7299.06,
        "id": 2207,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7297.06,
        "temperature": 0,
        "text": " But maybe next time.",
        "tokens": [
          51564,
          583,
          1310,
          958,
          565,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7300.06,
        "id": 2208,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7299.06,
        "temperature": 0,
        "text": " Okay. When did I start...",
        "tokens": [
          51664,
          1033,
          13,
          1133,
          630,
          286,
          722,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.208506833589994,
        "compression_ratio": 1.6983471074380165,
        "end": 7302.06,
        "id": 2209,
        "no_speech_prob": 0.0027146812062710524,
        "seek": 727306,
        "start": 7300.06,
        "temperature": 0,
        "text": " Oh, when did I start programming?",
        "tokens": [
          51714,
          876,
          11,
          562,
          630,
          286,
          722,
          9410,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7303.06,
        "id": 2210,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7302.06,
        "temperature": 0,
        "text": " And are you using...",
        "tokens": [
          50364,
          400,
          366,
          291,
          1228,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7305.06,
        "id": 2211,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7303.06,
        "temperature": 0,
        "text": " You know what? I forgot something.",
        "tokens": [
          50414,
          509,
          458,
          437,
          30,
          286,
          5298,
          746,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7307.06,
        "id": 2212,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7305.06,
        "temperature": 0,
        "text": " So, this is great, because this question is being asked,",
        "tokens": [
          50514,
          407,
          11,
          341,
          307,
          869,
          11,
          570,
          341,
          1168,
          307,
          885,
          2351,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7309.06,
        "id": 2213,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7307.06,
        "temperature": 0,
        "text": " and I always forget to mention this,",
        "tokens": [
          50614,
          293,
          286,
          1009,
          2870,
          281,
          2152,
          341,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7312.06,
        "id": 2214,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7309.06,
        "temperature": 0,
        "text": " and it came up in a discussion on Facebook recently,",
        "tokens": [
          50714,
          293,
          309,
          1361,
          493,
          294,
          257,
          5017,
          322,
          4384,
          3938,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7314.06,
        "id": 2215,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7312.06,
        "temperature": 0,
        "text": " which is that...",
        "tokens": [
          50864,
          597,
          307,
          300,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7317.06,
        "id": 2216,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7314.06,
        "temperature": 0,
        "text": " So, some people sometimes ask where I first discovered processing",
        "tokens": [
          50964,
          407,
          11,
          512,
          561,
          2171,
          1029,
          689,
          286,
          700,
          6941,
          9007,
          51114
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7319.06,
        "id": 2217,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7317.06,
        "temperature": 0,
        "text": " and how I got involved with it.",
        "tokens": [
          51114,
          293,
          577,
          286,
          658,
          3288,
          365,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7323.06,
        "id": 2218,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7319.06,
        "temperature": 0,
        "text": " And I was a student at ITP between 2001 and 2003.",
        "tokens": [
          51214,
          400,
          286,
          390,
          257,
          3107,
          412,
          6783,
          47,
          1296,
          16382,
          293,
          16416,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7326.06,
        "id": 2219,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7323.06,
        "temperature": 0,
        "text": " And at the time, I was programming in Director,",
        "tokens": [
          51414,
          400,
          412,
          264,
          565,
          11,
          286,
          390,
          9410,
          294,
          7680,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7328.06,
        "id": 2220,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7326.06,
        "temperature": 0,
        "text": " a Macromedia Director.",
        "tokens": [
          51564,
          257,
          5707,
          4397,
          14212,
          7680,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18901781152795863,
        "compression_ratio": 1.625418060200669,
        "end": 7330.06,
        "id": 2221,
        "no_speech_prob": 0.04956651106476784,
        "seek": 730206,
        "start": 7328.06,
        "temperature": 0,
        "text": " I was programming in Java, just plain old Java.",
        "tokens": [
          51664,
          286,
          390,
          9410,
          294,
          10745,
          11,
          445,
          11121,
          1331,
          10745,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7333.06,
        "id": 2222,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7330.06,
        "temperature": 0,
        "text": " And I was programming in C++, plain old C++.",
        "tokens": [
          50364,
          400,
          286,
          390,
          9410,
          294,
          383,
          25472,
          11,
          11121,
          1331,
          383,
          25472,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7335.06,
        "id": 2223,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7333.06,
        "temperature": 0,
        "text": " Open Framework, Cinder.",
        "tokens": [
          50514,
          7238,
          31628,
          1902,
          11,
          383,
          5669,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7337.06,
        "id": 2224,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7335.06,
        "temperature": 0,
        "text": " None of these things existed.",
        "tokens": [
          50614,
          14492,
          295,
          613,
          721,
          13135,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7339.06,
        "id": 2225,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7337.06,
        "temperature": 0,
        "text": " Processing did exist, but I was not aware of it.",
        "tokens": [
          50714,
          31093,
          278,
          630,
          2514,
          11,
          457,
          286,
          390,
          406,
          3650,
          295,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7345.06,
        "id": 2226,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7339.06,
        "temperature": 0,
        "text": " And the first person to run a processing workshop at ITP,",
        "tokens": [
          50814,
          400,
          264,
          700,
          954,
          281,
          1190,
          257,
          9007,
          13541,
          412,
          6783,
          47,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7348.06,
        "id": 2227,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7345.06,
        "temperature": 0,
        "text": " and this is actually still online,",
        "tokens": [
          51114,
          293,
          341,
          307,
          767,
          920,
          2950,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7351.06,
        "id": 2228,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7348.06,
        "temperature": 0,
        "text": " JT Nimoy Processing Workshop.",
        "tokens": [
          51264,
          508,
          51,
          45251,
          939,
          31093,
          278,
          48366,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7354.06,
        "id": 2229,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7351.06,
        "temperature": 0,
        "text": " Notes from this workshop. It's really terrific.",
        "tokens": [
          51414,
          41360,
          490,
          341,
          13541,
          13,
          467,
          311,
          534,
          20899,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18955393670832069,
        "compression_ratio": 1.5225225225225225,
        "end": 7358.06,
        "id": 2230,
        "no_speech_prob": 0.0021488203201442957,
        "seek": 733006,
        "start": 7356.06,
        "temperature": 0,
        "text": " If I can find it...",
        "tokens": [
          51664,
          759,
          286,
          393,
          915,
          309,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7361.06,
        "id": 2231,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7359.06,
        "temperature": 0,
        "text": " How come I can't find it right now?",
        "tokens": [
          50414,
          1012,
          808,
          286,
          393,
          380,
          915,
          309,
          558,
          586,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7363.06,
        "id": 2232,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7361.06,
        "temperature": 0,
        "text": " This is a fail.",
        "tokens": [
          50514,
          639,
          307,
          257,
          3061,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7366.06,
        "id": 2233,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7363.06,
        "temperature": 0,
        "text": " Processing Workshop. Let's put in ITP.",
        "tokens": [
          50614,
          31093,
          278,
          48366,
          13,
          961,
          311,
          829,
          294,
          6783,
          47,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7370.06,
        "id": 2234,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7368.06,
        "temperature": 0,
        "text": " Let's just put in Nimoy.",
        "tokens": [
          50864,
          961,
          311,
          445,
          829,
          294,
          45251,
          939,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7373.06,
        "id": 2235,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7371.06,
        "temperature": 0,
        "text": " There we go. Here it is.",
        "tokens": [
          51014,
          821,
          321,
          352,
          13,
          1692,
          309,
          307,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7378.06,
        "id": 2236,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7373.06,
        "temperature": 0,
        "text": " So, this is a tutorial from, I believe, 2003.",
        "tokens": [
          51114,
          407,
          11,
          341,
          307,
          257,
          7073,
          490,
          11,
          286,
          1697,
          11,
          16416,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7380.06,
        "id": 2237,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7378.06,
        "temperature": 0,
        "text": " You can read it from...",
        "tokens": [
          51364,
          509,
          393,
          1401,
          309,
          490,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7382.06,
        "id": 2238,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7380.06,
        "temperature": 0,
        "text": " First year of ITP, Dettelev Social Engineering,",
        "tokens": [
          51464,
          2386,
          1064,
          295,
          6783,
          47,
          11,
          413,
          3093,
          338,
          13379,
          9909,
          16215,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.27088773016836126,
        "compression_ratio": 1.4,
        "end": 7384.06,
        "id": 2239,
        "no_speech_prob": 0.000015206046555249486,
        "seek": 735806,
        "start": 7382.06,
        "temperature": 0,
        "text": " to bring open source culture to attention.",
        "tokens": [
          51564,
          281,
          1565,
          1269,
          4009,
          3713,
          281,
          3202,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7388.06,
        "id": 2240,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7385.06,
        "temperature": 0,
        "text": " I taught early releases of processing to students and faculty,",
        "tokens": [
          50414,
          286,
          5928,
          2440,
          16952,
          295,
          9007,
          281,
          1731,
          293,
          6389,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7392.06,
        "id": 2241,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7388.06,
        "temperature": 0,
        "text": " and current faculty who were students then, myself included,",
        "tokens": [
          50564,
          293,
          2190,
          6389,
          567,
          645,
          1731,
          550,
          11,
          2059,
          5556,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7396.06,
        "id": 2242,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7392.06,
        "temperature": 0,
        "text": " and chose to use processing to create a number of projects.",
        "tokens": [
          50764,
          293,
          5111,
          281,
          764,
          9007,
          281,
          1884,
          257,
          1230,
          295,
          4455,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7399.06,
        "id": 2243,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7396.06,
        "temperature": 0,
        "text": " Processing actually had two fives in the name.",
        "tokens": [
          50964,
          31093,
          278,
          767,
          632,
          732,
          283,
          1539,
          294,
          264,
          1315,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7402.06,
        "id": 2244,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7399.06,
        "temperature": 0,
        "text": " Then, because of the URL, processing was not available.",
        "tokens": [
          51114,
          1396,
          11,
          570,
          295,
          264,
          12905,
          11,
          9007,
          390,
          406,
          2435,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7406.06,
        "id": 2245,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7402.06,
        "temperature": 0,
        "text": " And so this workshop, which you can see here,",
        "tokens": [
          51264,
          400,
          370,
          341,
          13541,
          11,
          597,
          291,
          393,
          536,
          510,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7409.06,
        "id": 2246,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7406.06,
        "temperature": 0,
        "text": " and then by the fall semester, 2004,",
        "tokens": [
          51464,
          293,
          550,
          538,
          264,
          2100,
          11894,
          11,
          15817,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.22605033874511718,
        "compression_ratio": 1.6639004149377594,
        "end": 7411.06,
        "id": 2247,
        "no_speech_prob": 0.01665245182812214,
        "seek": 738406,
        "start": 7409.06,
        "temperature": 0,
        "text": " processing was adopted into the",
        "tokens": [
          51614,
          9007,
          390,
          12175,
          666,
          264,
          51714
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7413.06,
        "id": 2248,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7411.06,
        "temperature": 0,
        "text": " Introduction to Computational Media course series",
        "tokens": [
          50364,
          27193,
          882,
          281,
          37804,
          1478,
          14741,
          1164,
          2638,
          50464
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7415.06,
        "id": 2249,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7413.06,
        "temperature": 0,
        "text": " as a primary teaching tool.",
        "tokens": [
          50464,
          382,
          257,
          6194,
          4571,
          2290,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7417.06,
        "id": 2250,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7415.06,
        "temperature": 0,
        "text": " So, if you're interested in a little history,",
        "tokens": [
          50564,
          407,
          11,
          498,
          291,
          434,
          3102,
          294,
          257,
          707,
          2503,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7422.06,
        "id": 2251,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7417.06,
        "temperature": 0,
        "text": " the original date of this was Saturday, February 8, 2003.",
        "tokens": [
          50664,
          264,
          3380,
          4002,
          295,
          341,
          390,
          8803,
          11,
          8711,
          1649,
          11,
          16416,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7424.06,
        "id": 2252,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7422.06,
        "temperature": 0,
        "text": " And you can look at the tutorial. It's both in English,",
        "tokens": [
          50914,
          400,
          291,
          393,
          574,
          412,
          264,
          7073,
          13,
          467,
          311,
          1293,
          294,
          3669,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7427.06,
        "id": 2253,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7424.06,
        "temperature": 0,
        "text": " and it was also translated in Japanese.",
        "tokens": [
          51014,
          293,
          309,
          390,
          611,
          16805,
          294,
          5433,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7429.06,
        "id": 2254,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7427.06,
        "temperature": 0,
        "text": " And you can find this tutorial, and you can see",
        "tokens": [
          51164,
          400,
          291,
          393,
          915,
          341,
          7073,
          11,
          293,
          291,
          393,
          536,
          51264
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7431.06,
        "id": 2255,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7429.06,
        "temperature": 0,
        "text": " what's interesting about this is to see",
        "tokens": [
          51264,
          437,
          311,
          1880,
          466,
          341,
          307,
          281,
          536,
          51364
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7434.06,
        "id": 2256,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7431.06,
        "temperature": 0,
        "text": " it's comparing it to Flash.",
        "tokens": [
          51364,
          309,
          311,
          15763,
          309,
          281,
          20232,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7438.06,
        "id": 2257,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7434.06,
        "temperature": 0,
        "text": " And I remember looking at this tutorial and being fascinated and amazed by it.",
        "tokens": [
          51514,
          400,
          286,
          1604,
          1237,
          412,
          341,
          7073,
          293,
          885,
          24597,
          293,
          20507,
          538,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1937878114957336,
        "compression_ratio": 1.7243589743589745,
        "end": 7440.06,
        "id": 2258,
        "no_speech_prob": 0.2252855896949768,
        "seek": 741106,
        "start": 7438.06,
        "temperature": 0,
        "text": " And this, I think, is really an inspiration to a lot of the stuff",
        "tokens": [
          51714,
          400,
          341,
          11,
          286,
          519,
          11,
          307,
          534,
          364,
          10249,
          281,
          257,
          688,
          295,
          264,
          1507,
          51814
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7442.06,
        "id": 2259,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7440.06,
        "temperature": 0,
        "text": " that I did with teaching and processing.",
        "tokens": [
          50364,
          300,
          286,
          630,
          365,
          4571,
          293,
          9007,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7443.06,
        "id": 2260,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7442.06,
        "temperature": 0,
        "text": " Right, time and motion here.",
        "tokens": [
          50464,
          1779,
          11,
          565,
          293,
          5394,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7444.06,
        "id": 2261,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7443.06,
        "temperature": 0,
        "text": " So, I encourage you to check this out.",
        "tokens": [
          50514,
          407,
          11,
          286,
          5373,
          291,
          281,
          1520,
          341,
          484,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7450.06,
        "id": 2262,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7444.06,
        "temperature": 0,
        "text": " Also, at the time, Amit Pataru was teaching a class called Code and Me.",
        "tokens": [
          50564,
          2743,
          11,
          412,
          264,
          565,
          11,
          2012,
          270,
          4379,
          16870,
          390,
          4571,
          257,
          1508,
          1219,
          15549,
          293,
          1923,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7453.06,
        "id": 2263,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7450.06,
        "temperature": 0,
        "text": " I wonder if there's any documentation of this online.",
        "tokens": [
          50864,
          286,
          2441,
          498,
          456,
          311,
          604,
          14333,
          295,
          341,
          2950,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7459.06,
        "id": 2264,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7453.06,
        "temperature": 0,
        "text": " Archives, Code and Me.",
        "tokens": [
          51014,
          39258,
          11,
          15549,
          293,
          1923,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22963331033895304,
        "compression_ratio": 1.5380952380952382,
        "end": 7463.06,
        "id": 2265,
        "no_speech_prob": 0.03513694182038307,
        "seek": 744006,
        "start": 7459.06,
        "temperature": 0,
        "text": " So, anyway, if somebody wants to try to do some internet research",
        "tokens": [
          51314,
          407,
          11,
          4033,
          11,
          498,
          2618,
          2738,
          281,
          853,
          281,
          360,
          512,
          4705,
          2132,
          51514
        ]
      },
      {
        "avg_logprob": -0.21267142119231047,
        "compression_ratio": 1.5688073394495412,
        "end": 7471.06,
        "id": 2266,
        "no_speech_prob": 0.4565562307834625,
        "seek": 746306,
        "start": 7463.06,
        "temperature": 0,
        "text": " and can find the Code and Me Amit syllabus,",
        "tokens": [
          50364,
          293,
          393,
          915,
          264,
          15549,
          293,
          1923,
          2012,
          270,
          48077,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.21267142119231047,
        "compression_ratio": 1.5688073394495412,
        "end": 7474.06,
        "id": 2267,
        "no_speech_prob": 0.4565562307834625,
        "seek": 746306,
        "start": 7471.06,
        "temperature": 0,
        "text": " see if you can find it.",
        "tokens": [
          50764,
          536,
          498,
          291,
          393,
          915,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21267142119231047,
        "compression_ratio": 1.5688073394495412,
        "end": 7478.06,
        "id": 2268,
        "no_speech_prob": 0.4565562307834625,
        "seek": 746306,
        "start": 7474.06,
        "temperature": 0,
        "text": " There's Amit on Twitter, and I believe JT Nimoy on Twitter is at JT Nimoy as well.",
        "tokens": [
          50914,
          821,
          311,
          2012,
          270,
          322,
          5794,
          11,
          293,
          286,
          1697,
          508,
          51,
          45251,
          939,
          322,
          5794,
          307,
          412,
          508,
          51,
          45251,
          939,
          382,
          731,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21267142119231047,
        "compression_ratio": 1.5688073394495412,
        "end": 7482.06,
        "id": 2269,
        "no_speech_prob": 0.4565562307834625,
        "seek": 746306,
        "start": 7478.06,
        "temperature": 0,
        "text": " And JT has done all sorts of amazing stuff, a lot of graphics for Tron,",
        "tokens": [
          51114,
          400,
          508,
          51,
          575,
          1096,
          439,
          7527,
          295,
          2243,
          1507,
          11,
          257,
          688,
          295,
          11837,
          337,
          1765,
          266,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.21267142119231047,
        "compression_ratio": 1.5688073394495412,
        "end": 7486.06,
        "id": 2270,
        "no_speech_prob": 0.4565562307834625,
        "seek": 746306,
        "start": 7482.06,
        "temperature": 0,
        "text": " and I encourage you to check out the work of JT Nimoy as well.",
        "tokens": [
          51314,
          293,
          286,
          5373,
          291,
          281,
          1520,
          484,
          264,
          589,
          295,
          508,
          51,
          45251,
          939,
          382,
          731,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21267142119231047,
        "compression_ratio": 1.5688073394495412,
        "end": 7490.06,
        "id": 2271,
        "no_speech_prob": 0.4565562307834625,
        "seek": 746306,
        "start": 7486.06,
        "temperature": 0,
        "text": " Okay, so I wanted to bring that up because it's come up.",
        "tokens": [
          51514,
          1033,
          11,
          370,
          286,
          1415,
          281,
          1565,
          300,
          493,
          570,
          309,
          311,
          808,
          493,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7492.06,
        "id": 2272,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7490.06,
        "temperature": 0,
        "text": " It's come up and, oh, I didn't pause the song.",
        "tokens": [
          50364,
          467,
          311,
          808,
          493,
          293,
          11,
          1954,
          11,
          286,
          994,
          380,
          10465,
          264,
          2153,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7494.06,
        "id": 2273,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7492.06,
        "temperature": 0,
        "text": " So, let's see.",
        "tokens": [
          50464,
          407,
          11,
          718,
          311,
          536,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7497.06,
        "id": 2274,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7494.06,
        "temperature": 0,
        "text": " Oh, can you give some more info about the application process",
        "tokens": [
          50564,
          876,
          11,
          393,
          291,
          976,
          512,
          544,
          13614,
          466,
          264,
          3861,
          1399,
          50714
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7500.06,
        "id": 2275,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7497.06,
        "temperature": 0,
        "text": " for the Processing Fellowship?",
        "tokens": [
          50714,
          337,
          264,
          31093,
          278,
          40011,
          1210,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7503.06,
        "id": 2276,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7500.06,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50864,
          1079,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7505.06,
        "id": 2277,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7503.06,
        "temperature": 0,
        "text": " We pause.",
        "tokens": [
          51014,
          492,
          10465,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7507.06,
        "id": 2278,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7505.06,
        "temperature": 0,
        "text": " Processing Foundation Fellowships.",
        "tokens": [
          51114,
          31093,
          278,
          10335,
          40011,
          7640,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7510.06,
        "id": 2279,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7507.06,
        "temperature": 0,
        "text": " So, this is the application process.",
        "tokens": [
          51214,
          407,
          11,
          341,
          307,
          264,
          3861,
          1399,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7515.06,
        "id": 2280,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7510.06,
        "temperature": 0,
        "text": " The deadline is December 19th, so you have several weeks still.",
        "tokens": [
          51364,
          440,
          20615,
          307,
          7687,
          1294,
          392,
          11,
          370,
          291,
          362,
          2940,
          3259,
          920,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19651648141805408,
        "compression_ratio": 1.5806451612903225,
        "end": 7517.06,
        "id": 2281,
        "no_speech_prob": 0.09665755182504654,
        "seek": 749006,
        "start": 7515.06,
        "temperature": 0,
        "text": " I would read through this whole page,",
        "tokens": [
          51614,
          286,
          576,
          1401,
          807,
          341,
          1379,
          3028,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7522.06,
        "id": 2282,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7517.06,
        "temperature": 0,
        "text": " and then I would look at what the fellowships were from last year,",
        "tokens": [
          50364,
          293,
          550,
          286,
          576,
          574,
          412,
          437,
          264,
          24989,
          82,
          645,
          490,
          1036,
          1064,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7524.06,
        "id": 2283,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7522.06,
        "temperature": 0,
        "text": " and to apply, there's a Google form,",
        "tokens": [
          50614,
          293,
          281,
          3079,
          11,
          456,
          311,
          257,
          3329,
          1254,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7527.06,
        "id": 2284,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7524.06,
        "temperature": 0,
        "text": " and the Google form will go through.",
        "tokens": [
          50714,
          293,
          264,
          3329,
          1254,
          486,
          352,
          807,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7529.06,
        "id": 2285,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7527.06,
        "temperature": 0,
        "text": " You need to write a description of the project.",
        "tokens": [
          50864,
          509,
          643,
          281,
          2464,
          257,
          3855,
          295,
          264,
          1716,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7532.06,
        "id": 2286,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7529.06,
        "temperature": 0,
        "text": " You need to write up a plan for the project and schedule for it.",
        "tokens": [
          50964,
          509,
          643,
          281,
          2464,
          493,
          257,
          1393,
          337,
          264,
          1716,
          293,
          7567,
          337,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7536.06,
        "id": 2287,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7532.06,
        "temperature": 0,
        "text": " And the other thing, maybe it's on the –",
        "tokens": [
          51114,
          400,
          264,
          661,
          551,
          11,
          1310,
          309,
          311,
          322,
          264,
          220,
          5815,
          51314
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7542.06,
        "id": 2288,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7536.06,
        "temperature": 0,
        "text": " the link maybe is on the application submission form,",
        "tokens": [
          51314,
          264,
          2113,
          1310,
          307,
          322,
          264,
          3861,
          23689,
          1254,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20582350662776402,
        "compression_ratio": 1.7413793103448276,
        "end": 7545.06,
        "id": 2289,
        "no_speech_prob": 0.09008703380823135,
        "seek": 751706,
        "start": 7542.06,
        "temperature": 0,
        "text": " but what I'm looking for, which I'm looking for here,",
        "tokens": [
          51614,
          457,
          437,
          286,
          478,
          1237,
          337,
          11,
          597,
          286,
          478,
          1237,
          337,
          510,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7550.06,
        "id": 2290,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7545.06,
        "temperature": 0,
        "text": " something that's important, I'm not seeing it just scanning through very quickly.",
        "tokens": [
          50364,
          746,
          300,
          311,
          1021,
          11,
          286,
          478,
          406,
          2577,
          309,
          445,
          27019,
          807,
          588,
          2661,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7553.06,
        "id": 2291,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7550.06,
        "temperature": 0,
        "text": " Project ideas, ideas.",
        "tokens": [
          50614,
          9849,
          3487,
          11,
          3487,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7555.06,
        "id": 2292,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7553.06,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50764,
          2438,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7559.06,
        "id": 2293,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7555.06,
        "temperature": 0,
        "text": " So, this link here, applicants are encouraged to familiarize themselves",
        "tokens": [
          50864,
          407,
          11,
          341,
          2113,
          510,
          11,
          28767,
          366,
          14658,
          281,
          4963,
          1125,
          2969,
          51064
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7561.06,
        "id": 2294,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7559.06,
        "temperature": 0,
        "text": " with the list of fellowship ideas.",
        "tokens": [
          51064,
          365,
          264,
          1329,
          295,
          24989,
          3487,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7566.06,
        "id": 2295,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7561.06,
        "temperature": 0,
        "text": " This is another page which has some more ideas about the kinds of things",
        "tokens": [
          51164,
          639,
          307,
          1071,
          3028,
          597,
          575,
          512,
          544,
          3487,
          466,
          264,
          3685,
          295,
          721,
          51414
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7567.06,
        "id": 2296,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7566.06,
        "temperature": 0,
        "text": " that we're thinking about.",
        "tokens": [
          51414,
          300,
          321,
          434,
          1953,
          466,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7570.06,
        "id": 2297,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7567.06,
        "temperature": 0,
        "text": " You do not need to propose something on this list,",
        "tokens": [
          51464,
          509,
          360,
          406,
          643,
          281,
          17421,
          746,
          322,
          341,
          1329,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20095623864067924,
        "compression_ratio": 1.6179775280898876,
        "end": 7572.06,
        "id": 2298,
        "no_speech_prob": 0.007011649198830128,
        "seek": 754506,
        "start": 7570.06,
        "temperature": 0,
        "text": " but if you're trying to brainstorm or think about what's possible,",
        "tokens": [
          51614,
          457,
          498,
          291,
          434,
          1382,
          281,
          35245,
          420,
          519,
          466,
          437,
          311,
          1944,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7575.06,
        "id": 2299,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7572.06,
        "temperature": 0,
        "text": " I would encourage you to check out this list as well,",
        "tokens": [
          50364,
          286,
          576,
          5373,
          291,
          281,
          1520,
          484,
          341,
          1329,
          382,
          731,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7580.06,
        "id": 2300,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7575.06,
        "temperature": 0,
        "text": " and I'll make sure to include links to the fellowship page, the application,",
        "tokens": [
          50514,
          293,
          286,
          603,
          652,
          988,
          281,
          4090,
          6123,
          281,
          264,
          24989,
          3028,
          11,
          264,
          3861,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7585.06,
        "id": 2301,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7580.06,
        "temperature": 0,
        "text": " and this GitHub page in this archive's description.",
        "tokens": [
          50764,
          293,
          341,
          23331,
          3028,
          294,
          341,
          23507,
          311,
          3855,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7588.06,
        "id": 2302,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7585.06,
        "temperature": 0,
        "text": " The live stream is over, unfortunately.",
        "tokens": [
          51014,
          440,
          1621,
          4309,
          307,
          670,
          11,
          7015,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7591.06,
        "id": 2303,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7588.06,
        "temperature": 0,
        "text": " It has been going for two hours and ten minutes,",
        "tokens": [
          51164,
          467,
          575,
          668,
          516,
          337,
          732,
          2496,
          293,
          2064,
          2077,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7594.06,
        "id": 2304,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7591.06,
        "temperature": 0,
        "text": " and I'm actually going to tonight, if you're in New York City,",
        "tokens": [
          51314,
          293,
          286,
          478,
          767,
          516,
          281,
          4440,
          11,
          498,
          291,
          434,
          294,
          1873,
          3609,
          4392,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.22260487754389924,
        "compression_ratio": 1.5615384615384615,
        "end": 7598.06,
        "id": 2305,
        "no_speech_prob": 0.07158597558736801,
        "seek": 757206,
        "start": 7594.06,
        "temperature": 0,
        "text": " I encourage you to – one of the fellows from last year is Tiga Brain,",
        "tokens": [
          51464,
          286,
          5373,
          291,
          281,
          1662,
          472,
          295,
          264,
          35595,
          490,
          1036,
          1064,
          307,
          314,
          9900,
          29783,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7603.06,
        "id": 2306,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7598.06,
        "temperature": 0,
        "text": " who did a guest ICP Learn to Teach.",
        "tokens": [
          50364,
          567,
          630,
          257,
          8341,
          14360,
          47,
          17216,
          281,
          26816,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7605.06,
        "id": 2307,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7603.06,
        "temperature": 0,
        "text": " This event I want to get to.",
        "tokens": [
          50614,
          639,
          2280,
          286,
          528,
          281,
          483,
          281,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7606.06,
        "id": 2308,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7605.06,
        "temperature": 0,
        "text": " It starts at 6.30.",
        "tokens": [
          50714,
          467,
          3719,
          412,
          1386,
          13,
          3446,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7608.06,
        "id": 2309,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7606.06,
        "temperature": 0,
        "text": " I have a bunch of things to do beforehand.",
        "tokens": [
          50764,
          286,
          362,
          257,
          3840,
          295,
          721,
          281,
          360,
          22893,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7610.06,
        "id": 2310,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7608.06,
        "temperature": 0,
        "text": " Ah, I really have to go.",
        "tokens": [
          50864,
          2438,
          11,
          286,
          534,
          362,
          281,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7613.06,
        "id": 2311,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7610.06,
        "temperature": 0,
        "text": " Learning to Teach is an event here in New York City",
        "tokens": [
          50964,
          15205,
          281,
          26816,
          307,
          364,
          2280,
          510,
          294,
          1873,
          3609,
          4392,
          51114
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7616.06,
        "id": 2312,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7613.06,
        "temperature": 0,
        "text": " co-organized by the Processing Foundation,",
        "tokens": [
          51114,
          598,
          12,
          12372,
          1602,
          538,
          264,
          31093,
          278,
          10335,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7620.06,
        "id": 2313,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7616.06,
        "temperature": 0,
        "text": " and Tiga Brain will be presenting there along with DeAngela Duff,",
        "tokens": [
          51264,
          293,
          314,
          9900,
          29783,
          486,
          312,
          15578,
          456,
          2051,
          365,
          1346,
          23156,
          4053,
          413,
          1245,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7621.06,
        "id": 2314,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7620.06,
        "temperature": 0,
        "text": " who is also amazing.",
        "tokens": [
          51464,
          567,
          307,
          611,
          2243,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7623.06,
        "id": 2315,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7621.06,
        "temperature": 0,
        "text": " I should have her as a guest, and Ankit Patel,",
        "tokens": [
          51514,
          286,
          820,
          362,
          720,
          382,
          257,
          8341,
          11,
          293,
          1107,
          22681,
          4379,
          338,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.18087855914166864,
        "compression_ratio": 1.5326086956521738,
        "end": 7625.06,
        "id": 2316,
        "no_speech_prob": 0.1559879332780838,
        "seek": 759806,
        "start": 7623.06,
        "temperature": 0,
        "text": " who works for the Department of Education,",
        "tokens": [
          51614,
          567,
          1985,
          337,
          264,
          5982,
          295,
          10680,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7630.06,
        "id": 2317,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7625.06,
        "temperature": 0,
        "text": " and BBQ Dave Sheinkopf about education and creative coding.",
        "tokens": [
          50364,
          293,
          19168,
          48,
          11017,
          1240,
          475,
          21828,
          466,
          3309,
          293,
          5880,
          17720,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7632.06,
        "id": 2318,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7630.06,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7633.06,
        "id": 2319,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7632.06,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50714,
          1057,
          558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7634.06,
        "id": 2320,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7633.06,
        "temperature": 0,
        "text": " So I really have got to go.",
        "tokens": [
          50764,
          407,
          286,
          534,
          362,
          658,
          281,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7640.06,
        "id": 2321,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7634.06,
        "temperature": 0,
        "text": " I thank you all so much for tuning in, for watching, for being supportive.",
        "tokens": [
          50814,
          286,
          1309,
          291,
          439,
          370,
          709,
          337,
          15164,
          294,
          11,
          337,
          1976,
          11,
          337,
          885,
          14435,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7642.06,
        "id": 2322,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7640.06,
        "temperature": 0,
        "text": " I feel like today was kind of a mess, but I often feel that way,",
        "tokens": [
          51114,
          286,
          841,
          411,
          965,
          390,
          733,
          295,
          257,
          2082,
          11,
          457,
          286,
          2049,
          841,
          300,
          636,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7646.06,
        "id": 2323,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7642.06,
        "temperature": 0,
        "text": " and then people seem to think it was fine anyway.",
        "tokens": [
          51214,
          293,
          550,
          561,
          1643,
          281,
          519,
          309,
          390,
          2489,
          4033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7649.06,
        "id": 2324,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7646.06,
        "temperature": 0,
        "text": " And so out of this I think what really only comes –",
        "tokens": [
          51414,
          400,
          370,
          484,
          295,
          341,
          286,
          519,
          437,
          534,
          787,
          1487,
          1662,
          51564
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7652.06,
        "id": 2325,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7649.06,
        "temperature": 0,
        "text": " maybe those should be separated into more than two videos.",
        "tokens": [
          51564,
          1310,
          729,
          820,
          312,
          12005,
          666,
          544,
          813,
          732,
          2145,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21768696581731078,
        "compression_ratio": 1.5503597122302157,
        "end": 7653.06,
        "id": 2326,
        "no_speech_prob": 0.5503641366958618,
        "seek": 762506,
        "start": 7652.06,
        "temperature": 0,
        "text": " We'll think about that.",
        "tokens": [
          51714,
          492,
          603,
          519,
          466,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7655.06,
        "id": 2327,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7653.06,
        "temperature": 0,
        "text": " But certainly there's the sentiment analysis coding challenge",
        "tokens": [
          50364,
          583,
          3297,
          456,
          311,
          264,
          16149,
          5215,
          17720,
          3430,
          50464
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7660.06,
        "id": 2328,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7655.06,
        "temperature": 0,
        "text": " and the sentiment analysis node API video,",
        "tokens": [
          50464,
          293,
          264,
          16149,
          5215,
          9984,
          9362,
          960,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7662.06,
        "id": 2329,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7660.06,
        "temperature": 0,
        "text": " and next week I'll be back with hopefully Chrome extensions",
        "tokens": [
          50714,
          293,
          958,
          1243,
          286,
          603,
          312,
          646,
          365,
          4696,
          15327,
          25129,
          50814
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7664.06,
        "id": 2330,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7662.06,
        "temperature": 0,
        "text": " or more about a data persistence.",
        "tokens": [
          50814,
          420,
          544,
          466,
          257,
          1412,
          37617,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7665.06,
        "id": 2331,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7664.06,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7668.06,
        "id": 2332,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7665.06,
        "temperature": 0,
        "text": " And I'll see you guys in the future.",
        "tokens": [
          50964,
          400,
          286,
          603,
          536,
          291,
          1074,
          294,
          264,
          2027,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7670.06,
        "id": 2333,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7668.06,
        "temperature": 0,
        "text": " Stay in touch.",
        "tokens": [
          51114,
          8691,
          294,
          2557,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7673.06,
        "id": 2334,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7670.06,
        "temperature": 0,
        "text": " Next week I don't know if I'll have a live stream next week just yet.",
        "tokens": [
          51214,
          3087,
          1243,
          286,
          500,
          380,
          458,
          498,
          286,
          603,
          362,
          257,
          1621,
          4309,
          958,
          1243,
          445,
          1939,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7674.06,
        "id": 2335,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7673.06,
        "temperature": 0,
        "text": " Stay tuned to Twitter.",
        "tokens": [
          51364,
          8691,
          10870,
          281,
          5794,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7676.06,
        "id": 2336,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7674.06,
        "temperature": 0,
        "text": " I forgot to announce this on Twitter today.",
        "tokens": [
          51414,
          286,
          5298,
          281,
          7478,
          341,
          322,
          5794,
          965,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23303130521612653,
        "compression_ratio": 1.6014492753623188,
        "end": 7679.06,
        "id": 2337,
        "no_speech_prob": 0.7742584347724915,
        "seek": 765306,
        "start": 7676.06,
        "temperature": 0,
        "text": " Still had 200 viewers, which is kind of amazing.",
        "tokens": [
          51514,
          8291,
          632,
          2331,
          8499,
          11,
          597,
          307,
          733,
          295,
          2243,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25064679980278015,
        "compression_ratio": 1.1012658227848102,
        "end": 7683.06,
        "id": 2338,
        "no_speech_prob": 0.19676968455314636,
        "seek": 767906,
        "start": 7679.06,
        "temperature": 0,
        "text": " And I'll see you all soon.",
        "tokens": [
          50364,
          400,
          286,
          603,
          536,
          291,
          439,
          2321,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25064679980278015,
        "compression_ratio": 1.1012658227848102,
        "end": 7687.06,
        "id": 2339,
        "no_speech_prob": 0.19676968455314636,
        "seek": 767906,
        "start": 7683.06,
        "temperature": 0,
        "text": " Thank you all.",
        "tokens": [
          50564,
          1044,
          291,
          439,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.25064679980278015,
        "compression_ratio": 1.1012658227848102,
        "end": 7690.06,
        "id": 2340,
        "no_speech_prob": 0.19676968455314636,
        "seek": 767906,
        "start": 7687.06,
        "temperature": 0,
        "text": " I'll play the This song as I turn things off.",
        "tokens": [
          50764,
          286,
          603,
          862,
          264,
          639,
          2153,
          382,
          286,
          1261,
          721,
          766,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7693.06,
        "id": 2341,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7690.06,
        "temperature": 0,
        "text": " I always forget the this dot, this dot, this dot, this dot.",
        "tokens": [
          50364,
          286,
          1009,
          2870,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7695.06,
        "id": 2342,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7693.06,
        "temperature": 0,
        "text": " I'm going to do this dot, this dot.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7697.06,
        "id": 2343,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7695.06,
        "temperature": 0,
        "text": " I'm going to do this dot, this dot, this dot.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7699.06,
        "id": 2344,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7697.06,
        "temperature": 0,
        "text": " I'm going to do this dot, this dot.",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7700.06,
        "id": 2345,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7699.06,
        "temperature": 0,
        "text": " I'm going to do this dot, this dot, this dot.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          360,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7701.06,
        "id": 2346,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7700.06,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7707.06,
        "id": 2347,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7701.06,
        "temperature": 0,
        "text": " I'm going to pull up a blank screen, but you'll be able to listen to the rest of the song.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          2235,
          493,
          257,
          8247,
          2568,
          11,
          457,
          291,
          603,
          312,
          1075,
          281,
          2140,
          281,
          264,
          1472,
          295,
          264,
          2153,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7711.06,
        "id": 2348,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7707.06,
        "temperature": 0,
        "text": " You can't hear the song on that blank screen because I don't have the audio typed into that.",
        "tokens": [
          51214,
          509,
          393,
          380,
          1568,
          264,
          2153,
          322,
          300,
          8247,
          2568,
          570,
          286,
          500,
          380,
          362,
          264,
          6278,
          33941,
          666,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7712.06,
        "id": 2349,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7711.06,
        "temperature": 0,
        "text": " Wire cast.",
        "tokens": [
          51414,
          32598,
          4193,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22696176293778092,
        "compression_ratio": 2.3402061855670104,
        "end": 7714.06,
        "id": 2350,
        "no_speech_prob": 0.9342366456985474,
        "seek": 769006,
        "start": 7712.06,
        "temperature": 0,
        "text": " Anyway, I'll just stand here.",
        "tokens": [
          51464,
          5684,
          11,
          286,
          603,
          445,
          1463,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.31071084918397845,
        "compression_ratio": 1.1222222222222222,
        "end": 7727.06,
        "id": 2351,
        "no_speech_prob": 0.5958928465843201,
        "seek": 771406,
        "start": 7715.06,
        "temperature": 0,
        "text": " While I look and check out my e-mail, I see all the messages.",
        "tokens": [
          50414,
          3987,
          286,
          574,
          293,
          1520,
          484,
          452,
          308,
          12,
          11799,
          11,
          286,
          536,
          439,
          264,
          7897,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.31071084918397845,
        "compression_ratio": 1.1222222222222222,
        "end": 7729.06,
        "id": 2352,
        "no_speech_prob": 0.5958928465843201,
        "seek": 771406,
        "start": 7727.06,
        "temperature": 0,
        "text": " When the song's over, I'll say goodbye.",
        "tokens": [
          51014,
          1133,
          264,
          2153,
          311,
          670,
          11,
          286,
          603,
          584,
          12084,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7748.06,
        "id": 2353,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7745.06,
        "temperature": 0,
        "text": " This dot, this dot, this dot.",
        "tokens": [
          50414,
          639,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7750.06,
        "id": 2354,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7748.06,
        "temperature": 0,
        "text": " Never forget the this dot.",
        "tokens": [
          50564,
          7344,
          2870,
          264,
          341,
          5893,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7753.06,
        "id": 2355,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7750.06,
        "temperature": 0,
        "text": " I'm going to do the this dot, this dot, this dot, this dot.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          360,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7754.06,
        "id": 2356,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7753.06,
        "temperature": 0,
        "text": " The this dot song.",
        "tokens": [
          50814,
          440,
          341,
          5893,
          2153,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7756.06,
        "id": 2357,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7754.06,
        "temperature": 0,
        "text": " Never forget the this dot.",
        "tokens": [
          50864,
          7344,
          2870,
          264,
          341,
          5893,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7758.06,
        "id": 2358,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7756.06,
        "temperature": 0,
        "text": " Somebody compose that song for me.",
        "tokens": [
          50964,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7759.06,
        "id": 2359,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7758.06,
        "temperature": 0,
        "text": " Thanks for watching, everybody.",
        "tokens": [
          51064,
          2561,
          337,
          1976,
          11,
          2201,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17835244154318786,
        "compression_ratio": 1.9365079365079365,
        "end": 7761.06,
        "id": 2360,
        "no_speech_prob": 0.10966993868350983,
        "seek": 774406,
        "start": 7759.06,
        "temperature": 0,
        "text": " See you later.",
        "tokens": [
          51114,
          3008,
          291,
          1780,
          13,
          51214
        ]
      }
    ],
    "transcription": " Did you think that learning coding would be really rough? Throw your hands up in the air and say, enough's enough! Do you want to learn to code and make some awesome stuff? Learn that anyone can when you're coding with Dan on! Whether you're a pro or this is all brand new, learn the overarching concepts and some fun stuff too! And with Dan as your guide, come along for the ride on! Make a crazy pixel mirror to reflect your face, you can make a jump to light speed into outer space, you can generate a maze that can go on for days, you can make your own terrain and some purple rain, you can make a retro game to see how it's done, and then tweak a piece to make it yours for everyone! Make some fractally trees or twitter bots if you please, and when the seeds are a stone, you can make them your own! Run the colors of code, you can follow the road too! Hello, welcome to another episode of... I don't know what it is. Okay, so hopefully you're there and watching. I am here. It's been two weeks since I've been here on the YouTube. And I'm very excited and glad to be back. And this has been a very tricky month with busy end of semester for me, with my other job, and with the holidays that have been here in New York, this crazy election thing that happened, which I am upsetting on so many different kinds of levels. But here I am anyway, alive in this room here at the School for Poetic Computation in the West Village of New York City. And it's around 3.20 p.m. I don't think it's December yet. I'm pretty sure it's still just November. Please don't be November. Actually, you know what? December. Fine, let's bring on December. Bring on 2000. Some jump, let's jump a bunch of years into the future. And maybe that'll be a good thing. Anyway, what's up with the colors? Is anything looking weird? Am I, you know, I have a little, I have some, I'm sort of lighting challenged. So I don't know if there's some weird colored things going on. And, but yes, I did have a haircut. Thank you for noticing. I don't know. This is probably not what you tuned in for, or perhaps it is what you tuned in for. So what's going on with this thing? So my name is Dan. I do live streams on YouTube weekly, except for the weeks where that I miss, like last week, where I demonstrate a variety of different programming, coding techniques, generally in the creative sphere of applications. So look at generative algorithms for visual art, different kinds of algorithms for generating and analyzing text, which has been my focus this fall. I noticed somebody in the chat mentioned, mentioned, somebody in the chat mentioned machine learning. And that's actually on my list of topics. That's going to be one of my main focuses this spring in the new year in 2017. But so today, what I wanted to do, I want to do a couple things. One is I want to talk about the processing fellowships, which might be something that you aren't aware of. So I'm gonna spend a little time talking about the processing foundation and the fellowship program that's out now that any of you might be interested in, interested in applying to. Sorry, I'm trying to keep an eye on the chat, which it's very difficult to have this, to speak and have a continuous thought and read a chat at the same time. Hi, Arson. Arson, yes, I do remember. And yes, there will be JavaScript stuff today. So the coding that I will do after I talk about the processing fellowships, I'm going to look at sentiment analysis with a word list known as the AFIN111. Is that what you woke? You were like, you're lying in bed. Your alarm went off. And you woke up and you thought, I know what I'm going to do today. I'm going to turn off my computer. I'm going to watch somebody talk about AFIN111 sentiment analysis on YouTube. Well, that's what's happening. Oh, yeah. By the way, I noticed that Lourdes in the chat mentions everyone check out Siraj's channel. I noticed, actually, I got a notification that Siraj was also doing a live stream. Does anyone know if that's still going on? Let's pull it up. Let's see if we can embed a live stream. Siraj YouTube. No, that's not right. Sirajology. Sirajology? Sirajology. Is he live right now? Live. Oh, but this is finished. So I won't. I won't. So anyway, I'm sure this was a great live stream. Oh, by the way, am I in focus? The camera was all out of focus. I just randomly focused it. So I don't know if I got myself in focus. Siraj, I've been talking about Siraj doing a collaboration with him. So I hope hopefully that will come at some point soon. I'm hoping to do some videos about machine learning. He does a ton of them. They're really terrific. I love them. I watch them. And then I think, oh, maybe I could learn this stuff too. OK. Sorry, I got sidetracked. What was I talking about? OK, so the AFIN111 text stuff, I'm going to finish off. So I want to do a coding challenge of just AFIN111 in the browser just to look at, hey, I typed some text into a text field, and it gives me a sentiment score at the bottom. And then I'll also talk about other kinds of sentiment analysis beyond just this one technique, which is a very simple approach. And then if there's, and then I want to also finish off my examples about building your own API in Node. So once we do the sentiment analysis in the browser, we'll transfer that into Node and make a sentiment analysis API and look at what it means to make a POST request versus a GET request. So that's on my list for today. And then if there's extra time, I got some other things I would love to do. I keep whacking the microphone. I hope that's not making a weird sound for you. So let me say just a few quick words of where to find out more. So at this website, which is hmmhmm.com, if you go there, you can subscribe. You can become a patron if you are so inclined. And there's a Slack channel that comes as a benefit of being a patron on this service called Patreon. One thing I just want to point out, though, is I get this question a lot. So these days with my live streams, I'm kind of off into the weeds of doing examples and coding ideas, assuming that the people watching have done some programming before. And obviously, everybody watching, I'm sure, has a variety of different levels of experience. But I always get the question, oh, what should I do if I don't know anything, if I want to start learning to program from scratch? And so this playlist that's at the CodingRainbow.com website, you can look at that one, this will assume no knowledge of programming whatsoever and get you started using JavaScript. Of course, there are many other languages and other videos and books and things you can use to get started. But if you're looking for my stuff, this is what I would recommend right here. I also have another playlist for processing, which is a Java-based environment, which is beginner, for complete beginners that you can look at. And there's a textbook that goes along with that as well. OK. So what else do I need to mention? So I mentioned that I do send out emails periodically when I have a schedule for my live stream. And you can also sign up for that here. Let's see. Anything else? I do have my little soundboard, if you guys want to indulge me for a second. I can try to get that hooked up. Let me see something here. Let's go back to Siraj and see if, because I want to see if sound is working. We're going to play. Oops. Oh, no, add. I'm not being paid to play this ad. Skip. I don't think you guys can hear Siraj. So I need to fix this. System preferences, sound, multi-output device. This might change the sound in a second. Speak, Siraj. See who we got. What is that sound? OK. I heard some music. Oh, what is that? What is that? Hi, Siraj. This is like some sort of weird meta performance thing where I'm speaking to you as if. Come on. It's OK. The sound is working. You're live, except you're not. This is recorded. Hearing something. See, look, we're doing a collaboration already. I didn't realize it. Somebody snapshot this and tweet it to Siraj. I'm sure he would appreciate this weird thing that's happening right here. But I think you're hearing the sound. And I could also do this and talk to myself. And that would be a little bit weird. OK. Now what I want to do here is go to soundboard. I have this soundboard app. And I can airplay it to this laptop. You're going to see it in a second. Oh, mirroring on. There we go. And now you're seeing my soundboard, by the way. This is how this little behind the scenes. Behind the music. So let's see if this works. Does that sound horribly loud? As always, I always forget the this dot, this dot, this dot, this dot. I'm going to do this dot, this dot. I'm going to do this, this dot, this dot, this dot. I'm going to do this. So it looks like I have a soundboard working. In case I need to play some music or things, I can minimize this. You guys can let me know if the audio is a problem. Nobody could get that screenshot in time. You can reverse back in time. Maybe somebody else got it. It doesn't really matter. This will be there. Somebody will watch this later and then screenshot it then, thinking they're watching it live. OK. All right. You guys love that song. Somebody sent me a new song. Lost G Bear on Slack sent me a new song that I don't have loaded yet. If you're watching, I don't know if I got the name right. Let me know. Maybe I'll play that song. I'm hoping to have a new logo, a new name. A new song, a new video, all of these things. It's really unfortunate that I have this name and logo and video and song. And unfortunately, I can't use the name anymore. So there was a lot of time and effort went into that. And there just hasn't been a lot of time to do anything new. But I will get started on that. OK. Hello to Brazil. Oh, yes. So if you're looking for the this dot song, there are actually two this dot songs. One by F Looper and one by Christian Peterson. If you're looking for those, since it was asked. If you go to SoundCloud, I think if I just look Daniel Shiffman playlist, this dot, well, this comes up. But yeah, Daniel Shiffman's Coding Rainbow, the remixes is a few different remixes. So this is random. This is noise. This is Perlin noise. That is in the core random algorithm, the actual random algorithm itself. Those numbers aren't related at all. I'm picking random numbers between 0 and 10. 9, 2, 7, 6, 1, 9, 4, 8, 9, 2, 1, 3. So you guys can download and enjoy these songs. If anybody wants to make more songs, I love it. Nothing thrills me more than music. I'm just like a failed musical theater wannabe person. And then I just make programming videos on YouTube. So if I could somehow, you know, I forgot to enter the Hamilton lottery today. Maybe there's still time. Maybe I should enter it live. Because usually you can enter it till 4. You guys don't mind, do you? I have an app. It's really fast, I swear. I'll put on the This Dot song for you guys. As always, I always forget the This Dot. This Dot, This Dot, This Dot. I'm going to do This Dot, This Dot. I'm going to do This Dot, This Dot, This Dot. I'm going to do This Dot, This Dot, This Dot. What's today? This Dot. I'm going to do Wednesday. Yes, Wednesday. This Dot. This Dot, This Dot, This Dot. Enter. This Dot. Closes at 4 PM. Live on the air. I can't check at 4 o'clock. Somebody can remind me. I have to make sure I'm a pro. I have to select all the images with graphs. I'm selecting all the images with graphs. I'm entering the lottery. Oh, the cameras are going off. I'm going to enter it. Hold on. At 4 o'clock, I can check to see if I won the Hamilton lottery. $10 front row ticket. This Dot. I'm going to do This Dot, This Dot. I'm going to do This Dot, This Dot. This Dot, This Dot, Sorry. This Dot, This Dot, This Dot. Select all the images with trees. Oh my god. Watermelon is not a tree, is it? It's a little stressful. This Dot, This Dot, This Dot. I always feel so stressed out. I'm going to get in trouble if I don't answer the right one. There's trees on this one. OK, fine. This Dot, This Dot, This Dot. The This Dot song. Never forget the This Dot. Somebody composed that song for me. OK, I've now entered the Hamilton lottery. And this camera went off. Let me just fix that. Let me cycle this one. I need to erase the whiteboard. I don't know where the eraser is. Hmm. Where is the eraser? Where is that eraser? Erasure. Eraser. Oh. OK, hold on, everyone. Oh, here it is. I found it. I found it. I found it. Everything's going to be OK, everybody. I found it. I found it. I found it. I found it. I found it. I found it. Everything's going to be OK, everybody. I'm going to, this is what I had. Oh, look. Uh. Let me erase all this. This is such a nice eraser. Makes such a nice sound, too. Go to sleep. Go to sleep. Go to sleep, little eyes. Go to sleep. OK, I'm wrong. Ah, it's been a weird few weeks. OK, um, OK. All right, so the first thing I want to do, I'm actually going to start, weirdly, with a coding challenge. And that coding challenge, you should be confused, is to ch ch ch ch ch ch ch ch ch ch ch ch ch aphon111. So what I'm going to do, if, you know, a lot of you might have watched these before, but the live streams, typically, I do a lot of, like, talking and researching and clicking and getting set up. And at a certain point, I start an actual, like, tutorial or coding challenge, where I pretend as if I'm recording a video, even though that's what I'm doing all this time. So let me first kind of get set up here. And let's get some links that are relevant and talk to you a little bit about aphon111. So aphon is a list of English words rated for valence, meaning positivity or negativity, with an integer between minus 5 and plus 5. And so these words were manually labeled by Finn Arup Nielsen, which is why it's called the aphon. And aphon111 is the newest version that has 2,477 words and phrases. So if you are a scientist, I am not a scientist, I hope you would reference the above paper. I will reference the above paper and this link in this video's description. This database is copyright protected and distributed under the Open Database License. So what I'm going to do is I'm going to download it so we can take a look at it. OK, aphon. Oh, look, I downloaded it last week or two weeks ago. So let's look at the readme. This is what it says already on the site. OK, now let's look at this. Now, here's the thing. I really, really, really, really, really, really, really, really, really, really, really would like to have this list in JSON format. So the question I have for myself is, do I make the coding challenge itself, part of it, converting this to JSON? And also, what's up with this? What's up with this list? Like, wow, wow, wow, wow, with two W's, I guess. Yees, there's a lot of words. But why is there no space there between the number? So I feel like, oh, there's probably a tab. This is probably tab delimited, right? Yeah, so there's actually a space there. It's just, yeah, it's just there's a tab there. OK, so what I want to do is I'm going to do, I can't decide if I should do this as two separate coding challenges. Or I'm seeing in the chat that a note that the video quality is not good. So I don't know if sometimes with the stream, depending on your connection, you can get low quality. It is only 7. I am only broadcasting at 720p because I don't have a good enough connection here, I think, to support 108 broadcasting at 1080p. So let me know if anybody else is experiencing issues with quality. So what I want to do, let's do, hmm. I mean, this is not a complicated problem. I'm just trying to decide if I want to do it all together. Let's do it all together as one video. Why not? You know, who cares? So this video, what I'm going to do is I'm going to talk about what AFIN111 is. I'm going to grab this file. I'm going to open it in p5. I'm going to convert it to a file. I'm going to save it as JSON. And then I'm going to make a new sketch that loads it as JSON and does the sentiment analysis part. OK? So great. Here we go. So I think I'm ready for this. Let me check here. Let me get a little more set up. I'll play you another song. You can have the Perlin noise one now. Oh, that's just a clip? Who knows? Yeah, that was just a clip. As always, I always forget the this dot. Oh, that's the this dot. I pressed the wrong button. Empty example should be good. 0.584 is a good version of 0.5. So let's make this A to Z. Session. This is still session 8, if you can believe that. Oy vey, good old. I mean, in a way, this example is from an earlier session. This dot, this dot, this dot, never forget this dot. I'm using Sublimer Atom these days. I think I've been using Atom. This dot, this dot, this dot, never forget this dot. I'm going to do the this dot, this dot, this dot, this dot, the this dot song, never forget the this dot. Somebody compose that song for me. Oops. Oh, here we go. This. OK. I'm just opening up this project. Getting the code. There we go. I'm going to clean this up for a second. I want to have I don't need the sound library, but I do need the DOM library and sketch.js and index.html. And I'm going to say title. Title AFIN111 demo. I just get a few things set up here and then I want to run a server. Tempted. OK. Whoops. Let's run a server. Session eight. And let's take a look at everything in the browser. And let's get a console open. Let's do no canvas. Console.log sentiment. OK. So it looks like we are up and running. I need to have the website. I need also this URL. I will have open here. OK. I'm just checking the chat. Are you supposed to hear the audio from the computer? You are. Did you not? Hold on. Oh, you can't hear my voice when I'm playing the music at the same time. OK. That's good to know. I can also turn down the music and all that stuff. But I'm not going to worry about it right now. All right. Wow. This has been the least amount of technical difficulties I've had doing this in a while. But I shouldn't say anything because now everything's going to start crashing and burning. OK. So I'm checking in the chat to see if anyone is saying anything important. Like nothing is working. I can't see anything. It looks OK. So I am now going to get started. Oh, hold on. This microphone is awkwardly positioned. That's a little bit better. So this first video that I'm going to do, first of all, the reason why I'm doing this is because, I don't know. Why not? But what I want to do is have the node API that I'm making do be an example. Just be a sentiment analysis API. And so I thought it would be worth before going and adding all that code to node to just sort of show one simple technique for doing sentiment analysis. And do that in a coding challenge. Also just kind of like, there's a lot of stuff I think that's interesting to explore here. So here we go. The little shadow on the green screen. I know. It's because one of my lights is broken. Let's see if I might be able to do something about it. I shouldn't. I'm a little bit afraid to do this. Whoa. Hey, that shadow's gone. Now, oh, no, it's worse. OK, better not do that. OK. We're just going to have to live with it. It's if I step over here, it gets worse. If I stay over here, it's better. So that's just how it's going to be for now. OK. Audio is awesome. All right. All right. Here we go, everybody. This is a tutorial. It is 3. Oh, my god. It's 3.45 already. That's not good. OK. 25. Oh, I forgot. I was going to talk about the processing fellowships. So that was my first thing that I was going to talk about. Let's do that now. So, oh, boy. OK. I'm going to do this. So I just want to mention this because I think it's worth mentioning to kind of let the broadest audience know about this opportunity for those of you who might be interested. Processing Foundation, I've talked about before on live streams, is a non-for-profit foundation whose primary mission is to promote software literacy and make code and creative work with code accessible and available to diverse communities. And so in addition to education and diversity initiatives that we sponsor, which you can find out on the Processing Foundation's initiative page, we maintain what you're probably more familiar with, the platform's processing, which is a Java-based creative coding platform, p5.js, which is the JavaScript library that I'm using in a lot of my examples, at least the ones that I'll do today. There's also a Python version of processing. You can't see. I'm hovering with this tiny little pointer on these links. So you might be familiar with all of these different projects. What we started last year is a fellowship program, and the fellowship program currently has its open call right now. So just to let you know briefly, let me scroll down here and get, these are the fellows from last year, Allison Parrish, who worked on advocacy documentation and tutorials for processing Python mode, Claire Kearney-Volpe, who was a guest here on this YouTube channel to talk about her work with accessibility, working with low vision and blind people and code. Digital Citizens Lab created a learning platform about code using comics, worked with an after school program here in the Bronx in New York City. Jessica Klein and Atul Varma worked on a bunch of different features to make p5 more friendly and accessible. So these are some of the, oh, and sorry, I didn't scroll all the way down, Tiga Brain and Luisa Pereira, who worked on tutorials for p5. Tiga also did a tutorial for this channel. And these are some previous fellowships, Vilm Tobin, who worked on the processing sound library, Lauren McCarthy, who now is a core director of the Processing Foundation, the inventor of p5.js, what originally started as a fellowship, Greg Bornstein, who did a fellowship on OpenCV with processing. So these are fellowships that we've sponsored, and we now have an open call. The idea is that for you to propose a project that you want to spend about 100 hours on between February 1st and May 31st, and there is a $3,000 stipend, US dollars, but you don't have to be a US citizen. You don't have to live in New York or the United States or anywhere to apply for the fellowship. And if you are selected for the fellowship, you're assigned a mentor to work and develop this project. This is very similar to Google Summer of Code, which is a program that some of you might be familiar with. A key difference between the Processing Fellowship and Google Summer of Code, however, is that community-based education, diversity, projects about bringing processing to different and diverse communities, or documentation, tutorials, these are valid processing fellowships, which is different than Google Summer of Code, which requires projects to be about writing code. So you don't have to be a professional programmer, you don't have to be an advanced programmer, you can be a beginner, you can be a teacher. If you want to write curriculum, these are types of things that are possible for the Processing Fellowship. So I just wanted to mention that if you are interested in the fellowship and have questions about it, on Twitter is twitter.com slash processing org. You can tweet at ProcessingOrg. You can ask questions on the Processing Forum, which is forum.processing.org, and certainly you can get in touch with me in the comments of this video. I'm having trouble keeping up with YouTube comments, but I do read them. And so that's what I just wanted to make an announcement about and plug a little bit about this fellowship program. Okay, so the other thing I'll mention very briefly also, if I go to twitter.com processing org. So this is the link for the Processing Fellowships on Twitter. And then also if we do here. Ah, yes. So we have a community survey. So I would also encourage you if you are a user or a teacher or if you're a student, a teacher, a professional, a hobbyist, if you use processing p5.js, processing.py, please fill out this survey to help us understand how people use the software and make priorities for them. It's a really, a really exciting program. And I hope this is being spread to everyone who's interested. I can't wait. Hopefully, you want to have a look at it when you go to this time, but hopefully, But I did have a question here about the advantage flush, and I've also seen the amount of penalties for that change in penalties for penalties for non physical penjobs or pen quest at age states. And I don't actually understand why they do that that way. Because they just don't acknowledge that. So I guess the only real part of it is that it's unbelievable how many languages and Okay, so that is I wanted to mention and talk about can you can link the survey. So I'll link this if someone in the chat is a moderator. Oh, thank you. I think Alvaro in the chat link the survey. I will try and Matthew who helps me with this, of course, will try to remember to put a link to the survey also in this video's description. Okay. Thank you, everyone for listening and being supportive of the Processing Foundation. By the way, I have this weird idea. I shouldn't mention it. But the last week of not the last week of December, but the last week before the winter holiday, I think, which ends December 23rd, I have a fairly free week that week, not the beginning of the week, but towards the end of the week. And I had this idea that that I see that people are getting banned in the chat, but I should just like let that happen. I'm sure it distracts me a little bit too much. I had this idea of kind of doing an all day live stream. And by all day, I don't mean I mean something like starting at 10 or 11 and finishing at four or five, maybe with a little lunch break in the middle, maybe a guest would come in and do something. I would go have some lunch. I almost think of it as like a telethon, just like catch up on a lot of tutorials, have some fun. It's sort of like end of the year celebration of creative code stuff. And I thought it could be kind of like a telethon to raise money for the Processing Foundation. Or maybe there's another cause you should consider raising money for. So anyway, I'm thinking about that. You could encourage or discourage me. I'm sure you all would. But if that happens, it would be on the 22nd or the 23rd. So keep that in mind. I would love to if you're in the Slack channel, if you're a patron in the Slack channel, you can tell me your ideas about this there. OK. OK, cool. What's Nerdfighters? I don't know what that is. But I'm definitely looking to do more collaborations and things with other folks on YouTube, especially if they don't look like me or have different ideas and come from a different background. OK, so let's get back to that AFIN111 thing. I've got to do something programming-wise today. I want to just apologize that things have been a little light this month. I missed a week. I missed two weeks, I think. When I didn't miss a week, I had shorter streams. And today is no exception. I hope that December and January will bring back more of a regular routine of content. And I have more ideas about that in the future. OK. OK, so let's see. I'm going to cycle the cameras again since I babbled on for way too long. And it's so quiet today here. Eerie. OK. OK, let's do AFIN111. Hold on. Sorry, everybody. I just want to like try to, ah! I'm like so overly, neurotically, anal retentive in the worst way. OK, now we're good. I wish this had like a little bit of a prettier image. But what can you help? What if I do sentiment analysis images? This works for me. OK, I want to do a whole. I also want to do like a whole live stream only about emojis, which I find to be sort of like fascinating. OK, where are the barking dogs? Not today, I guess. Where's my bumper music? Can you hear that? Is it loud? Is that loud? It's so quiet for me. OK. OK, sorry, I'm paying too much attention to the chat. Wow, there are really 160 people watching? That is insane. Oh my goodness. OK, OK, here we go. Let me try that again. Hello, welcome to a coding challenge again. In this coding challenge, I am going to build from scratch a web application that does sentiment analysis. What is sentiment analysis? So first of all, I want to mention that the actual, oops, I'm in the wrong page. The particular technique I'm going to use is a score-based system using a list of words known as the AFIN111. So there are a lot of ways to do sentiment analysis. What I mean by sentiment analysis is here's some text, here's some information. I want to determine, is it positive? Is it negative? And I want to assign it a score. Is it a high number, meaning very positive? Is it 0, meaning completely neutral? Is it a low negative number, meaning very negative? And there are different ways you can do this. There are machine learning systems that can be trained. Here's a lot of very positive essays, and here's a lot of really negative essays. Learn about them. Here's an essay. Please give it a score. There's neural networks can do this. There's a technique known as Bayesian classification that can be trained to look, also be trained based on positive and negative text. And there's, I'm sure, a list many other techniques here. But the technique that I want to look at in this particular video is quite a simple one. And it involves a pre-made list of words that are assigned a valence, a positivity or negativity score. And so this list is a well-known list, the AFIN111. It is the newest version with 2,477 words and phrases. And these were labeled by Finn Arup Nielsen in 2009, 2011. So the way this works is you take a body of text, you read through it, you look for any time a word that appears on the AFIN111 list is, you look for any words that appear on that list, you look up its score, and you add all the scores together. I don't know why I felt like this video is going fine, but I just realized I don't have a marker. And I was going to, I was like, kept thinking, oh, I should just like do this on the whiteboard. And then I realized I don't have a marker. And then I lost my train of thought. And Denmark. Oh, OK. So I'm going to do something a little weird. Matias seems to be in the chat. I'm going to re-explain the AFIN111 thing. But I'm going to do it over by the whiteboard. And so you just have to, I think you can just cut out that quick explanation and splice in this new, better explanation with the whiteboard. Then I'll keep going. Sorry. If it doesn't work, whatever, we'll figure it out. Uh, so what, what is the AFIN111 technique? The AFIN111 technique involves a pre-assigned list of words. So if I were to say like happy, this has a score of five. Each, each word gets a positive or negative valence score. Five being very happy, very positive. Sad, very negative. No rainbow. Also very positive. Five. I don't want to give rainbow the score of four and happy five. That would be, and I could think of what's like, you know, turtle. I mean, turtles are like a little bit sad. I don't know, no turtles, turtles are happy. Turtle too, right? OK, so you get the idea. I'm not going to try to make, clearly I'm not qualified to make up a list of words and scores. So if you have this pre-made list of words, and these could be in any language. This is a particular list in the English language. And if you have thousands and thousands of them, then if you have a particular text with a lot of words in it, you could write a computer program to just look at each word and ask, is it in the list? If it's in the list, look up its score and add it to a running total. And at the end, you're going to get some value, like you might get 27. And it's going to be, that's going to be a positive. This is a positive email, a positive tweet, positive essay. Or you might get negative 31. And this is very, very negative. You can get the total score. And you can also get what's known as the comparable score. I think that's right. Comparable score? What is that called? OK, wait, wait, wait. What's that called? AFIN, I don't want to get it wrong. 111 comparable, comparable. Oh, look, I'm going to look at this. This is exactly, by the way, I've seen this web page before. This is exactly what I'm going to build. I am happy. Comparative, why did I say? OK, coming back to here. OK, oh, camera's still on the whiteboard. Sorry, everybody, but that's fine. I was just looking something up. Comparative, I don't know why I said comparable. So thank you, Mattheo, for being a master editor. Don't know if I would basically have to quit doing this if it wasn't for you. OK, so this is what would be known as the total score. But you can also look at the comparative score, meaning just because you have a really long document with the word happy in it a lot of times is that more positive than a short document with the word happy in it fewer times. So the comparative score would be the total score divided by the total number of words. OK, so this is exactly what I want to implement. So let's look back here. Sorry, so the AFIN111 is a particular list of words. It was manually made. This was manually made by Finn Arup Nielsen. You can imagine what kind of research and thought went into this. And I encourage you to read the paper. And also, if you use this list, you should also reference the paper. Everything is on this website, which is linked in this video's description. OK, so what I'm going to actually do is just download it. Oh, I've already downloaded it. I did that before it started. It's like a cooking show. Here's my AFIN111 list, except this is a fan. By the way, isn't it random that I just like underneath this desk? What else do I have? Nothing is the sad thing. Oh, watch this, though. I have another fan. It was just like in here. I have a magical. Oh, look at this. Look at this. Over here, I have a monitor. There's lots of stuff. It's like a magical bag of things that people are telling me to concentrate. I don't do a good job of that. OK, so I've already downloaded this list. I can't pull it out. And let's go take a look at it. So where would it be? It would be in my downloads. And here it is under AFIN111. So here, I'm going to open this up. And we can take a look at this list. So you can see this has several thousand words. And you can see abandon being negative 2, abandon negative 2, et cetera, et cetera, et cetera, compelled 1, congratulations 2, et cetera. You can see here all the words and all their scores. I can scroll through the whole thing. So the first thing that I want to do in this challenge, I think, is it would be so much more convenient if this text file was actually a JSON file. So let's write a little quick program to convert it to JSON. I could do that in like Node or Python or something. But I'm going to somewhat absurdly just do this in the browser. So first, what I want to do is I need to get this list. And I need to go to my folder that has my code. And I'm going to paste it in here. So right now, I have a folder that has an HTML file. I have a libraries folder because I'm using the p5.js and the p5.dom library. And sketch.js is where I'm going to have my JavaScript code. OK, so now what I want to do is here's the thing. This file, which I can load up here, this is actually, I'm almost certain, is a tab delimited file, meaning each word, the format of this file is word tab score. So there's a variety of ways I could parse this. And this may not actually work. But let's test the p5.js library and see if load table works with this file. So what I'm going to do is go back to my code. And I'm going to say var table. Function pre. I'm going to use preload, which is a function that I can use to make sure certain images or media or data files are loaded before the page, the sketch even begins. Load table. And then I need to give it the file name, afin111.txt. And then I'm just going to say console.log table. And let's see what happens. And this is my, so that's good. Look at this. This is very promising. You can see that a table object got loaded. And it includes an array of rows with 2,477. So frankly, there's not really a huge need to turn this into JSON because I have it in this nice table object, which makes it very easy to parse. But let's, for lookup, when I want to look up the scores, I'm going to want it as a JavaScript object. So let's see, how do we iterate over this table? So for var i equals 0, i is less than table.getRowCount. Here's the thing. I don't know that the table API off the top of my head. So let's go to p5js.org, reference. And then what I'm going to do is look for table. And we can see load table, p5 table. So let's go to p5 table. And we can see a bunch of the functions like getRowCount. So this is something I certainly need to that I want to iterate over all the rows. So I can say for var i equals 0, i is less than table.getRowCount, i plus plus. And then I can get each row probably by saying getRow i. That seems probably like it's the case. Let's say console.log row. Let's see if that works. Whoops, let me go back over here. So this looks good. Like I'm getting a row object for every row in that table. And I probably can say var word equals table.get0. And var score equals table.get1. And why am I saying that? Because if this file is in a table and each line of this text file is a row, think of it as a spreadsheet, a board is in column 0, 1 is in column 1. So this is me saying load that text file into a table, look at every single row, get every row, and then get the stuff that's in column 0 and get the stuff that's in column 1. And by the way, I could actually label the columns with headers and use that. There's lots of fancier things you can do with tables in p5n processing. But this should do. So let's say console.log word score. And let's run this. Undefined, undefined, undefined. So get, I suppose, is not the actual function. Oh, and I said table because I need to say row. Probably all of you are noticing this. I see in the chat that everyone noticed this like five minutes ago. So row.get because of course what I want to do is get column 0 from that row, not from the table. Sorry about that. And then we can see. Now, why do I still see some undefines? Oh, look at this. It didn't split it. It wasn't able to do it by tabs. That's so sad. Load table. So this might be a p5.js bug. Or I might just be wrong about how this table is formatted. Or I might need to give it a file extension. Let's try that. Oh, look at that. That worked. So what I needed to do is because it's.txt, p5 couldn't auto detect that it was a tab delimited file. So I'm able to give it a second argument and give it an extension tsv to tell it that it is a tab separated file. If it were a comma separated file, meaning commas in between instead of tabs, then that's what I had before. It was getting the whole thing, and then there's no second column. OK, so that fixed that. OK, so tsv. Great. So now what I want to do is I'm going to make an object called the afin. And it's an empty JavaScript object. And what I want to do is I want to say I want to put in that object the word as the key, the number as the value. Word is the key, number is the value. So I'm going to say afin word equals score. And then at the very end, I'm going to say console.log afin. And we're going to look at this. And we can see, look at that. There it is. There now is that afin list in a JavaScript object. Every word with a score. And I'm kind of scrolling through it just to see if anything broke, like if there was a weird apostrophe or something that broke it. But it doesn't look like it did. And just to remind you, remember, if I have an object and I say object something.x equals 100, this is the same. My laptop's about to fall over. As saying this. So since these words are all strings, and I want those to be the keys, the properties of the objects, I need to pass them in using this bracket syntax. I can't do it like this because it's not a variable name at this point. It's coming in as a string. OK. So now that that's done, one of the lovely things about using p5 is I can just say save afin111.json afin. And I'm saying it's with two n's, I think, right? Yeah. So now I can just save that file, save that data as a JSON file. And it should auto download that to me in the browser. So let's run it again. Oh, file name index of. OK. So I think maybe I'm supposed to say it the other way around. First, the data and then the file name. That seems right. There we go. And you can see my browser. I'm standing in front of it. But my browser auto downloaded this file called afinb because I must have put that in my code by accident. Where's my code? Yeah. Whoops. Two n's there. But that doesn't really matter. The point is now I have this file, afin, and I can put that, whoops, I can put that here instead of the text file. So let me rename it to fix it. So what I did just is now instead of this text file, I now converted that to a JSON file. And of course, it won't. Oh, but this is my, I can open it right through here. And we can see there it is. So this is great because now to do the text analysis, the sentiment analysis, it's going to be so much easier if I already have this data in a JSON file. And by the way, you could probably Google afin111 JSON. Countless people all over the world and internet have done this already. But I thought it was a useful demonstration to show in p5 how to convert between one format to another. Let's do the, so all of you who were like, I wanted to watch the video about sentiment analysis. Maybe I can put like a little time code in this challenge of like skip ahead to the sentiment analysis part. So now we're actually ready to do the sentiment analysis. So what I'm going to do is I'm going to just actually save this as the JavaScript file. I'm going to call it convert.js. And I'm just going to like get rid of everything and start over because I don't, what am I trying to say here? I don't need to ever do that again. I've already converted it to JSON. But it's good to save that code if you want to take a look at it. OK, so here we go. Part two. I don't know if there should be two videos just in case. Where's my bell? Part two of afin111 sentiment analysis. OK, here we go. So the first thing that I need to do is I want to load this file. So let's make a variable. I'm going to call it afin again. afin equals load JSON, afin111.json. And I just want to see that that worked. I'm going to say console.log afin. OK, so we're starting up. And I just want to see, great. So we can see that that list has been loaded, which is wonderful. Now, the next thing I need is I want to have a place. So let's add some stuff here. afin sentiment demo. Let's say type here. And make a text area like this. Text area id equals text, text area. OK, so now I should have on the HTML page, we should see, whoops. I definitely did something wrong. Text area, text area. There we go. OK, so we should see, oh, a global function text. Because your code has already used it. So I think it's a bad idea to, so let's call this txt. OK, so we can see here that, now, how do I, by the way, with text area, I kind of just want it to already start as like a slightly bigger thing, which is kind of unnecessary. I'm going to say columns equals 50. So that's good. And rows equals 10. OK, so now I can, the idea here is that what I want to do is as I type here, I am happy, how are you? What I want to do is I want to live calculate the sentiment of this text and have it appear below, as I press every single key. So first, I need to bind some sort of event. So I need an event for every time I type into this text area. So first of all, I need access to this text area in JavaScript. And I can do that with the select function. If I were jQuery, I'd use that dollar sign thing or document.getElementById with regular JavaScript. So I called id was txt. So what I need to do is say var txt equals select by the id txt. And then the event that I want to track is called an input event. There's a changed event. There's a change event and an input event. It's a little weird in the browser. The changed event is only if I hit like enter or tab, if I finished my action. But the input event happens anytime I press a key at all. So text.input, I'm going to call this event typing. And I'm going to say now function typing. And I'm just going to say console.log txt.value. So what I want to see is, as I'm typing, I just want to see that I have access to the words that are in what I'm typing. OK, so let's refresh this and say, hello, how are you? And you can see that this is working. That as I type what I'm typing, every time I hit a key, it comes out in the console there. OK, so that's perfect. That's what I want. Now I can start to calculate the sentiment score. So what should I, how should I calculate the sentiment score? The first thing I need to do is split up the text by words. And I can use a regular expression. See my videos about regular expressions using the split function. So I'm going to say var, I'm going to say tokens, I'm going to say words. Words equals txt.split. And then I want to split by a regular expression. And a regular expression in JavaScript is a string, like a sequence of characters, that goes between forward slashes rather than between quotes. And it defines a pattern in the text. And I have a whole set of videos all about regular expressions. What the pattern is, what separates the words? So whitespace, commas, periods, punctuation, whitespace, that sort of thing. Basically, I'm going to do something kind of silly and simple here. I'm going to say anything that's not a letter or number. And so there's, I can actually just say backslash w. So this is slash w is any letter or number. And backslash capital W is any non-letter, non-number. And I could also say, maybe I should say or an apostrophe. Oh no, but that's included. No, I should have let it be or not. Anyway, whatever. This will be good enough for now. You could spend your life trying to define the best regular expression for splitting, tokenizing a sentence into words or a paragraph into sentences or essay into paragraphs, all that sort of thing. OK, so I'm going to do that. And then I'm just going to see that this works. I'm going to say console.log words just to check that. Hello? Oh, txt.split is not a function. Well, of course it's not a function because txt, I can't come up with variable names. Word, text input, fine, equals txt.value. So I want to get the value. That's the contents. And then I need to split that. So it's good that I checked that. And now I'm going to say, hello, this is a test. So you can see as I type, it's splitting up into an array of words. Perfect. So now I need to iterate over that array of words. So I need to say for var i equals 0, i is less than words.length, i plus plus. Now, here's something that's important. Let's go back to our AFIN111 list. Notice something here. All of these words are entirely lowercase. There is not a single uppercase letter in this particular word list. So one thing I definitely want to do is when I'm in my code, the first thing I want to do is say word equals words index i dot to lowercase. Because when I look up to see what its score is, I need a lowercase word. So now that I've done that, then I want to say, does that word exist? So if AFIN word, does it exist? Now, I could use this has. I should probably use the has own property thing. So this is me asking, let's say the word is cat. If cat is in the AFIN word list, I'm going to get the score for cat, like 3. Maybe kitten would be like 4. I don't know. Cats and kittens, they're equal. I love it. Anyway, what am I talking about? I'm so worried about offending words with their positive negative score. It's a very strange personality I have. OK, but there was a point to what I was saying, which is that, that, ah, right. If cat exists, I'll get the score, like 4. If it doesn't, I'll get undefined, which will evaluate to false. But there's a weird sort of issue here. Like sometimes, like there might be like some built-in JavaScript properties that happen to have the same word as a word in the essay. So to be 100% sure, I can say has own property. This will evaluate to true or false if word is a particular property of this list that I've developed that's not part of the sort of JavaScript object thingy language itself, whatever. OK, so if it does, first of all, I need to say score equals 0. I can say score plus equals AFIN word. So now I can look up the score and add it. And then what I'm going to do is let's add a little area for results. I'm going to say PID equals score. And I'm going to add some things. Score, comparative, and what else? Maybe I'll do a word list just so we can see everything on the page. So OK, so I added three paragraphs because I want to report some information on the page. So the first thing I can do now in JavaScript here is say, I can say var scoreP equals select score. And then say scoreP.html is the score. This is sort of, there's better ways I could do this, but this will work just fine. Comparative, select comparative. And then the comparative is the score divided by words.length. So the score divided by the number of words in the file. And then also maybe word list, select word list, and word list HTML. Oh, I'm not saving the words. So let's make a list. So let's make a list. We'll call it scored words. And it's an empty array. And if I ever find one of those, I'm going to say scored words.push the word. Oh, and maybe colon its score, something like that. So I'm not being very thoughtful about the design of the display of the results. But comparative. OK, but let's see if this works. Hello. Oh, uncaught reference error. Score words is not defined. Scored words, scored words. And oh, scored words. I don't know what I'm doing here. OK, let's try this. So OK, let's try typing. I love kittens and rainbows. Also, unicorns and the color purple and pink and red and green and blue. I am happy. So, so very, very happy and joyful. So you can see, oh, a couple of things are wrong here. This is not at all correct. So what's happening here? It's getting the information from the JSON file. And it's adding those numbers together. It's saying 3 plus 3 plus 3 plus 3 equals 3, 3, 3, 3, 3. So it's not adding them as numbers. It thinks everything is a string, which is also why I'm getting some goofy results here. So one thing that I need to do here is make sure that when I get that score, I convert it to a number. So let's fix that. Right, that score that's coming out of the word list, I need to convert it to a number. I should have just happy, sad, not so sad, but not so happy. Happy and joyful and full of scared, fear for things that scream and monsters. But I like, am I still recording a video tutorial? Or did I just become hypnotized by my weird nonsensical typing? So you can see, I'm now getting, now, I'm seeing some weird stuff going on here, which might just be the fact that I'm not being very thoughtful about how I display the information. But let's do some more tests here. If I say sad, OK, that works. Score is negative 2. Oops, camera went off. If I say sad, exactly what I would expect. Let me move this over here. Right, I got a total score of negative 2. Comparative is negative 2 because it's negative 2 divided by one word total. If I say happy, right, OK, so this is working. And abandoned, I remember, was in there, is negative 1. So it's just the formatting. So we're really done. I could copy and paste some text, like, I don't know, if I go to kitten. I don't know if I can do that. I don't know if I go to kittens, Wikipedia. Let's get some text about kittens and see what happens if I paste it in here. And we can see I got a score of 4. Comparative of 0.04, this is positive text. The words that I got were solid and enjoy. I should get a score of 6. So something is wrong here, right? What did I forget? I made a, there's a bug in my code. Score plus equals. Let's say, let's just do console.log word and score. Yeah, something's wrong with the math. What did I say? Solid 2. What was the other word? Whatever, happy. 5. Solid, ooh, wait. Solid 0, happy 2. Huh? Debugging time. Hold on, hold on. Solid has a score of 2. But why is that coming out as 0? Oh, I don't have a variable. Oh, sorry. Okay, hold on. Oh, no. Did something, you know, sometimes if I have an element named with an, oh, whoops. Oh, sorry, this is, remind me later. I don't need a software update. Sometimes if I have an element, things in JavaScript can be, you know, Sometimes if I have an element, things in JavaScript can be, happen in weird things. Like I named this variable score, and I happen to have a DOM element with an ID of score. I wonder if that's causing me a weird sort of problem. So I'm going to go here and say score p, comparative p, word list p. And I'm going to go back to my sketch. I'm just going to see if that's an issue. Oh, I also, I'm just not, oh, I'm being score p dot. Oh, no, no, score. Yeah, that's right. And comparative word list p. Let's see. Let me just make all the variables name different to overdo it. Solid, happy. Solid is 2, happy is 3. Why am I seeing a score of 2? I'm seeing happy 5 here. So this is correct, this is correct, and this is wrong. I'm, I'm a little skeptical of, oh, I put the score. Oh, once again. I'm conflating the total score and the individual word score. So I should really if I want to be thoughtful about this. Boy, I'm terrible at this sort of stuff. So I don't think it was that at all. I think it was, this was my problem all along. So I want to make sure I have a difference between the individual word score and the actual total score that I'm adding up. And so this is the total score, and this is the total score, and the in, the things that I'm putting into the list. So I'm going to just add some padding here for formatting. Now, happy, sad, this is better, yes, no, no, no, no, no, no, no, no, no, no, no. OK, so there we go. You can see now I have real time sentiment analysis where I could be much, you know, if you're watching this video, if you're going to make something with this, you could be so much more thoughtful in terms of how you display the results, whether it's color or visualization, formatting the numbers nicely, formatting the list of words in a different way. But you have the basic framework for it here. I will show you that there is a major issue with this particular approach. OK, so here's a particular issue. Here is my text that I am going to type right now. I am not sad. I am not at all unhappy. I am not feeling worse today. So you can see I've got a really, really negative score of negative 6, even though I said I'm not sad, I am not at all unhappy, I am not feeling worse today. Because this particular technique is only looking at the raw counts of words and those scores. If I wanted to be a little more thoughtful about this, I could try to add a little bit of natural language processing. For example, the JavaScript library NLP compromise that I demonstrated can look for if a statement is a negation and you could perhaps invert the score. And then, of course, I could use a more sophisticated training methodology of actually not using a word list, but having a machine learning system learn about positive text, learn about negative text based on just word frequencies and words being next to each other and that sort of thing in a much more open-ended way. But this hopefully should get you started on something if you're interested in text analysis and how you might apply this to what type of data source and how you might show the result or how you might create an interface for people to type into and give us some information back. Okay, so in the chat, Gaurav writes, you must be sad, that's why you were insisting on it very much. And you know what? I think maybe this is a smarter sentiment analysis technique than I knew because maybe it can read in between the lines. Okay, thanks very much for watching this sentiment analysis video and I'll see you in other videos in the future perhaps. Okay, she's doing cycle analysis too. Okay, it is now 4.30. Ah, wow, this took me... How long was this? Did I really spend like 45 minutes on this? Wow, that's crazy if I did. Okay, let's think about what I have time for because there isn't a ton of time left. 35 minutes, okay. Maybe that could be... Maybe some of the debugging can be edited out. All right, so what do I want to look at next? Let's see if we have time to go back to the... I'm sorry, I'm just thinking here. Let's go back to the Node program. Let me pull that up. So I'm going to copy this and say API 3. You know, I realized I haven't posted any of this code on GitHub in so long. Let's go make API 3. And let's go to... I will be doing tutorials about machine learning in 2017. Maybe I'll do some on this all-day adventure that I would like to do. I'm trying to finish up this other list that I have first. So let's just say Node server. Let's see what this is doing. Oops, I'm sorry, localhost 3000. Okay, right. So now I remember that this, if you recall where I was last, is I made a simple list of all the nodes. And let me open this one up too. Sorry. I made a simple API that allows you to add a word with a score to a database. Add a word with a score to a database. And so you could build, you could have a crowdsourced AFIN111 style list. And you can see this is a front end to this that shows you everything that's been in there so far. So if I were to add happy and give it a score of 5, if I were to add sad and give it a score of negative 3, you can see those show up. And the API also, if I go to this particular route slash all, shows me everything that's currently in the database. It's not really a database, it's just a text file and their scores. So what I think I would like to do now is, is, is, I'm sorry, I'm reading the chat's interesting suggestions there. What I would like to do now is finally finish off this example by adding, adding the ability to put text into a text field, post it to the API, and then get a score back. And then also combine this list with the AFIN111 list. OK? OK. So I'm going to do that. That'll be, unfortunately, the last thing I'm going to do today. I had ambitions of getting further. But I do really want to finish this playlist about building your own API in Node. OK. Ah, it's 3 a.m. in India. I'm impressed that you're up and watching. OK. So let me get myself organized here. All right. I think I'm ready. Let me cycle these cameras. And let me make sure I have my pen and eraser. Hey, somebody's in Bushwick watching. That's not too far away. I'm impressed and amazed. OK. Here we go. All right. Welcome to another. We started that over. My throat has really never recovered from that illness I had a month ago. OK. Welcome to yet another. I'm losing my mind here. Welcome to another and what might possibly actually be the last video in this playlist about how to build your own API in Node. So if you remember, you might have just watched the last video. But it's been a while since I made it. So I'm going to just kind of set the stage here very, very briefly. We have so far an API made in Node that saves words and a score, a kind of positive or negative valence, the idea that we're going to do a sentimental API. We have a particular route where if I go to the server slash all, I can see all the words that are in a particular in that database. I also made a little front end that if I add a word like kitten and I give it a score like four and I hit submit and then I can hit refresh here and we can see now kitten has now been added to that database. Now it's a little bit more complicated than that. But it's a little bit more intuitive. We can see now kitten has now been added to that database. Now it's not actually a database. It is simply just a list, a JSON file. But the Node program is receiving the word and score from the client, saving it to the JSON file and loading again for later use. So there are two things in this video that I want to add to this particular application. Number one, I want to add a pre-existing list of words and valence scores. And this list is known as the AFIN111. So this will just make the sentiment analysis work a little better by giving us seeding it with a pre-existing list of words. I made a separate video where I went over this in more detail, which I'll link to in this. But this list comes from this particular website. And it was developed by Finn Arup-Nielsen. And if you use it, you should credit it. And there's links and information about how to do that here. OK, so that exists. That's number one. I want to bring that list over. Let's actually do that first. I'll say what the number two is in a second. Number two is I want to look at a post to the API. What's the difference between get and post? That's going to be part of this video too. So I'm actually just going to absurdly just do save as. And I'm going to go to my Node folder. And I'm going to save it as AFIN111.json. And then I'm going to go to the server. And we're going to look at where the server loads. Where does the server load that file? Right here. var data equals readFileSyncWords.json. So I also want to load AFIN111.json into a variable called AFIN. Actually, I'll call this AFINData. And then I want to say var data equals json.parse AFINData. Oh, no. Sorry. Var AFIN. So now my Node server has both the word list that's being saved and the AFIN list. Now, here's the thing. So I think what I want to do is just change this. I'm going to change this to additional. I think I'm going to keep these in separate files because this AFIN111 is never going to change. And what I want to do is, but I'm going to call that file additional just for clarification. Additional. And what I want to do now is in the server. So I have them as two. And I must have a save place somewhere else. So I need to change this to additional as well where I save that file. Because what I want to do is when it comes time to do this sentiment analysis, I need to look in both of those. I need to look in the AFIN word list. Is it there? If not, look in the additional word list. And I should decide if one overrides the other. In this case, probably the additional should override the AFIN. So I'll look in additional first. OK, great. So actually, done. We did it. Yay. But I guess I could in all. Let's look at that all route again. Let's here. Let's actually do something kind of a little goofy. I'm going to do, I'm going to say the data is additional is words. And AFIN is the AFIN list. So then, so I'm changing the server when you ask for all to not just give you the words that are in the database, but look at both of them. So this is just changing the response of the server. And what I'm going to do here, if you go here now, I have to restart the server. Where, oops, sorry, everybody. I'm going to restart the server. And I'm going to do this. And we can see now I have both the additional list and the AFIN list. Wonderful. OK, so now, but this probably broke this part because the way I was parsing, I was using that all route. But you know what? I'm going to get rid of this drawing thing. It's sort of unnecessary right now. I just want to have this word score interface. So let's go back to the client, which is here. And let's get rid of the draw data thing, which we don't need to do anymore. Because we're going to do some different stuff here. So I just want to see that this, I don't need draw data anymore. I want to see that this works. So I want to see what's another word that I could add. Puppy. And three, hit submit. And we can see that that worked. Success. Although I probably, again, should add something to this page that says, thank you. I added that word to the list. That's a great exercise for you. But we can just confirm now that if I go back to here, under additional, puppy is there. OK, so everything is working. But my API behind the scenes has access to both the full AFIN list and any additional words that have been added. Notice how things are a little bit different here. I probably should have been more thoughtful about fixing this up so that these are actually numbers and not strings. But I can deal with that later. So OK, now the thing we need to change now is how do we send a large body of text from the client to the server? And so I'm going to come over here for a second to, oh boy, this camera is off. I'm going to come to the void. And I want to talk about the difference between a get and a post. So HTTP, which stands for Hyper Text Transfer Protocol, I don't know if that's right. It's probably right. There is a request and response protocol. Hi, I'm a web browser. Could I please, I'm making a request, have some information about where I could get some nice apples this time of year? And maybe I would ask that to Google. And Google being the server would say, hey, I'm a web browser. And Google being the server would say, hey, here's a response. Here's some information. And the way that I can talk to that server in this request and response protocol, if we have server and we have client, is I can make a get request, which is like, could you please give me some information back? Or I could make a post request, which is, would you please take this information and save it onto your server or do something with it? So if I'm logging in with my username and password, that would be something I would want to send with a post request. If I want the results of a search, I might ask, use a get request to get the results back. Here's the thing. Even though this is how this protocol is designed and how it works, you'll notice something in our program a little bit strange. So if I go back to the code for a second and I look in the server, I can say, well, where are these happening? This is a get. Oh, I'm in the wrong place. If I go, we do that again. If I go back to the code for a second, you might ask, where are these happening? Well, right here, when I set up a route, I'm actually saying this is handling a get request. If the browser asks with a get request for slash all, send this information back as the response. Information that comes with the request is in this variable. Stuff that I want to do to respond is in this variable. This is a get request. And it makes sense. I would like all of the data in the database, please. Could I please have that? Thank you. I really wish it was this. Get, please. But it's just get. I guess there's no need for politeness between computers. Kindness. There's nothing that needs to be said for kindness between computers, though, and people. Anyway, I'm off track here. But you'll notice something. This is also a get request. Get add word score. Now, it makes sense that you would have parameters for a get request like search. So this is a get request. Search. Do you have the word kitten in your database? If so, could you please tell me its score? That's what's happening here. That's what's happening here. But in this particular route, this is a get request. And my get request is saying, here are this word and this score. Will you please add those to your database? And according to my discussion over here, that should really be a post, right? If you're sending data to the server for the server to save, that's really a post and not a get. The thing is, though, it's just so darn convenient to use a get. Why is it so convenient? Because that's what the browser does natively on its own. I can actually now just make a get request by saying, localhost 3000, add yellow, which is maybe a neutral color or slightly positive. So this is me now making a get request. That get request is done. It's saved into the database. I can use the fact that I can add parameters to a get request through the route or a query string. There are lots of ways to do it to actually have the server save, to send stuff to the server for it to do stuff with as well. And because it's just a little bit of data, it's just so easy to do it in the route with a get request, why not? But there are times where this get request isn't sufficient, and you really need to use a post. Well, one is username and password. So if security matters, you don't want to have the username and password just in the URL path as part of a get request that anybody could potentially hack and get access to. So this is really where for hidden data, it really needs to be a post. The other thing is like media. If you want to upload an image to a server or upload a sound file, you can't do that through a get request. You can't easily, although there's some tricky ways you could like base64 encode your image into like a number string that goes into the URL. But basically for media, but really what I mean in a lot of ways is like large data. So if I want to send a full paragraph to be our full many paragraphs, a thousand words to be analyzed and have the server send me a result back, I want to send that data through a post rather than a get because it's going to be much too awkward to try to like encode a full paragraph of text into some sort of route or URL query string. So this is really the difference between get and post. Post is for sending data. It happens behind the scenes in an invisible way. Get is for making a request and it happens right in a visible way because it's really basically the same as what you would be doing to type in a URL into the address bar. Okay, so now that we've covered that, how do I, there's two things I need to figure out. One is how do I handle a post in the server? The nice thing is you could imagine that it might be something like this, app.post.analyze. Analyze and analyze this, right? So this is now, I'm going to write and I have a function to handle that post request. So this is now how instead of a get request in a node program I can handle a post by saying app.post.analyze this. And then what's the other part? How do I make a post request? Well, there are countless ways you could do it because you could look at jQuery and you could look at native JavaScript and you could look at any JavaScript framework you want. In p5 there's a very nice lovely little function called HTTP post. And so let's, I'm going to add something. What I'm going to do is in the, here, I'm going to add a text area. So I'm going to say, I'm going to make another paragraph and I'm going to say text area id equals text input. Text area, let's just do columns equals 40 and rows equals 5. So we can, and so if I go now to here, we should see there's a text area there. So what I want to do is when I, and I'll add another submit button. I'll call it analyze. So now I have an analyze button. What I want is when I analyze this button to make a post request to the server. So what I need to do is I need to also in JavaScript get access to the analyze button. So I'm going to go to the analyze button. I'm going to go to the analyze button. I'm going to go to the analyze button. Button A for analyze and analyze. And analyze this I'll say. Function analyze this. And say dot value and then I want to make a post. And the way I make a post is with the p5 function HTTP post. So when I wanted to make a get request, load JSON was all I needed to do. Because load JSON by default is a get request just like load image or load. Any of the load functions. There is by the way an HTTP get method which allows you to have more control over that get request. But here I just want to make a post. So okay. So I'm going to do p5.js reference. And I'm going to look at HTTP post. And let's look at this page. The difference is and boy does this look confusing. The difference is when I make a post I need to send it a whole object which is all the data that I want included as part of the post. So this allows for a lot of possibilities because I can have multiple fields and I have multiple kinds of data. So really there's a bunch of stuff I need here. But what I care about most right now is the is I need to give it the path which is the route. The data that I want to send. I guess what kind of data it is which I'm going to make it JSON based data. And then a callback for when it's finished. So let's do all of that. And I'm going to say where was that? HTTP post. So first I need to say data is the text is the text. And that's actually all I need to post is just what's in there. So but I could add a lot more things into this object. And I want to go to slash analyze. Is that how I did it in like the load JSON at I don't need a slash in front. Sorry. Analyze. And then I need to say it's going to be JSON. And then I need to say data posted. And then I could also say data error. But let's let's skip the error right now. I should actually probably data post error. So let's write those functions. Function data posted. Result. I'm going to say console dot log result. And in the server now. So now I've posted this data to the server. And again, this could be a lot more stuff than just that text. And in this function and post, I should have a callback for error. And so now I just want to look at what comes back after it's posted. OK. So now in the server, I'm just going to say response dot send. Thank you. And actually, let's make this a reply message. Thank you. And send that reply. And let's just look at console dot log request. So we're going to figure out how do we get the stuff that was posted right here in the request. OK. Here we go. So let's see how far did we get here. First, I need to restart the server. And I want to go to this page here. The here, which I should see this. I want to look at the console. And now if I this is a test and I hit analyze, I got the message back. So the round trip happened. The question now is let's look at what's in the request. Oh my goodness. How am I ever going to look through all this and find the data that was posted? So here's the thing. Pause. Time out. Oh, by so if somebody in the chat by the way, so this part's going to have to get edited out. Thank you, Matia. Somebody in the chat says I keep changing my localhost port. So I'm using a different port for the node stuff as a one-time thing. I'm using a different port for the node stuff as a when I run like a Python server. But yes, I do keep changing that. So I need to look something up because I forgot what it is. And I just want to not look it up in the video tutorial. I want to act like I know what I'm doing. I particularly do not. And I'm going to go to node API. Maybe this one's actually going to have a simpler one. No, this one won't have the post. This is an example. Uh that I made. Ah yeah, so I need this. I need the body parser package. So let's look for that body parser. Node package. And I just want to look it up on GitHub because let's see if there is a very simple example. Oh, why isn't there like a... there we go. So I'm just looking at this. So this is the example. And then in my example, is that the same body parser.json? Yes. And app.usebodyparser URL encoded extended true. Extended false, whatever. And then what I did is... I know you probably can't see this. I'm just looking this up. Request.body.text. Okay, so that should do it. Okay. Okay, so I am good here. Okay, so where was I? Ah, yes. Okay. How do I bind that text? This is a mess of data that comes in with the request. Now we know if you go back to the server when I had a get request, I can simply just look at the request's parameters. Because these are the parameters that come in with the request with a get. With a post request, it's not so simple. There isn't just the parameters. There's a get request. And then there's a get request. It's not so simple. There isn't just the parameters. There's this part of it called the body, which has all this information in it. And I actually... And I have to parse it. Luckily for us, there's a node package which will do this parsing for us. And this parsing... This package is called body parser. So what I need to do is I need to install that package, body parser. And I want to save that as part of this project. So I'm saving it. I have the body parser package. And then what I want to do... And I'm on... I'll include a link in this video's description. But I'm on the GitHub repository. I just want to look at... I just want to... I need to require it. So I need to add it to my code at the top. Or it doesn't really... I'm going to add it here where I require express. And then after I create the app, this is serving static files. I now want to use this body parser package. I'm going to just scroll all the way down here on this documentation page where I know there's a quick example. And I can grab this code. And I can add it in. So I now am telling this app, this web application, which is an express application that's listening on this port, which uses static hosting for the stuff in the website folder, now also has the body parser. And I want to use JSON because I want to get the stuff... I want to parse everything as JSON. Okay. So now that I have that, I should be able to say... Oh boy, do I hope that that's true. In the... In the post, where I'm handling the post, I've already lost it right here. Let's say console.log request.body. And so I'm going to restart the server. Whoops. And I'm going to refresh this page. I'm going to say this is a test. I'm going to hit analyze. I got the message back. And oops. I got an empty object. But I think maybe just the... I think maybe just the... The console isn't like logging it properly. And so at some point, I want to show other ways of debugging and know where you can get a nice JavaScript console. But I'll have to do that in another video. Let's look if I can say... Where am I here? A body. In Sketch.js, boy, this is getting complicated. I sent it as data with a text property. So I should be able to say body.text. And I should see what was sent. So let me try doing this one more time and hitting refresh. And this is a test. And I look in here. Undefined. Time out. I have to debug this. I forgot what I did wrong. OK, let's see here. What did I do wrong? Let's look at my existing example. Do I need this? No, no, use function. OK, let me see if there was something I missed in my other example. Oh, boy, it's already five o'clock. Wow. This stuff always takes twice as long, if not four times as long as I think. But I'm close to the end of this. I made an example that does this. Let's look. And I want to mention cores. I mean, could extended true matter? I don't think so. Let's just let me grab this. Let me just make sure. This is the same, really. OK. So this is what I have. And then when I handle the post, analyze, analyze, request, response, request body text. This looks the same, right? All right, I'm going to have to look at the client, obviously, to see if that's where it's different. Let's also go to the client. I don't know if anybody in the data is not in the post request. Oh, I forgot to put data. I forgot to post the data. I bet you that's it. How many subscribers have I lost during the course of this making of this video? A test, analyze, thank you. And there we go. OK. Thank you to David in the chat who helped me solve this problem. Hopefully, I would have noticed it eventually. But I just completely forgot this. I need to take this out. I need to back up to here. This is the same. I just had this as false. I don't think that matters. Let me go down to here. And let me go to back to here, console.log. Console.log. Where, where, where, where, where, where? For when it's finished or if there's an error. What's missing? I just listed five things. I forgot to actually send the data. Data goes here. So I forgot to post the data. So there's no way for me to read or receive the data if I didn't post it. So that's done now. And I think it's going to work. So let me, oh, I actually don't have to restart the server because I just changed the client code. And you know what? This is driving me crazy. I just want to in the client, I just want to say, oh, this is not the right server. I'm going to say, just add something here. Like, I am happy today because I saw a rainbow and some kittens. OK, so now I have some text pre-filled in. I can hit analyze. I got a message saying thank you. And I can go look at the server and I can see that that data came into the server via the post. We have a post. We have a post working. That is awesome. OK, so now all I need to do is do sentiment analysis. I really should just give this to you as an exercise and end this video now. But I'm going to finish it up myself. So the nice thing is I, all I can, this isn't too hard for me to do now in the server. I'm going to go to the server code. And right here, instead of console logging, I want to look at and say var text equals request.body text. Then I want to split it up, text.split. And I'm going to use just a regular expression here to split it up into words by anything that's not a letter or number. I explain this in so many videos. But this is pattern matching and backslash capital W is anything that's not a to z or zero through nine. And so now I can loop through those words. And I can say now what I want to do is I want to first look, I need a total score. So I'm going to have a total score started at zero. I need to say if the, if, what's it called? Additional, pause. My two word lists are called words, my two word lists are called words and aphan. So what I want to do here is do if, if words, oh boy, I should call this, I need to call this additional. So because that's going to be a problem. Let's look everywhere I use words because additional, additional, additional, oh boy, additional. Okay, I just don't want to confuse my variable names. So here I should just call that tokens that I wouldn't have that problem. But if additional has own property. And I want to see if word equals words index I has own property word. Then total score plus equal additional. That word, the value and a number. I'm doing this kind of fast. I should reference you. I did this exact sentiment analysis entirely in a separate coding challenge, which I went through in a little more detail. So I can check if it's there. So I can check if it's there. If it's not there. Then I should also check if it is in the aphan list. And if it's in either one of those, I also let's get make a word list. We'll just make it a word list. So we'll actually make it a word list. An array. I could say in either of these cases, word list dot push an object that has word, word, score, and then and the score is var. The score is. I can say var score if it's in additional. Oh, yeah. Score equals number additional and then add that. This is not interesting to watch anymore. And otherwise, if it's in aphan. That's the score. And. And then sorry. If I and so. Number. OK, so I'm just cleaning this up because now I can say total score plus equal. Plus equal the score. So the score can start for every word can be assumed to be zero. And if it's in additional, add the score. You know, actually, so I don't need this here anymore. Get the score from additional. If it's in aphan, get the score from aphan. And now what I could do, let's just get this working. I could say reply is score. Total score. And comparative. Comparative. Comparative. Comparative in the aphan one eleven sentiment analysis, the comparative value. Is the total score. Divided by how many words are in the text words dot link. So now we should see that I'm getting the text. So my server is now receiving the text as the post request chopping up into words, looking at every single word, seeing if it's in one of the lists and then spitting back. So let's run this. Oh, I need to restart the server. Oh, I have an error. Words is not defined where in line number six, which is here. I don't actually need this console log was just for debugging earlier. So let's run the server again. Refresh and hit analyze. And we got an error. False. I got some error. So what happened? Let's look at the console. Oh, yeah, I got an error. Comp is not defined. So I made a mistake because I'm trying to do this so quickly and I'm not being careful. And where is where I have lost where the code this is. Oh, comp. Oh, wait, comp. And then this could be comparative. I'm just not naming things carefully. So this is the reply that I want to send back. Oops, I have to restart the server. There we go. And look at this. Every time I analyze, I get both the comparative score and the score. Now, I really want to also send back a list of words. And I want this to be an exercise. I'm going to do it anyway because I want to see it here. So what I'm going to do is I am going to also say I'm going to make a variable called found. Just add into an I'm going to make an array of objects with word, word, score, score, which is a little awkward. But now what I can do is I can also send back the list of words. So I'm just saving every word and its score if it was found in one of those lists. Because now if I run this again and it hits analyze array zero. So I did something wrong. Let's look at this again. Found is false. If found, word list dot push. So why would the list have nothing in it? Edit this part out. La la la la la. Thinking, thinking, thinking. Word list push. I made a word list with an empty. And then I say if it's in there, found. I say if it's in there, found. If it's in there, found. If found, push it in the list. All right, well, let's. Oh, whoa. The word list has to be out here. I initialized the array. Oh, I reinitialized the array in there. Hold on. Whoops. I initialized the array in the loop, which means I kept clearing it out. So of course, there's nothing in the array. Let me take that out there. Run this again. Refresh. Analyze. And now we can see this is what it got. This is the comparative. Oh, this is very small for you to read. Whoops. You can see here that this is the comparative. That's the score. And this is the list, happy and rainbow. So what I could say is, hmm, why didn't it get kittens? So what I would like to do is add kittens. And kittens should have a score of four. So I'm now going to hit submit. And now when I analyze it again, whoops, we can see that I got a score of 14. And let's say today is really positive with a number 100. I can add that to the database and analyze again. And now I have a score of 114. So now I have both. And on one page, I have both a system. Wow, we've really finished this example, where I can submit to the database using a get request. I can post to have text analyzed. I can submit to the API with a post. And I can get back the results. Now, here's the thing. As a challenge, as an exercise, take this exact code and really work on the interaction here and how this works. How could you actually effectively crowdsource a full word list? How could you use an animation or use design to show the results in the word list? You could click on them. And what if it showed you all the words here and the ones that are missing? And it let you type them in and hit submit. So you could kind of like, how could you train this to have a larger database of words for more sophisticated sentiment analysis? This would be, I think, a challenge for you to take this and take it further. But this is a fully functioning API. There's one piece of this that I think I should mention. This API can be accessed by my, so the server, the Node server, the thing running right here can be accessed by my server. And I can also access it from my own web page. So I can access it from my own web page. And I can actually get requests by this web page because this web page is hosted on this server. But what if you wanted to make a sentiment analysis API that is running somewhere, but anybody could access it from their own web pages and their own programming without being the programmer of the server? Well, to do that, what you want to do is open up on your server something called cross origin resource sharing. So you have a programmer of the server who also is hosting HTML files packaged with it. And to do that, you need to enable cores, which stands for cross origin resource sharing. You've probably encountered the flip side of this error. Anytime you've tried to request something from a server and you've got this XML request, not allowed, cross origin resources, not enabled. So if I want to enable cores, I can search for cores node package express. This is something I can enable with express. And I can actually just install this cores package. And I can say npm install cores dash dash save. Now I've installed that node package. And I can go here and I can just grab app dot use. Oh, I can say cores require cores. Right up here, the same place that I used body parser, var cores equals require cores. And app use body parser, app use et cetera, app use cores. So now I now have enabled cores. So if I put this, if I deploy this to Heroku or Digital Ocean or whatever web server hosting environment, my wherever my server is. Now, if I handed out the IP address or the URL, other people could call load JSON or HTTP post from their own server. So there is no really much to the API here. So the core we're going to need is something to issue PFCs. So we're going to make sure we've got an IP address owner, someone who one to protect the identity of an IP address holder, of some sort, relatively recently. And I'm going to give this IP address holder the IP address that has been given. Let's switch back to our notepad. How does that work? Pause. Does it not override today? It still has 100. It should override it, right, if it's already in there? I don't know why I attempted to do something in this last minute of this video. I was done. Oh, score is required. Ooh. Whoops. What did I mess up? Sorry, something got broken. I'm debugging, I'm debugging. Submit word. Word. Score. Oh, I'm probably... Once again, I have this score variable too many different places thing, probably. Score input. Let's just change that. I bet. Let's see if that's the problem. Add word plus score. Let's try that again. Oh, I wonder if you send it zero. You can't give it a score of... Oh, you can't give it a score of zero. Because zero must be like false or something. Oh, yeah, zero is evaluated as false. Oh, that's just a little mistake that I have in mind. Now that I gave it... I don't know what this... Cut this part out. I don't know why I was just fixing that. Where was I in this video? Cut back, rewind, rewind. Let me finish this video off. I don't know, it'll cut at some point. I just wanted to make sure it was still working. It's still working, but I'll fix that. Let me actually fix that. Let me show you what I mean in case you're wondering. This doesn't need to make it into the actual published version, the edited version of this tutorial. If I go to the get request for add... I'm doing so much scrolling, it's crazy. What I'm doing is I'm saying if there is no score, score is required. But if the score is zero, that'll evaluate. I want to say if score does not equal zero... If score... If no score and score does not equal zero. This is me just checking. I could also say if score equals undefined, because I think that's what it would be. But I could just say here... Let me just double check and make sure that... This is for things that are invalid, and I want zero to be valid. It's only invalid if it's something like null or undefined or hello, some text, but not zero. I need better error checking here. Let me just see that that works. And then today, zero. It added a sign, so that fixed it. I don't know where I was. I was checking to make sure this works. So, and then... But I'm just going to finish off this video. I'll just say some wrap-up words. So, this concludes my series about how to build an API from scratch using Node and a front end to that API using p5.js. Hopefully, you found this useful. If you make an API, if you build something, share it with me. Ask in the comments. Like, share this video. I guess those are the things I'm supposed to say. And I look forward to seeing you. I'll do some follow-up videos as part of this playlist if there are some good questions or other features that I think of adding. Okay? See you soon. Goodbye. Yes, Lordius, I could say score does not equal undefined. All right. So, thank you, everybody, for watching today. It is 5.20. Oh, my goodness. This has been a... Weirdly, the live stream says it's only been going for 10 minutes. Did it, like, stop and restart? I don't know why it's saying that. But this has been two hours. Hopefully, the live stream archive is okay, but I've been recording this. I lost... When did I lose all those viewers? There was some point where I went from 112 to 88. I have this, like, graph. You guys can't see this. I should show this to you. I have this graph of viewers. I don't know what I was doing a little after 5 where I lost everybody. Oh, it restarted a few times. I wonder why it did that, because it didn't on my end. So, hopefully, it didn't... I don't know if it's chopped it up into multiple videos, but we'll have to fix that later. I had 200 at one time. That's crazy. But I can understand why not everybody wanted to watch it this whole time. So, thank you, guys, for tuning in. I definitely have to go. But I will stay here for five minutes to see if there are any last questions in the chat. Next week, I will be back. And the things that I have not gotten to are how to build a Chrome extension. That's going to be a full-fledged video. I'm going to be doing a lot of stuff. I'm going to be doing a lot of stuff. I'm going to be doing a lot of stuff. I'm going to be doing a lot of stuff. How to build a Chrome extension. That's going to be a full set of tutorials. Maybe I'll do that next week. I wanted to do videos on using Sheetsu, which is an API for... Basically, turn a Google Sheet into an API, which is very useful, as well as Firebase. So, I wanted to look at... Oh, did I win the Hamilton Lottery? Thank you, guys. Thank you for asking. Let me check. Because, you know, you have to claim the tickets by, like... Oh, shoot. I think I already missed claiming the tickets. I think I have to do it within an hour. I really hope I didn't win. Boy, wouldn't that be crazy if I won? Hamilton Lottery, Hamilton Lottery. Unfortunately, you were not selected. So, not to worry. I didn't win. But maybe next time. Okay. When did I start... Oh, when did I start programming? And are you using... You know what? I forgot something. So, this is great, because this question is being asked, and I always forget to mention this, and it came up in a discussion on Facebook recently, which is that... So, some people sometimes ask where I first discovered processing and how I got involved with it. And I was a student at ITP between 2001 and 2003. And at the time, I was programming in Director, a Macromedia Director. I was programming in Java, just plain old Java. And I was programming in C++, plain old C++. Open Framework, Cinder. None of these things existed. Processing did exist, but I was not aware of it. And the first person to run a processing workshop at ITP, and this is actually still online, JT Nimoy Processing Workshop. Notes from this workshop. It's really terrific. If I can find it... How come I can't find it right now? This is a fail. Processing Workshop. Let's put in ITP. Let's just put in Nimoy. There we go. Here it is. So, this is a tutorial from, I believe, 2003. You can read it from... First year of ITP, Dettelev Social Engineering, to bring open source culture to attention. I taught early releases of processing to students and faculty, and current faculty who were students then, myself included, and chose to use processing to create a number of projects. Processing actually had two fives in the name. Then, because of the URL, processing was not available. And so this workshop, which you can see here, and then by the fall semester, 2004, processing was adopted into the Introduction to Computational Media course series as a primary teaching tool. So, if you're interested in a little history, the original date of this was Saturday, February 8, 2003. And you can look at the tutorial. It's both in English, and it was also translated in Japanese. And you can find this tutorial, and you can see what's interesting about this is to see it's comparing it to Flash. And I remember looking at this tutorial and being fascinated and amazed by it. And this, I think, is really an inspiration to a lot of the stuff that I did with teaching and processing. Right, time and motion here. So, I encourage you to check this out. Also, at the time, Amit Pataru was teaching a class called Code and Me. I wonder if there's any documentation of this online. Archives, Code and Me. So, anyway, if somebody wants to try to do some internet research and can find the Code and Me Amit syllabus, see if you can find it. There's Amit on Twitter, and I believe JT Nimoy on Twitter is at JT Nimoy as well. And JT has done all sorts of amazing stuff, a lot of graphics for Tron, and I encourage you to check out the work of JT Nimoy as well. Okay, so I wanted to bring that up because it's come up. It's come up and, oh, I didn't pause the song. So, let's see. Oh, can you give some more info about the application process for the Processing Fellowship? Yes. We pause. Processing Foundation Fellowships. So, this is the application process. The deadline is December 19th, so you have several weeks still. I would read through this whole page, and then I would look at what the fellowships were from last year, and to apply, there's a Google form, and the Google form will go through. You need to write a description of the project. You need to write up a plan for the project and schedule for it. And the other thing, maybe it's on the – the link maybe is on the application submission form, but what I'm looking for, which I'm looking for here, something that's important, I'm not seeing it just scanning through very quickly. Project ideas, ideas. Ah. So, this link here, applicants are encouraged to familiarize themselves with the list of fellowship ideas. This is another page which has some more ideas about the kinds of things that we're thinking about. You do not need to propose something on this list, but if you're trying to brainstorm or think about what's possible, I would encourage you to check out this list as well, and I'll make sure to include links to the fellowship page, the application, and this GitHub page in this archive's description. The live stream is over, unfortunately. It has been going for two hours and ten minutes, and I'm actually going to tonight, if you're in New York City, I encourage you to – one of the fellows from last year is Tiga Brain, who did a guest ICP Learn to Teach. This event I want to get to. It starts at 6.30. I have a bunch of things to do beforehand. Ah, I really have to go. Learning to Teach is an event here in New York City co-organized by the Processing Foundation, and Tiga Brain will be presenting there along with DeAngela Duff, who is also amazing. I should have her as a guest, and Ankit Patel, who works for the Department of Education, and BBQ Dave Sheinkopf about education and creative coding. Okay. All right. So I really have got to go. I thank you all so much for tuning in, for watching, for being supportive. I feel like today was kind of a mess, but I often feel that way, and then people seem to think it was fine anyway. And so out of this I think what really only comes – maybe those should be separated into more than two videos. We'll think about that. But certainly there's the sentiment analysis coding challenge and the sentiment analysis node API video, and next week I'll be back with hopefully Chrome extensions or more about a data persistence. Okay. And I'll see you guys in the future. Stay in touch. Next week I don't know if I'll have a live stream next week just yet. Stay tuned to Twitter. I forgot to announce this on Twitter today. Still had 200 viewers, which is kind of amazing. And I'll see you all soon. Thank you all. I'll play the This song as I turn things off. I always forget the this dot, this dot, this dot, this dot. I'm going to do this dot, this dot. I'm going to do this dot, this dot, this dot. I'm going to do this dot, this dot. I'm going to do this dot, this dot, this dot. Okay. I'm going to pull up a blank screen, but you'll be able to listen to the rest of the song. You can't hear the song on that blank screen because I don't have the audio typed into that. Wire cast. Anyway, I'll just stand here. While I look and check out my e-mail, I see all the messages. When the song's over, I'll say goodbye. This dot, this dot, this dot. Never forget the this dot. I'm going to do the this dot, this dot, this dot, this dot. The this dot song. Never forget the this dot. Somebody compose that song for me. Thanks for watching, everybody. See you later.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:39.221995Z",
  "started_at": "2023-09-26T21:16:06.162886Z",
  "completed_at": "2023-09-26T21:54:30.35186Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=lCzB9V9L8d0",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 2304.188974
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/l3cerszb4ea24lt6lba2erl2ti/cancel",
    "get": "https://api.replicate.com/v1/predictions/l3cerszb4ea24lt6lba2erl2ti"
  }
}