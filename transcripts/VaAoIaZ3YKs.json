{
  "id": "6do5dpzbp7p6tdqbmsjsoxnhrm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/VaAoIaZ3YKs.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/102332 [00:00<?, ?frames/s]\n  3%|▎         | 2840/102332 [00:07<04:38, 357.58frames/s]\n  6%|▌         | 5660/102332 [00:17<05:08, 313.06frames/s]\n  8%|▊         | 8620/102332 [00:27<04:59, 312.51frames/s]\n 11%|█▏        | 11556/102332 [00:34<04:27, 339.82frames/s]\n 14%|█▍        | 14512/102332 [00:43<04:17, 341.17frames/s]\n 17%|█▋        | 17420/102332 [00:51<04:00, 352.83frames/s]\n 19%|█▉        | 19952/102332 [01:00<04:15, 322.62frames/s]\n 22%|██▏       | 22736/102332 [01:08<03:57, 335.55frames/s]\n 25%|██▌       | 25616/102332 [01:15<03:39, 348.98frames/s]\n 28%|██▊       | 28348/102332 [01:22<03:24, 361.15frames/s]\n 31%|███       | 31234/102332 [01:30<03:18, 358.95frames/s]\n 33%|███▎      | 34078/102332 [01:36<02:54, 391.95frames/s]\n 36%|███▌      | 36870/102332 [01:42<02:40, 408.57frames/s]\n 39%|███▊      | 39490/102332 [01:50<02:43, 383.31frames/s]\n 41%|████▏     | 42218/102332 [01:58<02:39, 376.40frames/s]\n 44%|████▍     | 45026/102332 [02:05<02:31, 379.41frames/s]\n 47%|████▋     | 47910/102332 [02:11<02:15, 402.25frames/s]\n 50%|████▉     | 50886/102332 [02:22<02:28, 347.04frames/s]\n 52%|█████▏    | 53562/102332 [02:28<02:13, 366.15frames/s]\n 55%|█████▍    | 56126/102332 [02:35<02:05, 369.07frames/s]\n 57%|█████▋    | 58818/102332 [02:43<02:00, 360.14frames/s]\n 60%|██████    | 61558/102332 [02:54<02:06, 321.13frames/s]\n 60%|██████    | 61558/102332 [03:07<02:06, 321.13frames/s]\n 63%|██████▎   | 64330/102332 [03:10<02:28, 255.88frames/s]\n 66%|██████▌   | 67238/102332 [03:19<02:09, 270.08frames/s]\n 69%|██████▊   | 70138/102332 [03:29<01:54, 280.31frames/s]\n 71%|███████▏  | 72994/102332 [03:36<01:34, 309.77frames/s]\n 74%|███████▍  | 75742/102332 [03:45<01:28, 300.31frames/s]\n 77%|███████▋  | 78680/102332 [03:54<01:15, 312.68frames/s]\n 80%|███████▉  | 81460/102332 [04:04<01:08, 304.04frames/s]\n 82%|████████▏ | 84332/102332 [04:13<00:59, 301.94frames/s]\n 85%|████████▌ | 87248/102332 [04:20<00:45, 332.90frames/s]\n 88%|████████▊ | 89608/102332 [04:28<00:39, 324.36frames/s]\n 90%|█████████ | 92416/102332 [04:37<00:31, 315.48frames/s]\n 93%|█████████▎| 95168/102332 [04:48<00:23, 301.00frames/s]\n 96%|█████████▌| 97960/102332 [04:56<00:14, 309.41frames/s]\n 98%|█████████▊| 100780/102332 [05:06<00:05, 297.62frames/s]\n 99%|█████████▉| 101324/102332 [05:09<00:03, 291.30frames/s]\n99%|█████████▉| 101324/102332 [05:14<00:03, 322.68frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 2,
        "id": 0,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hey, hello there.",
        "tokens": [
          50364,
          1911,
          11,
          7751,
          456,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 6.44,
        "id": 1,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 2,
        "temperature": 0,
        "text": " Welcome to another video about context-free grammars.",
        "tokens": [
          50464,
          4027,
          281,
          1071,
          960,
          466,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 7.8,
        "id": 2,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 6.44,
        "temperature": 0,
        "text": " That's what I'm talking about.",
        "tokens": [
          50686,
          663,
          311,
          437,
          286,
          478,
          1417,
          466,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 9.56,
        "id": 3,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 7.8,
        "temperature": 0,
        "text": " So I've already done, I've sort of",
        "tokens": [
          50754,
          407,
          286,
          600,
          1217,
          1096,
          11,
          286,
          600,
          1333,
          295,
          50842
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 11.48,
        "id": 4,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 9.56,
        "temperature": 0,
        "text": " explained what a context-free grammar is.",
        "tokens": [
          50842,
          8825,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 14.6,
        "id": 5,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 11.48,
        "temperature": 0,
        "text": " I looked at a JavaScript library called Tracery.",
        "tokens": [
          50938,
          286,
          2956,
          412,
          257,
          15778,
          6405,
          1219,
          1765,
          326,
          2109,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 17.02,
        "id": 6,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 14.6,
        "temperature": 0,
        "text": " And in this video, I want to look at yet another JavaScript",
        "tokens": [
          51094,
          400,
          294,
          341,
          960,
          11,
          286,
          528,
          281,
          574,
          412,
          1939,
          1071,
          15778,
          51215
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 21.64,
        "id": 7,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 17.02,
        "temperature": 0,
        "text": " library called Rita.js that has a functionality that",
        "tokens": [
          51215,
          6405,
          1219,
          32672,
          13,
          25530,
          300,
          575,
          257,
          14980,
          300,
          51446
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 24.400000000000002,
        "id": 8,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 21.64,
        "temperature": 0,
        "text": " allows you to generate text based on a grammar.",
        "tokens": [
          51446,
          4045,
          291,
          281,
          8460,
          2487,
          2361,
          322,
          257,
          22317,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.27643588306458017,
        "compression_ratio": 1.725868725868726,
        "end": 28.400000000000002,
        "id": 9,
        "no_speech_prob": 0.014059326611459255,
        "seek": 0,
        "start": 24.400000000000002,
        "temperature": 0,
        "text": " Now, I previously made a video about the Rita.js library,",
        "tokens": [
          51584,
          823,
          11,
          286,
          8046,
          1027,
          257,
          960,
          466,
          264,
          32672,
          13,
          25530,
          6405,
          11,
          51784
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 30.84,
        "id": 10,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 28.4,
        "temperature": 0,
        "text": " showed some other aspects of it,",
        "tokens": [
          50364,
          4712,
          512,
          661,
          7270,
          295,
          309,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 33.36,
        "id": 11,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 30.84,
        "temperature": 0,
        "text": " ways that you can generate and do and evaluate,",
        "tokens": [
          50486,
          2098,
          300,
          291,
          393,
          8460,
          293,
          360,
          293,
          13059,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 35.44,
        "id": 12,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 33.36,
        "temperature": 0,
        "text": " actually analyze text with the Rita library.",
        "tokens": [
          50612,
          767,
          12477,
          2487,
          365,
          264,
          32672,
          6405,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 36.68,
        "id": 13,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 35.44,
        "temperature": 0,
        "text": " And I'll make sure to link to that",
        "tokens": [
          50716,
          400,
          286,
          603,
          652,
          988,
          281,
          2113,
          281,
          300,
          50778
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 37.72,
        "id": 14,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 36.68,
        "temperature": 0,
        "text": " in this video's description.",
        "tokens": [
          50778,
          294,
          341,
          960,
          311,
          3855,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 39.26,
        "id": 15,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 37.72,
        "temperature": 0,
        "text": " So I encourage you to check that out.",
        "tokens": [
          50830,
          407,
          286,
          5373,
          291,
          281,
          1520,
          300,
          484,
          13,
          50907
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 41.4,
        "id": 16,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 39.26,
        "temperature": 0,
        "text": " But an aspect that I did not look at",
        "tokens": [
          50907,
          583,
          364,
          4171,
          300,
          286,
          630,
          406,
          574,
          412,
          51014
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 45.04,
        "id": 17,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 41.4,
        "temperature": 0,
        "text": " is the Rita grammar, the RI grammar object.",
        "tokens": [
          51014,
          307,
          264,
          32672,
          22317,
          11,
          264,
          30474,
          22317,
          2657,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 46.92,
        "id": 18,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 45.04,
        "temperature": 0,
        "text": " So how does the RI grammar object work?",
        "tokens": [
          51196,
          407,
          577,
          775,
          264,
          30474,
          22317,
          2657,
          589,
          30,
          51290
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 48.76,
        "id": 19,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 46.92,
        "temperature": 0,
        "text": " And what kinds of things can you do with it?",
        "tokens": [
          51290,
          400,
          437,
          3685,
          295,
          721,
          393,
          291,
          360,
          365,
          309,
          30,
          51382
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 51.480000000000004,
        "id": 20,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 48.76,
        "temperature": 0,
        "text": " So first of all, the RI grammar object",
        "tokens": [
          51382,
          407,
          700,
          295,
          439,
          11,
          264,
          30474,
          22317,
          2657,
          51518
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 53.480000000000004,
        "id": 21,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 51.480000000000004,
        "temperature": 0,
        "text": " is designed for use with a context-free grammar.",
        "tokens": [
          51518,
          307,
          4761,
          337,
          764,
          365,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.25968187967936196,
        "compression_ratio": 1.7993311036789297,
        "end": 56.599999999999994,
        "id": 22,
        "no_speech_prob": 0.0014325117226690054,
        "seek": 2840,
        "start": 53.480000000000004,
        "temperature": 0,
        "text": " Now, if you're wondering what a context-free grammar is,",
        "tokens": [
          51618,
          823,
          11,
          498,
          291,
          434,
          6359,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          11,
          51774
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 58.28,
        "id": 23,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 56.6,
        "temperature": 0,
        "text": " you can double back a couple of videos",
        "tokens": [
          50364,
          291,
          393,
          3834,
          646,
          257,
          1916,
          295,
          2145,
          50448
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 60.24,
        "id": 24,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 58.28,
        "temperature": 0,
        "text": " where I maybe talk through it in a bit more detail.",
        "tokens": [
          50448,
          689,
          286,
          1310,
          751,
          807,
          309,
          294,
          257,
          857,
          544,
          2607,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 62.120000000000005,
        "id": 25,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 60.24,
        "temperature": 0,
        "text": " But just to remind you, if you're wondering,",
        "tokens": [
          50546,
          583,
          445,
          281,
          4160,
          291,
          11,
          498,
          291,
          434,
          6359,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 65.88,
        "id": 26,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 62.120000000000005,
        "temperature": 0,
        "text": " a context-free grammar is a system",
        "tokens": [
          50640,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          257,
          1185,
          50828
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 68.68,
        "id": 27,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 65.88,
        "temperature": 0,
        "text": " that defines the structure of a particular language.",
        "tokens": [
          50828,
          300,
          23122,
          264,
          3877,
          295,
          257,
          1729,
          2856,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 71.68,
        "id": 28,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 68.68,
        "temperature": 0,
        "text": " And in this sense, it could be a very small, tiny little",
        "tokens": [
          50968,
          400,
          294,
          341,
          2020,
          11,
          309,
          727,
          312,
          257,
          588,
          1359,
          11,
          5870,
          707,
          51118
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 72.24000000000001,
        "id": 29,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 71.68,
        "temperature": 0,
        "text": " language.",
        "tokens": [
          51118,
          2856,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 75.2,
        "id": 30,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 72.24000000000001,
        "temperature": 0,
        "text": " Like, here's a language that has only these elements,",
        "tokens": [
          51146,
          1743,
          11,
          510,
          311,
          257,
          2856,
          300,
          575,
          787,
          613,
          4959,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 80.08,
        "id": 31,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 75.2,
        "temperature": 0,
        "text": " sentence, nouns, verbs, and the cat, dog, meows, and barks.",
        "tokens": [
          51294,
          8174,
          11,
          48184,
          11,
          30051,
          11,
          293,
          264,
          3857,
          11,
          3000,
          11,
          385,
          1509,
          11,
          293,
          16202,
          82,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 82.68,
        "id": 32,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 80.08,
        "temperature": 0,
        "text": " So there are terminal and non-terminal characters.",
        "tokens": [
          51538,
          407,
          456,
          366,
          14709,
          293,
          2107,
          12,
          7039,
          2071,
          4342,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 84.26,
        "id": 33,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 82.68,
        "temperature": 0,
        "text": " These are non-terminal characters,",
        "tokens": [
          51668,
          1981,
          366,
          2107,
          12,
          7039,
          2071,
          4342,
          11,
          51747
        ]
      },
      {
        "avg_logprob": -0.2277499348127923,
        "compression_ratio": 1.6729559748427674,
        "end": 86.2,
        "id": 34,
        "no_speech_prob": 0.00016603784752078354,
        "seek": 5660,
        "start": 84.26,
        "temperature": 0,
        "text": " meaning they get replaced with something.",
        "tokens": [
          51747,
          3620,
          436,
          483,
          10772,
          365,
          746,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 90.32000000000001,
        "id": 35,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 86.28,
        "temperature": 0,
        "text": " Sass for sentence gets replaced with the noun verb.",
        "tokens": [
          50368,
          318,
          640,
          337,
          8174,
          2170,
          10772,
          365,
          264,
          23307,
          9595,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 92.76,
        "id": 36,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 90.32000000000001,
        "temperature": 0,
        "text": " Noun gets replaced with cat or dog.",
        "tokens": [
          50570,
          426,
          1733,
          2170,
          10772,
          365,
          3857,
          420,
          3000,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 95.12,
        "id": 37,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 92.76,
        "temperature": 0,
        "text": " Verb gets replaced with meows or barks.",
        "tokens": [
          50692,
          27034,
          2170,
          10772,
          365,
          385,
          1509,
          420,
          16202,
          82,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 100.92,
        "id": 38,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 95.12,
        "temperature": 0,
        "text": " So if I start with sentence, this gets expanded to the and v.",
        "tokens": [
          50810,
          407,
          498,
          286,
          722,
          365,
          8174,
          11,
          341,
          2170,
          14342,
          281,
          264,
          293,
          371,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 103.36,
        "id": 39,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 100.92,
        "temperature": 0,
        "text": " The is terminal, so it stays as the.",
        "tokens": [
          51100,
          440,
          307,
          14709,
          11,
          370,
          309,
          10834,
          382,
          264,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 105.92,
        "id": 40,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 103.36,
        "temperature": 0,
        "text": " And becomes flip a coin, cat or dog.",
        "tokens": [
          51222,
          400,
          3643,
          7929,
          257,
          11464,
          11,
          3857,
          420,
          3000,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 107.76,
        "id": 41,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 105.92,
        "temperature": 0,
        "text": " V becomes flip a coin, cat or dog.",
        "tokens": [
          51350,
          691,
          3643,
          7929,
          257,
          11464,
          11,
          3857,
          420,
          3000,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 109.32000000000001,
        "id": 42,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 107.76,
        "temperature": 0,
        "text": " And we get this expansion.",
        "tokens": [
          51442,
          400,
          321,
          483,
          341,
          11260,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 112.92,
        "id": 43,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 109.32000000000001,
        "temperature": 0,
        "text": " So certainly, the idea here is to design",
        "tokens": [
          51520,
          407,
          3297,
          11,
          264,
          1558,
          510,
          307,
          281,
          1715,
          51700
        ]
      },
      {
        "avg_logprob": -0.2508400648068159,
        "compression_ratio": 1.8493150684931507,
        "end": 115.56,
        "id": 44,
        "no_speech_prob": 0.000026688467187341303,
        "seek": 8620,
        "start": 112.92,
        "temperature": 0,
        "text": " sophisticated and interesting grammars",
        "tokens": [
          51700,
          16950,
          293,
          1880,
          17570,
          685,
          51832
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 118.64,
        "id": 45,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 115.56,
        "temperature": 0,
        "text": " with all sorts of creative language in them",
        "tokens": [
          50364,
          365,
          439,
          7527,
          295,
          5880,
          2856,
          294,
          552,
          50518
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 120.72,
        "id": 46,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 118.64,
        "temperature": 0,
        "text": " to generate text with some purpose.",
        "tokens": [
          50518,
          281,
          8460,
          2487,
          365,
          512,
          4334,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 123.8,
        "id": 47,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 120.72,
        "temperature": 0,
        "text": " Maybe you're making automatic Harry Potter spells,",
        "tokens": [
          50622,
          2704,
          291,
          434,
          1455,
          12509,
          9378,
          18115,
          25053,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 125.56,
        "id": 48,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 123.8,
        "temperature": 0,
        "text": " or maybe you're making recipes that",
        "tokens": [
          50776,
          420,
          1310,
          291,
          434,
          1455,
          13035,
          300,
          50864
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 126.8,
        "id": 49,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 125.56,
        "temperature": 0,
        "text": " are going to randomly generate.",
        "tokens": [
          50864,
          366,
          516,
          281,
          16979,
          8460,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 128.72,
        "id": 50,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 126.8,
        "temperature": 0,
        "text": " And you're going to cook some strange thing for dinner",
        "tokens": [
          50926,
          400,
          291,
          434,
          516,
          281,
          2543,
          512,
          5861,
          551,
          337,
          6148,
          51022
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 130.84,
        "id": 51,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 128.72,
        "temperature": 0,
        "text": " based on what your context-free grammar made you.",
        "tokens": [
          51022,
          2361,
          322,
          437,
          428,
          4319,
          12,
          10792,
          22317,
          1027,
          291,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 132.08,
        "id": 52,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 130.84,
        "temperature": 0,
        "text": " Lots of possibilities there.",
        "tokens": [
          51128,
          15908,
          295,
          12178,
          456,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 133.5,
        "id": 53,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 132.08,
        "temperature": 0,
        "text": " But let's see if we can figure out",
        "tokens": [
          51190,
          583,
          718,
          311,
          536,
          498,
          321,
          393,
          2573,
          484,
          51261
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 136.24,
        "id": 54,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 133.5,
        "temperature": 0,
        "text": " how to make a simple grammar work with the Rita library.",
        "tokens": [
          51261,
          577,
          281,
          652,
          257,
          2199,
          22317,
          589,
          365,
          264,
          32672,
          6405,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 139.56,
        "id": 55,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 136.24,
        "temperature": 0,
        "text": " And then we'll also look at some other examples of grammars",
        "tokens": [
          51398,
          400,
          550,
          321,
          603,
          611,
          574,
          412,
          512,
          661,
          5110,
          295,
          17570,
          685,
          51564
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 141.4,
        "id": 56,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 139.56,
        "temperature": 0,
        "text": " that you can generate with the Rita library.",
        "tokens": [
          51564,
          300,
          291,
          393,
          8460,
          365,
          264,
          32672,
          6405,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.26068375686119344,
        "compression_ratio": 1.8121019108280254,
        "end": 145.12,
        "id": 57,
        "no_speech_prob": 0.00033534792601130903,
        "seek": 11556,
        "start": 141.4,
        "temperature": 0,
        "text": " OK, so looking at this, the first thing",
        "tokens": [
          51656,
          2264,
          11,
          370,
          1237,
          412,
          341,
          11,
          264,
          700,
          551,
          51842
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 146.64000000000001,
        "id": 58,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 145.16,
        "temperature": 0,
        "text": " you might notice is I need to say,",
        "tokens": [
          50366,
          291,
          1062,
          3449,
          307,
          286,
          643,
          281,
          584,
          11,
          50440
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 149.6,
        "id": 59,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 146.64000000000001,
        "temperature": 0,
        "text": " make a new Rita grammar object.",
        "tokens": [
          50440,
          652,
          257,
          777,
          32672,
          22317,
          2657,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 151.88,
        "id": 60,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 149.6,
        "temperature": 0,
        "text": " So let me go to code.",
        "tokens": [
          50588,
          407,
          718,
          385,
          352,
          281,
          3089,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 153.72,
        "id": 61,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 151.88,
        "temperature": 0,
        "text": " And I'm going to say var.",
        "tokens": [
          50702,
          400,
          286,
          478,
          516,
          281,
          584,
          1374,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 155.84,
        "id": 62,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 153.72,
        "temperature": 0,
        "text": " I'm going to call it RG, just like in the example.",
        "tokens": [
          50794,
          286,
          478,
          516,
          281,
          818,
          309,
          497,
          38,
          11,
          445,
          411,
          294,
          264,
          1365,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 158.76,
        "id": 63,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 155.84,
        "temperature": 0,
        "text": " By the way, Rita is by Daniel Howe.",
        "tokens": [
          50900,
          3146,
          264,
          636,
          11,
          32672,
          307,
          538,
          8033,
          1012,
          68,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 161.16,
        "id": 64,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 158.76,
        "temperature": 0,
        "text": " Thank you, Daniel Howe, for this wonderful generative text",
        "tokens": [
          51046,
          1044,
          291,
          11,
          8033,
          1012,
          68,
          11,
          337,
          341,
          3715,
          1337,
          1166,
          2487,
          51166
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 161.64000000000001,
        "id": 65,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 161.16,
        "temperature": 0,
        "text": " library.",
        "tokens": [
          51166,
          6405,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 163.68,
        "id": 66,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 161.64000000000001,
        "temperature": 0,
        "text": " I encourage everybody watching to thank Daniel Howe",
        "tokens": [
          51190,
          286,
          5373,
          2201,
          1976,
          281,
          1309,
          8033,
          1012,
          68,
          51292
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 166.08,
        "id": 67,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 163.68,
        "temperature": 0,
        "text": " and contribute to the development of Rita.",
        "tokens": [
          51292,
          293,
          10586,
          281,
          264,
          3250,
          295,
          32672,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 169.36,
        "id": 68,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 166.08,
        "temperature": 0,
        "text": " RG equals new RI grammar.",
        "tokens": [
          51412,
          497,
          38,
          6915,
          777,
          30474,
          22317,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 171.68,
        "id": 69,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 169.36,
        "temperature": 0,
        "text": " Now, I'm going to leave the argument here empty.",
        "tokens": [
          51576,
          823,
          11,
          286,
          478,
          516,
          281,
          1856,
          264,
          6770,
          510,
          6707,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.23678931144818868,
        "compression_ratio": 1.658703071672355,
        "end": 174.20000000000002,
        "id": 70,
        "no_speech_prob": 0.0018101948080584407,
        "seek": 14512,
        "start": 171.68,
        "temperature": 0,
        "text": " So ultimately, there's a lot of different ways",
        "tokens": [
          51692,
          407,
          6284,
          11,
          456,
          311,
          257,
          688,
          295,
          819,
          2098,
          51818
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 176.6,
        "id": 71,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 174.2,
        "temperature": 0,
        "text": " that we might be able to create the grammar.",
        "tokens": [
          50364,
          300,
          321,
          1062,
          312,
          1075,
          281,
          1884,
          264,
          22317,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 178.23999999999998,
        "id": 72,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 176.6,
        "temperature": 0,
        "text": " I could do it dynamically in code",
        "tokens": [
          50484,
          286,
          727,
          360,
          309,
          43492,
          294,
          3089,
          50566
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 179.67999999999998,
        "id": 73,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 178.23999999999998,
        "temperature": 0,
        "text": " by just adding the rules, which is",
        "tokens": [
          50566,
          538,
          445,
          5127,
          264,
          4474,
          11,
          597,
          307,
          50638
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 181.26,
        "id": 74,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 179.67999999999998,
        "temperature": 0,
        "text": " what I'm going to try to do right now.",
        "tokens": [
          50638,
          437,
          286,
          478,
          516,
          281,
          853,
          281,
          360,
          558,
          586,
          13,
          50717
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 184.51999999999998,
        "id": 75,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 181.26,
        "temperature": 0,
        "text": " Or I could load the grammar from a pre-existing file.",
        "tokens": [
          50717,
          1610,
          286,
          727,
          3677,
          264,
          22317,
          490,
          257,
          659,
          12,
          36447,
          3991,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 185.72,
        "id": 76,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 184.51999999999998,
        "temperature": 0,
        "text": " And I can mix and match, too.",
        "tokens": [
          50880,
          400,
          286,
          393,
          2890,
          293,
          2995,
          11,
          886,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 187.56,
        "id": 77,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 185.72,
        "temperature": 0,
        "text": " But let's try to just dynamically generate it",
        "tokens": [
          50940,
          583,
          718,
          311,
          853,
          281,
          445,
          43492,
          8460,
          309,
          51032
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 188.64,
        "id": 78,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 187.56,
        "temperature": 0,
        "text": " with code.",
        "tokens": [
          51032,
          365,
          3089,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 191.28,
        "id": 79,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 188.64,
        "temperature": 0,
        "text": " So the first thing I want to do, just looking at this,",
        "tokens": [
          51086,
          407,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          11,
          445,
          1237,
          412,
          341,
          11,
          51218
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 193.28,
        "id": 80,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 191.28,
        "temperature": 0,
        "text": " is see if I have an object there.",
        "tokens": [
          51218,
          307,
          536,
          498,
          286,
          362,
          364,
          2657,
          456,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 195.32,
        "id": 81,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 193.28,
        "temperature": 0,
        "text": " So you can see I have some Rita grammar object.",
        "tokens": [
          51318,
          407,
          291,
          393,
          536,
          286,
          362,
          512,
          32672,
          22317,
          2657,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 196.88,
        "id": 82,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 195.32,
        "temperature": 0,
        "text": " It's got some rules in it.",
        "tokens": [
          51420,
          467,
          311,
          658,
          512,
          4474,
          294,
          309,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.22091202986867806,
        "compression_ratio": 1.7491408934707904,
        "end": 199.51999999999998,
        "id": 83,
        "no_speech_prob": 0.00014202325837686658,
        "seek": 17420,
        "start": 196.88,
        "temperature": 0,
        "text": " Something's happening, but I can't do anything yet.",
        "tokens": [
          51498,
          6595,
          311,
          2737,
          11,
          457,
          286,
          393,
          380,
          360,
          1340,
          1939,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 205.24,
        "id": 84,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 199.56,
        "temperature": 0,
        "text": " Now, if I go to here and I say, let me look at a result,",
        "tokens": [
          50366,
          823,
          11,
          498,
          286,
          352,
          281,
          510,
          293,
          286,
          584,
          11,
          718,
          385,
          574,
          412,
          257,
          1874,
          11,
          50650
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 205.96,
        "id": 85,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 205.24,
        "temperature": 0,
        "text": " let me expand.",
        "tokens": [
          50650,
          718,
          385,
          5268,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 208.52,
        "id": 86,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 205.96,
        "temperature": 0,
        "text": " Remember, an expansion is expanding",
        "tokens": [
          50686,
          5459,
          11,
          364,
          11260,
          307,
          14702,
          50814
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 212.88,
        "id": 87,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 208.52,
        "temperature": 0,
        "text": " from the start of the grammar out and getting a sentence that",
        "tokens": [
          50814,
          490,
          264,
          722,
          295,
          264,
          22317,
          484,
          293,
          1242,
          257,
          8174,
          300,
          51032
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 214.68,
        "id": 88,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 212.88,
        "temperature": 0,
        "text": " fits that grammar.",
        "tokens": [
          51032,
          9001,
          300,
          22317,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 219.32000000000002,
        "id": 89,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 214.68,
        "temperature": 0,
        "text": " So if I get some sort of result and I say console.log result,",
        "tokens": [
          51122,
          407,
          498,
          286,
          483,
          512,
          1333,
          295,
          1874,
          293,
          286,
          584,
          11076,
          13,
          4987,
          1874,
          11,
          51354
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 221.8,
        "id": 90,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 219.32000000000002,
        "temperature": 0,
        "text": " I should get nothing.",
        "tokens": [
          51354,
          286,
          820,
          483,
          1825,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 223.56,
        "id": 91,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 221.8,
        "temperature": 0,
        "text": " So no grammar rules found.",
        "tokens": [
          51478,
          407,
          572,
          22317,
          4474,
          1352,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 225.94,
        "id": 92,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 223.56,
        "temperature": 0,
        "text": " So the first thing that I need for a grammar to do anything",
        "tokens": [
          51566,
          407,
          264,
          700,
          551,
          300,
          286,
          643,
          337,
          257,
          22317,
          281,
          360,
          1340,
          51685
        ]
      },
      {
        "avg_logprob": -0.25288251468113493,
        "compression_ratio": 1.7767441860465116,
        "end": 227.36,
        "id": 93,
        "no_speech_prob": 0.00003944255513488315,
        "seek": 19952,
        "start": 225.94,
        "temperature": 0,
        "text": " is to have some rules.",
        "tokens": [
          51685,
          307,
          281,
          362,
          512,
          4474,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 233.88000000000002,
        "id": 94,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 227.36,
        "temperature": 0,
        "text": " So let's look now at the addRule function.",
        "tokens": [
          50364,
          407,
          718,
          311,
          574,
          586,
          412,
          264,
          909,
          49,
          2271,
          2445,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 236.64000000000001,
        "id": 95,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 233.88000000000002,
        "temperature": 0,
        "text": " So the addRule function requires a name.",
        "tokens": [
          50690,
          407,
          264,
          909,
          49,
          2271,
          2445,
          7029,
          257,
          1315,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 237.92000000000002,
        "id": 96,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 236.64000000000001,
        "temperature": 0,
        "text": " Oh, look at this, a weight.",
        "tokens": [
          50828,
          876,
          11,
          574,
          412,
          341,
          11,
          257,
          3364,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 239.16000000000003,
        "id": 97,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 237.92000000000002,
        "temperature": 0,
        "text": " Oh, I love that this has that.",
        "tokens": [
          50892,
          876,
          11,
          286,
          959,
          300,
          341,
          575,
          300,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 240.68,
        "id": 98,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 239.16000000000003,
        "temperature": 0,
        "text": " That is so fantastic.",
        "tokens": [
          50954,
          663,
          307,
          370,
          5456,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 244.04000000000002,
        "id": 99,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 240.68,
        "temperature": 0,
        "text": " So it has the rule name and the rule definition",
        "tokens": [
          51030,
          407,
          309,
          575,
          264,
          4978,
          1315,
          293,
          264,
          4978,
          7123,
          51198
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 245.12,
        "id": 100,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 244.04000000000002,
        "temperature": 0,
        "text": " and the rule weight.",
        "tokens": [
          51198,
          293,
          264,
          4978,
          3364,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 246.16000000000003,
        "id": 101,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 245.12,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51252,
          407,
          510,
          311,
          264,
          551,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 248.24,
        "id": 102,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 246.16000000000003,
        "temperature": 0,
        "text": " We're going to have to figure out what does Rita.",
        "tokens": [
          51304,
          492,
          434,
          516,
          281,
          362,
          281,
          2573,
          484,
          437,
          775,
          32672,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 249.56,
        "id": 103,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 248.24,
        "temperature": 0,
        "text": " And I honestly don't know this.",
        "tokens": [
          51408,
          400,
          286,
          6095,
          500,
          380,
          458,
          341,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 251.70000000000002,
        "id": 104,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 249.56,
        "temperature": 0,
        "text": " I'm going to figure this out while doing the video.",
        "tokens": [
          51474,
          286,
          478,
          516,
          281,
          2573,
          341,
          484,
          1339,
          884,
          264,
          960,
          13,
          51581
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 255.04000000000002,
        "id": 105,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 251.70000000000002,
        "temperature": 0,
        "text": " What does Rita expect that how this is formatted?",
        "tokens": [
          51581,
          708,
          775,
          32672,
          2066,
          300,
          577,
          341,
          307,
          1254,
          32509,
          30,
          51748
        ]
      },
      {
        "avg_logprob": -0.23902546034918892,
        "compression_ratio": 1.8699186991869918,
        "end": 256.16,
        "id": 106,
        "no_speech_prob": 0.00003373717481736094,
        "seek": 22736,
        "start": 255.04000000000002,
        "temperature": 0,
        "text": " So I'm going to look.",
        "tokens": [
          51748,
          407,
          286,
          478,
          516,
          281,
          574,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 258.12,
        "id": 107,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 256.16,
        "temperature": 0,
        "text": " I'm sure there's an example that I can look at.",
        "tokens": [
          50364,
          286,
          478,
          988,
          456,
          311,
          364,
          1365,
          300,
          286,
          393,
          574,
          412,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 262.20000000000005,
        "id": 108,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 258.12,
        "temperature": 0,
        "text": " But on the one hand, I know that I could say rg.addRule.",
        "tokens": [
          50462,
          583,
          322,
          264,
          472,
          1011,
          11,
          286,
          458,
          300,
          286,
          727,
          584,
          367,
          70,
          13,
          25224,
          49,
          2271,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 268.12,
        "id": 109,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 262.20000000000005,
        "temperature": 0,
        "text": " And so I could say maybe like start becomes a sentence.",
        "tokens": [
          50666,
          400,
          370,
          286,
          727,
          584,
          1310,
          411,
          722,
          3643,
          257,
          8174,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 271.76000000000005,
        "id": 110,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 268.12,
        "temperature": 0,
        "text": " Or let me just say the cat meows.",
        "tokens": [
          50962,
          1610,
          718,
          385,
          445,
          584,
          264,
          3857,
          385,
          1509,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 272.6,
        "id": 111,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 271.76000000000005,
        "temperature": 0,
        "text": " There's a rule.",
        "tokens": [
          51144,
          821,
          311,
          257,
          4978,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 276.24,
        "id": 112,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 272.6,
        "temperature": 0,
        "text": " Sentence becomes the cat meows, a probability",
        "tokens": [
          51186,
          23652,
          655,
          3643,
          264,
          3857,
          385,
          1509,
          11,
          257,
          8482,
          51368
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 278.28000000000003,
        "id": 113,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 276.24,
        "temperature": 0,
        "text": " of a weight of 1.",
        "tokens": [
          51368,
          295,
          257,
          3364,
          295,
          502,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 281.20000000000005,
        "id": 114,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 278.28000000000003,
        "temperature": 0,
        "text": " Now, I doubt that's enough.",
        "tokens": [
          51470,
          823,
          11,
          286,
          6385,
          300,
          311,
          1547,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2438518979133816,
        "compression_ratio": 1.5728155339805825,
        "end": 283.48,
        "id": 115,
        "no_speech_prob": 0.0020507320296019316,
        "seek": 25616,
        "start": 281.20000000000005,
        "temperature": 0,
        "text": " So that did not work.",
        "tokens": [
          51616,
          407,
          300,
          630,
          406,
          589,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 286.96000000000004,
        "id": 116,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 283.48,
        "temperature": 0,
        "text": " So I expect that I've got to conform",
        "tokens": [
          50364,
          407,
          286,
          2066,
          300,
          286,
          600,
          658,
          281,
          18975,
          50538
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 289.96000000000004,
        "id": 117,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 286.96000000000004,
        "temperature": 0,
        "text": " to the syntax of the Rita library",
        "tokens": [
          50538,
          281,
          264,
          28431,
          295,
          264,
          32672,
          6405,
          50688
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 291.44,
        "id": 118,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 289.96000000000004,
        "temperature": 0,
        "text": " and how it expects it to work.",
        "tokens": [
          50688,
          293,
          577,
          309,
          33280,
          309,
          281,
          589,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 293.44,
        "id": 119,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 291.44,
        "temperature": 0,
        "text": " Now, I'm kind of getting a little clue here.",
        "tokens": [
          50762,
          823,
          11,
          286,
          478,
          733,
          295,
          1242,
          257,
          707,
          13602,
          510,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 295.12,
        "id": 120,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 293.44,
        "temperature": 0,
        "text": " Rule not found start.",
        "tokens": [
          50862,
          27533,
          406,
          1352,
          722,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 297.72,
        "id": 121,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 295.12,
        "temperature": 0,
        "text": " So I think by definition, Rita probably",
        "tokens": [
          50946,
          407,
          286,
          519,
          538,
          7123,
          11,
          32672,
          1391,
          51076
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 299.92,
        "id": 122,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 297.72,
        "temperature": 0,
        "text": " expects, I'm just guessing from looking at this error,",
        "tokens": [
          51076,
          33280,
          11,
          286,
          478,
          445,
          17939,
          490,
          1237,
          412,
          341,
          6713,
          11,
          51186
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 304.52000000000004,
        "id": 123,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 299.92,
        "temperature": 0,
        "text": " that Rita expects there to be a rule called start.",
        "tokens": [
          51186,
          300,
          32672,
          33280,
          456,
          281,
          312,
          257,
          4978,
          1219,
          722,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 309.56,
        "id": 124,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 304.52000000000004,
        "temperature": 0,
        "text": " So let's see if that works, if I now get the cat meows.",
        "tokens": [
          51416,
          407,
          718,
          311,
          536,
          498,
          300,
          1985,
          11,
          498,
          286,
          586,
          483,
          264,
          3857,
          385,
          1509,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 310.34000000000003,
        "id": 125,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 309.56,
        "temperature": 0,
        "text": " Ah, I did.",
        "tokens": [
          51668,
          2438,
          11,
          286,
          630,
          13,
          51707
        ]
      },
      {
        "avg_logprob": -0.220148293546928,
        "compression_ratio": 1.6733067729083666,
        "end": 312.34000000000003,
        "id": 126,
        "no_speech_prob": 0.0008040816755965352,
        "seek": 28348,
        "start": 310.34000000000003,
        "temperature": 0,
        "text": " So now every time I get the cat meows.",
        "tokens": [
          51707,
          407,
          586,
          633,
          565,
          286,
          483,
          264,
          3857,
          385,
          1509,
          13,
          51807
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 314.06,
        "id": 127,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 312.34,
        "temperature": 0,
        "text": " Now, how can I get maybe?",
        "tokens": [
          50364,
          823,
          11,
          577,
          393,
          286,
          483,
          1310,
          30,
          50450
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 318.29999999999995,
        "id": 128,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 314.06,
        "temperature": 0,
        "text": " So let me see if I can now call this.",
        "tokens": [
          50450,
          407,
          718,
          385,
          536,
          498,
          286,
          393,
          586,
          818,
          341,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 319.97999999999996,
        "id": 129,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 318.29999999999995,
        "temperature": 0,
        "text": " Now, I'm expecting maybe if I make",
        "tokens": [
          50662,
          823,
          11,
          286,
          478,
          9650,
          1310,
          498,
          286,
          652,
          50746
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 323.21999999999997,
        "id": 130,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 319.97999999999996,
        "temperature": 0,
        "text": " a rule that has this syntax with the sort of tag",
        "tokens": [
          50746,
          257,
          4978,
          300,
          575,
          341,
          28431,
          365,
          264,
          1333,
          295,
          6162,
          50908
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 330.82,
        "id": 131,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 323.21999999999997,
        "temperature": 0,
        "text": " symbols around it, I can say addRule n.",
        "tokens": [
          50908,
          16944,
          926,
          309,
          11,
          286,
          393,
          584,
          909,
          49,
          2271,
          297,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 332.7,
        "id": 132,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 330.82,
        "temperature": 0,
        "text": " And I can say cat.",
        "tokens": [
          51288,
          400,
          286,
          393,
          584,
          3857,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 335.65999999999997,
        "id": 133,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 332.7,
        "temperature": 0,
        "text": " So now let's just see if I have a rule which",
        "tokens": [
          51382,
          407,
          586,
          718,
          311,
          445,
          536,
          498,
          286,
          362,
          257,
          4978,
          597,
          51530
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 337.65999999999997,
        "id": 134,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 335.65999999999997,
        "temperature": 0,
        "text": " the start is the n meows.",
        "tokens": [
          51530,
          264,
          722,
          307,
          264,
          297,
          385,
          1509,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 340.29999999999995,
        "id": 135,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 337.65999999999997,
        "temperature": 0,
        "text": " And maybe I'm going to get cat.",
        "tokens": [
          51630,
          400,
          1310,
          286,
          478,
          516,
          281,
          483,
          3857,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.21349641626531426,
        "compression_ratio": 1.606060606060606,
        "end": 340.78,
        "id": 136,
        "no_speech_prob": 0.000032699241273803636,
        "seek": 31234,
        "start": 340.29999999999995,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51762,
          10246,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 342.29999999999995,
        "id": 137,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 340.78,
        "temperature": 0,
        "text": " Now, how do I get?",
        "tokens": [
          50364,
          823,
          11,
          577,
          360,
          286,
          483,
          30,
          50440
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 345.5,
        "id": 138,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 342.29999999999995,
        "temperature": 0,
        "text": " Now, I have a feeling that the syntax it expects is this.",
        "tokens": [
          50440,
          823,
          11,
          286,
          362,
          257,
          2633,
          300,
          264,
          28431,
          309,
          33280,
          307,
          341,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 352.26,
        "id": 139,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 345.5,
        "temperature": 0,
        "text": " So there are a bunch of sort of conventional syntaxes",
        "tokens": [
          50600,
          407,
          456,
          366,
          257,
          3840,
          295,
          1333,
          295,
          16011,
          28431,
          279,
          50938
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 353.85999999999996,
        "id": 140,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 352.26,
        "temperature": 0,
        "text": " for grammars.",
        "tokens": [
          50938,
          337,
          17570,
          685,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 358.02,
        "id": 141,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 353.85999999999996,
        "temperature": 0,
        "text": " And you're going to see them in a variety of different ways.",
        "tokens": [
          51018,
          400,
          291,
          434,
          516,
          281,
          536,
          552,
          294,
          257,
          5673,
          295,
          819,
          2098,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 360.29999999999995,
        "id": 142,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 358.02,
        "temperature": 0,
        "text": " You can encode it in JSON, as we saw,",
        "tokens": [
          51226,
          509,
          393,
          2058,
          1429,
          309,
          294,
          31828,
          11,
          382,
          321,
          1866,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 362.78,
        "id": 143,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 360.29999999999995,
        "temperature": 0,
        "text": " in tracery with those sort of pound symbols.",
        "tokens": [
          51340,
          294,
          504,
          326,
          2109,
          365,
          729,
          1333,
          295,
          12013,
          16944,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 364.7,
        "id": 144,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 362.78,
        "temperature": 0,
        "text": " This, I believe, is based on some standard.",
        "tokens": [
          51464,
          639,
          11,
          286,
          1697,
          11,
          307,
          2361,
          322,
          512,
          3832,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 366.9,
        "id": 145,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 364.7,
        "temperature": 0,
        "text": " I should look it up and try to figure out what it is.",
        "tokens": [
          51560,
          286,
          820,
          574,
          309,
          493,
          293,
          853,
          281,
          2573,
          484,
          437,
          309,
          307,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2369474321603775,
        "compression_ratio": 1.5477941176470589,
        "end": 368.7,
        "id": 146,
        "no_speech_prob": 0.00002468283310008701,
        "seek": 34078,
        "start": 366.9,
        "temperature": 0,
        "text": " Annotation appear here to explain.",
        "tokens": [
          51670,
          1107,
          2247,
          399,
          4204,
          510,
          281,
          2903,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 370.97999999999996,
        "id": 147,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 368.7,
        "temperature": 0,
        "text": " But I have a feeling based on what I've done before",
        "tokens": [
          50364,
          583,
          286,
          362,
          257,
          2633,
          2361,
          322,
          437,
          286,
          600,
          1096,
          949,
          50478
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 374.7,
        "id": 148,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 370.97999999999996,
        "temperature": 0,
        "text": " and seen before that it's expecting the pipe",
        "tokens": [
          50478,
          293,
          1612,
          949,
          300,
          309,
          311,
          9650,
          264,
          11240,
          50664
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 376.42,
        "id": 149,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 374.7,
        "temperature": 0,
        "text": " symbol as one or the other.",
        "tokens": [
          50664,
          5986,
          382,
          472,
          420,
          264,
          661,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 378.82,
        "id": 150,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 376.42,
        "temperature": 0,
        "text": " Let's say what would happen if I didn't do this?",
        "tokens": [
          50750,
          961,
          311,
          584,
          437,
          576,
          1051,
          498,
          286,
          994,
          380,
          360,
          341,
          30,
          50870
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 380.09999999999997,
        "id": 151,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 378.82,
        "temperature": 0,
        "text": " Cat, dog.",
        "tokens": [
          50870,
          9565,
          11,
          3000,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 381.9,
        "id": 152,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 380.09999999999997,
        "temperature": 0,
        "text": " Well, I'm going to get the cat, dog, meows.",
        "tokens": [
          50934,
          1042,
          11,
          286,
          478,
          516,
          281,
          483,
          264,
          3857,
          11,
          3000,
          11,
          385,
          1509,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 382.53999999999996,
        "id": 153,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 381.9,
        "temperature": 0,
        "text": " That's what I'm getting.",
        "tokens": [
          51024,
          663,
          311,
          437,
          286,
          478,
          1242,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 384.34,
        "id": 154,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 382.53999999999996,
        "temperature": 0,
        "text": " That's the whole thing that's replaced.",
        "tokens": [
          51056,
          663,
          311,
          264,
          1379,
          551,
          300,
          311,
          10772,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 387.38,
        "id": 155,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 384.34,
        "temperature": 0,
        "text": " But if I put this pipe symbol here,",
        "tokens": [
          51146,
          583,
          498,
          286,
          829,
          341,
          11240,
          5986,
          510,
          11,
          51298
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 390.26,
        "id": 156,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 387.38,
        "temperature": 0,
        "text": " the cat meows, the dog meows, the cat meows, the dog meows.",
        "tokens": [
          51298,
          264,
          3857,
          385,
          1509,
          11,
          264,
          3000,
          385,
          1509,
          11,
          264,
          3857,
          385,
          1509,
          11,
          264,
          3000,
          385,
          1509,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 391.74,
        "id": 157,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 390.26,
        "temperature": 0,
        "text": " So we can see now the rules.",
        "tokens": [
          51442,
          407,
          321,
          393,
          536,
          586,
          264,
          4474,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.224126419463715,
        "compression_ratio": 1.788888888888889,
        "end": 394.9,
        "id": 158,
        "no_speech_prob": 0.00041731350938789546,
        "seek": 36870,
        "start": 391.74,
        "temperature": 0,
        "text": " Now, one thing I'm curious about is does this require these tags?",
        "tokens": [
          51516,
          823,
          11,
          472,
          551,
          286,
          478,
          6369,
          466,
          307,
          775,
          341,
          3651,
          613,
          18632,
          30,
          51674
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 397.21999999999997,
        "id": 159,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 395.5,
        "temperature": 0,
        "text": " It does not.",
        "tokens": [
          50394,
          467,
          775,
          406,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 400.65999999999997,
        "id": 160,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 397.21999999999997,
        "temperature": 0,
        "text": " The cat, the cat, the cat, the cat, the dog.",
        "tokens": [
          50480,
          440,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3000,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 405.21999999999997,
        "id": 161,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 400.65999999999997,
        "temperature": 0,
        "text": " So we can see here that this can be a useful distinction just",
        "tokens": [
          50652,
          407,
          321,
          393,
          536,
          510,
          300,
          341,
          393,
          312,
          257,
          4420,
          16844,
          445,
          50880
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 410.58,
        "id": 162,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 405.21999999999997,
        "temperature": 0,
        "text": " for ourselves to illustrate what I mean to be non-terminal.",
        "tokens": [
          50880,
          337,
          4175,
          281,
          23221,
          437,
          286,
          914,
          281,
          312,
          2107,
          12,
          7039,
          2071,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 413.78,
        "id": 163,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 410.58,
        "temperature": 0,
        "text": " Maybe put the tag, the greater than, less than around it.",
        "tokens": [
          51148,
          2704,
          829,
          264,
          6162,
          11,
          264,
          5044,
          813,
          11,
          1570,
          813,
          926,
          309,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 415.21999999999997,
        "id": 164,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 413.78,
        "temperature": 0,
        "text": " And that can be useful here.",
        "tokens": [
          51308,
          400,
          300,
          393,
          312,
          4420,
          510,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 418.02,
        "id": 165,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 415.21999999999997,
        "temperature": 0,
        "text": " So one thing that I'm kind of, the other thing",
        "tokens": [
          51380,
          407,
          472,
          551,
          300,
          286,
          478,
          733,
          295,
          11,
          264,
          661,
          551,
          51520
        ]
      },
      {
        "avg_logprob": -0.3759065454656428,
        "compression_ratio": 1.748792270531401,
        "end": 422.17999999999995,
        "id": 166,
        "no_speech_prob": 0.00024923167075030506,
        "seek": 39490,
        "start": 418.02,
        "temperature": 0,
        "text": " that I'm kind of curious about is if I say this,",
        "tokens": [
          51520,
          300,
          286,
          478,
          733,
          295,
          6369,
          466,
          307,
          498,
          286,
          584,
          341,
          11,
          51728
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 425.58,
        "id": 167,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 422.18,
        "temperature": 0,
        "text": " I could also probably put them in a separate line.",
        "tokens": [
          50364,
          286,
          727,
          611,
          1391,
          829,
          552,
          294,
          257,
          4994,
          1622,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 428.90000000000003,
        "id": 168,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 425.58,
        "temperature": 0,
        "text": " The dog, the dog, the cat, the cat, the dog.",
        "tokens": [
          50534,
          440,
          3000,
          11,
          264,
          3000,
          11,
          264,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3000,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 432.26,
        "id": 169,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 428.90000000000003,
        "temperature": 0,
        "text": " And so now let's look at, let's think about this weight.",
        "tokens": [
          50700,
          400,
          370,
          586,
          718,
          311,
          574,
          412,
          11,
          718,
          311,
          519,
          466,
          341,
          3364,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 435.74,
        "id": 170,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 432.26,
        "temperature": 0,
        "text": " So if I go back now to the documentation",
        "tokens": [
          50868,
          407,
          498,
          286,
          352,
          646,
          586,
          281,
          264,
          14333,
          51042
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 440.18,
        "id": 171,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 435.74,
        "temperature": 0,
        "text": " and we look at the rule weight, optional defaults to 1.",
        "tokens": [
          51042,
          293,
          321,
          574,
          412,
          264,
          4978,
          3364,
          11,
          17312,
          7576,
          82,
          281,
          502,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 443.78000000000003,
        "id": 172,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 440.18,
        "temperature": 0,
        "text": " So how might I alter the probability?",
        "tokens": [
          51264,
          407,
          577,
          1062,
          286,
          11337,
          264,
          8482,
          30,
          51444
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 445.98,
        "id": 173,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 443.78000000000003,
        "temperature": 0,
        "text": " So I'm just going to make sort of a guess",
        "tokens": [
          51444,
          407,
          286,
          478,
          445,
          516,
          281,
          652,
          1333,
          295,
          257,
          2041,
          51554
        ]
      },
      {
        "avg_logprob": -0.3289307680996982,
        "compression_ratio": 1.6123348017621146,
        "end": 450.26,
        "id": 174,
        "no_speech_prob": 0.0004583121626637876,
        "seek": 42218,
        "start": 445.98,
        "temperature": 0,
        "text": " that if I do something like 5, which",
        "tokens": [
          51554,
          300,
          498,
          286,
          360,
          746,
          411,
          1025,
          11,
          597,
          51768
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 454.53999999999996,
        "id": 175,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 450.26,
        "temperature": 0,
        "text": " is a 5, then I've got kind of a 5 to 1,",
        "tokens": [
          50364,
          307,
          257,
          1025,
          11,
          550,
          286,
          600,
          658,
          733,
          295,
          257,
          1025,
          281,
          502,
          11,
          50578
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 458.26,
        "id": 176,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 454.53999999999996,
        "temperature": 0,
        "text": " maybe a 5 out of 6 chance of picking cat over dog.",
        "tokens": [
          50578,
          1310,
          257,
          1025,
          484,
          295,
          1386,
          2931,
          295,
          8867,
          3857,
          670,
          3000,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 460.42,
        "id": 177,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 458.26,
        "temperature": 0,
        "text": " And what we could do is I could also",
        "tokens": [
          50764,
          400,
          437,
          321,
          727,
          360,
          307,
          286,
          727,
          611,
          50872
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 466.3,
        "id": 178,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 460.42,
        "temperature": 0,
        "text": " do this maybe 100 times just to sort of see how this works.",
        "tokens": [
          50872,
          360,
          341,
          1310,
          2319,
          1413,
          445,
          281,
          1333,
          295,
          536,
          577,
          341,
          1985,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 471.38,
        "id": 179,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 470.21999999999997,
        "temperature": 0,
        "text": " And let's run this.",
        "tokens": [
          51362,
          400,
          718,
          311,
          1190,
          341,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 476.74,
        "id": 180,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 474.18,
        "temperature": 0,
        "text": " And so you can see here it's picking cat.",
        "tokens": [
          51560,
          400,
          370,
          291,
          393,
          536,
          510,
          309,
          311,
          8867,
          3857,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.3545336271587171,
        "compression_ratio": 1.6368715083798884,
        "end": 479.09999999999997,
        "id": 181,
        "no_speech_prob": 0.00033534879912622273,
        "seek": 45026,
        "start": 476.74,
        "temperature": 0,
        "text": " It picked cat 16 times, then it picked dog.",
        "tokens": [
          51688,
          467,
          6183,
          3857,
          3165,
          1413,
          11,
          550,
          309,
          6183,
          3000,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 480.78000000000003,
        "id": 182,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 479.1,
        "temperature": 0,
        "text": " Then cat four times, then it picked dog.",
        "tokens": [
          50364,
          1396,
          3857,
          1451,
          1413,
          11,
          550,
          309,
          6183,
          3000,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 482.78000000000003,
        "id": 183,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 480.78000000000003,
        "temperature": 0,
        "text": " Then cat four times, then cat seven times.",
        "tokens": [
          50448,
          1396,
          3857,
          1451,
          1413,
          11,
          550,
          3857,
          3407,
          1413,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 484.70000000000005,
        "id": 184,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 482.78000000000003,
        "temperature": 0,
        "text": " So you can see that that weighting allows",
        "tokens": [
          50548,
          407,
          291,
          393,
          536,
          300,
          300,
          3364,
          278,
          4045,
          50644
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 488.82000000000005,
        "id": 185,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 484.70000000000005,
        "temperature": 0,
        "text": " you to add the rules and kind of weight them particularly.",
        "tokens": [
          50644,
          291,
          281,
          909,
          264,
          4474,
          293,
          733,
          295,
          3364,
          552,
          4098,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 491.06,
        "id": 186,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 488.82000000000005,
        "temperature": 0,
        "text": " And I could also probably do cat or unicorn.",
        "tokens": [
          50850,
          400,
          286,
          727,
          611,
          1391,
          360,
          3857,
          420,
          28122,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 492.78000000000003,
        "id": 187,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 491.06,
        "temperature": 0,
        "text": " And both, I'm imagining both of those",
        "tokens": [
          50962,
          400,
          1293,
          11,
          286,
          478,
          27798,
          1293,
          295,
          729,
          51048
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 494.86,
        "id": 188,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 492.78000000000003,
        "temperature": 0,
        "text": " probably have the weight of 5 and the dog",
        "tokens": [
          51048,
          1391,
          362,
          264,
          3364,
          295,
          1025,
          293,
          264,
          3000,
          51152
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 496.14000000000004,
        "id": 189,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 494.86,
        "temperature": 0,
        "text": " has the weight of 1.",
        "tokens": [
          51152,
          575,
          264,
          3364,
          295,
          502,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 498.1,
        "id": 190,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 496.14000000000004,
        "temperature": 0,
        "text": " So if I ran this again, we can see",
        "tokens": [
          51216,
          407,
          498,
          286,
          5872,
          341,
          797,
          11,
          321,
          393,
          536,
          51314
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 501.5,
        "id": 191,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 498.1,
        "temperature": 0,
        "text": " there's going to be a lot of cat and unicorn and not so much",
        "tokens": [
          51314,
          456,
          311,
          516,
          281,
          312,
          257,
          688,
          295,
          3857,
          293,
          28122,
          293,
          406,
          370,
          709,
          51484
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 502.66,
        "id": 192,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 501.5,
        "temperature": 0,
        "text": " dog, I'm sort of guessing.",
        "tokens": [
          51484,
          3000,
          11,
          286,
          478,
          1333,
          295,
          17939,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 504.58000000000004,
        "id": 193,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 502.66,
        "temperature": 0,
        "text": " So I'd have to really like strictly evaluate",
        "tokens": [
          51542,
          407,
          286,
          1116,
          362,
          281,
          534,
          411,
          20792,
          13059,
          51638
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 505.54,
        "id": 194,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 504.58000000000004,
        "temperature": 0,
        "text": " how this is working.",
        "tokens": [
          51638,
          577,
          341,
          307,
          1364,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 507.70000000000005,
        "id": 195,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 505.54,
        "temperature": 0,
        "text": " But you can see it's nice that you have this ability",
        "tokens": [
          51686,
          583,
          291,
          393,
          536,
          309,
          311,
          1481,
          300,
          291,
          362,
          341,
          3485,
          51794
        ]
      },
      {
        "avg_logprob": -0.23566851699561403,
        "compression_ratio": 1.871875,
        "end": 508.86,
        "id": 196,
        "no_speech_prob": 0.006388257723301649,
        "seek": 47910,
        "start": 507.70000000000005,
        "temperature": 0,
        "text": " to manipulate the weights.",
        "tokens": [
          51794,
          281,
          20459,
          264,
          17443,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 512.86,
        "id": 197,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 509.62,
        "temperature": 0,
        "text": " So if I go back to this particular simple scenario,",
        "tokens": [
          50402,
          407,
          498,
          286,
          352,
          646,
          281,
          341,
          1729,
          2199,
          9005,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 515.0600000000001,
        "id": 198,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 512.86,
        "temperature": 0,
        "text": " let's just finish implementing that.",
        "tokens": [
          50564,
          718,
          311,
          445,
          2413,
          18114,
          300,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 518.26,
        "id": 199,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 515.0600000000001,
        "temperature": 0,
        "text": " I'm going to say the noun.",
        "tokens": [
          50674,
          286,
          478,
          516,
          281,
          584,
          264,
          23307,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 522.1800000000001,
        "id": 200,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 518.26,
        "temperature": 0,
        "text": " And I can add a cat, unicorn, dog.",
        "tokens": [
          50834,
          400,
          286,
          393,
          909,
          257,
          3857,
          11,
          28122,
          11,
          3000,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 525.02,
        "id": 201,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 522.1800000000001,
        "temperature": 0,
        "text": " I'm going to just leave the default weights.",
        "tokens": [
          51030,
          286,
          478,
          516,
          281,
          445,
          1856,
          264,
          7576,
          17443,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 528.9,
        "id": 202,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 525.02,
        "temperature": 0,
        "text": " And then I'm going to add another rule.",
        "tokens": [
          51172,
          400,
          550,
          286,
          478,
          516,
          281,
          909,
          1071,
          4978,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 530.9,
        "id": 203,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 528.9,
        "temperature": 0,
        "text": " What sound does a unicorn make?",
        "tokens": [
          51366,
          708,
          1626,
          775,
          257,
          28122,
          652,
          30,
          51466
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 532.94,
        "id": 204,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 530.9,
        "temperature": 0,
        "text": " Meows.",
        "tokens": [
          51466,
          1923,
          1509,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 533.98,
        "id": 205,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 532.94,
        "temperature": 0,
        "text": " The cat meows.",
        "tokens": [
          51568,
          440,
          3857,
          385,
          1509,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.2938427973275233,
        "compression_ratio": 1.558974358974359,
        "end": 535.62,
        "id": 206,
        "no_speech_prob": 0.000013007082088734023,
        "seek": 50886,
        "start": 533.98,
        "temperature": 0,
        "text": " The dog barks.",
        "tokens": [
          51620,
          440,
          3000,
          16202,
          82,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 540.26,
        "id": 207,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 535.62,
        "temperature": 0,
        "text": " The unicorn, the tulips.",
        "tokens": [
          50364,
          440,
          28122,
          11,
          264,
          30210,
          2600,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 541.54,
        "id": 208,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 540.26,
        "temperature": 0,
        "text": " That's the sound of a unicorn.",
        "tokens": [
          50596,
          663,
          311,
          264,
          1626,
          295,
          257,
          28122,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 543.9,
        "id": 209,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 541.54,
        "temperature": 0,
        "text": " It's a word that I made up called tulips.",
        "tokens": [
          50660,
          467,
          311,
          257,
          1349,
          300,
          286,
          1027,
          493,
          1219,
          30210,
          2600,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 545.7,
        "id": 210,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 543.9,
        "temperature": 0,
        "text": " And then I'm going to put a period here.",
        "tokens": [
          50778,
          400,
          550,
          286,
          478,
          516,
          281,
          829,
          257,
          2896,
          510,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 549.78,
        "id": 211,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 545.7,
        "temperature": 0,
        "text": " And so now we can see if I generate this,",
        "tokens": [
          50868,
          400,
          370,
          586,
          321,
          393,
          536,
          498,
          286,
          8460,
          341,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 552.3,
        "id": 212,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 549.78,
        "temperature": 0,
        "text": " we can see all of these different possible sentences,",
        "tokens": [
          51072,
          321,
          393,
          536,
          439,
          295,
          613,
          819,
          1944,
          16579,
          11,
          51198
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 554.3,
        "id": 213,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 552.3,
        "temperature": 0,
        "text": " all which conform to that grammar.",
        "tokens": [
          51198,
          439,
          597,
          18975,
          281,
          300,
          22317,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 557.18,
        "id": 214,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 554.3,
        "temperature": 0,
        "text": " So this is a very basic idea.",
        "tokens": [
          51298,
          407,
          341,
          307,
          257,
          588,
          3875,
          1558,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 559.7,
        "id": 215,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 557.18,
        "temperature": 0,
        "text": " You can imagine how you could make this much more",
        "tokens": [
          51442,
          509,
          393,
          3811,
          577,
          291,
          727,
          652,
          341,
          709,
          544,
          51568
        ]
      },
      {
        "avg_logprob": -0.2385218164942286,
        "compression_ratio": 1.596638655462185,
        "end": 561.26,
        "id": 216,
        "no_speech_prob": 0.00011061120312660933,
        "seek": 53562,
        "start": 559.7,
        "temperature": 0,
        "text": " sophisticated through nesting.",
        "tokens": [
          51568,
          16950,
          807,
          297,
          8714,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 566.18,
        "id": 217,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 561.78,
        "temperature": 0,
        "text": " So I'm going to stay away from more exciting and interesting",
        "tokens": [
          50390,
          407,
          286,
          478,
          516,
          281,
          1754,
          1314,
          490,
          544,
          4670,
          293,
          1880,
          50610
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 567.18,
        "id": 218,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 566.18,
        "temperature": 0,
        "text": " possibilities with this.",
        "tokens": [
          50610,
          12178,
          365,
          341,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 569.42,
        "id": 219,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 567.18,
        "temperature": 0,
        "text": " Here I'm just giving you the building blocks.",
        "tokens": [
          50660,
          1692,
          286,
          478,
          445,
          2902,
          291,
          264,
          2390,
          8474,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 571.5,
        "id": 220,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 569.42,
        "temperature": 0,
        "text": " But let's look at actually what happens",
        "tokens": [
          50772,
          583,
          718,
          311,
          574,
          412,
          767,
          437,
          2314,
          50876
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 575.58,
        "id": 221,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 571.5,
        "temperature": 0,
        "text": " if you want to encode a grammar not in your code,",
        "tokens": [
          50876,
          498,
          291,
          528,
          281,
          2058,
          1429,
          257,
          22317,
          406,
          294,
          428,
          3089,
          11,
          51080
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 577.54,
        "id": 222,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 575.58,
        "temperature": 0,
        "text": " but have it come from a separate file.",
        "tokens": [
          51080,
          457,
          362,
          309,
          808,
          490,
          257,
          4994,
          3991,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 580.98,
        "id": 223,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 577.54,
        "temperature": 0,
        "text": " And I can look here in the reference and look at load",
        "tokens": [
          51178,
          400,
          286,
          393,
          574,
          510,
          294,
          264,
          6408,
          293,
          574,
          412,
          3677,
          51350
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 581.5,
        "id": 224,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 580.98,
        "temperature": 0,
        "text": " from.",
        "tokens": [
          51350,
          490,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 583.34,
        "id": 225,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 581.5,
        "temperature": 0,
        "text": " Whoops, I clicked on the wrong thing.",
        "tokens": [
          51376,
          45263,
          11,
          286,
          23370,
          322,
          264,
          2085,
          551,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 584.78,
        "id": 226,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 583.34,
        "temperature": 0,
        "text": " I'm going to click at load from.",
        "tokens": [
          51468,
          286,
          478,
          516,
          281,
          2052,
          412,
          3677,
          490,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.3579146169847058,
        "compression_ratio": 1.694980694980695,
        "end": 588.18,
        "id": 227,
        "no_speech_prob": 0.00028240637038834393,
        "seek": 56126,
        "start": 584.78,
        "temperature": 0,
        "text": " So what load from says, load from a file or URL",
        "tokens": [
          51540,
          407,
          437,
          3677,
          490,
          1619,
          11,
          3677,
          490,
          257,
          3991,
          420,
          12905,
          51710
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 590.5799999999999,
        "id": 228,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 588.2199999999999,
        "temperature": 0,
        "text": " So in option, the option in JavaScript",
        "tokens": [
          50366,
          407,
          294,
          3614,
          11,
          264,
          3614,
          294,
          15778,
          50484
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 591.66,
        "id": 229,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 590.5799999999999,
        "temperature": 0,
        "text": " is going to be a callback.",
        "tokens": [
          50484,
          307,
          516,
          281,
          312,
          257,
          818,
          3207,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 594.3,
        "id": 230,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 591.66,
        "temperature": 0,
        "text": " Because when you ask for a file, it's going to happen.",
        "tokens": [
          50538,
          1436,
          562,
          291,
          1029,
          337,
          257,
          3991,
          11,
          309,
          311,
          516,
          281,
          1051,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 596.18,
        "id": 231,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 594.3,
        "temperature": 0,
        "text": " The file is going to be loaded asynchronously.",
        "tokens": [
          50670,
          440,
          3991,
          307,
          516,
          281,
          312,
          13210,
          42642,
          5098,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 598.0999999999999,
        "id": 232,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 596.18,
        "temperature": 0,
        "text": " So I need to know when the grammar is ready.",
        "tokens": [
          50764,
          407,
          286,
          643,
          281,
          458,
          562,
          264,
          22317,
          307,
          1919,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 600.42,
        "id": 233,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 598.0999999999999,
        "temperature": 0,
        "text": " So there are a bunch of different ways",
        "tokens": [
          50860,
          407,
          456,
          366,
          257,
          3840,
          295,
          819,
          2098,
          50976
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 602.62,
        "id": 234,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 600.42,
        "temperature": 0,
        "text": " grammar files can be formatted.",
        "tokens": [
          50976,
          22317,
          7098,
          393,
          312,
          1254,
          32509,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 605.18,
        "id": 235,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 602.62,
        "temperature": 0,
        "text": " And a typical way you might see is",
        "tokens": [
          51086,
          400,
          257,
          7476,
          636,
          291,
          1062,
          536,
          307,
          51214
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 607.9,
        "id": 236,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 605.18,
        "temperature": 0,
        "text": " with a syntax that looks something like this.",
        "tokens": [
          51214,
          365,
          257,
          28431,
          300,
          1542,
          746,
          411,
          341,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 610.06,
        "id": 237,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 607.9,
        "temperature": 0,
        "text": " And I have some examples that, when",
        "tokens": [
          51350,
          400,
          286,
          362,
          512,
          5110,
          300,
          11,
          562,
          51458
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 612.02,
        "id": 238,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 610.06,
        "temperature": 0,
        "text": " you look at the code examples, that load files",
        "tokens": [
          51458,
          291,
          574,
          412,
          264,
          3089,
          5110,
          11,
          300,
          3677,
          7098,
          51556
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 612.9799999999999,
        "id": 239,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 612.02,
        "temperature": 0,
        "text": " that look like this.",
        "tokens": [
          51556,
          300,
          574,
          411,
          341,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 614.5,
        "id": 240,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 612.9799999999999,
        "temperature": 0,
        "text": " Here's another sort of way that you",
        "tokens": [
          51604,
          1692,
          311,
          1071,
          1333,
          295,
          636,
          300,
          291,
          51680
        ]
      },
      {
        "avg_logprob": -0.4293671664812707,
        "compression_ratio": 1.8373702422145328,
        "end": 615.5799999999999,
        "id": 241,
        "no_speech_prob": 0.002434349153190851,
        "seek": 58818,
        "start": 614.5,
        "temperature": 0,
        "text": " might see that you can do.",
        "tokens": [
          51680,
          1062,
          536,
          300,
          291,
          393,
          360,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 618.22,
        "id": 242,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 615.58,
        "temperature": 0.2,
        "text": " So I'm going to try loading this particular file, which",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          853,
          15114,
          341,
          1729,
          3991,
          11,
          597,
          50496
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 619.82,
        "id": 243,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 618.22,
        "temperature": 0.2,
        "text": " is a.grammar file.",
        "tokens": [
          50496,
          307,
          257,
          2411,
          1342,
          6209,
          3991,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 623.22,
        "id": 244,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 619.82,
        "temperature": 0.2,
        "text": " And whoops, so let me comment this out.",
        "tokens": [
          50576,
          400,
          567,
          3370,
          11,
          370,
          718,
          385,
          2871,
          341,
          484,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 628.3000000000001,
        "id": 245,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 623.22,
        "temperature": 0.2,
        "text": " And I'm going to say rg.load from test.grammar.",
        "tokens": [
          50746,
          400,
          286,
          478,
          516,
          281,
          584,
          367,
          70,
          13,
          2907,
          490,
          1500,
          13,
          1342,
          6209,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 631.9000000000001,
        "id": 246,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 628.3000000000001,
        "temperature": 0.2,
        "text": " And I'm going to say grammar ready.",
        "tokens": [
          51000,
          400,
          286,
          478,
          516,
          281,
          584,
          22317,
          1919,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 635.58,
        "id": 247,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 631.9000000000001,
        "temperature": 0.2,
        "text": " So this is my callback for when the grammar is ready.",
        "tokens": [
          51180,
          407,
          341,
          307,
          452,
          818,
          3207,
          337,
          562,
          264,
          22317,
          307,
          1919,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 637.94,
        "id": 248,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 635.58,
        "temperature": 0.2,
        "text": " I'm going to just say, when the grammar is ready.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          445,
          584,
          11,
          562,
          264,
          22317,
          307,
          1919,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 640.1800000000001,
        "id": 249,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 637.94,
        "temperature": 0.2,
        "text": " And I'm going to say, when the grammar is ready.",
        "tokens": [
          51482,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          562,
          264,
          22317,
          307,
          1919,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.5584325114573081,
        "compression_ratio": 2.395209580838323,
        "end": 643.3000000000001,
        "id": 250,
        "no_speech_prob": 0.27508652210235596,
        "seek": 61558,
        "start": 640.1800000000001,
        "temperature": 0.2,
        "text": " And I'm going to say, when the grammar is ready.",
        "tokens": [
          51594,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          562,
          264,
          22317,
          307,
          1919,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 645.14,
        "id": 251,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 643.62,
        "temperature": 0,
        "text": " The grammar is ready.",
        "tokens": [
          50380,
          440,
          22317,
          307,
          1919,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 648.3399999999999,
        "id": 252,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 645.14,
        "temperature": 0,
        "text": " I'm going to just say, ready.",
        "tokens": [
          50456,
          286,
          478,
          516,
          281,
          445,
          584,
          11,
          1919,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 651.9,
        "id": 253,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 648.3399999999999,
        "temperature": 0,
        "text": " So if I do this and run this now,",
        "tokens": [
          50616,
          407,
          498,
          286,
          360,
          341,
          293,
          1190,
          341,
          586,
          11,
          50794
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 655.62,
        "id": 254,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 651.9,
        "temperature": 0,
        "text": " it's going to say, ah, grammar appears to be invalid JSON.",
        "tokens": [
          50794,
          309,
          311,
          516,
          281,
          584,
          11,
          3716,
          11,
          22317,
          7038,
          281,
          312,
          34702,
          31828,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 657.74,
        "id": 255,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 655.62,
        "temperature": 0,
        "text": " Please check it if you're using YAML.",
        "tokens": [
          50980,
          2555,
          1520,
          309,
          498,
          291,
          434,
          1228,
          398,
          2865,
          43,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 659.56,
        "id": 256,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 657.74,
        "temperature": 0,
        "text": " So there are so many different kinds",
        "tokens": [
          51086,
          407,
          456,
          366,
          370,
          867,
          819,
          3685,
          51177
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 661.8199999999999,
        "id": 257,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 659.56,
        "temperature": 0,
        "text": " of standardized data formats.",
        "tokens": [
          51177,
          295,
          31677,
          1412,
          25879,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 664.8199999999999,
        "id": 258,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 661.8199999999999,
        "temperature": 0,
        "text": " There's XML markup and YAML and blah, blah, blah, blah, blah,",
        "tokens": [
          51290,
          821,
          311,
          43484,
          1491,
          1010,
          293,
          398,
          2865,
          43,
          293,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          51440
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 665.5,
        "id": 259,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 664.8199999999999,
        "temperature": 0,
        "text": " blah, blah.",
        "tokens": [
          51440,
          12288,
          11,
          12288,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 667.02,
        "id": 260,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 665.5,
        "temperature": 0,
        "text": " If you've watched some of my data videos,",
        "tokens": [
          51474,
          759,
          291,
          600,
          6337,
          512,
          295,
          452,
          1412,
          2145,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 669.14,
        "id": 261,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 667.02,
        "temperature": 0,
        "text": " I kind of cover some of these different formats.",
        "tokens": [
          51550,
          286,
          733,
          295,
          2060,
          512,
          295,
          613,
          819,
          25879,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.23564728101094565,
        "compression_ratio": 1.7593984962406015,
        "end": 672.38,
        "id": 262,
        "no_speech_prob": 0.00009761534602148458,
        "seek": 64330,
        "start": 669.14,
        "temperature": 0,
        "text": " I think JSON is going to be the easiest format for us",
        "tokens": [
          51656,
          286,
          519,
          31828,
          307,
          516,
          281,
          312,
          264,
          12889,
          7877,
          337,
          505,
          51818
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 675.62,
        "id": 263,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 672.74,
        "temperature": 0,
        "text": " to encode a grammar and then load it",
        "tokens": [
          50382,
          281,
          2058,
          1429,
          257,
          22317,
          293,
          550,
          3677,
          309,
          50526
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 677.9,
        "id": 264,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 675.62,
        "temperature": 0,
        "text": " into Rita or another program that we write.",
        "tokens": [
          50526,
          666,
          32672,
          420,
          1071,
          1461,
          300,
          321,
          2464,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 682.74,
        "id": 265,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 677.9,
        "temperature": 0,
        "text": " So I actually have already taken this exact grammar",
        "tokens": [
          50640,
          407,
          286,
          767,
          362,
          1217,
          2726,
          341,
          1900,
          22317,
          50882
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 685.54,
        "id": 266,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 682.74,
        "temperature": 0,
        "text": " and rewritten it using a JSON syntax.",
        "tokens": [
          50882,
          293,
          319,
          26859,
          309,
          1228,
          257,
          31828,
          28431,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 686.9,
        "id": 267,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 685.54,
        "temperature": 0,
        "text": " And you can see that here.",
        "tokens": [
          51022,
          400,
          291,
          393,
          536,
          300,
          510,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 690.06,
        "id": 268,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 686.9,
        "temperature": 0,
        "text": " So I have a start, which is a noun phrase or a verb phrase.",
        "tokens": [
          51090,
          407,
          286,
          362,
          257,
          722,
          11,
          597,
          307,
          257,
          23307,
          9535,
          420,
          257,
          9595,
          9535,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 692.06,
        "id": 269,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 690.06,
        "temperature": 0,
        "text": " A noun phrase is a determiner and a noun.",
        "tokens": [
          51248,
          316,
          23307,
          9535,
          307,
          257,
          3618,
          4564,
          293,
          257,
          23307,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 694.46,
        "id": 270,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 692.06,
        "temperature": 0,
        "text": " A verb phrase could be verb phrase followed by verb",
        "tokens": [
          51348,
          316,
          9595,
          9535,
          727,
          312,
          9595,
          9535,
          6263,
          538,
          9595,
          51468
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 696.62,
        "id": 271,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 694.46,
        "temperature": 0,
        "text": " followed by a noun phrase or just a verb.",
        "tokens": [
          51468,
          6263,
          538,
          257,
          23307,
          9535,
          420,
          445,
          257,
          9595,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 699.02,
        "id": 272,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 696.62,
        "temperature": 0,
        "text": " So you can see there is some nesting into this grammar.",
        "tokens": [
          51576,
          407,
          291,
          393,
          536,
          456,
          307,
          512,
          297,
          8714,
          666,
          341,
          22317,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.24219518467999887,
        "compression_ratio": 1.9683794466403162,
        "end": 701.38,
        "id": 273,
        "no_speech_prob": 0.0003250341978855431,
        "seek": 67238,
        "start": 699.02,
        "temperature": 0,
        "text": " And then here you can see the sort of terminals.",
        "tokens": [
          51696,
          400,
          550,
          510,
          291,
          393,
          536,
          264,
          1333,
          295,
          38579,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 705.02,
        "id": 274,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 701.38,
        "temperature": 0,
        "text": " And each key has an array for multiple possibilities.",
        "tokens": [
          50364,
          400,
          1184,
          2141,
          575,
          364,
          10225,
          337,
          3866,
          12178,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 708.58,
        "id": 275,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 705.02,
        "temperature": 0,
        "text": " So now if I were to go back to my code",
        "tokens": [
          50546,
          407,
          586,
          498,
          286,
          645,
          281,
          352,
          646,
          281,
          452,
          3089,
          50724
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 714.26,
        "id": 276,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 708.58,
        "temperature": 0,
        "text": " and load grammar.json, I should at least be able to run this.",
        "tokens": [
          50724,
          293,
          3677,
          22317,
          13,
          73,
          3015,
          11,
          286,
          820,
          412,
          1935,
          312,
          1075,
          281,
          1190,
          341,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 715.3,
        "id": 277,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 714.26,
        "temperature": 0,
        "text": " And I see no error.",
        "tokens": [
          51008,
          400,
          286,
          536,
          572,
          6713,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 716.5,
        "id": 278,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 715.3,
        "temperature": 0,
        "text": " I just see ready.",
        "tokens": [
          51060,
          286,
          445,
          536,
          1919,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 718.3,
        "id": 279,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 716.5,
        "temperature": 0,
        "text": " And now I have a grammar already going.",
        "tokens": [
          51120,
          400,
          586,
          286,
          362,
          257,
          22317,
          1217,
          516,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 725.7,
        "id": 280,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 718.3,
        "temperature": 0,
        "text": " And I could say result equals grammar.rg.expand.",
        "tokens": [
          51210,
          400,
          286,
          727,
          584,
          1874,
          6915,
          22317,
          13,
          81,
          70,
          13,
          15952,
          474,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 729.06,
        "id": 281,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 725.7,
        "temperature": 0,
        "text": " And then console.log.rg.",
        "tokens": [
          51580,
          400,
          550,
          11076,
          13,
          4987,
          13,
          81,
          70,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.2338873545328776,
        "compression_ratio": 1.551219512195122,
        "end": 729.94,
        "id": 282,
        "no_speech_prob": 0.0002571403456386179,
        "seek": 70138,
        "start": 729.06,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51748,
          1692,
          321,
          352,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 732.1,
        "id": 283,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 730.5400000000001,
        "temperature": 0,
        "text": " Oh, look at that.",
        "tokens": [
          50394,
          876,
          11,
          574,
          412,
          300,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 733.46,
        "id": 284,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 732.1,
        "temperature": 0,
        "text": " What did I just say?",
        "tokens": [
          50472,
          708,
          630,
          286,
          445,
          584,
          30,
          50540
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 733.96,
        "id": 285,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 733.46,
        "temperature": 0,
        "text": " Rg.",
        "tokens": [
          50540,
          497,
          70,
          13,
          50565
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 735.34,
        "id": 286,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 733.96,
        "temperature": 0,
        "text": " No, that was interesting, though.",
        "tokens": [
          50565,
          883,
          11,
          300,
          390,
          1880,
          11,
          1673,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 736.6600000000001,
        "id": 287,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 735.34,
        "temperature": 0,
        "text": " Result is what I want to see.",
        "tokens": [
          50634,
          5015,
          723,
          307,
          437,
          286,
          528,
          281,
          536,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 738.1,
        "id": 288,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 736.6600000000001,
        "temperature": 0,
        "text": " And we can see the unicorn dances.",
        "tokens": [
          50700,
          400,
          321,
          393,
          536,
          264,
          28122,
          28322,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 739.3800000000001,
        "id": 289,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 738.1,
        "temperature": 0,
        "text": " The unicorn dances the rainbow.",
        "tokens": [
          50772,
          440,
          28122,
          28322,
          264,
          18526,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 740.22,
        "id": 290,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 739.3800000000001,
        "temperature": 0,
        "text": " The unicorn dances.",
        "tokens": [
          50836,
          440,
          28122,
          28322,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 741.1800000000001,
        "id": 291,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 740.22,
        "temperature": 0,
        "text": " The rainbow dances.",
        "tokens": [
          50878,
          440,
          18526,
          28322,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 742.2600000000001,
        "id": 292,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 741.1800000000001,
        "temperature": 0,
        "text": " A rainbow dances the rainbow.",
        "tokens": [
          50926,
          316,
          18526,
          28322,
          264,
          18526,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 743.1400000000001,
        "id": 293,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 742.2600000000001,
        "temperature": 0,
        "text": " A unicorn dances.",
        "tokens": [
          50980,
          316,
          28122,
          28322,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 743.86,
        "id": 294,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 743.1400000000001,
        "temperature": 0,
        "text": " A rainbow dances.",
        "tokens": [
          51024,
          316,
          18526,
          28322,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 744.7,
        "id": 295,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 743.86,
        "temperature": 0,
        "text": " A unicorn dances.",
        "tokens": [
          51060,
          316,
          28122,
          28322,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 745.6600000000001,
        "id": 296,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 744.7,
        "temperature": 0,
        "text": " A rainbow dances.",
        "tokens": [
          51102,
          316,
          18526,
          28322,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 746.98,
        "id": 297,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 745.6600000000001,
        "temperature": 0,
        "text": " Unicorn dances the rainbow.",
        "tokens": [
          51150,
          1156,
          23115,
          28322,
          264,
          18526,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 748.62,
        "id": 298,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 746.98,
        "temperature": 0,
        "text": " Somebody could make a song out of that.",
        "tokens": [
          51216,
          13463,
          727,
          652,
          257,
          2153,
          484,
          295,
          300,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 750.1,
        "id": 299,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 748.62,
        "temperature": 0,
        "text": " The unicorn dances the rainbow.",
        "tokens": [
          51298,
          440,
          28122,
          28322,
          264,
          18526,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 751.9000000000001,
        "id": 300,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 750.1,
        "temperature": 0,
        "text": " The rainbow dances the rainbow.",
        "tokens": [
          51372,
          440,
          18526,
          28322,
          264,
          18526,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 753.1800000000001,
        "id": 301,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 751.9000000000001,
        "temperature": 0,
        "text": " Unicorn dances the unicorn.",
        "tokens": [
          51462,
          1156,
          23115,
          28322,
          264,
          28122,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 753.84,
        "id": 302,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 753.1800000000001,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51526,
          2264,
          13,
          51559
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 756.5400000000001,
        "id": 303,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 753.84,
        "temperature": 0,
        "text": " So yes, please not yaml, someone says in the chat.",
        "tokens": [
          51559,
          407,
          2086,
          11,
          1767,
          406,
          288,
          335,
          75,
          11,
          1580,
          1619,
          294,
          264,
          5081,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.2791717052459717,
        "compression_ratio": 2.3755458515283845,
        "end": 757.4200000000001,
        "id": 304,
        "no_speech_prob": 0.0012644082307815552,
        "seek": 72994,
        "start": 756.5400000000001,
        "temperature": 0,
        "text": " Not to worry.",
        "tokens": [
          51694,
          1726,
          281,
          3292,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 762.14,
        "id": 305,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 757.42,
        "temperature": 0,
        "text": " So now we can see here, once again, just as with tracery,",
        "tokens": [
          50364,
          407,
          586,
          321,
          393,
          536,
          510,
          11,
          1564,
          797,
          11,
          445,
          382,
          365,
          504,
          326,
          2109,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 766.8199999999999,
        "id": 306,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 762.14,
        "temperature": 0,
        "text": " it's your job, if you want to work with context-free grammars,",
        "tokens": [
          50600,
          309,
          311,
          428,
          1691,
          11,
          498,
          291,
          528,
          281,
          589,
          365,
          4319,
          12,
          10792,
          17570,
          685,
          11,
          50834
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 768.02,
        "id": 307,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 766.8199999999999,
        "temperature": 0,
        "text": " to design the grammar.",
        "tokens": [
          50834,
          281,
          1715,
          264,
          22317,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 769.9799999999999,
        "id": 308,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 768.02,
        "temperature": 0,
        "text": " And this is an effective way of working",
        "tokens": [
          50894,
          400,
          341,
          307,
          364,
          4942,
          636,
          295,
          1364,
          50992
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 774.3399999999999,
        "id": 309,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 769.9799999999999,
        "temperature": 0,
        "text": " in that you could actually have a completely separate file",
        "tokens": [
          50992,
          294,
          300,
          291,
          727,
          767,
          362,
          257,
          2584,
          4994,
          3991,
          51210
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 775.8399999999999,
        "id": 310,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 774.3399999999999,
        "temperature": 0,
        "text": " where you put all of the grammar.",
        "tokens": [
          51210,
          689,
          291,
          829,
          439,
          295,
          264,
          22317,
          13,
          51285
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 777.5,
        "id": 311,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 775.8399999999999,
        "temperature": 0,
        "text": " So this could become very long.",
        "tokens": [
          51285,
          407,
          341,
          727,
          1813,
          588,
          938,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 779.66,
        "id": 312,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 777.5,
        "temperature": 0,
        "text": " In fact, you might start thinking about, hmm,",
        "tokens": [
          51368,
          682,
          1186,
          11,
          291,
          1062,
          722,
          1953,
          466,
          11,
          16478,
          11,
          51476
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 784.06,
        "id": 313,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 779.66,
        "temperature": 0,
        "text": " how could I do things like whenever I get to a noun,",
        "tokens": [
          51476,
          577,
          727,
          286,
          360,
          721,
          411,
          5699,
          286,
          483,
          281,
          257,
          23307,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.23083578695462445,
        "compression_ratio": 1.6483516483516483,
        "end": 786.8,
        "id": 314,
        "no_speech_prob": 0.000010953095625154674,
        "seek": 75742,
        "start": 784.06,
        "temperature": 0,
        "text": " instead of picking from just a fixed list,",
        "tokens": [
          51696,
          2602,
          295,
          8867,
          490,
          445,
          257,
          6806,
          1329,
          11,
          51833
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 789.68,
        "id": 315,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 786.8,
        "temperature": 0,
        "text": " actually use the Rita lexicon to give me a random noun,",
        "tokens": [
          50364,
          767,
          764,
          264,
          32672,
          476,
          87,
          11911,
          281,
          976,
          385,
          257,
          4974,
          23307,
          11,
          50508
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 794.0799999999999,
        "id": 316,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 789.68,
        "temperature": 0,
        "text": " or query Wordnik, like an API, to get a noun from?",
        "tokens": [
          50508,
          420,
          14581,
          8725,
          13123,
          11,
          411,
          364,
          9362,
          11,
          281,
          483,
          257,
          23307,
          490,
          30,
          50728
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 795.8399999999999,
        "id": 317,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 794.0799999999999,
        "temperature": 0,
        "text": " There's a lot of possible ways you",
        "tokens": [
          50728,
          821,
          311,
          257,
          688,
          295,
          1944,
          2098,
          291,
          50816
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 797.8399999999999,
        "id": 318,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 795.8399999999999,
        "temperature": 0,
        "text": " could think about this.",
        "tokens": [
          50816,
          727,
          519,
          466,
          341,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 800.12,
        "id": 319,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 797.8399999999999,
        "temperature": 0,
        "text": " One other grammar that I want to show you,",
        "tokens": [
          50916,
          1485,
          661,
          22317,
          300,
          286,
          528,
          281,
          855,
          291,
          11,
          51030
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 802,
        "id": 320,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 800.12,
        "temperature": 0,
        "text": " which, again, is thank you to Daniel Howe,",
        "tokens": [
          51030,
          597,
          11,
          797,
          11,
          307,
          1309,
          291,
          281,
          8033,
          1012,
          68,
          11,
          51124
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 803.28,
        "id": 321,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 802,
        "temperature": 0,
        "text": " the creator of Rita.",
        "tokens": [
          51124,
          264,
          14181,
          295,
          32672,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 805.68,
        "id": 322,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 803.28,
        "temperature": 0,
        "text": " I'm going to see if I can pull this up,",
        "tokens": [
          51188,
          286,
          478,
          516,
          281,
          536,
          498,
          286,
          393,
          2235,
          341,
          493,
          11,
          51308
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 807.8399999999999,
        "id": 323,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 805.68,
        "temperature": 0,
        "text": " because I have it in one of my other examples.",
        "tokens": [
          51308,
          570,
          286,
          362,
          309,
          294,
          472,
          295,
          452,
          661,
          5110,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 808.52,
        "id": 324,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 807.8399999999999,
        "temperature": 0,
        "text": " This one.",
        "tokens": [
          51416,
          639,
          472,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 809.64,
        "id": 325,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 808.52,
        "temperature": 0,
        "text": " So let's see if this works.",
        "tokens": [
          51450,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 812.3199999999999,
        "id": 326,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 809.64,
        "temperature": 0,
        "text": " I'm going to copy paste this grammar.",
        "tokens": [
          51506,
          286,
          478,
          516,
          281,
          5055,
          9163,
          341,
          22317,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.2513299490276136,
        "compression_ratio": 1.608695652173913,
        "end": 814.5999999999999,
        "id": 327,
        "no_speech_prob": 0.0041339099407196045,
        "seek": 78680,
        "start": 812.3199999999999,
        "temperature": 0,
        "text": " And I'm just going to put it over right here,",
        "tokens": [
          51640,
          400,
          286,
          478,
          445,
          516,
          281,
          829,
          309,
          670,
          558,
          510,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 817.4,
        "id": 328,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 814.6,
        "temperature": 0,
        "text": " grammar.json, paste it in, hit Save.",
        "tokens": [
          50364,
          22317,
          13,
          73,
          3015,
          11,
          9163,
          309,
          294,
          11,
          2045,
          15541,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 818.52,
        "id": 329,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 817.4,
        "temperature": 0,
        "text": " And I'm going to run it.",
        "tokens": [
          50504,
          400,
          286,
          478,
          516,
          281,
          1190,
          309,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 819.6,
        "id": 330,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 818.52,
        "temperature": 0,
        "text": " And we can see now.",
        "tokens": [
          50560,
          400,
          321,
          393,
          536,
          586,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 822.36,
        "id": 331,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 819.6,
        "temperature": 0,
        "text": " And actually, what I'm going to do is,",
        "tokens": [
          50614,
          400,
          767,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 825.24,
        "id": 332,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 822.36,
        "temperature": 0,
        "text": " let's be a little bit more sophisticated about this.",
        "tokens": [
          50752,
          718,
          311,
          312,
          257,
          707,
          857,
          544,
          16950,
          466,
          341,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 825.9200000000001,
        "id": 333,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 825.24,
        "temperature": 0,
        "text": " Sophisticated.",
        "tokens": [
          50896,
          18921,
          3142,
          770,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 828,
        "id": 334,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 825.9200000000001,
        "temperature": 0,
        "text": " This is a very sophisticated cooking show.",
        "tokens": [
          50930,
          639,
          307,
          257,
          588,
          16950,
          6361,
          855,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 829.58,
        "id": 335,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 828,
        "temperature": 0,
        "text": " By the way, this is called the cooking show now,",
        "tokens": [
          51034,
          3146,
          264,
          636,
          11,
          341,
          307,
          1219,
          264,
          6361,
          855,
          586,
          11,
          51113
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 830.44,
        "id": 336,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 829.58,
        "temperature": 0,
        "text": " because I'm cooking.",
        "tokens": [
          51113,
          570,
          286,
          478,
          6361,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 831.24,
        "id": 337,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 830.44,
        "temperature": 0,
        "text": " Cooking with code.",
        "tokens": [
          51156,
          36647,
          365,
          3089,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 833.0400000000001,
        "id": 338,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 831.24,
        "temperature": 0,
        "text": " Maybe that's it.",
        "tokens": [
          51196,
          2704,
          300,
          311,
          309,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 835.64,
        "id": 339,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 833.0400000000001,
        "temperature": 0,
        "text": " Button equals createButton.",
        "tokens": [
          51286,
          38435,
          6915,
          1884,
          7835,
          1756,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 837.5600000000001,
        "id": 340,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 835.64,
        "temperature": 0,
        "text": " Generate.",
        "tokens": [
          51416,
          15409,
          473,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 840.0400000000001,
        "id": 341,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 837.5600000000001,
        "temperature": 0,
        "text": " Button.mousePressed.",
        "tokens": [
          51512,
          38435,
          13,
          76,
          1316,
          47,
          3805,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.29782361400370694,
        "compression_ratio": 1.6753731343283582,
        "end": 843.32,
        "id": 342,
        "no_speech_prob": 0.009708350524306297,
        "seek": 81460,
        "start": 840.0400000000001,
        "temperature": 0,
        "text": " I'm using the p5 DOM library to attach a click event",
        "tokens": [
          51636,
          286,
          478,
          1228,
          264,
          280,
          20,
          35727,
          6405,
          281,
          5085,
          257,
          2052,
          2280,
          51800
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 844.5600000000001,
        "id": 343,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 843.32,
        "temperature": 0,
        "text": " to a button.",
        "tokens": [
          50364,
          281,
          257,
          2960,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 847.24,
        "id": 344,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 844.5600000000001,
        "temperature": 0,
        "text": " And I'm going to say new haiku.",
        "tokens": [
          50426,
          400,
          286,
          478,
          516,
          281,
          584,
          777,
          324,
          24320,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 853,
        "id": 345,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 850.12,
        "temperature": 0,
        "text": " And then I'm going to say function new haiku.",
        "tokens": [
          50704,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          2445,
          777,
          324,
          24320,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 859.5600000000001,
        "id": 346,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 857.12,
        "temperature": 0,
        "text": " And I'm going to say, and now I'm going to do here.",
        "tokens": [
          51054,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          293,
          586,
          286,
          478,
          516,
          281,
          360,
          510,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 863.12,
        "id": 347,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 859.5600000000001,
        "temperature": 0,
        "text": " I'm going to get the result, is expand the grammar.",
        "tokens": [
          51176,
          286,
          478,
          516,
          281,
          483,
          264,
          1874,
          11,
          307,
          5268,
          264,
          22317,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 866.1600000000001,
        "id": 348,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 863.12,
        "temperature": 0,
        "text": " And then I'm going to say createP result.",
        "tokens": [
          51354,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          1884,
          47,
          1874,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 868.96,
        "id": 349,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 866.1600000000001,
        "temperature": 0,
        "text": " So let me run this.",
        "tokens": [
          51506,
          407,
          718,
          385,
          1190,
          341,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.2991529010591053,
        "compression_ratio": 1.9197530864197532,
        "end": 872.48,
        "id": 350,
        "no_speech_prob": 0.0010162293910980225,
        "seek": 84332,
        "start": 868.96,
        "temperature": 0,
        "text": " And we should see, ah, result is not defined, line 12.",
        "tokens": [
          51646,
          400,
          321,
          820,
          536,
          11,
          3716,
          11,
          1874,
          307,
          406,
          7642,
          11,
          1622,
          2272,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 875.16,
        "id": 351,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 872.48,
        "temperature": 0,
        "text": " And I forgot that I have some extra code there.",
        "tokens": [
          50364,
          400,
          286,
          5298,
          300,
          286,
          362,
          512,
          2857,
          3089,
          456,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 876.6800000000001,
        "id": 352,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 875.16,
        "temperature": 0,
        "text": " So the idea here is that I generate,",
        "tokens": [
          50498,
          407,
          264,
          1558,
          510,
          307,
          300,
          286,
          8460,
          11,
          50574
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 877.9200000000001,
        "id": 353,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 876.6800000000001,
        "temperature": 0,
        "text": " and I get these haikus.",
        "tokens": [
          50574,
          293,
          286,
          483,
          613,
          324,
          1035,
          301,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 879.84,
        "id": 354,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 877.9200000000001,
        "temperature": 0,
        "text": " Now, a couple of things about this.",
        "tokens": [
          50636,
          823,
          11,
          257,
          1916,
          295,
          721,
          466,
          341,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 882.2,
        "id": 355,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 879.84,
        "temperature": 0,
        "text": " Why is there this percent sign in there?",
        "tokens": [
          50732,
          1545,
          307,
          456,
          341,
          3043,
          1465,
          294,
          456,
          30,
          50850
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 884.6,
        "id": 356,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 882.2,
        "temperature": 0,
        "text": " So one of the things you can do when designing a grammar",
        "tokens": [
          50850,
          407,
          472,
          295,
          264,
          721,
          291,
          393,
          360,
          562,
          14685,
          257,
          22317,
          50970
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 886.64,
        "id": 357,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 884.6,
        "temperature": 0,
        "text": " is kind of create your own protocol.",
        "tokens": [
          50970,
          307,
          733,
          295,
          1884,
          428,
          1065,
          10336,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 889.72,
        "id": 358,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 886.64,
        "temperature": 0,
        "text": " I really, what I want to have is like a br tag there.",
        "tokens": [
          51072,
          286,
          534,
          11,
          437,
          286,
          528,
          281,
          362,
          307,
          411,
          257,
          738,
          6162,
          456,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 891.88,
        "id": 359,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 889.72,
        "temperature": 0,
        "text": " So I could just go into the grammar",
        "tokens": [
          51226,
          407,
          286,
          727,
          445,
          352,
          666,
          264,
          22317,
          51334
        ]
      },
      {
        "avg_logprob": -0.27671858101836905,
        "compression_ratio": 1.6653225806451613,
        "end": 896.08,
        "id": 360,
        "no_speech_prob": 0.00031503767240792513,
        "seek": 87248,
        "start": 891.88,
        "temperature": 0,
        "text": " and just do this, which will probably work.",
        "tokens": [
          51334,
          293,
          445,
          360,
          341,
          11,
          597,
          486,
          1391,
          589,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 900.5200000000001,
        "id": 361,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 896.64,
        "temperature": 0,
        "text": " And because I'm outputting to HTML, I'm getting a br tag.",
        "tokens": [
          50392,
          400,
          570,
          286,
          478,
          5598,
          783,
          281,
          17995,
          11,
          286,
          478,
          1242,
          257,
          738,
          6162,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 902.36,
        "id": 362,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 900.5200000000001,
        "temperature": 0,
        "text": " But I might be outputting to other things,",
        "tokens": [
          50586,
          583,
          286,
          1062,
          312,
          5598,
          783,
          281,
          661,
          721,
          11,
          50678
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 904.64,
        "id": 363,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 902.36,
        "temperature": 0,
        "text": " and I actually want to replace that with a line break.",
        "tokens": [
          50678,
          293,
          286,
          767,
          528,
          281,
          7406,
          300,
          365,
          257,
          1622,
          1821,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 907.36,
        "id": 364,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 904.64,
        "temperature": 0,
        "text": " So but you can see here, let's look at how this grammar works.",
        "tokens": [
          50792,
          407,
          457,
          291,
          393,
          536,
          510,
          11,
          718,
          311,
          574,
          412,
          577,
          341,
          22317,
          1985,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 910.08,
        "id": 365,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 907.36,
        "temperature": 0,
        "text": " This is an interesting way that you can use a grammar",
        "tokens": [
          50928,
          639,
          307,
          364,
          1880,
          636,
          300,
          291,
          393,
          764,
          257,
          22317,
          51064
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 912.24,
        "id": 366,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 910.08,
        "temperature": 0,
        "text": " to generate a haiku.",
        "tokens": [
          51064,
          281,
          8460,
          257,
          324,
          24320,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 915.08,
        "id": 367,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 912.24,
        "temperature": 0,
        "text": " So the haiku form is a complex thing.",
        "tokens": [
          51172,
          407,
          264,
          324,
          24320,
          1254,
          307,
          257,
          3997,
          551,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 917.5200000000001,
        "id": 368,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 915.08,
        "temperature": 0,
        "text": " There is a variety of ways you can sort of think of haiku.",
        "tokens": [
          51314,
          821,
          307,
          257,
          5673,
          295,
          2098,
          291,
          393,
          1333,
          295,
          519,
          295,
          324,
          24320,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 919.4000000000001,
        "id": 369,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 917.5200000000001,
        "temperature": 0,
        "text": " But here's one scenario.",
        "tokens": [
          51436,
          583,
          510,
          311,
          472,
          9005,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 922.32,
        "id": 370,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 919.4000000000001,
        "temperature": 0,
        "text": " A line with five syllables, a line with seven syllables,",
        "tokens": [
          51530,
          316,
          1622,
          365,
          1732,
          45364,
          11,
          257,
          1622,
          365,
          3407,
          45364,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.3037992543187635,
        "compression_ratio": 1.8194945848375452,
        "end": 924.1600000000001,
        "id": 371,
        "no_speech_prob": 0.0002694778668228537,
        "seek": 89608,
        "start": 922.32,
        "temperature": 0,
        "text": " and a line with five syllables.",
        "tokens": [
          51676,
          293,
          257,
          1622,
          365,
          1732,
          45364,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 927.8399999999999,
        "id": 372,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 924.16,
        "temperature": 0,
        "text": " So that is the start axiom.",
        "tokens": [
          50364,
          407,
          300,
          307,
          264,
          722,
          6360,
          72,
          298,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 930.48,
        "id": 373,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 927.8399999999999,
        "temperature": 0,
        "text": " Then here are a bunch of ways you can create",
        "tokens": [
          50548,
          1396,
          510,
          366,
          257,
          3840,
          295,
          2098,
          291,
          393,
          1884,
          50680
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 932.56,
        "id": 374,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 930.48,
        "temperature": 0,
        "text": " a line with five syllables, a one syllable",
        "tokens": [
          50680,
          257,
          1622,
          365,
          1732,
          45364,
          11,
          257,
          472,
          40151,
          50784
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 934.7199999999999,
        "id": 375,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 932.56,
        "temperature": 0,
        "text": " followed by a four syllable, a one syllable followed",
        "tokens": [
          50784,
          6263,
          538,
          257,
          1451,
          40151,
          11,
          257,
          472,
          40151,
          6263,
          50892
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 937.6,
        "id": 376,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 934.7199999999999,
        "temperature": 0,
        "text": " by a three or a one, a one, a one, three, one, two, two, one,",
        "tokens": [
          50892,
          538,
          257,
          1045,
          420,
          257,
          472,
          11,
          257,
          472,
          11,
          257,
          472,
          11,
          1045,
          11,
          472,
          11,
          732,
          11,
          732,
          11,
          472,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 938.24,
        "id": 377,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 937.6,
        "temperature": 0,
        "text": " two, one, one.",
        "tokens": [
          51036,
          732,
          11,
          472,
          11,
          472,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 940.56,
        "id": 378,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 938.24,
        "temperature": 0,
        "text": " So you can see here's a whole set of possibilities.",
        "tokens": [
          51068,
          407,
          291,
          393,
          536,
          510,
          311,
          257,
          1379,
          992,
          295,
          12178,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 942.88,
        "id": 379,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 940.56,
        "temperature": 0,
        "text": " Here are possibilities for seven line.",
        "tokens": [
          51184,
          1692,
          366,
          12178,
          337,
          3407,
          1622,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 945.04,
        "id": 380,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 942.88,
        "temperature": 0,
        "text": " Notice how I'm reusing the five line here,",
        "tokens": [
          51300,
          13428,
          577,
          286,
          478,
          319,
          7981,
          264,
          1732,
          1622,
          510,
          11,
          51408
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 947.52,
        "id": 381,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 945.04,
        "temperature": 0,
        "text": " because I could have one, one, five line, two, five line,",
        "tokens": [
          51408,
          570,
          286,
          727,
          362,
          472,
          11,
          472,
          11,
          1732,
          1622,
          11,
          732,
          11,
          1732,
          1622,
          11,
          51532
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 949.36,
        "id": 382,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 947.52,
        "temperature": 0,
        "text": " five line, one, one, or five line, two.",
        "tokens": [
          51532,
          1732,
          1622,
          11,
          472,
          11,
          472,
          11,
          420,
          1732,
          1622,
          11,
          732,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.3618543451482599,
        "compression_ratio": 2.111111111111111,
        "end": 951.68,
        "id": 383,
        "no_speech_prob": 0.03676680848002434,
        "seek": 92416,
        "start": 949.36,
        "temperature": 0,
        "text": " And then here's a whole lot of one-line possibilities.",
        "tokens": [
          51624,
          400,
          550,
          510,
          311,
          257,
          1379,
          688,
          295,
          472,
          12,
          1889,
          12178,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 954.4799999999999,
        "id": 384,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 951.68,
        "temperature": 0,
        "text": " So I could have one, one, five line, two, five line, one, one,",
        "tokens": [
          50364,
          407,
          286,
          727,
          362,
          472,
          11,
          472,
          11,
          1732,
          1622,
          11,
          732,
          11,
          1732,
          1622,
          11,
          472,
          11,
          472,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 955.3199999999999,
        "id": 385,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 954.4799999999999,
        "temperature": 0,
        "text": " five line, two.",
        "tokens": [
          50504,
          1732,
          1622,
          11,
          732,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 958.3199999999999,
        "id": 386,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 955.3199999999999,
        "temperature": 0,
        "text": " And then here's a whole lot of one-syllable words.",
        "tokens": [
          50546,
          400,
          550,
          510,
          311,
          257,
          1379,
          688,
          295,
          472,
          12,
          3187,
          285,
          712,
          2283,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 959.8399999999999,
        "id": 387,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 958.3199999999999,
        "temperature": 0,
        "text": " This is all from Daniel Howe.",
        "tokens": [
          50696,
          639,
          307,
          439,
          490,
          8033,
          1012,
          68,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 961.5999999999999,
        "id": 388,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 959.8399999999999,
        "temperature": 0,
        "text": " A whole lot of two-syllable words,",
        "tokens": [
          50772,
          316,
          1379,
          688,
          295,
          732,
          12,
          3187,
          285,
          712,
          2283,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 964.3199999999999,
        "id": 389,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 961.5999999999999,
        "temperature": 0,
        "text": " a whole lot of three-syllable, not just words, but phrases,",
        "tokens": [
          50860,
          257,
          1379,
          688,
          295,
          1045,
          12,
          3187,
          285,
          712,
          11,
          406,
          445,
          2283,
          11,
          457,
          20312,
          11,
          50996
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 965.92,
        "id": 390,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 964.3199999999999,
        "temperature": 0,
        "text": " four syllables, et cetera.",
        "tokens": [
          50996,
          1451,
          45364,
          11,
          1030,
          11458,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 969,
        "id": 391,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 965.92,
        "temperature": 0,
        "text": " So now if I were to run this, we can see",
        "tokens": [
          51076,
          407,
          586,
          498,
          286,
          645,
          281,
          1190,
          341,
          11,
          321,
          393,
          536,
          51230
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 972.16,
        "id": 392,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 969,
        "temperature": 0,
        "text": " I'm always going to get cranes, Japan.",
        "tokens": [
          51230,
          286,
          478,
          1009,
          516,
          281,
          483,
          941,
          12779,
          11,
          3367,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 974.0799999999999,
        "id": 393,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 972.16,
        "temperature": 0,
        "text": " I'm going to get five syllables.",
        "tokens": [
          51388,
          286,
          478,
          516,
          281,
          483,
          1732,
          45364,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 976.88,
        "id": 394,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 974.0799999999999,
        "temperature": 0,
        "text": " Cranes, Japan, day breaks, followed by seven.",
        "tokens": [
          51484,
          383,
          4257,
          279,
          11,
          3367,
          11,
          786,
          9857,
          11,
          6263,
          538,
          3407,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.4119344169710889,
        "compression_ratio": 1.8849206349206349,
        "end": 979.5999999999999,
        "id": 395,
        "no_speech_prob": 0.30728572607040405,
        "seek": 95168,
        "start": 976.88,
        "temperature": 0,
        "text": " Dawn, smoke, Japan, dawn, rushing,",
        "tokens": [
          51624,
          26001,
          11,
          8439,
          11,
          3367,
          11,
          18192,
          11,
          25876,
          11,
          51760
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 980.48,
        "id": 396,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 979.6,
        "temperature": 0,
        "text": " to, nip, her.",
        "tokens": [
          50364,
          220,
          1353,
          11,
          297,
          647,
          11,
          720,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 982.28,
        "id": 397,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 980.48,
        "temperature": 0,
        "text": " So I encourage you to think about what",
        "tokens": [
          50408,
          407,
          286,
          5373,
          291,
          281,
          519,
          466,
          437,
          50498
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 984.8000000000001,
        "id": 398,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 982.28,
        "temperature": 0,
        "text": " might be some creative ways you can write",
        "tokens": [
          50498,
          1062,
          312,
          512,
          5880,
          2098,
          291,
          393,
          2464,
          50624
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 987.52,
        "id": 399,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 984.8000000000001,
        "temperature": 0,
        "text": " a grammar to generate text.",
        "tokens": [
          50624,
          257,
          22317,
          281,
          8460,
          2487,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 989.36,
        "id": 400,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 987.52,
        "temperature": 0,
        "text": " And now we've seen how you can do",
        "tokens": [
          50760,
          400,
          586,
          321,
          600,
          1612,
          577,
          291,
          393,
          360,
          50852
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 992.8000000000001,
        "id": 401,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 989.36,
        "temperature": 0,
        "text": " this same type of context-free grammar with tracery.",
        "tokens": [
          50852,
          341,
          912,
          2010,
          295,
          4319,
          12,
          10792,
          22317,
          365,
          504,
          326,
          2109,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 995.88,
        "id": 402,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 992.8000000000001,
        "temperature": 0,
        "text": " We've seen how you can do it with the reada library.",
        "tokens": [
          51024,
          492,
          600,
          1612,
          577,
          291,
          393,
          360,
          309,
          365,
          264,
          1401,
          64,
          6405,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 999.4,
        "id": 403,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 995.88,
        "temperature": 0,
        "text": " And in the next video, which will be coming at some point",
        "tokens": [
          51178,
          400,
          294,
          264,
          958,
          960,
          11,
          597,
          486,
          312,
          1348,
          412,
          512,
          935,
          51354
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 1000.84,
        "id": 404,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 999.4,
        "temperature": 0,
        "text": " if it's not already there, I'm going",
        "tokens": [
          51354,
          498,
          309,
          311,
          406,
          1217,
          456,
          11,
          286,
          478,
          516,
          51426
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 1003.32,
        "id": 405,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 1000.84,
        "temperature": 0,
        "text": " to just kind of look at the basic recursive algorithm",
        "tokens": [
          51426,
          281,
          445,
          733,
          295,
          574,
          412,
          264,
          3875,
          20560,
          488,
          9284,
          51550
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 1005.24,
        "id": 406,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 1003.32,
        "temperature": 0,
        "text": " for doing this expansion from scratch,",
        "tokens": [
          51550,
          337,
          884,
          341,
          11260,
          490,
          8459,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.26783590846591526,
        "compression_ratio": 1.7003367003367003,
        "end": 1007.8000000000001,
        "id": 407,
        "no_speech_prob": 0.15000149607658386,
        "seek": 97960,
        "start": 1005.24,
        "temperature": 0,
        "text": " in case you at some point want to start playing around",
        "tokens": [
          51646,
          294,
          1389,
          291,
          412,
          512,
          935,
          528,
          281,
          722,
          2433,
          926,
          51774
        ]
      },
      {
        "avg_logprob": -0.4724392524132362,
        "compression_ratio": 1.1097560975609757,
        "end": 1010.9599999999999,
        "id": 408,
        "no_speech_prob": 0.00009027922351378947,
        "seek": 100780,
        "start": 1007.8,
        "temperature": 0,
        "text": " with the guts of how the context-free grammar generation",
        "tokens": [
          50364,
          365,
          264,
          28560,
          295,
          577,
          264,
          4319,
          12,
          10792,
          22317,
          5125,
          50522
        ]
      },
      {
        "avg_logprob": -0.4724392524132362,
        "compression_ratio": 1.1097560975609757,
        "end": 1012.04,
        "id": 409,
        "no_speech_prob": 0.00009027922351378947,
        "seek": 100780,
        "start": 1010.9599999999999,
        "temperature": 0,
        "text": " system works.",
        "tokens": [
          50522,
          1185,
          1985,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.4724392524132362,
        "compression_ratio": 1.1097560975609757,
        "end": 1013.24,
        "id": 410,
        "no_speech_prob": 0.00009027922351378947,
        "seek": 100780,
        "start": 1012.04,
        "temperature": 0,
        "text": " Thanks for watching.",
        "tokens": [
          50576,
          2561,
          337,
          1976,
          13,
          50636
        ]
      }
    ],
    "transcription": " Hey, hello there. Welcome to another video about context-free grammars. That's what I'm talking about. So I've already done, I've sort of explained what a context-free grammar is. I looked at a JavaScript library called Tracery. And in this video, I want to look at yet another JavaScript library called Rita.js that has a functionality that allows you to generate text based on a grammar. Now, I previously made a video about the Rita.js library, showed some other aspects of it, ways that you can generate and do and evaluate, actually analyze text with the Rita library. And I'll make sure to link to that in this video's description. So I encourage you to check that out. But an aspect that I did not look at is the Rita grammar, the RI grammar object. So how does the RI grammar object work? And what kinds of things can you do with it? So first of all, the RI grammar object is designed for use with a context-free grammar. Now, if you're wondering what a context-free grammar is, you can double back a couple of videos where I maybe talk through it in a bit more detail. But just to remind you, if you're wondering, a context-free grammar is a system that defines the structure of a particular language. And in this sense, it could be a very small, tiny little language. Like, here's a language that has only these elements, sentence, nouns, verbs, and the cat, dog, meows, and barks. So there are terminal and non-terminal characters. These are non-terminal characters, meaning they get replaced with something. Sass for sentence gets replaced with the noun verb. Noun gets replaced with cat or dog. Verb gets replaced with meows or barks. So if I start with sentence, this gets expanded to the and v. The is terminal, so it stays as the. And becomes flip a coin, cat or dog. V becomes flip a coin, cat or dog. And we get this expansion. So certainly, the idea here is to design sophisticated and interesting grammars with all sorts of creative language in them to generate text with some purpose. Maybe you're making automatic Harry Potter spells, or maybe you're making recipes that are going to randomly generate. And you're going to cook some strange thing for dinner based on what your context-free grammar made you. Lots of possibilities there. But let's see if we can figure out how to make a simple grammar work with the Rita library. And then we'll also look at some other examples of grammars that you can generate with the Rita library. OK, so looking at this, the first thing you might notice is I need to say, make a new Rita grammar object. So let me go to code. And I'm going to say var. I'm going to call it RG, just like in the example. By the way, Rita is by Daniel Howe. Thank you, Daniel Howe, for this wonderful generative text library. I encourage everybody watching to thank Daniel Howe and contribute to the development of Rita. RG equals new RI grammar. Now, I'm going to leave the argument here empty. So ultimately, there's a lot of different ways that we might be able to create the grammar. I could do it dynamically in code by just adding the rules, which is what I'm going to try to do right now. Or I could load the grammar from a pre-existing file. And I can mix and match, too. But let's try to just dynamically generate it with code. So the first thing I want to do, just looking at this, is see if I have an object there. So you can see I have some Rita grammar object. It's got some rules in it. Something's happening, but I can't do anything yet. Now, if I go to here and I say, let me look at a result, let me expand. Remember, an expansion is expanding from the start of the grammar out and getting a sentence that fits that grammar. So if I get some sort of result and I say console.log result, I should get nothing. So no grammar rules found. So the first thing that I need for a grammar to do anything is to have some rules. So let's look now at the addRule function. So the addRule function requires a name. Oh, look at this, a weight. Oh, I love that this has that. That is so fantastic. So it has the rule name and the rule definition and the rule weight. So here's the thing. We're going to have to figure out what does Rita. And I honestly don't know this. I'm going to figure this out while doing the video. What does Rita expect that how this is formatted? So I'm going to look. I'm sure there's an example that I can look at. But on the one hand, I know that I could say rg.addRule. And so I could say maybe like start becomes a sentence. Or let me just say the cat meows. There's a rule. Sentence becomes the cat meows, a probability of a weight of 1. Now, I doubt that's enough. So that did not work. So I expect that I've got to conform to the syntax of the Rita library and how it expects it to work. Now, I'm kind of getting a little clue here. Rule not found start. So I think by definition, Rita probably expects, I'm just guessing from looking at this error, that Rita expects there to be a rule called start. So let's see if that works, if I now get the cat meows. Ah, I did. So now every time I get the cat meows. Now, how can I get maybe? So let me see if I can now call this. Now, I'm expecting maybe if I make a rule that has this syntax with the sort of tag symbols around it, I can say addRule n. And I can say cat. So now let's just see if I have a rule which the start is the n meows. And maybe I'm going to get cat. Perfect. Now, how do I get? Now, I have a feeling that the syntax it expects is this. So there are a bunch of sort of conventional syntaxes for grammars. And you're going to see them in a variety of different ways. You can encode it in JSON, as we saw, in tracery with those sort of pound symbols. This, I believe, is based on some standard. I should look it up and try to figure out what it is. Annotation appear here to explain. But I have a feeling based on what I've done before and seen before that it's expecting the pipe symbol as one or the other. Let's say what would happen if I didn't do this? Cat, dog. Well, I'm going to get the cat, dog, meows. That's what I'm getting. That's the whole thing that's replaced. But if I put this pipe symbol here, the cat meows, the dog meows, the cat meows, the dog meows. So we can see now the rules. Now, one thing I'm curious about is does this require these tags? It does not. The cat, the cat, the cat, the cat, the dog. So we can see here that this can be a useful distinction just for ourselves to illustrate what I mean to be non-terminal. Maybe put the tag, the greater than, less than around it. And that can be useful here. So one thing that I'm kind of, the other thing that I'm kind of curious about is if I say this, I could also probably put them in a separate line. The dog, the dog, the cat, the cat, the dog. And so now let's look at, let's think about this weight. So if I go back now to the documentation and we look at the rule weight, optional defaults to 1. So how might I alter the probability? So I'm just going to make sort of a guess that if I do something like 5, which is a 5, then I've got kind of a 5 to 1, maybe a 5 out of 6 chance of picking cat over dog. And what we could do is I could also do this maybe 100 times just to sort of see how this works. And let's run this. And so you can see here it's picking cat. It picked cat 16 times, then it picked dog. Then cat four times, then it picked dog. Then cat four times, then cat seven times. So you can see that that weighting allows you to add the rules and kind of weight them particularly. And I could also probably do cat or unicorn. And both, I'm imagining both of those probably have the weight of 5 and the dog has the weight of 1. So if I ran this again, we can see there's going to be a lot of cat and unicorn and not so much dog, I'm sort of guessing. So I'd have to really like strictly evaluate how this is working. But you can see it's nice that you have this ability to manipulate the weights. So if I go back to this particular simple scenario, let's just finish implementing that. I'm going to say the noun. And I can add a cat, unicorn, dog. I'm going to just leave the default weights. And then I'm going to add another rule. What sound does a unicorn make? Meows. The cat meows. The dog barks. The unicorn, the tulips. That's the sound of a unicorn. It's a word that I made up called tulips. And then I'm going to put a period here. And so now we can see if I generate this, we can see all of these different possible sentences, all which conform to that grammar. So this is a very basic idea. You can imagine how you could make this much more sophisticated through nesting. So I'm going to stay away from more exciting and interesting possibilities with this. Here I'm just giving you the building blocks. But let's look at actually what happens if you want to encode a grammar not in your code, but have it come from a separate file. And I can look here in the reference and look at load from. Whoops, I clicked on the wrong thing. I'm going to click at load from. So what load from says, load from a file or URL So in option, the option in JavaScript is going to be a callback. Because when you ask for a file, it's going to happen. The file is going to be loaded asynchronously. So I need to know when the grammar is ready. So there are a bunch of different ways grammar files can be formatted. And a typical way you might see is with a syntax that looks something like this. And I have some examples that, when you look at the code examples, that load files that look like this. Here's another sort of way that you might see that you can do. So I'm going to try loading this particular file, which is a.grammar file. And whoops, so let me comment this out. And I'm going to say rg.load from test.grammar. And I'm going to say grammar ready. So this is my callback for when the grammar is ready. I'm going to just say, when the grammar is ready. And I'm going to say, when the grammar is ready. And I'm going to say, when the grammar is ready. The grammar is ready. I'm going to just say, ready. So if I do this and run this now, it's going to say, ah, grammar appears to be invalid JSON. Please check it if you're using YAML. So there are so many different kinds of standardized data formats. There's XML markup and YAML and blah, blah, blah, blah, blah, blah, blah. If you've watched some of my data videos, I kind of cover some of these different formats. I think JSON is going to be the easiest format for us to encode a grammar and then load it into Rita or another program that we write. So I actually have already taken this exact grammar and rewritten it using a JSON syntax. And you can see that here. So I have a start, which is a noun phrase or a verb phrase. A noun phrase is a determiner and a noun. A verb phrase could be verb phrase followed by verb followed by a noun phrase or just a verb. So you can see there is some nesting into this grammar. And then here you can see the sort of terminals. And each key has an array for multiple possibilities. So now if I were to go back to my code and load grammar.json, I should at least be able to run this. And I see no error. I just see ready. And now I have a grammar already going. And I could say result equals grammar.rg.expand. And then console.log.rg. Here we go. Oh, look at that. What did I just say? Rg. No, that was interesting, though. Result is what I want to see. And we can see the unicorn dances. The unicorn dances the rainbow. The unicorn dances. The rainbow dances. A rainbow dances the rainbow. A unicorn dances. A rainbow dances. A unicorn dances. A rainbow dances. Unicorn dances the rainbow. Somebody could make a song out of that. The unicorn dances the rainbow. The rainbow dances the rainbow. Unicorn dances the unicorn. OK. So yes, please not yaml, someone says in the chat. Not to worry. So now we can see here, once again, just as with tracery, it's your job, if you want to work with context-free grammars, to design the grammar. And this is an effective way of working in that you could actually have a completely separate file where you put all of the grammar. So this could become very long. In fact, you might start thinking about, hmm, how could I do things like whenever I get to a noun, instead of picking from just a fixed list, actually use the Rita lexicon to give me a random noun, or query Wordnik, like an API, to get a noun from? There's a lot of possible ways you could think about this. One other grammar that I want to show you, which, again, is thank you to Daniel Howe, the creator of Rita. I'm going to see if I can pull this up, because I have it in one of my other examples. This one. So let's see if this works. I'm going to copy paste this grammar. And I'm just going to put it over right here, grammar.json, paste it in, hit Save. And I'm going to run it. And we can see now. And actually, what I'm going to do is, let's be a little bit more sophisticated about this. Sophisticated. This is a very sophisticated cooking show. By the way, this is called the cooking show now, because I'm cooking. Cooking with code. Maybe that's it. Button equals createButton. Generate. Button.mousePressed. I'm using the p5 DOM library to attach a click event to a button. And I'm going to say new haiku. And then I'm going to say function new haiku. And I'm going to say, and now I'm going to do here. I'm going to get the result, is expand the grammar. And then I'm going to say createP result. So let me run this. And we should see, ah, result is not defined, line 12. And I forgot that I have some extra code there. So the idea here is that I generate, and I get these haikus. Now, a couple of things about this. Why is there this percent sign in there? So one of the things you can do when designing a grammar is kind of create your own protocol. I really, what I want to have is like a br tag there. So I could just go into the grammar and just do this, which will probably work. And because I'm outputting to HTML, I'm getting a br tag. But I might be outputting to other things, and I actually want to replace that with a line break. So but you can see here, let's look at how this grammar works. This is an interesting way that you can use a grammar to generate a haiku. So the haiku form is a complex thing. There is a variety of ways you can sort of think of haiku. But here's one scenario. A line with five syllables, a line with seven syllables, and a line with five syllables. So that is the start axiom. Then here are a bunch of ways you can create a line with five syllables, a one syllable followed by a four syllable, a one syllable followed by a three or a one, a one, a one, three, one, two, two, one, two, one, one. So you can see here's a whole set of possibilities. Here are possibilities for seven line. Notice how I'm reusing the five line here, because I could have one, one, five line, two, five line, five line, one, one, or five line, two. And then here's a whole lot of one-line possibilities. So I could have one, one, five line, two, five line, one, one, five line, two. And then here's a whole lot of one-syllable words. This is all from Daniel Howe. A whole lot of two-syllable words, a whole lot of three-syllable, not just words, but phrases, four syllables, et cetera. So now if I were to run this, we can see I'm always going to get cranes, Japan. I'm going to get five syllables. Cranes, Japan, day breaks, followed by seven. Dawn, smoke, Japan, dawn, rushing, to, nip, her. So I encourage you to think about what might be some creative ways you can write a grammar to generate text. And now we've seen how you can do this same type of context-free grammar with tracery. We've seen how you can do it with the reada library. And in the next video, which will be coming at some point if it's not already there, I'm going to just kind of look at the basic recursive algorithm for doing this expansion from scratch, in case you at some point want to start playing around with the guts of how the context-free grammar generation system works. Thanks for watching.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T20:41:53.068186Z",
  "started_at": "2023-09-26T20:54:35.939874Z",
  "completed_at": "2023-09-26T20:59:54.925438Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=VaAoIaZ3YKs",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 318.985564
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/6do5dpzbp7p6tdqbmsjsoxnhrm/cancel",
    "get": "https://api.replicate.com/v1/predictions/6do5dpzbp7p6tdqbmsjsoxnhrm"
  }
}