{
  "id": "am7mzpbblit5ht2gtn4ftpal24",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/q6cwxORPDo8.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/76516 [00:00<?, ?frames/s]\n  4%|▎         | 2810/76516 [00:05<02:12, 555.50frames/s]\n  7%|▋         | 5514/76516 [00:12<02:47, 423.70frames/s]\n 11%|█         | 8444/76516 [00:18<02:34, 440.33frames/s]\n 15%|█▍        | 11432/76516 [00:25<02:30, 432.81frames/s]\n 18%|█▊        | 14076/76516 [00:30<02:11, 473.95frames/s]\n 22%|██▏       | 16756/76516 [00:36<02:06, 471.91frames/s]\n 25%|██▌       | 19414/76516 [00:42<02:06, 451.46frames/s]\n 29%|██▉       | 22134/76516 [00:49<02:02, 442.17frames/s]\n 33%|███▎      | 25022/76516 [00:57<02:09, 398.56frames/s]\n 36%|███▋      | 27814/76516 [01:04<02:02, 396.41frames/s]\n 40%|████      | 30814/76516 [01:14<02:05, 365.34frames/s]\n 44%|████▍     | 33814/76516 [01:19<01:40, 424.90frames/s]\n 48%|████▊     | 36690/76516 [01:25<01:31, 434.89frames/s]\n 52%|█████▏    | 39542/76516 [01:33<01:30, 408.70frames/s]\n 55%|█████▌    | 42318/76516 [01:40<01:25, 399.97frames/s]\n 59%|█████▉    | 45126/76516 [01:46<01:14, 421.41frames/s]\n 63%|██████▎   | 47946/76516 [01:55<01:13, 387.91frames/s]\n 66%|██████▌   | 50590/76516 [02:04<01:13, 350.61frames/s]\n 70%|███████   | 53590/76516 [02:14<01:08, 336.34frames/s]\n 74%|███████▍  | 56434/76516 [02:21<00:58, 343.68frames/s]\n 77%|███████▋  | 59234/76516 [02:27<00:45, 381.87frames/s]\n 81%|████████  | 62078/76516 [02:34<00:36, 391.09frames/s]\n 85%|████████▍ | 64882/76516 [02:42<00:30, 376.60frames/s]\n 88%|████████▊ | 67706/76516 [02:53<00:26, 331.37frames/s]\n 92%|█████████▏| 70466/76516 [02:58<00:16, 373.91frames/s]\n 96%|█████████▌| 73446/76516 [03:08<00:08, 342.66frames/s]\n 99%|█████████▊| 75538/76516 [03:14<00:02, 339.58frames/s]\n 99%|█████████▊| 75538/76516 [03:29<00:02, 339.58frames/s]\n99%|█████████▊| 75538/76516 [03:32<00:02, 354.81frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 4.28,
        "id": 0,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, and welcome to another ML5 neural network video",
        "tokens": [
          50364,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          21601,
          20,
          18161,
          3209,
          960,
          50578
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 4.96,
        "id": 1,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 4.28,
        "temperature": 0,
        "text": " tutorial.",
        "tokens": [
          50578,
          7073,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 8.58,
        "id": 2,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 4.96,
        "temperature": 0,
        "text": " So I am following up on what I did in this previous video,",
        "tokens": [
          50612,
          407,
          286,
          669,
          3480,
          493,
          322,
          437,
          286,
          630,
          294,
          341,
          3894,
          960,
          11,
          50793
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 10.5,
        "id": 3,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 8.58,
        "temperature": 0,
        "text": " where I built this example.",
        "tokens": [
          50793,
          689,
          286,
          3094,
          341,
          1365,
          13,
          50889
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 14.38,
        "id": 4,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 10.5,
        "temperature": 0,
        "text": " This example has this interaction",
        "tokens": [
          50889,
          639,
          1365,
          575,
          341,
          9285,
          51083
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 17.400000000000002,
        "id": 5,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 14.38,
        "temperature": 0,
        "text": " where you click the mouse all over this canvas",
        "tokens": [
          51083,
          689,
          291,
          2052,
          264,
          9719,
          439,
          670,
          341,
          16267,
          51234
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 22.580000000000002,
        "id": 6,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 17.400000000000002,
        "temperature": 0,
        "text": " and press keys to assign each xy point a label, CDE.",
        "tokens": [
          51234,
          293,
          1886,
          9317,
          281,
          6269,
          1184,
          2031,
          88,
          935,
          257,
          7645,
          11,
          6743,
          36,
          13,
          51493
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 24.86,
        "id": 7,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 22.580000000000002,
        "temperature": 0,
        "text": " And I added a bunch of notes since the previous video,",
        "tokens": [
          51493,
          400,
          286,
          3869,
          257,
          3840,
          295,
          5570,
          1670,
          264,
          3894,
          960,
          11,
          51607
        ]
      },
      {
        "avg_logprob": -0.28503538527578676,
        "compression_ratio": 1.5583333333333333,
        "end": 28.1,
        "id": 8,
        "no_speech_prob": 0.009409508667886257,
        "seek": 0,
        "start": 24.86,
        "temperature": 0,
        "text": " so I have the full scale CDEFGAB.",
        "tokens": [
          51607,
          370,
          286,
          362,
          264,
          1577,
          4373,
          6743,
          36,
          37,
          12570,
          33,
          13,
          51769
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 30.900000000000002,
        "id": 9,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 28.1,
        "temperature": 0,
        "text": " Then I train the model with the inputs",
        "tokens": [
          50364,
          1396,
          286,
          3847,
          264,
          2316,
          365,
          264,
          15743,
          50504
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 34.660000000000004,
        "id": 10,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 30.900000000000002,
        "temperature": 0,
        "text": " being the xy of all these points and the target",
        "tokens": [
          50504,
          885,
          264,
          2031,
          88,
          295,
          439,
          613,
          2793,
          293,
          264,
          3779,
          50692
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 35.9,
        "id": 11,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 34.660000000000004,
        "temperature": 0,
        "text": " being the actual label.",
        "tokens": [
          50692,
          885,
          264,
          3539,
          7645,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 38.74,
        "id": 12,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 35.9,
        "temperature": 0,
        "text": " And once the model is trained, it can make guesses.",
        "tokens": [
          50754,
          400,
          1564,
          264,
          2316,
          307,
          8895,
          11,
          309,
          393,
          652,
          42703,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 41.06,
        "id": 13,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 38.74,
        "temperature": 0,
        "text": " So in theory, I just collected this data set,",
        "tokens": [
          50896,
          407,
          294,
          5261,
          11,
          286,
          445,
          11087,
          341,
          1412,
          992,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 41.94,
        "id": 14,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 41.06,
        "temperature": 0,
        "text": " trained the model.",
        "tokens": [
          51012,
          8895,
          264,
          2316,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 44.22,
        "id": 15,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 41.94,
        "temperature": 0,
        "text": " When I click into it, when I click over here,",
        "tokens": [
          51056,
          1133,
          286,
          2052,
          666,
          309,
          11,
          562,
          286,
          2052,
          670,
          510,
          11,
          51170
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 47.540000000000006,
        "id": 16,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 44.22,
        "temperature": 0,
        "text": " I should hear the musical note D. I should hear the musical note",
        "tokens": [
          51170,
          286,
          820,
          1568,
          264,
          9165,
          3637,
          413,
          13,
          286,
          820,
          1568,
          264,
          9165,
          3637,
          51336
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 53.82,
        "id": 17,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 47.540000000000006,
        "temperature": 0,
        "text": " E, G, A. And in between, it's sort of interesting",
        "tokens": [
          51336,
          462,
          11,
          460,
          11,
          316,
          13,
          400,
          294,
          1296,
          11,
          309,
          311,
          1333,
          295,
          1880,
          51650
        ]
      },
      {
        "avg_logprob": -0.2402575969696045,
        "compression_ratio": 1.777292576419214,
        "end": 55.14,
        "id": 18,
        "no_speech_prob": 0.00005475896978168748,
        "seek": 2810,
        "start": 53.82,
        "temperature": 0,
        "text": " to see what I get.",
        "tokens": [
          51650,
          281,
          536,
          437,
          286,
          483,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 59.94,
        "id": 19,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 55.14,
        "temperature": 0,
        "text": " But it works as expected.",
        "tokens": [
          50364,
          583,
          309,
          1985,
          382,
          5176,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 62.78,
        "id": 20,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 59.94,
        "temperature": 0,
        "text": " But I ran into a pretty significant problem",
        "tokens": [
          50604,
          583,
          286,
          5872,
          666,
          257,
          1238,
          4776,
          1154,
          50746
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 64.1,
        "id": 21,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 62.78,
        "temperature": 0,
        "text": " while working on this.",
        "tokens": [
          50746,
          1339,
          1364,
          322,
          341,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 67.68,
        "id": 22,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 64.1,
        "temperature": 0,
        "text": " Because once I've collected the data set",
        "tokens": [
          50812,
          1436,
          1564,
          286,
          600,
          11087,
          264,
          1412,
          992,
          50991
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 70.1,
        "id": 23,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 67.68,
        "temperature": 0,
        "text": " and trained the model, if I had a bug in the code",
        "tokens": [
          50991,
          293,
          8895,
          264,
          2316,
          11,
          498,
          286,
          632,
          257,
          7426,
          294,
          264,
          3089,
          51112
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 71.48,
        "id": 24,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 70.1,
        "temperature": 0,
        "text": " or something I needed to fix or I",
        "tokens": [
          51112,
          420,
          746,
          286,
          2978,
          281,
          3191,
          420,
          286,
          51181
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 73.02,
        "id": 25,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 71.48,
        "temperature": 0,
        "text": " wanted to try a different parameter,",
        "tokens": [
          51181,
          1415,
          281,
          853,
          257,
          819,
          13075,
          11,
          51258
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 77.5,
        "id": 26,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 73.02,
        "temperature": 0,
        "text": " I have to stop the sketch and run it again and sit there",
        "tokens": [
          51258,
          286,
          362,
          281,
          1590,
          264,
          12325,
          293,
          1190,
          309,
          797,
          293,
          1394,
          456,
          51482
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 80.82,
        "id": 27,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 77.5,
        "temperature": 0,
        "text": " and do this.",
        "tokens": [
          51482,
          293,
          360,
          341,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 83.1,
        "id": 28,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 80.82,
        "temperature": 0,
        "text": " This highly manual process of clicking, clicking,",
        "tokens": [
          51648,
          639,
          5405,
          9688,
          1399,
          295,
          9697,
          11,
          9697,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.27878149918147493,
        "compression_ratio": 1.6929460580912863,
        "end": 84.44,
        "id": 29,
        "no_speech_prob": 0.00035143576678819954,
        "seek": 5514,
        "start": 83.1,
        "temperature": 0,
        "text": " clicking to collect the data set.",
        "tokens": [
          51762,
          9697,
          281,
          2500,
          264,
          1412,
          992,
          13,
          51829
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 86.67999999999999,
        "id": 30,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 84.44,
        "temperature": 0,
        "text": " So in this video, I want to look at saving the data.",
        "tokens": [
          50364,
          407,
          294,
          341,
          960,
          11,
          286,
          528,
          281,
          574,
          412,
          6816,
          264,
          1412,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 89.28,
        "id": 31,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 86.67999999999999,
        "temperature": 0,
        "text": " And I also want to look at saving the model, which",
        "tokens": [
          50476,
          400,
          286,
          611,
          528,
          281,
          574,
          412,
          6816,
          264,
          2316,
          11,
          597,
          50606
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 91.96,
        "id": 32,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 89.28,
        "temperature": 0,
        "text": " is those are two pretty different things.",
        "tokens": [
          50606,
          307,
          729,
          366,
          732,
          1238,
          819,
          721,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 93.44,
        "id": 33,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 91.96,
        "temperature": 0,
        "text": " It might seem like the same idea.",
        "tokens": [
          50740,
          467,
          1062,
          1643,
          411,
          264,
          912,
          1558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 94.6,
        "id": 34,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 93.44,
        "temperature": 0,
        "text": " Oh, I want to save the data.",
        "tokens": [
          50814,
          876,
          11,
          286,
          528,
          281,
          3155,
          264,
          1412,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 95.64,
        "id": 35,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 94.6,
        "temperature": 0,
        "text": " I want to save the model.",
        "tokens": [
          50872,
          286,
          528,
          281,
          3155,
          264,
          2316,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 97.48,
        "id": 36,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 95.64,
        "temperature": 0,
        "text": " Why would I do one versus the other?",
        "tokens": [
          50924,
          1545,
          576,
          286,
          360,
          472,
          5717,
          264,
          661,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 99.48,
        "id": 37,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 97.48,
        "temperature": 0,
        "text": " Let's pause for a second and examine",
        "tokens": [
          51016,
          961,
          311,
          10465,
          337,
          257,
          1150,
          293,
          17496,
          51116
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 101.8,
        "id": 38,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 99.48,
        "temperature": 0,
        "text": " all the steps of a machine learning project",
        "tokens": [
          51116,
          439,
          264,
          4439,
          295,
          257,
          3479,
          2539,
          1716,
          51232
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 104.68,
        "id": 39,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 101.8,
        "temperature": 0,
        "text": " and where we might want to save the data versus save",
        "tokens": [
          51232,
          293,
          689,
          321,
          1062,
          528,
          281,
          3155,
          264,
          1412,
          5717,
          3155,
          51376
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 105.8,
        "id": 40,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 104.68,
        "temperature": 0,
        "text": " the model and why.",
        "tokens": [
          51376,
          264,
          2316,
          293,
          983,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 108.03999999999999,
        "id": 41,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 105.8,
        "temperature": 0,
        "text": " Step one, collect the data.",
        "tokens": [
          51432,
          5470,
          472,
          11,
          2500,
          264,
          1412,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.24423306608853274,
        "compression_ratio": 1.862962962962963,
        "end": 114.32,
        "id": 42,
        "no_speech_prob": 0.00002546633913880214,
        "seek": 8444,
        "start": 111.52,
        "temperature": 0,
        "text": " Now, this could be a really big, complicated step.",
        "tokens": [
          51718,
          823,
          11,
          341,
          727,
          312,
          257,
          534,
          955,
          11,
          6179,
          1823,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 116.47999999999999,
        "id": 43,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 115.19999999999999,
        "temperature": 0,
        "text": " But in my scenario, in my example,",
        "tokens": [
          50408,
          583,
          294,
          452,
          9005,
          11,
          294,
          452,
          1365,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 118.63999999999999,
        "id": 44,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 116.47999999999999,
        "temperature": 0,
        "text": " it's just clicking the mouse a whole bunch of times",
        "tokens": [
          50472,
          309,
          311,
          445,
          9697,
          264,
          9719,
          257,
          1379,
          3840,
          295,
          1413,
          50580
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 120.27999999999999,
        "id": 45,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 118.63999999999999,
        "temperature": 0,
        "text": " and pressing keys on the keyboard.",
        "tokens": [
          50580,
          293,
          12417,
          9317,
          322,
          264,
          10186,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 122.75999999999999,
        "id": 46,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 120.27999999999999,
        "temperature": 0,
        "text": " Step two, train the model.",
        "tokens": [
          50662,
          5470,
          732,
          11,
          3847,
          264,
          2316,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 127.52,
        "id": 47,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 125.6,
        "temperature": 0,
        "text": " Once the model has been trained, the idea",
        "tokens": [
          50928,
          3443,
          264,
          2316,
          575,
          668,
          8895,
          11,
          264,
          1558,
          51024
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 129.95999999999998,
        "id": 48,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 127.52,
        "temperature": 0,
        "text": " is to use that model in some scenario.",
        "tokens": [
          51024,
          307,
          281,
          764,
          300,
          2316,
          294,
          512,
          9005,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 132.64,
        "id": 49,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 129.95999999999998,
        "temperature": 0,
        "text": " So that we can call step three, deploy the model",
        "tokens": [
          51146,
          407,
          300,
          321,
          393,
          818,
          1823,
          1045,
          11,
          7274,
          264,
          2316,
          51280
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 134.07999999999998,
        "id": 50,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 132.64,
        "temperature": 0,
        "text": " or prediction inference.",
        "tokens": [
          51280,
          420,
          17630,
          38253,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2395406113457434,
        "compression_ratio": 1.6523809523809523,
        "end": 140.76,
        "id": 51,
        "no_speech_prob": 0.000016442443666164763,
        "seek": 11432,
        "start": 137.32,
        "temperature": 0,
        "text": " So now the question is, where along the way",
        "tokens": [
          51514,
          407,
          586,
          264,
          1168,
          307,
          11,
          689,
          2051,
          264,
          636,
          51686
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 144.39999999999998,
        "id": 52,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 140.76,
        "temperature": 0,
        "text": " might you want to save the state of what you're doing?",
        "tokens": [
          50364,
          1062,
          291,
          528,
          281,
          3155,
          264,
          1785,
          295,
          437,
          291,
          434,
          884,
          30,
          50546
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 148.16,
        "id": 53,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 144.39999999999998,
        "temperature": 0,
        "text": " So in the most traditional machine learning sense,",
        "tokens": [
          50546,
          407,
          294,
          264,
          881,
          5164,
          3479,
          2539,
          2020,
          11,
          50734
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 152.64,
        "id": 54,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 148.16,
        "temperature": 0,
        "text": " once you've done all of this and your model is trained,",
        "tokens": [
          50734,
          1564,
          291,
          600,
          1096,
          439,
          295,
          341,
          293,
          428,
          2316,
          307,
          8895,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 154,
        "id": 55,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 152.64,
        "temperature": 0,
        "text": " you don't ever need to look back.",
        "tokens": [
          50958,
          291,
          500,
          380,
          1562,
          643,
          281,
          574,
          646,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 155.48,
        "id": 56,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 154,
        "temperature": 0,
        "text": " You've got a trained model.",
        "tokens": [
          51026,
          509,
          600,
          658,
          257,
          8895,
          2316,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 156.79999999999998,
        "id": 57,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 155.48,
        "temperature": 0,
        "text": " You can save that model.",
        "tokens": [
          51100,
          509,
          393,
          3155,
          300,
          2316,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 160.2,
        "id": 58,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 156.79999999999998,
        "temperature": 0,
        "text": " So right here in between steps two and three",
        "tokens": [
          51166,
          407,
          558,
          510,
          294,
          1296,
          4439,
          732,
          293,
          1045,
          51336
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 162.48,
        "id": 59,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 160.2,
        "temperature": 0,
        "text": " is a point where we might want to save the model.",
        "tokens": [
          51336,
          307,
          257,
          935,
          689,
          321,
          1062,
          528,
          281,
          3155,
          264,
          2316,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 165.2,
        "id": 60,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 162.48,
        "temperature": 0,
        "text": " If we're done and our model is exactly the way we want it",
        "tokens": [
          51450,
          759,
          321,
          434,
          1096,
          293,
          527,
          2316,
          307,
          2293,
          264,
          636,
          321,
          528,
          309,
          51586
        ]
      },
      {
        "avg_logprob": -0.19121219998314268,
        "compression_ratio": 1.7911646586345382,
        "end": 167.56,
        "id": 61,
        "no_speech_prob": 0.0003740948741324246,
        "seek": 14076,
        "start": 165.2,
        "temperature": 0,
        "text": " and we're ready to just use it in a project.",
        "tokens": [
          51586,
          293,
          321,
          434,
          1919,
          281,
          445,
          764,
          309,
          294,
          257,
          1716,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 170.84,
        "id": 62,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 167.56,
        "temperature": 0,
        "text": " However, you might want to try training the model",
        "tokens": [
          50364,
          2908,
          11,
          291,
          1062,
          528,
          281,
          853,
          3097,
          264,
          2316,
          50528
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 172.8,
        "id": 63,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 170.84,
        "temperature": 0,
        "text": " a variety of different ways.",
        "tokens": [
          50528,
          257,
          5673,
          295,
          819,
          2098,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 176.68,
        "id": 64,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 172.8,
        "temperature": 0,
        "text": " And this is where you might want to in between these two steps",
        "tokens": [
          50626,
          400,
          341,
          307,
          689,
          291,
          1062,
          528,
          281,
          294,
          1296,
          613,
          732,
          4439,
          50820
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 179.12,
        "id": 65,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 176.68,
        "temperature": 0,
        "text": " save the data.",
        "tokens": [
          50820,
          3155,
          264,
          1412,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 180.84,
        "id": 66,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 179.12,
        "temperature": 0,
        "text": " We also might collect a lot of data.",
        "tokens": [
          50942,
          492,
          611,
          1062,
          2500,
          257,
          688,
          295,
          1412,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 184.44,
        "id": 67,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 180.84,
        "temperature": 0,
        "text": " I want to take a break, reload that data, collect more data.",
        "tokens": [
          51028,
          286,
          528,
          281,
          747,
          257,
          1821,
          11,
          25628,
          300,
          1412,
          11,
          2500,
          544,
          1412,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 185.9,
        "id": 68,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 184.44,
        "temperature": 0,
        "text": " There's a lot of different reasons",
        "tokens": [
          51208,
          821,
          311,
          257,
          688,
          295,
          819,
          4112,
          51281
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 189.64000000000001,
        "id": 69,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 185.9,
        "temperature": 0,
        "text": " why we might want to stop in between step one and two",
        "tokens": [
          51281,
          983,
          321,
          1062,
          528,
          281,
          1590,
          294,
          1296,
          1823,
          472,
          293,
          732,
          51468
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 191.48000000000002,
        "id": 70,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 189.64000000000001,
        "temperature": 0,
        "text": " and save where we are.",
        "tokens": [
          51468,
          293,
          3155,
          689,
          321,
          366,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2481367546215392,
        "compression_ratio": 1.800865800865801,
        "end": 194.14000000000001,
        "id": 71,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 16756,
        "start": 191.48000000000002,
        "temperature": 0,
        "text": " And the functions in the ml5 neural network class",
        "tokens": [
          51560,
          400,
          264,
          6828,
          294,
          264,
          23271,
          20,
          18161,
          3209,
          1508,
          51693
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 200.33999999999997,
        "id": 72,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 194.17999999999998,
        "temperature": 0,
        "text": " that we want to use are save data and save.",
        "tokens": [
          50366,
          300,
          321,
          528,
          281,
          764,
          366,
          3155,
          1412,
          293,
          3155,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 203.17999999999998,
        "id": 73,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 200.33999999999997,
        "temperature": 0,
        "text": " So just save is saving the model.",
        "tokens": [
          50674,
          407,
          445,
          3155,
          307,
          6816,
          264,
          2316,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 205.61999999999998,
        "id": 74,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 203.17999999999998,
        "temperature": 0,
        "text": " Save data is saving the data.",
        "tokens": [
          50816,
          15541,
          1412,
          307,
          6816,
          264,
          1412,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 208.05999999999997,
        "id": 75,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 205.61999999999998,
        "temperature": 0,
        "text": " There are also functions for loading it back,",
        "tokens": [
          50938,
          821,
          366,
          611,
          6828,
          337,
          15114,
          309,
          646,
          11,
          51060
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 208.94,
        "id": 76,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 208.05999999999997,
        "temperature": 0,
        "text": " which we'll look at.",
        "tokens": [
          51060,
          597,
          321,
          603,
          574,
          412,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 213.01999999999998,
        "id": 77,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 208.94,
        "temperature": 0,
        "text": " Load data and load.",
        "tokens": [
          51104,
          48408,
          1412,
          293,
          3677,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 216.38,
        "id": 78,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 213.01999999999998,
        "temperature": 0,
        "text": " Let's begin by just looking at save data.",
        "tokens": [
          51308,
          961,
          311,
          1841,
          538,
          445,
          1237,
          412,
          3155,
          1412,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 218.61999999999998,
        "id": 79,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 216.38,
        "temperature": 0,
        "text": " So in this particular example, all of the interaction",
        "tokens": [
          51476,
          407,
          294,
          341,
          1729,
          1365,
          11,
          439,
          295,
          264,
          9285,
          51588
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 219.82,
        "id": 80,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 218.61999999999998,
        "temperature": 0,
        "text": " happens with key presses.",
        "tokens": [
          51588,
          2314,
          365,
          2141,
          40892,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2314152670378732,
        "compression_ratio": 1.6267281105990783,
        "end": 221.33999999999997,
        "id": 81,
        "no_speech_prob": 0.0005527772009372711,
        "seek": 19414,
        "start": 219.82,
        "temperature": 0,
        "text": " Certainly, as I've mentioned before,",
        "tokens": [
          51648,
          16628,
          11,
          382,
          286,
          600,
          2835,
          949,
          11,
          51724
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 224.3,
        "id": 82,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 221.34,
        "temperature": 0,
        "text": " you might want to think about a more thoughtful interface",
        "tokens": [
          50364,
          291,
          1062,
          528,
          281,
          519,
          466,
          257,
          544,
          21566,
          9226,
          50512
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 225.5,
        "id": 83,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 224.3,
        "temperature": 0,
        "text": " for doing all this work.",
        "tokens": [
          50512,
          337,
          884,
          439,
          341,
          589,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 227.78,
        "id": 84,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 225.5,
        "temperature": 0,
        "text": " But for me, I'm just going to add another key press",
        "tokens": [
          50572,
          583,
          337,
          385,
          11,
          286,
          478,
          445,
          516,
          281,
          909,
          1071,
          2141,
          1886,
          50686
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 229.94,
        "id": 85,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 227.78,
        "temperature": 0,
        "text": " S for save data.",
        "tokens": [
          50686,
          318,
          337,
          3155,
          1412,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 234.7,
        "id": 86,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 229.94,
        "temperature": 0,
        "text": " So I'm going to say else if the key is S.",
        "tokens": [
          50794,
          407,
          286,
          478,
          516,
          281,
          584,
          1646,
          498,
          264,
          2141,
          307,
          318,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 236.54,
        "id": 87,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 234.7,
        "temperature": 0,
        "text": " Then I'm going to call model save data.",
        "tokens": [
          51032,
          1396,
          286,
          478,
          516,
          281,
          818,
          2316,
          3155,
          1412,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 241.62,
        "id": 88,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 239.38,
        "temperature": 0,
        "text": " I can look at more about how the save data function works",
        "tokens": [
          51266,
          286,
          393,
          574,
          412,
          544,
          466,
          577,
          264,
          3155,
          1412,
          2445,
          1985,
          51378
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 243.24,
        "id": 89,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 241.62,
        "temperature": 0,
        "text": " by looking at the ml5 website.",
        "tokens": [
          51378,
          538,
          1237,
          412,
          264,
          23271,
          20,
          3144,
          13,
          51459
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 245.3,
        "id": 90,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 243.24,
        "temperature": 0,
        "text": " We can see there's two optional arguments.",
        "tokens": [
          51459,
          492,
          393,
          536,
          456,
          311,
          732,
          17312,
          12869,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 247.02,
        "id": 91,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 245.3,
        "temperature": 0,
        "text": " So one argument is a file name, which",
        "tokens": [
          51562,
          407,
          472,
          6770,
          307,
          257,
          3991,
          1315,
          11,
          597,
          51648
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 248.66,
        "id": 92,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 247.02,
        "temperature": 0,
        "text": " I want to use because I want to set the file name.",
        "tokens": [
          51648,
          286,
          528,
          281,
          764,
          570,
          286,
          528,
          281,
          992,
          264,
          3991,
          1315,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.2266393464187096,
        "compression_ratio": 1.7789855072463767,
        "end": 250.22,
        "id": 93,
        "no_speech_prob": 0.0006986735970713198,
        "seek": 22134,
        "start": 248.66,
        "temperature": 0,
        "text": " It'll just pick a date if you don't.",
        "tokens": [
          51730,
          467,
          603,
          445,
          1888,
          257,
          4002,
          498,
          291,
          500,
          380,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 252.02,
        "id": 94,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 250.22,
        "temperature": 0,
        "text": " And then a callback to know that it's done.",
        "tokens": [
          50364,
          400,
          550,
          257,
          818,
          3207,
          281,
          458,
          300,
          309,
          311,
          1096,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 253.98,
        "id": 95,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 252.02,
        "temperature": 0,
        "text": " I don't actually really need to worry about that",
        "tokens": [
          50454,
          286,
          500,
          380,
          767,
          534,
          643,
          281,
          3292,
          466,
          300,
          50552
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 256.66,
        "id": 96,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 253.98,
        "temperature": 0,
        "text": " because I'll know that it's done when the file is there",
        "tokens": [
          50552,
          570,
          286,
          603,
          458,
          300,
          309,
          311,
          1096,
          562,
          264,
          3991,
          307,
          456,
          50686
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 259.42,
        "id": 97,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 256.66,
        "temperature": 0,
        "text": " and downloaded to the downloads directory.",
        "tokens": [
          50686,
          293,
          21748,
          281,
          264,
          36553,
          21120,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 264.38,
        "id": 98,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 259.42,
        "temperature": 0,
        "text": " I'm going to give it the name mouse notes and run the sketch",
        "tokens": [
          50824,
          286,
          478,
          516,
          281,
          976,
          309,
          264,
          1315,
          9719,
          5570,
          293,
          1190,
          264,
          12325,
          51072
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 265.3,
        "id": 99,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 264.38,
        "temperature": 0,
        "text": " and collect some data.",
        "tokens": [
          51072,
          293,
          2500,
          512,
          1412,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 271.26,
        "id": 100,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 269.58,
        "temperature": 0,
        "text": " So I'm just going to do a little bit just",
        "tokens": [
          51332,
          407,
          286,
          478,
          445,
          516,
          281,
          360,
          257,
          707,
          857,
          445,
          51416
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 272.46,
        "id": 101,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 271.26,
        "temperature": 0,
        "text": " to make sure it's working.",
        "tokens": [
          51416,
          281,
          652,
          988,
          309,
          311,
          1364,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.22815296338952107,
        "compression_ratio": 1.7179487179487178,
        "end": 278.14,
        "id": 102,
        "no_speech_prob": 0.00013341903104446828,
        "seek": 25022,
        "start": 272.46,
        "temperature": 0,
        "text": " So now I can hit S. And look, a file has been downloaded.",
        "tokens": [
          51476,
          407,
          586,
          286,
          393,
          2045,
          318,
          13,
          400,
          574,
          11,
          257,
          3991,
          575,
          668,
          21748,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 280.9,
        "id": 103,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 278.14,
        "temperature": 0,
        "text": " I can take a look at this file in Visual Studio Code.",
        "tokens": [
          50364,
          286,
          393,
          747,
          257,
          574,
          412,
          341,
          3991,
          294,
          23187,
          13500,
          15549,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 282.4,
        "id": 104,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 280.9,
        "temperature": 0,
        "text": " And here's what the file looks like.",
        "tokens": [
          50502,
          400,
          510,
          311,
          437,
          264,
          3991,
          1542,
          411,
          13,
          50577
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 285.18,
        "id": 105,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 282.4,
        "temperature": 0,
        "text": " So I've got a data property with an array that",
        "tokens": [
          50577,
          407,
          286,
          600,
          658,
          257,
          1412,
          4707,
          365,
          364,
          10225,
          300,
          50716
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 286.21999999999997,
        "id": 106,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 285.18,
        "temperature": 0,
        "text": " has all the data in it.",
        "tokens": [
          50716,
          575,
          439,
          264,
          1412,
          294,
          309,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 287.38,
        "id": 107,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 286.21999999999997,
        "temperature": 0,
        "text": " X, Y's with a label.",
        "tokens": [
          50768,
          1783,
          11,
          398,
          311,
          365,
          257,
          7645,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 288.74,
        "id": 108,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 287.38,
        "temperature": 0,
        "text": " X, Y with a label.",
        "tokens": [
          50826,
          1783,
          11,
          398,
          365,
          257,
          7645,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 291.14,
        "id": 109,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 288.74,
        "temperature": 0,
        "text": " And if I reformat the JSON, you can actually see it here.",
        "tokens": [
          50894,
          400,
          498,
          286,
          8290,
          267,
          264,
          31828,
          11,
          291,
          393,
          767,
          536,
          309,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 293.02,
        "id": 110,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 291.14,
        "temperature": 0,
        "text": " And it's much more legible what's going on.",
        "tokens": [
          51014,
          400,
          309,
          311,
          709,
          544,
          1676,
          964,
          437,
          311,
          516,
          322,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 295.5,
        "id": 111,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 293.02,
        "temperature": 0,
        "text": " So this is all of the data that I've collected.",
        "tokens": [
          51108,
          407,
          341,
          307,
          439,
          295,
          264,
          1412,
          300,
          286,
          600,
          11087,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 297.21999999999997,
        "id": 112,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 295.5,
        "temperature": 0,
        "text": " Not very much data, but there it is.",
        "tokens": [
          51232,
          1726,
          588,
          709,
          1412,
          11,
          457,
          456,
          309,
          307,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 299.97999999999996,
        "id": 113,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 297.21999999999997,
        "temperature": 0,
        "text": " So now that I've done that, I might as well",
        "tokens": [
          51318,
          407,
          586,
          300,
          286,
          600,
          1096,
          300,
          11,
          286,
          1062,
          382,
          731,
          51456
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 303.18,
        "id": 114,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 299.97999999999996,
        "temperature": 0,
        "text": " take the time to collect a lot more data",
        "tokens": [
          51456,
          747,
          264,
          565,
          281,
          2500,
          257,
          688,
          544,
          1412,
          51616
        ]
      },
      {
        "avg_logprob": -0.21864623543601366,
        "compression_ratio": 1.745644599303136,
        "end": 304.5,
        "id": 115,
        "no_speech_prob": 0.00022341460862662643,
        "seek": 27814,
        "start": 303.18,
        "temperature": 0,
        "text": " knowing that I can save it.",
        "tokens": [
          51616,
          5276,
          300,
          286,
          393,
          3155,
          309,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 318.53999999999996,
        "id": 116,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 308.14,
        "temperature": 0,
        "text": " So I've methodically collected a large data set.",
        "tokens": [
          50364,
          407,
          286,
          600,
          3170,
          984,
          11087,
          257,
          2416,
          1412,
          992,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 322.86,
        "id": 117,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 318.53999999999996,
        "temperature": 0,
        "text": " Now I'm going to press S to save it.",
        "tokens": [
          50884,
          823,
          286,
          478,
          516,
          281,
          1886,
          318,
          281,
          3155,
          309,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 324.53999999999996,
        "id": 118,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 322.86,
        "temperature": 0,
        "text": " And here's what it looks like.",
        "tokens": [
          51100,
          400,
          510,
          311,
          437,
          309,
          1542,
          411,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 326.14,
        "id": 119,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 324.53999999999996,
        "temperature": 0,
        "text": " Almost 400 data samples.",
        "tokens": [
          51184,
          12627,
          8423,
          1412,
          10938,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 327.21999999999997,
        "id": 120,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 326.14,
        "temperature": 0,
        "text": " Let's see how it performs.",
        "tokens": [
          51264,
          961,
          311,
          536,
          577,
          309,
          26213,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 328.41999999999996,
        "id": 121,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 327.21999999999997,
        "temperature": 0,
        "text": " I'm going to train the model.",
        "tokens": [
          51318,
          286,
          478,
          516,
          281,
          3847,
          264,
          2316,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.2945137568882534,
        "compression_ratio": 1.382716049382716,
        "end": 332.53999999999996,
        "id": 122,
        "no_speech_prob": 0.00009915213740896434,
        "seek": 30814,
        "start": 331.34,
        "temperature": 0,
        "text": " Try doing some inference.",
        "tokens": [
          51524,
          6526,
          884,
          512,
          38253,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 343.41999999999996,
        "id": 123,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 339.14,
        "temperature": 0,
        "text": " And it works pretty well.",
        "tokens": [
          50414,
          400,
          309,
          1985,
          1238,
          731,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 346.53999999999996,
        "id": 124,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 343.41999999999996,
        "temperature": 0,
        "text": " So now the next thing that I want to try to do",
        "tokens": [
          50628,
          407,
          586,
          264,
          958,
          551,
          300,
          286,
          528,
          281,
          853,
          281,
          360,
          50784
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 349.41999999999996,
        "id": 125,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 346.53999999999996,
        "temperature": 0,
        "text": " is hit Stop and run the sketch again,",
        "tokens": [
          50784,
          307,
          2045,
          5535,
          293,
          1190,
          264,
          12325,
          797,
          11,
          50928
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 351.34,
        "id": 126,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 349.41999999999996,
        "temperature": 0,
        "text": " but have all of my data reappear.",
        "tokens": [
          50928,
          457,
          362,
          439,
          295,
          452,
          1412,
          35638,
          14881,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 353.09999999999997,
        "id": 127,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 351.34,
        "temperature": 0,
        "text": " Let's see if I can make that happen.",
        "tokens": [
          51024,
          961,
          311,
          536,
          498,
          286,
          393,
          652,
          300,
          1051,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 357.18,
        "id": 128,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 353.09999999999997,
        "temperature": 0,
        "text": " Now, instead of just creating the neural network,",
        "tokens": [
          51112,
          823,
          11,
          2602,
          295,
          445,
          4084,
          264,
          18161,
          3209,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 360.3,
        "id": 129,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 357.18,
        "temperature": 0,
        "text": " I can create the neural network and load data into it.",
        "tokens": [
          51316,
          286,
          393,
          1884,
          264,
          18161,
          3209,
          293,
          3677,
          1412,
          666,
          309,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 365.26,
        "id": 130,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 360.3,
        "temperature": 0,
        "text": " And that's as easy as saying model load data mouse notes",
        "tokens": [
          51472,
          400,
          300,
          311,
          382,
          1858,
          382,
          1566,
          2316,
          3677,
          1412,
          9719,
          5570,
          51720
        ]
      },
      {
        "avg_logprob": -0.2565152621963649,
        "compression_ratio": 1.5829596412556053,
        "end": 366.9,
        "id": 131,
        "no_speech_prob": 0.0002492312924005091,
        "seek": 33814,
        "start": 365.26,
        "temperature": 0,
        "text": " dot JSON.",
        "tokens": [
          51720,
          5893,
          31828,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 368.88,
        "id": 132,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 366.9,
        "temperature": 0,
        "text": " The only thing here is that you have",
        "tokens": [
          50364,
          440,
          787,
          551,
          510,
          307,
          300,
          291,
          362,
          50463
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 372.21999999999997,
        "id": 133,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 368.88,
        "temperature": 0,
        "text": " to remember that I'm working in client-side JavaScript only.",
        "tokens": [
          50463,
          281,
          1604,
          300,
          286,
          478,
          1364,
          294,
          6423,
          12,
          1812,
          15778,
          787,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 377.62,
        "id": 134,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 372.21999999999997,
        "temperature": 0,
        "text": " So if I run this right now, it's giving me this nice error",
        "tokens": [
          50630,
          407,
          498,
          286,
          1190,
          341,
          558,
          586,
          11,
          309,
          311,
          2902,
          385,
          341,
          1481,
          6713,
          50900
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 380.82,
        "id": 135,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 377.62,
        "temperature": 0,
        "text": " here because it's looking for a JSON object",
        "tokens": [
          50900,
          510,
          570,
          309,
          311,
          1237,
          337,
          257,
          31828,
          2657,
          51060
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 382.29999999999995,
        "id": 136,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 380.82,
        "temperature": 0,
        "text": " with an array called data.",
        "tokens": [
          51060,
          365,
          364,
          10225,
          1219,
          1412,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 386.34,
        "id": 137,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 382.29999999999995,
        "temperature": 0,
        "text": " But it can't find it because that JSON file doesn't exist.",
        "tokens": [
          51134,
          583,
          309,
          393,
          380,
          915,
          309,
          570,
          300,
          31828,
          3991,
          1177,
          380,
          2514,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 387.97999999999996,
        "id": 138,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 386.34,
        "temperature": 0,
        "text": " It doesn't exist because I downloaded it",
        "tokens": [
          51336,
          467,
          1177,
          380,
          2514,
          570,
          286,
          21748,
          309,
          51418
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 389.58,
        "id": 139,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 387.97999999999996,
        "temperature": 0,
        "text": " to the downloads directory.",
        "tokens": [
          51418,
          281,
          264,
          36553,
          21120,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 392.58,
        "id": 140,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 389.58,
        "temperature": 0,
        "text": " And so for my p5 sketch to be able to access it,",
        "tokens": [
          51498,
          400,
          370,
          337,
          452,
          280,
          20,
          12325,
          281,
          312,
          1075,
          281,
          2105,
          309,
          11,
          51648
        ]
      },
      {
        "avg_logprob": -0.2083578109741211,
        "compression_ratio": 1.6546762589928057,
        "end": 395.41999999999996,
        "id": 141,
        "no_speech_prob": 0.00015118095325306058,
        "seek": 36690,
        "start": 392.58,
        "temperature": 0,
        "text": " I have to manually upload it back to the p5 web editor.",
        "tokens": [
          51648,
          286,
          362,
          281,
          16945,
          6580,
          309,
          646,
          281,
          264,
          280,
          20,
          3670,
          9839,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 398.5,
        "id": 142,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 395.42,
        "temperature": 0,
        "text": " If I were writing my own server, maybe with Node.js,",
        "tokens": [
          50364,
          759,
          286,
          645,
          3579,
          452,
          1065,
          7154,
          11,
          1310,
          365,
          38640,
          13,
          25530,
          11,
          50518
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 400.86,
        "id": 143,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 398.5,
        "temperature": 0,
        "text": " I could do something where I could save the data",
        "tokens": [
          50518,
          286,
          727,
          360,
          746,
          689,
          286,
          727,
          3155,
          264,
          1412,
          50636
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 402.46000000000004,
        "id": 144,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 400.86,
        "temperature": 0,
        "text": " and have it reload back automatically.",
        "tokens": [
          50636,
          293,
          362,
          309,
          25628,
          646,
          6772,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 405.7,
        "id": 145,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 402.46000000000004,
        "temperature": 0,
        "text": " But that's another example for another time.",
        "tokens": [
          50716,
          583,
          300,
          311,
          1071,
          1365,
          337,
          1071,
          565,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 409.42,
        "id": 146,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 405.7,
        "temperature": 0,
        "text": " Let me do add file and drag mouse notes JSON in here.",
        "tokens": [
          50878,
          961,
          385,
          360,
          909,
          3991,
          293,
          5286,
          9719,
          5570,
          31828,
          294,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 416.06,
        "id": 147,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 411.98,
        "temperature": 0,
        "text": " Now we can see that that file is part of my p5 sketch.",
        "tokens": [
          51192,
          823,
          321,
          393,
          536,
          300,
          300,
          3991,
          307,
          644,
          295,
          452,
          280,
          20,
          12325,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 418.18,
        "id": 148,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 416.06,
        "temperature": 0,
        "text": " And it should be able to run the sketch now.",
        "tokens": [
          51396,
          400,
          309,
          820,
          312,
          1075,
          281,
          1190,
          264,
          12325,
          586,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 420.5,
        "id": 149,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 418.18,
        "temperature": 0,
        "text": " All right, I think the data was loaded.",
        "tokens": [
          51502,
          1057,
          558,
          11,
          286,
          519,
          264,
          1412,
          390,
          13210,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.22506627169522372,
        "compression_ratio": 1.5805243445692885,
        "end": 423.18,
        "id": 150,
        "no_speech_prob": 0.00003321411713841371,
        "seek": 39542,
        "start": 420.5,
        "temperature": 0,
        "text": " I don't see it because I'm not drawing it.",
        "tokens": [
          51618,
          286,
          500,
          380,
          536,
          309,
          570,
          286,
          478,
          406,
          6316,
          309,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 425.46,
        "id": 151,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 423.22,
        "temperature": 0,
        "text": " So this might be something I want to add in a moment,",
        "tokens": [
          50366,
          407,
          341,
          1062,
          312,
          746,
          286,
          528,
          281,
          909,
          294,
          257,
          1623,
          11,
          50478
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 427.5,
        "id": 152,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 425.46,
        "temperature": 0,
        "text": " be able to draw the data that it's loaded.",
        "tokens": [
          50478,
          312,
          1075,
          281,
          2642,
          264,
          1412,
          300,
          309,
          311,
          13210,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 431.58,
        "id": 153,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 427.5,
        "temperature": 0,
        "text": " But in theory, there's no reason why I couldn't train the model.",
        "tokens": [
          50580,
          583,
          294,
          5261,
          11,
          456,
          311,
          572,
          1778,
          983,
          286,
          2809,
          380,
          3847,
          264,
          2316,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 436.18,
        "id": 154,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 434.94,
        "temperature": 0,
        "text": " All right, the model's trained.",
        "tokens": [
          50952,
          1057,
          558,
          11,
          264,
          2316,
          311,
          8895,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 443.66,
        "id": 155,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 441.18,
        "temperature": 0,
        "text": " And you can see, I'm not seeing the data.",
        "tokens": [
          51264,
          400,
          291,
          393,
          536,
          11,
          286,
          478,
          406,
          2577,
          264,
          1412,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 445.14,
        "id": 156,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 443.66,
        "temperature": 0,
        "text": " I'm not seeing those clusters.",
        "tokens": [
          51388,
          286,
          478,
          406,
          2577,
          729,
          23313,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 449.62,
        "id": 157,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 445.14,
        "temperature": 0,
        "text": " But it's clearly been trained based on that data.",
        "tokens": [
          51462,
          583,
          309,
          311,
          4448,
          668,
          8895,
          2361,
          322,
          300,
          1412,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2732440948486328,
        "compression_ratio": 1.6761904761904762,
        "end": 451.26,
        "id": 158,
        "no_speech_prob": 0.0006771864136680961,
        "seek": 42318,
        "start": 449.62,
        "temperature": 0,
        "text": " To show you how this can be useful,",
        "tokens": [
          51686,
          1407,
          855,
          291,
          577,
          341,
          393,
          312,
          4420,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 452.65999999999997,
        "id": 159,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 451.26,
        "temperature": 0,
        "text": " one thing that I might want to do",
        "tokens": [
          50364,
          472,
          551,
          300,
          286,
          1062,
          528,
          281,
          360,
          50434
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 455.65999999999997,
        "id": 160,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 452.65999999999997,
        "temperature": 0,
        "text": " is change some property that affects the training process",
        "tokens": [
          50434,
          307,
          1319,
          512,
          4707,
          300,
          11807,
          264,
          3097,
          1399,
          50584
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 457.14,
        "id": 161,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 455.65999999999997,
        "temperature": 0,
        "text": " so I could try it multiple times.",
        "tokens": [
          50584,
          370,
          286,
          727,
          853,
          309,
          3866,
          1413,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 459.7,
        "id": 162,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 457.14,
        "temperature": 0,
        "text": " And an obvious one might be to try learning rate.",
        "tokens": [
          50658,
          400,
          364,
          6322,
          472,
          1062,
          312,
          281,
          853,
          2539,
          3314,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 464.18,
        "id": 163,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 459.7,
        "temperature": 0,
        "text": " So let's say I make a really smaller learning rate, 0.01,",
        "tokens": [
          50786,
          407,
          718,
          311,
          584,
          286,
          652,
          257,
          534,
          4356,
          2539,
          3314,
          11,
          1958,
          13,
          10607,
          11,
          51010
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 465.5,
        "id": 164,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 464.18,
        "temperature": 0,
        "text": " and I run the sketch again.",
        "tokens": [
          51010,
          293,
          286,
          1190,
          264,
          12325,
          797,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 467.42,
        "id": 165,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 465.5,
        "temperature": 0,
        "text": " I've got to click in here so that my key press gets",
        "tokens": [
          51076,
          286,
          600,
          658,
          281,
          2052,
          294,
          510,
          370,
          300,
          452,
          2141,
          1886,
          2170,
          51172
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 468.18,
        "id": 166,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 467.42,
        "temperature": 0,
        "text": " activated.",
        "tokens": [
          51172,
          18157,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 473.3,
        "id": 167,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 468.18,
        "temperature": 0,
        "text": " So I'm going to add one more piece of data and hit T.",
        "tokens": [
          51210,
          407,
          286,
          478,
          516,
          281,
          909,
          472,
          544,
          2522,
          295,
          1412,
          293,
          2045,
          314,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 475.9,
        "id": 168,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 473.3,
        "temperature": 0,
        "text": " So you can see, with a small learning rate,",
        "tokens": [
          51466,
          407,
          291,
          393,
          536,
          11,
          365,
          257,
          1359,
          2539,
          3314,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.22492440541585287,
        "compression_ratio": 1.7060931899641576,
        "end": 479.46,
        "id": 169,
        "no_speech_prob": 0.000054759544582339004,
        "seek": 45126,
        "start": 475.9,
        "temperature": 0,
        "text": " the loss is going down very, very, very, very slowly.",
        "tokens": [
          51596,
          264,
          4470,
          307,
          516,
          760,
          588,
          11,
          588,
          11,
          588,
          11,
          588,
          5692,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 481.34,
        "id": 170,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 479.46,
        "temperature": 0,
        "text": " So in this case, having a small learning rate",
        "tokens": [
          50364,
          407,
          294,
          341,
          1389,
          11,
          1419,
          257,
          1359,
          2539,
          3314,
          50458
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 483.02,
        "id": 171,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 481.34,
        "temperature": 0,
        "text": " is not super helpful.",
        "tokens": [
          50458,
          307,
          406,
          1687,
          4961,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 485.53999999999996,
        "id": 172,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 483.02,
        "temperature": 0,
        "text": " But I can say, OK, that learning rate wasn't good.",
        "tokens": [
          50542,
          583,
          286,
          393,
          584,
          11,
          2264,
          11,
          300,
          2539,
          3314,
          2067,
          380,
          665,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 488.73999999999995,
        "id": 173,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 485.53999999999996,
        "temperature": 0,
        "text": " Let me try a much larger learning rate, like 0.5,",
        "tokens": [
          50668,
          961,
          385,
          853,
          257,
          709,
          4833,
          2539,
          3314,
          11,
          411,
          1958,
          13,
          20,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 491.34,
        "id": 174,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 488.73999999999995,
        "temperature": 0,
        "text": " run it again, hit T for train.",
        "tokens": [
          50828,
          1190,
          309,
          797,
          11,
          2045,
          314,
          337,
          3847,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 496.94,
        "id": 175,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 494.5,
        "temperature": 0,
        "text": " And then, ah, you can see with this high learning rate,",
        "tokens": [
          51116,
          400,
          550,
          11,
          3716,
          11,
          291,
          393,
          536,
          365,
          341,
          1090,
          2539,
          3314,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 498.94,
        "id": 176,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 496.94,
        "temperature": 0,
        "text": " that loss is going down really, really quickly.",
        "tokens": [
          51238,
          300,
          4470,
          307,
          516,
          760,
          534,
          11,
          534,
          2661,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 500.47999999999996,
        "id": 177,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 498.94,
        "temperature": 0,
        "text": " Now, I don't mean to suggest here",
        "tokens": [
          51338,
          823,
          11,
          286,
          500,
          380,
          914,
          281,
          3402,
          510,
          51415
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 502.58,
        "id": 178,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 500.47999999999996,
        "temperature": 0,
        "text": " that universally a high learning rate is",
        "tokens": [
          51415,
          300,
          43995,
          257,
          1090,
          2539,
          3314,
          307,
          51520
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 503.94,
        "id": 179,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 502.58,
        "temperature": 0,
        "text": " better than a low learning rate.",
        "tokens": [
          51520,
          1101,
          813,
          257,
          2295,
          2539,
          3314,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.22782581502741034,
        "compression_ratio": 1.718146718146718,
        "end": 505.9,
        "id": 180,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 47946,
        "start": 503.94,
        "temperature": 0,
        "text": " There's a lot of it depends here.",
        "tokens": [
          51588,
          821,
          311,
          257,
          688,
          295,
          309,
          5946,
          510,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 509.06,
        "id": 181,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 505.94,
        "temperature": 0,
        "text": " But just to show you how you can now",
        "tokens": [
          50366,
          583,
          445,
          281,
          855,
          291,
          577,
          291,
          393,
          586,
          50522
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 511.78,
        "id": 182,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 509.06,
        "temperature": 0,
        "text": " retrain the model changing all of the different kinds",
        "tokens": [
          50522,
          1533,
          7146,
          264,
          2316,
          4473,
          439,
          295,
          264,
          819,
          3685,
          50658
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 515.86,
        "id": 183,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 511.78,
        "temperature": 0,
        "text": " of options, and you could look at the ml5 neural network",
        "tokens": [
          50658,
          295,
          3956,
          11,
          293,
          291,
          727,
          574,
          412,
          264,
          23271,
          20,
          18161,
          3209,
          50862
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 518.5,
        "id": 184,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 515.86,
        "temperature": 0,
        "text": " documentation and see what other kind of options",
        "tokens": [
          50862,
          14333,
          293,
          536,
          437,
          661,
          733,
          295,
          3956,
          50994
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 520.54,
        "id": 185,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 518.5,
        "temperature": 0,
        "text": " you might want to play around with or change.",
        "tokens": [
          50994,
          291,
          1062,
          528,
          281,
          862,
          926,
          365,
          420,
          1319,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 522.4599999999999,
        "id": 186,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 520.54,
        "temperature": 0,
        "text": " You might be finding this example a little bit",
        "tokens": [
          51096,
          509,
          1062,
          312,
          5006,
          341,
          1365,
          257,
          707,
          857,
          51192
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 524.86,
        "id": 187,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 522.4599999999999,
        "temperature": 0,
        "text": " tricky to follow because you can't actually see the data.",
        "tokens": [
          51192,
          12414,
          281,
          1524,
          570,
          291,
          393,
          380,
          767,
          536,
          264,
          1412,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 527.3,
        "id": 188,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 524.86,
        "temperature": 0,
        "text": " So let's add that feature of, once I've loaded the data,",
        "tokens": [
          51312,
          407,
          718,
          311,
          909,
          300,
          4111,
          295,
          11,
          1564,
          286,
          600,
          13210,
          264,
          1412,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 528.78,
        "id": 189,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 527.3,
        "temperature": 0,
        "text": " also drawing it to the canvas.",
        "tokens": [
          51434,
          611,
          6316,
          309,
          281,
          264,
          16267,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 530.3,
        "id": 190,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 528.78,
        "temperature": 0,
        "text": " So in this case, having a callback",
        "tokens": [
          51508,
          407,
          294,
          341,
          1389,
          11,
          1419,
          257,
          818,
          3207,
          51584
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 532.98,
        "id": 191,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 530.3,
        "temperature": 0,
        "text": " for when the data is ready would be very useful.",
        "tokens": [
          51584,
          337,
          562,
          264,
          1412,
          307,
          1919,
          576,
          312,
          588,
          4420,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.24222619566198897,
        "compression_ratio": 1.7210031347962382,
        "end": 534.78,
        "id": 192,
        "no_speech_prob": 0.0004373304545879364,
        "seek": 50590,
        "start": 532.98,
        "temperature": 0,
        "text": " I'm going to say data loaded.",
        "tokens": [
          51718,
          286,
          478,
          516,
          281,
          584,
          1412,
          13210,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 540.9,
        "id": 193,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 536.9,
        "temperature": 0,
        "text": " I'm going to write my data loaded function.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          2464,
          452,
          1412,
          13210,
          2445,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 544.62,
        "id": 194,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 540.9,
        "temperature": 0,
        "text": " And let me just look at where I'm drawing stuff.",
        "tokens": [
          50614,
          400,
          718,
          385,
          445,
          574,
          412,
          689,
          286,
          478,
          6316,
          1507,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 546.5799999999999,
        "id": 195,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 544.62,
        "temperature": 0,
        "text": " I'm going to grab all this drawing code,",
        "tokens": [
          50800,
          286,
          478,
          516,
          281,
          4444,
          439,
          341,
          6316,
          3089,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 548.38,
        "id": 196,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 546.5799999999999,
        "temperature": 0,
        "text": " bring it back up here.",
        "tokens": [
          50898,
          1565,
          309,
          646,
          493,
          510,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 549.86,
        "id": 197,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 548.38,
        "temperature": 0,
        "text": " Let me comment it out.",
        "tokens": [
          50988,
          961,
          385,
          2871,
          309,
          484,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 551.78,
        "id": 198,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 549.86,
        "temperature": 0,
        "text": " And let's actually look at what the data looks",
        "tokens": [
          51062,
          400,
          718,
          311,
          767,
          574,
          412,
          437,
          264,
          1412,
          1542,
          51158
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 555.9399999999999,
        "id": 199,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 551.78,
        "temperature": 0,
        "text": " like in the neural network model.",
        "tokens": [
          51158,
          411,
          294,
          264,
          18161,
          3209,
          2316,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 558.66,
        "id": 200,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 555.9399999999999,
        "temperature": 0,
        "text": " So I think I should be able to just console log the model's",
        "tokens": [
          51366,
          407,
          286,
          519,
          286,
          820,
          312,
          1075,
          281,
          445,
          11076,
          3565,
          264,
          2316,
          311,
          51502
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 561.02,
        "id": 201,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 558.66,
        "temperature": 0,
        "text": " data, I think.",
        "tokens": [
          51502,
          1412,
          11,
          286,
          519,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.25147841269509835,
        "compression_ratio": 1.7022222222222223,
        "end": 564.34,
        "id": 202,
        "no_speech_prob": 0.000034268399758730084,
        "seek": 53590,
        "start": 561.02,
        "temperature": 0,
        "text": " So this is what the ml5 data object looks like.",
        "tokens": [
          51620,
          407,
          341,
          307,
          437,
          264,
          23271,
          20,
          1412,
          2657,
          1542,
          411,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 569.0600000000001,
        "id": 203,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 564.34,
        "temperature": 0,
        "text": " And for me, the important bit here is under data, under raw.",
        "tokens": [
          50364,
          400,
          337,
          385,
          11,
          264,
          1021,
          857,
          510,
          307,
          833,
          1412,
          11,
          833,
          8936,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 574.62,
        "id": 204,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 569.0600000000001,
        "temperature": 0,
        "text": " This raw data is all of the actual xy coordinate",
        "tokens": [
          50600,
          639,
          8936,
          1412,
          307,
          439,
          295,
          264,
          3539,
          2031,
          88,
          15670,
          50878
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 577.7800000000001,
        "id": 205,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 574.62,
        "temperature": 0,
        "text": " with the target label.",
        "tokens": [
          50878,
          365,
          264,
          3779,
          7645,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 580.98,
        "id": 206,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 577.7800000000001,
        "temperature": 0,
        "text": " I can make a variable called data.",
        "tokens": [
          51036,
          286,
          393,
          652,
          257,
          7006,
          1219,
          1412,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 582.14,
        "id": 207,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 580.98,
        "temperature": 0,
        "text": " And I can iterate over it.",
        "tokens": [
          51196,
          400,
          286,
          393,
          44497,
          670,
          309,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 590.3000000000001,
        "id": 208,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 587.7800000000001,
        "temperature": 0,
        "text": " So here, I'm looking at the raw data,",
        "tokens": [
          51536,
          407,
          510,
          11,
          286,
          478,
          1237,
          412,
          264,
          8936,
          1412,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.22309975624084472,
        "compression_ratio": 1.563953488372093,
        "end": 592.34,
        "id": 209,
        "no_speech_prob": 0.00009170182602247223,
        "seek": 56434,
        "start": 590.3000000000001,
        "temperature": 0,
        "text": " iterating over every single element,",
        "tokens": [
          51662,
          17138,
          990,
          670,
          633,
          2167,
          4478,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 595.86,
        "id": 210,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 592.34,
        "temperature": 0,
        "text": " pulling out the x's into the inputs, the y's into the target.",
        "tokens": [
          50364,
          8407,
          484,
          264,
          2031,
          311,
          666,
          264,
          15743,
          11,
          264,
          288,
          311,
          666,
          264,
          3779,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 599.58,
        "id": 211,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 595.86,
        "temperature": 0,
        "text": " And then I can add the drawing code back in.",
        "tokens": [
          50540,
          400,
          550,
          286,
          393,
          909,
          264,
          6316,
          3089,
          646,
          294,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 606.14,
        "id": 212,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 599.58,
        "temperature": 0,
        "text": " Only here, I'm saying inputs.x, inputs.y,",
        "tokens": [
          50726,
          5686,
          510,
          11,
          286,
          478,
          1566,
          15743,
          13,
          87,
          11,
          15743,
          13,
          88,
          11,
          51054
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 608.26,
        "id": 213,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 606.14,
        "temperature": 0,
        "text": " and this is target.label.",
        "tokens": [
          51054,
          293,
          341,
          307,
          3779,
          13,
          75,
          18657,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 615.7800000000001,
        "id": 214,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 608.26,
        "temperature": 0,
        "text": " So I believe if I run it, aha, I figured out what my mistake is.",
        "tokens": [
          51160,
          407,
          286,
          1697,
          498,
          286,
          1190,
          309,
          11,
          47340,
          11,
          286,
          8932,
          484,
          437,
          452,
          6146,
          307,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 616.9000000000001,
        "id": 215,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 615.7800000000001,
        "temperature": 0,
        "text": " This is confusing.",
        "tokens": [
          51536,
          639,
          307,
          13181,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.22503931382123163,
        "compression_ratio": 1.5757575757575757,
        "end": 620.7800000000001,
        "id": 216,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 59234,
        "start": 616.9000000000001,
        "temperature": 0,
        "text": " Because in model, what I'm seeing here is model.data.",
        "tokens": [
          51592,
          1436,
          294,
          2316,
          11,
          437,
          286,
          478,
          2577,
          510,
          307,
          2316,
          13,
          67,
          3274,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 622.8199999999999,
        "id": 217,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 620.78,
        "temperature": 0,
        "text": " And I want to look at model.data.data.raw.",
        "tokens": [
          50364,
          400,
          286,
          528,
          281,
          574,
          412,
          2316,
          13,
          67,
          3274,
          13,
          67,
          3274,
          13,
          5131,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 630.1,
        "id": 218,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 628.5,
        "temperature": 0,
        "text": " This leads me to think that maybe it",
        "tokens": [
          50750,
          639,
          6689,
          385,
          281,
          519,
          300,
          1310,
          309,
          50830
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 632.18,
        "id": 219,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 630.1,
        "temperature": 0,
        "text": " would make sense to have something like a get data",
        "tokens": [
          50830,
          576,
          652,
          2020,
          281,
          362,
          746,
          411,
          257,
          483,
          1412,
          50934
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 634.3,
        "id": 220,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 632.18,
        "temperature": 0,
        "text": " function.",
        "tokens": [
          50934,
          2445,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 635.98,
        "id": 221,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 634.3,
        "temperature": 0,
        "text": " So that you could, because in many cases,",
        "tokens": [
          51040,
          407,
          300,
          291,
          727,
          11,
          570,
          294,
          867,
          3331,
          11,
          51124
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 637.98,
        "id": 222,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 635.98,
        "temperature": 0,
        "text": " you just want the raw data.",
        "tokens": [
          51124,
          291,
          445,
          528,
          264,
          8936,
          1412,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 639.78,
        "id": 223,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 637.98,
        "temperature": 0,
        "text": " ml5 is storing a lot of information",
        "tokens": [
          51224,
          23271,
          20,
          307,
          26085,
          257,
          688,
          295,
          1589,
          51314
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 642.3399999999999,
        "id": 224,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 639.78,
        "temperature": 0,
        "text": " about the data set additionally to help it",
        "tokens": [
          51314,
          466,
          264,
          1412,
          992,
          43181,
          281,
          854,
          309,
          51442
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 643.5,
        "id": 225,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 642.3399999999999,
        "temperature": 0,
        "text": " when it loads it later.",
        "tokens": [
          51442,
          562,
          309,
          12668,
          309,
          1780,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 646.9,
        "id": 226,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 643.5,
        "temperature": 0,
        "text": " But for looking at it again, it might be easier",
        "tokens": [
          51500,
          583,
          337,
          1237,
          412,
          309,
          797,
          11,
          309,
          1062,
          312,
          3571,
          51670
        ]
      },
      {
        "avg_logprob": -0.2921100366310995,
        "compression_ratio": 1.6963562753036436,
        "end": 648.8199999999999,
        "id": 227,
        "no_speech_prob": 0.00006205020326888189,
        "seek": 62078,
        "start": 646.9,
        "temperature": 0,
        "text": " just to have a function that just grabs that, rather than",
        "tokens": [
          51670,
          445,
          281,
          362,
          257,
          2445,
          300,
          445,
          30028,
          300,
          11,
          2831,
          813,
          51766
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 650.1400000000001,
        "id": 228,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 648.86,
        "temperature": 0,
        "text": " I'm saying data.data.raw.",
        "tokens": [
          50366,
          286,
          478,
          1566,
          1412,
          13,
          67,
          3274,
          13,
          5131,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 651.38,
        "id": 229,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 650.1400000000001,
        "temperature": 0,
        "text": " But take a look.",
        "tokens": [
          50430,
          583,
          747,
          257,
          574,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 653.0600000000001,
        "id": 230,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 651.38,
        "temperature": 0,
        "text": " Maybe by the time you're watching this,",
        "tokens": [
          50492,
          2704,
          538,
          264,
          565,
          291,
          434,
          1976,
          341,
          11,
          50576
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 654.94,
        "id": 231,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 653.0600000000001,
        "temperature": 0,
        "text": " this will have been added to the ml5 library.",
        "tokens": [
          50576,
          341,
          486,
          362,
          668,
          3869,
          281,
          264,
          23271,
          20,
          6405,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 656.9000000000001,
        "id": 232,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 654.94,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          50670,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 657.46,
        "id": 233,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 656.9000000000001,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50768,
          821,
          321,
          352,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 658.46,
        "id": 234,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 657.46,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50796,
          7951,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 661.2600000000001,
        "id": 235,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 658.46,
        "temperature": 0,
        "text": " So it drew all the circles, but I have the label wrong.",
        "tokens": [
          50846,
          407,
          309,
          12804,
          439,
          264,
          13040,
          11,
          457,
          286,
          362,
          264,
          7645,
          2085,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 663.58,
        "id": 236,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 661.2600000000001,
        "temperature": 0,
        "text": " Why do I have the label wrong?",
        "tokens": [
          50986,
          1545,
          360,
          286,
          362,
          264,
          7645,
          2085,
          30,
          51102
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 664.34,
        "id": 237,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 663.58,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51102,
          21726,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 667.3000000000001,
        "id": 238,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 664.34,
        "temperature": 0,
        "text": " I had copy pasted mouse x, mouse y in there,",
        "tokens": [
          51140,
          286,
          632,
          5055,
          1791,
          292,
          9719,
          2031,
          11,
          9719,
          288,
          294,
          456,
          11,
          51288
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 670.0600000000001,
        "id": 239,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 667.3000000000001,
        "temperature": 0,
        "text": " but I've got to get the actual xy coordinate.",
        "tokens": [
          51288,
          457,
          286,
          600,
          658,
          281,
          483,
          264,
          3539,
          2031,
          88,
          15670,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 671.5400000000001,
        "id": 240,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 670.0600000000001,
        "temperature": 0,
        "text": " Always making silly mistakes.",
        "tokens": [
          51426,
          11270,
          1455,
          11774,
          8038,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 672.74,
        "id": 241,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 671.5400000000001,
        "temperature": 0,
        "text": " Let's run this again.",
        "tokens": [
          51500,
          961,
          311,
          1190,
          341,
          797,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 673.3800000000001,
        "id": 242,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 672.74,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51560,
          400,
          456,
          321,
          352,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 674.86,
        "id": 243,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 673.3800000000001,
        "temperature": 0,
        "text": " Now it's loading that data.",
        "tokens": [
          51592,
          823,
          309,
          311,
          15114,
          300,
          1412,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.2668354769787156,
        "compression_ratio": 1.683673469387755,
        "end": 677.0600000000001,
        "id": 244,
        "no_speech_prob": 0.000146531019709073,
        "seek": 64882,
        "start": 674.86,
        "temperature": 0,
        "text": " And maybe actually what I want to do also,",
        "tokens": [
          51666,
          400,
          1310,
          767,
          437,
          286,
          528,
          281,
          360,
          611,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 681.06,
        "id": 245,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 677.06,
        "temperature": 0,
        "text": " once the data is loaded, is just automatically call train.",
        "tokens": [
          50364,
          1564,
          264,
          1412,
          307,
          13210,
          11,
          307,
          445,
          6772,
          818,
          3847,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 687.6999999999999,
        "id": 246,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 683.9399999999999,
        "temperature": 0,
        "text": " So I could do all this stuff right here.",
        "tokens": [
          50708,
          407,
          286,
          727,
          360,
          439,
          341,
          1507,
          558,
          510,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 690.0999999999999,
        "id": 247,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 687.6999999999999,
        "temperature": 0,
        "text": " I could run the sketch, and it's immediately",
        "tokens": [
          50896,
          286,
          727,
          1190,
          264,
          12325,
          11,
          293,
          309,
          311,
          4258,
          51016
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 691.3399999999999,
        "id": 248,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 690.0999999999999,
        "temperature": 0,
        "text": " going to train the model.",
        "tokens": [
          51016,
          516,
          281,
          3847,
          264,
          2316,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 695.06,
        "id": 249,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 691.3399999999999,
        "temperature": 0,
        "text": " And I'm ready for inference.",
        "tokens": [
          51078,
          400,
          286,
          478,
          1919,
          337,
          38253,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 702.8599999999999,
        "id": 250,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 701.2199999999999,
        "temperature": 0,
        "text": " Now that this is working, I might",
        "tokens": [
          51572,
          823,
          300,
          341,
          307,
          1364,
          11,
          286,
          1062,
          51654
        ]
      },
      {
        "avg_logprob": -0.27683835416226776,
        "compression_ratio": 1.461111111111111,
        "end": 704.66,
        "id": 251,
        "no_speech_prob": 0.00024156560539267957,
        "seek": 67706,
        "start": 702.8599999999999,
        "temperature": 0,
        "text": " offer an exercise suggestion.",
        "tokens": [
          51654,
          2626,
          364,
          5380,
          16541,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 707.86,
        "id": 252,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 704.74,
        "temperature": 0,
        "text": " And I will try to remember to, in the video's description,",
        "tokens": [
          50368,
          400,
          286,
          486,
          853,
          281,
          1604,
          281,
          11,
          294,
          264,
          960,
          311,
          3855,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 710.9,
        "id": 253,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 707.86,
        "temperature": 0,
        "text": " link to code that does this, in addition to just the code",
        "tokens": [
          50524,
          2113,
          281,
          3089,
          300,
          775,
          341,
          11,
          294,
          4500,
          281,
          445,
          264,
          3089,
          50676
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 711.78,
        "id": 254,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 710.9,
        "temperature": 0,
        "text": " that's here right now.",
        "tokens": [
          50676,
          300,
          311,
          510,
          558,
          586,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 713.5799999999999,
        "id": 255,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 711.78,
        "temperature": 0,
        "text": " So remind me in the comments if I haven't.",
        "tokens": [
          50720,
          407,
          4160,
          385,
          294,
          264,
          3053,
          498,
          286,
          2378,
          380,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 715.78,
        "id": 256,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 713.5799999999999,
        "temperature": 0,
        "text": " But how could you take this example, which",
        "tokens": [
          50810,
          583,
          577,
          727,
          291,
          747,
          341,
          1365,
          11,
          597,
          50920
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 718.3,
        "id": 257,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 715.78,
        "temperature": 0,
        "text": " now loads a data set and immediately trains the model,",
        "tokens": [
          50920,
          586,
          12668,
          257,
          1412,
          992,
          293,
          4258,
          16329,
          264,
          2316,
          11,
          51046
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 722.18,
        "id": 258,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 718.3,
        "temperature": 0,
        "text": " to allow you to change the state back to data collection?",
        "tokens": [
          51046,
          281,
          2089,
          291,
          281,
          1319,
          264,
          1785,
          646,
          281,
          1412,
          5765,
          30,
          51240
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 723.74,
        "id": 259,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 722.18,
        "temperature": 0,
        "text": " So I train the model.",
        "tokens": [
          51240,
          407,
          286,
          3847,
          264,
          2316,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 726.14,
        "id": 260,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 723.74,
        "temperature": 0,
        "text": " Then I want to add some more data, retrain the model,",
        "tokens": [
          51318,
          1396,
          286,
          528,
          281,
          909,
          512,
          544,
          1412,
          11,
          1533,
          7146,
          264,
          2316,
          11,
          51438
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 727.06,
        "id": 261,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 726.14,
        "temperature": 0,
        "text": " resave the data.",
        "tokens": [
          51438,
          725,
          946,
          264,
          1412,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 728.86,
        "id": 262,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 727.06,
        "temperature": 0,
        "text": " How could you have a workflow that",
        "tokens": [
          51484,
          1012,
          727,
          291,
          362,
          257,
          20993,
          300,
          51574
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 732.06,
        "id": 263,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 728.86,
        "temperature": 0,
        "text": " allows you to load the data you previously had",
        "tokens": [
          51574,
          4045,
          291,
          281,
          3677,
          264,
          1412,
          291,
          8046,
          632,
          51734
        ]
      },
      {
        "avg_logprob": -0.2144329046747487,
        "compression_ratio": 1.8273615635179152,
        "end": 734.4599999999999,
        "id": 264,
        "no_speech_prob": 0.003538028569892049,
        "seek": 70466,
        "start": 732.06,
        "temperature": 0,
        "text": " and add new data, remove some of the data even?",
        "tokens": [
          51734,
          293,
          909,
          777,
          1412,
          11,
          4159,
          512,
          295,
          264,
          1412,
          754,
          30,
          51854
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 735.86,
        "id": 265,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 735.26,
        "temperature": 0,
        "text": " How would you do that?",
        "tokens": [
          50404,
          1012,
          576,
          291,
          360,
          300,
          30,
          50434
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 737.5400000000001,
        "id": 266,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 735.86,
        "temperature": 0,
        "text": " And retrain the model.",
        "tokens": [
          50434,
          400,
          1533,
          7146,
          264,
          2316,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 741.9000000000001,
        "id": 267,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 737.5400000000001,
        "temperature": 0,
        "text": " And once we are there, and we've got this workflow where",
        "tokens": [
          50518,
          400,
          1564,
          321,
          366,
          456,
          11,
          293,
          321,
          600,
          658,
          341,
          20993,
          689,
          50736
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 744.34,
        "id": 268,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 741.9000000000001,
        "temperature": 0,
        "text": " I can collect data, train, change parameters,",
        "tokens": [
          50736,
          286,
          393,
          2500,
          1412,
          11,
          3847,
          11,
          1319,
          9834,
          11,
          50858
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 746.94,
        "id": 269,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 744.34,
        "temperature": 0,
        "text": " train again, recollect, all that kind of stuff,",
        "tokens": [
          50858,
          3847,
          797,
          11,
          39495,
          557,
          11,
          439,
          300,
          733,
          295,
          1507,
          11,
          50988
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 748.5400000000001,
        "id": 270,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 746.94,
        "temperature": 0,
        "text": " I'm ready for the next step.",
        "tokens": [
          50988,
          286,
          478,
          1919,
          337,
          264,
          958,
          1823,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 749.0400000000001,
        "id": 271,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 748.5400000000001,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51068,
          1079,
          13,
          51093
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 751.9000000000001,
        "id": 272,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 749.0400000000001,
        "temperature": 0,
        "text": " Definitely want to ring the bell for this,",
        "tokens": [
          51093,
          12151,
          528,
          281,
          4875,
          264,
          4549,
          337,
          341,
          11,
          51236
        ]
      },
      {
        "avg_logprob": -0.29198550174110816,
        "compression_ratio": 1.5480769230769231,
        "end": 755.38,
        "id": 273,
        "no_speech_prob": 0.000048325586249120533,
        "seek": 73446,
        "start": 751.9000000000001,
        "temperature": 0,
        "text": " which is actually save the trained model itself.",
        "tokens": [
          51236,
          597,
          307,
          767,
          3155,
          264,
          8895,
          2316,
          2564,
          13,
          51410
        ]
      }
    ],
    "transcription": " Hello, and welcome to another ML5 neural network video tutorial. So I am following up on what I did in this previous video, where I built this example. This example has this interaction where you click the mouse all over this canvas and press keys to assign each xy point a label, CDE. And I added a bunch of notes since the previous video, so I have the full scale CDEFGAB. Then I train the model with the inputs being the xy of all these points and the target being the actual label. And once the model is trained, it can make guesses. So in theory, I just collected this data set, trained the model. When I click into it, when I click over here, I should hear the musical note D. I should hear the musical note E, G, A. And in between, it's sort of interesting to see what I get. But it works as expected. But I ran into a pretty significant problem while working on this. Because once I've collected the data set and trained the model, if I had a bug in the code or something I needed to fix or I wanted to try a different parameter, I have to stop the sketch and run it again and sit there and do this. This highly manual process of clicking, clicking, clicking to collect the data set. So in this video, I want to look at saving the data. And I also want to look at saving the model, which is those are two pretty different things. It might seem like the same idea. Oh, I want to save the data. I want to save the model. Why would I do one versus the other? Let's pause for a second and examine all the steps of a machine learning project and where we might want to save the data versus save the model and why. Step one, collect the data. Now, this could be a really big, complicated step. But in my scenario, in my example, it's just clicking the mouse a whole bunch of times and pressing keys on the keyboard. Step two, train the model. Once the model has been trained, the idea is to use that model in some scenario. So that we can call step three, deploy the model or prediction inference. So now the question is, where along the way might you want to save the state of what you're doing? So in the most traditional machine learning sense, once you've done all of this and your model is trained, you don't ever need to look back. You've got a trained model. You can save that model. So right here in between steps two and three is a point where we might want to save the model. If we're done and our model is exactly the way we want it and we're ready to just use it in a project. However, you might want to try training the model a variety of different ways. And this is where you might want to in between these two steps save the data. We also might collect a lot of data. I want to take a break, reload that data, collect more data. There's a lot of different reasons why we might want to stop in between step one and two and save where we are. And the functions in the ml5 neural network class that we want to use are save data and save. So just save is saving the model. Save data is saving the data. There are also functions for loading it back, which we'll look at. Load data and load. Let's begin by just looking at save data. So in this particular example, all of the interaction happens with key presses. Certainly, as I've mentioned before, you might want to think about a more thoughtful interface for doing all this work. But for me, I'm just going to add another key press S for save data. So I'm going to say else if the key is S. Then I'm going to call model save data. I can look at more about how the save data function works by looking at the ml5 website. We can see there's two optional arguments. So one argument is a file name, which I want to use because I want to set the file name. It'll just pick a date if you don't. And then a callback to know that it's done. I don't actually really need to worry about that because I'll know that it's done when the file is there and downloaded to the downloads directory. I'm going to give it the name mouse notes and run the sketch and collect some data. So I'm just going to do a little bit just to make sure it's working. So now I can hit S. And look, a file has been downloaded. I can take a look at this file in Visual Studio Code. And here's what the file looks like. So I've got a data property with an array that has all the data in it. X, Y's with a label. X, Y with a label. And if I reformat the JSON, you can actually see it here. And it's much more legible what's going on. So this is all of the data that I've collected. Not very much data, but there it is. So now that I've done that, I might as well take the time to collect a lot more data knowing that I can save it. So I've methodically collected a large data set. Now I'm going to press S to save it. And here's what it looks like. Almost 400 data samples. Let's see how it performs. I'm going to train the model. Try doing some inference. And it works pretty well. So now the next thing that I want to try to do is hit Stop and run the sketch again, but have all of my data reappear. Let's see if I can make that happen. Now, instead of just creating the neural network, I can create the neural network and load data into it. And that's as easy as saying model load data mouse notes dot JSON. The only thing here is that you have to remember that I'm working in client-side JavaScript only. So if I run this right now, it's giving me this nice error here because it's looking for a JSON object with an array called data. But it can't find it because that JSON file doesn't exist. It doesn't exist because I downloaded it to the downloads directory. And so for my p5 sketch to be able to access it, I have to manually upload it back to the p5 web editor. If I were writing my own server, maybe with Node.js, I could do something where I could save the data and have it reload back automatically. But that's another example for another time. Let me do add file and drag mouse notes JSON in here. Now we can see that that file is part of my p5 sketch. And it should be able to run the sketch now. All right, I think the data was loaded. I don't see it because I'm not drawing it. So this might be something I want to add in a moment, be able to draw the data that it's loaded. But in theory, there's no reason why I couldn't train the model. All right, the model's trained. And you can see, I'm not seeing the data. I'm not seeing those clusters. But it's clearly been trained based on that data. To show you how this can be useful, one thing that I might want to do is change some property that affects the training process so I could try it multiple times. And an obvious one might be to try learning rate. So let's say I make a really smaller learning rate, 0.01, and I run the sketch again. I've got to click in here so that my key press gets activated. So I'm going to add one more piece of data and hit T. So you can see, with a small learning rate, the loss is going down very, very, very, very slowly. So in this case, having a small learning rate is not super helpful. But I can say, OK, that learning rate wasn't good. Let me try a much larger learning rate, like 0.5, run it again, hit T for train. And then, ah, you can see with this high learning rate, that loss is going down really, really quickly. Now, I don't mean to suggest here that universally a high learning rate is better than a low learning rate. There's a lot of it depends here. But just to show you how you can now retrain the model changing all of the different kinds of options, and you could look at the ml5 neural network documentation and see what other kind of options you might want to play around with or change. You might be finding this example a little bit tricky to follow because you can't actually see the data. So let's add that feature of, once I've loaded the data, also drawing it to the canvas. So in this case, having a callback for when the data is ready would be very useful. I'm going to say data loaded. I'm going to write my data loaded function. And let me just look at where I'm drawing stuff. I'm going to grab all this drawing code, bring it back up here. Let me comment it out. And let's actually look at what the data looks like in the neural network model. So I think I should be able to just console log the model's data, I think. So this is what the ml5 data object looks like. And for me, the important bit here is under data, under raw. This raw data is all of the actual xy coordinate with the target label. I can make a variable called data. And I can iterate over it. So here, I'm looking at the raw data, iterating over every single element, pulling out the x's into the inputs, the y's into the target. And then I can add the drawing code back in. Only here, I'm saying inputs.x, inputs.y, and this is target.label. So I believe if I run it, aha, I figured out what my mistake is. This is confusing. Because in model, what I'm seeing here is model.data. And I want to look at model.data.data.raw. This leads me to think that maybe it would make sense to have something like a get data function. So that you could, because in many cases, you just want the raw data. ml5 is storing a lot of information about the data set additionally to help it when it loads it later. But for looking at it again, it might be easier just to have a function that just grabs that, rather than I'm saying data.data.raw. But take a look. Maybe by the time you're watching this, this will have been added to the ml5 library. Let's see if this works. There we go. Ooh. So it drew all the circles, but I have the label wrong. Why do I have the label wrong? Oops. I had copy pasted mouse x, mouse y in there, but I've got to get the actual xy coordinate. Always making silly mistakes. Let's run this again. And there we go. Now it's loading that data. And maybe actually what I want to do also, once the data is loaded, is just automatically call train. So I could do all this stuff right here. I could run the sketch, and it's immediately going to train the model. And I'm ready for inference. Now that this is working, I might offer an exercise suggestion. And I will try to remember to, in the video's description, link to code that does this, in addition to just the code that's here right now. So remind me in the comments if I haven't. But how could you take this example, which now loads a data set and immediately trains the model, to allow you to change the state back to data collection? So I train the model. Then I want to add some more data, retrain the model, resave the data. How could you have a workflow that allows you to load the data you previously had and add new data, remove some of the data even? How would you do that? And retrain the model. And once we are there, and we've got this workflow where I can collect data, train, change parameters, train again, recollect, all that kind of stuff, I'm ready for the next step. Yes. Definitely want to ring the bell for this, which is actually save the trained model itself.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:34.089313Z",
  "started_at": "2023-09-26T21:15:08.295359Z",
  "completed_at": "2023-09-26T21:18:45.02064Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=q6cwxORPDo8",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 216.725281
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/am7mzpbblit5ht2gtn4ftpal24/cancel",
    "get": "https://api.replicate.com/v1/predictions/am7mzpbblit5ht2gtn4ftpal24"
  }
}