{
  "id": "eclwzcbbx44ynze3quziw4w3ra",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/HRBS_OtQupM.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/414678 [00:00<?, ?frames/s]\n  1%|          | 2700/414678 [00:08<21:07, 325.03frames/s]\n  1%|▏         | 5500/414678 [00:15<19:23, 351.77frames/s]\n  2%|▏         | 8300/414678 [00:20<15:46, 429.38frames/s]\n  3%|▎         | 11300/414678 [00:23<11:52, 566.39frames/s]\n  3%|▎         | 14300/414678 [00:24<08:20, 800.50frames/s]\n  3%|▎         | 14300/414678 [00:43<08:20, 800.50frames/s]\n  4%|▍         | 17100/414678 [00:48<24:16, 272.93frames/s]\n  5%|▍         | 19900/414678 [00:55<21:25, 307.04frames/s]\n  5%|▌         | 22800/414678 [01:01<18:39, 350.11frames/s]\n  6%|▌         | 25500/414678 [01:06<16:53, 384.02frames/s]\n  7%|▋         | 27800/414678 [01:11<16:21, 394.33frames/s]\n  7%|▋         | 30600/414678 [01:18<15:30, 412.66frames/s]\n  8%|▊         | 33500/414678 [01:25<15:49, 401.33frames/s]\n  9%|▊         | 36100/414678 [01:33<16:19, 386.61frames/s]\n  9%|▉         | 39000/414678 [01:40<16:07, 388.25frames/s]\n 10%|█         | 41800/414678 [01:47<15:52, 391.57frames/s]\n 11%|█         | 44700/414678 [01:55<16:02, 384.37frames/s]\n 11%|█▏        | 47300/414678 [02:03<16:43, 366.07frames/s]\n 12%|█▏        | 50100/414678 [02:10<16:25, 369.75frames/s]\n 13%|█▎        | 52800/414678 [02:17<15:44, 383.25frames/s]\n 13%|█▎        | 55500/414678 [02:25<16:20, 366.37frames/s]\n 14%|█▍        | 58400/414678 [02:32<16:02, 370.02frames/s]\n 15%|█▍        | 61300/414678 [02:38<14:47, 398.10frames/s]\n 15%|█▌        | 63900/414678 [02:44<13:51, 421.91frames/s]\n 16%|█▌        | 66700/414678 [02:48<12:30, 463.69frames/s]\n 17%|█▋        | 69200/414678 [02:54<12:47, 450.37frames/s]\n 17%|█▋        | 71900/414678 [02:59<12:01, 475.24frames/s]\n 18%|█▊        | 74400/414678 [03:05<11:55, 475.82frames/s]\n 19%|█▊        | 77200/414678 [03:09<11:11, 502.92frames/s]\n 19%|█▉        | 80000/414678 [03:14<10:37, 525.15frames/s]\n 20%|█▉        | 82400/414678 [03:18<10:09, 545.09frames/s]\n 21%|██        | 85200/414678 [03:23<10:07, 542.02frames/s]\n 21%|██        | 88100/414678 [03:28<09:43, 559.80frames/s]\n 22%|██▏       | 90900/414678 [03:34<09:55, 543.84frames/s]\n 23%|██▎       | 93800/414678 [03:39<10:04, 530.87frames/s]\n 23%|██▎       | 96400/414678 [03:44<09:57, 532.46frames/s]\n 24%|██▍       | 99100/414678 [03:50<10:03, 523.21frames/s]\n 25%|██▍       | 101800/414678 [03:56<10:24, 500.95frames/s]\n 25%|██▌       | 104400/414678 [03:59<09:28, 545.67frames/s]\n 26%|██▌       | 107200/414678 [04:05<09:40, 530.11frames/s]\n 27%|██▋       | 110100/414678 [04:10<09:16, 547.12frames/s]\n 27%|██▋       | 112800/414678 [04:14<08:54, 564.33frames/s]\n 28%|██▊       | 115400/414678 [04:18<08:27, 589.89frames/s]\n 28%|██▊       | 118100/414678 [04:23<08:31, 579.33frames/s]\n 29%|██▉       | 120900/414678 [04:27<08:04, 606.46frames/s]\n 30%|██▉       | 123400/414678 [04:31<07:55, 612.04frames/s]\n 30%|███       | 126300/414678 [04:38<09:01, 532.15frames/s]\n 31%|███       | 129100/414678 [04:46<10:23, 458.16frames/s]\n 32%|███▏      | 131700/414678 [04:54<11:26, 412.30frames/s]\n 32%|███▏      | 134100/414678 [05:01<11:43, 399.04frames/s]\n 33%|███▎      | 136600/414678 [05:06<11:09, 415.06frames/s]\n 34%|███▎      | 139400/414678 [05:13<11:19, 405.05frames/s]\n 34%|███▍      | 142000/414678 [05:20<11:07, 408.22frames/s]\n 35%|███▍      | 144800/414678 [05:25<10:22, 433.46frames/s]\n 36%|███▌      | 147700/414678 [05:34<11:29, 387.20frames/s]\n 36%|███▌      | 150300/414678 [05:42<11:49, 372.80frames/s]\n 37%|███▋      | 153000/414678 [05:52<12:55, 337.54frames/s]\n 38%|███▊      | 155600/414678 [06:01<13:19, 323.86frames/s]\n 38%|███▊      | 158200/414678 [06:07<12:37, 338.58frames/s]\n 39%|███▉      | 160800/414678 [06:16<12:44, 332.07frames/s]\n 39%|███▉      | 163300/414678 [06:24<13:00, 322.27frames/s]\n 40%|████      | 166000/414678 [06:33<13:05, 316.62frames/s]\n 41%|████      | 168900/414678 [06:38<11:19, 361.62frames/s]\n 41%|████▏     | 171600/414678 [06:45<10:53, 371.77frames/s]\n 42%|████▏     | 174500/414678 [06:52<10:29, 381.53frames/s]\n 43%|████▎     | 177400/414678 [07:01<10:36, 372.70frames/s]\n 43%|████▎     | 180300/414678 [07:08<10:16, 379.97frames/s]\n 44%|████▍     | 183200/414678 [07:15<10:10, 379.20frames/s]\n 45%|████▍     | 185700/414678 [07:23<10:21, 368.46frames/s]\n 45%|████▌     | 188300/414678 [07:28<09:30, 396.99frames/s]\n 46%|████▌     | 191100/414678 [07:33<08:28, 439.59frames/s]\n 47%|████▋     | 194000/414678 [07:38<07:44, 474.79frames/s]\n 47%|████▋     | 196900/414678 [07:46<08:26, 430.36frames/s]\n 48%|████▊     | 199700/414678 [07:52<07:58, 448.84frames/s]\n 49%|████▉     | 202300/414678 [07:56<07:23, 478.74frames/s]\n 49%|████▉     | 205100/414678 [08:02<07:11, 485.51frames/s]\n 50%|█████     | 207900/414678 [08:08<07:21, 468.24frames/s]\n 51%|█████     | 210600/414678 [08:14<07:23, 460.56frames/s]\n 51%|█████▏    | 213200/414678 [08:20<07:18, 459.27frames/s]\n 52%|█████▏    | 215900/414678 [08:25<06:48, 486.20frames/s]\n 53%|█████▎    | 218700/414678 [08:32<07:17, 448.08frames/s]\n 53%|█████▎    | 221500/414678 [08:39<07:15, 444.03frames/s]\n 54%|█████▍    | 224400/414678 [08:44<06:49, 465.04frames/s]\n 55%|█████▍    | 227200/414678 [08:51<06:53, 452.90frames/s]\n 55%|█████▌    | 230000/414678 [08:55<06:14, 493.61frames/s]\n 56%|█████▌    | 232700/414678 [09:02<06:31, 464.97frames/s]\n 57%|█████▋    | 235500/414678 [09:08<06:33, 454.96frames/s]\n 57%|█████▋    | 238000/414678 [09:12<05:59, 491.37frames/s]\n 58%|█████▊    | 240900/414678 [09:18<05:52, 492.60frames/s]\n 59%|█████▊    | 243600/414678 [09:23<05:29, 519.76frames/s]\n 59%|█████▉    | 246100/414678 [09:27<05:09, 544.44frames/s]\n 60%|█████▉    | 248700/414678 [09:31<04:53, 565.98frames/s]\n 61%|██████    | 251600/414678 [09:35<04:29, 604.52frames/s]\n 61%|██████▏   | 254400/414678 [09:40<04:27, 599.02frames/s]\n 62%|██████▏   | 257200/414678 [09:44<04:07, 637.08frames/s]\n 63%|██████▎   | 260200/414678 [09:50<04:29, 573.76frames/s]\n 63%|██████▎   | 262900/414678 [09:53<03:52, 652.64frames/s]\n 64%|██████▍   | 265700/414678 [10:00<04:29, 553.32frames/s]\n 65%|██████▍   | 268600/414678 [10:06<04:47, 508.25frames/s]\n 65%|██████▌   | 270900/414678 [10:12<05:00, 478.29frames/s]\n 66%|██████▌   | 273700/414678 [10:17<04:47, 491.18frames/s]\n 67%|██████▋   | 276200/414678 [10:22<04:39, 495.48frames/s]\n 67%|██████▋   | 278700/414678 [10:27<04:26, 511.03frames/s]\n 68%|██████▊   | 281600/414678 [10:33<04:27, 498.38frames/s]\n 69%|██████▊   | 284500/414678 [10:38<04:14, 511.47frames/s]\n 69%|██████▉   | 287300/414678 [10:45<04:31, 469.33frames/s]\n 70%|██████▉   | 289800/414678 [10:51<04:29, 463.88frames/s]\n 70%|███████   | 292100/414678 [10:55<04:16, 477.50frames/s]\n 71%|███████   | 294600/414678 [10:59<03:55, 510.49frames/s]\n 72%|███████▏  | 297200/414678 [11:05<03:56, 496.42frames/s]\n 72%|███████▏  | 299900/414678 [11:09<03:36, 530.08frames/s]\n 73%|███████▎  | 302600/414678 [11:14<03:26, 541.76frames/s]\n 74%|███████▎  | 305400/414678 [11:19<03:22, 540.24frames/s]\n 74%|███████▍  | 308200/414678 [11:24<03:13, 550.02frames/s]\n 75%|███████▌  | 311100/414678 [11:30<03:21, 514.42frames/s]\n 76%|███████▌  | 313600/414678 [11:35<03:16, 514.25frames/s]\n 76%|███████▋  | 316400/414678 [11:39<02:56, 557.37frames/s]\n 77%|███████▋  | 319100/414678 [11:46<03:09, 505.08frames/s]\n 78%|███████▊  | 321900/414678 [11:50<02:47, 552.48frames/s]\n 78%|███████▊  | 324700/414678 [11:57<02:59, 501.70frames/s]\n 79%|███████▉  | 327400/414678 [12:02<02:49, 513.69frames/s]\n 80%|███████▉  | 329700/414678 [12:07<02:49, 501.51frames/s]\n 80%|████████  | 332500/414678 [12:11<02:37, 520.15frames/s]\n 81%|████████  | 335300/414678 [12:17<02:35, 509.40frames/s]\n 82%|████████▏ | 338000/414678 [12:24<02:44, 467.09frames/s]\n 82%|████████▏ | 340900/414678 [12:30<02:34, 478.49frames/s]\n 83%|████████▎ | 343700/414678 [12:37<02:35, 455.97frames/s]\n 83%|████████▎ | 345900/414678 [12:41<02:23, 479.33frames/s]\n 84%|████████▍ | 348600/414678 [12:44<01:58, 558.01frames/s]\n 85%|████████▍ | 351100/414678 [12:49<02:02, 519.14frames/s]\n 85%|████████▌ | 353900/414678 [12:56<02:03, 494.10frames/s]\n 86%|████████▌ | 356600/414678 [13:01<01:54, 506.99frames/s]\n 87%|████████▋ | 359400/414678 [13:05<01:42, 540.28frames/s]\n 87%|████████▋ | 362100/414678 [13:11<01:41, 518.34frames/s]\n 88%|████████▊ | 365000/414678 [13:18<01:43, 481.93frames/s]\n 89%|████████▊ | 367800/414678 [13:23<01:35, 489.27frames/s]\n 89%|████████▉ | 370400/414678 [13:30<01:37, 453.53frames/s]\n 90%|████████▉ | 373100/414678 [13:38<01:42, 406.14frames/s]\n 91%|█████████ | 375600/414678 [13:47<01:47, 363.92frames/s]\n 91%|█████████ | 378100/414678 [13:53<01:37, 374.47frames/s]\n 92%|█████████▏| 381000/414678 [14:03<01:36, 349.10frames/s]\n 93%|█████████▎| 383700/414678 [14:11<01:30, 341.43frames/s]\n 93%|█████████▎| 386500/414678 [14:20<01:24, 332.29frames/s]\n 94%|█████████▍| 389100/414678 [14:27<01:14, 341.90frames/s]\n 95%|█████████▍| 391900/414678 [14:34<01:03, 357.33frames/s]\n 95%|█████████▌| 394300/414678 [14:40<00:56, 362.82frames/s]\n 96%|█████████▌| 397000/414678 [14:46<00:45, 387.94frames/s]\n 96%|█████████▋| 399600/414678 [14:52<00:37, 398.07frames/s]\n 97%|█████████▋| 402300/414678 [14:59<00:30, 404.94frames/s]\n 97%|█████████▋| 402800/414678 [15:01<00:30, 383.56frames/s]\n 97%|█████████▋| 404200/414678 [15:04<00:26, 392.06frames/s]\n 98%|█████████▊| 407200/414678 [15:05<00:11, 625.24frames/s]\n 99%|█████████▉| 410200/414678 [15:06<00:04, 911.38frames/s]\n99%|█████████▉| 411678/414678 [15:08<00:03, 874.35frames/s]\n99%|█████████▉| 411678/414678 [15:08<00:06, 453.36frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 6,
        "id": 0,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, I think I am live. Welcome to another live stream.",
        "tokens": [
          50364,
          2425,
          11,
          286,
          519,
          286,
          669,
          1621,
          13,
          4027,
          281,
          1071,
          1621,
          4309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 9,
        "id": 1,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 6,
        "temperature": 0,
        "text": " A little bit of some, as always, technical difficulties.",
        "tokens": [
          50664,
          316,
          707,
          857,
          295,
          512,
          11,
          382,
          1009,
          11,
          6191,
          14399,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 12,
        "id": 2,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 9,
        "temperature": 0,
        "text": " Welcome, my name is Dan. I see that I'm here.",
        "tokens": [
          50814,
          4027,
          11,
          452,
          1315,
          307,
          3394,
          13,
          286,
          536,
          300,
          286,
          478,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 15,
        "id": 3,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 12,
        "temperature": 0,
        "text": " Let me know, oops, I've got to turn my volume off here.",
        "tokens": [
          50964,
          961,
          385,
          458,
          11,
          34166,
          11,
          286,
          600,
          658,
          281,
          1261,
          452,
          5523,
          766,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 19,
        "id": 4,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 15,
        "temperature": 0,
        "text": " Let me know if you can hear and see me okay.",
        "tokens": [
          51114,
          961,
          385,
          458,
          498,
          291,
          393,
          1568,
          293,
          536,
          385,
          1392,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 21,
        "id": 5,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 19,
        "temperature": 0,
        "text": " We're live for another session.",
        "tokens": [
          51314,
          492,
          434,
          1621,
          337,
          1071,
          5481,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 24,
        "id": 6,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 21,
        "temperature": 0,
        "text": " Now I have something to admit, a bunch of things to admit, which is that",
        "tokens": [
          51414,
          823,
          286,
          362,
          746,
          281,
          9796,
          11,
          257,
          3840,
          295,
          721,
          281,
          9796,
          11,
          597,
          307,
          300,
          51564
        ]
      },
      {
        "avg_logprob": -0.2674173087127938,
        "compression_ratio": 1.6181102362204725,
        "end": 27,
        "id": 7,
        "no_speech_prob": 0.22767235338687897,
        "seek": 0,
        "start": 24,
        "temperature": 0,
        "text": " the whole last week has been kind of a blur.",
        "tokens": [
          51564,
          264,
          1379,
          1036,
          1243,
          575,
          668,
          733,
          295,
          257,
          14257,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 31,
        "id": 8,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 27,
        "temperature": 0,
        "text": " A lot of things have been happening in this country.",
        "tokens": [
          50364,
          316,
          688,
          295,
          721,
          362,
          668,
          2737,
          294,
          341,
          1941,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 34,
        "id": 9,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 31,
        "temperature": 0,
        "text": " I missed last week, even doing a live stream.",
        "tokens": [
          50564,
          286,
          6721,
          1036,
          1243,
          11,
          754,
          884,
          257,
          1621,
          4309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 41,
        "id": 10,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 34,
        "temperature": 0,
        "text": " Things were very busy with my other job, which is teaching classes at NYU.",
        "tokens": [
          50714,
          9514,
          645,
          588,
          5856,
          365,
          452,
          661,
          1691,
          11,
          597,
          307,
          4571,
          5359,
          412,
          42682,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 44,
        "id": 11,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 41,
        "temperature": 0,
        "text": " So, and today I'm in a bit of a tight schedule.",
        "tokens": [
          51064,
          407,
          11,
          293,
          965,
          286,
          478,
          294,
          257,
          857,
          295,
          257,
          4524,
          7567,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 49,
        "id": 12,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 44,
        "temperature": 0,
        "text": " It's 10 of 2 and I only have currently until 3 p.m. Eastern time.",
        "tokens": [
          51214,
          467,
          311,
          1266,
          295,
          568,
          293,
          286,
          787,
          362,
          4362,
          1826,
          805,
          280,
          13,
          76,
          13,
          12901,
          565,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 52,
        "id": 13,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 49,
        "temperature": 0,
        "text": " Oh, lots of noise.",
        "tokens": [
          51464,
          876,
          11,
          3195,
          295,
          5658,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.25605109243681934,
        "compression_ratio": 1.4273127753303965,
        "end": 55,
        "id": 14,
        "no_speech_prob": 0.03156712278723717,
        "seek": 2700,
        "start": 52,
        "temperature": 0,
        "text": " Okay, okay, okay.",
        "tokens": [
          51614,
          1033,
          11,
          1392,
          11,
          1392,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 60,
        "id": 15,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 55,
        "temperature": 0,
        "text": " Okay, so far this is a failure with the mic glitching.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          1400,
          341,
          307,
          257,
          7763,
          365,
          264,
          3123,
          23552,
          278,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 68,
        "id": 16,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 60,
        "temperature": 0,
        "text": " Let's see what I can do about that.",
        "tokens": [
          50614,
          961,
          311,
          536,
          437,
          286,
          393,
          360,
          466,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 74,
        "id": 17,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 68,
        "temperature": 0,
        "text": " Is that better?",
        "tokens": [
          51014,
          1119,
          300,
          1101,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 77,
        "id": 18,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 74,
        "temperature": 0,
        "text": " Is that better by any chance?",
        "tokens": [
          51314,
          1119,
          300,
          1101,
          538,
          604,
          2931,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 79,
        "id": 19,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 77,
        "temperature": 0,
        "text": " Did I fix something?",
        "tokens": [
          51464,
          2589,
          286,
          3191,
          746,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 81,
        "id": 20,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 79,
        "temperature": 0,
        "text": " Talk, talk, talk, talk.",
        "tokens": [
          51564,
          8780,
          11,
          751,
          11,
          751,
          11,
          751,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17512359619140624,
        "compression_ratio": 1.4154929577464788,
        "end": 83,
        "id": 21,
        "no_speech_prob": 0.004068894311785698,
        "seek": 5500,
        "start": 81,
        "temperature": 0,
        "text": " Or is it still bad?",
        "tokens": [
          51664,
          1610,
          307,
          309,
          920,
          1578,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.3061117444719587,
        "compression_ratio": 1,
        "end": 85,
        "id": 22,
        "no_speech_prob": 0.7734348177909851,
        "seek": 8300,
        "start": 83,
        "temperature": 0,
        "text": " I pressed a button.",
        "tokens": [
          50364,
          286,
          17355,
          257,
          2960,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3061117444719587,
        "compression_ratio": 1,
        "end": 88,
        "id": 23,
        "no_speech_prob": 0.7734348177909851,
        "seek": 8300,
        "start": 85,
        "temperature": 0,
        "text": " No, it's not better?",
        "tokens": [
          50464,
          883,
          11,
          309,
          311,
          406,
          1101,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.3061117444719587,
        "compression_ratio": 1,
        "end": 94,
        "id": 24,
        "no_speech_prob": 0.7734348177909851,
        "seek": 8300,
        "start": 88,
        "temperature": 0,
        "text": " I can't, I don't, okay.",
        "tokens": [
          50614,
          286,
          393,
          380,
          11,
          286,
          500,
          380,
          11,
          1392,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3061117444719587,
        "compression_ratio": 1,
        "end": 96,
        "id": 25,
        "no_speech_prob": 0.7734348177909851,
        "seek": 8300,
        "start": 94,
        "temperature": 0,
        "text": " Test, test.",
        "tokens": [
          50914,
          9279,
          11,
          1500,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.8058725357055664,
        "compression_ratio": 0.7333333333333333,
        "end": 118,
        "id": 26,
        "no_speech_prob": 0.9832478761672974,
        "seek": 11300,
        "start": 113,
        "temperature": 0,
        "text": " I'm going to use this.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          764,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.30565826260313694,
        "compression_ratio": 1.2476190476190476,
        "end": 184,
        "id": 27,
        "no_speech_prob": 0.015183337964117527,
        "seek": 17300,
        "start": 174,
        "temperature": 0,
        "text": " Is this better?",
        "tokens": [
          50414,
          1119,
          341,
          1101,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.30565826260313694,
        "compression_ratio": 1.2476190476190476,
        "end": 186,
        "id": 28,
        "no_speech_prob": 0.015183337964117527,
        "seek": 17300,
        "start": 184,
        "temperature": 0,
        "text": " Am I good?",
        "tokens": [
          50914,
          2012,
          286,
          665,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.30565826260313694,
        "compression_ratio": 1.2476190476190476,
        "end": 189,
        "id": 29,
        "no_speech_prob": 0.015183337964117527,
        "seek": 17300,
        "start": 186,
        "temperature": 0,
        "text": " Any better?",
        "tokens": [
          51014,
          2639,
          1101,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.30565826260313694,
        "compression_ratio": 1.2476190476190476,
        "end": 192,
        "id": 30,
        "no_speech_prob": 0.015183337964117527,
        "seek": 17300,
        "start": 189,
        "temperature": 0,
        "text": " I'm watching this chat with bated breath.",
        "tokens": [
          51164,
          286,
          478,
          1976,
          341,
          5081,
          365,
          272,
          770,
          6045,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.30565826260313694,
        "compression_ratio": 1.2476190476190476,
        "end": 199,
        "id": 31,
        "no_speech_prob": 0.015183337964117527,
        "seek": 17300,
        "start": 192,
        "temperature": 0,
        "text": " Better, okay, great, yay.",
        "tokens": [
          51314,
          15753,
          11,
          1392,
          11,
          869,
          11,
          23986,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.30565826260313694,
        "compression_ratio": 1.2476190476190476,
        "end": 201,
        "id": 32,
        "no_speech_prob": 0.015183337964117527,
        "seek": 17300,
        "start": 199,
        "temperature": 0,
        "text": " Okay, I switched cables.",
        "tokens": [
          51664,
          1033,
          11,
          286,
          16858,
          17555,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 206,
        "id": 33,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 202,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50414,
          876,
          11,
          452,
          8387,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 209,
        "id": 34,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 206,
        "temperature": 0,
        "text": " Very, very close to not having a live stream today, everybody.",
        "tokens": [
          50614,
          4372,
          11,
          588,
          1998,
          281,
          406,
          1419,
          257,
          1621,
          4309,
          965,
          11,
          2201,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 213,
        "id": 35,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 209,
        "temperature": 0,
        "text": " But so far, hello, Arvind.",
        "tokens": [
          50764,
          583,
          370,
          1400,
          11,
          7751,
          11,
          1587,
          85,
          471,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 215,
        "id": 36,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 213,
        "temperature": 0,
        "text": " I love seeing all those hearts.",
        "tokens": [
          50964,
          286,
          959,
          2577,
          439,
          729,
          8852,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 221,
        "id": 37,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 215,
        "temperature": 0,
        "text": " Okay, so let me say a few words in a matter of introduction.",
        "tokens": [
          51064,
          1033,
          11,
          370,
          718,
          385,
          584,
          257,
          1326,
          2283,
          294,
          257,
          1871,
          295,
          9339,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 223,
        "id": 38,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 221,
        "temperature": 0,
        "text": " My name is Dan.",
        "tokens": [
          51364,
          1222,
          1315,
          307,
          3394,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22462681664360895,
        "compression_ratio": 1.5144230769230769,
        "end": 229,
        "id": 39,
        "no_speech_prob": 0.1623256653547287,
        "seek": 20100,
        "start": 223,
        "temperature": 0,
        "text": " I attempt to do weekly live streams and make programming tutorials in the kind of idea of inspiring",
        "tokens": [
          51464,
          286,
          5217,
          281,
          360,
          12460,
          1621,
          15842,
          293,
          652,
          9410,
          17616,
          294,
          264,
          733,
          295,
          1558,
          295,
          15883,
          51764
        ]
      },
      {
        "avg_logprob": -0.2066357737839824,
        "compression_ratio": 1.5336134453781514,
        "end": 234,
        "id": 40,
        "no_speech_prob": 0.09805873036384583,
        "seek": 22900,
        "start": 229,
        "temperature": 0,
        "text": " and teaching people to be creative and think differently with code.",
        "tokens": [
          50364,
          293,
          4571,
          561,
          281,
          312,
          5880,
          293,
          519,
          7614,
          365,
          3089,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2066357737839824,
        "compression_ratio": 1.5336134453781514,
        "end": 237,
        "id": 41,
        "no_speech_prob": 0.09805873036384583,
        "seek": 22900,
        "start": 234,
        "temperature": 0,
        "text": " That's not a good way of describing it.",
        "tokens": [
          50614,
          663,
          311,
          406,
          257,
          665,
          636,
          295,
          16141,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2066357737839824,
        "compression_ratio": 1.5336134453781514,
        "end": 242,
        "id": 42,
        "no_speech_prob": 0.09805873036384583,
        "seek": 22900,
        "start": 237,
        "temperature": 0,
        "text": " Today is Tuesday, November 15th.",
        "tokens": [
          50764,
          2692,
          307,
          10017,
          11,
          7674,
          2119,
          392,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2066357737839824,
        "compression_ratio": 1.5336134453781514,
        "end": 245,
        "id": 43,
        "no_speech_prob": 0.09805873036384583,
        "seek": 22900,
        "start": 242,
        "temperature": 0,
        "text": " A lot has happened in the last week.",
        "tokens": [
          51014,
          316,
          688,
          575,
          2011,
          294,
          264,
          1036,
          1243,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2066357737839824,
        "compression_ratio": 1.5336134453781514,
        "end": 252,
        "id": 44,
        "no_speech_prob": 0.09805873036384583,
        "seek": 22900,
        "start": 245,
        "temperature": 0,
        "text": " And I would like to, before I begin doing some tutorials, I would like to read from you the,",
        "tokens": [
          51164,
          400,
          286,
          576,
          411,
          281,
          11,
          949,
          286,
          1841,
          884,
          512,
          17616,
          11,
          286,
          576,
          411,
          281,
          1401,
          490,
          291,
          264,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.2066357737839824,
        "compression_ratio": 1.5336134453781514,
        "end": 258,
        "id": 45,
        "no_speech_prob": 0.09805873036384583,
        "seek": 22900,
        "start": 252,
        "temperature": 0,
        "text": " so first of all, so one thing that's always been a little confusing to me is that, turn it up.",
        "tokens": [
          51514,
          370,
          700,
          295,
          439,
          11,
          370,
          472,
          551,
          300,
          311,
          1009,
          668,
          257,
          707,
          13181,
          281,
          385,
          307,
          300,
          11,
          1261,
          309,
          493,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 260,
        "id": 46,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 258,
        "temperature": 0,
        "text": " Okay, yeah.",
        "tokens": [
          50364,
          1033,
          11,
          1338,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 262,
        "id": 47,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 260,
        "temperature": 0,
        "text": " I turned the volume up a little bit.",
        "tokens": [
          50464,
          286,
          3574,
          264,
          5523,
          493,
          257,
          707,
          857,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 266,
        "id": 48,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 262,
        "temperature": 0,
        "text": " Is that I do a number of things.",
        "tokens": [
          50564,
          1119,
          300,
          286,
          360,
          257,
          1230,
          295,
          721,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 270,
        "id": 49,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 266,
        "temperature": 0,
        "text": " I work at New York University, Tisch School of the Arts, a program called ITP.",
        "tokens": [
          50764,
          286,
          589,
          412,
          1873,
          3609,
          3535,
          11,
          48192,
          5070,
          295,
          264,
          12407,
          11,
          257,
          1461,
          1219,
          6783,
          47,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 272,
        "id": 50,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 270,
        "temperature": 0,
        "text": " I spend almost all of my time there.",
        "tokens": [
          50964,
          286,
          3496,
          1920,
          439,
          295,
          452,
          565,
          456,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 277,
        "id": 51,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 272,
        "temperature": 0,
        "text": " I also work on something called the Processing Foundation.",
        "tokens": [
          51064,
          286,
          611,
          589,
          322,
          746,
          1219,
          264,
          31093,
          278,
          10335,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20168947136920432,
        "compression_ratio": 1.569377990430622,
        "end": 285,
        "id": 52,
        "no_speech_prob": 0.0012065117480233312,
        "seek": 25800,
        "start": 277,
        "temperature": 0,
        "text": " The Processing Foundation is a not-for-profit foundation, organization,",
        "tokens": [
          51314,
          440,
          31093,
          278,
          10335,
          307,
          257,
          406,
          12,
          2994,
          12,
          14583,
          7030,
          11,
          4475,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.2153145260281033,
        "compression_ratio": 1.6638655462184875,
        "end": 291,
        "id": 53,
        "no_speech_prob": 0.005819512065500021,
        "seek": 28500,
        "start": 285,
        "temperature": 0,
        "text": " whose mission is to promote software literacy in the visual arts and visual literacy in the technology-related fields",
        "tokens": [
          50364,
          6104,
          4447,
          307,
          281,
          9773,
          4722,
          23166,
          294,
          264,
          5056,
          8609,
          293,
          5056,
          23166,
          294,
          264,
          2899,
          12,
          12004,
          7909,
          50664
        ]
      },
      {
        "avg_logprob": -0.2153145260281033,
        "compression_ratio": 1.6638655462184875,
        "end": 294,
        "id": 54,
        "no_speech_prob": 0.005819512065500021,
        "seek": 28500,
        "start": 291,
        "temperature": 0,
        "text": " and to make these fields accessible to diverse communities.",
        "tokens": [
          50664,
          293,
          281,
          652,
          613,
          7909,
          9515,
          281,
          9521,
          4456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2153145260281033,
        "compression_ratio": 1.6638655462184875,
        "end": 298,
        "id": 55,
        "no_speech_prob": 0.005819512065500021,
        "seek": 28500,
        "start": 294,
        "temperature": 0,
        "text": " Those are my two primary things that I do.",
        "tokens": [
          50814,
          3950,
          366,
          452,
          732,
          6194,
          721,
          300,
          286,
          360,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2153145260281033,
        "compression_ratio": 1.6638655462184875,
        "end": 301,
        "id": 56,
        "no_speech_prob": 0.005819512065500021,
        "seek": 28500,
        "start": 298,
        "temperature": 0,
        "text": " This YouTube channel is a bit of an independent project.",
        "tokens": [
          51014,
          639,
          3088,
          2269,
          307,
          257,
          857,
          295,
          364,
          6695,
          1716,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2153145260281033,
        "compression_ratio": 1.6638655462184875,
        "end": 308,
        "id": 57,
        "no_speech_prob": 0.005819512065500021,
        "seek": 28500,
        "start": 301,
        "temperature": 0,
        "text": " It has a lot of relationships to the Processing Foundation in that I do a lot of tutorials around processing in P5.js.",
        "tokens": [
          51164,
          467,
          575,
          257,
          688,
          295,
          6159,
          281,
          264,
          31093,
          278,
          10335,
          294,
          300,
          286,
          360,
          257,
          688,
          295,
          17616,
          926,
          9007,
          294,
          430,
          20,
          13,
          25530,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20487743616104126,
        "compression_ratio": 1.6452991452991452,
        "end": 317,
        "id": 58,
        "no_speech_prob": 0.09262339025735855,
        "seek": 30800,
        "start": 309,
        "temperature": 0,
        "text": " But what I want to do for just the first five minutes here is piggyback off of the P5.js Projects community statement.",
        "tokens": [
          50414,
          583,
          437,
          286,
          528,
          281,
          360,
          337,
          445,
          264,
          700,
          1732,
          2077,
          510,
          307,
          39349,
          3207,
          766,
          295,
          264,
          430,
          20,
          13,
          25530,
          9849,
          82,
          1768,
          5629,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20487743616104126,
        "compression_ratio": 1.6452991452991452,
        "end": 326,
        "id": 59,
        "no_speech_prob": 0.09262339025735855,
        "seek": 30800,
        "start": 317,
        "temperature": 0,
        "text": " And I think it's really important after the election here in this country to make this statement as part of this YouTube channel",
        "tokens": [
          50814,
          400,
          286,
          519,
          309,
          311,
          534,
          1021,
          934,
          264,
          6618,
          510,
          294,
          341,
          1941,
          281,
          652,
          341,
          5629,
          382,
          644,
          295,
          341,
          3088,
          2269,
          51264
        ]
      },
      {
        "avg_logprob": -0.20487743616104126,
        "compression_ratio": 1.6452991452991452,
        "end": 332,
        "id": 60,
        "no_speech_prob": 0.09262339025735855,
        "seek": 30800,
        "start": 326,
        "temperature": 0,
        "text": " and to talk about just how I envision and think about this community.",
        "tokens": [
          51264,
          293,
          281,
          751,
          466,
          445,
          577,
          286,
          24739,
          293,
          519,
          466,
          341,
          1768,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20487743616104126,
        "compression_ratio": 1.6452991452991452,
        "end": 335,
        "id": 61,
        "no_speech_prob": 0.09262339025735855,
        "seek": 30800,
        "start": 332,
        "temperature": 0,
        "text": " So this is the P5.js community statement.",
        "tokens": [
          51564,
          407,
          341,
          307,
          264,
          430,
          20,
          13,
          25530,
          1768,
          5629,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20487743616104126,
        "compression_ratio": 1.6452991452991452,
        "end": 336,
        "id": 62,
        "no_speech_prob": 0.09262339025735855,
        "seek": 30800,
        "start": 335,
        "temperature": 0,
        "text": " It was not written by me.",
        "tokens": [
          51714,
          467,
          390,
          406,
          3720,
          538,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 339,
        "id": 63,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 336,
        "temperature": 0,
        "text": " It was written by contributors to P5.js.",
        "tokens": [
          50364,
          467,
          390,
          3720,
          538,
          45627,
          281,
          430,
          20,
          13,
          25530,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 344,
        "id": 64,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 339,
        "temperature": 0,
        "text": " I believe it was created at the P5.js Contributors Conference.",
        "tokens": [
          50514,
          286,
          1697,
          309,
          390,
          2942,
          412,
          264,
          430,
          20,
          13,
          25530,
          4839,
          2024,
          30751,
          22131,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 346,
        "id": 65,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 344,
        "temperature": 0,
        "text": " I don't know if that's right.",
        "tokens": [
          50764,
          286,
          500,
          380,
          458,
          498,
          300,
          311,
          558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 347,
        "id": 66,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 346,
        "temperature": 0,
        "text": " Somebody fact-checked me on that.",
        "tokens": [
          50864,
          13463,
          1186,
          12,
          15723,
          292,
          385,
          322,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 352,
        "id": 67,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 347,
        "temperature": 0,
        "text": " But this statement goes for this YouTube channel as well.",
        "tokens": [
          50914,
          583,
          341,
          5629,
          1709,
          337,
          341,
          3088,
          2269,
          382,
          731,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 358,
        "id": 68,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 352,
        "temperature": 0,
        "text": " We are a community of and in solidarity with people from every gender, identity, and expression,",
        "tokens": [
          51164,
          492,
          366,
          257,
          1768,
          295,
          293,
          294,
          27220,
          365,
          561,
          490,
          633,
          7898,
          11,
          6575,
          11,
          293,
          6114,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1506735646826589,
        "compression_ratio": 1.5575539568345325,
        "end": 365,
        "id": 69,
        "no_speech_prob": 0.10661543160676956,
        "seek": 33600,
        "start": 358,
        "temperature": 0,
        "text": " sexual orientation, race, ethnicity, language, neurotype, size, ability, class, religion, culture, subculture,",
        "tokens": [
          51464,
          6701,
          14764,
          11,
          4569,
          11,
          33774,
          11,
          2856,
          11,
          12087,
          13108,
          11,
          2744,
          11,
          3485,
          11,
          1508,
          11,
          7561,
          11,
          3713,
          11,
          1422,
          66,
          8389,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 369,
        "id": 70,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 365,
        "temperature": 0,
        "text": " political opinion, age, skill level, occupation, and background.",
        "tokens": [
          50364,
          3905,
          4800,
          11,
          3205,
          11,
          5389,
          1496,
          11,
          24482,
          11,
          293,
          3678,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 373,
        "id": 71,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 369,
        "temperature": 0,
        "text": " We acknowledge that not everyone has the time, financial means, or capacity to actively participate.",
        "tokens": [
          50564,
          492,
          10692,
          300,
          406,
          1518,
          575,
          264,
          565,
          11,
          4669,
          1355,
          11,
          420,
          6042,
          281,
          13022,
          8197,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 376,
        "id": 72,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 373,
        "temperature": 0,
        "text": " That's referring to the open source nature of P5.js.",
        "tokens": [
          50764,
          663,
          311,
          13761,
          281,
          264,
          1269,
          4009,
          3687,
          295,
          430,
          20,
          13,
          25530,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 379,
        "id": 73,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 376,
        "temperature": 0,
        "text": " But we recognize and encourage involvement of all kinds.",
        "tokens": [
          50914,
          583,
          321,
          5521,
          293,
          5373,
          17447,
          295,
          439,
          3685,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 382,
        "id": 74,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 379,
        "temperature": 0,
        "text": " We facilitate and foster access and empowerment.",
        "tokens": [
          51064,
          492,
          20207,
          293,
          17114,
          2105,
          293,
          34825,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 383,
        "id": 75,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 382,
        "temperature": 0,
        "text": " We are all learners.",
        "tokens": [
          51214,
          492,
          366,
          439,
          23655,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 386,
        "id": 76,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 383,
        "temperature": 0,
        "text": " And this is how I feel about this channel.",
        "tokens": [
          51264,
          400,
          341,
          307,
          577,
          286,
          841,
          466,
          341,
          2269,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.131846792047674,
        "compression_ratio": 1.6170212765957446,
        "end": 391,
        "id": 77,
        "no_speech_prob": 0.058275677263736725,
        "seek": 36500,
        "start": 386,
        "temperature": 0,
        "text": " I want this channel to be open, accessible, inclusive for everyone.",
        "tokens": [
          51414,
          286,
          528,
          341,
          2269,
          281,
          312,
          1269,
          11,
          9515,
          11,
          13429,
          337,
          1518,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 396,
        "id": 78,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 392,
        "temperature": 0,
        "text": " And I would like this channel in particular to be a friendly place for beginners",
        "tokens": [
          50414,
          400,
          286,
          576,
          411,
          341,
          2269,
          294,
          1729,
          281,
          312,
          257,
          9208,
          1081,
          337,
          26992,
          50614
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 402,
        "id": 79,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 396,
        "temperature": 0,
        "text": " and people who are new to coding and creative coding to feel welcome and included in part of the discussion.",
        "tokens": [
          50614,
          293,
          561,
          567,
          366,
          777,
          281,
          17720,
          293,
          5880,
          17720,
          281,
          841,
          2928,
          293,
          5556,
          294,
          644,
          295,
          264,
          5017,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 406,
        "id": 80,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 402,
        "temperature": 0,
        "text": " So, I want to make that statement at the beginning of this live stream.",
        "tokens": [
          50914,
          407,
          11,
          286,
          528,
          281,
          652,
          300,
          5629,
          412,
          264,
          2863,
          295,
          341,
          1621,
          4309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 413,
        "id": 81,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 410,
        "temperature": 0,
        "text": " Actually, you should read this whole page.",
        "tokens": [
          51314,
          5135,
          11,
          291,
          820,
          1401,
          341,
          1379,
          3028,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 415,
        "id": 82,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 413,
        "temperature": 0,
        "text": " I'm going to read a little bit more of it to you.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          1401,
          257,
          707,
          857,
          544,
          295,
          309,
          281,
          291,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 417,
        "id": 83,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 415,
        "temperature": 0,
        "text": " And then I'm going to move on to talking about Node.",
        "tokens": [
          51564,
          400,
          550,
          286,
          478,
          516,
          281,
          1286,
          322,
          281,
          1417,
          466,
          38640,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1956613774885211,
        "compression_ratio": 1.678030303030303,
        "end": 420,
        "id": 84,
        "no_speech_prob": 0.05498850718140602,
        "seek": 39100,
        "start": 417,
        "temperature": 0,
        "text": " In practice, we are not code snobs.",
        "tokens": [
          51664,
          682,
          3124,
          11,
          321,
          366,
          406,
          3089,
          43287,
          929,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 423,
        "id": 85,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 420,
        "temperature": 0,
        "text": " We do not assume knowledge or imply there are things that somebody should know.",
        "tokens": [
          50364,
          492,
          360,
          406,
          6552,
          3601,
          420,
          33616,
          456,
          366,
          721,
          300,
          2618,
          820,
          458,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 428,
        "id": 86,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 423,
        "temperature": 0,
        "text": " We insist on actively engaging with requests for feedback regardless of their complexity.",
        "tokens": [
          50514,
          492,
          13466,
          322,
          13022,
          11268,
          365,
          12475,
          337,
          5824,
          10060,
          295,
          641,
          14024,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 432,
        "id": 87,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 428,
        "temperature": 0,
        "text": " We welcome newcomers and prioritize the education of others.",
        "tokens": [
          50764,
          492,
          2928,
          40014,
          433,
          293,
          25164,
          264,
          3309,
          295,
          2357,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 436,
        "id": 88,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 432,
        "temperature": 0,
        "text": " We strive to approach all tasks with the enthusiasm of a newcomer.",
        "tokens": [
          50964,
          492,
          23829,
          281,
          3109,
          439,
          9608,
          365,
          264,
          23417,
          295,
          257,
          40014,
          260,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 440,
        "id": 89,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 436,
        "temperature": 0,
        "text": " Because we believe that newcomers are just as valuable in this effort as experts.",
        "tokens": [
          51164,
          1436,
          321,
          1697,
          300,
          40014,
          433,
          366,
          445,
          382,
          8263,
          294,
          341,
          4630,
          382,
          8572,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 445,
        "id": 90,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 440,
        "temperature": 0,
        "text": " We consistently make the effort to actively recognize and validate multiple types of contributions.",
        "tokens": [
          51364,
          492,
          14961,
          652,
          264,
          4630,
          281,
          13022,
          5521,
          293,
          29562,
          3866,
          3467,
          295,
          15725,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1568436150078301,
        "compression_ratio": 1.7087378640776698,
        "end": 448,
        "id": 91,
        "no_speech_prob": 0.060042768716812134,
        "seek": 42000,
        "start": 445,
        "temperature": 0,
        "text": " We are always willing to offer help or guidance.",
        "tokens": [
          51614,
          492,
          366,
          1009,
          4950,
          281,
          2626,
          854,
          420,
          10056,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 452,
        "id": 92,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 448,
        "temperature": 0,
        "text": " We listen. We clearly communicate. We admit when we're wrong.",
        "tokens": [
          50364,
          492,
          2140,
          13,
          492,
          4448,
          7890,
          13,
          492,
          9796,
          562,
          321,
          434,
          2085,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 454,
        "id": 93,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 452,
        "temperature": 0,
        "text": " We continuously seek to improve ourselves.",
        "tokens": [
          50564,
          492,
          15684,
          8075,
          281,
          3470,
          4175,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 456,
        "id": 94,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 454,
        "temperature": 0,
        "text": " We keep our community respectful and open.",
        "tokens": [
          50664,
          492,
          1066,
          527,
          1768,
          26205,
          293,
          1269,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 458,
        "id": 95,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 456,
        "temperature": 0,
        "text": " We make everyone feel heard.",
        "tokens": [
          50764,
          492,
          652,
          1518,
          841,
          2198,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 460,
        "id": 96,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 458,
        "temperature": 0,
        "text": " And we are mindful and kind in our interactions.",
        "tokens": [
          50864,
          400,
          321,
          366,
          14618,
          293,
          733,
          294,
          527,
          13280,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 465,
        "id": 97,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 460,
        "temperature": 0,
        "text": " Okay. So, thanks for tuning in.",
        "tokens": [
          50964,
          1033,
          13,
          407,
          11,
          3231,
          337,
          15164,
          294,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 469,
        "id": 98,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 465,
        "temperature": 0,
        "text": " Thanks for listening to me as I read the p5.js community statement.",
        "tokens": [
          51214,
          2561,
          337,
          4764,
          281,
          385,
          382,
          286,
          1401,
          264,
          280,
          20,
          13,
          25530,
          1768,
          5629,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 474,
        "id": 99,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 469,
        "temperature": 0,
        "text": " And I hope that you enjoy this YouTube channel and find it useful.",
        "tokens": [
          51414,
          400,
          286,
          1454,
          300,
          291,
          2103,
          341,
          3088,
          2269,
          293,
          915,
          309,
          4420,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19849125544230142,
        "compression_ratio": 1.6801470588235294,
        "end": 477,
        "id": 100,
        "no_speech_prob": 0.0012057310668751597,
        "seek": 44800,
        "start": 474,
        "temperature": 0,
        "text": " And I hope that you will be in touch in the chat and on Twitter.",
        "tokens": [
          51664,
          400,
          286,
          1454,
          300,
          291,
          486,
          312,
          294,
          2557,
          294,
          264,
          5081,
          293,
          322,
          5794,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21781870096671482,
        "compression_ratio": 1.5848375451263539,
        "end": 484,
        "id": 101,
        "no_speech_prob": 0.03620496392250061,
        "seek": 47700,
        "start": 477,
        "temperature": 0,
        "text": " And all the other ways that we can be in touch with each other and help support everyone in their desire to learn more.",
        "tokens": [
          50364,
          400,
          439,
          264,
          661,
          2098,
          300,
          321,
          393,
          312,
          294,
          2557,
          365,
          1184,
          661,
          293,
          854,
          1406,
          1518,
          294,
          641,
          7516,
          281,
          1466,
          544,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21781870096671482,
        "compression_ratio": 1.5848375451263539,
        "end": 487,
        "id": 102,
        "no_speech_prob": 0.03620496392250061,
        "seek": 47700,
        "start": 484,
        "temperature": 0,
        "text": " And create and communicate.",
        "tokens": [
          50714,
          400,
          1884,
          293,
          7890,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21781870096671482,
        "compression_ratio": 1.5848375451263539,
        "end": 491,
        "id": 103,
        "no_speech_prob": 0.03620496392250061,
        "seek": 47700,
        "start": 487,
        "temperature": 0,
        "text": " Express themselves through code, the internet, technology, all that sort of stuff.",
        "tokens": [
          50864,
          20212,
          2969,
          807,
          3089,
          11,
          264,
          4705,
          11,
          2899,
          11,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21781870096671482,
        "compression_ratio": 1.5848375451263539,
        "end": 495,
        "id": 104,
        "no_speech_prob": 0.03620496392250061,
        "seek": 47700,
        "start": 491,
        "temperature": 0,
        "text": " Okay. So, I'm a little bit... It is 2 o'clock. I have exactly one hour.",
        "tokens": [
          51064,
          1033,
          13,
          407,
          11,
          286,
          478,
          257,
          707,
          857,
          485,
          467,
          307,
          568,
          277,
          6,
          9023,
          13,
          286,
          362,
          2293,
          472,
          1773,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21781870096671482,
        "compression_ratio": 1.5848375451263539,
        "end": 500,
        "id": 105,
        "no_speech_prob": 0.03620496392250061,
        "seek": 47700,
        "start": 495,
        "temperature": 0,
        "text": " And in my last session, I'm just going to pull up the playlist that I didn't get to finish.",
        "tokens": [
          51264,
          400,
          294,
          452,
          1036,
          5481,
          11,
          286,
          478,
          445,
          516,
          281,
          2235,
          493,
          264,
          16788,
          300,
          286,
          994,
          380,
          483,
          281,
          2413,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21781870096671482,
        "compression_ratio": 1.5848375451263539,
        "end": 503,
        "id": 106,
        "no_speech_prob": 0.03620496392250061,
        "seek": 47700,
        "start": 500,
        "temperature": 0,
        "text": " I don't know if I'll get to finish it today.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          498,
          286,
          603,
          483,
          281,
          2413,
          309,
          965,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 508,
        "id": 107,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 503,
        "temperature": 0,
        "text": " But my most recent playlist, session 8, which is...",
        "tokens": [
          50364,
          583,
          452,
          881,
          5162,
          16788,
          11,
          5481,
          1649,
          11,
          597,
          307,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 512,
        "id": 108,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 508,
        "temperature": 0,
        "text": " The topic was looking at how to build your own API in Node.",
        "tokens": [
          50614,
          440,
          4829,
          390,
          1237,
          412,
          577,
          281,
          1322,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 518,
        "id": 109,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 512,
        "temperature": 0,
        "text": " And the API example that I'm building is sentiment analysis API.",
        "tokens": [
          50814,
          400,
          264,
          9362,
          1365,
          300,
          286,
          478,
          2390,
          307,
          16149,
          5215,
          9362,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 520,
        "id": 110,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 518,
        "temperature": 0,
        "text": " Since... Why not?",
        "tokens": [
          51114,
          4162,
          485,
          1545,
          406,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 524,
        "id": 111,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 520,
        "temperature": 0,
        "text": " Since this is arguably... These sessions from this fall are all about programming with text.",
        "tokens": [
          51214,
          4162,
          341,
          307,
          26771,
          485,
          1981,
          11081,
          490,
          341,
          2100,
          366,
          439,
          466,
          9410,
          365,
          2487,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 526,
        "id": 112,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 524,
        "temperature": 0,
        "text": " So, that's useful.",
        "tokens": [
          51414,
          407,
          11,
          300,
          311,
          4420,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 529,
        "id": 113,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 526,
        "temperature": 0,
        "text": " So, I'm going to kind of pick up right where I left.",
        "tokens": [
          51514,
          407,
          11,
          286,
          478,
          516,
          281,
          733,
          295,
          1888,
          493,
          558,
          689,
          286,
          1411,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20080493825726806,
        "compression_ratio": 1.548148148148148,
        "end": 531,
        "id": 114,
        "no_speech_prob": 0.05580274388194084,
        "seek": 50300,
        "start": 529,
        "temperature": 0,
        "text": " And I've got a couple more little short tutorials to make.",
        "tokens": [
          51664,
          400,
          286,
          600,
          658,
          257,
          1916,
          544,
          707,
          2099,
          17616,
          281,
          652,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1885186662065222,
        "compression_ratio": 1.445945945945946,
        "end": 537,
        "id": 115,
        "no_speech_prob": 0.1520046889781952,
        "seek": 53100,
        "start": 531,
        "temperature": 0,
        "text": " Now, I'll say a couple of other things about my plans for the rest of this 2016 year.",
        "tokens": [
          50364,
          823,
          11,
          286,
          603,
          584,
          257,
          1916,
          295,
          661,
          721,
          466,
          452,
          5482,
          337,
          264,
          1472,
          295,
          341,
          6549,
          1064,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1885186662065222,
        "compression_ratio": 1.445945945945946,
        "end": 541,
        "id": 116,
        "no_speech_prob": 0.1520046889781952,
        "seek": 53100,
        "start": 537,
        "temperature": 0,
        "text": " Which, as far as I'm concerned, 2017 can't come soon enough.",
        "tokens": [
          50664,
          3013,
          11,
          382,
          1400,
          382,
          286,
          478,
          5922,
          11,
          6591,
          393,
          380,
          808,
          2321,
          1547,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1885186662065222,
        "compression_ratio": 1.445945945945946,
        "end": 543,
        "id": 117,
        "no_speech_prob": 0.1520046889781952,
        "seek": 53100,
        "start": 541,
        "temperature": 0,
        "text": " Maybe 2020 should come soon enough.",
        "tokens": [
          50864,
          2704,
          4808,
          820,
          808,
          2321,
          1547,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1885186662065222,
        "compression_ratio": 1.445945945945946,
        "end": 549,
        "id": 118,
        "no_speech_prob": 0.1520046889781952,
        "seek": 53100,
        "start": 543,
        "temperature": 0,
        "text": " But... Let me... Okay.",
        "tokens": [
          50964,
          583,
          485,
          961,
          385,
          485,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1885186662065222,
        "compression_ratio": 1.445945945945946,
        "end": 556,
        "id": 119,
        "no_speech_prob": 0.1520046889781952,
        "seek": 53100,
        "start": 549,
        "temperature": 0,
        "text": " So, if you recall, what I'm doing right now in this fall is making videos for this course.",
        "tokens": [
          51264,
          407,
          11,
          498,
          291,
          9901,
          11,
          437,
          286,
          478,
          884,
          558,
          586,
          294,
          341,
          2100,
          307,
          1455,
          2145,
          337,
          341,
          1164,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1885186662065222,
        "compression_ratio": 1.445945945945946,
        "end": 558,
        "id": 120,
        "no_speech_prob": 0.1520046889781952,
        "seek": 53100,
        "start": 556,
        "temperature": 0,
        "text": " Programming from A to Z.",
        "tokens": [
          51614,
          8338,
          2810,
          490,
          316,
          281,
          1176,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 562,
        "id": 121,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 558,
        "temperature": 0,
        "text": " Which is... Everything can be found at shiffman.net.com.",
        "tokens": [
          50364,
          3013,
          307,
          485,
          5471,
          393,
          312,
          1352,
          412,
          402,
          3661,
          1601,
          13,
          7129,
          13,
          1112,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 567,
        "id": 122,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 562,
        "temperature": 0,
        "text": " These are all written tutorials on various topics with videos.",
        "tokens": [
          50564,
          1981,
          366,
          439,
          3720,
          17616,
          322,
          3683,
          8378,
          365,
          2145,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 571,
        "id": 123,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 567,
        "temperature": 0,
        "text": " So, right now, I'm working on this page, which is building an API with Node and Express.",
        "tokens": [
          50814,
          407,
          11,
          558,
          586,
          11,
          286,
          478,
          1364,
          322,
          341,
          3028,
          11,
          597,
          307,
          2390,
          364,
          9362,
          365,
          38640,
          293,
          20212,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 573,
        "id": 124,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 571,
        "temperature": 0,
        "text": " And you can see I've got some examples.",
        "tokens": [
          51014,
          400,
          291,
          393,
          536,
          286,
          600,
          658,
          512,
          5110,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 574,
        "id": 125,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 573,
        "temperature": 0,
        "text": " I've got some text descriptions.",
        "tokens": [
          51114,
          286,
          600,
          658,
          512,
          2487,
          24406,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 577,
        "id": 126,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 574,
        "temperature": 0,
        "text": " And I've got some embedded videos.",
        "tokens": [
          51164,
          400,
          286,
          600,
          658,
          512,
          16741,
          2145,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 581,
        "id": 127,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 577,
        "temperature": 0,
        "text": " So, before the end of 2016, I hope to finish this page.",
        "tokens": [
          51314,
          407,
          11,
          949,
          264,
          917,
          295,
          6549,
          11,
          286,
          1454,
          281,
          2413,
          341,
          3028,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21619921282303234,
        "compression_ratio": 1.6139705882352942,
        "end": 585,
        "id": 128,
        "no_speech_prob": 0.19925549626350403,
        "seek": 55800,
        "start": 581,
        "temperature": 0,
        "text": " I want to do some videos about working with a database as service.",
        "tokens": [
          51514,
          286,
          528,
          281,
          360,
          512,
          2145,
          466,
          1364,
          365,
          257,
          8149,
          382,
          2643,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 588,
        "id": 129,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 585,
        "temperature": 0,
        "text": " Something called Firebase, which you may or may not have heard of.",
        "tokens": [
          50364,
          6595,
          1219,
          35173,
          11,
          597,
          291,
          815,
          420,
          815,
          406,
          362,
          2198,
          295,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 591,
        "id": 130,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 588,
        "temperature": 0,
        "text": " So, I already have a written tutorial, but there are no videos for that yet.",
        "tokens": [
          50514,
          407,
          11,
          286,
          1217,
          362,
          257,
          3720,
          7073,
          11,
          457,
          456,
          366,
          572,
          2145,
          337,
          300,
          1939,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 594,
        "id": 131,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 591,
        "temperature": 0,
        "text": " As well as looking at Chrome extensions.",
        "tokens": [
          50664,
          1018,
          731,
          382,
          1237,
          412,
          15327,
          25129,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 597,
        "id": 132,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 594,
        "temperature": 0,
        "text": " So, the Firebase topic is a smaller topic.",
        "tokens": [
          50814,
          407,
          11,
          264,
          35173,
          4829,
          307,
          257,
          4356,
          4829,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 599,
        "id": 133,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 597,
        "temperature": 0,
        "text": " Probably can happen in a shorter session.",
        "tokens": [
          50964,
          9210,
          393,
          1051,
          294,
          257,
          11639,
          5481,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 603,
        "id": 134,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 599,
        "temperature": 0,
        "text": " The Chrome extensions is a longer topic that will need a longer session.",
        "tokens": [
          51064,
          440,
          15327,
          25129,
          307,
          257,
          2854,
          4829,
          300,
          486,
          643,
          257,
          2854,
          5481,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 605,
        "id": 135,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 603,
        "temperature": 0,
        "text": " So, it is the middle of November.",
        "tokens": [
          51264,
          407,
          11,
          309,
          307,
          264,
          2808,
          295,
          7674,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 608,
        "id": 136,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 605,
        "temperature": 0,
        "text": " And I have until the end of December to get through all this stuff.",
        "tokens": [
          51364,
          400,
          286,
          362,
          1826,
          264,
          917,
          295,
          7687,
          281,
          483,
          807,
          439,
          341,
          1507,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 611,
        "id": 137,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 608,
        "temperature": 0,
        "text": " I'm hoping that, actually, I'll get through this stuff relatively soon.",
        "tokens": [
          51514,
          286,
          478,
          7159,
          300,
          11,
          767,
          11,
          286,
          603,
          483,
          807,
          341,
          1507,
          7226,
          2321,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.188800043707726,
        "compression_ratio": 1.7400611620795108,
        "end": 614,
        "id": 138,
        "no_speech_prob": 0.17778612673282623,
        "seek": 58500,
        "start": 611,
        "temperature": 0,
        "text": " And return, I would like to, by the end of the year.",
        "tokens": [
          51664,
          400,
          2736,
          11,
          286,
          576,
          411,
          281,
          11,
          538,
          264,
          917,
          295,
          264,
          1064,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 619,
        "id": 139,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 614,
        "temperature": 0,
        "text": " Maybe for kind of like a holiday special, just do some fun, quirky coding challenges.",
        "tokens": [
          50364,
          2704,
          337,
          733,
          295,
          411,
          257,
          9960,
          2121,
          11,
          445,
          360,
          512,
          1019,
          11,
          49515,
          17720,
          4759,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 622,
        "id": 140,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 619,
        "temperature": 0,
        "text": " Some different algorithms that I would like to explore.",
        "tokens": [
          50614,
          2188,
          819,
          14642,
          300,
          286,
          576,
          411,
          281,
          6839,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 628,
        "id": 141,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 622,
        "temperature": 0,
        "text": " And as well as my most popular videos, which I've said before.",
        "tokens": [
          50764,
          400,
          382,
          731,
          382,
          452,
          881,
          3743,
          2145,
          11,
          597,
          286,
          600,
          848,
          949,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 632,
        "id": 142,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 628,
        "temperature": 0,
        "text": " Where I take an old kind of classic arcade style game and try to make a JavaScript version of it.",
        "tokens": [
          51064,
          2305,
          286,
          747,
          364,
          1331,
          733,
          295,
          7230,
          25664,
          3758,
          1216,
          293,
          853,
          281,
          652,
          257,
          15778,
          3037,
          295,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 635,
        "id": 143,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 632,
        "temperature": 0,
        "text": " So, I'm hoping to do those kind of things before the end of the year.",
        "tokens": [
          51264,
          407,
          11,
          286,
          478,
          7159,
          281,
          360,
          729,
          733,
          295,
          721,
          949,
          264,
          917,
          295,
          264,
          1064,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 639,
        "id": 144,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 635,
        "temperature": 0,
        "text": " This spring, I will be returning to the nature of code materials.",
        "tokens": [
          51414,
          639,
          5587,
          11,
          286,
          486,
          312,
          12678,
          281,
          264,
          3687,
          295,
          3089,
          5319,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 641,
        "id": 145,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 639,
        "temperature": 0,
        "text": " Which is physics and animation.",
        "tokens": [
          51614,
          3013,
          307,
          10649,
          293,
          9603,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20319680949203842,
        "compression_ratio": 1.64375,
        "end": 643,
        "id": 146,
        "no_speech_prob": 0.000896922021638602,
        "seek": 61400,
        "start": 641,
        "temperature": 0,
        "text": " As well as starting to look at machine learning topics.",
        "tokens": [
          51714,
          1018,
          731,
          382,
          2891,
          281,
          574,
          412,
          3479,
          2539,
          8378,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 646,
        "id": 147,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 643,
        "temperature": 0,
        "text": " So, that's all coming in the pipeline.",
        "tokens": [
          50364,
          407,
          11,
          300,
          311,
          439,
          1348,
          294,
          264,
          15517,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 654,
        "id": 148,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 646,
        "temperature": 0,
        "text": " Now, another thing I'll say, just as a matter of updating you as to what's happening.",
        "tokens": [
          50514,
          823,
          11,
          1071,
          551,
          286,
          603,
          584,
          11,
          445,
          382,
          257,
          1871,
          295,
          25113,
          291,
          382,
          281,
          437,
          311,
          2737,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 657,
        "id": 149,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 654,
        "temperature": 0,
        "text": " Is that I have started having guests.",
        "tokens": [
          50914,
          1119,
          300,
          286,
          362,
          1409,
          1419,
          9804,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 660,
        "id": 150,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 657,
        "temperature": 0,
        "text": " And in fact, later today, I just didn't get to do it this morning.",
        "tokens": [
          51064,
          400,
          294,
          1186,
          11,
          1780,
          965,
          11,
          286,
          445,
          994,
          380,
          483,
          281,
          360,
          309,
          341,
          2446,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 662,
        "id": 151,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 660,
        "temperature": 0,
        "text": " I will make live a tutorial from Tega Brain.",
        "tokens": [
          51214,
          286,
          486,
          652,
          1621,
          257,
          7073,
          490,
          314,
          6335,
          29783,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 667,
        "id": 152,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 662,
        "temperature": 0,
        "text": " Who is one of the teachers and alumni of the School for Product Computation.",
        "tokens": [
          51314,
          2102,
          307,
          472,
          295,
          264,
          6023,
          293,
          16347,
          295,
          264,
          5070,
          337,
          22005,
          37804,
          399,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19919311248504365,
        "compression_ratio": 1.558139534883721,
        "end": 669,
        "id": 153,
        "no_speech_prob": 0.008186496794223785,
        "seek": 64300,
        "start": 667,
        "temperature": 0,
        "text": " Which is where I'm recording the videos right now.",
        "tokens": [
          51564,
          3013,
          307,
          689,
          286,
          478,
          6613,
          264,
          2145,
          558,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22794908406783124,
        "compression_ratio": 1.5414847161572052,
        "end": 674,
        "id": 154,
        "no_speech_prob": 0.388255774974823,
        "seek": 66900,
        "start": 669,
        "temperature": 0,
        "text": " And she has a tutorial about working with physical sensors and P5.js.",
        "tokens": [
          50364,
          400,
          750,
          575,
          257,
          7073,
          466,
          1364,
          365,
          4001,
          14840,
          293,
          430,
          20,
          13,
          25530,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22794908406783124,
        "compression_ratio": 1.5414847161572052,
        "end": 678,
        "id": 155,
        "no_speech_prob": 0.388255774974823,
        "seek": 66900,
        "start": 674,
        "temperature": 0,
        "text": " So, that tutorial, you'll see that in the channel, in the stream later today.",
        "tokens": [
          50614,
          407,
          11,
          300,
          7073,
          11,
          291,
          603,
          536,
          300,
          294,
          264,
          2269,
          11,
          294,
          264,
          4309,
          1780,
          965,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22794908406783124,
        "compression_ratio": 1.5414847161572052,
        "end": 681,
        "id": 156,
        "no_speech_prob": 0.388255774974823,
        "seek": 66900,
        "start": 678,
        "temperature": 0,
        "text": " And then also, if all goes according to plan.",
        "tokens": [
          50814,
          400,
          550,
          611,
          11,
          498,
          439,
          1709,
          4650,
          281,
          1393,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22794908406783124,
        "compression_ratio": 1.5414847161572052,
        "end": 687,
        "id": 157,
        "no_speech_prob": 0.388255774974823,
        "seek": 66900,
        "start": 681,
        "temperature": 0,
        "text": " At around 6.30pm, Eastern Time today.",
        "tokens": [
          50964,
          1711,
          926,
          1386,
          13,
          3446,
          14395,
          11,
          12901,
          6161,
          965,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22794908406783124,
        "compression_ratio": 1.5414847161572052,
        "end": 691,
        "id": 158,
        "no_speech_prob": 0.388255774974823,
        "seek": 66900,
        "start": 687,
        "temperature": 0,
        "text": " I will be welcoming Jane Friedhoff into the studio.",
        "tokens": [
          51264,
          286,
          486,
          312,
          17378,
          13048,
          17605,
          1289,
          602,
          666,
          264,
          6811,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22794908406783124,
        "compression_ratio": 1.5414847161572052,
        "end": 697,
        "id": 159,
        "no_speech_prob": 0.388255774974823,
        "seek": 66900,
        "start": 691,
        "temperature": 0,
        "text": " And Jane Friedhoff is a creative researcher, designer, game designer.",
        "tokens": [
          51464,
          400,
          13048,
          17605,
          1289,
          602,
          307,
          257,
          5880,
          21751,
          11,
          11795,
          11,
          1216,
          11795,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 699,
        "id": 160,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 697,
        "temperature": 0,
        "text": " She does amazing, wonderful work.",
        "tokens": [
          50364,
          1240,
          775,
          2243,
          11,
          3715,
          589,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 702,
        "id": 161,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 699,
        "temperature": 0,
        "text": " And she's going to talk about a game called Slam City Oracles.",
        "tokens": [
          50464,
          400,
          750,
          311,
          516,
          281,
          751,
          466,
          257,
          1216,
          1219,
          318,
          4326,
          4392,
          1610,
          9918,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 704,
        "id": 162,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 702,
        "temperature": 0,
        "text": " And how she made it.",
        "tokens": [
          50614,
          400,
          577,
          750,
          1027,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 706,
        "id": 163,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 704,
        "temperature": 0,
        "text": " And I'll ask her a few questions about that.",
        "tokens": [
          50714,
          400,
          286,
          603,
          1029,
          720,
          257,
          1326,
          1651,
          466,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 708,
        "id": 164,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 706,
        "temperature": 0,
        "text": " And if you're tuning in live, you can ask questions in the chat.",
        "tokens": [
          50814,
          400,
          498,
          291,
          434,
          15164,
          294,
          1621,
          11,
          291,
          393,
          1029,
          1651,
          294,
          264,
          5081,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 713,
        "id": 165,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 708,
        "temperature": 0,
        "text": " So, I'm also trying... I have very limited time these couple weeks.",
        "tokens": [
          50914,
          407,
          11,
          286,
          478,
          611,
          1382,
          485,
          286,
          362,
          588,
          5567,
          565,
          613,
          1916,
          3259,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 716,
        "id": 166,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 713,
        "temperature": 0,
        "text": " But as time goes on, I'm going to try to have more guests.",
        "tokens": [
          51164,
          583,
          382,
          565,
          1709,
          322,
          11,
          286,
          478,
          516,
          281,
          853,
          281,
          362,
          544,
          9804,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 720,
        "id": 167,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 716,
        "temperature": 0,
        "text": " To bring you additional content and different voices and different faces.",
        "tokens": [
          51314,
          1407,
          1565,
          291,
          4497,
          2701,
          293,
          819,
          9802,
          293,
          819,
          8475,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1952087222121832,
        "compression_ratio": 1.6298932384341638,
        "end": 722,
        "id": 168,
        "no_speech_prob": 0.04333246499300003,
        "seek": 69700,
        "start": 720,
        "temperature": 0,
        "text": " From just me in this channel.",
        "tokens": [
          51514,
          3358,
          445,
          385,
          294,
          341,
          2269,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 727,
        "id": 169,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 722,
        "temperature": 0,
        "text": " Okay. So, I'm going to get myself set up here.",
        "tokens": [
          50364,
          1033,
          13,
          407,
          11,
          286,
          478,
          516,
          281,
          483,
          2059,
          992,
          493,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 730,
        "id": 170,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 727,
        "temperature": 0,
        "text": " I'm kind of keeping half of an eye on the chat.",
        "tokens": [
          50614,
          286,
          478,
          733,
          295,
          5145,
          1922,
          295,
          364,
          3313,
          322,
          264,
          5081,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 733,
        "id": 171,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 730,
        "temperature": 0,
        "text": " So, if you have a question in there, you can ask.",
        "tokens": [
          50764,
          407,
          11,
          498,
          291,
          362,
          257,
          1168,
          294,
          456,
          11,
          291,
          393,
          1029,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 739,
        "id": 172,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 735,
        "temperature": 0,
        "text": " But in the words of Jane, let's make it happen.",
        "tokens": [
          51014,
          583,
          294,
          264,
          2283,
          295,
          13048,
          11,
          718,
          311,
          652,
          309,
          1051,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 745,
        "id": 173,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 739,
        "temperature": 0,
        "text": " Okay. So, what I've got to do here...",
        "tokens": [
          51214,
          1033,
          13,
          407,
          11,
          437,
          286,
          600,
          658,
          281,
          360,
          510,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 747,
        "id": 174,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 745,
        "temperature": 0,
        "text": " And I don't have my sound stuff hooked up.",
        "tokens": [
          51514,
          400,
          286,
          500,
          380,
          362,
          452,
          1626,
          1507,
          20410,
          493,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1903244434016766,
        "compression_ratio": 1.5,
        "end": 749,
        "id": 175,
        "no_speech_prob": 0.006691526155918837,
        "seek": 72200,
        "start": 747,
        "temperature": 0,
        "text": " Because I had a bunch of issues.",
        "tokens": [
          51614,
          1436,
          286,
          632,
          257,
          3840,
          295,
          2663,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 756,
        "id": 176,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 749,
        "temperature": 0,
        "text": " So, I normally like to play background music when I'm just in the let me get myself situated here.",
        "tokens": [
          50364,
          407,
          11,
          286,
          5646,
          411,
          281,
          862,
          3678,
          1318,
          562,
          286,
          478,
          445,
          294,
          264,
          718,
          385,
          483,
          2059,
          30143,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 759,
        "id": 177,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 756,
        "temperature": 0,
        "text": " But let's see if I can find where I left off.",
        "tokens": [
          50714,
          583,
          718,
          311,
          536,
          498,
          286,
          393,
          915,
          689,
          286,
          1411,
          766,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 763,
        "id": 178,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 759,
        "temperature": 0,
        "text": " Session 8, API 1.",
        "tokens": [
          50864,
          318,
          4311,
          1649,
          11,
          9362,
          502,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 766,
        "id": 179,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 763,
        "temperature": 0,
        "text": " So, let's copy that. I don't remember where I left off.",
        "tokens": [
          51064,
          407,
          11,
          718,
          311,
          5055,
          300,
          13,
          286,
          500,
          380,
          1604,
          689,
          286,
          1411,
          766,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 768,
        "id": 180,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 766,
        "temperature": 0,
        "text": " Let's copy that into API 2.",
        "tokens": [
          51214,
          961,
          311,
          5055,
          300,
          666,
          9362,
          568,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 772,
        "id": 181,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 768,
        "temperature": 0,
        "text": " I also have a little bit of an issue where my whiteboard camera...",
        "tokens": [
          51314,
          286,
          611,
          362,
          257,
          707,
          857,
          295,
          364,
          2734,
          689,
          452,
          2418,
          3787,
          2799,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2022627714638398,
        "compression_ratio": 1.5260869565217392,
        "end": 774,
        "id": 182,
        "no_speech_prob": 0.013221999630331993,
        "seek": 74900,
        "start": 772,
        "temperature": 0,
        "text": " I just went all black. Isn't working.",
        "tokens": [
          51514,
          286,
          445,
          1437,
          439,
          2211,
          13,
          6998,
          380,
          1364,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 778,
        "id": 183,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 774,
        "temperature": 0,
        "text": " So, I don't know if I'm going to be able to use the whiteboard today.",
        "tokens": [
          50364,
          407,
          11,
          286,
          500,
          380,
          458,
          498,
          286,
          478,
          516,
          281,
          312,
          1075,
          281,
          764,
          264,
          2418,
          3787,
          965,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 781,
        "id": 184,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 778,
        "temperature": 0,
        "text": " But that's okay. I think we can live with that.",
        "tokens": [
          50564,
          583,
          300,
          311,
          1392,
          13,
          286,
          519,
          321,
          393,
          1621,
          365,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 783,
        "id": 185,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 781,
        "temperature": 0,
        "text": " So, this is where I left off last time.",
        "tokens": [
          50714,
          407,
          11,
          341,
          307,
          689,
          286,
          1411,
          766,
          1036,
          565,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 786,
        "id": 186,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 783,
        "temperature": 0,
        "text": " Let me run Adam as a text editor.",
        "tokens": [
          50814,
          961,
          385,
          1190,
          7938,
          382,
          257,
          2487,
          9839,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 791,
        "id": 187,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 788,
        "temperature": 0,
        "text": " Boy, there's a lot of great questions in the chat.",
        "tokens": [
          51064,
          9486,
          11,
          456,
          311,
          257,
          688,
          295,
          869,
          1651,
          294,
          264,
          5081,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 795,
        "id": 188,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 793,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51314,
          400,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.17024903345589687,
        "compression_ratio": 1.4878048780487805,
        "end": 802,
        "id": 189,
        "no_speech_prob": 0.05339779332280159,
        "seek": 77400,
        "start": 799,
        "temperature": 0,
        "text": " Actually, I don't know if... Someone's asking about D3.",
        "tokens": [
          51614,
          5135,
          11,
          286,
          500,
          380,
          458,
          498,
          485,
          8734,
          311,
          3365,
          466,
          413,
          18,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2127096939086914,
        "compression_ratio": 1.676056338028169,
        "end": 807,
        "id": 190,
        "no_speech_prob": 0.0027575104031711817,
        "seek": 80200,
        "start": 802,
        "temperature": 0,
        "text": " In the hope that I would be able to make a video tutorial about everything and anything that exists in the world.",
        "tokens": [
          50364,
          682,
          264,
          1454,
          300,
          286,
          576,
          312,
          1075,
          281,
          652,
          257,
          960,
          7073,
          466,
          1203,
          293,
          1340,
          300,
          8198,
          294,
          264,
          1002,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2127096939086914,
        "compression_ratio": 1.676056338028169,
        "end": 810,
        "id": 191,
        "no_speech_prob": 0.0027575104031711817,
        "seek": 80200,
        "start": 807,
        "temperature": 0,
        "text": " I would love to do something about D3.",
        "tokens": [
          50614,
          286,
          576,
          959,
          281,
          360,
          746,
          466,
          413,
          18,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2127096939086914,
        "compression_ratio": 1.676056338028169,
        "end": 819,
        "id": 192,
        "no_speech_prob": 0.0027575104031711817,
        "seek": 80200,
        "start": 813,
        "temperature": 0,
        "text": " But it's not on my list in something that I'm going to be getting to soon.",
        "tokens": [
          50914,
          583,
          309,
          311,
          406,
          322,
          452,
          1329,
          294,
          746,
          300,
          286,
          478,
          516,
          281,
          312,
          1242,
          281,
          2321,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2127096939086914,
        "compression_ratio": 1.676056338028169,
        "end": 822,
        "id": 193,
        "no_speech_prob": 0.0027575104031711817,
        "seek": 80200,
        "start": 819,
        "temperature": 0,
        "text": " But that would be a great topic for a guest to come in and do a tutorial.",
        "tokens": [
          51214,
          583,
          300,
          576,
          312,
          257,
          869,
          4829,
          337,
          257,
          8341,
          281,
          808,
          294,
          293,
          360,
          257,
          7073,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2127096939086914,
        "compression_ratio": 1.676056338028169,
        "end": 826,
        "id": 194,
        "no_speech_prob": 0.0027575104031711817,
        "seek": 80200,
        "start": 822,
        "temperature": 0,
        "text": " Okay. So, here is my node server.",
        "tokens": [
          51364,
          1033,
          13,
          407,
          11,
          510,
          307,
          452,
          9984,
          7154,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2127096939086914,
        "compression_ratio": 1.676056338028169,
        "end": 830,
        "id": 195,
        "no_speech_prob": 0.0027575104031711817,
        "seek": 80200,
        "start": 826,
        "temperature": 0,
        "text": " Here is the web page.",
        "tokens": [
          51564,
          1692,
          307,
          264,
          3670,
          3028,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23084479111891526,
        "compression_ratio": 1.3567567567567567,
        "end": 832,
        "id": 196,
        "no_speech_prob": 0.0017273637931793928,
        "seek": 83000,
        "start": 830,
        "temperature": 0,
        "text": " Okay. So, let me open up terminal.",
        "tokens": [
          50364,
          1033,
          13,
          407,
          11,
          718,
          385,
          1269,
          493,
          14709,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23084479111891526,
        "compression_ratio": 1.3567567567567567,
        "end": 835,
        "id": 197,
        "no_speech_prob": 0.0017273637931793928,
        "seek": 83000,
        "start": 832,
        "temperature": 0,
        "text": " I'm just trying to catch up to remember where I left off.",
        "tokens": [
          50464,
          286,
          478,
          445,
          1382,
          281,
          3745,
          493,
          281,
          1604,
          689,
          286,
          1411,
          766,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23084479111891526,
        "compression_ratio": 1.3567567567567567,
        "end": 839,
        "id": 198,
        "no_speech_prob": 0.0017273637931793928,
        "seek": 83000,
        "start": 835,
        "temperature": 0,
        "text": " And I should have watched the last video I made, which was two weeks ago.",
        "tokens": [
          50614,
          400,
          286,
          820,
          362,
          6337,
          264,
          1036,
          960,
          286,
          1027,
          11,
          597,
          390,
          732,
          3259,
          2057,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23084479111891526,
        "compression_ratio": 1.3567567567567567,
        "end": 842,
        "id": 199,
        "no_speech_prob": 0.0017273637931793928,
        "seek": 83000,
        "start": 839,
        "temperature": 0,
        "text": " But if I look at this example...",
        "tokens": [
          50814,
          583,
          498,
          286,
          574,
          412,
          341,
          1365,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.23084479111891526,
        "compression_ratio": 1.3567567567567567,
        "end": 854,
        "id": 200,
        "no_speech_prob": 0.0017273637931793928,
        "seek": 83000,
        "start": 850,
        "temperature": 0,
        "text": " Where am I? Oh, no. I want to be in desktop. Sorry.",
        "tokens": [
          51364,
          2305,
          669,
          286,
          30,
          876,
          11,
          572,
          13,
          286,
          528,
          281,
          312,
          294,
          14502,
          13,
          4919,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 857,
        "id": 201,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 855,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50414,
          21726,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 860,
        "id": 202,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 857,
        "temperature": 0,
        "text": " Trying to get to the right folder right now.",
        "tokens": [
          50514,
          20180,
          281,
          483,
          281,
          264,
          558,
          10820,
          558,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 863,
        "id": 203,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 860,
        "temperature": 0,
        "text": " And I'm going to API 2.",
        "tokens": [
          50664,
          400,
          286,
          478,
          516,
          281,
          9362,
          568,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 866,
        "id": 204,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 863,
        "temperature": 0,
        "text": " And I'm saying node server.",
        "tokens": [
          50814,
          400,
          286,
          478,
          1566,
          9984,
          7154,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 868,
        "id": 205,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 866,
        "temperature": 0,
        "text": " And I'm running the server.",
        "tokens": [
          50964,
          400,
          286,
          478,
          2614,
          264,
          7154,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 871,
        "id": 206,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 868,
        "temperature": 0,
        "text": " Did I talk about nodemon? I think I did. I'm going to run that.",
        "tokens": [
          51064,
          2589,
          286,
          751,
          466,
          9984,
          3317,
          30,
          286,
          519,
          286,
          630,
          13,
          286,
          478,
          516,
          281,
          1190,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 875,
        "id": 207,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 871,
        "temperature": 0,
        "text": " Okay. And now I'm going to bring up Chrome.",
        "tokens": [
          51214,
          1033,
          13,
          400,
          586,
          286,
          478,
          516,
          281,
          1565,
          493,
          15327,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 878,
        "id": 208,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 875,
        "temperature": 0,
        "text": " Localhost... I don't remember what port I'm running it on.",
        "tokens": [
          51414,
          22755,
          6037,
          485,
          286,
          500,
          380,
          1604,
          437,
          2436,
          286,
          478,
          2614,
          309,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 880,
        "id": 209,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 878,
        "temperature": 0,
        "text": " 3000.",
        "tokens": [
          51564,
          20984,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23365765697551225,
        "compression_ratio": 1.631578947368421,
        "end": 882,
        "id": 210,
        "no_speech_prob": 0.0065880268812179565,
        "seek": 85400,
        "start": 880,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51664,
          2425,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 886,
        "id": 211,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 883,
        "temperature": 0,
        "text": " The point of this is that...",
        "tokens": [
          50414,
          440,
          935,
          295,
          341,
          307,
          300,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 889,
        "id": 212,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 886,
        "temperature": 0,
        "text": " Okay. So, this is where we were last time.",
        "tokens": [
          50564,
          1033,
          13,
          407,
          11,
          341,
          307,
          689,
          321,
          645,
          1036,
          565,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 893,
        "id": 213,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 889,
        "temperature": 0,
        "text": " We're creating a sentiment analysis API.",
        "tokens": [
          50714,
          492,
          434,
          4084,
          257,
          16149,
          5215,
          9362,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 897,
        "id": 214,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 893,
        "temperature": 0,
        "text": " One of the things you can do with a sentiment analysis API",
        "tokens": [
          50914,
          1485,
          295,
          264,
          721,
          291,
          393,
          360,
          365,
          257,
          16149,
          5215,
          9362,
          51114
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 901,
        "id": 215,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 897,
        "temperature": 0,
        "text": " is add words to a quote-unquote database.",
        "tokens": [
          51114,
          307,
          909,
          2283,
          281,
          257,
          6513,
          12,
          409,
          25016,
          8149,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 904,
        "id": 216,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 901,
        "temperature": 0,
        "text": " Which is here.",
        "tokens": [
          51314,
          3013,
          307,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 907,
        "id": 217,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 904,
        "temperature": 0,
        "text": " Database is just like hard-coded in the code.",
        "tokens": [
          51464,
          40461,
          651,
          307,
          445,
          411,
          1152,
          12,
          66,
          12340,
          294,
          264,
          3089,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23835958753313338,
        "compression_ratio": 1.6294416243654823,
        "end": 911,
        "id": 218,
        "no_speech_prob": 0.002323131076991558,
        "seek": 88200,
        "start": 907,
        "temperature": 0,
        "text": " And so, if I try to add words to a database...",
        "tokens": [
          51614,
          400,
          370,
          11,
          498,
          286,
          853,
          281,
          909,
          2283,
          281,
          257,
          8149,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 913,
        "id": 219,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 911,
        "temperature": 0,
        "text": " If I try to add something...",
        "tokens": [
          50364,
          759,
          286,
          853,
          281,
          909,
          746,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 918,
        "id": 220,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 913,
        "temperature": 0,
        "text": " I'm going to add, for example, add rainbow 5.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          909,
          11,
          337,
          1365,
          11,
          909,
          18526,
          1025,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 923,
        "id": 221,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 918,
        "temperature": 0,
        "text": " This... I have now gone to... I'm just reviewing where I left off.",
        "tokens": [
          50714,
          639,
          485,
          286,
          362,
          586,
          2780,
          281,
          485,
          286,
          478,
          445,
          19576,
          689,
          286,
          1411,
          766,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 926,
        "id": 222,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 923,
        "temperature": 0,
        "text": " I've gone to this route. Add rainbow 5.",
        "tokens": [
          50964,
          286,
          600,
          2780,
          281,
          341,
          7955,
          13,
          5349,
          18526,
          1025,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 928,
        "id": 223,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 926,
        "temperature": 0,
        "text": " I get the parameters from that route.",
        "tokens": [
          51114,
          286,
          483,
          264,
          9834,
          490,
          300,
          7955,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 930,
        "id": 224,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 928,
        "temperature": 0,
        "text": " Which are rainbow and 5.",
        "tokens": [
          51214,
          3013,
          366,
          18526,
          293,
          1025,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 933,
        "id": 225,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 930,
        "temperature": 0,
        "text": " And if I look now in terminal...",
        "tokens": [
          51314,
          400,
          498,
          286,
          574,
          586,
          294,
          14709,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 936,
        "id": 226,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 933,
        "temperature": 0,
        "text": " Oh, I don't have any console logging going on.",
        "tokens": [
          51464,
          876,
          11,
          286,
          500,
          380,
          362,
          604,
          11076,
          27991,
          516,
          322,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2174184492656163,
        "compression_ratio": 1.6026200873362446,
        "end": 939,
        "id": 227,
        "no_speech_prob": 0.00844528991729021,
        "seek": 91100,
        "start": 936,
        "temperature": 0,
        "text": " It sends a message back that it was added.",
        "tokens": [
          51614,
          467,
          14790,
          257,
          3636,
          646,
          300,
          309,
          390,
          3869,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 943,
        "id": 228,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 939,
        "temperature": 0,
        "text": " And then I can also go to the route all.",
        "tokens": [
          50364,
          400,
          550,
          286,
          393,
          611,
          352,
          281,
          264,
          7955,
          439,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 947,
        "id": 229,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 943,
        "temperature": 0,
        "text": " And I can go to the route all.",
        "tokens": [
          50564,
          400,
          286,
          393,
          352,
          281,
          264,
          7955,
          439,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 950,
        "id": 230,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 947,
        "temperature": 0,
        "text": " And I can see...",
        "tokens": [
          50764,
          400,
          286,
          393,
          536,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 953,
        "id": 231,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 950,
        "temperature": 0,
        "text": " Oh, rainbow is in there. Sorry.",
        "tokens": [
          50914,
          876,
          11,
          18526,
          307,
          294,
          456,
          13,
          4919,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 955,
        "id": 232,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 953,
        "temperature": 0,
        "text": " And rainbow is already in there.",
        "tokens": [
          51064,
          400,
          18526,
          307,
          1217,
          294,
          456,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 956,
        "id": 233,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 955,
        "temperature": 0,
        "text": " As one of the ones.",
        "tokens": [
          51164,
          1018,
          472,
          295,
          264,
          2306,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 958,
        "id": 234,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 956,
        "temperature": 0,
        "text": " So, let me add something else.",
        "tokens": [
          51214,
          407,
          11,
          718,
          385,
          909,
          746,
          1646,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 961,
        "id": 235,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 958,
        "temperature": 0,
        "text": " Add... Right. I was using purple 3.",
        "tokens": [
          51314,
          5349,
          485,
          1779,
          13,
          286,
          390,
          1228,
          9656,
          805,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 964,
        "id": 236,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 961,
        "temperature": 0,
        "text": " That is now added. Let me go to all.",
        "tokens": [
          51464,
          663,
          307,
          586,
          3869,
          13,
          961,
          385,
          352,
          281,
          439,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 967,
        "id": 237,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 964,
        "temperature": 0,
        "text": " And I can see that I've added now purple to this list.",
        "tokens": [
          51614,
          400,
          286,
          393,
          536,
          300,
          286,
          600,
          3869,
          586,
          9656,
          281,
          341,
          1329,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22191330591837566,
        "compression_ratio": 1.775,
        "end": 968,
        "id": 238,
        "no_speech_prob": 0.010488261468708515,
        "seek": 93900,
        "start": 967,
        "temperature": 0,
        "text": " Great. That's working.",
        "tokens": [
          51764,
          3769,
          13,
          663,
          311,
          1364,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 970,
        "id": 239,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 968,
        "temperature": 0,
        "text": " And I also have a search route.",
        "tokens": [
          50364,
          400,
          286,
          611,
          362,
          257,
          3164,
          7955,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 973,
        "id": 240,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 970,
        "temperature": 0,
        "text": " If I look for kitten, not found.",
        "tokens": [
          50464,
          759,
          286,
          574,
          337,
          39696,
          11,
          406,
          1352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 979,
        "id": 241,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 973,
        "temperature": 0,
        "text": " But if I look for purple, it's found and I get the score.",
        "tokens": [
          50614,
          583,
          498,
          286,
          574,
          337,
          9656,
          11,
          309,
          311,
          1352,
          293,
          286,
          483,
          264,
          6175,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 982,
        "id": 242,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 979,
        "temperature": 0,
        "text": " Okay. So, this is what I'm doing.",
        "tokens": [
          50914,
          1033,
          13,
          407,
          11,
          341,
          307,
          437,
          286,
          478,
          884,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 985,
        "id": 243,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 982,
        "temperature": 0,
        "text": " I'm building a sentiment analysis API.",
        "tokens": [
          51064,
          286,
          478,
          2390,
          257,
          16149,
          5215,
          9362,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 988,
        "id": 244,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 985,
        "temperature": 0,
        "text": " Now, what are the other pieces of this that I need?",
        "tokens": [
          51214,
          823,
          11,
          437,
          366,
          264,
          661,
          3755,
          295,
          341,
          300,
          286,
          643,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 991,
        "id": 245,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 988,
        "temperature": 0,
        "text": " I want to do something about persistence.",
        "tokens": [
          51364,
          286,
          528,
          281,
          360,
          746,
          466,
          37617,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15833012420352144,
        "compression_ratio": 1.5406698564593302,
        "end": 994,
        "id": 246,
        "no_speech_prob": 0.010986341163516045,
        "seek": 96800,
        "start": 991,
        "temperature": 0,
        "text": " So, I want the data to be saved.",
        "tokens": [
          51514,
          407,
          11,
          286,
          528,
          264,
          1412,
          281,
          312,
          6624,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1001,
        "id": 247,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 995,
        "temperature": 0,
        "text": " So, I want to save the data to a JSON file every time a new word is added.",
        "tokens": [
          50414,
          407,
          11,
          286,
          528,
          281,
          3155,
          264,
          1412,
          281,
          257,
          31828,
          3991,
          633,
          565,
          257,
          777,
          1349,
          307,
          3869,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1004,
        "id": 248,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 1001,
        "temperature": 0,
        "text": " And then when the server restarts, it loads the JSON file.",
        "tokens": [
          50714,
          400,
          550,
          562,
          264,
          7154,
          1472,
          11814,
          11,
          309,
          12668,
          264,
          31828,
          3991,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1007,
        "id": 249,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 1004,
        "temperature": 0,
        "text": " Okay. So, that's one thing I want to do.",
        "tokens": [
          50864,
          1033,
          13,
          407,
          11,
          300,
          311,
          472,
          551,
          286,
          528,
          281,
          360,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1011,
        "id": 250,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 1007,
        "temperature": 0,
        "text": " Another thing I want to do is create a front end to interact with the API.",
        "tokens": [
          51014,
          3996,
          551,
          286,
          528,
          281,
          360,
          307,
          1884,
          257,
          1868,
          917,
          281,
          4648,
          365,
          264,
          9362,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1015,
        "id": 251,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 1011,
        "temperature": 0,
        "text": " As a way of just being able to see how it works.",
        "tokens": [
          51214,
          1018,
          257,
          636,
          295,
          445,
          885,
          1075,
          281,
          536,
          577,
          309,
          1985,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1019,
        "id": 252,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 1015,
        "temperature": 0,
        "text": " And see how you can interface with your own API that you made.",
        "tokens": [
          51414,
          400,
          536,
          577,
          291,
          393,
          9226,
          365,
          428,
          1065,
          9362,
          300,
          291,
          1027,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18067632641708642,
        "compression_ratio": 1.7066666666666668,
        "end": 1021,
        "id": 253,
        "no_speech_prob": 0.01150770764797926,
        "seek": 99400,
        "start": 1019,
        "temperature": 0,
        "text": " So, that's two things.",
        "tokens": [
          51614,
          407,
          11,
          300,
          311,
          732,
          721,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1026,
        "id": 254,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1021,
        "temperature": 0,
        "text": " And then I also, third thing, is I need to cover how to post to an API.",
        "tokens": [
          50364,
          400,
          550,
          286,
          611,
          11,
          2636,
          551,
          11,
          307,
          286,
          643,
          281,
          2060,
          577,
          281,
          2183,
          281,
          364,
          9362,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1028,
        "id": 255,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1026,
        "temperature": 0,
        "text": " The difference between a get request and a post request.",
        "tokens": [
          50614,
          440,
          2649,
          1296,
          257,
          483,
          5308,
          293,
          257,
          2183,
          5308,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1031,
        "id": 256,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1028,
        "temperature": 0,
        "text": " Let me see if I can get this camera working.",
        "tokens": [
          50714,
          961,
          385,
          536,
          498,
          286,
          393,
          483,
          341,
          2799,
          1364,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1033,
        "id": 257,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1031,
        "temperature": 0,
        "text": " Because I kind of feel like I want a diagram for that.",
        "tokens": [
          50864,
          1436,
          286,
          733,
          295,
          841,
          411,
          286,
          528,
          257,
          10686,
          337,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1035,
        "id": 258,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1033,
        "temperature": 0,
        "text": " Oh, that's promising.",
        "tokens": [
          50964,
          876,
          11,
          300,
          311,
          20257,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1037,
        "id": 259,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1035,
        "temperature": 0,
        "text": " I heard a click.",
        "tokens": [
          51064,
          286,
          2198,
          257,
          2052,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1042,
        "id": 260,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1037,
        "temperature": 0,
        "text": " So, I think, if you would just bear with me for a second.",
        "tokens": [
          51164,
          407,
          11,
          286,
          519,
          11,
          498,
          291,
          576,
          445,
          6155,
          365,
          385,
          337,
          257,
          1150,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1046,
        "id": 261,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1042,
        "temperature": 0,
        "text": " You're going to have to look at a blank screen for a minute.",
        "tokens": [
          51414,
          509,
          434,
          516,
          281,
          362,
          281,
          574,
          412,
          257,
          8247,
          2568,
          337,
          257,
          3456,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.162612548828125,
        "compression_ratio": 1.5522388059701493,
        "end": 1048,
        "id": 262,
        "no_speech_prob": 0.0120532913133502,
        "seek": 102100,
        "start": 1046,
        "temperature": 0,
        "text": " But I promise I'm still here.",
        "tokens": [
          51614,
          583,
          286,
          6228,
          286,
          478,
          920,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22844011942545572,
        "compression_ratio": 1.6470588235294117,
        "end": 1054,
        "id": 263,
        "no_speech_prob": 0.3240196108818054,
        "seek": 104800,
        "start": 1048,
        "temperature": 0,
        "text": " And I am now changing my view to see the preview.",
        "tokens": [
          50364,
          400,
          286,
          669,
          586,
          4473,
          452,
          1910,
          281,
          536,
          264,
          14281,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22844011942545572,
        "compression_ratio": 1.6470588235294117,
        "end": 1058,
        "id": 264,
        "no_speech_prob": 0.3240196108818054,
        "seek": 104800,
        "start": 1054,
        "temperature": 0,
        "text": " And then I am going to edit shot.",
        "tokens": [
          50664,
          400,
          550,
          286,
          669,
          516,
          281,
          8129,
          3347,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22844011942545572,
        "compression_ratio": 1.6470588235294117,
        "end": 1062,
        "id": 265,
        "no_speech_prob": 0.3240196108818054,
        "seek": 104800,
        "start": 1058,
        "temperature": 0,
        "text": " And I need to go to capture device 2.",
        "tokens": [
          50864,
          400,
          286,
          643,
          281,
          352,
          281,
          7983,
          4302,
          568,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22844011942545572,
        "compression_ratio": 1.6470588235294117,
        "end": 1066,
        "id": 266,
        "no_speech_prob": 0.3240196108818054,
        "seek": 104800,
        "start": 1062,
        "temperature": 0,
        "text": " And then I need to change this to 59.94.",
        "tokens": [
          51064,
          400,
          550,
          286,
          643,
          281,
          1319,
          341,
          281,
          24624,
          13,
          27032,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22844011942545572,
        "compression_ratio": 1.6470588235294117,
        "end": 1072,
        "id": 267,
        "no_speech_prob": 0.3240196108818054,
        "seek": 104800,
        "start": 1066,
        "temperature": 0,
        "text": " And then I also, this is the preview.",
        "tokens": [
          51264,
          400,
          550,
          286,
          611,
          11,
          341,
          307,
          264,
          14281,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22844011942545572,
        "compression_ratio": 1.6470588235294117,
        "end": 1074,
        "id": 268,
        "no_speech_prob": 0.3240196108818054,
        "seek": 104800,
        "start": 1072,
        "temperature": 0,
        "text": " I also need to, whoops.",
        "tokens": [
          51564,
          286,
          611,
          643,
          281,
          11,
          567,
          3370,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1077,
        "id": 269,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1075,
        "temperature": 0,
        "text": " I need to go to here.",
        "tokens": [
          50414,
          286,
          643,
          281,
          352,
          281,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1079,
        "id": 270,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1077,
        "temperature": 0,
        "text": " And zoom it in a little bit.",
        "tokens": [
          50514,
          400,
          8863,
          309,
          294,
          257,
          707,
          857,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1082,
        "id": 271,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1079,
        "temperature": 0,
        "text": " And do this.",
        "tokens": [
          50614,
          400,
          360,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1084,
        "id": 272,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1082,
        "temperature": 0,
        "text": " So that you can see.",
        "tokens": [
          50764,
          407,
          300,
          291,
          393,
          536,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1086,
        "id": 273,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1084,
        "temperature": 0,
        "text": " Let me zoom in a little bit more.",
        "tokens": [
          50864,
          961,
          385,
          8863,
          294,
          257,
          707,
          857,
          544,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1088,
        "id": 274,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1086,
        "temperature": 0,
        "text": " I swear this is going to be done in a second.",
        "tokens": [
          50964,
          286,
          11902,
          341,
          307,
          516,
          281,
          312,
          1096,
          294,
          257,
          1150,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1090,
        "id": 275,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1088,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1092,
        "id": 276,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1090,
        "temperature": 0,
        "text": " So, not my finest work.",
        "tokens": [
          51164,
          407,
          11,
          406,
          452,
          28141,
          589,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1095,
        "id": 277,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1092,
        "temperature": 0,
        "text": " But now you should have a whiteboard shot.",
        "tokens": [
          51264,
          583,
          586,
          291,
          820,
          362,
          257,
          2418,
          3787,
          3347,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1097,
        "id": 278,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1095,
        "temperature": 0,
        "text": " And now I'm only coming in one ear, right?",
        "tokens": [
          51414,
          400,
          586,
          286,
          478,
          787,
          1348,
          294,
          472,
          1273,
          11,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1099,
        "id": 279,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1097,
        "temperature": 0,
        "text": " So, I have to fix the audio for this.",
        "tokens": [
          51514,
          407,
          11,
          286,
          362,
          281,
          3191,
          264,
          6278,
          337,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1738901138305664,
        "compression_ratio": 1.5754716981132075,
        "end": 1102,
        "id": 280,
        "no_speech_prob": 0.09400033950805664,
        "seek": 107400,
        "start": 1099,
        "temperature": 0,
        "text": " This is really.",
        "tokens": [
          51614,
          639,
          307,
          534,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1106,
        "id": 281,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1102,
        "temperature": 0,
        "text": " So much setup time, which is really a problem.",
        "tokens": [
          50364,
          407,
          709,
          8657,
          565,
          11,
          597,
          307,
          534,
          257,
          1154,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1108,
        "id": 282,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1106,
        "temperature": 0,
        "text": " When.",
        "tokens": [
          50564,
          1133,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1110,
        "id": 283,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1108,
        "temperature": 0,
        "text": " Left.",
        "tokens": [
          50664,
          16405,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1113,
        "id": 284,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1110,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1117,
        "id": 285,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1113,
        "temperature": 0,
        "text": " Now, if I am over in the whiteboard, you should be able to hear me in both ears now.",
        "tokens": [
          50914,
          823,
          11,
          498,
          286,
          669,
          670,
          294,
          264,
          2418,
          3787,
          11,
          291,
          820,
          312,
          1075,
          281,
          1568,
          385,
          294,
          1293,
          8798,
          586,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1119,
        "id": 286,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1117,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1121,
        "id": 287,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1119,
        "temperature": 0,
        "text": " And I should be able to switch back and forth like this.",
        "tokens": [
          51214,
          400,
          286,
          820,
          312,
          1075,
          281,
          3679,
          646,
          293,
          5220,
          411,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1122,
        "id": 288,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1121,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1123,
        "id": 289,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1122,
        "temperature": 0,
        "text": " I am set up.",
        "tokens": [
          51364,
          286,
          669,
          992,
          493,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1125,
        "id": 290,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1123,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1127,
        "id": 291,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1125,
        "temperature": 0,
        "text": " So, let me look for my eraser.",
        "tokens": [
          51514,
          407,
          11,
          718,
          385,
          574,
          337,
          452,
          46018,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21352628198000465,
        "compression_ratio": 1.5393258426966292,
        "end": 1131,
        "id": 292,
        "no_speech_prob": 0.0005357784102670848,
        "seek": 110200,
        "start": 1127,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1910689493243614,
        "compression_ratio": 1.583756345177665,
        "end": 1133,
        "id": 293,
        "no_speech_prob": 0.002050696173682809,
        "seek": 113100,
        "start": 1131,
        "temperature": 0,
        "text": " So, this is my list.",
        "tokens": [
          50364,
          407,
          11,
          341,
          307,
          452,
          1329,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1910689493243614,
        "compression_ratio": 1.583756345177665,
        "end": 1140,
        "id": 294,
        "no_speech_prob": 0.002050696173682809,
        "seek": 113100,
        "start": 1133,
        "temperature": 0,
        "text": " So, I think maybe what might make sense to do first is talk about persistence.",
        "tokens": [
          50464,
          407,
          11,
          286,
          519,
          1310,
          437,
          1062,
          652,
          2020,
          281,
          360,
          700,
          307,
          751,
          466,
          37617,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1910689493243614,
        "compression_ratio": 1.583756345177665,
        "end": 1146,
        "id": 295,
        "no_speech_prob": 0.002050696173682809,
        "seek": 113100,
        "start": 1140,
        "temperature": 0,
        "text": " So, the very first tutorial that I'm going to add to that list today is persistence.",
        "tokens": [
          50814,
          407,
          11,
          264,
          588,
          700,
          7073,
          300,
          286,
          478,
          516,
          281,
          909,
          281,
          300,
          1329,
          965,
          307,
          37617,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1910689493243614,
        "compression_ratio": 1.583756345177665,
        "end": 1149,
        "id": 296,
        "no_speech_prob": 0.002050696173682809,
        "seek": 113100,
        "start": 1146,
        "temperature": 0,
        "text": " Meaning how to save data over time.",
        "tokens": [
          51114,
          19948,
          577,
          281,
          3155,
          1412,
          670,
          565,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1910689493243614,
        "compression_ratio": 1.583756345177665,
        "end": 1154,
        "id": 297,
        "no_speech_prob": 0.002050696173682809,
        "seek": 113100,
        "start": 1149,
        "temperature": 0,
        "text": " Now, what I want to do before I add this.",
        "tokens": [
          51264,
          823,
          11,
          437,
          286,
          528,
          281,
          360,
          949,
          286,
          909,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1910689493243614,
        "compression_ratio": 1.583756345177665,
        "end": 1158,
        "id": 298,
        "no_speech_prob": 0.002050696173682809,
        "seek": 113100,
        "start": 1154,
        "temperature": 0,
        "text": " Is I want to look at one of my existing examples.",
        "tokens": [
          51514,
          1119,
          286,
          528,
          281,
          574,
          412,
          472,
          295,
          452,
          6741,
          5110,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1162,
        "id": 299,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1158,
        "temperature": 0,
        "text": " Just to review in my head how I did it.",
        "tokens": [
          50364,
          1449,
          281,
          3131,
          294,
          452,
          1378,
          577,
          286,
          630,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1164,
        "id": 300,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1162,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50564,
          45263,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1169,
        "id": 301,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1164,
        "temperature": 0,
        "text": " So, I'm going to the GitHub repository for the class.",
        "tokens": [
          50664,
          407,
          11,
          286,
          478,
          516,
          281,
          264,
          23331,
          25841,
          337,
          264,
          1508,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1174,
        "id": 302,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1169,
        "temperature": 0,
        "text": " And everything in my brain is broken today.",
        "tokens": [
          50914,
          400,
          1203,
          294,
          452,
          3567,
          307,
          5463,
          965,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1176,
        "id": 303,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1174,
        "temperature": 0,
        "text": " This is me getting back into this.",
        "tokens": [
          51164,
          639,
          307,
          385,
          1242,
          646,
          666,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1181,
        "id": 304,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1176,
        "temperature": 0,
        "text": " I miss a week and I lose track of how everything works.",
        "tokens": [
          51264,
          286,
          1713,
          257,
          1243,
          293,
          286,
          3624,
          2837,
          295,
          577,
          1203,
          1985,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1942153588319436,
        "compression_ratio": 1.434065934065934,
        "end": 1184,
        "id": 305,
        "no_speech_prob": 0.109700046479702,
        "seek": 115800,
        "start": 1181,
        "temperature": 0,
        "text": " Go into my API examples.",
        "tokens": [
          51514,
          1037,
          666,
          452,
          9362,
          5110,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1188,
        "id": 306,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1184,
        "temperature": 0,
        "text": " Into, let's look at the spell check one.",
        "tokens": [
          50364,
          23373,
          11,
          718,
          311,
          574,
          412,
          264,
          9827,
          1520,
          472,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1189,
        "id": 307,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1188,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50564,
          883,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1192,
        "id": 308,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1189,
        "temperature": 0,
        "text": " Is this the one I want to look at?",
        "tokens": [
          50614,
          1119,
          341,
          264,
          472,
          286,
          528,
          281,
          574,
          412,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1194,
        "id": 309,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1192,
        "temperature": 0,
        "text": " Read file sync.",
        "tokens": [
          50764,
          17604,
          3991,
          20271,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1196,
        "id": 310,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1194,
        "temperature": 0,
        "text": " Yes, that's what I want.",
        "tokens": [
          50864,
          1079,
          11,
          300,
          311,
          437,
          286,
          528,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1198,
        "id": 311,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1196,
        "temperature": 0,
        "text": " And then save file.",
        "tokens": [
          50964,
          400,
          550,
          3155,
          3991,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1199,
        "id": 312,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1198,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1200,
        "id": 313,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1199,
        "temperature": 0,
        "text": " I don't actually need to look at this.",
        "tokens": [
          51114,
          286,
          500,
          380,
          767,
          643,
          281,
          574,
          412,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1202,
        "id": 314,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1200,
        "temperature": 0,
        "text": " I can add this on the fly.",
        "tokens": [
          51164,
          286,
          393,
          909,
          341,
          322,
          264,
          3603,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1205,
        "id": 315,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1202,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1208,
        "id": 316,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1205,
        "temperature": 0,
        "text": " And, okay.",
        "tokens": [
          51414,
          400,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18493040481416306,
        "compression_ratio": 1.5380116959064327,
        "end": 1211,
        "id": 317,
        "no_speech_prob": 0.19680176675319672,
        "seek": 118400,
        "start": 1208,
        "temperature": 0,
        "text": " So, I love seeing the chat going.",
        "tokens": [
          51564,
          407,
          11,
          286,
          959,
          2577,
          264,
          5081,
          516,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1214,
        "id": 318,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1211,
        "temperature": 0,
        "text": " And I love seeing that there are so many people here.",
        "tokens": [
          50364,
          400,
          286,
          959,
          2577,
          300,
          456,
          366,
          370,
          867,
          561,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1217,
        "id": 319,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1214,
        "temperature": 0,
        "text": " I'm going to just switch to a particular view.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          445,
          3679,
          281,
          257,
          1729,
          1910,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1222,
        "id": 320,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1217,
        "temperature": 0,
        "text": " So, I can see better who's there.",
        "tokens": [
          50664,
          407,
          11,
          286,
          393,
          536,
          1101,
          567,
          311,
          456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1224,
        "id": 321,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1222,
        "temperature": 0,
        "text": " And the camera went off.",
        "tokens": [
          50914,
          400,
          264,
          2799,
          1437,
          766,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1226,
        "id": 322,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1224,
        "temperature": 0,
        "text": " I will fix that.",
        "tokens": [
          51014,
          286,
          486,
          3191,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1235,
        "id": 323,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1226,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1236,
        "id": 324,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1235,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1237,
        "id": 325,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1236,
        "temperature": 0,
        "text": " So, here we go.",
        "tokens": [
          51614,
          407,
          11,
          510,
          321,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17289500517003675,
        "compression_ratio": 1.4727272727272727,
        "end": 1239,
        "id": 326,
        "no_speech_prob": 0.23645125329494476,
        "seek": 121100,
        "start": 1237,
        "temperature": 0,
        "text": " I'm going to try to pick this back up.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          853,
          281,
          1888,
          341,
          646,
          493,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20621644997898536,
        "compression_ratio": 1.4848484848484849,
        "end": 1244,
        "id": 327,
        "no_speech_prob": 0.10229986906051636,
        "seek": 123900,
        "start": 1239,
        "temperature": 0,
        "text": " And I'm going to start with, have this screen over.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          722,
          365,
          11,
          362,
          341,
          2568,
          670,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20621644997898536,
        "compression_ratio": 1.4848484848484849,
        "end": 1254,
        "id": 328,
        "no_speech_prob": 0.10229986906051636,
        "seek": 123900,
        "start": 1244,
        "temperature": 0,
        "text": " And I'm going to talk about how to save data to a database.",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          751,
          466,
          577,
          281,
          3155,
          1412,
          281,
          257,
          8149,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20621644997898536,
        "compression_ratio": 1.4848484848484849,
        "end": 1256,
        "id": 329,
        "no_speech_prob": 0.10229986906051636,
        "seek": 123900,
        "start": 1254,
        "temperature": 0,
        "text": " Except I'm not really going to use a database yet.",
        "tokens": [
          51114,
          16192,
          286,
          478,
          406,
          534,
          516,
          281,
          764,
          257,
          8149,
          1939,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20621644997898536,
        "compression_ratio": 1.4848484848484849,
        "end": 1257,
        "id": 330,
        "no_speech_prob": 0.10229986906051636,
        "seek": 123900,
        "start": 1256,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20621644997898536,
        "compression_ratio": 1.4848484848484849,
        "end": 1259,
        "id": 331,
        "no_speech_prob": 0.10229986906051636,
        "seek": 123900,
        "start": 1257,
        "temperature": 0,
        "text": " So, here we go.",
        "tokens": [
          51264,
          407,
          11,
          510,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20621644997898536,
        "compression_ratio": 1.4848484848484849,
        "end": 1264,
        "id": 332,
        "no_speech_prob": 0.10229986906051636,
        "seek": 123900,
        "start": 1259,
        "temperature": 0,
        "text": " This will be, so, for those of you who might be new, cancel.",
        "tokens": [
          51364,
          639,
          486,
          312,
          11,
          370,
          11,
          337,
          729,
          295,
          291,
          567,
          1062,
          312,
          777,
          11,
          10373,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1273,
        "id": 333,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1265,
        "temperature": 0,
        "text": " What I do with these live streams is I have a lot of wasted time in them while I get set up and figure out what to do.",
        "tokens": [
          50414,
          708,
          286,
          360,
          365,
          613,
          1621,
          15842,
          307,
          286,
          362,
          257,
          688,
          295,
          19496,
          565,
          294,
          552,
          1339,
          286,
          483,
          992,
          493,
          293,
          2573,
          484,
          437,
          281,
          360,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1276,
        "id": 334,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1273,
        "temperature": 0,
        "text": " And then after the live stream is over, the full thing gets archived.",
        "tokens": [
          50814,
          400,
          550,
          934,
          264,
          1621,
          4309,
          307,
          670,
          11,
          264,
          1577,
          551,
          2170,
          3912,
          3194,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1285,
        "id": 335,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1276,
        "temperature": 0,
        "text": " But I edit, I don't do this, Mathieu, who gratefully does this work really wonderfully, edits together portions of it as tutorials.",
        "tokens": [
          50964,
          583,
          286,
          8129,
          11,
          286,
          500,
          380,
          360,
          341,
          11,
          15776,
          19347,
          11,
          567,
          46214,
          2277,
          775,
          341,
          589,
          534,
          38917,
          11,
          41752,
          1214,
          25070,
          295,
          309,
          382,
          17616,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1286,
        "id": 336,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1285,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1288,
        "id": 337,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1286,
        "temperature": 0,
        "text": " So, thanks for being here, everybody.",
        "tokens": [
          51464,
          407,
          11,
          3231,
          337,
          885,
          510,
          11,
          2201,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1289,
        "id": 338,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1288,
        "temperature": 0,
        "text": " Thanks for bearing with me.",
        "tokens": [
          51564,
          2561,
          337,
          17350,
          365,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2048489810856244,
        "compression_ratio": 1.6308724832214765,
        "end": 1293,
        "id": 339,
        "no_speech_prob": 0.5735460519790649,
        "seek": 126400,
        "start": 1289,
        "temperature": 0,
        "text": " I'm about, you know, at this point, like 40 minutes later than I really meant to get started.",
        "tokens": [
          51614,
          286,
          478,
          466,
          11,
          291,
          458,
          11,
          412,
          341,
          935,
          11,
          411,
          3356,
          2077,
          1780,
          813,
          286,
          534,
          4140,
          281,
          483,
          1409,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1294,
        "id": 340,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1293,
        "temperature": 0,
        "text": " But here we are.",
        "tokens": [
          50364,
          583,
          510,
          321,
          366,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1296,
        "id": 341,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1294,
        "temperature": 0,
        "text": " I've got about 45 minutes left.",
        "tokens": [
          50414,
          286,
          600,
          658,
          466,
          6905,
          2077,
          1411,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1301,
        "id": 342,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1296,
        "temperature": 0,
        "text": " And I'm going to just, hopefully, something nice will happen in this session and just keep going.",
        "tokens": [
          50514,
          400,
          286,
          478,
          516,
          281,
          445,
          11,
          4696,
          11,
          746,
          1481,
          486,
          1051,
          294,
          341,
          5481,
          293,
          445,
          1066,
          516,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1302,
        "id": 343,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1301,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1306,
        "id": 344,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1302,
        "temperature": 0,
        "text": " So, I'm trying to, okay.",
        "tokens": [
          50814,
          407,
          11,
          286,
          478,
          1382,
          281,
          11,
          1392,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1308,
        "id": 345,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1306,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51014,
          1057,
          558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1309,
        "id": 346,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1308,
        "temperature": 0,
        "text": " Welcome.",
        "tokens": [
          51114,
          4027,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1314,
        "id": 347,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1309,
        "temperature": 0,
        "text": " So, this video continues the series about building your own API in Node.",
        "tokens": [
          51164,
          407,
          11,
          341,
          960,
          6515,
          264,
          2638,
          466,
          2390,
          428,
          1065,
          9362,
          294,
          38640,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1643772640743771,
        "compression_ratio": 1.548,
        "end": 1321,
        "id": 348,
        "no_speech_prob": 0.012430880218744278,
        "seek": 129300,
        "start": 1314,
        "temperature": 0,
        "text": " And in this video, what I want to do is add a very important, very key piece of functionality, which is persistence.",
        "tokens": [
          51414,
          400,
          294,
          341,
          960,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          909,
          257,
          588,
          1021,
          11,
          588,
          2141,
          2522,
          295,
          14980,
          11,
          597,
          307,
          37617,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20297466475388098,
        "compression_ratio": 1.63135593220339,
        "end": 1330,
        "id": 349,
        "no_speech_prob": 0.00013341958401724696,
        "seek": 132100,
        "start": 1321,
        "temperature": 0,
        "text": " So, right now, this particular API that I'm building in Node, if you recall, in the code, at the top of the code, just has hard-coded, essentially, a database.",
        "tokens": [
          50364,
          407,
          11,
          558,
          586,
          11,
          341,
          1729,
          9362,
          300,
          286,
          478,
          2390,
          294,
          38640,
          11,
          498,
          291,
          9901,
          11,
          294,
          264,
          3089,
          11,
          412,
          264,
          1192,
          295,
          264,
          3089,
          11,
          445,
          575,
          1152,
          12,
          66,
          12340,
          11,
          4476,
          11,
          257,
          8149,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20297466475388098,
        "compression_ratio": 1.63135593220339,
        "end": 1333,
        "id": 350,
        "no_speech_prob": 0.00013341958401724696,
        "seek": 132100,
        "start": 1330,
        "temperature": 0,
        "text": " A database of words and their sentiment score.",
        "tokens": [
          50814,
          316,
          8149,
          295,
          2283,
          293,
          641,
          16149,
          6175,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20297466475388098,
        "compression_ratio": 1.63135593220339,
        "end": 1337,
        "id": 351,
        "no_speech_prob": 0.00013341958401724696,
        "seek": 132100,
        "start": 1333,
        "temperature": 0,
        "text": " Rainbow 5, Unicorn 3, Doom negative 3, Gloom negative 2.",
        "tokens": [
          50964,
          29477,
          1025,
          11,
          1156,
          23115,
          805,
          11,
          30168,
          3671,
          805,
          11,
          10786,
          298,
          3671,
          568,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20297466475388098,
        "compression_ratio": 1.63135593220339,
        "end": 1341,
        "id": 352,
        "no_speech_prob": 0.00013341958401724696,
        "seek": 132100,
        "start": 1337,
        "temperature": 0,
        "text": " So, they're in, but they're, and I can add, and I can add to it.",
        "tokens": [
          51164,
          407,
          11,
          436,
          434,
          294,
          11,
          457,
          436,
          434,
          11,
          293,
          286,
          393,
          909,
          11,
          293,
          286,
          393,
          909,
          281,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20297466475388098,
        "compression_ratio": 1.63135593220339,
        "end": 1347,
        "id": 353,
        "no_speech_prob": 0.00013341958401724696,
        "seek": 132100,
        "start": 1341,
        "temperature": 0,
        "text": " So, I can go to a particular route and say add purple 4.",
        "tokens": [
          51364,
          407,
          11,
          286,
          393,
          352,
          281,
          257,
          1729,
          7955,
          293,
          584,
          909,
          9656,
          1017,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14262869834899902,
        "compression_ratio": 1.6153846153846154,
        "end": 1351,
        "id": 354,
        "no_speech_prob": 0.060084324330091476,
        "seek": 134700,
        "start": 1347,
        "temperature": 0,
        "text": " And then if I go back to all, I'll see that purple is there.",
        "tokens": [
          50364,
          400,
          550,
          498,
          286,
          352,
          646,
          281,
          439,
          11,
          286,
          603,
          536,
          300,
          9656,
          307,
          456,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.14262869834899902,
        "compression_ratio": 1.6153846153846154,
        "end": 1358,
        "id": 355,
        "no_speech_prob": 0.060084324330091476,
        "seek": 134700,
        "start": 1351,
        "temperature": 0,
        "text": " But as soon as I go to terminal, quit, and relaunch the server, and go back, purple is gone.",
        "tokens": [
          50564,
          583,
          382,
          2321,
          382,
          286,
          352,
          281,
          14709,
          11,
          10366,
          11,
          293,
          5195,
          1680,
          264,
          7154,
          11,
          293,
          352,
          646,
          11,
          9656,
          307,
          2780,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14262869834899902,
        "compression_ratio": 1.6153846153846154,
        "end": 1364,
        "id": 356,
        "no_speech_prob": 0.060084324330091476,
        "seek": 134700,
        "start": 1358,
        "temperature": 0,
        "text": " So, I need some mechanism by which I can save the data forever.",
        "tokens": [
          50914,
          407,
          11,
          286,
          643,
          512,
          7513,
          538,
          597,
          286,
          393,
          3155,
          264,
          1412,
          5680,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.14262869834899902,
        "compression_ratio": 1.6153846153846154,
        "end": 1368,
        "id": 357,
        "no_speech_prob": 0.060084324330091476,
        "seek": 134700,
        "start": 1364,
        "temperature": 0,
        "text": " Whether or not I'm running the server, quitting the server, not just in memory.",
        "tokens": [
          51214,
          8503,
          420,
          406,
          286,
          478,
          2614,
          264,
          7154,
          11,
          42789,
          264,
          7154,
          11,
          406,
          445,
          294,
          4675,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14262869834899902,
        "compression_ratio": 1.6153846153846154,
        "end": 1371,
        "id": 358,
        "no_speech_prob": 0.060084324330091476,
        "seek": 134700,
        "start": 1368,
        "temperature": 0,
        "text": " And the way that this is done is typically with a database.",
        "tokens": [
          51414,
          400,
          264,
          636,
          300,
          341,
          307,
          1096,
          307,
          5850,
          365,
          257,
          8149,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1767094930013021,
        "compression_ratio": 1.5714285714285714,
        "end": 1382,
        "id": 359,
        "no_speech_prob": 0.03846396505832672,
        "seek": 137100,
        "start": 1371,
        "temperature": 0,
        "text": " Now, a database is a big topic, and I expect that in the, what I imagine, future amount of time that I have in my life to make videos, I'll get into a lot of different facets of it.",
        "tokens": [
          50364,
          823,
          11,
          257,
          8149,
          307,
          257,
          955,
          4829,
          11,
          293,
          286,
          2066,
          300,
          294,
          264,
          11,
          437,
          286,
          3811,
          11,
          2027,
          2372,
          295,
          565,
          300,
          286,
          362,
          294,
          452,
          993,
          281,
          652,
          2145,
          11,
          286,
          603,
          483,
          666,
          257,
          688,
          295,
          819,
          49752,
          295,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1767094930013021,
        "compression_ratio": 1.5714285714285714,
        "end": 1390,
        "id": 360,
        "no_speech_prob": 0.03846396505832672,
        "seek": 137100,
        "start": 1382,
        "temperature": 0,
        "text": " So, what do we have so far is we have just like data in memory.",
        "tokens": [
          50914,
          407,
          11,
          437,
          360,
          321,
          362,
          370,
          1400,
          307,
          321,
          362,
          445,
          411,
          1412,
          294,
          4675,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1767094930013021,
        "compression_ratio": 1.5714285714285714,
        "end": 1392,
        "id": 361,
        "no_speech_prob": 0.03846396505832672,
        "seek": 137100,
        "start": 1390,
        "temperature": 0,
        "text": " That's what I have so far.",
        "tokens": [
          51314,
          663,
          311,
          437,
          286,
          362,
          370,
          1400,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1767094930013021,
        "compression_ratio": 1.5714285714285714,
        "end": 1396,
        "id": 362,
        "no_speech_prob": 0.03846396505832672,
        "seek": 137100,
        "start": 1392,
        "temperature": 0,
        "text": " Quit the program, the data is lost.",
        "tokens": [
          51414,
          50139,
          264,
          1461,
          11,
          264,
          1412,
          307,
          2731,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16631722650608094,
        "compression_ratio": 1.7520661157024793,
        "end": 1405,
        "id": 363,
        "no_speech_prob": 0.02635408192873001,
        "seek": 139600,
        "start": 1396,
        "temperature": 0,
        "text": " One quick and dirty way to save data, to have data persist over time, is simply to save to a text file.",
        "tokens": [
          50364,
          1485,
          1702,
          293,
          9360,
          636,
          281,
          3155,
          1412,
          11,
          281,
          362,
          1412,
          13233,
          670,
          565,
          11,
          307,
          2935,
          281,
          3155,
          281,
          257,
          2487,
          3991,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16631722650608094,
        "compression_ratio": 1.7520661157024793,
        "end": 1409,
        "id": 364,
        "no_speech_prob": 0.02635408192873001,
        "seek": 139600,
        "start": 1405,
        "temperature": 0,
        "text": " It's easy to forget that you could just have a text file as a database, right?",
        "tokens": [
          50814,
          467,
          311,
          1858,
          281,
          2870,
          300,
          291,
          727,
          445,
          362,
          257,
          2487,
          3991,
          382,
          257,
          8149,
          11,
          558,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.16631722650608094,
        "compression_ratio": 1.7520661157024793,
        "end": 1412,
        "id": 365,
        "no_speech_prob": 0.02635408192873001,
        "seek": 139600,
        "start": 1409,
        "temperature": 0,
        "text": " I can have a text file that has a list of words in it.",
        "tokens": [
          51014,
          286,
          393,
          362,
          257,
          2487,
          3991,
          300,
          575,
          257,
          1329,
          295,
          2283,
          294,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16631722650608094,
        "compression_ratio": 1.7520661157024793,
        "end": 1414,
        "id": 366,
        "no_speech_prob": 0.02635408192873001,
        "seek": 139600,
        "start": 1412,
        "temperature": 0,
        "text": " Word, comma, score, word, comma, score.",
        "tokens": [
          51164,
          8725,
          11,
          22117,
          11,
          6175,
          11,
          1349,
          11,
          22117,
          11,
          6175,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16631722650608094,
        "compression_ratio": 1.7520661157024793,
        "end": 1419,
        "id": 367,
        "no_speech_prob": 0.02635408192873001,
        "seek": 139600,
        "start": 1414,
        "temperature": 0,
        "text": " And I could just save all this stuff and load that when I run the program.",
        "tokens": [
          51264,
          400,
          286,
          727,
          445,
          3155,
          439,
          341,
          1507,
          293,
          3677,
          300,
          562,
          286,
          1190,
          264,
          1461,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16631722650608094,
        "compression_ratio": 1.7520661157024793,
        "end": 1424,
        "id": 368,
        "no_speech_prob": 0.02635408192873001,
        "seek": 139600,
        "start": 1419,
        "temperature": 0,
        "text": " A way to make this even easier is to actually save this to a JSON file.",
        "tokens": [
          51514,
          316,
          636,
          281,
          652,
          341,
          754,
          3571,
          307,
          281,
          767,
          3155,
          341,
          281,
          257,
          31828,
          3991,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1427,
        "id": 369,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1424,
        "temperature": 0,
        "text": " JSON standing for JavaScript Object Notation.",
        "tokens": [
          50364,
          31828,
          4877,
          337,
          15778,
          24753,
          1726,
          399,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1432,
        "id": 370,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1427,
        "temperature": 0,
        "text": " So, the stuff that's right here, did I switch back and forth?",
        "tokens": [
          50514,
          407,
          11,
          264,
          1507,
          300,
          311,
          558,
          510,
          11,
          630,
          286,
          3679,
          646,
          293,
          5220,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1433,
        "id": 371,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1432,
        "temperature": 0,
        "text": " I hope I did.",
        "tokens": [
          50764,
          286,
          1454,
          286,
          630,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1435,
        "id": 372,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1433,
        "temperature": 0,
        "text": " Was I in the right screen?",
        "tokens": [
          50814,
          3027,
          286,
          294,
          264,
          558,
          2568,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1438,
        "id": 373,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1435,
        "temperature": 0,
        "text": " Somebody in the chat, somebody would have told me if I wasn't in the right screen.",
        "tokens": [
          50914,
          13463,
          294,
          264,
          5081,
          11,
          2618,
          576,
          362,
          1907,
          385,
          498,
          286,
          2067,
          380,
          294,
          264,
          558,
          2568,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1441,
        "id": 374,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1438,
        "temperature": 0,
        "text": " Matt, you're ahead of the score.",
        "tokens": [
          51064,
          7397,
          11,
          291,
          434,
          2286,
          295,
          264,
          262,
          12352,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1449,
        "id": 375,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1441,
        "temperature": 0,
        "text": " I forgot, I had my momentum, I lost.",
        "tokens": [
          51214,
          286,
          5298,
          11,
          286,
          632,
          452,
          11244,
          11,
          286,
          2731,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.30161329712530577,
        "compression_ratio": 1.5023696682464456,
        "end": 1450,
        "id": 376,
        "no_speech_prob": 0.14803674817085266,
        "seek": 142400,
        "start": 1449,
        "temperature": 0,
        "text": " Yeah, all good.",
        "tokens": [
          51614,
          865,
          11,
          439,
          665,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20059763730227292,
        "compression_ratio": 1.579185520361991,
        "end": 1460,
        "id": 377,
        "no_speech_prob": 0.06560207158327103,
        "seek": 145000,
        "start": 1450,
        "temperature": 0,
        "text": " This data, if you look at this, this is JavaScript Object Notation.",
        "tokens": [
          50364,
          639,
          1412,
          11,
          498,
          291,
          574,
          412,
          341,
          11,
          341,
          307,
          15778,
          24753,
          1726,
          399,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20059763730227292,
        "compression_ratio": 1.579185520361991,
        "end": 1465,
        "id": 378,
        "no_speech_prob": 0.06560207158327103,
        "seek": 145000,
        "start": 1460,
        "temperature": 0,
        "text": " This syntax of having a variable full of key value pairs, that's JSON.",
        "tokens": [
          50864,
          639,
          28431,
          295,
          1419,
          257,
          7006,
          1577,
          295,
          2141,
          2158,
          15494,
          11,
          300,
          311,
          31828,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20059763730227292,
        "compression_ratio": 1.579185520361991,
        "end": 1474,
        "id": 379,
        "no_speech_prob": 0.06560207158327103,
        "seek": 145000,
        "start": 1465,
        "temperature": 0,
        "text": " So, I can actually, nice option is just save the data to a JSON file, and then load that JSON file every time the server starts.",
        "tokens": [
          51114,
          407,
          11,
          286,
          393,
          767,
          11,
          1481,
          3614,
          307,
          445,
          3155,
          264,
          1412,
          281,
          257,
          31828,
          3991,
          11,
          293,
          550,
          3677,
          300,
          31828,
          3991,
          633,
          565,
          264,
          7154,
          3719,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20059763730227292,
        "compression_ratio": 1.579185520361991,
        "end": 1478,
        "id": 380,
        "no_speech_prob": 0.06560207158327103,
        "seek": 145000,
        "start": 1474,
        "temperature": 0,
        "text": " So, this is actually the way that I'm going to do it in this particular tutorial.",
        "tokens": [
          51564,
          407,
          11,
          341,
          307,
          767,
          264,
          636,
          300,
          286,
          478,
          516,
          281,
          360,
          309,
          294,
          341,
          1729,
          7073,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1480,
        "id": 381,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1478,
        "temperature": 0,
        "text": " But this is very limiting.",
        "tokens": [
          50364,
          583,
          341,
          307,
          588,
          22083,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1485,
        "id": 382,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1480,
        "temperature": 0,
        "text": " First of all, if I have a massive amount of data, huge data set, this isn't going to work very well.",
        "tokens": [
          50464,
          2386,
          295,
          439,
          11,
          498,
          286,
          362,
          257,
          5994,
          2372,
          295,
          1412,
          11,
          2603,
          1412,
          992,
          11,
          341,
          1943,
          380,
          516,
          281,
          589,
          588,
          731,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1488,
        "id": 383,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1485,
        "temperature": 0,
        "text": " I have to load this giant text file and save this giant text file all the time.",
        "tokens": [
          50714,
          286,
          362,
          281,
          3677,
          341,
          7410,
          2487,
          3991,
          293,
          3155,
          341,
          7410,
          2487,
          3991,
          439,
          264,
          565,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1490,
        "id": 384,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1488,
        "temperature": 0,
        "text": " That's not going to work very well.",
        "tokens": [
          50864,
          663,
          311,
          406,
          516,
          281,
          589,
          588,
          731,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1495,
        "id": 385,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1490,
        "temperature": 0,
        "text": " If I care about security, and I have private data, just having it all sitting there in a big text file,",
        "tokens": [
          50964,
          759,
          286,
          1127,
          466,
          3825,
          11,
          293,
          286,
          362,
          4551,
          1412,
          11,
          445,
          1419,
          309,
          439,
          3798,
          456,
          294,
          257,
          955,
          2487,
          3991,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1499,
        "id": 386,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1495,
        "temperature": 0,
        "text": " text file full of everybody's logins and passwords, that's not going to work very well.",
        "tokens": [
          51214,
          2487,
          3991,
          1577,
          295,
          2201,
          311,
          3565,
          1292,
          293,
          33149,
          11,
          300,
          311,
          406,
          516,
          281,
          589,
          588,
          731,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1502,
        "id": 387,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1499,
        "temperature": 0,
        "text": " So, there are a lot of reasons why this isn't a particular great solution.",
        "tokens": [
          51414,
          407,
          11,
          456,
          366,
          257,
          688,
          295,
          4112,
          983,
          341,
          1943,
          380,
          257,
          1729,
          869,
          3827,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19851480471860072,
        "compression_ratio": 1.9113924050632911,
        "end": 1507,
        "id": 388,
        "no_speech_prob": 0.28136107325553894,
        "seek": 147800,
        "start": 1502,
        "temperature": 0,
        "text": " But for a quick and dirty project, for understanding how things work, playing around in Node,",
        "tokens": [
          51564,
          583,
          337,
          257,
          1702,
          293,
          9360,
          1716,
          11,
          337,
          3701,
          577,
          721,
          589,
          11,
          2433,
          926,
          294,
          38640,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1509,
        "id": 389,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1507,
        "temperature": 0,
        "text": " I think this is going to be a great demonstration.",
        "tokens": [
          50364,
          286,
          519,
          341,
          307,
          516,
          281,
          312,
          257,
          869,
          16520,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1516,
        "id": 390,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1509,
        "temperature": 0,
        "text": " But I will be making videos in the future that look at other database systems, namely one called Firebase.",
        "tokens": [
          50464,
          583,
          286,
          486,
          312,
          1455,
          2145,
          294,
          264,
          2027,
          300,
          574,
          412,
          661,
          8149,
          3652,
          11,
          20926,
          472,
          1219,
          35173,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1521,
        "id": 391,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1516,
        "temperature": 0,
        "text": " Firebase is something that's referred to, it's a Google product, database as service,",
        "tokens": [
          50814,
          35173,
          307,
          746,
          300,
          311,
          10839,
          281,
          11,
          309,
          311,
          257,
          3329,
          1674,
          11,
          8149,
          382,
          2643,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1524,
        "id": 392,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1521,
        "temperature": 0,
        "text": " meaning you don't have to have your own server.",
        "tokens": [
          51064,
          3620,
          291,
          500,
          380,
          362,
          281,
          362,
          428,
          1065,
          7154,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1527,
        "id": 393,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1524,
        "temperature": 0,
        "text": " You're just a program and you're keeping track of stuff, and you're like,",
        "tokens": [
          51214,
          509,
          434,
          445,
          257,
          1461,
          293,
          291,
          434,
          5145,
          2837,
          295,
          1507,
          11,
          293,
          291,
          434,
          411,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1531,
        "id": 394,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1527,
        "temperature": 0,
        "text": " hey Firebase, can you save this for me? I'll ask for it later.",
        "tokens": [
          51364,
          4177,
          35173,
          11,
          393,
          291,
          3155,
          341,
          337,
          385,
          30,
          286,
          603,
          1029,
          337,
          309,
          1780,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2252748918163684,
        "compression_ratio": 1.6996587030716723,
        "end": 1533,
        "id": 395,
        "no_speech_prob": 0.020021526142954826,
        "seek": 150700,
        "start": 1531,
        "temperature": 0,
        "text": " And then later you come back and say, Firebase, can I have that data?",
        "tokens": [
          51564,
          400,
          550,
          1780,
          291,
          808,
          646,
          293,
          584,
          11,
          35173,
          11,
          393,
          286,
          362,
          300,
          1412,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1536,
        "id": 396,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1533,
        "temperature": 0,
        "text": " So, you get an account, you sign up, you send the data, you ask for data,",
        "tokens": [
          50364,
          407,
          11,
          291,
          483,
          364,
          2696,
          11,
          291,
          1465,
          493,
          11,
          291,
          2845,
          264,
          1412,
          11,
          291,
          1029,
          337,
          1412,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1539,
        "id": 397,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1536,
        "temperature": 0,
        "text": " and it has a lot of sophisticated features.",
        "tokens": [
          50514,
          293,
          309,
          575,
          257,
          688,
          295,
          16950,
          4122,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1541,
        "id": 398,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1539,
        "temperature": 0,
        "text": " So, that's certainly one thing you can do.",
        "tokens": [
          50664,
          407,
          11,
          300,
          311,
          3297,
          472,
          551,
          291,
          393,
          360,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1545,
        "id": 399,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1541,
        "temperature": 0,
        "text": " And then, of course, you could use a quote-unquote real database or some type of database system.",
        "tokens": [
          50764,
          400,
          550,
          11,
          295,
          1164,
          11,
          291,
          727,
          764,
          257,
          6513,
          12,
          409,
          25016,
          957,
          8149,
          420,
          512,
          2010,
          295,
          8149,
          1185,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1548,
        "id": 400,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1545,
        "temperature": 0,
        "text": " There are other databases as service products, by the way, so you can find those.",
        "tokens": [
          50964,
          821,
          366,
          661,
          22380,
          382,
          2643,
          3383,
          11,
          538,
          264,
          636,
          11,
          370,
          291,
          393,
          915,
          729,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1558,
        "id": 401,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1548,
        "temperature": 0,
        "text": " But you could use something like CouchDB or MongoDB or another database that I actually like,",
        "tokens": [
          51114,
          583,
          291,
          727,
          764,
          746,
          411,
          383,
          2220,
          27735,
          420,
          48380,
          27735,
          420,
          1071,
          8149,
          300,
          286,
          767,
          411,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.22293876705313087,
        "compression_ratio": 1.7208480565371025,
        "end": 1560,
        "id": 402,
        "no_speech_prob": 0.4415467381477356,
        "seek": 153300,
        "start": 1558,
        "temperature": 0,
        "text": " which is very simple, which is called Nedb, I think.",
        "tokens": [
          51614,
          597,
          307,
          588,
          2199,
          11,
          597,
          307,
          1219,
          426,
          292,
          65,
          11,
          286,
          519,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2111642538023389,
        "compression_ratio": 1.5819397993311037,
        "end": 1566,
        "id": 403,
        "no_speech_prob": 0.033587146550416946,
        "seek": 156000,
        "start": 1560,
        "temperature": 0,
        "text": " So, these are all database systems that you can use with Node or other server-side programming frameworks.",
        "tokens": [
          50364,
          407,
          11,
          613,
          366,
          439,
          8149,
          3652,
          300,
          291,
          393,
          764,
          365,
          38640,
          420,
          661,
          7154,
          12,
          1812,
          9410,
          29834,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2111642538023389,
        "compression_ratio": 1.5819397993311037,
        "end": 1571,
        "id": 404,
        "no_speech_prob": 0.033587146550416946,
        "seek": 156000,
        "start": 1566,
        "temperature": 0,
        "text": " So, at some point, somebody remind me, hey, definitely I have a whole bunch of examples already for Firebase,",
        "tokens": [
          50664,
          407,
          11,
          412,
          512,
          935,
          11,
          2618,
          4160,
          385,
          11,
          4177,
          11,
          2138,
          286,
          362,
          257,
          1379,
          3840,
          295,
          5110,
          1217,
          337,
          35173,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2111642538023389,
        "compression_ratio": 1.5819397993311037,
        "end": 1576,
        "id": 405,
        "no_speech_prob": 0.033587146550416946,
        "seek": 156000,
        "start": 1571,
        "temperature": 0,
        "text": " so I intend to do that, but I'd love to look into this kind of stuff and make some examples with that as well.",
        "tokens": [
          50914,
          370,
          286,
          19759,
          281,
          360,
          300,
          11,
          457,
          286,
          1116,
          959,
          281,
          574,
          666,
          341,
          733,
          295,
          1507,
          293,
          652,
          512,
          5110,
          365,
          300,
          382,
          731,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2111642538023389,
        "compression_ratio": 1.5819397993311037,
        "end": 1581,
        "id": 406,
        "no_speech_prob": 0.033587146550416946,
        "seek": 156000,
        "start": 1576,
        "temperature": 0,
        "text": " But in this particular video, let's look at even just what saving a JSON file gets us.",
        "tokens": [
          51164,
          583,
          294,
          341,
          1729,
          960,
          11,
          718,
          311,
          574,
          412,
          754,
          445,
          437,
          6816,
          257,
          31828,
          3991,
          2170,
          505,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2111642538023389,
        "compression_ratio": 1.5819397993311037,
        "end": 1586,
        "id": 407,
        "no_speech_prob": 0.033587146550416946,
        "seek": 156000,
        "start": 1581,
        "temperature": 0,
        "text": " Okay, so back over here, I'm going to go back to the code.",
        "tokens": [
          51414,
          1033,
          11,
          370,
          646,
          670,
          510,
          11,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          3089,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1795582264027697,
        "compression_ratio": 1.6040609137055837,
        "end": 1593,
        "id": 408,
        "no_speech_prob": 0.09946347773075104,
        "seek": 158600,
        "start": 1587,
        "temperature": 0,
        "text": " And the first thing I want to do is let's just actually make that JSON file ourself.",
        "tokens": [
          50414,
          400,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          307,
          718,
          311,
          445,
          767,
          652,
          300,
          31828,
          3991,
          527,
          927,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1795582264027697,
        "compression_ratio": 1.6040609137055837,
        "end": 1598,
        "id": 409,
        "no_speech_prob": 0.09946347773075104,
        "seek": 158600,
        "start": 1593,
        "temperature": 0,
        "text": " So, right here, I'm going to, in my Node project, where my server code is,",
        "tokens": [
          50714,
          407,
          11,
          558,
          510,
          11,
          286,
          478,
          516,
          281,
          11,
          294,
          452,
          38640,
          1716,
          11,
          689,
          452,
          7154,
          3089,
          307,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1795582264027697,
        "compression_ratio": 1.6040609137055837,
        "end": 1603,
        "id": 410,
        "no_speech_prob": 0.09946347773075104,
        "seek": 158600,
        "start": 1598,
        "temperature": 0,
        "text": " I'm just going to create a new file, and I'm going to call it words.json.",
        "tokens": [
          50964,
          286,
          478,
          445,
          516,
          281,
          1884,
          257,
          777,
          3991,
          11,
          293,
          286,
          478,
          516,
          281,
          818,
          309,
          2283,
          13,
          73,
          3015,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1795582264027697,
        "compression_ratio": 1.6040609137055837,
        "end": 1612,
        "id": 411,
        "no_speech_prob": 0.09946347773075104,
        "seek": 158600,
        "start": 1603,
        "temperature": 0,
        "text": " And in that file, instead of having this in the code, I'm just going to take this,",
        "tokens": [
          51214,
          400,
          294,
          300,
          3991,
          11,
          2602,
          295,
          1419,
          341,
          294,
          264,
          3089,
          11,
          286,
          478,
          445,
          516,
          281,
          747,
          341,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.17217156867019268,
        "compression_ratio": 1.6991525423728813,
        "end": 1618,
        "id": 412,
        "no_speech_prob": 0.003884396282956004,
        "seek": 161200,
        "start": 1613,
        "temperature": 0,
        "text": " and I'm going to comment this out, and I'm going to put this into words.json.",
        "tokens": [
          50414,
          293,
          286,
          478,
          516,
          281,
          2871,
          341,
          484,
          11,
          293,
          286,
          478,
          516,
          281,
          829,
          341,
          666,
          2283,
          13,
          73,
          3015,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17217156867019268,
        "compression_ratio": 1.6991525423728813,
        "end": 1624,
        "id": 413,
        "no_speech_prob": 0.003884396282956004,
        "seek": 161200,
        "start": 1618,
        "temperature": 0,
        "text": " So, here is now a JSON file with the initial data that I want for my program to start with.",
        "tokens": [
          50664,
          407,
          11,
          510,
          307,
          586,
          257,
          31828,
          3991,
          365,
          264,
          5883,
          1412,
          300,
          286,
          528,
          337,
          452,
          1461,
          281,
          722,
          365,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17217156867019268,
        "compression_ratio": 1.6991525423728813,
        "end": 1632,
        "id": 414,
        "no_speech_prob": 0.003884396282956004,
        "seek": 161200,
        "start": 1624,
        "temperature": 0,
        "text": " So, now what I want to do in the program is, instead of having var words equal the hard-coded data,",
        "tokens": [
          50964,
          407,
          11,
          586,
          437,
          286,
          528,
          281,
          360,
          294,
          264,
          1461,
          307,
          11,
          2602,
          295,
          1419,
          1374,
          2283,
          2681,
          264,
          1152,
          12,
          66,
          12340,
          1412,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17217156867019268,
        "compression_ratio": 1.6991525423728813,
        "end": 1634,
        "id": 415,
        "no_speech_prob": 0.003884396282956004,
        "seek": 161200,
        "start": 1632,
        "temperature": 0,
        "text": " I want to just load from the file.",
        "tokens": [
          51364,
          286,
          528,
          281,
          445,
          3677,
          490,
          264,
          3991,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17217156867019268,
        "compression_ratio": 1.6991525423728813,
        "end": 1638,
        "id": 416,
        "no_speech_prob": 0.003884396282956004,
        "seek": 161200,
        "start": 1634,
        "temperature": 0,
        "text": " I want to do something like, you know, if I were in client-side p5 land, I would just say, like,",
        "tokens": [
          51464,
          286,
          528,
          281,
          360,
          746,
          411,
          11,
          291,
          458,
          11,
          498,
          286,
          645,
          294,
          6423,
          12,
          1812,
          280,
          20,
          2117,
          11,
          286,
          576,
          445,
          584,
          11,
          411,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1641,
        "id": 417,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1638,
        "temperature": 0,
        "text": " loadJSON words.json.",
        "tokens": [
          50364,
          3677,
          41,
          10388,
          2283,
          13,
          73,
          3015,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1644,
        "id": 418,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1641,
        "temperature": 0,
        "text": " Right? I want just to load whatever's in that file and stick it in words.",
        "tokens": [
          50514,
          1779,
          30,
          286,
          528,
          445,
          281,
          3677,
          2035,
          311,
          294,
          300,
          3991,
          293,
          2897,
          309,
          294,
          2283,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1647,
        "id": 419,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1644,
        "temperature": 0,
        "text": " But this is not Node code. This is p5 code.",
        "tokens": [
          50664,
          583,
          341,
          307,
          406,
          38640,
          3089,
          13,
          639,
          307,
          280,
          20,
          3089,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1649,
        "id": 420,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1647,
        "temperature": 0,
        "text": " So, I need a different set of syntax for that.",
        "tokens": [
          50814,
          407,
          11,
          286,
          643,
          257,
          819,
          992,
          295,
          28431,
          337,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1656,
        "id": 421,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1649,
        "temperature": 0,
        "text": " And the package that I'm going to use, node package file, is called filesystemfs.",
        "tokens": [
          50914,
          400,
          264,
          7372,
          300,
          286,
          478,
          516,
          281,
          764,
          11,
          9984,
          7372,
          3991,
          11,
          307,
          1219,
          7098,
          9321,
          16883,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1662,
        "id": 422,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1656,
        "temperature": 0,
        "text": " So, if I come here to the filesystem package, I want to look for the document.",
        "tokens": [
          51264,
          407,
          11,
          498,
          286,
          808,
          510,
          281,
          264,
          7098,
          9321,
          7372,
          11,
          286,
          528,
          281,
          574,
          337,
          264,
          4166,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21738203640641837,
        "compression_ratio": 1.596638655462185,
        "end": 1663,
        "id": 423,
        "no_speech_prob": 0.040844760835170746,
        "seek": 163800,
        "start": 1662,
        "temperature": 0,
        "text": " Well, this is good enough for me.",
        "tokens": [
          51564,
          1042,
          11,
          341,
          307,
          665,
          1547,
          337,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1668,
        "id": 424,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1663,
        "temperature": 0,
        "text": " You can see there are lots of functions for writing a file, writefilesync.",
        "tokens": [
          50364,
          509,
          393,
          536,
          456,
          366,
          3195,
          295,
          6828,
          337,
          3579,
          257,
          3991,
          11,
          2464,
          69,
          4680,
          34015,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1671,
        "id": 425,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1668,
        "temperature": 0,
        "text": " We're going to have to talk about that, writefile versus writefilesync.",
        "tokens": [
          50614,
          492,
          434,
          516,
          281,
          362,
          281,
          751,
          466,
          300,
          11,
          2464,
          69,
          794,
          5717,
          2464,
          69,
          4680,
          34015,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1675,
        "id": 426,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1671,
        "temperature": 0,
        "text": " And what I'm looking for is really readfile.",
        "tokens": [
          50764,
          400,
          437,
          286,
          478,
          1237,
          337,
          307,
          534,
          1401,
          69,
          794,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1677,
        "id": 427,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1675,
        "temperature": 0,
        "text": " Readfile.",
        "tokens": [
          50964,
          17604,
          69,
          794,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1680,
        "id": 428,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1677,
        "temperature": 0,
        "text": " Oh, there it is.",
        "tokens": [
          51064,
          876,
          11,
          456,
          309,
          307,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1682,
        "id": 429,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1680,
        "temperature": 0,
        "text": " Oh, you know what? I'm in the wrong package.",
        "tokens": [
          51214,
          876,
          11,
          291,
          458,
          437,
          30,
          286,
          478,
          294,
          264,
          2085,
          7372,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1685,
        "id": 430,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1682,
        "temperature": 0,
        "text": " I'm in the file-system package.",
        "tokens": [
          51314,
          286,
          478,
          294,
          264,
          3991,
          12,
          28215,
          7372,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1688,
        "id": 431,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1685,
        "temperature": 0,
        "text": " The package I want to be in is actually just called fs.",
        "tokens": [
          51464,
          440,
          7372,
          286,
          528,
          281,
          312,
          294,
          307,
          767,
          445,
          1219,
          283,
          82,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16907158493995667,
        "compression_ratio": 1.6808510638297873,
        "end": 1690,
        "id": 432,
        "no_speech_prob": 0.08756040781736374,
        "seek": 166300,
        "start": 1688,
        "temperature": 0,
        "text": " I don't know if it's the same thing or not.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          264,
          912,
          551,
          420,
          406,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1693,
        "id": 433,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1690,
        "temperature": 0,
        "text": " Oh, well, time out.",
        "tokens": [
          50364,
          876,
          11,
          731,
          11,
          565,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1698,
        "id": 434,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1693,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          50514,
          31973,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1699,
        "id": 435,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1698,
        "temperature": 0,
        "text": " This is interesting to me.",
        "tokens": [
          50764,
          639,
          307,
          1880,
          281,
          385,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1702,
        "id": 436,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1699,
        "temperature": 0,
        "text": " Is it no longer called fs? That's what I've always used.",
        "tokens": [
          50814,
          1119,
          309,
          572,
          2854,
          1219,
          283,
          82,
          30,
          663,
          311,
          437,
          286,
          600,
          1009,
          1143,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1705,
        "id": 437,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1702,
        "temperature": 0,
        "text": " Is it called filesystem now?",
        "tokens": [
          50964,
          1119,
          309,
          1219,
          7098,
          9321,
          586,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1707,
        "id": 438,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1705,
        "temperature": 0,
        "text": " File extend node fs origin.",
        "tokens": [
          51114,
          26196,
          10101,
          9984,
          283,
          82,
          4957,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1708,
        "id": 439,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1707,
        "temperature": 0,
        "text": " Like, what's going on here?",
        "tokens": [
          51214,
          1743,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1712,
        "id": 440,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1708,
        "temperature": 0,
        "text": " Does somebody know what I'm talking about?",
        "tokens": [
          51264,
          4402,
          2618,
          458,
          437,
          286,
          478,
          1417,
          466,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1714,
        "id": 441,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1712,
        "temperature": 0,
        "text": " This is a different, let me look.",
        "tokens": [
          51464,
          639,
          307,
          257,
          819,
          11,
          718,
          385,
          574,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1716,
        "id": 442,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1714,
        "temperature": 0,
        "text": " Node fs package.",
        "tokens": [
          51564,
          38640,
          283,
          82,
          7372,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1890915941309046,
        "compression_ratio": 1.5213270142180095,
        "end": 1719,
        "id": 443,
        "no_speech_prob": 0.023689156398177147,
        "seek": 169000,
        "start": 1716,
        "temperature": 0,
        "text": " This is going to be edited out.",
        "tokens": [
          51664,
          639,
          307,
          516,
          281,
          312,
          23016,
          484,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1721,
        "id": 444,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1719,
        "temperature": 0,
        "text": " This is where I want to be.",
        "tokens": [
          50364,
          639,
          307,
          689,
          286,
          528,
          281,
          312,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1724,
        "id": 445,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1721,
        "temperature": 0,
        "text": " I was in the wrong documentation page.",
        "tokens": [
          50464,
          286,
          390,
          294,
          264,
          2085,
          14333,
          3028,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1726,
        "id": 446,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1724,
        "temperature": 0,
        "text": " Let me back up and start over.",
        "tokens": [
          50614,
          961,
          385,
          646,
          493,
          293,
          722,
          670,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1729,
        "id": 447,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1726,
        "temperature": 0,
        "text": " Because I don't want to use a separate, yeah, yeah, yeah, yeah.",
        "tokens": [
          50714,
          1436,
          286,
          500,
          380,
          528,
          281,
          764,
          257,
          4994,
          11,
          1338,
          11,
          1338,
          11,
          1338,
          11,
          1338,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1731,
        "id": 448,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1729,
        "temperature": 0,
        "text": " I want the official node.js.",
        "tokens": [
          50864,
          286,
          528,
          264,
          4783,
          9984,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1734,
        "id": 449,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1731,
        "temperature": 0,
        "text": " So I don't know where to go back to,",
        "tokens": [
          50964,
          407,
          286,
          500,
          380,
          458,
          689,
          281,
          352,
          646,
          281,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1736,
        "id": 450,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1734,
        "temperature": 0,
        "text": " but I think this can get stitched back together.",
        "tokens": [
          51114,
          457,
          286,
          519,
          341,
          393,
          483,
          48992,
          646,
          1214,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1738,
        "id": 451,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1736,
        "temperature": 0,
        "text": " Thank you, everyone in the chat.",
        "tokens": [
          51214,
          1044,
          291,
          11,
          1518,
          294,
          264,
          5081,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1740,
        "id": 452,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1738,
        "temperature": 0,
        "text": " I've got it now.",
        "tokens": [
          51314,
          286,
          600,
          658,
          309,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1743,
        "id": 453,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1740,
        "temperature": 0,
        "text": " So I'm going to look for, okay.",
        "tokens": [
          51414,
          407,
          286,
          478,
          516,
          281,
          574,
          337,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16294457362248346,
        "compression_ratio": 1.7339055793991416,
        "end": 1746,
        "id": 454,
        "no_speech_prob": 0.004264608025550842,
        "seek": 171900,
        "start": 1743,
        "temperature": 0,
        "text": " I think this can get spliced back in somehow.",
        "tokens": [
          51564,
          286,
          519,
          341,
          393,
          483,
          4732,
          4233,
          646,
          294,
          6063,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1752,
        "id": 455,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1746,
        "temperature": 0,
        "text": " So to read and write to files, I need to look into, oh, right.",
        "tokens": [
          50364,
          407,
          281,
          1401,
          293,
          2464,
          281,
          7098,
          11,
          286,
          643,
          281,
          574,
          666,
          11,
          1954,
          11,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1758,
        "id": 456,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1752,
        "temperature": 0,
        "text": " I was saying I can't use this p5.js code.",
        "tokens": [
          50664,
          286,
          390,
          1566,
          286,
          393,
          380,
          764,
          341,
          280,
          20,
          13,
          25530,
          3089,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1760,
        "id": 457,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1758,
        "temperature": 0,
        "text": " So how do I do that in node?",
        "tokens": [
          50964,
          407,
          577,
          360,
          286,
          360,
          300,
          294,
          9984,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1762,
        "id": 458,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1760,
        "temperature": 0,
        "text": " Well, what I need to use is the fs module.",
        "tokens": [
          51064,
          1042,
          11,
          437,
          286,
          643,
          281,
          764,
          307,
          264,
          283,
          82,
          10088,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1766,
        "id": 459,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1762,
        "temperature": 0,
        "text": " So fs node, node.",
        "tokens": [
          51164,
          407,
          283,
          82,
          9984,
          11,
          9984,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1768,
        "id": 460,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1766,
        "temperature": 0,
        "text": " I'm just going to Google fs and node.",
        "tokens": [
          51364,
          286,
          478,
          445,
          516,
          281,
          3329,
          283,
          82,
          293,
          9984,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1772,
        "id": 461,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1768,
        "temperature": 0,
        "text": " And here I'm going to get the documentation for the file system API,",
        "tokens": [
          51464,
          400,
          510,
          286,
          478,
          516,
          281,
          483,
          264,
          14333,
          337,
          264,
          3991,
          1185,
          9362,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1773,
        "id": 462,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1772,
        "temperature": 0,
        "text": " which is built in part of node.",
        "tokens": [
          51664,
          597,
          307,
          3094,
          294,
          644,
          295,
          9984,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1767662593296596,
        "compression_ratio": 1.5864978902953586,
        "end": 1775,
        "id": 463,
        "no_speech_prob": 0.0020829502027481794,
        "seek": 174600,
        "start": 1773,
        "temperature": 0,
        "text": " It's not an extra thing I have to install.",
        "tokens": [
          51714,
          467,
          311,
          406,
          364,
          2857,
          551,
          286,
          362,
          281,
          3625,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1777,
        "id": 464,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1775,
        "temperature": 0,
        "text": " So this is the documentation for it.",
        "tokens": [
          50364,
          407,
          341,
          307,
          264,
          14333,
          337,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1779,
        "id": 465,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1777,
        "temperature": 0,
        "text": " There's a lot, a lot of functions.",
        "tokens": [
          50464,
          821,
          311,
          257,
          688,
          11,
          257,
          688,
          295,
          6828,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1782,
        "id": 466,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1779,
        "temperature": 0,
        "text": " What I'm looking for is one called read file and right here.",
        "tokens": [
          50564,
          708,
          286,
          478,
          1237,
          337,
          307,
          472,
          1219,
          1401,
          3991,
          293,
          558,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1788,
        "id": 467,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1782,
        "temperature": 0,
        "text": " So you can see, first of all, there's fs.readfile and fs.readfilesync.",
        "tokens": [
          50714,
          407,
          291,
          393,
          536,
          11,
          700,
          295,
          439,
          11,
          456,
          311,
          283,
          82,
          13,
          2538,
          69,
          794,
          293,
          283,
          82,
          13,
          2538,
          69,
          4680,
          34015,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1791,
        "id": 468,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1788,
        "temperature": 0,
        "text": " So why would I use one versus the other?",
        "tokens": [
          51014,
          407,
          983,
          576,
          286,
          764,
          472,
          5717,
          264,
          661,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1793,
        "id": 469,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1791,
        "temperature": 0,
        "text": " This is something I definitely want to talk about.",
        "tokens": [
          51164,
          639,
          307,
          746,
          286,
          2138,
          528,
          281,
          751,
          466,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1797,
        "id": 470,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1793,
        "temperature": 0,
        "text": " But let's just at first, and actually I'm going to start with using readfilesync.",
        "tokens": [
          51264,
          583,
          718,
          311,
          445,
          412,
          700,
          11,
          293,
          767,
          286,
          478,
          516,
          281,
          722,
          365,
          1228,
          1401,
          69,
          4680,
          34015,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1803,
        "id": 471,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1797,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to say var fs equals require fs.",
        "tokens": [
          51464,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          1374,
          283,
          82,
          6915,
          3651,
          283,
          82,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14360801487752836,
        "compression_ratio": 1.737037037037037,
        "end": 1804,
        "id": 472,
        "no_speech_prob": 0.0025508743710815907,
        "seek": 177500,
        "start": 1803,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          51764,
          286,
          519,
          300,
          311,
          558,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1807,
        "id": 473,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1804,
        "temperature": 0,
        "text": " This is like importing the file system package.",
        "tokens": [
          50364,
          639,
          307,
          411,
          43866,
          264,
          3991,
          1185,
          7372,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1808,
        "id": 474,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1807,
        "temperature": 0,
        "text": " It's built in as part of node.",
        "tokens": [
          50514,
          467,
          311,
          3094,
          294,
          382,
          644,
          295,
          9984,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1812,
        "id": 475,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1808,
        "temperature": 0,
        "text": " I don't have to install it, but I do have to reference it in an import or require statement.",
        "tokens": [
          50564,
          286,
          500,
          380,
          362,
          281,
          3625,
          309,
          11,
          457,
          286,
          360,
          362,
          281,
          6408,
          309,
          294,
          364,
          974,
          420,
          3651,
          5629,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1819,
        "id": 476,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1812,
        "temperature": 0,
        "text": " And then I want to say words equals fs.readfilesync words.json.",
        "tokens": [
          50764,
          400,
          550,
          286,
          528,
          281,
          584,
          2283,
          6915,
          283,
          82,
          13,
          2538,
          69,
          4680,
          34015,
          2283,
          13,
          73,
          3015,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1821,
        "id": 477,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1819,
        "temperature": 0,
        "text": " And let's just see.",
        "tokens": [
          51114,
          400,
          718,
          311,
          445,
          536,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1824,
        "id": 478,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1821,
        "temperature": 0,
        "text": " And then I'm going to say console.log words.",
        "tokens": [
          51214,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          2283,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1827,
        "id": 479,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1824,
        "temperature": 0,
        "text": " Let's see what's happening here.",
        "tokens": [
          51364,
          961,
          311,
          536,
          437,
          311,
          2737,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1828,
        "id": 480,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1827,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          51514,
          2438,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1830,
        "id": 481,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1828,
        "temperature": 0,
        "text": " So it runs and look, I read the file.",
        "tokens": [
          51564,
          407,
          309,
          6676,
          293,
          574,
          11,
          286,
          1401,
          264,
          3991,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1831,
        "id": 482,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1830,
        "temperature": 0,
        "text": " There's the file.",
        "tokens": [
          51664,
          821,
          311,
          264,
          3991,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1832,
        "id": 483,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1831,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51714,
          10246,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16747014985667716,
        "compression_ratio": 1.6823529411764706,
        "end": 1833,
        "id": 484,
        "no_speech_prob": 0.001573106274008751,
        "seek": 180400,
        "start": 1832,
        "temperature": 0,
        "text": " There's my contents.",
        "tokens": [
          51764,
          821,
          311,
          452,
          15768,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1834,
        "id": 485,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1833,
        "temperature": 0,
        "text": " What is that?",
        "tokens": [
          50364,
          708,
          307,
          300,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1839,
        "id": 486,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1834,
        "temperature": 0,
        "text": " So one thing you have to realize is the node file system package is just reading the raw data files",
        "tokens": [
          50414,
          407,
          472,
          551,
          291,
          362,
          281,
          4325,
          307,
          264,
          9984,
          3991,
          1185,
          7372,
          307,
          445,
          3760,
          264,
          8936,
          1412,
          7098,
          50664
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1840,
        "id": 487,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1839,
        "temperature": 0,
        "text": " and writing the raw data out.",
        "tokens": [
          50664,
          293,
          3579,
          264,
          8936,
          1412,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1843,
        "id": 488,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1840,
        "temperature": 0,
        "text": " It doesn't know, oh, I want this to be like JSON and all of that.",
        "tokens": [
          50714,
          467,
          1177,
          380,
          458,
          11,
          1954,
          11,
          286,
          528,
          341,
          281,
          312,
          411,
          31828,
          293,
          439,
          295,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1850,
        "id": 489,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1843,
        "temperature": 0,
        "text": " So if I have that raw data from the file, but I actually want it to be JavaScript and JavaScript object,",
        "tokens": [
          50864,
          407,
          498,
          286,
          362,
          300,
          8936,
          1412,
          490,
          264,
          3991,
          11,
          457,
          286,
          767,
          528,
          309,
          281,
          312,
          15778,
          293,
          15778,
          2657,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1851,
        "id": 490,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1850,
        "temperature": 0,
        "text": " I need to parse it.",
        "tokens": [
          51214,
          286,
          643,
          281,
          48377,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1853,
        "id": 491,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1851,
        "temperature": 0,
        "text": " And there's a quick and easy way of doing that.",
        "tokens": [
          51264,
          400,
          456,
          311,
          257,
          1702,
          293,
          1858,
          636,
          295,
          884,
          300,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1858,
        "id": 492,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1853,
        "temperature": 0,
        "text": " So actually what I want to do is I'm going to say, I'm just going to say var data equals that.",
        "tokens": [
          51364,
          407,
          767,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          1374,
          1412,
          6915,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1684234873453776,
        "compression_ratio": 1.9042553191489362,
        "end": 1862,
        "id": 493,
        "no_speech_prob": 0.010818314738571644,
        "seek": 183300,
        "start": 1858,
        "temperature": 0,
        "text": " And then I'm going to say var words equals JSON parse data.",
        "tokens": [
          51614,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          1374,
          2283,
          6915,
          31828,
          48377,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1866,
        "id": 494,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1862,
        "temperature": 0,
        "text": " So this is something you're going to see once I'm using local files.",
        "tokens": [
          50364,
          407,
          341,
          307,
          746,
          291,
          434,
          516,
          281,
          536,
          1564,
          286,
          478,
          1228,
          2654,
          7098,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1870,
        "id": 495,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1866,
        "temperature": 0,
        "text": " When I want to read a file, I need to interpret it as JSON.",
        "tokens": [
          50564,
          1133,
          286,
          528,
          281,
          1401,
          257,
          3991,
          11,
          286,
          643,
          281,
          7302,
          309,
          382,
          31828,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1875,
        "id": 496,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1870,
        "temperature": 0,
        "text": " When I have a JavaScript, I need to interpret it as a JavaScript object before I can use it.",
        "tokens": [
          50764,
          1133,
          286,
          362,
          257,
          15778,
          11,
          286,
          643,
          281,
          7302,
          309,
          382,
          257,
          15778,
          2657,
          949,
          286,
          393,
          764,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1878,
        "id": 497,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1875,
        "temperature": 0,
        "text": " When I have a JavaScript object and I want to save it to the file,",
        "tokens": [
          51014,
          1133,
          286,
          362,
          257,
          15778,
          2657,
          293,
          286,
          528,
          281,
          3155,
          309,
          281,
          264,
          3991,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1881,
        "id": 498,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1878,
        "temperature": 0,
        "text": " I need to convert it to just plain old text and then save it to the file.",
        "tokens": [
          51164,
          286,
          643,
          281,
          7620,
          309,
          281,
          445,
          11121,
          1331,
          2487,
          293,
          550,
          3155,
          309,
          281,
          264,
          3991,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1883,
        "id": 499,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1881,
        "temperature": 0,
        "text": " So let's look how that works now.",
        "tokens": [
          51314,
          407,
          718,
          311,
          574,
          577,
          300,
          1985,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1884,
        "id": 500,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1883,
        "temperature": 0,
        "text": " And you can see, there we go.",
        "tokens": [
          51414,
          400,
          291,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.12172737988558682,
        "compression_ratio": 1.8943089430894309,
        "end": 1887,
        "id": 501,
        "no_speech_prob": 0.0039453813806176186,
        "seek": 186200,
        "start": 1884,
        "temperature": 0,
        "text": " So now my server is reading that stuff.",
        "tokens": [
          51464,
          407,
          586,
          452,
          7154,
          307,
          3760,
          300,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16589843680005556,
        "compression_ratio": 1.641350210970464,
        "end": 1892,
        "id": 502,
        "no_speech_prob": 0.010327860713005066,
        "seek": 188700,
        "start": 1887,
        "temperature": 0,
        "text": " So we've got step one in that everything should work as it did before.",
        "tokens": [
          50364,
          407,
          321,
          600,
          658,
          1823,
          472,
          294,
          300,
          1203,
          820,
          589,
          382,
          309,
          630,
          949,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16589843680005556,
        "compression_ratio": 1.641350210970464,
        "end": 1896,
        "id": 503,
        "no_speech_prob": 0.010327860713005066,
        "seek": 188700,
        "start": 1892,
        "temperature": 0,
        "text": " All, and I could add something, but I'm still going to have the problem.",
        "tokens": [
          50614,
          1057,
          11,
          293,
          286,
          727,
          909,
          746,
          11,
          457,
          286,
          478,
          920,
          516,
          281,
          362,
          264,
          1154,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16589843680005556,
        "compression_ratio": 1.641350210970464,
        "end": 1901,
        "id": 504,
        "no_speech_prob": 0.010327860713005066,
        "seek": 188700,
        "start": 1896,
        "temperature": 0,
        "text": " As soon as I quit the server and relaunch it, anything that I've added will be gone.",
        "tokens": [
          50814,
          1018,
          2321,
          382,
          286,
          10366,
          264,
          7154,
          293,
          5195,
          1680,
          309,
          11,
          1340,
          300,
          286,
          600,
          3869,
          486,
          312,
          2780,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16589843680005556,
        "compression_ratio": 1.641350210970464,
        "end": 1904,
        "id": 505,
        "no_speech_prob": 0.010327860713005066,
        "seek": 188700,
        "start": 1901,
        "temperature": 0,
        "text": " So how do I now have persistence?",
        "tokens": [
          51064,
          407,
          577,
          360,
          286,
          586,
          362,
          37617,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.16589843680005556,
        "compression_ratio": 1.641350210970464,
        "end": 1909,
        "id": 506,
        "no_speech_prob": 0.010327860713005066,
        "seek": 188700,
        "start": 1904,
        "temperature": 0,
        "text": " Where in my code do I want to save data to the file itself?",
        "tokens": [
          51214,
          2305,
          294,
          452,
          3089,
          360,
          286,
          528,
          281,
          3155,
          1412,
          281,
          264,
          3991,
          2564,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.16589843680005556,
        "compression_ratio": 1.641350210970464,
        "end": 1913,
        "id": 507,
        "no_speech_prob": 0.010327860713005066,
        "seek": 188700,
        "start": 1909,
        "temperature": 0,
        "text": " Well, I want to do that any time I add something new to this list.",
        "tokens": [
          51464,
          1042,
          11,
          286,
          528,
          281,
          360,
          300,
          604,
          565,
          286,
          909,
          746,
          777,
          281,
          341,
          1329,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1915,
        "id": 508,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1913,
        "temperature": 0,
        "text": " And if I go back to the server program,",
        "tokens": [
          50364,
          400,
          498,
          286,
          352,
          646,
          281,
          264,
          7154,
          1461,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1921,
        "id": 509,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1915,
        "temperature": 0,
        "text": " the only time I add something new to the list is right here under add words, add word.",
        "tokens": [
          50464,
          264,
          787,
          565,
          286,
          909,
          746,
          777,
          281,
          264,
          1329,
          307,
          558,
          510,
          833,
          909,
          2283,
          11,
          909,
          1349,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1924,
        "id": 510,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1921,
        "temperature": 0,
        "text": " So this is where I want to save data.",
        "tokens": [
          50764,
          407,
          341,
          307,
          689,
          286,
          528,
          281,
          3155,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1927,
        "id": 511,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1924,
        "temperature": 0,
        "text": " Now this brings me to another important point, which I glossed over,",
        "tokens": [
          50914,
          823,
          341,
          5607,
          385,
          281,
          1071,
          1021,
          935,
          11,
          597,
          286,
          19574,
          292,
          670,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1930,
        "id": 512,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1927,
        "temperature": 0,
        "text": " which I will come over here to discuss for a second.",
        "tokens": [
          51064,
          597,
          286,
          486,
          808,
          670,
          510,
          281,
          2248,
          337,
          257,
          1150,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1936,
        "id": 513,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1930,
        "temperature": 0,
        "text": " Sync versus no sync.",
        "tokens": [
          51214,
          26155,
          66,
          5717,
          572,
          20271,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20436631035558955,
        "compression_ratio": 1.6009389671361502,
        "end": 1941,
        "id": 514,
        "no_speech_prob": 0.09137970209121704,
        "seek": 191300,
        "start": 1936,
        "temperature": 0,
        "text": " So there are both read file sync.",
        "tokens": [
          51514,
          407,
          456,
          366,
          1293,
          1401,
          3991,
          20271,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1945,
        "id": 515,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1941,
        "temperature": 0,
        "text": " That's a function as part of the node file system package.",
        "tokens": [
          50364,
          663,
          311,
          257,
          2445,
          382,
          644,
          295,
          264,
          9984,
          3991,
          1185,
          7372,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1949,
        "id": 516,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1945,
        "temperature": 0,
        "text": " And there is also read file without the word sync.",
        "tokens": [
          50564,
          400,
          456,
          307,
          611,
          1401,
          3991,
          1553,
          264,
          1349,
          20271,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1952,
        "id": 517,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1949,
        "temperature": 0,
        "text": " There's also write file sync and just write file.",
        "tokens": [
          50764,
          821,
          311,
          611,
          2464,
          3991,
          20271,
          293,
          445,
          2464,
          3991,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1953,
        "id": 518,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1952,
        "temperature": 0,
        "text": " What's the difference?",
        "tokens": [
          50914,
          708,
          311,
          264,
          2649,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1960,
        "id": 519,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1953,
        "temperature": 0,
        "text": " The difference is this is synchronous, also known as like a blocking line of code.",
        "tokens": [
          50964,
          440,
          2649,
          307,
          341,
          307,
          44743,
          11,
          611,
          2570,
          382,
          411,
          257,
          17776,
          1622,
          295,
          3089,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1965,
        "id": 520,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1960,
        "temperature": 0,
        "text": " Meaning, if I come back here, if I'm using the sync function,",
        "tokens": [
          51314,
          19948,
          11,
          498,
          286,
          808,
          646,
          510,
          11,
          498,
          286,
          478,
          1228,
          264,
          20271,
          2445,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.19666341634897086,
        "compression_ratio": 1.6721991701244814,
        "end": 1970,
        "id": 521,
        "no_speech_prob": 0.0029810057021677494,
        "seek": 194100,
        "start": 1965,
        "temperature": 0,
        "text": " the next line of code will not execute until that action has been finished.",
        "tokens": [
          51564,
          264,
          958,
          1622,
          295,
          3089,
          486,
          406,
          14483,
          1826,
          300,
          3069,
          575,
          668,
          4335,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1972,
        "id": 522,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1970,
        "temperature": 0,
        "text": " And in this case, that's what I want.",
        "tokens": [
          50364,
          400,
          294,
          341,
          1389,
          11,
          300,
          311,
          437,
          286,
          528,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1974,
        "id": 523,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1972,
        "temperature": 0,
        "text": " When the server starts up, I don't want to do anything, actually,",
        "tokens": [
          50464,
          1133,
          264,
          7154,
          3719,
          493,
          11,
          286,
          500,
          380,
          528,
          281,
          360,
          1340,
          11,
          767,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1976,
        "id": 524,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1974,
        "temperature": 0,
        "text": " until the data has been read.",
        "tokens": [
          50564,
          1826,
          264,
          1412,
          575,
          668,
          1401,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1979,
        "id": 525,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1976,
        "temperature": 0,
        "text": " So I want to use the synchronous version, so I load the data,",
        "tokens": [
          50664,
          407,
          286,
          528,
          281,
          764,
          264,
          44743,
          3037,
          11,
          370,
          286,
          3677,
          264,
          1412,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1981,
        "id": 526,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1979,
        "temperature": 0,
        "text": " and it makes, I don't have to have a callback,",
        "tokens": [
          50814,
          293,
          309,
          1669,
          11,
          286,
          500,
          380,
          362,
          281,
          362,
          257,
          818,
          3207,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1984,
        "id": 527,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1981,
        "temperature": 0,
        "text": " and it makes writing the code a little bit simpler.",
        "tokens": [
          50914,
          293,
          309,
          1669,
          3579,
          264,
          3089,
          257,
          707,
          857,
          18587,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1989,
        "id": 528,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1984,
        "temperature": 0,
        "text": " However, if I'm going to perform an action where I'm reading and writing to files",
        "tokens": [
          51064,
          2908,
          11,
          498,
          286,
          478,
          516,
          281,
          2042,
          364,
          3069,
          689,
          286,
          478,
          3760,
          293,
          3579,
          281,
          7098,
          51314
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1993,
        "id": 529,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1989,
        "temperature": 0,
        "text": " while a user is making an API request, I don't want to use the sync method",
        "tokens": [
          51314,
          1339,
          257,
          4195,
          307,
          1455,
          364,
          9362,
          5308,
          11,
          286,
          500,
          380,
          528,
          281,
          764,
          264,
          20271,
          3170,
          51514
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1996,
        "id": 530,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1993,
        "temperature": 0,
        "text": " because that will actually lock up the server while it's waiting to do this operation.",
        "tokens": [
          51514,
          570,
          300,
          486,
          767,
          4017,
          493,
          264,
          7154,
          1339,
          309,
          311,
          3806,
          281,
          360,
          341,
          6916,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17632599818853684,
        "compression_ratio": 1.9278688524590164,
        "end": 1999,
        "id": 531,
        "no_speech_prob": 0.0008969238260760903,
        "seek": 197000,
        "start": 1996,
        "temperature": 0,
        "text": " I want to use the non-sync, asynchronous version,",
        "tokens": [
          51664,
          286,
          528,
          281,
          764,
          264,
          2107,
          12,
          82,
          34015,
          11,
          49174,
          3037,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2002,
        "id": 532,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 1999,
        "temperature": 0,
        "text": " so a callback will happen and the server can still listen for other connections",
        "tokens": [
          50364,
          370,
          257,
          818,
          3207,
          486,
          1051,
          293,
          264,
          7154,
          393,
          920,
          2140,
          337,
          661,
          9271,
          50514
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2003,
        "id": 533,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 2002,
        "temperature": 0,
        "text": " and that type of thing.",
        "tokens": [
          50514,
          293,
          300,
          2010,
          295,
          551,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2010,
        "id": 534,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 2003,
        "temperature": 0,
        "text": " So this is now a moment where right here, under add word,",
        "tokens": [
          50564,
          407,
          341,
          307,
          586,
          257,
          1623,
          689,
          558,
          510,
          11,
          833,
          909,
          1349,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2015,
        "id": 535,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 2010,
        "temperature": 0,
        "text": " I want to write the data back to the file, but asynchronously.",
        "tokens": [
          50914,
          286,
          528,
          281,
          2464,
          264,
          1412,
          646,
          281,
          264,
          3991,
          11,
          457,
          382,
          2534,
          339,
          2044,
          5098,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2018,
        "id": 536,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 2015,
        "temperature": 0,
        "text": " So let me show you how that works.",
        "tokens": [
          51164,
          407,
          718,
          385,
          855,
          291,
          577,
          300,
          1985,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2024,
        "id": 537,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 2018,
        "temperature": 0,
        "text": " So first of all, this is a little error handling that we built in last time,",
        "tokens": [
          51314,
          407,
          700,
          295,
          439,
          11,
          341,
          307,
          257,
          707,
          6713,
          13175,
          300,
          321,
          3094,
          294,
          1036,
          565,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.18917504378727504,
        "compression_ratio": 1.673728813559322,
        "end": 2027,
        "id": 538,
        "no_speech_prob": 0.0014325218508020043,
        "seek": 199900,
        "start": 2024,
        "temperature": 0,
        "text": " so I don't want to write the data if a score wasn't given.",
        "tokens": [
          51614,
          370,
          286,
          500,
          380,
          528,
          281,
          2464,
          264,
          1412,
          498,
          257,
          6175,
          2067,
          380,
          2212,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2030,
        "id": 539,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2027,
        "temperature": 0,
        "text": " So I want to write the data right here.",
        "tokens": [
          50364,
          407,
          286,
          528,
          281,
          2464,
          264,
          1412,
          558,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2038,
        "id": 540,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2030,
        "temperature": 0,
        "text": " So I can say now, write file words.",
        "tokens": [
          50514,
          407,
          286,
          393,
          584,
          586,
          11,
          2464,
          3991,
          2283,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2041,
        "id": 541,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2038,
        "temperature": 0,
        "text": " Let's look at the documentation.",
        "tokens": [
          50914,
          961,
          311,
          574,
          412,
          264,
          14333,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2044,
        "id": 542,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2041,
        "temperature": 0,
        "text": " Let's look for write file.",
        "tokens": [
          51064,
          961,
          311,
          574,
          337,
          2464,
          3991,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2049,
        "id": 543,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2044,
        "temperature": 0,
        "text": " So it looks like write file, I need to give it the file name and the data,",
        "tokens": [
          51214,
          407,
          309,
          1542,
          411,
          2464,
          3991,
          11,
          286,
          643,
          281,
          976,
          309,
          264,
          3991,
          1315,
          293,
          264,
          1412,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2051,
        "id": 544,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2049,
        "temperature": 0,
        "text": " and there's some other options and that sort of thing.",
        "tokens": [
          51464,
          293,
          456,
          311,
          512,
          661,
          3956,
          293,
          300,
          1333,
          295,
          551,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19670096503363715,
        "compression_ratio": 1.6818181818181819,
        "end": 2053,
        "id": 545,
        "no_speech_prob": 0.0017546055605635047,
        "seek": 202700,
        "start": 2051,
        "temperature": 0,
        "text": " But I'm going to do it simply.",
        "tokens": [
          51564,
          583,
          286,
          478,
          516,
          281,
          360,
          309,
          2935,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2061,
        "id": 546,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2053,
        "temperature": 0,
        "text": " I need to say write to words.json and now the data, which is words,",
        "tokens": [
          50364,
          286,
          643,
          281,
          584,
          2464,
          281,
          2283,
          13,
          73,
          3015,
          293,
          586,
          264,
          1412,
          11,
          597,
          307,
          2283,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2064,
        "id": 547,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2061,
        "temperature": 0,
        "text": " and then a callback, finished, I'll call it.",
        "tokens": [
          50764,
          293,
          550,
          257,
          818,
          3207,
          11,
          4335,
          11,
          286,
          603,
          818,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2066,
        "id": 548,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2064,
        "temperature": 0,
        "text": " And then I can say function finished.",
        "tokens": [
          50914,
          400,
          550,
          286,
          393,
          584,
          2445,
          4335,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2067,
        "id": 549,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2066,
        "temperature": 0,
        "text": " Maybe it gets an error or something.",
        "tokens": [
          51014,
          2704,
          309,
          2170,
          364,
          6713,
          420,
          746,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2068,
        "id": 550,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2067,
        "temperature": 0,
        "text": " I don't actually know.",
        "tokens": [
          51064,
          286,
          500,
          380,
          767,
          458,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2069,
        "id": 551,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2068,
        "temperature": 0,
        "text": " I should look this up.",
        "tokens": [
          51114,
          286,
          820,
          574,
          341,
          493,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2075,
        "id": 552,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2069,
        "temperature": 0,
        "text": " I'm just going to say console log all set.",
        "tokens": [
          51164,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          3565,
          439,
          992,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2077,
        "id": 553,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2075,
        "temperature": 0,
        "text": " So let's look at this now and see what happens.",
        "tokens": [
          51464,
          407,
          718,
          311,
          574,
          412,
          341,
          586,
          293,
          536,
          437,
          2314,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17786440074953258,
        "compression_ratio": 1.5732217573221758,
        "end": 2081,
        "id": 554,
        "no_speech_prob": 0.08755797147750854,
        "seek": 205300,
        "start": 2077,
        "temperature": 0,
        "text": " Now, first of all, I've made a big mistake already,",
        "tokens": [
          51564,
          823,
          11,
          700,
          295,
          439,
          11,
          286,
          600,
          1027,
          257,
          955,
          6146,
          1217,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2084,
        "id": 555,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2081,
        "temperature": 0,
        "text": " but let's just see what happens anyway, even with my mistake.",
        "tokens": [
          50364,
          457,
          718,
          311,
          445,
          536,
          437,
          2314,
          4033,
          11,
          754,
          365,
          452,
          6146,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2086,
        "id": 556,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2084,
        "temperature": 0,
        "text": " Probably going to get an error or something like that.",
        "tokens": [
          50514,
          9210,
          516,
          281,
          483,
          364,
          6713,
          420,
          746,
          411,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2088,
        "id": 557,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2086,
        "temperature": 0,
        "text": " So the server has restarted.",
        "tokens": [
          50614,
          407,
          264,
          7154,
          575,
          21022,
          292,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2089,
        "id": 558,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2088,
        "temperature": 0,
        "text": " It's listening and waiting.",
        "tokens": [
          50714,
          467,
          311,
          4764,
          293,
          3806,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2095,
        "id": 559,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2089,
        "temperature": 0,
        "text": " Let's go to the add route, and I'm going to say I want to add the word purple",
        "tokens": [
          50764,
          961,
          311,
          352,
          281,
          264,
          909,
          7955,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          286,
          528,
          281,
          909,
          264,
          1349,
          9656,
          51064
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2097,
        "id": 560,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2095,
        "temperature": 0,
        "text": " and the score three.",
        "tokens": [
          51064,
          293,
          264,
          6175,
          1045,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2099,
        "id": 561,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2097,
        "temperature": 0,
        "text": " Now, write file is not defined.",
        "tokens": [
          51164,
          823,
          11,
          2464,
          3991,
          307,
          406,
          7642,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2101,
        "id": 562,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2099,
        "temperature": 0,
        "text": " Okay, oops, silly me.",
        "tokens": [
          51264,
          1033,
          11,
          34166,
          11,
          11774,
          385,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2104,
        "id": 563,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2101,
        "temperature": 0,
        "text": " I actually just made a mistake in my code where I need to say fs.",
        "tokens": [
          51364,
          286,
          767,
          445,
          1027,
          257,
          6146,
          294,
          452,
          3089,
          689,
          286,
          643,
          281,
          584,
          283,
          82,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16727627187535382,
        "compression_ratio": 1.6453900709219857,
        "end": 2109,
        "id": 564,
        "no_speech_prob": 0.02194800227880478,
        "seek": 208100,
        "start": 2104,
        "temperature": 0,
        "text": " I need to refer to that file system module, that package, fs.writefile.",
        "tokens": [
          51514,
          286,
          643,
          281,
          2864,
          281,
          300,
          3991,
          1185,
          10088,
          11,
          300,
          7372,
          11,
          283,
          82,
          13,
          21561,
          69,
          794,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2111,
        "id": 565,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2109,
        "temperature": 0,
        "text": " That's not the error I was expecting.",
        "tokens": [
          50364,
          663,
          311,
          406,
          264,
          6713,
          286,
          390,
          9650,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2113,
        "id": 566,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2111,
        "temperature": 0,
        "text": " The server should restart.",
        "tokens": [
          50464,
          440,
          7154,
          820,
          21022,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2115,
        "id": 567,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2113,
        "temperature": 0,
        "text": " Okay, it has.",
        "tokens": [
          50564,
          1033,
          11,
          309,
          575,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2116,
        "id": 568,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2115,
        "temperature": 0,
        "text": " Hit refresh.",
        "tokens": [
          50664,
          9217,
          15134,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2120,
        "id": 569,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2116,
        "temperature": 0,
        "text": " Thank you for your word, but let's look at, ah, crashed.",
        "tokens": [
          50714,
          1044,
          291,
          337,
          428,
          1349,
          11,
          457,
          718,
          311,
          574,
          412,
          11,
          3716,
          11,
          24190,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2123,
        "id": 570,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2120,
        "temperature": 0,
        "text": " Unexpected token, blah, blah, blah, object, object.",
        "tokens": [
          50914,
          16701,
          87,
          10729,
          14862,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          2657,
          11,
          2657,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2126,
        "id": 571,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2123,
        "temperature": 0,
        "text": " It couldn't figure out how to write that to a file, right?",
        "tokens": [
          51064,
          467,
          2809,
          380,
          2573,
          484,
          577,
          281,
          2464,
          300,
          281,
          257,
          3991,
          11,
          558,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2131,
        "id": 572,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2126,
        "temperature": 0,
        "text": " Because once again, just as if I'm reading data from a file,",
        "tokens": [
          51214,
          1436,
          1564,
          797,
          11,
          445,
          382,
          498,
          286,
          478,
          3760,
          1412,
          490,
          257,
          3991,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2135,
        "id": 573,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2131,
        "temperature": 0,
        "text": " I'm getting the raw bytes, I need to parse it as a JavaScript object",
        "tokens": [
          51464,
          286,
          478,
          1242,
          264,
          8936,
          36088,
          11,
          286,
          643,
          281,
          48377,
          309,
          382,
          257,
          15778,
          2657,
          51664
        ]
      },
      {
        "avg_logprob": -0.16641409566083293,
        "compression_ratio": 1.5769230769230769,
        "end": 2136,
        "id": 574,
        "no_speech_prob": 0.0006986739463172853,
        "seek": 210900,
        "start": 2135,
        "temperature": 0,
        "text": " before I can use it.",
        "tokens": [
          51664,
          949,
          286,
          393,
          764,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2139,
        "id": 575,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2136,
        "temperature": 0,
        "text": " Now what I need to do is I need to turn it into text-based data",
        "tokens": [
          50364,
          823,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          1261,
          309,
          666,
          2487,
          12,
          6032,
          1412,
          50514
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2141,
        "id": 576,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2139,
        "temperature": 0,
        "text": " before I write it to the file.",
        "tokens": [
          50514,
          949,
          286,
          2464,
          309,
          281,
          264,
          3991,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2145,
        "id": 577,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2141,
        "temperature": 0,
        "text": " And the way to do that, I can say just var data equals json.",
        "tokens": [
          50614,
          400,
          264,
          636,
          281,
          360,
          300,
          11,
          286,
          393,
          584,
          445,
          1374,
          1412,
          6915,
          361,
          3015,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2148,
        "id": 578,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2145,
        "temperature": 0,
        "text": " The opposite of parse or the inverse is stringify.",
        "tokens": [
          50814,
          440,
          6182,
          295,
          48377,
          420,
          264,
          17340,
          307,
          6798,
          2505,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2155,
        "id": 579,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2148,
        "temperature": 0,
        "text": " So I can say stringify words and then write that data to the file.",
        "tokens": [
          50964,
          407,
          286,
          393,
          584,
          6798,
          2505,
          2283,
          293,
          550,
          2464,
          300,
          1412,
          281,
          264,
          3991,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2157,
        "id": 580,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2155,
        "temperature": 0,
        "text": " So now that I've done that, now one thing I want to do actually",
        "tokens": [
          51314,
          407,
          586,
          300,
          286,
          600,
          1096,
          300,
          11,
          586,
          472,
          551,
          286,
          528,
          281,
          360,
          767,
          51414
        ]
      },
      {
        "avg_logprob": -0.19026679006116143,
        "compression_ratio": 1.7763157894736843,
        "end": 2162,
        "id": 581,
        "no_speech_prob": 0.0008167368359863758,
        "seek": 213600,
        "start": 2157,
        "temperature": 0,
        "text": " is I want to stop using NodeMon because NodeMon restarts the server",
        "tokens": [
          51414,
          307,
          286,
          528,
          281,
          1590,
          1228,
          38640,
          32498,
          570,
          38640,
          32498,
          1472,
          11814,
          264,
          7154,
          51664
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2170,
        "id": 582,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2163,
        "temperature": 0,
        "text": " every time, oops, I have, oops, what's going on here?",
        "tokens": [
          50414,
          633,
          565,
          11,
          34166,
          11,
          286,
          362,
          11,
          34166,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2176,
        "id": 583,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2170,
        "temperature": 0,
        "text": " Error, undefined, one, unexpected token, json.",
        "tokens": [
          50764,
          3300,
          2874,
          11,
          674,
          5666,
          2001,
          11,
          472,
          11,
          13106,
          14862,
          11,
          361,
          3015,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2177,
        "id": 584,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2176,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          51064,
          876,
          11,
          291,
          458,
          437,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2179,
        "id": 585,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2177,
        "temperature": 0,
        "text": " I messed up the file.",
        "tokens": [
          51114,
          286,
          16507,
          493,
          264,
          3991,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2184,
        "id": 586,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2179,
        "temperature": 0,
        "text": " So this is what I wrote to the file because when I made my mistake.",
        "tokens": [
          51214,
          407,
          341,
          307,
          437,
          286,
          4114,
          281,
          264,
          3991,
          570,
          562,
          286,
          1027,
          452,
          6146,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2187,
        "id": 587,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2184,
        "temperature": 0,
        "text": " So that's why it's not working.",
        "tokens": [
          51464,
          407,
          300,
          311,
          983,
          309,
          311,
          406,
          1364,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1845796351530114,
        "compression_ratio": 1.5076142131979695,
        "end": 2189,
        "id": 588,
        "no_speech_prob": 0.046032994985580444,
        "seek": 216200,
        "start": 2187,
        "temperature": 0,
        "text": " So the reason why I don't want to use NodeMon right now",
        "tokens": [
          51614,
          407,
          264,
          1778,
          983,
          286,
          500,
          380,
          528,
          281,
          764,
          38640,
          32498,
          558,
          586,
          51714
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2192,
        "id": 589,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2189,
        "temperature": 0,
        "text": " is because every time I rewrite that file, it thinks like,",
        "tokens": [
          50364,
          307,
          570,
          633,
          565,
          286,
          28132,
          300,
          3991,
          11,
          309,
          7309,
          411,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2194,
        "id": 590,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2192,
        "temperature": 0,
        "text": " oh, something changed, it's going to restart the server,",
        "tokens": [
          50514,
          1954,
          11,
          746,
          3105,
          11,
          309,
          311,
          516,
          281,
          21022,
          264,
          7154,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2195,
        "id": 591,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2194,
        "temperature": 0,
        "text": " which will mess things up.",
        "tokens": [
          50614,
          597,
          486,
          2082,
          721,
          493,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2197,
        "id": 592,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2195,
        "temperature": 0,
        "text": " So right now I just want to manually stop and start the server myself",
        "tokens": [
          50664,
          407,
          558,
          586,
          286,
          445,
          528,
          281,
          16945,
          1590,
          293,
          722,
          264,
          7154,
          2059,
          50764
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2199,
        "id": 593,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2197,
        "temperature": 0,
        "text": " to make sure things are good.",
        "tokens": [
          50764,
          281,
          652,
          988,
          721,
          366,
          665,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2204,
        "id": 594,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2199,
        "temperature": 0,
        "text": " So, okay, so now the server starts, it reads the data from the file.",
        "tokens": [
          50864,
          407,
          11,
          1392,
          11,
          370,
          586,
          264,
          7154,
          3719,
          11,
          309,
          15700,
          264,
          1412,
          490,
          264,
          3991,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2209,
        "id": 595,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2204,
        "temperature": 0,
        "text": " Then what I'm going to do here is I'm going to now go to this route again",
        "tokens": [
          51114,
          1396,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          307,
          286,
          478,
          516,
          281,
          586,
          352,
          281,
          341,
          7955,
          797,
          51364
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2211,
        "id": 596,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2209,
        "temperature": 0,
        "text": " and I'm going to hit enter.",
        "tokens": [
          51364,
          293,
          286,
          478,
          516,
          281,
          2045,
          3242,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2212,
        "id": 597,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2211,
        "temperature": 0,
        "text": " Thank you for your word.",
        "tokens": [
          51464,
          1044,
          291,
          337,
          428,
          1349,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2214,
        "id": 598,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2212,
        "temperature": 0,
        "text": " I'm going to go back and I'm going to look and look.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          352,
          646,
          293,
          286,
          478,
          516,
          281,
          574,
          293,
          574,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2215,
        "id": 599,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2214,
        "temperature": 0,
        "text": " It's there.",
        "tokens": [
          51614,
          467,
          311,
          456,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17847797369501392,
        "compression_ratio": 1.8606271777003485,
        "end": 2217,
        "id": 600,
        "no_speech_prob": 0.052615951746702194,
        "seek": 218900,
        "start": 2215,
        "temperature": 0,
        "text": " Oh, but I lost the formatting.",
        "tokens": [
          51664,
          876,
          11,
          457,
          286,
          2731,
          264,
          39366,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2220,
        "id": 601,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2217,
        "temperature": 0,
        "text": " Like my json file is all just one long thing.",
        "tokens": [
          50364,
          1743,
          452,
          361,
          3015,
          3991,
          307,
          439,
          445,
          472,
          938,
          551,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2223,
        "id": 602,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2220,
        "temperature": 0,
        "text": " So one thing that's – I mean this is sort of like a small point",
        "tokens": [
          50514,
          407,
          472,
          551,
          300,
          311,
          220,
          5815,
          286,
          914,
          341,
          307,
          1333,
          295,
          411,
          257,
          1359,
          935,
          50664
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2225,
        "id": 603,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2223,
        "temperature": 0,
        "text": " and sometimes it could matter in various scenarios,",
        "tokens": [
          50664,
          293,
          2171,
          309,
          727,
          1871,
          294,
          3683,
          15077,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2228,
        "id": 604,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2225,
        "temperature": 0,
        "text": " but since we're talking about it, I might as well talk about it.",
        "tokens": [
          50764,
          457,
          1670,
          321,
          434,
          1417,
          466,
          309,
          11,
          286,
          1062,
          382,
          731,
          751,
          466,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2231,
        "id": 605,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2228,
        "temperature": 0,
        "text": " This stringify function takes the JavaScript object",
        "tokens": [
          50914,
          639,
          6798,
          2505,
          2445,
          2516,
          264,
          15778,
          2657,
          51064
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2235,
        "id": 606,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2231,
        "temperature": 0,
        "text": " and kind of makes it a string with as few characters as possible.",
        "tokens": [
          51064,
          293,
          733,
          295,
          1669,
          309,
          257,
          6798,
          365,
          382,
          1326,
          4342,
          382,
          1944,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2237,
        "id": 607,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2235,
        "temperature": 0,
        "text": " So no white space to make it kind of human readable.",
        "tokens": [
          51264,
          407,
          572,
          2418,
          1901,
          281,
          652,
          309,
          733,
          295,
          1952,
          49857,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2241,
        "id": 608,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2237,
        "temperature": 0,
        "text": " But I can use some other arguments and I can add like –",
        "tokens": [
          51364,
          583,
          286,
          393,
          764,
          512,
          661,
          12869,
          293,
          286,
          393,
          909,
          411,
          1662,
          51564
        ]
      },
      {
        "avg_logprob": -0.18711193112561303,
        "compression_ratio": 1.665625,
        "end": 2245,
        "id": 609,
        "no_speech_prob": 0.0850934311747551,
        "seek": 221700,
        "start": 2241,
        "temperature": 0,
        "text": " I forget why you put null there to look at the documentation for stringify,",
        "tokens": [
          51564,
          286,
          2870,
          983,
          291,
          829,
          18184,
          456,
          281,
          574,
          412,
          264,
          14333,
          337,
          6798,
          2505,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2249,
        "id": 610,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2245,
        "temperature": 0,
        "text": " but two meaning that I want to use two spaces for an indent.",
        "tokens": [
          50364,
          457,
          732,
          3620,
          300,
          286,
          528,
          281,
          764,
          732,
          7673,
          337,
          364,
          44494,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2254,
        "id": 611,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2249,
        "temperature": 0,
        "text": " So if I do this and I restart the server –",
        "tokens": [
          50564,
          407,
          498,
          286,
          360,
          341,
          293,
          286,
          21022,
          264,
          7154,
          1662,
          50814
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2257,
        "id": 612,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2254,
        "temperature": 0,
        "text": " and by the way, purple is already there, so purple is now there forever.",
        "tokens": [
          50814,
          293,
          538,
          264,
          636,
          11,
          9656,
          307,
          1217,
          456,
          11,
          370,
          9656,
          307,
          586,
          456,
          5680,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2262,
        "id": 613,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2257,
        "temperature": 0,
        "text": " And I can go to pink and add the number six.",
        "tokens": [
          50964,
          400,
          286,
          393,
          352,
          281,
          7022,
          293,
          909,
          264,
          1230,
          2309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2264,
        "id": 614,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2262,
        "temperature": 0,
        "text": " Thank you for your word.",
        "tokens": [
          51214,
          1044,
          291,
          337,
          428,
          1349,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2267,
        "id": 615,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2264,
        "temperature": 0,
        "text": " And if I go back and I look at that, we can see there we go.",
        "tokens": [
          51314,
          400,
          498,
          286,
          352,
          646,
          293,
          286,
          574,
          412,
          300,
          11,
          321,
          393,
          536,
          456,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2269,
        "id": 616,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2267,
        "temperature": 0,
        "text": " So every time I go to that route,",
        "tokens": [
          51464,
          407,
          633,
          565,
          286,
          352,
          281,
          300,
          7955,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.16557230268205916,
        "compression_ratio": 1.6584362139917694,
        "end": 2274,
        "id": 617,
        "no_speech_prob": 0.009559162892401218,
        "seek": 224500,
        "start": 2269,
        "temperature": 0,
        "text": " it rewrites the entire file with the current list of words.",
        "tokens": [
          51564,
          309,
          319,
          86,
          30931,
          264,
          2302,
          3991,
          365,
          264,
          2190,
          1329,
          295,
          2283,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2276,
        "id": 618,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2274,
        "temperature": 0,
        "text": " Every time I quit the server and start the server back up,",
        "tokens": [
          50364,
          2048,
          565,
          286,
          10366,
          264,
          7154,
          293,
          722,
          264,
          7154,
          646,
          493,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2278,
        "id": 619,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2276,
        "temperature": 0,
        "text": " it reads the list of words.",
        "tokens": [
          50464,
          309,
          15700,
          264,
          1329,
          295,
          2283,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2280,
        "id": 620,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2278,
        "temperature": 0,
        "text": " So this is the full round trip.",
        "tokens": [
          50564,
          407,
          341,
          307,
          264,
          1577,
          3098,
          4931,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2285,
        "id": 621,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2280,
        "temperature": 0,
        "text": " There's lots of inefficiencies and issues again with scalability and privacy,",
        "tokens": [
          50664,
          821,
          311,
          3195,
          295,
          7167,
          3341,
          31294,
          293,
          2663,
          797,
          365,
          15664,
          2310,
          293,
          11427,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2289,
        "id": 622,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2285,
        "temperature": 0,
        "text": " but this works for a simple project where you just want to save a high score list",
        "tokens": [
          50914,
          457,
          341,
          1985,
          337,
          257,
          2199,
          1716,
          689,
          291,
          445,
          528,
          281,
          3155,
          257,
          1090,
          6175,
          1329,
          51114
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2292,
        "id": 623,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2289,
        "temperature": 0,
        "text": " or a table of words in their sentiment score.",
        "tokens": [
          51114,
          420,
          257,
          3199,
          295,
          2283,
          294,
          641,
          16149,
          6175,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2293,
        "id": 624,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2292,
        "temperature": 0,
        "text": " You can do something like this.",
        "tokens": [
          51264,
          509,
          393,
          360,
          746,
          411,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2295,
        "id": 625,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2293,
        "temperature": 0,
        "text": " I'm sure you can imagine some other scenarios",
        "tokens": [
          51314,
          286,
          478,
          988,
          291,
          393,
          3811,
          512,
          661,
          15077,
          51414
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2298,
        "id": 626,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2295,
        "temperature": 0,
        "text": " where just this basic idea is plenty good enough.",
        "tokens": [
          51414,
          689,
          445,
          341,
          3875,
          1558,
          307,
          7140,
          665,
          1547,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2300,
        "id": 627,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2298,
        "temperature": 0,
        "text": " Let me say another few things about this though",
        "tokens": [
          51564,
          961,
          385,
          584,
          1071,
          1326,
          721,
          466,
          341,
          1673,
          51664
        ]
      },
      {
        "avg_logprob": -0.17740850448608397,
        "compression_ratio": 1.6981132075471699,
        "end": 2302,
        "id": 628,
        "no_speech_prob": 0.005384728778153658,
        "seek": 227400,
        "start": 2300,
        "temperature": 0,
        "text": " before I move to the end of this video.",
        "tokens": [
          51664,
          949,
          286,
          1286,
          281,
          264,
          917,
          295,
          341,
          960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18128189833267874,
        "compression_ratio": 1.6175115207373272,
        "end": 2305,
        "id": 629,
        "no_speech_prob": 0.01883246935904026,
        "seek": 230200,
        "start": 2302,
        "temperature": 0,
        "text": " One is that I've kind of made a little bit of a mistake here,",
        "tokens": [
          50364,
          1485,
          307,
          300,
          286,
          600,
          733,
          295,
          1027,
          257,
          707,
          857,
          295,
          257,
          6146,
          510,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.18128189833267874,
        "compression_ratio": 1.6175115207373272,
        "end": 2310,
        "id": 630,
        "no_speech_prob": 0.01883246935904026,
        "seek": 230200,
        "start": 2305,
        "temperature": 0,
        "text": " which is that even if something goes wrong here,",
        "tokens": [
          50514,
          597,
          307,
          300,
          754,
          498,
          746,
          1709,
          2085,
          510,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.18128189833267874,
        "compression_ratio": 1.6175115207373272,
        "end": 2314,
        "id": 631,
        "no_speech_prob": 0.01883246935904026,
        "seek": 230200,
        "start": 2310,
        "temperature": 0,
        "text": " I still send the reply like, thank you for your word.",
        "tokens": [
          50764,
          286,
          920,
          2845,
          264,
          16972,
          411,
          11,
          1309,
          291,
          337,
          428,
          1349,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18128189833267874,
        "compression_ratio": 1.6175115207373272,
        "end": 2317,
        "id": 632,
        "no_speech_prob": 0.01883246935904026,
        "seek": 230200,
        "start": 2314,
        "temperature": 0,
        "text": " So really probably I should wait to send a reply to the client",
        "tokens": [
          50964,
          407,
          534,
          1391,
          286,
          820,
          1699,
          281,
          2845,
          257,
          16972,
          281,
          264,
          6423,
          51114
        ]
      },
      {
        "avg_logprob": -0.18128189833267874,
        "compression_ratio": 1.6175115207373272,
        "end": 2321,
        "id": 633,
        "no_speech_prob": 0.01883246935904026,
        "seek": 230200,
        "start": 2317,
        "temperature": 0,
        "text": " who added this word until that file has finished being written.",
        "tokens": [
          51114,
          567,
          3869,
          341,
          1349,
          1826,
          300,
          3991,
          575,
          4335,
          885,
          3720,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18128189833267874,
        "compression_ratio": 1.6175115207373272,
        "end": 2330,
        "id": 634,
        "no_speech_prob": 0.01883246935904026,
        "seek": 230200,
        "start": 2321,
        "temperature": 0,
        "text": " So I would say it probably makes sense to put that in here,",
        "tokens": [
          51314,
          407,
          286,
          576,
          584,
          309,
          1391,
          1669,
          2020,
          281,
          829,
          300,
          294,
          510,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2334,
        "id": 635,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2331,
        "temperature": 0,
        "text": " and I'm going to send the reply actually.",
        "tokens": [
          50414,
          293,
          286,
          478,
          516,
          281,
          2845,
          264,
          16972,
          767,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2337,
        "id": 636,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2334,
        "temperature": 0,
        "text": " And because I had this error checking, I have to send the reply up here.",
        "tokens": [
          50564,
          400,
          570,
          286,
          632,
          341,
          6713,
          8568,
          11,
          286,
          362,
          281,
          2845,
          264,
          16972,
          493,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2339,
        "id": 637,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2337,
        "temperature": 0,
        "text": " I can think about if there's a better way,",
        "tokens": [
          50714,
          286,
          393,
          519,
          466,
          498,
          456,
          311,
          257,
          1101,
          636,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2341,
        "id": 638,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2339,
        "temperature": 0,
        "text": " but I'm going to have if there's no score, I send back a message,",
        "tokens": [
          50814,
          457,
          286,
          478,
          516,
          281,
          362,
          498,
          456,
          311,
          572,
          6175,
          11,
          286,
          2845,
          646,
          257,
          3636,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2343,
        "id": 639,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2341,
        "temperature": 0,
        "text": " score is required.",
        "tokens": [
          50914,
          6175,
          307,
          4739,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2346,
        "id": 640,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2343,
        "temperature": 0,
        "text": " And if it gets the data, if it gets the word, adds it, writes the file,",
        "tokens": [
          51014,
          400,
          498,
          309,
          2170,
          264,
          1412,
          11,
          498,
          309,
          2170,
          264,
          1349,
          11,
          10860,
          309,
          11,
          13657,
          264,
          3991,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2349,
        "id": 641,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2346,
        "temperature": 0,
        "text": " and all that is successful, then I'm going to say,",
        "tokens": [
          51164,
          293,
          439,
          300,
          307,
          4406,
          11,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2351,
        "id": 642,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2349,
        "temperature": 0,
        "text": " and you know what I think is useful in an API,",
        "tokens": [
          51314,
          293,
          291,
          458,
          437,
          286,
          519,
          307,
          4420,
          294,
          364,
          9362,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.23194707951075594,
        "compression_ratio": 1.8715953307392996,
        "end": 2357,
        "id": 643,
        "no_speech_prob": 0.06278491765260696,
        "seek": 233000,
        "start": 2351,
        "temperature": 0,
        "text": " is for a word to actually, for an API to just send you back the data",
        "tokens": [
          51414,
          307,
          337,
          257,
          1349,
          281,
          767,
          11,
          337,
          364,
          9362,
          281,
          445,
          2845,
          291,
          646,
          264,
          1412,
          51714
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2364,
        "id": 644,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2357,
        "temperature": 0,
        "text": " that you've sent it, and then I could say something like status success.",
        "tokens": [
          50364,
          300,
          291,
          600,
          2279,
          309,
          11,
          293,
          550,
          286,
          727,
          584,
          746,
          411,
          6558,
          2245,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2368,
        "id": 645,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2364,
        "temperature": 0,
        "text": " So in other words, sometimes when you're making an API request",
        "tokens": [
          50714,
          407,
          294,
          661,
          2283,
          11,
          2171,
          562,
          291,
          434,
          1455,
          364,
          9362,
          5308,
          50914
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2371,
        "id": 646,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2368,
        "temperature": 0,
        "text": " or you're adding something, you're sending some data to an API,",
        "tokens": [
          50914,
          420,
          291,
          434,
          5127,
          746,
          11,
          291,
          434,
          7750,
          512,
          1412,
          281,
          364,
          9362,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2374,
        "id": 647,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2371,
        "temperature": 0,
        "text": " and you're doing that like many, many times, as a client,",
        "tokens": [
          51064,
          293,
          291,
          434,
          884,
          300,
          411,
          867,
          11,
          867,
          1413,
          11,
          382,
          257,
          6423,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2377,
        "id": 648,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2374,
        "temperature": 0,
        "text": " when you get a reply back, you need to match it with which one you sent.",
        "tokens": [
          51214,
          562,
          291,
          483,
          257,
          16972,
          646,
          11,
          291,
          643,
          281,
          2995,
          309,
          365,
          597,
          472,
          291,
          2279,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2379,
        "id": 649,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2377,
        "temperature": 0,
        "text": " So if you get some information back that you can match,",
        "tokens": [
          51364,
          407,
          498,
          291,
          483,
          512,
          1589,
          646,
          300,
          291,
          393,
          2995,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2380,
        "id": 650,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2379,
        "temperature": 0,
        "text": " that can often be helpful.",
        "tokens": [
          51464,
          300,
          393,
          2049,
          312,
          4961,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2383,
        "id": 651,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2380,
        "temperature": 0,
        "text": " So even though this is redundant, and I don't personally need this information,",
        "tokens": [
          51514,
          407,
          754,
          1673,
          341,
          307,
          40997,
          11,
          293,
          286,
          500,
          380,
          5665,
          643,
          341,
          1589,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.18089701974992273,
        "compression_ratio": 1.8027681660899655,
        "end": 2385,
        "id": 652,
        "no_speech_prob": 0.02716805413365364,
        "seek": 235700,
        "start": 2383,
        "temperature": 0,
        "text": " I think it's useful to add.",
        "tokens": [
          51664,
          286,
          519,
          309,
          311,
          4420,
          281,
          909,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23804639333701996,
        "compression_ratio": 1.4642857142857142,
        "end": 2388,
        "id": 653,
        "no_speech_prob": 0.01150780450552702,
        "seek": 238500,
        "start": 2385,
        "temperature": 0,
        "text": " So I did sort of a very awkward thing where my variables all have the same name,",
        "tokens": [
          50364,
          407,
          286,
          630,
          1333,
          295,
          257,
          588,
          11411,
          551,
          689,
          452,
          9102,
          439,
          362,
          264,
          912,
          1315,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.23804639333701996,
        "compression_ratio": 1.4642857142857142,
        "end": 2391,
        "id": 654,
        "no_speech_prob": 0.01150780450552702,
        "seek": 238500,
        "start": 2388,
        "temperature": 0,
        "text": " but this will actually, should work.",
        "tokens": [
          50514,
          457,
          341,
          486,
          767,
          11,
          820,
          589,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23804639333701996,
        "compression_ratio": 1.4642857142857142,
        "end": 2394,
        "id": 655,
        "no_speech_prob": 0.01150780450552702,
        "seek": 238500,
        "start": 2391,
        "temperature": 0,
        "text": " So let's restart the server one more time.",
        "tokens": [
          50664,
          407,
          718,
          311,
          21022,
          264,
          7154,
          472,
          544,
          565,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23804639333701996,
        "compression_ratio": 1.4642857142857142,
        "end": 2397,
        "id": 656,
        "no_speech_prob": 0.01150780450552702,
        "seek": 238500,
        "start": 2394,
        "temperature": 0,
        "text": " We can see I've got all the words that I added before,",
        "tokens": [
          50814,
          492,
          393,
          536,
          286,
          600,
          658,
          439,
          264,
          2283,
          300,
          286,
          3869,
          949,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.23804639333701996,
        "compression_ratio": 1.4642857142857142,
        "end": 2410,
        "id": 657,
        "no_speech_prob": 0.01150780450552702,
        "seek": 238500,
        "start": 2397,
        "temperature": 0,
        "text": " and now if I go back and I say add flower, 7, and I hit enter, success.",
        "tokens": [
          50964,
          293,
          586,
          498,
          286,
          352,
          646,
          293,
          286,
          584,
          909,
          8617,
          11,
          1614,
          11,
          293,
          286,
          2045,
          3242,
          11,
          2245,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2415,
        "id": 658,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2410,
        "temperature": 0,
        "text": " The word flower was added, and if I go to all, we can see flower is in there,",
        "tokens": [
          50364,
          440,
          1349,
          8617,
          390,
          3869,
          11,
          293,
          498,
          286,
          352,
          281,
          439,
          11,
          321,
          393,
          536,
          8617,
          307,
          294,
          456,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2419,
        "id": 659,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2415,
        "temperature": 0,
        "text": " pink is in there, purple is in there, and I can even restart the server.",
        "tokens": [
          50614,
          7022,
          307,
          294,
          456,
          11,
          9656,
          307,
          294,
          456,
          11,
          293,
          286,
          393,
          754,
          21022,
          264,
          7154,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2423,
        "id": 660,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2419,
        "temperature": 0,
        "text": " I restart the server, and there it all is again.",
        "tokens": [
          50814,
          286,
          21022,
          264,
          7154,
          11,
          293,
          456,
          309,
          439,
          307,
          797,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2429,
        "id": 661,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2423,
        "temperature": 0,
        "text": " So this is the full round trip of how to receive from a get request",
        "tokens": [
          51014,
          407,
          341,
          307,
          264,
          1577,
          3098,
          4931,
          295,
          577,
          281,
          4774,
          490,
          257,
          483,
          5308,
          51314
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2432,
        "id": 662,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2429,
        "temperature": 0,
        "text": " through a route data from a user, save that data to a file,",
        "tokens": [
          51314,
          807,
          257,
          7955,
          1412,
          490,
          257,
          4195,
          11,
          3155,
          300,
          1412,
          281,
          257,
          3991,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2435,
        "id": 663,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2432,
        "temperature": 0,
        "text": " and have the server always keep track of that data.",
        "tokens": [
          51464,
          293,
          362,
          264,
          7154,
          1009,
          1066,
          2837,
          295,
          300,
          1412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15381827005525914,
        "compression_ratio": 1.7991803278688525,
        "end": 2439,
        "id": 664,
        "no_speech_prob": 0.1276446282863617,
        "seek": 241000,
        "start": 2435,
        "temperature": 0,
        "text": " So I've still got more to do in terms of building this API,",
        "tokens": [
          51614,
          407,
          286,
          600,
          920,
          658,
          544,
          281,
          360,
          294,
          2115,
          295,
          2390,
          341,
          9362,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2442,
        "id": 665,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2439,
        "temperature": 0,
        "text": " which is actually like get some text and produce a sentiment score.",
        "tokens": [
          50364,
          597,
          307,
          767,
          411,
          483,
          512,
          2487,
          293,
          5258,
          257,
          16149,
          6175,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2445,
        "id": 666,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2442,
        "temperature": 0,
        "text": " I need to look at how would I build a client, a front end,",
        "tokens": [
          50514,
          286,
          643,
          281,
          574,
          412,
          577,
          576,
          286,
          1322,
          257,
          6423,
          11,
          257,
          1868,
          917,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2448,
        "id": 667,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2445,
        "temperature": 0,
        "text": " that would actually interface and interact with the API,",
        "tokens": [
          50664,
          300,
          576,
          767,
          9226,
          293,
          4648,
          365,
          264,
          9362,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2450,
        "id": 668,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2448,
        "temperature": 0,
        "text": " but at least now we've seen a little bit about saving data.",
        "tokens": [
          50814,
          457,
          412,
          1935,
          586,
          321,
          600,
          1612,
          257,
          707,
          857,
          466,
          6816,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2453,
        "id": 669,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2450,
        "temperature": 0,
        "text": " Thanks for watching.",
        "tokens": [
          50914,
          2561,
          337,
          1976,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2456,
        "id": 670,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2453,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2458,
        "id": 671,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2456,
        "temperature": 0,
        "text": " Did that make sense, everybody?",
        "tokens": [
          51214,
          2589,
          300,
          652,
          2020,
          11,
          2201,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.22873031452137937,
        "compression_ratio": 1.4934497816593886,
        "end": 2466,
        "id": 672,
        "no_speech_prob": 0.000677185133099556,
        "seek": 243900,
        "start": 2458,
        "temperature": 0,
        "text": " We've got one little extra tutorial in.",
        "tokens": [
          51314,
          492,
          600,
          658,
          472,
          707,
          2857,
          7073,
          294,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.13919958254186118,
        "compression_ratio": 1.5224719101123596,
        "end": 2469,
        "id": 673,
        "no_speech_prob": 0.21731579303741455,
        "seek": 246600,
        "start": 2466,
        "temperature": 0,
        "text": " I have a half an hour.",
        "tokens": [
          50364,
          286,
          362,
          257,
          1922,
          364,
          1773,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.13919958254186118,
        "compression_ratio": 1.5224719101123596,
        "end": 2475,
        "id": 674,
        "no_speech_prob": 0.21731579303741455,
        "seek": 246600,
        "start": 2469,
        "temperature": 0,
        "text": " I think what I want to do in the next one is make a client for it,",
        "tokens": [
          50514,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          294,
          264,
          958,
          472,
          307,
          652,
          257,
          6423,
          337,
          309,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.13919958254186118,
        "compression_ratio": 1.5224719101123596,
        "end": 2480,
        "id": 675,
        "no_speech_prob": 0.21731579303741455,
        "seek": 246600,
        "start": 2475,
        "temperature": 0,
        "text": " because that's going to be necessary once we look at doing a post.",
        "tokens": [
          50814,
          570,
          300,
          311,
          516,
          281,
          312,
          4818,
          1564,
          321,
          574,
          412,
          884,
          257,
          2183,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.13919958254186118,
        "compression_ratio": 1.5224719101123596,
        "end": 2482,
        "id": 676,
        "no_speech_prob": 0.21731579303741455,
        "seek": 246600,
        "start": 2480,
        "temperature": 0,
        "text": " Electron tutorial, that is a great idea.",
        "tokens": [
          51064,
          12575,
          2044,
          7073,
          11,
          300,
          307,
          257,
          869,
          1558,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.13919958254186118,
        "compression_ratio": 1.5224719101123596,
        "end": 2486,
        "id": 677,
        "no_speech_prob": 0.21731579303741455,
        "seek": 246600,
        "start": 2482,
        "temperature": 0,
        "text": " I would love to do an electron tutorial.",
        "tokens": [
          51164,
          286,
          576,
          959,
          281,
          360,
          364,
          6084,
          7073,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.13919958254186118,
        "compression_ratio": 1.5224719101123596,
        "end": 2491,
        "id": 678,
        "no_speech_prob": 0.21731579303741455,
        "seek": 246600,
        "start": 2486,
        "temperature": 0,
        "text": " If only I had so much more time.",
        "tokens": [
          51364,
          759,
          787,
          286,
          632,
          370,
          709,
          544,
          565,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21381899367931279,
        "compression_ratio": 1.5227272727272727,
        "end": 2492,
        "id": 679,
        "no_speech_prob": 0.01048828475177288,
        "seek": 249100,
        "start": 2491,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.21381899367931279,
        "compression_ratio": 1.5227272727272727,
        "end": 2497,
        "id": 680,
        "no_speech_prob": 0.01048828475177288,
        "seek": 249100,
        "start": 2492,
        "temperature": 0,
        "text": " So let me just keep moving here.",
        "tokens": [
          50414,
          407,
          718,
          385,
          445,
          1066,
          2684,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21381899367931279,
        "compression_ratio": 1.5227272727272727,
        "end": 2500,
        "id": 681,
        "no_speech_prob": 0.01048828475177288,
        "seek": 249100,
        "start": 2497,
        "temperature": 0,
        "text": " It's a little bit warm in here with the light on.",
        "tokens": [
          50664,
          467,
          311,
          257,
          707,
          857,
          4561,
          294,
          510,
          365,
          264,
          1442,
          322,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21381899367931279,
        "compression_ratio": 1.5227272727272727,
        "end": 2506,
        "id": 682,
        "no_speech_prob": 0.01048828475177288,
        "seek": 249100,
        "start": 2500,
        "temperature": 0,
        "text": " So what I'm going to do now, in a way, is kind of like the easy part for me at least.",
        "tokens": [
          50814,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          11,
          294,
          257,
          636,
          11,
          307,
          733,
          295,
          411,
          264,
          1858,
          644,
          337,
          385,
          412,
          1935,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21381899367931279,
        "compression_ratio": 1.5227272727272727,
        "end": 2516,
        "id": 683,
        "no_speech_prob": 0.01048828475177288,
        "seek": 249100,
        "start": 2506,
        "temperature": 0,
        "text": " And I'm going to go into here, and we're going to start working on the client,",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          352,
          666,
          510,
          11,
          293,
          321,
          434,
          516,
          281,
          722,
          1364,
          322,
          264,
          6423,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21381899367931279,
        "compression_ratio": 1.5227272727272727,
        "end": 2517,
        "id": 684,
        "no_speech_prob": 0.01048828475177288,
        "seek": 249100,
        "start": 2516,
        "temperature": 0,
        "text": " the front end.",
        "tokens": [
          51614,
          264,
          1868,
          917,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1761864606071921,
        "compression_ratio": 1.473053892215569,
        "end": 2526,
        "id": 685,
        "no_speech_prob": 0.005301702301949263,
        "seek": 251700,
        "start": 2517,
        "temperature": 0,
        "text": " So I'm going to use p5 for this, and I'm thinking about the best way to do this.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          764,
          280,
          20,
          337,
          341,
          11,
          293,
          286,
          478,
          1953,
          466,
          264,
          1151,
          636,
          281,
          360,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1761864606071921,
        "compression_ratio": 1.473053892215569,
        "end": 2534,
        "id": 686,
        "no_speech_prob": 0.005301702301949263,
        "seek": 251700,
        "start": 2526,
        "temperature": 0,
        "text": " So let me go to desktop, A to Z.",
        "tokens": [
          50814,
          407,
          718,
          385,
          352,
          281,
          14502,
          11,
          316,
          281,
          1176,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1761864606071921,
        "compression_ratio": 1.473053892215569,
        "end": 2536,
        "id": 687,
        "no_speech_prob": 0.005301702301949263,
        "seek": 251700,
        "start": 2534,
        "temperature": 0,
        "text": " I'm sure I have some.",
        "tokens": [
          51214,
          286,
          478,
          988,
          286,
          362,
          512,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1761864606071921,
        "compression_ratio": 1.473053892215569,
        "end": 2539,
        "id": 688,
        "no_speech_prob": 0.005301702301949263,
        "seek": 251700,
        "start": 2536,
        "temperature": 0,
        "text": " Actually, I'm going to do the ridiculous thing that I always do,",
        "tokens": [
          51314,
          5135,
          11,
          286,
          478,
          516,
          281,
          360,
          264,
          11083,
          551,
          300,
          286,
          1009,
          360,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1761864606071921,
        "compression_ratio": 1.473053892215569,
        "end": 2546,
        "id": 689,
        "no_speech_prob": 0.005301702301949263,
        "seek": 251700,
        "start": 2539,
        "temperature": 0,
        "text": " which is p5.js.org, download, p5.js complete.",
        "tokens": [
          51464,
          597,
          307,
          280,
          20,
          13,
          25530,
          13,
          4646,
          11,
          5484,
          11,
          280,
          20,
          13,
          25530,
          3566,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2549,
        "id": 690,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2547,
        "temperature": 0,
        "text": " I'm going to do this.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2552,
        "id": 691,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2549,
        "temperature": 0,
        "text": " I want to get to the AFIN coding challenge today.",
        "tokens": [
          50514,
          286,
          528,
          281,
          483,
          281,
          264,
          20389,
          1464,
          17720,
          3430,
          965,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2556,
        "id": 692,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2552,
        "temperature": 0,
        "text": " Maybe if I can come back later and do it.",
        "tokens": [
          50664,
          2704,
          498,
          286,
          393,
          808,
          646,
          1780,
          293,
          360,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2565,
        "id": 693,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2556,
        "temperature": 0,
        "text": " I'm tempted to just do the coding challenge I had envisioned today instead,",
        "tokens": [
          50864,
          286,
          478,
          29941,
          281,
          445,
          360,
          264,
          17720,
          3430,
          286,
          632,
          47733,
          965,
          2602,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2570,
        "id": 694,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2565,
        "temperature": 0,
        "text": " because that, in a way, could be the front end.",
        "tokens": [
          51314,
          570,
          300,
          11,
          294,
          257,
          636,
          11,
          727,
          312,
          264,
          1868,
          917,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2571,
        "id": 695,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2570,
        "temperature": 0,
        "text": " Okay, fine.",
        "tokens": [
          51564,
          1033,
          11,
          2489,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2572,
        "id": 696,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2571,
        "temperature": 0,
        "text": " I'm going to do the interface.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          360,
          264,
          9226,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19317322910422147,
        "compression_ratio": 1.5330188679245282,
        "end": 2574,
        "id": 697,
        "no_speech_prob": 0.0010162396356463432,
        "seek": 254600,
        "start": 2572,
        "temperature": 0,
        "text": " Yes, I can use p5 manager, Tutuber suggests.",
        "tokens": [
          51664,
          1079,
          11,
          286,
          393,
          764,
          280,
          20,
          6598,
          11,
          18392,
          10261,
          13409,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2581,
        "id": 698,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2575,
        "temperature": 0,
        "text": " I'm kind of like a terrible – I have very bad habits, but I can't help them sometimes.",
        "tokens": [
          50414,
          286,
          478,
          733,
          295,
          411,
          257,
          6237,
          220,
          5815,
          286,
          362,
          588,
          1578,
          14100,
          11,
          457,
          286,
          393,
          380,
          854,
          552,
          2171,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2582,
        "id": 699,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2581,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2587,
        "id": 700,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2585,
        "temperature": 0,
        "text": " Okay, so here we go.",
        "tokens": [
          50914,
          1033,
          11,
          370,
          510,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2590,
        "id": 701,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2587,
        "temperature": 0,
        "text": " I am going to join Pranger.",
        "tokens": [
          51014,
          286,
          669,
          516,
          281,
          3917,
          2114,
          3176,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2591,
        "id": 702,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2590,
        "temperature": 0,
        "text": " So how did I do?",
        "tokens": [
          51164,
          407,
          577,
          630,
          286,
          360,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2595,
        "id": 703,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2591,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.28500591180263424,
        "compression_ratio": 1.3905325443786982,
        "end": 2602,
        "id": 704,
        "no_speech_prob": 0.017985953018069267,
        "seek": 257400,
        "start": 2595,
        "temperature": 0,
        "text": " Okay, so this is probably going to be the last short little tutorial",
        "tokens": [
          51414,
          1033,
          11,
          370,
          341,
          307,
          1391,
          516,
          281,
          312,
          264,
          1036,
          2099,
          707,
          7073,
          51764
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2604,
        "id": 705,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2602,
        "temperature": 0,
        "text": " where I'm just going to add a little front end for this,",
        "tokens": [
          50364,
          689,
          286,
          478,
          445,
          516,
          281,
          909,
          257,
          707,
          1868,
          917,
          337,
          341,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2608,
        "id": 706,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2604,
        "temperature": 0,
        "text": " and I still have a bunch of pieces to finish up with this,",
        "tokens": [
          50464,
          293,
          286,
          920,
          362,
          257,
          3840,
          295,
          3755,
          281,
          2413,
          493,
          365,
          341,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2611,
        "id": 707,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2608,
        "temperature": 0,
        "text": " which if there's time actually later, I will in fact be able to –",
        "tokens": [
          50664,
          597,
          498,
          456,
          311,
          565,
          767,
          1780,
          11,
          286,
          486,
          294,
          1186,
          312,
          1075,
          281,
          1662,
          50814
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2615,
        "id": 708,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2611,
        "temperature": 0,
        "text": " after there's a class that starts here at 3 right in the room next to me.",
        "tokens": [
          50814,
          934,
          456,
          311,
          257,
          1508,
          300,
          3719,
          510,
          412,
          805,
          558,
          294,
          264,
          1808,
          958,
          281,
          385,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2619,
        "id": 709,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2615,
        "temperature": 0,
        "text": " So noise-wise, I can't be talking and broadcasting very loudly.",
        "tokens": [
          51014,
          407,
          5658,
          12,
          3711,
          11,
          286,
          393,
          380,
          312,
          1417,
          293,
          30024,
          588,
          22958,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2624,
        "id": 710,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2619,
        "temperature": 0,
        "text": " But as soon as that class ends, I'm going to have an interview with Jane that I mentioned earlier,",
        "tokens": [
          51214,
          583,
          382,
          2321,
          382,
          300,
          1508,
          5314,
          11,
          286,
          478,
          516,
          281,
          362,
          364,
          4049,
          365,
          13048,
          300,
          286,
          2835,
          3071,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20655246341929717,
        "compression_ratio": 1.6506410256410255,
        "end": 2628,
        "id": 711,
        "no_speech_prob": 0.09007725864648819,
        "seek": 260200,
        "start": 2624,
        "temperature": 0,
        "text": " and then also if there's a little extra time, I might do one more tutorial about this as well.",
        "tokens": [
          51464,
          293,
          550,
          611,
          498,
          456,
          311,
          257,
          707,
          2857,
          565,
          11,
          286,
          1062,
          360,
          472,
          544,
          7073,
          466,
          341,
          382,
          731,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20403757635152564,
        "compression_ratio": 1.2868217054263567,
        "end": 2636,
        "id": 712,
        "no_speech_prob": 0.00012339356180746108,
        "seek": 263200,
        "start": 2633,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          50414,
          1033,
          11,
          510,
          321,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20403757635152564,
        "compression_ratio": 1.2868217054263567,
        "end": 2638,
        "id": 713,
        "no_speech_prob": 0.00012339356180746108,
        "seek": 263200,
        "start": 2636,
        "temperature": 0,
        "text": " Let me cycle the cameras.",
        "tokens": [
          50564,
          961,
          385,
          6586,
          264,
          8622,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20403757635152564,
        "compression_ratio": 1.2868217054263567,
        "end": 2651,
        "id": 714,
        "no_speech_prob": 0.00012339356180746108,
        "seek": 263200,
        "start": 2646,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20403757635152564,
        "compression_ratio": 1.2868217054263567,
        "end": 2652,
        "id": 715,
        "no_speech_prob": 0.00012339356180746108,
        "seek": 263200,
        "start": 2651,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51314,
          2425,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20403757635152564,
        "compression_ratio": 1.2868217054263567,
        "end": 2659,
        "id": 716,
        "no_speech_prob": 0.00012339356180746108,
        "seek": 263200,
        "start": 2652,
        "temperature": 0,
        "text": " Okay, so now what I would like to do in this video is actually add a front end client to this particular API.",
        "tokens": [
          51364,
          1033,
          11,
          370,
          586,
          437,
          286,
          576,
          411,
          281,
          360,
          294,
          341,
          960,
          307,
          767,
          909,
          257,
          1868,
          917,
          6423,
          281,
          341,
          1729,
          9362,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2663,
        "id": 717,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2659,
        "temperature": 0,
        "text": " Now, there's a kind of question in my mind just floating around here,",
        "tokens": [
          50364,
          823,
          11,
          456,
          311,
          257,
          733,
          295,
          1168,
          294,
          452,
          1575,
          445,
          12607,
          926,
          510,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2666,
        "id": 718,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2663,
        "temperature": 0,
        "text": " which is like, whoa, why am I doing any of this?",
        "tokens": [
          50564,
          597,
          307,
          411,
          11,
          13310,
          11,
          983,
          669,
          286,
          884,
          604,
          295,
          341,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2672,
        "id": 719,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2666,
        "temperature": 0,
        "text": " And so on the one hand, I might be making kind of a build-your-own API in Node just for one person,",
        "tokens": [
          50714,
          400,
          370,
          322,
          264,
          472,
          1011,
          11,
          286,
          1062,
          312,
          1455,
          733,
          295,
          257,
          1322,
          12,
          23093,
          12,
          648,
          9362,
          294,
          38640,
          445,
          337,
          472,
          954,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2673,
        "id": 720,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2672,
        "temperature": 0,
        "text": " and that's for myself.",
        "tokens": [
          51014,
          293,
          300,
          311,
          337,
          2059,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2677,
        "id": 721,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2673,
        "temperature": 0,
        "text": " Like I might want to make an API as a way of storing data and communicating",
        "tokens": [
          51064,
          1743,
          286,
          1062,
          528,
          281,
          652,
          364,
          9362,
          382,
          257,
          636,
          295,
          26085,
          1412,
          293,
          17559,
          51264
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2680,
        "id": 722,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2677,
        "temperature": 0,
        "text": " and doing server-side stuff for my particular front end.",
        "tokens": [
          51264,
          293,
          884,
          7154,
          12,
          1812,
          1507,
          337,
          452,
          1729,
          1868,
          917,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2684,
        "id": 723,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2680,
        "temperature": 0,
        "text": " I also might want to make an API that is open for other clients to be able to connect to,",
        "tokens": [
          51414,
          286,
          611,
          1062,
          528,
          281,
          652,
          364,
          9362,
          300,
          307,
          1269,
          337,
          661,
          6982,
          281,
          312,
          1075,
          281,
          1745,
          281,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.17525007313695448,
        "compression_ratio": 1.7433333333333334,
        "end": 2687,
        "id": 724,
        "no_speech_prob": 0.011331332847476006,
        "seek": 265900,
        "start": 2684,
        "temperature": 0,
        "text": " and that's something that I've got to get to in this list.",
        "tokens": [
          51614,
          293,
          300,
          311,
          746,
          300,
          286,
          600,
          658,
          281,
          483,
          281,
          294,
          341,
          1329,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2688,
        "id": 725,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2687,
        "temperature": 0,
        "text": " So at some point I'll show you.",
        "tokens": [
          50364,
          407,
          412,
          512,
          935,
          286,
          603,
          855,
          291,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2695,
        "id": 726,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2688,
        "temperature": 0,
        "text": " It's actually very easy to open up your API to other servers to make requests using a Node package called cores,",
        "tokens": [
          50414,
          467,
          311,
          767,
          588,
          1858,
          281,
          1269,
          493,
          428,
          9362,
          281,
          661,
          15909,
          281,
          652,
          12475,
          1228,
          257,
          38640,
          7372,
          1219,
          24826,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2696,
        "id": 727,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2695,
        "temperature": 0,
        "text": " but I'll come back to that.",
        "tokens": [
          50764,
          457,
          286,
          603,
          808,
          646,
          281,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2700,
        "id": 728,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2696,
        "temperature": 0,
        "text": " For right now, I'm almost thinking of this as just my own little project,",
        "tokens": [
          50814,
          1171,
          558,
          586,
          11,
          286,
          478,
          1920,
          1953,
          295,
          341,
          382,
          445,
          452,
          1065,
          707,
          1716,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2702,
        "id": 729,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2700,
        "temperature": 0,
        "text": " and some of my project I need server-side programming,",
        "tokens": [
          51014,
          293,
          512,
          295,
          452,
          1716,
          286,
          643,
          7154,
          12,
          1812,
          9410,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2704,
        "id": 730,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2702,
        "temperature": 0,
        "text": " and some of my project I need client-side programming,",
        "tokens": [
          51114,
          293,
          512,
          295,
          452,
          1716,
          286,
          643,
          6423,
          12,
          1812,
          9410,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2706,
        "id": 731,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2704,
        "temperature": 0,
        "text": " but I need those two things to talk to each other.",
        "tokens": [
          51214,
          457,
          286,
          643,
          729,
          732,
          721,
          281,
          751,
          281,
          1184,
          661,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2711,
        "id": 732,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2706,
        "temperature": 0,
        "text": " So the first thing that I want, if you recall, one of the pieces of this program that we've written",
        "tokens": [
          51314,
          407,
          264,
          700,
          551,
          300,
          286,
          528,
          11,
          498,
          291,
          9901,
          11,
          472,
          295,
          264,
          3755,
          295,
          341,
          1461,
          300,
          321,
          600,
          3720,
          51564
        ]
      },
      {
        "avg_logprob": -0.20130780625016723,
        "compression_ratio": 1.792332268370607,
        "end": 2716,
        "id": 733,
        "no_speech_prob": 0.027584092691540718,
        "seek": 268700,
        "start": 2711,
        "temperature": 0,
        "text": " actually uses Express's ability to host static files,",
        "tokens": [
          51564,
          767,
          4960,
          20212,
          311,
          3485,
          281,
          3975,
          13437,
          7098,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.21902122182294356,
        "compression_ratio": 1.8468085106382979,
        "end": 2719,
        "id": 734,
        "no_speech_prob": 0.02931136265397072,
        "seek": 271600,
        "start": 2716,
        "temperature": 0,
        "text": " and all the static files are in this directory called website.",
        "tokens": [
          50364,
          293,
          439,
          264,
          13437,
          7098,
          366,
          294,
          341,
          21120,
          1219,
          3144,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21902122182294356,
        "compression_ratio": 1.8468085106382979,
        "end": 2723,
        "id": 735,
        "no_speech_prob": 0.02931136265397072,
        "seek": 271600,
        "start": 2719,
        "temperature": 0,
        "text": " But I called it website just to call it something, but often it's called public,",
        "tokens": [
          50514,
          583,
          286,
          1219,
          309,
          3144,
          445,
          281,
          818,
          309,
          746,
          11,
          457,
          2049,
          309,
          311,
          1219,
          1908,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.21902122182294356,
        "compression_ratio": 1.8468085106382979,
        "end": 2725,
        "id": 736,
        "no_speech_prob": 0.02931136265397072,
        "seek": 271600,
        "start": 2723,
        "temperature": 0,
        "text": " or you can call it whatever you want, unicorn, whatever you want to call it.",
        "tokens": [
          50714,
          420,
          291,
          393,
          818,
          309,
          2035,
          291,
          528,
          11,
          28122,
          11,
          2035,
          291,
          528,
          281,
          818,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21902122182294356,
        "compression_ratio": 1.8468085106382979,
        "end": 2730,
        "id": 737,
        "no_speech_prob": 0.02931136265397072,
        "seek": 271600,
        "start": 2725,
        "temperature": 0,
        "text": " You have a folder with files that you want to serve, and I have right in there,",
        "tokens": [
          50814,
          509,
          362,
          257,
          10820,
          365,
          7098,
          300,
          291,
          528,
          281,
          4596,
          11,
          293,
          286,
          362,
          558,
          294,
          456,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.21902122182294356,
        "compression_ratio": 1.8468085106382979,
        "end": 2734,
        "id": 738,
        "no_speech_prob": 0.02931136265397072,
        "seek": 271600,
        "start": 2730,
        "temperature": 0,
        "text": " I have this index.html file, and all it says in it is, hello.",
        "tokens": [
          51064,
          286,
          362,
          341,
          8186,
          13,
          357,
          15480,
          3991,
          11,
          293,
          439,
          309,
          1619,
          294,
          309,
          307,
          11,
          7751,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21902122182294356,
        "compression_ratio": 1.8468085106382979,
        "end": 2739,
        "id": 739,
        "no_speech_prob": 0.02931136265397072,
        "seek": 271600,
        "start": 2734,
        "temperature": 0,
        "text": " So if I go back to the browser and I go to the root page, I see, hello.",
        "tokens": [
          51264,
          407,
          498,
          286,
          352,
          646,
          281,
          264,
          11185,
          293,
          286,
          352,
          281,
          264,
          5593,
          3028,
          11,
          286,
          536,
          11,
          7751,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16532518138056215,
        "compression_ratio": 1.7155172413793103,
        "end": 2747,
        "id": 740,
        "no_speech_prob": 0.057486508041620255,
        "seek": 273900,
        "start": 2740,
        "temperature": 0,
        "text": " And so what I want to do now is I'm going to grab from my desktop a p5 sketch.",
        "tokens": [
          50414,
          400,
          370,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          286,
          478,
          516,
          281,
          4444,
          490,
          452,
          14502,
          257,
          280,
          20,
          12325,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16532518138056215,
        "compression_ratio": 1.7155172413793103,
        "end": 2752,
        "id": 741,
        "no_speech_prob": 0.057486508041620255,
        "seek": 273900,
        "start": 2747,
        "temperature": 0,
        "text": " So it has an index.html file, some JavaScript code, and the libraries that I want to use,",
        "tokens": [
          50764,
          407,
          309,
          575,
          364,
          8186,
          13,
          357,
          15480,
          3991,
          11,
          512,
          15778,
          3089,
          11,
          293,
          264,
          15148,
          300,
          286,
          528,
          281,
          764,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.16532518138056215,
        "compression_ratio": 1.7155172413793103,
        "end": 2760,
        "id": 742,
        "no_speech_prob": 0.057486508041620255,
        "seek": 273900,
        "start": 2752,
        "temperature": 0,
        "text": " and I'm going to actually go into this particular API example that I'm making,",
        "tokens": [
          51014,
          293,
          286,
          478,
          516,
          281,
          767,
          352,
          666,
          341,
          1729,
          9362,
          1365,
          300,
          286,
          478,
          1455,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.16532518138056215,
        "compression_ratio": 1.7155172413793103,
        "end": 2762,
        "id": 743,
        "no_speech_prob": 0.057486508041620255,
        "seek": 273900,
        "start": 2760,
        "temperature": 0,
        "text": " and I'm going to put that all in here, and I'm going to replace.",
        "tokens": [
          51414,
          293,
          286,
          478,
          516,
          281,
          829,
          300,
          439,
          294,
          510,
          11,
          293,
          286,
          478,
          516,
          281,
          7406,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16532518138056215,
        "compression_ratio": 1.7155172413793103,
        "end": 2767,
        "id": 744,
        "no_speech_prob": 0.057486508041620255,
        "seek": 273900,
        "start": 2762,
        "temperature": 0,
        "text": " So now if I hit refresh, one thing is I don't have to restart the server, by the way.",
        "tokens": [
          51514,
          407,
          586,
          498,
          286,
          2045,
          15134,
          11,
          472,
          551,
          307,
          286,
          500,
          380,
          362,
          281,
          21022,
          264,
          7154,
          11,
          538,
          264,
          636,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21457292483403131,
        "compression_ratio": 1.6244343891402715,
        "end": 2770,
        "id": 745,
        "no_speech_prob": 0.00600353954359889,
        "seek": 276700,
        "start": 2767,
        "temperature": 0,
        "text": " The server is going to be able to just serve up those files as they change,",
        "tokens": [
          50364,
          440,
          7154,
          307,
          516,
          281,
          312,
          1075,
          281,
          445,
          4596,
          493,
          729,
          7098,
          382,
          436,
          1319,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.21457292483403131,
        "compression_ratio": 1.6244343891402715,
        "end": 2776,
        "id": 746,
        "no_speech_prob": 0.00600353954359889,
        "seek": 276700,
        "start": 2770,
        "temperature": 0,
        "text": " and we can see now anything, and I go over here and I can add some code.",
        "tokens": [
          50514,
          293,
          321,
          393,
          536,
          586,
          1340,
          11,
          293,
          286,
          352,
          670,
          510,
          293,
          286,
          393,
          909,
          512,
          3089,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21457292483403131,
        "compression_ratio": 1.6244343891402715,
        "end": 2780,
        "id": 747,
        "no_speech_prob": 0.00600353954359889,
        "seek": 276700,
        "start": 2776,
        "temperature": 0,
        "text": " I can say, you know, maybe no canvas. I don't want a canvas right now.",
        "tokens": [
          50814,
          286,
          393,
          584,
          11,
          291,
          458,
          11,
          1310,
          572,
          16267,
          13,
          286,
          500,
          380,
          528,
          257,
          16267,
          558,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21457292483403131,
        "compression_ratio": 1.6244343891402715,
        "end": 2787,
        "id": 748,
        "no_speech_prob": 0.00600353954359889,
        "seek": 276700,
        "start": 2780,
        "temperature": 0,
        "text": " And I can say console.log running. Is your refrigerator running?",
        "tokens": [
          51014,
          400,
          286,
          393,
          584,
          11076,
          13,
          4987,
          2614,
          13,
          1119,
          428,
          19655,
          2614,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.21457292483403131,
        "compression_ratio": 1.6244343891402715,
        "end": 2790,
        "id": 749,
        "no_speech_prob": 0.00600353954359889,
        "seek": 276700,
        "start": 2787,
        "temperature": 0,
        "text": " You better go and catch it. And I can see, aha.",
        "tokens": [
          51364,
          509,
          1101,
          352,
          293,
          3745,
          309,
          13,
          400,
          286,
          393,
          536,
          11,
          47340,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21457292483403131,
        "compression_ratio": 1.6244343891402715,
        "end": 2792,
        "id": 750,
        "no_speech_prob": 0.00600353954359889,
        "seek": 276700,
        "start": 2790,
        "temperature": 0,
        "text": " So that sketch is working.",
        "tokens": [
          51514,
          407,
          300,
          12325,
          307,
          1364,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19668546977796053,
        "compression_ratio": 1.6386138613861385,
        "end": 2798,
        "id": 751,
        "no_speech_prob": 0.00970828253775835,
        "seek": 279200,
        "start": 2792,
        "temperature": 0,
        "text": " So now how do I do something to access the data that's part of this API?",
        "tokens": [
          50364,
          407,
          586,
          577,
          360,
          286,
          360,
          746,
          281,
          2105,
          264,
          1412,
          300,
          311,
          644,
          295,
          341,
          9362,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.19668546977796053,
        "compression_ratio": 1.6386138613861385,
        "end": 2801,
        "id": 752,
        "no_speech_prob": 0.00970828253775835,
        "seek": 279200,
        "start": 2798,
        "temperature": 0,
        "text": " So one thing is actually, never mind that. Let me actually add a canvas.",
        "tokens": [
          50664,
          407,
          472,
          551,
          307,
          767,
          11,
          1128,
          1575,
          300,
          13,
          961,
          385,
          767,
          909,
          257,
          16267,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19668546977796053,
        "compression_ratio": 1.6386138613861385,
        "end": 2807,
        "id": 753,
        "no_speech_prob": 0.00970828253775835,
        "seek": 279200,
        "start": 2801,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to say create canvas,",
        "tokens": [
          50814,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          1884,
          16267,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19668546977796053,
        "compression_ratio": 1.6386138613861385,
        "end": 2815,
        "id": 754,
        "no_speech_prob": 0.00970828253775835,
        "seek": 279200,
        "start": 2807,
        "temperature": 0,
        "text": " and I'm going to say 400, 400, and background 51, which is my background color of choice,",
        "tokens": [
          51114,
          293,
          286,
          478,
          516,
          281,
          584,
          8423,
          11,
          8423,
          11,
          293,
          3678,
          18485,
          11,
          597,
          307,
          452,
          3678,
          2017,
          295,
          3922,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.19668546977796053,
        "compression_ratio": 1.6386138613861385,
        "end": 2817,
        "id": 755,
        "no_speech_prob": 0.00970828253775835,
        "seek": 279200,
        "start": 2815,
        "temperature": 0,
        "text": " and we can see I now have a canvas.",
        "tokens": [
          51514,
          293,
          321,
          393,
          536,
          286,
          586,
          362,
          257,
          16267,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21685189911813446,
        "compression_ratio": 1.6277372262773722,
        "end": 2821,
        "id": 756,
        "no_speech_prob": 0.2909499704837799,
        "seek": 281700,
        "start": 2817,
        "temperature": 0,
        "text": " It's huge. No, no, no, no. Stay large over there and small over here.",
        "tokens": [
          50364,
          467,
          311,
          2603,
          13,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          8691,
          2416,
          670,
          456,
          293,
          1359,
          670,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21685189911813446,
        "compression_ratio": 1.6277372262773722,
        "end": 2829,
        "id": 757,
        "no_speech_prob": 0.2909499704837799,
        "seek": 281700,
        "start": 2821,
        "temperature": 0,
        "text": " Okay, so now I have this canvas, and what I want to do is I now want to say load JSON slash all.",
        "tokens": [
          50564,
          1033,
          11,
          370,
          586,
          286,
          362,
          341,
          16267,
          11,
          293,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          586,
          528,
          281,
          584,
          3677,
          31828,
          17330,
          439,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21685189911813446,
        "compression_ratio": 1.6277372262773722,
        "end": 2831,
        "id": 758,
        "no_speech_prob": 0.2909499704837799,
        "seek": 281700,
        "start": 2829,
        "temperature": 0,
        "text": " And I don't even know if I need that slash.",
        "tokens": [
          50964,
          400,
          286,
          500,
          380,
          754,
          458,
          498,
          286,
          643,
          300,
          17330,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21685189911813446,
        "compression_ratio": 1.6277372262773722,
        "end": 2836,
        "id": 759,
        "no_speech_prob": 0.2909499704837799,
        "seek": 281700,
        "start": 2831,
        "temperature": 0,
        "text": " Look at this. If you've ever done anything with p5 or jQuery",
        "tokens": [
          51064,
          2053,
          412,
          341,
          13,
          759,
          291,
          600,
          1562,
          1096,
          1340,
          365,
          280,
          20,
          420,
          361,
          35550,
          51314
        ]
      },
      {
        "avg_logprob": -0.21685189911813446,
        "compression_ratio": 1.6277372262773722,
        "end": 2842,
        "id": 760,
        "no_speech_prob": 0.2909499704837799,
        "seek": 281700,
        "start": 2836,
        "temperature": 0,
        "text": " where you're loading something from an API, openweathermap.org slash API slash city slash New York,",
        "tokens": [
          51314,
          689,
          291,
          434,
          15114,
          746,
          490,
          364,
          9362,
          11,
          1269,
          826,
          1172,
          24223,
          13,
          4646,
          17330,
          9362,
          17330,
          2307,
          17330,
          1873,
          3609,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21685189911813446,
        "compression_ratio": 1.6277372262773722,
        "end": 2846,
        "id": 761,
        "no_speech_prob": 0.2909499704837799,
        "seek": 281700,
        "start": 2842,
        "temperature": 0,
        "text": " what I'm doing here is I'm querying the API, but rather than the full URL,",
        "tokens": [
          51614,
          437,
          286,
          478,
          884,
          510,
          307,
          286,
          478,
          7083,
          1840,
          264,
          9362,
          11,
          457,
          2831,
          813,
          264,
          1577,
          12905,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1787475117465906,
        "compression_ratio": 1.7489878542510122,
        "end": 2851,
        "id": 762,
        "no_speech_prob": 0.009267904795706272,
        "seek": 284600,
        "start": 2846,
        "temperature": 0,
        "text": " the API is running on the same server that's hosting this JavaScript sketch.",
        "tokens": [
          50364,
          264,
          9362,
          307,
          2614,
          322,
          264,
          912,
          7154,
          300,
          311,
          16058,
          341,
          15778,
          12325,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1787475117465906,
        "compression_ratio": 1.7489878542510122,
        "end": 2858,
        "id": 763,
        "no_speech_prob": 0.009267904795706272,
        "seek": 284600,
        "start": 2851,
        "temperature": 0,
        "text": " So I could just say slash all, or I could say slash search slash rainbow.",
        "tokens": [
          50614,
          407,
          286,
          727,
          445,
          584,
          17330,
          439,
          11,
          420,
          286,
          727,
          584,
          17330,
          3164,
          17330,
          18526,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1787475117465906,
        "compression_ratio": 1.7489878542510122,
        "end": 2862,
        "id": 764,
        "no_speech_prob": 0.009267904795706272,
        "seek": 284600,
        "start": 2858,
        "temperature": 0,
        "text": " I can go to any of the routes simply from the load JSON function.",
        "tokens": [
          50964,
          286,
          393,
          352,
          281,
          604,
          295,
          264,
          18242,
          2935,
          490,
          264,
          3677,
          31828,
          2445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1787475117465906,
        "compression_ratio": 1.7489878542510122,
        "end": 2866,
        "id": 765,
        "no_speech_prob": 0.009267904795706272,
        "seek": 284600,
        "start": 2862,
        "temperature": 0,
        "text": " So what I want to do is do slash all, and I'm going to then have a callback",
        "tokens": [
          51164,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          360,
          17330,
          439,
          11,
          293,
          286,
          478,
          516,
          281,
          550,
          362,
          257,
          818,
          3207,
          51364
        ]
      },
      {
        "avg_logprob": -0.1787475117465906,
        "compression_ratio": 1.7489878542510122,
        "end": 2871,
        "id": 766,
        "no_speech_prob": 0.009267904795706272,
        "seek": 284600,
        "start": 2866,
        "temperature": 0,
        "text": " for when I've gotten the data called got data, and I'm going to write that function,",
        "tokens": [
          51364,
          337,
          562,
          286,
          600,
          5768,
          264,
          1412,
          1219,
          658,
          1412,
          11,
          293,
          286,
          478,
          516,
          281,
          2464,
          300,
          2445,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.1787475117465906,
        "compression_ratio": 1.7489878542510122,
        "end": 2875,
        "id": 767,
        "no_speech_prob": 0.009267904795706272,
        "seek": 284600,
        "start": 2871,
        "temperature": 0,
        "text": " and the data comes in as an argument to that function,",
        "tokens": [
          51614,
          293,
          264,
          1412,
          1487,
          294,
          382,
          364,
          6770,
          281,
          300,
          2445,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2878,
        "id": 768,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2875,
        "temperature": 0,
        "text": " and just to see that it's working, I'm going to say console.log data.",
        "tokens": [
          50364,
          293,
          445,
          281,
          536,
          300,
          309,
          311,
          1364,
          11,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          1412,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2881,
        "id": 769,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2878,
        "temperature": 0,
        "text": " So let's run this again, and we can see there it is.",
        "tokens": [
          50514,
          407,
          718,
          311,
          1190,
          341,
          797,
          11,
          293,
          321,
          393,
          536,
          456,
          309,
          307,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2887,
        "id": 770,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2881,
        "temperature": 0,
        "text": " I now have accessed in my client-side code all the data that's running in the server.",
        "tokens": [
          50664,
          286,
          586,
          362,
          34211,
          294,
          452,
          6423,
          12,
          1812,
          3089,
          439,
          264,
          1412,
          300,
          311,
          2614,
          294,
          264,
          7154,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2891,
        "id": 771,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2887,
        "temperature": 0,
        "text": " And one thing that I'll do here just out of curiosity, so I'm going to get rid of this slash.",
        "tokens": [
          50964,
          400,
          472,
          551,
          300,
          286,
          603,
          360,
          510,
          445,
          484,
          295,
          18769,
          11,
          370,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          341,
          17330,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2895,
        "id": 772,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2891,
        "temperature": 0,
        "text": " I think it works with absolute or relative paths, so you can see that works either way.",
        "tokens": [
          51164,
          286,
          519,
          309,
          1985,
          365,
          8236,
          420,
          4972,
          14518,
          11,
          370,
          291,
          393,
          536,
          300,
          1985,
          2139,
          636,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2899,
        "id": 773,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2895,
        "temperature": 0,
        "text": " Okay, now what could I do? Let's say I want to iterate all over these.",
        "tokens": [
          51364,
          1033,
          11,
          586,
          437,
          727,
          286,
          360,
          30,
          961,
          311,
          584,
          286,
          528,
          281,
          44497,
          439,
          670,
          613,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16866061626336512,
        "compression_ratio": 1.7827476038338659,
        "end": 2903,
        "id": 774,
        "no_speech_prob": 0.02228577435016632,
        "seek": 287500,
        "start": 2899,
        "temperature": 0,
        "text": " There's kind of a trick. This is an object, so there's not an easy way to iterate over an object",
        "tokens": [
          51564,
          821,
          311,
          733,
          295,
          257,
          4282,
          13,
          639,
          307,
          364,
          2657,
          11,
          370,
          456,
          311,
          406,
          364,
          1858,
          636,
          281,
          44497,
          670,
          364,
          2657,
          51764
        ]
      },
      {
        "avg_logprob": -0.14819361582523635,
        "compression_ratio": 1.8103448275862069,
        "end": 2906,
        "id": 775,
        "no_speech_prob": 0.021947670727968216,
        "seek": 290300,
        "start": 2903,
        "temperature": 0,
        "text": " as if it's an array, although there are plenty of ways to do that.",
        "tokens": [
          50364,
          382,
          498,
          309,
          311,
          364,
          10225,
          11,
          4878,
          456,
          366,
          7140,
          295,
          2098,
          281,
          360,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14819361582523635,
        "compression_ratio": 1.8103448275862069,
        "end": 2912,
        "id": 776,
        "no_speech_prob": 0.021947670727968216,
        "seek": 290300,
        "start": 2906,
        "temperature": 0,
        "text": " A way that I like to do it is I can say var keys equals object keys data,",
        "tokens": [
          50514,
          316,
          636,
          300,
          286,
          411,
          281,
          360,
          309,
          307,
          286,
          393,
          584,
          1374,
          9317,
          6915,
          2657,
          9317,
          1412,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.14819361582523635,
        "compression_ratio": 1.8103448275862069,
        "end": 2917,
        "id": 777,
        "no_speech_prob": 0.021947670727968216,
        "seek": 290300,
        "start": 2912,
        "temperature": 0,
        "text": " and I'm going to just show you what that gives you, console.log keys.",
        "tokens": [
          50814,
          293,
          286,
          478,
          516,
          281,
          445,
          855,
          291,
          437,
          300,
          2709,
          291,
          11,
          11076,
          13,
          4987,
          9317,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14819361582523635,
        "compression_ratio": 1.8103448275862069,
        "end": 2922,
        "id": 778,
        "no_speech_prob": 0.021947670727968216,
        "seek": 290300,
        "start": 2917,
        "temperature": 0,
        "text": " What you can see is it gives you an array with just the keys in that object.",
        "tokens": [
          51064,
          708,
          291,
          393,
          536,
          307,
          309,
          2709,
          291,
          364,
          10225,
          365,
          445,
          264,
          9317,
          294,
          300,
          2657,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14819361582523635,
        "compression_ratio": 1.8103448275862069,
        "end": 2926,
        "id": 779,
        "no_speech_prob": 0.021947670727968216,
        "seek": 290300,
        "start": 2922,
        "temperature": 0,
        "text": " So you can see this is the full object, but now I have an array with just the keys,",
        "tokens": [
          51314,
          407,
          291,
          393,
          536,
          341,
          307,
          264,
          1577,
          2657,
          11,
          457,
          586,
          286,
          362,
          364,
          10225,
          365,
          445,
          264,
          9317,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.14819361582523635,
        "compression_ratio": 1.8103448275862069,
        "end": 2928,
        "id": 780,
        "no_speech_prob": 0.021947670727968216,
        "seek": 290300,
        "start": 2926,
        "temperature": 0,
        "text": " and that's an easy thing for me to iterate over.",
        "tokens": [
          51514,
          293,
          300,
          311,
          364,
          1858,
          551,
          337,
          385,
          281,
          44497,
          670,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2333429100808133,
        "compression_ratio": 1.5441176470588236,
        "end": 2935,
        "id": 781,
        "no_speech_prob": 0.3207840323448181,
        "seek": 292800,
        "start": 2929,
        "temperature": 0,
        "text": " So I can do something like for var i equals 0, and I know I could do a for each or whatever.",
        "tokens": [
          50414,
          407,
          286,
          393,
          360,
          746,
          411,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          293,
          286,
          458,
          286,
          727,
          360,
          257,
          337,
          1184,
          420,
          2035,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2333429100808133,
        "compression_ratio": 1.5441176470588236,
        "end": 2939,
        "id": 782,
        "no_speech_prob": 0.3207840323448181,
        "seek": 292800,
        "start": 2935,
        "temperature": 0,
        "text": " Everybody always complains, but I just have an old-world style of programming.",
        "tokens": [
          50714,
          7646,
          1009,
          1209,
          2315,
          11,
          457,
          286,
          445,
          362,
          364,
          1331,
          12,
          13217,
          3758,
          295,
          9410,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2333429100808133,
        "compression_ratio": 1.5441176470588236,
        "end": 2941,
        "id": 783,
        "no_speech_prob": 0.3207840323448181,
        "seek": 292800,
        "start": 2939,
        "temperature": 0,
        "text": " I like my for loops like this.",
        "tokens": [
          50914,
          286,
          411,
          452,
          337,
          16121,
          411,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2333429100808133,
        "compression_ratio": 1.5441176470588236,
        "end": 2945,
        "id": 784,
        "no_speech_prob": 0.3207840323448181,
        "seek": 292800,
        "start": 2941,
        "temperature": 0,
        "text": " And I'm going to say key equals keys index i.",
        "tokens": [
          51014,
          400,
          286,
          478,
          516,
          281,
          584,
          2141,
          6915,
          9317,
          8186,
          741,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2333429100808133,
        "compression_ratio": 1.5441176470588236,
        "end": 2951,
        "id": 785,
        "no_speech_prob": 0.3207840323448181,
        "seek": 292800,
        "start": 2945,
        "temperature": 0,
        "text": " I'm going to say word, actually, and score equals data index word.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          584,
          1349,
          11,
          767,
          11,
          293,
          6175,
          6915,
          1412,
          8186,
          1349,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20028537152761436,
        "compression_ratio": 1.496969696969697,
        "end": 2959,
        "id": 786,
        "no_speech_prob": 0.12251544743776321,
        "seek": 295100,
        "start": 2951,
        "temperature": 0,
        "text": " And then I could say var x equals random width, and var y equals random height,",
        "tokens": [
          50364,
          400,
          550,
          286,
          727,
          584,
          1374,
          2031,
          6915,
          4974,
          11402,
          11,
          293,
          1374,
          288,
          6915,
          4974,
          6681,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.20028537152761436,
        "compression_ratio": 1.496969696969697,
        "end": 2965,
        "id": 787,
        "no_speech_prob": 0.12251544743776321,
        "seek": 295100,
        "start": 2959,
        "temperature": 0,
        "text": " and fill 255, and text word at x and y.",
        "tokens": [
          50764,
          293,
          2836,
          3552,
          20,
          11,
          293,
          2487,
          1349,
          412,
          2031,
          293,
          288,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20028537152761436,
        "compression_ratio": 1.496969696969697,
        "end": 2968,
        "id": 788,
        "no_speech_prob": 0.12251544743776321,
        "seek": 295100,
        "start": 2965,
        "temperature": 0,
        "text": " And let's see what I get now.",
        "tokens": [
          51064,
          400,
          718,
          311,
          536,
          437,
          286,
          483,
          586,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20028537152761436,
        "compression_ratio": 1.496969696969697,
        "end": 2971,
        "id": 789,
        "no_speech_prob": 0.12251544743776321,
        "seek": 295100,
        "start": 2968,
        "temperature": 0,
        "text": " If we run this, we can see. And let's make it bigger.",
        "tokens": [
          51214,
          759,
          321,
          1190,
          341,
          11,
          321,
          393,
          536,
          13,
          400,
          718,
          311,
          652,
          309,
          3801,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20028537152761436,
        "compression_ratio": 1.496969696969697,
        "end": 2974,
        "id": 790,
        "no_speech_prob": 0.12251544743776321,
        "seek": 295100,
        "start": 2971,
        "temperature": 0,
        "text": " Text size 64.",
        "tokens": [
          51364,
          18643,
          2744,
          12145,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20028537152761436,
        "compression_ratio": 1.496969696969697,
        "end": 2976,
        "id": 791,
        "no_speech_prob": 0.12251544743776321,
        "seek": 295100,
        "start": 2974,
        "temperature": 0,
        "text": " And you can see, there we go.",
        "tokens": [
          51514,
          400,
          291,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 2982,
        "id": 792,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2976,
        "temperature": 0,
        "text": " So obviously I could... I'm seeing now all the words that are in the database",
        "tokens": [
          50364,
          407,
          2745,
          286,
          727,
          485,
          286,
          478,
          2577,
          586,
          439,
          264,
          2283,
          300,
          366,
          294,
          264,
          8149,
          50664
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 2984,
        "id": 793,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2982,
        "temperature": 0,
        "text": " kind of visualized in the canvas.",
        "tokens": [
          50664,
          733,
          295,
          5056,
          1602,
          294,
          264,
          16267,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 2986,
        "id": 794,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2984,
        "temperature": 0,
        "text": " And I could, of course, like color them.",
        "tokens": [
          50764,
          400,
          286,
          727,
          11,
          295,
          1164,
          11,
          411,
          2017,
          552,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 2988,
        "id": 795,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2986,
        "temperature": 0,
        "text": " I could think about visualizing in a thoughtful way.",
        "tokens": [
          50864,
          286,
          727,
          519,
          466,
          5056,
          3319,
          294,
          257,
          21566,
          636,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 2992,
        "id": 796,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2988,
        "temperature": 0,
        "text": " I could make their font size and their color based on their sentiment score.",
        "tokens": [
          50964,
          286,
          727,
          652,
          641,
          10703,
          2744,
          293,
          641,
          2017,
          2361,
          322,
          641,
          16149,
          6175,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 2996,
        "id": 797,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2992,
        "temperature": 0,
        "text": " But I'm just showing you that I can access a particular route",
        "tokens": [
          51164,
          583,
          286,
          478,
          445,
          4099,
          291,
          300,
          286,
          393,
          2105,
          257,
          1729,
          7955,
          51364
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 3000,
        "id": 798,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 2996,
        "temperature": 0,
        "text": " and then visualize that route, visualize the results of the data",
        "tokens": [
          51364,
          293,
          550,
          23273,
          300,
          7955,
          11,
          23273,
          264,
          3542,
          295,
          264,
          1412,
          51564
        ]
      },
      {
        "avg_logprob": -0.20332007572568697,
        "compression_ratio": 1.832,
        "end": 3002,
        "id": 799,
        "no_speech_prob": 0.036218080669641495,
        "seek": 297600,
        "start": 3000,
        "temperature": 0,
        "text": " that I'm getting through that route in a canvas.",
        "tokens": [
          51564,
          300,
          286,
          478,
          1242,
          807,
          300,
          7955,
          294,
          257,
          16267,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3006,
        "id": 800,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3002,
        "temperature": 0,
        "text": " But ultimately, what I might want to do here, actually, even more importantly,",
        "tokens": [
          50364,
          583,
          6284,
          11,
          437,
          286,
          1062,
          528,
          281,
          360,
          510,
          11,
          767,
          11,
          754,
          544,
          8906,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3011,
        "id": 801,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3006,
        "temperature": 0,
        "text": " is I might want to add input id equals word.",
        "tokens": [
          50564,
          307,
          286,
          1062,
          528,
          281,
          909,
          4846,
          4496,
          6915,
          1349,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3016,
        "id": 802,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3011,
        "temperature": 0,
        "text": " And then input id equals score.",
        "tokens": [
          50814,
          400,
          550,
          4846,
          4496,
          6915,
          6175,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3018,
        "id": 803,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3016,
        "temperature": 0,
        "text": " So let's look at what that looks like.",
        "tokens": [
          51064,
          407,
          718,
          311,
          574,
          412,
          437,
          300,
          1542,
          411,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3024,
        "id": 804,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3018,
        "temperature": 0,
        "text": " And I'm going to wrap that in a paragraph.",
        "tokens": [
          51164,
          400,
          286,
          478,
          516,
          281,
          7019,
          300,
          294,
          257,
          18865,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3026,
        "id": 805,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3024,
        "temperature": 0,
        "text": " And I'm going to say word.",
        "tokens": [
          51464,
          400,
          286,
          478,
          516,
          281,
          584,
          1349,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1976761711968316,
        "compression_ratio": 1.7485380116959064,
        "end": 3029,
        "id": 806,
        "no_speech_prob": 0.03567729890346527,
        "seek": 300200,
        "start": 3026,
        "temperature": 0,
        "text": " And I'm going to put a line break.",
        "tokens": [
          51564,
          400,
          286,
          478,
          516,
          281,
          829,
          257,
          1622,
          1821,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18114639282226563,
        "compression_ratio": 1.6129032258064515,
        "end": 3034,
        "id": 807,
        "no_speech_prob": 0.051843348890542984,
        "seek": 302900,
        "start": 3029,
        "temperature": 0,
        "text": " And I'm going to say score and slash p.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          584,
          6175,
          293,
          17330,
          280,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18114639282226563,
        "compression_ratio": 1.6129032258064515,
        "end": 3038,
        "id": 808,
        "no_speech_prob": 0.051843348890542984,
        "seek": 302900,
        "start": 3034,
        "temperature": 0,
        "text": " So now we can see on my web page, and something's driving me a little bit crazy here,",
        "tokens": [
          50614,
          407,
          586,
          321,
          393,
          536,
          322,
          452,
          3670,
          3028,
          11,
          293,
          746,
          311,
          4840,
          385,
          257,
          707,
          857,
          3219,
          510,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.18114639282226563,
        "compression_ratio": 1.6129032258064515,
        "end": 3041,
        "id": 809,
        "no_speech_prob": 0.051843348890542984,
        "seek": 302900,
        "start": 3038,
        "temperature": 0,
        "text": " which is this default styling.",
        "tokens": [
          50814,
          597,
          307,
          341,
          7576,
          27944,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18114639282226563,
        "compression_ratio": 1.6129032258064515,
        "end": 3049,
        "id": 810,
        "no_speech_prob": 0.051843348890542984,
        "seek": 302900,
        "start": 3041,
        "temperature": 0,
        "text": " We can see here that I now have this little kind of basic form.",
        "tokens": [
          50964,
          492,
          393,
          536,
          510,
          300,
          286,
          586,
          362,
          341,
          707,
          733,
          295,
          3875,
          1254,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18114639282226563,
        "compression_ratio": 1.6129032258064515,
        "end": 3054,
        "id": 811,
        "no_speech_prob": 0.051843348890542984,
        "seek": 302900,
        "start": 3049,
        "temperature": 0,
        "text": " It's barely a form, but it's like I made a little paragraph that has word",
        "tokens": [
          51364,
          467,
          311,
          10268,
          257,
          1254,
          11,
          457,
          309,
          311,
          411,
          286,
          1027,
          257,
          707,
          18865,
          300,
          575,
          1349,
          51614
        ]
      },
      {
        "avg_logprob": -0.18114639282226563,
        "compression_ratio": 1.6129032258064515,
        "end": 3056,
        "id": 812,
        "no_speech_prob": 0.051843348890542984,
        "seek": 302900,
        "start": 3054,
        "temperature": 0,
        "text": " and then a text input box, score, and a text input box.",
        "tokens": [
          51614,
          293,
          550,
          257,
          2487,
          4846,
          2424,
          11,
          6175,
          11,
          293,
          257,
          2487,
          4846,
          2424,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3059,
        "id": 813,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3056,
        "temperature": 0,
        "text": " And I just put that in the HTML directly.",
        "tokens": [
          50364,
          400,
          286,
          445,
          829,
          300,
          294,
          264,
          17995,
          3838,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3067,
        "id": 814,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3059,
        "temperature": 0,
        "text": " And then I probably also maybe want to add some sort of button, submit button,",
        "tokens": [
          50514,
          400,
          550,
          286,
          1391,
          611,
          1310,
          528,
          281,
          909,
          512,
          1333,
          295,
          2960,
          11,
          10315,
          2960,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3071,
        "id": 815,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3067,
        "temperature": 0,
        "text": " and I can give that an id also, id equals submit.",
        "tokens": [
          50914,
          293,
          286,
          393,
          976,
          300,
          364,
          4496,
          611,
          11,
          4496,
          6915,
          10315,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3075,
        "id": 816,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3071,
        "temperature": 0,
        "text": " So what I'm doing here is I've made a little interface that has a place for me",
        "tokens": [
          51114,
          407,
          437,
          286,
          478,
          884,
          510,
          307,
          286,
          600,
          1027,
          257,
          707,
          9226,
          300,
          575,
          257,
          1081,
          337,
          385,
          51314
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3079,
        "id": 817,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3075,
        "temperature": 0,
        "text": " to type a word and a score, and I'm able to hit submit.",
        "tokens": [
          51314,
          281,
          2010,
          257,
          1349,
          293,
          257,
          6175,
          11,
          293,
          286,
          478,
          1075,
          281,
          2045,
          10315,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3081,
        "id": 818,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3079,
        "temperature": 0,
        "text": " So why am I doing this?",
        "tokens": [
          51514,
          407,
          983,
          669,
          286,
          884,
          341,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1715883377495162,
        "compression_ratio": 1.6059322033898304,
        "end": 3084,
        "id": 819,
        "no_speech_prob": 0.04023699462413788,
        "seek": 305600,
        "start": 3081,
        "temperature": 0,
        "text": " Because what I want is the moment I click submit,",
        "tokens": [
          51614,
          1436,
          437,
          286,
          528,
          307,
          264,
          1623,
          286,
          2052,
          10315,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.1795350456237793,
        "compression_ratio": 1.6168224299065421,
        "end": 3088,
        "id": 820,
        "no_speech_prob": 0.15609414875507355,
        "seek": 308400,
        "start": 3084,
        "temperature": 0,
        "text": " I want to send what is in those two text fields to the route add.",
        "tokens": [
          50364,
          286,
          528,
          281,
          2845,
          437,
          307,
          294,
          729,
          732,
          2487,
          7909,
          281,
          264,
          7955,
          909,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1795350456237793,
        "compression_ratio": 1.6168224299065421,
        "end": 3099,
        "id": 821,
        "no_speech_prob": 0.15609414875507355,
        "seek": 308400,
        "start": 3088,
        "temperature": 0,
        "text": " I need to go to, if I go right now to add sunflower43,",
        "tokens": [
          50564,
          286,
          643,
          281,
          352,
          281,
          11,
          498,
          286,
          352,
          558,
          586,
          281,
          909,
          48215,
          17201,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.1795350456237793,
        "compression_ratio": 1.6168224299065421,
        "end": 3101,
        "id": 822,
        "no_speech_prob": 0.15609414875507355,
        "seek": 308400,
        "start": 3099,
        "temperature": 0,
        "text": " we can see that that was added.",
        "tokens": [
          51114,
          321,
          393,
          536,
          300,
          300,
          390,
          3869,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1795350456237793,
        "compression_ratio": 1.6168224299065421,
        "end": 3106,
        "id": 823,
        "no_speech_prob": 0.15609414875507355,
        "seek": 308400,
        "start": 3101,
        "temperature": 0,
        "text": " And now if I go back to here, we're going to see that sunflower shows up there.",
        "tokens": [
          51214,
          400,
          586,
          498,
          286,
          352,
          646,
          281,
          510,
          11,
          321,
          434,
          516,
          281,
          536,
          300,
          48215,
          3110,
          493,
          456,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1795350456237793,
        "compression_ratio": 1.6168224299065421,
        "end": 3109,
        "id": 824,
        "no_speech_prob": 0.15609414875507355,
        "seek": 308400,
        "start": 3106,
        "temperature": 0,
        "text": " I don't really like what I've done here with this visualization",
        "tokens": [
          51464,
          286,
          500,
          380,
          534,
          411,
          437,
          286,
          600,
          1096,
          510,
          365,
          341,
          25801,
          51614
        ]
      },
      {
        "avg_logprob": -0.1795350456237793,
        "compression_ratio": 1.6168224299065421,
        "end": 3112,
        "id": 825,
        "no_speech_prob": 0.15609414875507355,
        "seek": 308400,
        "start": 3109,
        "temperature": 0,
        "text": " because it's sort of hard to see what's going on.",
        "tokens": [
          51614,
          570,
          309,
          311,
          1333,
          295,
          1152,
          281,
          536,
          437,
          311,
          516,
          322,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3118,
        "id": 826,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3112,
        "temperature": 0,
        "text": " So I'm going to make that a little bit smaller, and let's just make it a...",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          652,
          300,
          257,
          707,
          857,
          4356,
          11,
          293,
          718,
          311,
          445,
          652,
          309,
          257,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3120,
        "id": 827,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3118,
        "temperature": 0,
        "text": " I'm sorry, I'm going a little crazy here,",
        "tokens": [
          50664,
          286,
          478,
          2597,
          11,
          286,
          478,
          516,
          257,
          707,
          3219,
          510,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3123,
        "id": 828,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3120,
        "temperature": 0,
        "text": " but just bear with me for a second unnecessarily.",
        "tokens": [
          50764,
          457,
          445,
          6155,
          365,
          385,
          337,
          257,
          1150,
          16799,
          3289,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3124,
        "id": 829,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3123,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50914,
          821,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3127,
        "id": 830,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3124,
        "temperature": 0,
        "text": " So now I can see that sunflower was added there,",
        "tokens": [
          50964,
          407,
          586,
          286,
          393,
          536,
          300,
          48215,
          390,
          3869,
          456,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3131,
        "id": 831,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3127,
        "temperature": 0,
        "text": " but I added it manually only by going to the route in the address bar.",
        "tokens": [
          51114,
          457,
          286,
          3869,
          309,
          16945,
          787,
          538,
          516,
          281,
          264,
          7955,
          294,
          264,
          2985,
          2159,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3135,
        "id": 832,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3131,
        "temperature": 0,
        "text": " But that's not really how anybody normally interacts with an API.",
        "tokens": [
          51314,
          583,
          300,
          311,
          406,
          534,
          577,
          4472,
          5646,
          43582,
          365,
          364,
          9362,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3137,
        "id": 833,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3135,
        "temperature": 0,
        "text": " I don't know, maybe I do that quite normally.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          11,
          1310,
          286,
          360,
          300,
          1596,
          5646,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17447920905219183,
        "compression_ratio": 1.7345454545454546,
        "end": 3141,
        "id": 834,
        "no_speech_prob": 0.12591306865215302,
        "seek": 311200,
        "start": 3137,
        "temperature": 0,
        "text": " So now what I need to do is I need to handle that submit button.",
        "tokens": [
          51614,
          407,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          4813,
          300,
          10315,
          2960,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2105388832092285,
        "compression_ratio": 1.6589861751152073,
        "end": 3147,
        "id": 835,
        "no_speech_prob": 0.0005442110705189407,
        "seek": 314100,
        "start": 3141,
        "temperature": 0,
        "text": " So in p5, I can gain access to that through the select function.",
        "tokens": [
          50364,
          407,
          294,
          280,
          20,
          11,
          286,
          393,
          6052,
          2105,
          281,
          300,
          807,
          264,
          3048,
          2445,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2105388832092285,
        "compression_ratio": 1.6589861751152073,
        "end": 3151,
        "id": 836,
        "no_speech_prob": 0.0005442110705189407,
        "seek": 314100,
        "start": 3147,
        "temperature": 0,
        "text": " So this is me using... submit, sorry, this should say submit.",
        "tokens": [
          50664,
          407,
          341,
          307,
          385,
          1228,
          485,
          10315,
          11,
          2597,
          11,
          341,
          820,
          584,
          10315,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2105388832092285,
        "compression_ratio": 1.6589861751152073,
        "end": 3155,
        "id": 837,
        "no_speech_prob": 0.0005442110705189407,
        "seek": 314100,
        "start": 3151,
        "temperature": 0,
        "text": " This is me selecting the DOM element with the ID submit,",
        "tokens": [
          50864,
          639,
          307,
          385,
          18182,
          264,
          35727,
          4478,
          365,
          264,
          7348,
          10315,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2105388832092285,
        "compression_ratio": 1.6589861751152073,
        "end": 3157,
        "id": 838,
        "no_speech_prob": 0.0005442110705189407,
        "seek": 314100,
        "start": 3155,
        "temperature": 0,
        "text": " and that button has the ID submit.",
        "tokens": [
          51064,
          293,
          300,
          2960,
          575,
          264,
          7348,
          10315,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2105388832092285,
        "compression_ratio": 1.6589861751152073,
        "end": 3160,
        "id": 839,
        "no_speech_prob": 0.0005442110705189407,
        "seek": 314100,
        "start": 3157,
        "temperature": 0,
        "text": " And now I have it in a variable, and I can now attach an event,",
        "tokens": [
          51164,
          400,
          586,
          286,
          362,
          309,
          294,
          257,
          7006,
          11,
          293,
          286,
          393,
          586,
          5085,
          364,
          2280,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2105388832092285,
        "compression_ratio": 1.6589861751152073,
        "end": 3166,
        "id": 840,
        "no_speech_prob": 0.0005442110705189407,
        "seek": 314100,
        "start": 3160,
        "temperature": 0,
        "text": " like whenever the mouse is clicked on that button, to, I can say submit word.",
        "tokens": [
          51314,
          411,
          5699,
          264,
          9719,
          307,
          23370,
          322,
          300,
          2960,
          11,
          281,
          11,
          286,
          393,
          584,
          10315,
          1349,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17009431770048947,
        "compression_ratio": 1.7325581395348837,
        "end": 3170,
        "id": 841,
        "no_speech_prob": 0.0007793622207827866,
        "seek": 316600,
        "start": 3166,
        "temperature": 0,
        "text": " And now I can write a function, submit word,",
        "tokens": [
          50364,
          400,
          586,
          286,
          393,
          2464,
          257,
          2445,
          11,
          10315,
          1349,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17009431770048947,
        "compression_ratio": 1.7325581395348837,
        "end": 3178,
        "id": 842,
        "no_speech_prob": 0.0007793622207827866,
        "seek": 316600,
        "start": 3170,
        "temperature": 0,
        "text": " where I get the word from the word element, and I can just say.value.",
        "tokens": [
          50564,
          689,
          286,
          483,
          264,
          1349,
          490,
          264,
          1349,
          4478,
          11,
          293,
          286,
          393,
          445,
          584,
          2411,
          29155,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17009431770048947,
        "compression_ratio": 1.7325581395348837,
        "end": 3185,
        "id": 843,
        "no_speech_prob": 0.0007793622207827866,
        "seek": 316600,
        "start": 3178,
        "temperature": 0,
        "text": " I can get the score from the score element's value.",
        "tokens": [
          50964,
          286,
          393,
          483,
          264,
          6175,
          490,
          264,
          6175,
          4478,
          311,
          2158,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17009431770048947,
        "compression_ratio": 1.7325581395348837,
        "end": 3191,
        "id": 844,
        "no_speech_prob": 0.0007793622207827866,
        "seek": 316600,
        "start": 3185,
        "temperature": 0,
        "text": " So select looks for the text input box, word, and then score,",
        "tokens": [
          51314,
          407,
          3048,
          1542,
          337,
          264,
          2487,
          4846,
          2424,
          11,
          1349,
          11,
          293,
          550,
          6175,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.17009431770048947,
        "compression_ratio": 1.7325581395348837,
        "end": 3194,
        "id": 845,
        "no_speech_prob": 0.0007793622207827866,
        "seek": 316600,
        "start": 3191,
        "temperature": 0,
        "text": " and then the value function gives me the contents of what's in there.",
        "tokens": [
          51614,
          293,
          550,
          264,
          2158,
          2445,
          2709,
          385,
          264,
          15768,
          295,
          437,
          311,
          294,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3196,
        "id": 846,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3194,
        "temperature": 0,
        "text": " So just to see that this is doing what I want it to do,",
        "tokens": [
          50364,
          407,
          445,
          281,
          536,
          300,
          341,
          307,
          884,
          437,
          286,
          528,
          309,
          281,
          360,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3199,
        "id": 847,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3196,
        "temperature": 0,
        "text": " I'm going to say console.log word score.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          1349,
          6175,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3202,
        "id": 848,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3199,
        "temperature": 0,
        "text": " So let's go back. So I'm not submitting it yet, but let's go back,",
        "tokens": [
          50614,
          407,
          718,
          311,
          352,
          646,
          13,
          407,
          286,
          478,
          406,
          31836,
          309,
          1939,
          11,
          457,
          718,
          311,
          352,
          646,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3204,
        "id": 849,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3202,
        "temperature": 0,
        "text": " and I'm going to hit refresh.",
        "tokens": [
          50764,
          293,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3206,
        "id": 850,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3204,
        "temperature": 0,
        "text": " Oh, select is not defined. Guess what?",
        "tokens": [
          50864,
          876,
          11,
          3048,
          307,
          406,
          7642,
          13,
          17795,
          437,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3210,
        "id": 851,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3206,
        "temperature": 0,
        "text": " These functions are part of the p5 DOM library,",
        "tokens": [
          50964,
          1981,
          6828,
          366,
          644,
          295,
          264,
          280,
          20,
          35727,
          6405,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3215,
        "id": 852,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3210,
        "temperature": 0,
        "text": " so I need to make sure I am referencing the p5 DOM library in my HTML,",
        "tokens": [
          51164,
          370,
          286,
          643,
          281,
          652,
          988,
          286,
          669,
          40582,
          264,
          280,
          20,
          35727,
          6405,
          294,
          452,
          17995,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3218,
        "id": 853,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3215,
        "temperature": 0,
        "text": " which now I am, p5.dom.js.",
        "tokens": [
          51414,
          597,
          586,
          286,
          669,
          11,
          280,
          20,
          13,
          4121,
          13,
          25530,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15619963758132038,
        "compression_ratio": 1.6666666666666667,
        "end": 3221,
        "id": 854,
        "no_speech_prob": 0.005220034159719944,
        "seek": 319400,
        "start": 3218,
        "temperature": 0,
        "text": " And so now I can go back and hit refresh.",
        "tokens": [
          51564,
          400,
          370,
          586,
          286,
          393,
          352,
          646,
          293,
          2045,
          15134,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1714149832725525,
        "compression_ratio": 1.4685714285714286,
        "end": 3228,
        "id": 855,
        "no_speech_prob": 0.0038844565860927105,
        "seek": 322100,
        "start": 3221,
        "temperature": 0,
        "text": " And now I should be able to type in cherry blossom 2 and hit submit,",
        "tokens": [
          50364,
          400,
          586,
          286,
          820,
          312,
          1075,
          281,
          2010,
          294,
          20164,
          38524,
          568,
          293,
          2045,
          10315,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1714149832725525,
        "compression_ratio": 1.4685714285714286,
        "end": 3232,
        "id": 856,
        "no_speech_prob": 0.0038844565860927105,
        "seek": 322100,
        "start": 3228,
        "temperature": 0,
        "text": " and we can see that I'm able to access those two values.",
        "tokens": [
          50714,
          293,
          321,
          393,
          536,
          300,
          286,
          478,
          1075,
          281,
          2105,
          729,
          732,
          4190,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1714149832725525,
        "compression_ratio": 1.4685714285714286,
        "end": 3235,
        "id": 857,
        "no_speech_prob": 0.0038844565860927105,
        "seek": 322100,
        "start": 3232,
        "temperature": 0,
        "text": " And now what do I want to do?",
        "tokens": [
          50914,
          400,
          586,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1714149832725525,
        "compression_ratio": 1.4685714285714286,
        "end": 3241,
        "id": 858,
        "no_speech_prob": 0.0038844565860927105,
        "seek": 322100,
        "start": 3235,
        "temperature": 0,
        "text": " All I need to do is go to load JSON.",
        "tokens": [
          51064,
          1057,
          286,
          643,
          281,
          360,
          307,
          352,
          281,
          3677,
          31828,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1714149832725525,
        "compression_ratio": 1.4685714285714286,
        "end": 3242,
        "id": 859,
        "no_speech_prob": 0.0038844565860927105,
        "seek": 322100,
        "start": 3241,
        "temperature": 0,
        "text": " What's the route?",
        "tokens": [
          51364,
          708,
          311,
          264,
          7955,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1714149832725525,
        "compression_ratio": 1.4685714285714286,
        "end": 3249,
        "id": 860,
        "no_speech_prob": 0.0038844565860927105,
        "seek": 322100,
        "start": 3242,
        "temperature": 0,
        "text": " Add slash plus word plus a slash plus a score.",
        "tokens": [
          51414,
          5349,
          17330,
          1804,
          1349,
          1804,
          257,
          17330,
          1804,
          257,
          6175,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3253,
        "id": 861,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3249,
        "temperature": 0,
        "text": " So I can dynamically create this route in my code",
        "tokens": [
          50364,
          407,
          286,
          393,
          43492,
          1884,
          341,
          7955,
          294,
          452,
          3089,
          50564
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3257,
        "id": 862,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3253,
        "temperature": 0,
        "text": " based on what the user put into those two text boxes.",
        "tokens": [
          50564,
          2361,
          322,
          437,
          264,
          4195,
          829,
          666,
          729,
          732,
          2487,
          9002,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3259,
        "id": 863,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3257,
        "temperature": 0,
        "text": " So now I want to – now this is a little bit weird,",
        "tokens": [
          50764,
          407,
          586,
          286,
          528,
          281,
          220,
          5815,
          586,
          341,
          307,
          257,
          707,
          857,
          3657,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3263,
        "id": 864,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3259,
        "temperature": 0,
        "text": " and I'm going to get to this in a future video where I talk about get versus post.",
        "tokens": [
          50864,
          293,
          286,
          478,
          516,
          281,
          483,
          281,
          341,
          294,
          257,
          2027,
          960,
          689,
          286,
          751,
          466,
          483,
          5717,
          2183,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3267,
        "id": 865,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3263,
        "temperature": 0,
        "text": " I'm actually doing something that's sort of against the traditional conventions.",
        "tokens": [
          51064,
          286,
          478,
          767,
          884,
          746,
          300,
          311,
          1333,
          295,
          1970,
          264,
          5164,
          33520,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3270,
        "id": 866,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3267,
        "temperature": 0,
        "text": " I'm using load JSON, which is a get request,",
        "tokens": [
          51264,
          286,
          478,
          1228,
          3677,
          31828,
          11,
          597,
          307,
          257,
          483,
          5308,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3273,
        "id": 867,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3270,
        "temperature": 0,
        "text": " to actually send data, the word and the score, to the server,",
        "tokens": [
          51414,
          281,
          767,
          2845,
          1412,
          11,
          264,
          1349,
          293,
          264,
          6175,
          11,
          281,
          264,
          7154,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3275,
        "id": 868,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3273,
        "temperature": 0,
        "text": " but I'm really doing that out of convenience",
        "tokens": [
          51564,
          457,
          286,
          478,
          534,
          884,
          300,
          484,
          295,
          19283,
          51664
        ]
      },
      {
        "avg_logprob": -0.17191909898257424,
        "compression_ratio": 1.6815286624203822,
        "end": 3277,
        "id": 869,
        "no_speech_prob": 0.004609464667737484,
        "seek": 324900,
        "start": 3275,
        "temperature": 0,
        "text": " because it kind of works and it's easy and it's simple.",
        "tokens": [
          51664,
          570,
          309,
          733,
          295,
          1985,
          293,
          309,
          311,
          1858,
          293,
          309,
          311,
          2199,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16130600723565794,
        "compression_ratio": 1.6379310344827587,
        "end": 3281,
        "id": 870,
        "no_speech_prob": 0.010488811880350113,
        "seek": 327700,
        "start": 3277,
        "temperature": 0,
        "text": " You'll see in a lot of other scenarios if you want to send data to the server,",
        "tokens": [
          50364,
          509,
          603,
          536,
          294,
          257,
          688,
          295,
          661,
          15077,
          498,
          291,
          528,
          281,
          2845,
          1412,
          281,
          264,
          7154,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.16130600723565794,
        "compression_ratio": 1.6379310344827587,
        "end": 3283,
        "id": 871,
        "no_speech_prob": 0.010488811880350113,
        "seek": 327700,
        "start": 3281,
        "temperature": 0,
        "text": " images, large data, private data,",
        "tokens": [
          50564,
          5267,
          11,
          2416,
          1412,
          11,
          4551,
          1412,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.16130600723565794,
        "compression_ratio": 1.6379310344827587,
        "end": 3285,
        "id": 872,
        "no_speech_prob": 0.010488811880350113,
        "seek": 327700,
        "start": 3283,
        "temperature": 0,
        "text": " you're going to need to use something called a post,",
        "tokens": [
          50664,
          291,
          434,
          516,
          281,
          643,
          281,
          764,
          746,
          1219,
          257,
          2183,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.16130600723565794,
        "compression_ratio": 1.6379310344827587,
        "end": 3289,
        "id": 873,
        "no_speech_prob": 0.010488811880350113,
        "seek": 327700,
        "start": 3285,
        "temperature": 0,
        "text": " which cannot be done through load JSON, but I'll get to that in a future video.",
        "tokens": [
          50764,
          597,
          2644,
          312,
          1096,
          807,
          3677,
          31828,
          11,
          457,
          286,
          603,
          483,
          281,
          300,
          294,
          257,
          2027,
          960,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16130600723565794,
        "compression_ratio": 1.6379310344827587,
        "end": 3297,
        "id": 874,
        "no_speech_prob": 0.010488811880350113,
        "seek": 327700,
        "start": 3289,
        "temperature": 0,
        "text": " And then I'm going to just add a function called finished as the callback.",
        "tokens": [
          50964,
          400,
          550,
          286,
          478,
          516,
          281,
          445,
          909,
          257,
          2445,
          1219,
          4335,
          382,
          264,
          818,
          3207,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16130600723565794,
        "compression_ratio": 1.6379310344827587,
        "end": 3304,
        "id": 875,
        "no_speech_prob": 0.010488811880350113,
        "seek": 327700,
        "start": 3297,
        "temperature": 0,
        "text": " And then I can say function finished data console.log data.",
        "tokens": [
          51364,
          400,
          550,
          286,
          393,
          584,
          2445,
          4335,
          1412,
          11076,
          13,
          4987,
          1412,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17731477700027765,
        "compression_ratio": 1.8524590163934427,
        "end": 3307,
        "id": 876,
        "no_speech_prob": 0.0073456228710711,
        "seek": 330400,
        "start": 3304,
        "temperature": 0,
        "text": " So I just want to see that it came back.",
        "tokens": [
          50364,
          407,
          286,
          445,
          528,
          281,
          536,
          300,
          309,
          1361,
          646,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17731477700027765,
        "compression_ratio": 1.8524590163934427,
        "end": 3311,
        "id": 877,
        "no_speech_prob": 0.0073456228710711,
        "seek": 330400,
        "start": 3307,
        "temperature": 0,
        "text": " So I'm going to send that data and see that it came back.",
        "tokens": [
          50514,
          407,
          286,
          478,
          516,
          281,
          2845,
          300,
          1412,
          293,
          536,
          300,
          309,
          1361,
          646,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17731477700027765,
        "compression_ratio": 1.8524590163934427,
        "end": 3314,
        "id": 878,
        "no_speech_prob": 0.0073456228710711,
        "seek": 330400,
        "start": 3311,
        "temperature": 0,
        "text": " And then I'm going to – so I'm going to hit refresh,",
        "tokens": [
          50714,
          400,
          550,
          286,
          478,
          516,
          281,
          1662,
          370,
          286,
          478,
          516,
          281,
          2045,
          15134,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17731477700027765,
        "compression_ratio": 1.8524590163934427,
        "end": 3320,
        "id": 879,
        "no_speech_prob": 0.0073456228710711,
        "seek": 330400,
        "start": 3314,
        "temperature": 0,
        "text": " and I'm going to add a blueberry, 10, and I'm going to hit submit,",
        "tokens": [
          50864,
          293,
          286,
          478,
          516,
          281,
          909,
          257,
          48243,
          11,
          1266,
          11,
          293,
          286,
          478,
          516,
          281,
          2045,
          10315,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.17731477700027765,
        "compression_ratio": 1.8524590163934427,
        "end": 3323,
        "id": 880,
        "no_speech_prob": 0.0073456228710711,
        "seek": 330400,
        "start": 3320,
        "temperature": 0,
        "text": " and we can see that this was sent to the database.",
        "tokens": [
          51164,
          293,
          321,
          393,
          536,
          300,
          341,
          390,
          2279,
          281,
          264,
          8149,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17731477700027765,
        "compression_ratio": 1.8524590163934427,
        "end": 3327,
        "id": 881,
        "no_speech_prob": 0.0073456228710711,
        "seek": 330400,
        "start": 3323,
        "temperature": 0,
        "text": " Now, if I hit refresh again, we should see that blueberry is there.",
        "tokens": [
          51314,
          823,
          11,
          498,
          286,
          2045,
          15134,
          797,
          11,
          321,
          820,
          536,
          300,
          48243,
          307,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3336,
        "id": 882,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3328,
        "temperature": 0,
        "text": " Why not, though, however, once it's done, ask the database for all the words again",
        "tokens": [
          50414,
          1545,
          406,
          11,
          1673,
          11,
          4461,
          11,
          1564,
          309,
          311,
          1096,
          11,
          1029,
          264,
          8149,
          337,
          439,
          264,
          2283,
          797,
          50814
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3338,
        "id": 883,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3336,
        "temperature": 0,
        "text": " to redraw what's in there.",
        "tokens": [
          50814,
          281,
          2182,
          5131,
          437,
          311,
          294,
          456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3341,
        "id": 884,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3338,
        "temperature": 0,
        "text": " So here, this is what I did to redraw everything.",
        "tokens": [
          50914,
          407,
          510,
          11,
          341,
          307,
          437,
          286,
          630,
          281,
          2182,
          5131,
          1203,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3343,
        "id": 885,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3341,
        "temperature": 0,
        "text": " I could actually put this in a function.",
        "tokens": [
          51064,
          286,
          727,
          767,
          829,
          341,
          294,
          257,
          2445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3348,
        "id": 886,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3343,
        "temperature": 0,
        "text": " I could call this function draw data.",
        "tokens": [
          51164,
          286,
          727,
          818,
          341,
          2445,
          2642,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3353,
        "id": 887,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3348,
        "temperature": 0,
        "text": " And so when the program first starts, I want to draw the data.",
        "tokens": [
          51414,
          400,
          370,
          562,
          264,
          1461,
          700,
          3719,
          11,
          286,
          528,
          281,
          2642,
          264,
          1412,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17840035756429037,
        "compression_ratio": 1.6842105263157894,
        "end": 3355,
        "id": 888,
        "no_speech_prob": 0.23369158804416656,
        "seek": 332700,
        "start": 3353,
        "temperature": 0,
        "text": " And then every time I submit a word and it's done,",
        "tokens": [
          51664,
          400,
          550,
          633,
          565,
          286,
          10315,
          257,
          1349,
          293,
          309,
          311,
          1096,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3357,
        "id": 889,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3355,
        "temperature": 0,
        "text": " I also want to draw the data again.",
        "tokens": [
          50364,
          286,
          611,
          528,
          281,
          2642,
          264,
          1412,
          797,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3364,
        "id": 890,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3357,
        "temperature": 0,
        "text": " So now, if I do this, I can say, hey, let me add the word mango",
        "tokens": [
          50464,
          407,
          586,
          11,
          498,
          286,
          360,
          341,
          11,
          286,
          393,
          584,
          11,
          4177,
          11,
          718,
          385,
          909,
          264,
          1349,
          23481,
          50814
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3367,
        "id": 891,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3364,
        "temperature": 0,
        "text": " and give it a score of 3 and hit submit.",
        "tokens": [
          50814,
          293,
          976,
          309,
          257,
          6175,
          295,
          805,
          293,
          2045,
          10315,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3368,
        "id": 892,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3367,
        "temperature": 0,
        "text": " And now, ooh, look at that.",
        "tokens": [
          50964,
          400,
          586,
          11,
          17024,
          11,
          574,
          412,
          300,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3372,
        "id": 893,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3368,
        "temperature": 0,
        "text": " One thing I forgot in my draw data function was to clear the background",
        "tokens": [
          51014,
          1485,
          551,
          286,
          5298,
          294,
          452,
          2642,
          1412,
          2445,
          390,
          281,
          1850,
          264,
          3678,
          51214
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3374,
        "id": 894,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3372,
        "temperature": 0,
        "text": " because it drew it again over everything.",
        "tokens": [
          51214,
          570,
          309,
          12804,
          309,
          797,
          670,
          1203,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3377,
        "id": 895,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3374,
        "temperature": 0,
        "text": " So I'm going to take this background function",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          281,
          747,
          341,
          3678,
          2445,
          51464
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3381,
        "id": 896,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3377,
        "temperature": 0,
        "text": " and put it right here in the got data function,",
        "tokens": [
          51464,
          293,
          829,
          309,
          558,
          510,
          294,
          264,
          658,
          1412,
          2445,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.15424660504874538,
        "compression_ratio": 1.6557377049180328,
        "end": 3383,
        "id": 897,
        "no_speech_prob": 0.07807524502277374,
        "seek": 335500,
        "start": 3381,
        "temperature": 0,
        "text": " and I'll hit refresh again.",
        "tokens": [
          51664,
          293,
          286,
          603,
          2045,
          15134,
          797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3386,
        "id": 898,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3383,
        "temperature": 0,
        "text": " And now we can see everything's in there, mango, flower, blueberry, sunflower,",
        "tokens": [
          50364,
          400,
          586,
          321,
          393,
          536,
          1203,
          311,
          294,
          456,
          11,
          23481,
          11,
          8617,
          11,
          48243,
          11,
          48215,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3387,
        "id": 899,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3386,
        "temperature": 0,
        "text": " all these things.",
        "tokens": [
          50514,
          439,
          613,
          721,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3389,
        "id": 900,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3387,
        "temperature": 0,
        "text": " What's another fruit that is delicious?",
        "tokens": [
          50564,
          708,
          311,
          1071,
          6773,
          300,
          307,
          4809,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3390,
        "id": 901,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3389,
        "temperature": 0,
        "text": " A raspberry.",
        "tokens": [
          50664,
          316,
          41468,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3393,
        "id": 902,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3390,
        "temperature": 0,
        "text": " I only know how to spell raspberry now because of the raspberry pie,",
        "tokens": [
          50714,
          286,
          787,
          458,
          577,
          281,
          9827,
          41468,
          586,
          570,
          295,
          264,
          41468,
          1730,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3395,
        "id": 903,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3393,
        "temperature": 0,
        "text": " and that's like the password or something.",
        "tokens": [
          50864,
          293,
          300,
          311,
          411,
          264,
          11524,
          420,
          746,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3397,
        "id": 904,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3395,
        "temperature": 0,
        "text": " Do you want to type it in all the time?",
        "tokens": [
          50964,
          1144,
          291,
          528,
          281,
          2010,
          309,
          294,
          439,
          264,
          565,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3401,
        "id": 905,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3397,
        "temperature": 0,
        "text": " Score 4, and I'm going to hit submit.",
        "tokens": [
          51064,
          47901,
          1017,
          11,
          293,
          286,
          478,
          516,
          281,
          2045,
          10315,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3402,
        "id": 906,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3401,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51264,
          400,
          456,
          321,
          352,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3403,
        "id": 907,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3402,
        "temperature": 0,
        "text": " It runs, and we see the result.",
        "tokens": [
          51314,
          467,
          6676,
          11,
          293,
          321,
          536,
          264,
          1874,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3407,
        "id": 908,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3403,
        "temperature": 0,
        "text": " So now I have an interface where I can sit here and submit new words to the database,",
        "tokens": [
          51364,
          407,
          586,
          286,
          362,
          364,
          9226,
          689,
          286,
          393,
          1394,
          510,
          293,
          10315,
          777,
          2283,
          281,
          264,
          8149,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.2119087786287875,
        "compression_ratio": 1.6938110749185669,
        "end": 3410,
        "id": 909,
        "no_speech_prob": 0.10818060487508774,
        "seek": 338300,
        "start": 3407,
        "temperature": 0,
        "text": " and I also have this sort of goofy front end,",
        "tokens": [
          51564,
          293,
          286,
          611,
          362,
          341,
          1333,
          295,
          42995,
          1868,
          917,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3414,
        "id": 910,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3410,
        "temperature": 0,
        "text": " which just shows me a very poor visualization of all the words",
        "tokens": [
          50364,
          597,
          445,
          3110,
          385,
          257,
          588,
          4716,
          25801,
          295,
          439,
          264,
          2283,
          50564
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3416,
        "id": 911,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3414,
        "temperature": 0,
        "text": " that are currently in this database.",
        "tokens": [
          50564,
          300,
          366,
          4362,
          294,
          341,
          8149,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3419,
        "id": 912,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3416,
        "temperature": 0,
        "text": " And if I go look in the server code, I should be able to see, hey, look at this.",
        "tokens": [
          50664,
          400,
          498,
          286,
          352,
          574,
          294,
          264,
          7154,
          3089,
          11,
          286,
          820,
          312,
          1075,
          281,
          536,
          11,
          4177,
          11,
          574,
          412,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3422,
        "id": 913,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3419,
        "temperature": 0,
        "text": " This words.json file, it has everything.",
        "tokens": [
          50814,
          639,
          2283,
          13,
          73,
          3015,
          3991,
          11,
          309,
          575,
          1203,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3429,
        "id": 914,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3422,
        "temperature": 0,
        "text": " So even if I now quit and restart the server and go here again,",
        "tokens": [
          50964,
          407,
          754,
          498,
          286,
          586,
          10366,
          293,
          21022,
          264,
          7154,
          293,
          352,
          510,
          797,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3431,
        "id": 915,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3429,
        "temperature": 0,
        "text": " I'm still going to see all of those words.",
        "tokens": [
          51314,
          286,
          478,
          920,
          516,
          281,
          536,
          439,
          295,
          729,
          2283,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3435,
        "id": 916,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3431,
        "temperature": 0,
        "text": " So now we have an API with routes that accept parameters.",
        "tokens": [
          51414,
          407,
          586,
          321,
          362,
          364,
          9362,
          365,
          18242,
          300,
          3241,
          9834,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14040119921574828,
        "compression_ratio": 1.6323529411764706,
        "end": 3439,
        "id": 917,
        "no_speech_prob": 0.05419708788394928,
        "seek": 341000,
        "start": 3435,
        "temperature": 0,
        "text": " We have a persistence saving all the data to a JSON file,",
        "tokens": [
          51614,
          492,
          362,
          257,
          37617,
          6816,
          439,
          264,
          1412,
          281,
          257,
          31828,
          3991,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3444,
        "id": 918,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3439,
        "temperature": 0,
        "text": " and now we have even an interface that allows us to interact with the API in one way.",
        "tokens": [
          50364,
          293,
          586,
          321,
          362,
          754,
          364,
          9226,
          300,
          4045,
          505,
          281,
          4648,
          365,
          264,
          9362,
          294,
          472,
          636,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3451,
        "id": 919,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3444,
        "temperature": 0,
        "text": " And so the next video that I'm going to do is look at how do I submit data to a server using a post",
        "tokens": [
          50614,
          400,
          370,
          264,
          958,
          960,
          300,
          286,
          478,
          516,
          281,
          360,
          307,
          574,
          412,
          577,
          360,
          286,
          10315,
          1412,
          281,
          257,
          7154,
          1228,
          257,
          2183,
          50964
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3453,
        "id": 920,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3451,
        "temperature": 0,
        "text": " and why would I need to use a post versus a get.",
        "tokens": [
          50964,
          293,
          983,
          576,
          286,
          643,
          281,
          764,
          257,
          2183,
          5717,
          257,
          483,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3454,
        "id": 921,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3453,
        "temperature": 0,
        "text": " What's a get? What's a post?",
        "tokens": [
          51064,
          708,
          311,
          257,
          483,
          30,
          708,
          311,
          257,
          2183,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3457,
        "id": 922,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3454,
        "temperature": 0,
        "text": " So that's what I'm going to look at in the next video that I'll make,",
        "tokens": [
          51114,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          574,
          412,
          294,
          264,
          958,
          960,
          300,
          286,
          603,
          652,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3463,
        "id": 923,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3457,
        "temperature": 0,
        "text": " and then by the end I'll wrap it up and actually make this thing do some sort of sentiment analysis",
        "tokens": [
          51264,
          293,
          550,
          538,
          264,
          917,
          286,
          603,
          7019,
          309,
          493,
          293,
          767,
          652,
          341,
          551,
          360,
          512,
          1333,
          295,
          16149,
          5215,
          51564
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3466,
        "id": 924,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3463,
        "temperature": 0,
        "text": " and give a score back when you post a large body of text to it.",
        "tokens": [
          51564,
          293,
          976,
          257,
          6175,
          646,
          562,
          291,
          2183,
          257,
          2416,
          1772,
          295,
          2487,
          281,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16033752597108178,
        "compression_ratio": 1.7583892617449663,
        "end": 3467,
        "id": 925,
        "no_speech_prob": 0.012624555267393589,
        "seek": 343900,
        "start": 3466,
        "temperature": 0,
        "text": " Okay, thanks for watching.",
        "tokens": [
          51714,
          1033,
          11,
          3231,
          337,
          1976,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18034889698028564,
        "compression_ratio": 1.5210526315789474,
        "end": 3472,
        "id": 926,
        "no_speech_prob": 0.21729034185409546,
        "seek": 346700,
        "start": 3467,
        "temperature": 0,
        "text": " I look forward to hearing what you think in the comments and all that sort of stuff.",
        "tokens": [
          50364,
          286,
          574,
          2128,
          281,
          4763,
          437,
          291,
          519,
          294,
          264,
          3053,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18034889698028564,
        "compression_ratio": 1.5210526315789474,
        "end": 3479,
        "id": 927,
        "no_speech_prob": 0.21729034185409546,
        "seek": 346700,
        "start": 3472,
        "temperature": 0,
        "text": " Okay, so that, I have about five or ten minutes left,",
        "tokens": [
          50614,
          1033,
          11,
          370,
          300,
          11,
          286,
          362,
          466,
          1732,
          420,
          2064,
          2077,
          1411,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18034889698028564,
        "compression_ratio": 1.5210526315789474,
        "end": 3482,
        "id": 928,
        "no_speech_prob": 0.21729034185409546,
        "seek": 346700,
        "start": 3479,
        "temperature": 0,
        "text": " so I'm not going to try to do the next piece of this.",
        "tokens": [
          50964,
          370,
          286,
          478,
          406,
          516,
          281,
          853,
          281,
          360,
          264,
          958,
          2522,
          295,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18034889698028564,
        "compression_ratio": 1.5210526315789474,
        "end": 3489,
        "id": 929,
        "no_speech_prob": 0.21729034185409546,
        "seek": 346700,
        "start": 3482,
        "temperature": 0,
        "text": " If I have time later today when I come back after the class is finished, I might try to do that.",
        "tokens": [
          51114,
          759,
          286,
          362,
          565,
          1780,
          965,
          562,
          286,
          808,
          646,
          934,
          264,
          1508,
          307,
          4335,
          11,
          286,
          1062,
          853,
          281,
          360,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26254097360079404,
        "compression_ratio": 1.3973509933774835,
        "end": 3493,
        "id": 930,
        "no_speech_prob": 0.02064470387995243,
        "seek": 348900,
        "start": 3489,
        "temperature": 0,
        "text": " But I do have about five or ten minutes.",
        "tokens": [
          50364,
          583,
          286,
          360,
          362,
          466,
          1732,
          420,
          2064,
          2077,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26254097360079404,
        "compression_ratio": 1.3973509933774835,
        "end": 3501,
        "id": 931,
        "no_speech_prob": 0.02064470387995243,
        "seek": 348900,
        "start": 3493,
        "temperature": 0,
        "text": " If anyone wants to ask a short little question in the chat, I'm happy to answer them if I can.",
        "tokens": [
          50564,
          759,
          2878,
          2738,
          281,
          1029,
          257,
          2099,
          707,
          1168,
          294,
          264,
          5081,
          11,
          286,
          478,
          2055,
          281,
          1867,
          552,
          498,
          286,
          393,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26254097360079404,
        "compression_ratio": 1.3973509933774835,
        "end": 3516,
        "id": 932,
        "no_speech_prob": 0.02064470387995243,
        "seek": 348900,
        "start": 3509,
        "temperature": 0,
        "text": " I see that there's been some, so Ariane writes, this is way beyond my head.",
        "tokens": [
          51364,
          286,
          536,
          300,
          456,
          311,
          668,
          512,
          11,
          370,
          9433,
          1929,
          13657,
          11,
          341,
          307,
          636,
          4399,
          452,
          1378,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20512418510500063,
        "compression_ratio": 1.6872727272727273,
        "end": 3519,
        "id": 933,
        "no_speech_prob": 0.0023964608553797007,
        "seek": 351600,
        "start": 3516,
        "temperature": 0,
        "text": " So, yeah, so one thing that is tricky about what I'm doing,",
        "tokens": [
          50364,
          407,
          11,
          1338,
          11,
          370,
          472,
          551,
          300,
          307,
          12414,
          466,
          437,
          286,
          478,
          884,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20512418510500063,
        "compression_ratio": 1.6872727272727273,
        "end": 3522,
        "id": 934,
        "no_speech_prob": 0.0023964608553797007,
        "seek": 351600,
        "start": 3519,
        "temperature": 0,
        "text": " which I've definitely gotten this comment before,",
        "tokens": [
          50514,
          597,
          286,
          600,
          2138,
          5768,
          341,
          2871,
          949,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.20512418510500063,
        "compression_ratio": 1.6872727272727273,
        "end": 3526,
        "id": 935,
        "no_speech_prob": 0.0023964608553797007,
        "seek": 351600,
        "start": 3522,
        "temperature": 0,
        "text": " which is that I've heard from people, oh, I went to your YouTube channel, I found it,",
        "tokens": [
          50664,
          597,
          307,
          300,
          286,
          600,
          2198,
          490,
          561,
          11,
          1954,
          11,
          286,
          1437,
          281,
          428,
          3088,
          2269,
          11,
          286,
          1352,
          309,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.20512418510500063,
        "compression_ratio": 1.6872727272727273,
        "end": 3531,
        "id": 936,
        "no_speech_prob": 0.0023964608553797007,
        "seek": 351600,
        "start": 3526,
        "temperature": 0,
        "text": " and it's all, it's too advanced for me, it's for advanced programmers.",
        "tokens": [
          50864,
          293,
          309,
          311,
          439,
          11,
          309,
          311,
          886,
          7339,
          337,
          385,
          11,
          309,
          311,
          337,
          7339,
          41504,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20512418510500063,
        "compression_ratio": 1.6872727272727273,
        "end": 3537,
        "id": 937,
        "no_speech_prob": 0.0023964608553797007,
        "seek": 351600,
        "start": 3531,
        "temperature": 0,
        "text": " And really my goal is for this to be for, I would like my channel to be a place that complete and total beginners",
        "tokens": [
          51114,
          400,
          534,
          452,
          3387,
          307,
          337,
          341,
          281,
          312,
          337,
          11,
          286,
          576,
          411,
          452,
          2269,
          281,
          312,
          257,
          1081,
          300,
          3566,
          293,
          3217,
          26992,
          51414
        ]
      },
      {
        "avg_logprob": -0.20512418510500063,
        "compression_ratio": 1.6872727272727273,
        "end": 3541,
        "id": 938,
        "no_speech_prob": 0.0023964608553797007,
        "seek": 351600,
        "start": 3537,
        "temperature": 0,
        "text": " who have never done any coding before could come and learn and start to make stuff.",
        "tokens": [
          51414,
          567,
          362,
          1128,
          1096,
          604,
          17720,
          949,
          727,
          808,
          293,
          1466,
          293,
          722,
          281,
          652,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3548,
        "id": 939,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3541,
        "temperature": 0,
        "text": " The tricky thing is that, the tricky thing about this is that it's hard to find where to begin,",
        "tokens": [
          50364,
          440,
          12414,
          551,
          307,
          300,
          11,
          264,
          12414,
          551,
          466,
          341,
          307,
          300,
          309,
          311,
          1152,
          281,
          915,
          689,
          281,
          1841,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3550,
        "id": 940,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3548,
        "temperature": 0,
        "text": " and I need to figure out a better way of doing this.",
        "tokens": [
          50714,
          293,
          286,
          643,
          281,
          2573,
          484,
          257,
          1101,
          636,
          295,
          884,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3555,
        "id": 941,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3550,
        "temperature": 0,
        "text": " Maybe if I can eventually get my act together and get a title and a new logo and a new website.",
        "tokens": [
          50814,
          2704,
          498,
          286,
          393,
          4728,
          483,
          452,
          605,
          1214,
          293,
          483,
          257,
          4876,
          293,
          257,
          777,
          9699,
          293,
          257,
          777,
          3144,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3559,
        "id": 942,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3555,
        "temperature": 0,
        "text": " But one thing I will just mention is that if you're interested in web programming,",
        "tokens": [
          51064,
          583,
          472,
          551,
          286,
          486,
          445,
          2152,
          307,
          300,
          498,
          291,
          434,
          3102,
          294,
          3670,
          9410,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3563,
        "id": 943,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3559,
        "temperature": 0,
        "text": " JavaScript, HTML, CSS, at least through the lens of P5.js,",
        "tokens": [
          51264,
          15778,
          11,
          17995,
          11,
          24387,
          11,
          412,
          1935,
          807,
          264,
          6765,
          295,
          430,
          20,
          13,
          25530,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3568,
        "id": 944,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3563,
        "temperature": 0,
        "text": " I also get the other frequent comment I get is, why are you using this P5.js thing?",
        "tokens": [
          51464,
          286,
          611,
          483,
          264,
          661,
          18004,
          2871,
          286,
          483,
          307,
          11,
          983,
          366,
          291,
          1228,
          341,
          430,
          20,
          13,
          25530,
          551,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.19077231414126652,
        "compression_ratio": 1.66,
        "end": 3569,
        "id": 945,
        "no_speech_prob": 0.012051536701619625,
        "seek": 354100,
        "start": 3568,
        "temperature": 0,
        "text": " I don't want to learn that.",
        "tokens": [
          51714,
          286,
          500,
          380,
          528,
          281,
          1466,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3571,
        "id": 946,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3569,
        "temperature": 0,
        "text": " Well, sorry, I guess.",
        "tokens": [
          50364,
          1042,
          11,
          2597,
          11,
          286,
          2041,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3576,
        "id": 947,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3571,
        "temperature": 0,
        "text": " But it's a platform that I'm invested in personally and also through the work that I do,",
        "tokens": [
          50464,
          583,
          309,
          311,
          257,
          3663,
          300,
          286,
          478,
          13104,
          294,
          5665,
          293,
          611,
          807,
          264,
          589,
          300,
          286,
          360,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3581,
        "id": 948,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3576,
        "temperature": 0,
        "text": " and so I'm interested in making tutorials with it and making it better.",
        "tokens": [
          50714,
          293,
          370,
          286,
          478,
          3102,
          294,
          1455,
          17616,
          365,
          309,
          293,
          1455,
          309,
          1101,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3584,
        "id": 949,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3581,
        "temperature": 0,
        "text": " So, but by no means do I completely restrict myself to that,",
        "tokens": [
          50964,
          407,
          11,
          457,
          538,
          572,
          1355,
          360,
          286,
          2584,
          7694,
          2059,
          281,
          300,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3588,
        "id": 950,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3584,
        "temperature": 0,
        "text": " but these tutorials here, one through six introduction,",
        "tokens": [
          51114,
          457,
          613,
          17616,
          510,
          11,
          472,
          807,
          2309,
          9339,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3591,
        "id": 951,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3588,
        "temperature": 0,
        "text": " these are for complete beginners who have never done anything before.",
        "tokens": [
          51314,
          613,
          366,
          337,
          3566,
          26992,
          567,
          362,
          1128,
          1096,
          1340,
          949,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23637448961489668,
        "compression_ratio": 1.7003891050583657,
        "end": 3596,
        "id": 952,
        "no_speech_prob": 0.010817509144544601,
        "seek": 356900,
        "start": 3591,
        "temperature": 0,
        "text": " And then also this set of tutorials down here, learning processing,",
        "tokens": [
          51464,
          400,
          550,
          611,
          341,
          992,
          295,
          17616,
          760,
          510,
          11,
          2539,
          9007,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.2143159119979195,
        "compression_ratio": 1.6271186440677967,
        "end": 3602,
        "id": 953,
        "no_speech_prob": 0.0004802930634468794,
        "seek": 359600,
        "start": 3597,
        "temperature": 0,
        "text": " this is for complete and total beginners looking at learning a processing,",
        "tokens": [
          50414,
          341,
          307,
          337,
          3566,
          293,
          3217,
          26992,
          1237,
          412,
          2539,
          257,
          9007,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2143159119979195,
        "compression_ratio": 1.6271186440677967,
        "end": 3608,
        "id": 954,
        "no_speech_prob": 0.0004802930634468794,
        "seek": 359600,
        "start": 3602,
        "temperature": 0,
        "text": " which is a Java-based platform for doing different kind of programming things.",
        "tokens": [
          50664,
          597,
          307,
          257,
          10745,
          12,
          6032,
          3663,
          337,
          884,
          819,
          733,
          295,
          9410,
          721,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2143159119979195,
        "compression_ratio": 1.6271186440677967,
        "end": 3614,
        "id": 955,
        "no_speech_prob": 0.0004802930634468794,
        "seek": 359600,
        "start": 3608,
        "temperature": 0,
        "text": " I don't know enough about SC, SS, and SAS to answer that question.",
        "tokens": [
          50964,
          286,
          500,
          380,
          458,
          1547,
          466,
          9028,
          11,
          12238,
          11,
          293,
          33441,
          281,
          1867,
          300,
          1168,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2143159119979195,
        "compression_ratio": 1.6271186440677967,
        "end": 3618,
        "id": 956,
        "no_speech_prob": 0.0004802930634468794,
        "seek": 359600,
        "start": 3614,
        "temperature": 0,
        "text": " And I'll also mention here if you're interested in Git and GitHub,",
        "tokens": [
          51264,
          400,
          286,
          603,
          611,
          2152,
          510,
          498,
          291,
          434,
          3102,
          294,
          16939,
          293,
          23331,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2143159119979195,
        "compression_ratio": 1.6271186440677967,
        "end": 3624,
        "id": 957,
        "no_speech_prob": 0.0004802930634468794,
        "seek": 359600,
        "start": 3618,
        "temperature": 0,
        "text": " this is a playlist that is also for complete and total beginners if you've never used it before.",
        "tokens": [
          51464,
          341,
          307,
          257,
          16788,
          300,
          307,
          611,
          337,
          3566,
          293,
          3217,
          26992,
          498,
          291,
          600,
          1128,
          1143,
          309,
          949,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3628,
        "id": 958,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3624,
        "temperature": 0,
        "text": " And most of the other playlists, particular programming from A to Z,",
        "tokens": [
          50364,
          400,
          881,
          295,
          264,
          661,
          862,
          36693,
          11,
          1729,
          9410,
          490,
          316,
          281,
          1176,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3633,
        "id": 959,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3628,
        "temperature": 0,
        "text": " and I'm thinking of this WebSockets one, this Twitter one, nature of code,",
        "tokens": [
          50564,
          293,
          286,
          478,
          1953,
          295,
          341,
          9573,
          50,
          1560,
          1385,
          472,
          11,
          341,
          5794,
          472,
          11,
          3687,
          295,
          3089,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3637,
        "id": 960,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3633,
        "temperature": 0,
        "text": " all assume kind of what's in those two beginner playlists.",
        "tokens": [
          50814,
          439,
          6552,
          733,
          295,
          437,
          311,
          294,
          729,
          732,
          22080,
          862,
          36693,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3644,
        "id": 961,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3637,
        "temperature": 0,
        "text": " So if anybody has any ideas about how I can make this stuff more accessible and easy,",
        "tokens": [
          51014,
          407,
          498,
          4472,
          575,
          604,
          3487,
          466,
          577,
          286,
          393,
          652,
          341,
          1507,
          544,
          9515,
          293,
          1858,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3646,
        "id": 962,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3644,
        "temperature": 0,
        "text": " easier for people to find or get started,",
        "tokens": [
          51364,
          3571,
          337,
          561,
          281,
          915,
          420,
          483,
          1409,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3650,
        "id": 963,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3646,
        "temperature": 0,
        "text": " and if you have a friend who's a beginner, send them my way.",
        "tokens": [
          51464,
          293,
          498,
          291,
          362,
          257,
          1277,
          567,
          311,
          257,
          22080,
          11,
          2845,
          552,
          452,
          636,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19410015986515924,
        "compression_ratio": 1.5970149253731343,
        "end": 3651,
        "id": 964,
        "no_speech_prob": 0.03846187889575958,
        "seek": 362400,
        "start": 3650,
        "temperature": 0,
        "text": " I want to see how it works for them.",
        "tokens": [
          51664,
          286,
          528,
          281,
          536,
          577,
          309,
          1985,
          337,
          552,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3654,
        "id": 965,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3651,
        "temperature": 0,
        "text": " Because most of the core audience I'm finding at least tuning into the live stream",
        "tokens": [
          50364,
          1436,
          881,
          295,
          264,
          4965,
          4034,
          286,
          478,
          5006,
          412,
          1935,
          15164,
          666,
          264,
          1621,
          4309,
          50514
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3656,
        "id": 966,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3654,
        "temperature": 0,
        "text": " are people who already know about programming.",
        "tokens": [
          50514,
          366,
          561,
          567,
          1217,
          458,
          466,
          9410,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3658,
        "id": 967,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3656,
        "temperature": 0,
        "text": " I saw a great question.",
        "tokens": [
          50614,
          286,
          1866,
          257,
          869,
          1168,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3659,
        "id": 968,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3658,
        "temperature": 0,
        "text": " It's two questions.",
        "tokens": [
          50714,
          467,
          311,
          732,
          1651,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3663,
        "id": 969,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3659,
        "temperature": 0,
        "text": " One is, where is it? Where is it? I'm scrolling back.",
        "tokens": [
          50764,
          1485,
          307,
          11,
          689,
          307,
          309,
          30,
          2305,
          307,
          309,
          30,
          286,
          478,
          29053,
          646,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3666,
        "id": 970,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3663,
        "temperature": 0,
        "text": " Oh, code it in a full IDE, Eclipse.",
        "tokens": [
          50964,
          876,
          11,
          3089,
          309,
          294,
          257,
          1577,
          40930,
          11,
          462,
          27197,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3671,
        "id": 971,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3666,
        "temperature": 0,
        "text": " So I really want to make a tutorial about how to make a processing library.",
        "tokens": [
          51114,
          407,
          286,
          534,
          528,
          281,
          652,
          257,
          7073,
          466,
          577,
          281,
          652,
          257,
          9007,
          6405,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3673,
        "id": 972,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3671,
        "temperature": 0,
        "text": " And to do that, you need to use Eclipse.",
        "tokens": [
          51364,
          400,
          281,
          360,
          300,
          11,
          291,
          643,
          281,
          764,
          462,
          27197,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3675,
        "id": 973,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3673,
        "temperature": 0,
        "text": " And also just program with processing in Eclipse.",
        "tokens": [
          51464,
          400,
          611,
          445,
          1461,
          365,
          9007,
          294,
          462,
          27197,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3676,
        "id": 974,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3675,
        "temperature": 0,
        "text": " It's on my list.",
        "tokens": [
          51564,
          467,
          311,
          322,
          452,
          1329,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3678,
        "id": 975,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3676,
        "temperature": 0,
        "text": " Please keep reminding me about that.",
        "tokens": [
          51614,
          2555,
          1066,
          27639,
          385,
          466,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23566998520942584,
        "compression_ratio": 1.6943521594684385,
        "end": 3680,
        "id": 976,
        "no_speech_prob": 0.23930993676185608,
        "seek": 365100,
        "start": 3678,
        "temperature": 0,
        "text": " I did an entire tutorial.",
        "tokens": [
          51714,
          286,
          630,
          364,
          2302,
          7073,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3682,
        "id": 977,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3680,
        "temperature": 0,
        "text": " I was asking about Markov chains.",
        "tokens": [
          50364,
          286,
          390,
          3365,
          466,
          3934,
          5179,
          12626,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3685,
        "id": 978,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3682,
        "temperature": 0,
        "text": " So I did a tutorial about Markov chains.",
        "tokens": [
          50464,
          407,
          286,
          630,
          257,
          7073,
          466,
          3934,
          5179,
          12626,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3688,
        "id": 979,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3685,
        "temperature": 0,
        "text": " It related to text-based Markov chains.",
        "tokens": [
          50614,
          467,
          4077,
          281,
          2487,
          12,
          6032,
          3934,
          5179,
          12626,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3691,
        "id": 980,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3688,
        "temperature": 0,
        "text": " And that's part of the A to Z playlist.",
        "tokens": [
          50764,
          400,
          300,
          311,
          644,
          295,
          264,
          316,
          281,
          1176,
          16788,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3696,
        "id": 981,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3691,
        "temperature": 0,
        "text": " And I believe it is, boy, I guess session 5?",
        "tokens": [
          50914,
          400,
          286,
          1697,
          309,
          307,
          11,
          3237,
          11,
          286,
          2041,
          5481,
          1025,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3698,
        "id": 982,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3696,
        "temperature": 0,
        "text": " No, session 6.",
        "tokens": [
          51164,
          883,
          11,
          5481,
          1386,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3700,
        "id": 983,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3698,
        "temperature": 0,
        "text": " So if you go here to session 6,",
        "tokens": [
          51264,
          407,
          498,
          291,
          352,
          510,
          281,
          5481,
          1386,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3704,
        "id": 984,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3700,
        "temperature": 0,
        "text": " there are a set of videos about Ngram's Markov chains.",
        "tokens": [
          51364,
          456,
          366,
          257,
          992,
          295,
          2145,
          466,
          426,
          1342,
          311,
          3934,
          5179,
          12626,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19656787599836076,
        "compression_ratio": 1.6712328767123288,
        "end": 3708,
        "id": 985,
        "no_speech_prob": 0.10817085951566696,
        "seek": 368000,
        "start": 3704,
        "temperature": 0,
        "text": " And I do a couple different challenges or experiments with them.",
        "tokens": [
          51564,
          400,
          286,
          360,
          257,
          1916,
          819,
          4759,
          420,
          12050,
          365,
          552,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3710,
        "id": 986,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3708,
        "temperature": 0,
        "text": " I don't know what's in these, but I did make them.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          437,
          311,
          294,
          613,
          11,
          457,
          286,
          630,
          652,
          552,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3716,
        "id": 987,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3710,
        "temperature": 0,
        "text": " Jason asks, are there any benefits to using JSON files versus something like Mongo?",
        "tokens": [
          50464,
          11181,
          8962,
          11,
          366,
          456,
          604,
          5311,
          281,
          1228,
          31828,
          7098,
          5717,
          746,
          411,
          48380,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3719,
        "id": 988,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3716,
        "temperature": 0,
        "text": " Now this is just what I think at this moment right now.",
        "tokens": [
          50764,
          823,
          341,
          307,
          445,
          437,
          286,
          519,
          412,
          341,
          1623,
          558,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3724,
        "id": 989,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3719,
        "temperature": 0,
        "text": " But I would say that the advantage to using JSON file versus something like Mongo",
        "tokens": [
          50914,
          583,
          286,
          576,
          584,
          300,
          264,
          5002,
          281,
          1228,
          31828,
          3991,
          5717,
          746,
          411,
          48380,
          51164
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3728,
        "id": 990,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3724,
        "temperature": 0,
        "text": " is you could just get started doing it really quickly and easily.",
        "tokens": [
          51164,
          307,
          291,
          727,
          445,
          483,
          1409,
          884,
          309,
          534,
          2661,
          293,
          3612,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3729,
        "id": 991,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3728,
        "temperature": 0,
        "text": " So I have a little bit of data.",
        "tokens": [
          51364,
          407,
          286,
          362,
          257,
          707,
          857,
          295,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3730,
        "id": 992,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3729,
        "temperature": 0,
        "text": " I just want to save it.",
        "tokens": [
          51414,
          286,
          445,
          528,
          281,
          3155,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3731,
        "id": 993,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3730,
        "temperature": 0,
        "text": " I just want to load it.",
        "tokens": [
          51464,
          286,
          445,
          528,
          281,
          3677,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2013310740764876,
        "compression_ratio": 1.7508896797153024,
        "end": 3734,
        "id": 994,
        "no_speech_prob": 0.12418901920318604,
        "seek": 370800,
        "start": 3731,
        "temperature": 0,
        "text": " I'm done in two seconds with just a few lines of code in the file system.",
        "tokens": [
          51514,
          286,
          478,
          1096,
          294,
          732,
          3949,
          365,
          445,
          257,
          1326,
          3876,
          295,
          3089,
          294,
          264,
          3991,
          1185,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3739,
        "id": 995,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3735,
        "temperature": 0,
        "text": " A Mongo database is certainly going to have so much more robust",
        "tokens": [
          50414,
          316,
          48380,
          8149,
          307,
          3297,
          516,
          281,
          362,
          370,
          709,
          544,
          13956,
          50614
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3741,
        "id": 996,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3739,
        "temperature": 0,
        "text": " and sophisticated functionality.",
        "tokens": [
          50614,
          293,
          16950,
          14980,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3742,
        "id": 997,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3741,
        "temperature": 0,
        "text": " Databases can be relational.",
        "tokens": [
          50714,
          40461,
          1957,
          393,
          312,
          38444,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3745,
        "id": 998,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3742,
        "temperature": 0,
        "text": " They can be really fast to do sorting and searching through them.",
        "tokens": [
          50764,
          814,
          393,
          312,
          534,
          2370,
          281,
          360,
          32411,
          293,
          10808,
          807,
          552,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3749,
        "id": 999,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3745,
        "temperature": 0,
        "text": " But you're going to have to spend a lot of time learning how the database works,",
        "tokens": [
          50914,
          583,
          291,
          434,
          516,
          281,
          362,
          281,
          3496,
          257,
          688,
          295,
          565,
          2539,
          577,
          264,
          8149,
          1985,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3752,
        "id": 1000,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3749,
        "temperature": 0,
        "text": " how the particular node package for using a MongoDB works.",
        "tokens": [
          51114,
          577,
          264,
          1729,
          9984,
          7372,
          337,
          1228,
          257,
          48380,
          27735,
          1985,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3755,
        "id": 1001,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3752,
        "temperature": 0,
        "text": " So for a larger scale project and for a lot of time,",
        "tokens": [
          51264,
          407,
          337,
          257,
          4833,
          4373,
          1716,
          293,
          337,
          257,
          688,
          295,
          565,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3759,
        "id": 1002,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3755,
        "temperature": 0,
        "text": " but for something you're just making because you're making some quick game experiment",
        "tokens": [
          51414,
          457,
          337,
          746,
          291,
          434,
          445,
          1455,
          570,
          291,
          434,
          1455,
          512,
          1702,
          1216,
          5120,
          51614
        ]
      },
      {
        "avg_logprob": -0.18869418785220288,
        "compression_ratio": 1.7713310580204777,
        "end": 3761,
        "id": 1003,
        "no_speech_prob": 0.052613694220781326,
        "seek": 373400,
        "start": 3759,
        "temperature": 0,
        "text": " and you have this other Arduino hooked over here",
        "tokens": [
          51614,
          293,
          291,
          362,
          341,
          661,
          39539,
          20410,
          670,
          510,
          51714
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3764,
        "id": 1004,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3761,
        "temperature": 0,
        "text": " and it's talking to a node server which is hooked up to a sensor.",
        "tokens": [
          50364,
          293,
          309,
          311,
          1417,
          281,
          257,
          9984,
          7154,
          597,
          307,
          20410,
          493,
          281,
          257,
          10200,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3766,
        "id": 1005,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3764,
        "temperature": 0,
        "text": " You just want to save a bunch of readings to it.",
        "tokens": [
          50514,
          509,
          445,
          528,
          281,
          3155,
          257,
          3840,
          295,
          27319,
          281,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3771,
        "id": 1006,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3766,
        "temperature": 0,
        "text": " Using a text file, a JSON file, I think is a great way of doing that.",
        "tokens": [
          50614,
          11142,
          257,
          2487,
          3991,
          11,
          257,
          31828,
          3991,
          11,
          286,
          519,
          307,
          257,
          869,
          636,
          295,
          884,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3774,
        "id": 1007,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3771,
        "temperature": 0,
        "text": " Do you ever plan on making games in p5.js or processing?",
        "tokens": [
          50864,
          1144,
          291,
          1562,
          1393,
          322,
          1455,
          2813,
          294,
          280,
          20,
          13,
          25530,
          420,
          9007,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3777,
        "id": 1008,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3774,
        "temperature": 0,
        "text": " So yes, this is a question from Minor Scotty.",
        "tokens": [
          51014,
          407,
          2086,
          11,
          341,
          307,
          257,
          1168,
          490,
          36117,
          9534,
          874,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3778,
        "id": 1009,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3777,
        "temperature": 0,
        "text": " I do plan on doing that.",
        "tokens": [
          51164,
          286,
          360,
          1393,
          322,
          884,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3780,
        "id": 1010,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3778,
        "temperature": 0,
        "text": " I have a few.",
        "tokens": [
          51214,
          286,
          362,
          257,
          1326,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3782,
        "id": 1011,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3780,
        "temperature": 0,
        "text": " I've been doing this kind of A to Z course,",
        "tokens": [
          51314,
          286,
          600,
          668,
          884,
          341,
          733,
          295,
          316,
          281,
          1176,
          1164,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.17131794117115162,
        "compression_ratio": 1.5854545454545454,
        "end": 3786,
        "id": 1012,
        "no_speech_prob": 0.028003063052892685,
        "seek": 376100,
        "start": 3782,
        "temperature": 0,
        "text": " so I'm quite behind on my mental list of what I would like to do.",
        "tokens": [
          51414,
          370,
          286,
          478,
          1596,
          2261,
          322,
          452,
          4973,
          1329,
          295,
          437,
          286,
          576,
          411,
          281,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3792,
        "id": 1013,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3786,
        "temperature": 0,
        "text": " But if I go to my playlists and look for coding challenges.",
        "tokens": [
          50364,
          583,
          498,
          286,
          352,
          281,
          452,
          862,
          36693,
          293,
          574,
          337,
          17720,
          4759,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3794,
        "id": 1014,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3792,
        "temperature": 0,
        "text": " Where is that one?",
        "tokens": [
          50664,
          2305,
          307,
          300,
          472,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3799,
        "id": 1015,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3794,
        "temperature": 0,
        "text": " Oh, I'm logged in here.",
        "tokens": [
          50764,
          876,
          11,
          286,
          478,
          27231,
          294,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3801,
        "id": 1016,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3799,
        "temperature": 0,
        "text": " So you're seeing all my private.",
        "tokens": [
          51014,
          407,
          291,
          434,
          2577,
          439,
          452,
          4551,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3805,
        "id": 1017,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3801,
        "temperature": 0,
        "text": " This is the video that I'm going to launch as soon as I turn this off,",
        "tokens": [
          51114,
          639,
          307,
          264,
          960,
          300,
          286,
          478,
          516,
          281,
          4025,
          382,
          2321,
          382,
          286,
          1261,
          341,
          766,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3807,
        "id": 1018,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3805,
        "temperature": 0,
        "text": " which is a guest tutorial from Tiga that I mentioned.",
        "tokens": [
          51314,
          597,
          307,
          257,
          8341,
          7073,
          490,
          314,
          9900,
          300,
          286,
          2835,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3809,
        "id": 1019,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3807,
        "temperature": 0,
        "text": " I don't know why I'm not finding the coding challenges all of a sudden.",
        "tokens": [
          51414,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          406,
          5006,
          264,
          17720,
          4759,
          439,
          295,
          257,
          3990,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23174322568453276,
        "compression_ratio": 1.5491071428571428,
        "end": 3811,
        "id": 1020,
        "no_speech_prob": 0.4648001194000244,
        "seek": 378600,
        "start": 3809,
        "temperature": 0,
        "text": " Here they are.",
        "tokens": [
          51514,
          1692,
          436,
          366,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3816,
        "id": 1021,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3811,
        "temperature": 0,
        "text": " So this particular video, this particular playlist is where I will typically,",
        "tokens": [
          50364,
          407,
          341,
          1729,
          960,
          11,
          341,
          1729,
          16788,
          307,
          689,
          286,
          486,
          5850,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3819,
        "id": 1022,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3816,
        "temperature": 0,
        "text": " if I'm going to do a coding challenge to implement a particular game,",
        "tokens": [
          50614,
          498,
          286,
          478,
          516,
          281,
          360,
          257,
          17720,
          3430,
          281,
          4445,
          257,
          1729,
          1216,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3820,
        "id": 1023,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3819,
        "temperature": 0,
        "text": " you'll find it.",
        "tokens": [
          50764,
          291,
          603,
          915,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3826,
        "id": 1024,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3820,
        "temperature": 0,
        "text": " So I did Space Invaders 1 and the snake game for whatever reason.",
        "tokens": [
          50814,
          407,
          286,
          630,
          8705,
          31124,
          15221,
          502,
          293,
          264,
          12650,
          1216,
          337,
          2035,
          1778,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3827,
        "id": 1025,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3826,
        "temperature": 0,
        "text": " I don't understand.",
        "tokens": [
          51114,
          286,
          500,
          380,
          1223,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3831,
        "id": 1026,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3827,
        "temperature": 0,
        "text": " Wherever that is, that is my most watched video,",
        "tokens": [
          51164,
          30903,
          300,
          307,
          11,
          300,
          307,
          452,
          881,
          6337,
          960,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3833,
        "id": 1027,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3831,
        "temperature": 0,
        "text": " which gives me sort of an inclination to do some more of them.",
        "tokens": [
          51364,
          597,
          2709,
          385,
          1333,
          295,
          364,
          37070,
          2486,
          281,
          360,
          512,
          544,
          295,
          552,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3838,
        "id": 1028,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3833,
        "temperature": 0,
        "text": " And I've had requests for Frogger and there was another one.",
        "tokens": [
          51464,
          400,
          286,
          600,
          632,
          12475,
          337,
          40103,
          1321,
          293,
          456,
          390,
          1071,
          472,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19968752707204512,
        "compression_ratio": 1.6129032258064515,
        "end": 3840,
        "id": 1029,
        "no_speech_prob": 0.008315488696098328,
        "seek": 381100,
        "start": 3838,
        "temperature": 0,
        "text": " Oh, I did Flappy Bird also.",
        "tokens": [
          51714,
          876,
          11,
          286,
          630,
          479,
          875,
          7966,
          15931,
          611,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3842,
        "id": 1030,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3840,
        "temperature": 0,
        "text": " I did a version where you clap too.",
        "tokens": [
          50364,
          286,
          630,
          257,
          3037,
          689,
          291,
          20760,
          886,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3847,
        "id": 1031,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3842,
        "temperature": 0,
        "text": " I can certainly consider more videos about Markov chains.",
        "tokens": [
          50464,
          286,
          393,
          3297,
          1949,
          544,
          2145,
          466,
          3934,
          5179,
          12626,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3849,
        "id": 1032,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3847,
        "temperature": 0,
        "text": " People are asking about Python.",
        "tokens": [
          50714,
          3432,
          366,
          3365,
          466,
          15329,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3852,
        "id": 1033,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3849,
        "temperature": 0,
        "text": " Python is a really amazing programming language to work with,",
        "tokens": [
          50814,
          15329,
          307,
          257,
          534,
          2243,
          9410,
          2856,
          281,
          589,
          365,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3856,
        "id": 1034,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3852,
        "temperature": 0,
        "text": " in particular because of the access that you have to so many Python packages",
        "tokens": [
          50964,
          294,
          1729,
          570,
          295,
          264,
          2105,
          300,
          291,
          362,
          281,
          370,
          867,
          15329,
          17401,
          51164
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3862,
        "id": 1035,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3856,
        "temperature": 0,
        "text": " for data, machine learning, data science, text, natural language.",
        "tokens": [
          51164,
          337,
          1412,
          11,
          3479,
          2539,
          11,
          1412,
          3497,
          11,
          2487,
          11,
          3303,
          2856,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3865,
        "id": 1036,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3862,
        "temperature": 0,
        "text": " It's not really an environment that I personally do a lot of work with,",
        "tokens": [
          51464,
          467,
          311,
          406,
          534,
          364,
          2823,
          300,
          286,
          5665,
          360,
          257,
          688,
          295,
          589,
          365,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.18830861082864464,
        "compression_ratio": 1.649056603773585,
        "end": 3867,
        "id": 1037,
        "no_speech_prob": 0.06560127437114716,
        "seek": 384000,
        "start": 3865,
        "temperature": 0,
        "text": " which is a bit of a fault of mine,",
        "tokens": [
          51614,
          597,
          307,
          257,
          857,
          295,
          257,
          7441,
          295,
          3892,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3870,
        "id": 1038,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3867,
        "temperature": 0,
        "text": " but I do think it's an opportunity for me to look at how a lot of these",
        "tokens": [
          50364,
          457,
          286,
          360,
          519,
          309,
          311,
          364,
          2650,
          337,
          385,
          281,
          574,
          412,
          577,
          257,
          688,
          295,
          613,
          50514
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3874,
        "id": 1039,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3870,
        "temperature": 0,
        "text": " kinds of algorithms and projects that are often made with Python work",
        "tokens": [
          50514,
          3685,
          295,
          14642,
          293,
          4455,
          300,
          366,
          2049,
          1027,
          365,
          15329,
          589,
          50714
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3878,
        "id": 1040,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3874,
        "temperature": 0,
        "text": " and can be programmed in other contexts like processing and JavaScript.",
        "tokens": [
          50714,
          293,
          393,
          312,
          31092,
          294,
          661,
          30628,
          411,
          9007,
          293,
          15778,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3883,
        "id": 1041,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3878,
        "temperature": 0,
        "text": " But I certainly would, if you're interested in the kind of topics that I do",
        "tokens": [
          50914,
          583,
          286,
          3297,
          576,
          11,
          498,
          291,
          434,
          3102,
          294,
          264,
          733,
          295,
          8378,
          300,
          286,
          360,
          51164
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3888,
        "id": 1042,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3883,
        "temperature": 0,
        "text": " in this channel, learning about Python, and there's a YouTube channel,",
        "tokens": [
          51164,
          294,
          341,
          2269,
          11,
          2539,
          466,
          15329,
          11,
          293,
          456,
          311,
          257,
          3088,
          2269,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3892,
        "id": 1043,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3888,
        "temperature": 0,
        "text": " Seraj's YouTube channel, which maybe somebody can post in the chat.",
        "tokens": [
          51414,
          318,
          1663,
          73,
          311,
          3088,
          2269,
          11,
          597,
          1310,
          2618,
          393,
          2183,
          294,
          264,
          5081,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.203385591506958,
        "compression_ratio": 1.7089041095890412,
        "end": 3895,
        "id": 1044,
        "no_speech_prob": 0.0003920285089407116,
        "seek": 386700,
        "start": 3892,
        "temperature": 0,
        "text": " He does a lot of data science and machine learning videos with Python.",
        "tokens": [
          51614,
          634,
          775,
          257,
          688,
          295,
          1412,
          3497,
          293,
          3479,
          2539,
          2145,
          365,
          15329,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3901,
        "id": 1045,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3895,
        "temperature": 0,
        "text": " And I am planning to do some stuff on machine learning in the spring.",
        "tokens": [
          50364,
          400,
          286,
          669,
          5038,
          281,
          360,
          512,
          1507,
          322,
          3479,
          2539,
          294,
          264,
          5587,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3903,
        "id": 1046,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3901,
        "temperature": 0,
        "text": " Android development is not something on my list.",
        "tokens": [
          50664,
          8853,
          3250,
          307,
          406,
          746,
          322,
          452,
          1329,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3905,
        "id": 1047,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3903,
        "temperature": 0,
        "text": " It's not something I know a lot about, but I would love to have a guest",
        "tokens": [
          50764,
          467,
          311,
          406,
          746,
          286,
          458,
          257,
          688,
          466,
          11,
          457,
          286,
          576,
          959,
          281,
          362,
          257,
          8341,
          50864
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3909,
        "id": 1048,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3905,
        "temperature": 0,
        "text": " come in and do some guest Android development tutorials for sure.",
        "tokens": [
          50864,
          808,
          294,
          293,
          360,
          512,
          8341,
          8853,
          3250,
          17616,
          337,
          988,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3913,
        "id": 1049,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3909,
        "temperature": 0,
        "text": " Okay, so I think I am wrapping up for today.",
        "tokens": [
          51064,
          1033,
          11,
          370,
          286,
          519,
          286,
          669,
          21993,
          493,
          337,
          965,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3916,
        "id": 1050,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3913,
        "temperature": 0,
        "text": " I'm sorry, this was a one-hour and five-minute livestream,",
        "tokens": [
          51264,
          286,
          478,
          2597,
          11,
          341,
          390,
          257,
          472,
          12,
          18048,
          293,
          1732,
          12,
          18256,
          29782,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1783391869586447,
        "compression_ratio": 1.6793893129770991,
        "end": 3921,
        "id": 1051,
        "no_speech_prob": 0.008187232539057732,
        "seek": 389500,
        "start": 3916,
        "temperature": 0,
        "text": " which is much shorter than they usually are, so I apologize for that shortness.",
        "tokens": [
          51414,
          597,
          307,
          709,
          11639,
          813,
          436,
          2673,
          366,
          11,
          370,
          286,
          12328,
          337,
          300,
          2099,
          1287,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3926,
        "id": 1052,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3921,
        "temperature": 0,
        "text": " I am going to be back live in about three and a half hours",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          312,
          646,
          1621,
          294,
          466,
          1045,
          293,
          257,
          1922,
          2496,
          50614
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3930,
        "id": 1053,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3926,
        "temperature": 0,
        "text": " with Jane Friedhoff, I mentioned, who's a game developer and artist.",
        "tokens": [
          50614,
          365,
          13048,
          17605,
          1289,
          602,
          11,
          286,
          2835,
          11,
          567,
          311,
          257,
          1216,
          10754,
          293,
          5748,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3933,
        "id": 1054,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3930,
        "temperature": 0,
        "text": " And she's going to just show a project, and you can ask her questions about it.",
        "tokens": [
          50814,
          400,
          750,
          311,
          516,
          281,
          445,
          855,
          257,
          1716,
          11,
          293,
          291,
          393,
          1029,
          720,
          1651,
          466,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3939,
        "id": 1055,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3933,
        "temperature": 0,
        "text": " But I might not be here, unfortunately, again next week",
        "tokens": [
          50964,
          583,
          286,
          1062,
          406,
          312,
          510,
          11,
          7015,
          11,
          797,
          958,
          1243,
          51264
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3941,
        "id": 1056,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3939,
        "temperature": 0,
        "text": " due to the Thanksgiving holiday.",
        "tokens": [
          51264,
          3462,
          281,
          264,
          21230,
          9960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3945,
        "id": 1057,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3941,
        "temperature": 0,
        "text": " So next week's schedule is all crazy, and things are a bit more tight now",
        "tokens": [
          51364,
          407,
          958,
          1243,
          311,
          7567,
          307,
          439,
          3219,
          11,
          293,
          721,
          366,
          257,
          857,
          544,
          4524,
          586,
          51564
        ]
      },
      {
        "avg_logprob": -0.21639008357607084,
        "compression_ratio": 1.6036363636363635,
        "end": 3949,
        "id": 1058,
        "no_speech_prob": 0.017980817705392838,
        "seek": 392100,
        "start": 3945,
        "temperature": 0,
        "text": " with the school schedule here and the NYU schedule that I have at NYU.",
        "tokens": [
          51564,
          365,
          264,
          1395,
          7567,
          510,
          293,
          264,
          42682,
          7567,
          300,
          286,
          362,
          412,
          42682,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3953,
        "id": 1059,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3949,
        "temperature": 0,
        "text": " But hopefully by the time I get to January, I'll be back up and running",
        "tokens": [
          50364,
          583,
          4696,
          538,
          264,
          565,
          286,
          483,
          281,
          7061,
          11,
          286,
          603,
          312,
          646,
          493,
          293,
          2614,
          50564
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3956,
        "id": 1060,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3953,
        "temperature": 0,
        "text": " with full, weekly, longer livestreams.",
        "tokens": [
          50564,
          365,
          1577,
          11,
          12460,
          11,
          2854,
          29782,
          82,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3961,
        "id": 1061,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3956,
        "temperature": 0,
        "text": " But I am really hoping to finish all the A to Z materials this fall.",
        "tokens": [
          50714,
          583,
          286,
          669,
          534,
          7159,
          281,
          2413,
          439,
          264,
          316,
          281,
          1176,
          5319,
          341,
          2100,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3963,
        "id": 1062,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3961,
        "temperature": 0,
        "text": " So hopefully that's going to happen.",
        "tokens": [
          50964,
          407,
          4696,
          300,
          311,
          516,
          281,
          1051,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3967,
        "id": 1063,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3963,
        "temperature": 0,
        "text": " So thank you. It's nice to see all these friendly messages in the chat.",
        "tokens": [
          51064,
          407,
          1309,
          291,
          13,
          467,
          311,
          1481,
          281,
          536,
          439,
          613,
          9208,
          7897,
          294,
          264,
          5081,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3970,
        "id": 1064,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3967,
        "temperature": 0,
        "text": " And I will see you. Please come back.",
        "tokens": [
          51264,
          400,
          286,
          486,
          536,
          291,
          13,
          2555,
          808,
          646,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22205617406346775,
        "compression_ratio": 1.58984375,
        "end": 3973,
        "id": 1065,
        "no_speech_prob": 0.006094892509281635,
        "seek": 394900,
        "start": 3970,
        "temperature": 0,
        "text": " Everything I do will be archived, so you'll be able to watch the video interview",
        "tokens": [
          51414,
          5471,
          286,
          360,
          486,
          312,
          3912,
          3194,
          11,
          370,
          291,
          603,
          312,
          1075,
          281,
          1159,
          264,
          960,
          4049,
          51564
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 3976,
        "id": 1066,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3974,
        "temperature": 0,
        "text": " with Jane any time later.",
        "tokens": [
          50414,
          365,
          13048,
          604,
          565,
          1780,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 3982,
        "id": 1067,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3976,
        "temperature": 0,
        "text": " But if you're around, not in Europe in a sleep, or some other country",
        "tokens": [
          50514,
          583,
          498,
          291,
          434,
          926,
          11,
          406,
          294,
          3315,
          294,
          257,
          2817,
          11,
          420,
          512,
          661,
          1941,
          50814
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 3987,
        "id": 1068,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3982,
        "temperature": 0,
        "text": " where it's the middle of the night in three or four hours, come back.",
        "tokens": [
          50814,
          689,
          309,
          311,
          264,
          2808,
          295,
          264,
          1818,
          294,
          1045,
          420,
          1451,
          2496,
          11,
          808,
          646,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 3991,
        "id": 1069,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3987,
        "temperature": 0,
        "text": " And I'll post on Twitter time-wise, and I'll also try to make the YouTube",
        "tokens": [
          51064,
          400,
          286,
          603,
          2183,
          322,
          5794,
          565,
          12,
          3711,
          11,
          293,
          286,
          603,
          611,
          853,
          281,
          652,
          264,
          3088,
          51264
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 3994,
        "id": 1070,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3991,
        "temperature": 0,
        "text": " stream page show the time until that's happening as well.",
        "tokens": [
          51264,
          4309,
          3028,
          855,
          264,
          565,
          1826,
          300,
          311,
          2737,
          382,
          731,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 3996,
        "id": 1071,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3994,
        "temperature": 0,
        "text": " Okay? Thanks, everybody.",
        "tokens": [
          51414,
          1033,
          30,
          2561,
          11,
          2201,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24560314525257457,
        "compression_ratio": 1.505703422053232,
        "end": 4000,
        "id": 1072,
        "no_speech_prob": 0.0926351398229599,
        "seek": 397300,
        "start": 3996,
        "temperature": 0,
        "text": " And last thing I'll say, because Robert Perez asks, is when are my normal",
        "tokens": [
          51514,
          400,
          1036,
          551,
          286,
          603,
          584,
          11,
          570,
          7977,
          47317,
          8962,
          11,
          307,
          562,
          366,
          452,
          2710,
          51714
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4004,
        "id": 1073,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4000,
        "temperature": 0,
        "text": " livestreams? It was every Tuesday in the afternoon, but it's been a little",
        "tokens": [
          50364,
          29782,
          82,
          30,
          467,
          390,
          633,
          10017,
          294,
          264,
          6499,
          11,
          457,
          309,
          311,
          668,
          257,
          707,
          50564
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4010,
        "id": 1074,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4004,
        "temperature": 0,
        "text": " haphazard. If you go to codingrainbow.com, I actually didn't send out an email",
        "tokens": [
          50564,
          324,
          950,
          921,
          515,
          13,
          759,
          291,
          352,
          281,
          17720,
          7146,
          8202,
          13,
          1112,
          11,
          286,
          767,
          994,
          380,
          2845,
          484,
          364,
          3796,
          50864
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4012,
        "id": 1075,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4010,
        "temperature": 0,
        "text": " notice for today because I've just been so...",
        "tokens": [
          50864,
          3449,
          337,
          965,
          570,
          286,
          600,
          445,
          668,
          370,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4017,
        "id": 1076,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4012,
        "temperature": 0,
        "text": " But I post to Twitter, and I also, if you sign up for this email list,",
        "tokens": [
          50964,
          583,
          286,
          2183,
          281,
          5794,
          11,
          293,
          286,
          611,
          11,
          498,
          291,
          1465,
          493,
          337,
          341,
          3796,
          1329,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4021,
        "id": 1077,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4017,
        "temperature": 0,
        "text": " you can...if you sign up for this email list, you can...",
        "tokens": [
          51214,
          291,
          393,
          485,
          351,
          291,
          1465,
          493,
          337,
          341,
          3796,
          1329,
          11,
          291,
          393,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4024,
        "id": 1078,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4021,
        "temperature": 0,
        "text": " I do try to send out email announcements about the schedule,",
        "tokens": [
          51414,
          286,
          360,
          853,
          281,
          2845,
          484,
          3796,
          23785,
          466,
          264,
          7567,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.19573258151527212,
        "compression_ratio": 1.7131147540983607,
        "end": 4026,
        "id": 1079,
        "no_speech_prob": 0.15810300409793854,
        "seek": 400000,
        "start": 4024,
        "temperature": 0,
        "text": " and sometimes I just miss it.",
        "tokens": [
          51564,
          293,
          2171,
          286,
          445,
          1713,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4031,
        "id": 1080,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4026,
        "temperature": 0,
        "text": " But the other...it's always archived, and also I'll just mention, too,",
        "tokens": [
          50364,
          583,
          264,
          661,
          485,
          270,
          311,
          1009,
          3912,
          3194,
          11,
          293,
          611,
          286,
          603,
          445,
          2152,
          11,
          886,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4035,
        "id": 1081,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4031,
        "temperature": 0,
        "text": " subscribe, and if you're interested, there is an opportunity...",
        "tokens": [
          50614,
          3022,
          11,
          293,
          498,
          291,
          434,
          3102,
          11,
          456,
          307,
          364,
          2650,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4038,
        "id": 1082,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4035,
        "temperature": 0,
        "text": " I'm using a site called Patreon, which is a crowdfunding site.",
        "tokens": [
          50814,
          286,
          478,
          1228,
          257,
          3621,
          1219,
          15692,
          11,
          597,
          307,
          257,
          6919,
          45033,
          3621,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4041,
        "id": 1083,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4038,
        "temperature": 0,
        "text": " If you want to join that and join a Slack channel where we discuss",
        "tokens": [
          50964,
          759,
          291,
          528,
          281,
          3917,
          300,
          293,
          3917,
          257,
          37211,
          2269,
          689,
          321,
          2248,
          51114
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4043,
        "id": 1084,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4041,
        "temperature": 0,
        "text": " a lot of the videos and stuff.",
        "tokens": [
          51114,
          257,
          688,
          295,
          264,
          2145,
          293,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4045,
        "id": 1085,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4043,
        "temperature": 0,
        "text": " Okay. Thanks, everybody.",
        "tokens": [
          51214,
          1033,
          13,
          2561,
          11,
          2201,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4050,
        "id": 1086,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4045,
        "temperature": 0,
        "text": " Oh, I'm going to play you out with my video trailer, since it's the edited one",
        "tokens": [
          51314,
          876,
          11,
          286,
          478,
          516,
          281,
          862,
          291,
          484,
          365,
          452,
          960,
          11724,
          11,
          1670,
          309,
          311,
          264,
          23016,
          472,
          51564
        ]
      },
      {
        "avg_logprob": -0.19753851890563964,
        "compression_ratio": 1.5607142857142857,
        "end": 4053,
        "id": 1087,
        "no_speech_prob": 0.028425006195902824,
        "seek": 402600,
        "start": 4050,
        "temperature": 0,
        "text": " because of my legal trademark issues.",
        "tokens": [
          51564,
          570,
          295,
          452,
          5089,
          31361,
          2663,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19794904863512194,
        "compression_ratio": 1.2474226804123711,
        "end": 4056,
        "id": 1088,
        "no_speech_prob": 0.08751250058412552,
        "seek": 405300,
        "start": 4053,
        "temperature": 0,
        "text": " But I'll play that for you at the end, since I didn't play it at the beginning,",
        "tokens": [
          50364,
          583,
          286,
          603,
          862,
          300,
          337,
          291,
          412,
          264,
          917,
          11,
          1670,
          286,
          994,
          380,
          862,
          309,
          412,
          264,
          2863,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.19794904863512194,
        "compression_ratio": 1.2474226804123711,
        "end": 4058,
        "id": 1089,
        "no_speech_prob": 0.08751250058412552,
        "seek": 405300,
        "start": 4056,
        "temperature": 0,
        "text": " and then I'll be shutting the stream off.",
        "tokens": [
          50514,
          293,
          550,
          286,
          603,
          312,
          36057,
          264,
          4309,
          766,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.317388117313385,
        "compression_ratio": 1.406060606060606,
        "end": 4062,
        "id": 1090,
        "no_speech_prob": 0.7536519169807434,
        "seek": 405800,
        "start": 4059,
        "temperature": 0,
        "text": " ♪ Did you think that learning coding would be really rough?",
        "tokens": [
          50414,
          220,
          158,
          247,
          103,
          2589,
          291,
          519,
          300,
          2539,
          17720,
          576,
          312,
          534,
          5903,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.317388117313385,
        "compression_ratio": 1.406060606060606,
        "end": 4065,
        "id": 1091,
        "no_speech_prob": 0.7536519169807434,
        "seek": 405800,
        "start": 4062,
        "temperature": 0,
        "text": " Throw your hands up in the air and say, enough's enough.",
        "tokens": [
          50564,
          22228,
          428,
          2377,
          493,
          294,
          264,
          1988,
          293,
          584,
          11,
          1547,
          311,
          1547,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.317388117313385,
        "compression_ratio": 1.406060606060606,
        "end": 4068,
        "id": 1092,
        "no_speech_prob": 0.7536519169807434,
        "seek": 405800,
        "start": 4065,
        "temperature": 0,
        "text": " Do you want to learn to code and make some awesome stuff?",
        "tokens": [
          50714,
          1144,
          291,
          528,
          281,
          1466,
          281,
          3089,
          293,
          652,
          512,
          3476,
          1507,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.317388117313385,
        "compression_ratio": 1.406060606060606,
        "end": 4072,
        "id": 1093,
        "no_speech_prob": 0.7536519169807434,
        "seek": 405800,
        "start": 4068,
        "temperature": 0,
        "text": " Learn that anyone can when you're coding with Dan on...",
        "tokens": [
          50864,
          17216,
          300,
          2878,
          393,
          562,
          291,
          434,
          17720,
          365,
          3394,
          322,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.760737555367606,
        "compression_ratio": 0.2727272727272727,
        "end": 4075,
        "id": 1094,
        "no_speech_prob": 0.6149371862411499,
        "seek": 407200,
        "start": 4072,
        "temperature": 0,
        "text": " ♪",
        "tokens": [
          50364,
          220,
          158,
          247,
          103,
          50514
        ]
      },
      {
        "avg_logprob": -0.24803142888205393,
        "compression_ratio": 0.2727272727272727,
        "end": 4106,
        "id": 1095,
        "no_speech_prob": 0.8197124004364014,
        "seek": 410200,
        "start": 4102,
        "temperature": 0,
        "text": " ♪",
        "tokens": [
          50414,
          220,
          158,
          247,
          103,
          50564
        ]
      },
      {
        "avg_logprob": -0.3114633560180664,
        "compression_ratio": 0.9852941176470589,
        "end": 4135,
        "id": 1096,
        "no_speech_prob": 0.43770888447761536,
        "seek": 413200,
        "start": 4132,
        "temperature": 0,
        "text": " ♪",
        "tokens": [
          50364,
          220,
          158,
          247,
          103,
          50514
        ]
      },
      {
        "avg_logprob": -0.3114633560180664,
        "compression_ratio": 0.9852941176470589,
        "end": 4140,
        "id": 1097,
        "no_speech_prob": 0.43770888447761536,
        "seek": 413200,
        "start": 4136,
        "temperature": 0,
        "text": " Write the colors of code. You can follow the road, too.",
        "tokens": [
          50564,
          23499,
          264,
          4577,
          295,
          3089,
          13,
          509,
          393,
          1524,
          264,
          3060,
          11,
          886,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3114633560180664,
        "compression_ratio": 0.9852941176470589,
        "end": 4143,
        "id": 1098,
        "no_speech_prob": 0.43770888447761536,
        "seek": 413200,
        "start": 4140,
        "temperature": 0,
        "text": " ♪",
        "tokens": [
          50764,
          220,
          158,
          247,
          103,
          50914
        ]
      },
      {
        "avg_logprob": -0.3114633560180664,
        "compression_ratio": 0.9852941176470589,
        "end": 4147,
        "id": 1099,
        "no_speech_prob": 0.43770888447761536,
        "seek": 413200,
        "start": 4146,
        "temperature": 0,
        "text": " ♪",
        "tokens": [
          51064,
          220,
          158,
          247,
          103,
          51114
        ]
      }
    ],
    "transcription": " Hello, I think I am live. Welcome to another live stream. A little bit of some, as always, technical difficulties. Welcome, my name is Dan. I see that I'm here. Let me know, oops, I've got to turn my volume off here. Let me know if you can hear and see me okay. We're live for another session. Now I have something to admit, a bunch of things to admit, which is that the whole last week has been kind of a blur. A lot of things have been happening in this country. I missed last week, even doing a live stream. Things were very busy with my other job, which is teaching classes at NYU. So, and today I'm in a bit of a tight schedule. It's 10 of 2 and I only have currently until 3 p.m. Eastern time. Oh, lots of noise. Okay, okay, okay. Okay, so far this is a failure with the mic glitching. Let's see what I can do about that. Is that better? Is that better by any chance? Did I fix something? Talk, talk, talk, talk. Or is it still bad? I pressed a button. No, it's not better? I can't, I don't, okay. Test, test. I'm going to use this. Is this better? Am I good? Any better? I'm watching this chat with bated breath. Better, okay, great, yay. Okay, I switched cables. Oh, my goodness. Very, very close to not having a live stream today, everybody. But so far, hello, Arvind. I love seeing all those hearts. Okay, so let me say a few words in a matter of introduction. My name is Dan. I attempt to do weekly live streams and make programming tutorials in the kind of idea of inspiring and teaching people to be creative and think differently with code. That's not a good way of describing it. Today is Tuesday, November 15th. A lot has happened in the last week. And I would like to, before I begin doing some tutorials, I would like to read from you the, so first of all, so one thing that's always been a little confusing to me is that, turn it up. Okay, yeah. I turned the volume up a little bit. Is that I do a number of things. I work at New York University, Tisch School of the Arts, a program called ITP. I spend almost all of my time there. I also work on something called the Processing Foundation. The Processing Foundation is a not-for-profit foundation, organization, whose mission is to promote software literacy in the visual arts and visual literacy in the technology-related fields and to make these fields accessible to diverse communities. Those are my two primary things that I do. This YouTube channel is a bit of an independent project. It has a lot of relationships to the Processing Foundation in that I do a lot of tutorials around processing in P5.js. But what I want to do for just the first five minutes here is piggyback off of the P5.js Projects community statement. And I think it's really important after the election here in this country to make this statement as part of this YouTube channel and to talk about just how I envision and think about this community. So this is the P5.js community statement. It was not written by me. It was written by contributors to P5.js. I believe it was created at the P5.js Contributors Conference. I don't know if that's right. Somebody fact-checked me on that. But this statement goes for this YouTube channel as well. We are a community of and in solidarity with people from every gender, identity, and expression, sexual orientation, race, ethnicity, language, neurotype, size, ability, class, religion, culture, subculture, political opinion, age, skill level, occupation, and background. We acknowledge that not everyone has the time, financial means, or capacity to actively participate. That's referring to the open source nature of P5.js. But we recognize and encourage involvement of all kinds. We facilitate and foster access and empowerment. We are all learners. And this is how I feel about this channel. I want this channel to be open, accessible, inclusive for everyone. And I would like this channel in particular to be a friendly place for beginners and people who are new to coding and creative coding to feel welcome and included in part of the discussion. So, I want to make that statement at the beginning of this live stream. Actually, you should read this whole page. I'm going to read a little bit more of it to you. And then I'm going to move on to talking about Node. In practice, we are not code snobs. We do not assume knowledge or imply there are things that somebody should know. We insist on actively engaging with requests for feedback regardless of their complexity. We welcome newcomers and prioritize the education of others. We strive to approach all tasks with the enthusiasm of a newcomer. Because we believe that newcomers are just as valuable in this effort as experts. We consistently make the effort to actively recognize and validate multiple types of contributions. We are always willing to offer help or guidance. We listen. We clearly communicate. We admit when we're wrong. We continuously seek to improve ourselves. We keep our community respectful and open. We make everyone feel heard. And we are mindful and kind in our interactions. Okay. So, thanks for tuning in. Thanks for listening to me as I read the p5.js community statement. And I hope that you enjoy this YouTube channel and find it useful. And I hope that you will be in touch in the chat and on Twitter. And all the other ways that we can be in touch with each other and help support everyone in their desire to learn more. And create and communicate. Express themselves through code, the internet, technology, all that sort of stuff. Okay. So, I'm a little bit... It is 2 o'clock. I have exactly one hour. And in my last session, I'm just going to pull up the playlist that I didn't get to finish. I don't know if I'll get to finish it today. But my most recent playlist, session 8, which is... The topic was looking at how to build your own API in Node. And the API example that I'm building is sentiment analysis API. Since... Why not? Since this is arguably... These sessions from this fall are all about programming with text. So, that's useful. So, I'm going to kind of pick up right where I left. And I've got a couple more little short tutorials to make. Now, I'll say a couple of other things about my plans for the rest of this 2016 year. Which, as far as I'm concerned, 2017 can't come soon enough. Maybe 2020 should come soon enough. But... Let me... Okay. So, if you recall, what I'm doing right now in this fall is making videos for this course. Programming from A to Z. Which is... Everything can be found at shiffman.net.com. These are all written tutorials on various topics with videos. So, right now, I'm working on this page, which is building an API with Node and Express. And you can see I've got some examples. I've got some text descriptions. And I've got some embedded videos. So, before the end of 2016, I hope to finish this page. I want to do some videos about working with a database as service. Something called Firebase, which you may or may not have heard of. So, I already have a written tutorial, but there are no videos for that yet. As well as looking at Chrome extensions. So, the Firebase topic is a smaller topic. Probably can happen in a shorter session. The Chrome extensions is a longer topic that will need a longer session. So, it is the middle of November. And I have until the end of December to get through all this stuff. I'm hoping that, actually, I'll get through this stuff relatively soon. And return, I would like to, by the end of the year. Maybe for kind of like a holiday special, just do some fun, quirky coding challenges. Some different algorithms that I would like to explore. And as well as my most popular videos, which I've said before. Where I take an old kind of classic arcade style game and try to make a JavaScript version of it. So, I'm hoping to do those kind of things before the end of the year. This spring, I will be returning to the nature of code materials. Which is physics and animation. As well as starting to look at machine learning topics. So, that's all coming in the pipeline. Now, another thing I'll say, just as a matter of updating you as to what's happening. Is that I have started having guests. And in fact, later today, I just didn't get to do it this morning. I will make live a tutorial from Tega Brain. Who is one of the teachers and alumni of the School for Product Computation. Which is where I'm recording the videos right now. And she has a tutorial about working with physical sensors and P5.js. So, that tutorial, you'll see that in the channel, in the stream later today. And then also, if all goes according to plan. At around 6.30pm, Eastern Time today. I will be welcoming Jane Friedhoff into the studio. And Jane Friedhoff is a creative researcher, designer, game designer. She does amazing, wonderful work. And she's going to talk about a game called Slam City Oracles. And how she made it. And I'll ask her a few questions about that. And if you're tuning in live, you can ask questions in the chat. So, I'm also trying... I have very limited time these couple weeks. But as time goes on, I'm going to try to have more guests. To bring you additional content and different voices and different faces. From just me in this channel. Okay. So, I'm going to get myself set up here. I'm kind of keeping half of an eye on the chat. So, if you have a question in there, you can ask. But in the words of Jane, let's make it happen. Okay. So, what I've got to do here... And I don't have my sound stuff hooked up. Because I had a bunch of issues. So, I normally like to play background music when I'm just in the let me get myself situated here. But let's see if I can find where I left off. Session 8, API 1. So, let's copy that. I don't remember where I left off. Let's copy that into API 2. I also have a little bit of an issue where my whiteboard camera... I just went all black. Isn't working. So, I don't know if I'm going to be able to use the whiteboard today. But that's okay. I think we can live with that. So, this is where I left off last time. Let me run Adam as a text editor. Boy, there's a lot of great questions in the chat. And... Actually, I don't know if... Someone's asking about D3. In the hope that I would be able to make a video tutorial about everything and anything that exists in the world. I would love to do something about D3. But it's not on my list in something that I'm going to be getting to soon. But that would be a great topic for a guest to come in and do a tutorial. Okay. So, here is my node server. Here is the web page. Okay. So, let me open up terminal. I'm just trying to catch up to remember where I left off. And I should have watched the last video I made, which was two weeks ago. But if I look at this example... Where am I? Oh, no. I want to be in desktop. Sorry. Oops. Trying to get to the right folder right now. And I'm going to API 2. And I'm saying node server. And I'm running the server. Did I talk about nodemon? I think I did. I'm going to run that. Okay. And now I'm going to bring up Chrome. Localhost... I don't remember what port I'm running it on. 3000. Hello. The point of this is that... Okay. So, this is where we were last time. We're creating a sentiment analysis API. One of the things you can do with a sentiment analysis API is add words to a quote-unquote database. Which is here. Database is just like hard-coded in the code. And so, if I try to add words to a database... If I try to add something... I'm going to add, for example, add rainbow 5. This... I have now gone to... I'm just reviewing where I left off. I've gone to this route. Add rainbow 5. I get the parameters from that route. Which are rainbow and 5. And if I look now in terminal... Oh, I don't have any console logging going on. It sends a message back that it was added. And then I can also go to the route all. And I can go to the route all. And I can see... Oh, rainbow is in there. Sorry. And rainbow is already in there. As one of the ones. So, let me add something else. Add... Right. I was using purple 3. That is now added. Let me go to all. And I can see that I've added now purple to this list. Great. That's working. And I also have a search route. If I look for kitten, not found. But if I look for purple, it's found and I get the score. Okay. So, this is what I'm doing. I'm building a sentiment analysis API. Now, what are the other pieces of this that I need? I want to do something about persistence. So, I want the data to be saved. So, I want to save the data to a JSON file every time a new word is added. And then when the server restarts, it loads the JSON file. Okay. So, that's one thing I want to do. Another thing I want to do is create a front end to interact with the API. As a way of just being able to see how it works. And see how you can interface with your own API that you made. So, that's two things. And then I also, third thing, is I need to cover how to post to an API. The difference between a get request and a post request. Let me see if I can get this camera working. Because I kind of feel like I want a diagram for that. Oh, that's promising. I heard a click. So, I think, if you would just bear with me for a second. You're going to have to look at a blank screen for a minute. But I promise I'm still here. And I am now changing my view to see the preview. And then I am going to edit shot. And I need to go to capture device 2. And then I need to change this to 59.94. And then I also, this is the preview. I also need to, whoops. I need to go to here. And zoom it in a little bit. And do this. So that you can see. Let me zoom in a little bit more. I swear this is going to be done in a second. Okay. So, not my finest work. But now you should have a whiteboard shot. And now I'm only coming in one ear, right? So, I have to fix the audio for this. This is really. So much setup time, which is really a problem. When. Left. Okay. Now, if I am over in the whiteboard, you should be able to hear me in both ears now. Okay. And I should be able to switch back and forth like this. Okay. I am set up. Okay. So, let me look for my eraser. Okay. So, this is my list. So, I think maybe what might make sense to do first is talk about persistence. So, the very first tutorial that I'm going to add to that list today is persistence. Meaning how to save data over time. Now, what I want to do before I add this. Is I want to look at one of my existing examples. Just to review in my head how I did it. Whoops. So, I'm going to the GitHub repository for the class. And everything in my brain is broken today. This is me getting back into this. I miss a week and I lose track of how everything works. Go into my API examples. Into, let's look at the spell check one. No. Is this the one I want to look at? Read file sync. Yes, that's what I want. And then save file. Okay. I don't actually need to look at this. I can add this on the fly. Okay. And, okay. So, I love seeing the chat going. And I love seeing that there are so many people here. I'm going to just switch to a particular view. So, I can see better who's there. And the camera went off. I will fix that. Okay. Okay. So, here we go. I'm going to try to pick this back up. And I'm going to start with, have this screen over. And I'm going to talk about how to save data to a database. Except I'm not really going to use a database yet. Okay. So, here we go. This will be, so, for those of you who might be new, cancel. What I do with these live streams is I have a lot of wasted time in them while I get set up and figure out what to do. And then after the live stream is over, the full thing gets archived. But I edit, I don't do this, Mathieu, who gratefully does this work really wonderfully, edits together portions of it as tutorials. Okay. So, thanks for being here, everybody. Thanks for bearing with me. I'm about, you know, at this point, like 40 minutes later than I really meant to get started. But here we are. I've got about 45 minutes left. And I'm going to just, hopefully, something nice will happen in this session and just keep going. Okay. So, I'm trying to, okay. All right. Welcome. So, this video continues the series about building your own API in Node. And in this video, what I want to do is add a very important, very key piece of functionality, which is persistence. So, right now, this particular API that I'm building in Node, if you recall, in the code, at the top of the code, just has hard-coded, essentially, a database. A database of words and their sentiment score. Rainbow 5, Unicorn 3, Doom negative 3, Gloom negative 2. So, they're in, but they're, and I can add, and I can add to it. So, I can go to a particular route and say add purple 4. And then if I go back to all, I'll see that purple is there. But as soon as I go to terminal, quit, and relaunch the server, and go back, purple is gone. So, I need some mechanism by which I can save the data forever. Whether or not I'm running the server, quitting the server, not just in memory. And the way that this is done is typically with a database. Now, a database is a big topic, and I expect that in the, what I imagine, future amount of time that I have in my life to make videos, I'll get into a lot of different facets of it. So, what do we have so far is we have just like data in memory. That's what I have so far. Quit the program, the data is lost. One quick and dirty way to save data, to have data persist over time, is simply to save to a text file. It's easy to forget that you could just have a text file as a database, right? I can have a text file that has a list of words in it. Word, comma, score, word, comma, score. And I could just save all this stuff and load that when I run the program. A way to make this even easier is to actually save this to a JSON file. JSON standing for JavaScript Object Notation. So, the stuff that's right here, did I switch back and forth? I hope I did. Was I in the right screen? Somebody in the chat, somebody would have told me if I wasn't in the right screen. Matt, you're ahead of the score. I forgot, I had my momentum, I lost. Yeah, all good. This data, if you look at this, this is JavaScript Object Notation. This syntax of having a variable full of key value pairs, that's JSON. So, I can actually, nice option is just save the data to a JSON file, and then load that JSON file every time the server starts. So, this is actually the way that I'm going to do it in this particular tutorial. But this is very limiting. First of all, if I have a massive amount of data, huge data set, this isn't going to work very well. I have to load this giant text file and save this giant text file all the time. That's not going to work very well. If I care about security, and I have private data, just having it all sitting there in a big text file, text file full of everybody's logins and passwords, that's not going to work very well. So, there are a lot of reasons why this isn't a particular great solution. But for a quick and dirty project, for understanding how things work, playing around in Node, I think this is going to be a great demonstration. But I will be making videos in the future that look at other database systems, namely one called Firebase. Firebase is something that's referred to, it's a Google product, database as service, meaning you don't have to have your own server. You're just a program and you're keeping track of stuff, and you're like, hey Firebase, can you save this for me? I'll ask for it later. And then later you come back and say, Firebase, can I have that data? So, you get an account, you sign up, you send the data, you ask for data, and it has a lot of sophisticated features. So, that's certainly one thing you can do. And then, of course, you could use a quote-unquote real database or some type of database system. There are other databases as service products, by the way, so you can find those. But you could use something like CouchDB or MongoDB or another database that I actually like, which is very simple, which is called Nedb, I think. So, these are all database systems that you can use with Node or other server-side programming frameworks. So, at some point, somebody remind me, hey, definitely I have a whole bunch of examples already for Firebase, so I intend to do that, but I'd love to look into this kind of stuff and make some examples with that as well. But in this particular video, let's look at even just what saving a JSON file gets us. Okay, so back over here, I'm going to go back to the code. And the first thing I want to do is let's just actually make that JSON file ourself. So, right here, I'm going to, in my Node project, where my server code is, I'm just going to create a new file, and I'm going to call it words.json. And in that file, instead of having this in the code, I'm just going to take this, and I'm going to comment this out, and I'm going to put this into words.json. So, here is now a JSON file with the initial data that I want for my program to start with. So, now what I want to do in the program is, instead of having var words equal the hard-coded data, I want to just load from the file. I want to do something like, you know, if I were in client-side p5 land, I would just say, like, loadJSON words.json. Right? I want just to load whatever's in that file and stick it in words. But this is not Node code. This is p5 code. So, I need a different set of syntax for that. And the package that I'm going to use, node package file, is called filesystemfs. So, if I come here to the filesystem package, I want to look for the document. Well, this is good enough for me. You can see there are lots of functions for writing a file, writefilesync. We're going to have to talk about that, writefile versus writefilesync. And what I'm looking for is really readfile. Readfile. Oh, there it is. Oh, you know what? I'm in the wrong package. I'm in the file-system package. The package I want to be in is actually just called fs. I don't know if it's the same thing or not. Oh, well, time out. Pause. This is interesting to me. Is it no longer called fs? That's what I've always used. Is it called filesystem now? File extend node fs origin. Like, what's going on here? Does somebody know what I'm talking about? This is a different, let me look. Node fs package. This is going to be edited out. This is where I want to be. I was in the wrong documentation page. Let me back up and start over. Because I don't want to use a separate, yeah, yeah, yeah, yeah. I want the official node.js. So I don't know where to go back to, but I think this can get stitched back together. Thank you, everyone in the chat. I've got it now. So I'm going to look for, okay. I think this can get spliced back in somehow. So to read and write to files, I need to look into, oh, right. I was saying I can't use this p5.js code. So how do I do that in node? Well, what I need to use is the fs module. So fs node, node. I'm just going to Google fs and node. And here I'm going to get the documentation for the file system API, which is built in part of node. It's not an extra thing I have to install. So this is the documentation for it. There's a lot, a lot of functions. What I'm looking for is one called read file and right here. So you can see, first of all, there's fs.readfile and fs.readfilesync. So why would I use one versus the other? This is something I definitely want to talk about. But let's just at first, and actually I'm going to start with using readfilesync. So what I'm going to do is I'm going to say var fs equals require fs. I think that's right. This is like importing the file system package. It's built in as part of node. I don't have to install it, but I do have to reference it in an import or require statement. And then I want to say words equals fs.readfilesync words.json. And let's just see. And then I'm going to say console.log words. Let's see what's happening here. Ah, okay. So it runs and look, I read the file. There's the file. Perfect. There's my contents. What is that? So one thing you have to realize is the node file system package is just reading the raw data files and writing the raw data out. It doesn't know, oh, I want this to be like JSON and all of that. So if I have that raw data from the file, but I actually want it to be JavaScript and JavaScript object, I need to parse it. And there's a quick and easy way of doing that. So actually what I want to do is I'm going to say, I'm just going to say var data equals that. And then I'm going to say var words equals JSON parse data. So this is something you're going to see once I'm using local files. When I want to read a file, I need to interpret it as JSON. When I have a JavaScript, I need to interpret it as a JavaScript object before I can use it. When I have a JavaScript object and I want to save it to the file, I need to convert it to just plain old text and then save it to the file. So let's look how that works now. And you can see, there we go. So now my server is reading that stuff. So we've got step one in that everything should work as it did before. All, and I could add something, but I'm still going to have the problem. As soon as I quit the server and relaunch it, anything that I've added will be gone. So how do I now have persistence? Where in my code do I want to save data to the file itself? Well, I want to do that any time I add something new to this list. And if I go back to the server program, the only time I add something new to the list is right here under add words, add word. So this is where I want to save data. Now this brings me to another important point, which I glossed over, which I will come over here to discuss for a second. Sync versus no sync. So there are both read file sync. That's a function as part of the node file system package. And there is also read file without the word sync. There's also write file sync and just write file. What's the difference? The difference is this is synchronous, also known as like a blocking line of code. Meaning, if I come back here, if I'm using the sync function, the next line of code will not execute until that action has been finished. And in this case, that's what I want. When the server starts up, I don't want to do anything, actually, until the data has been read. So I want to use the synchronous version, so I load the data, and it makes, I don't have to have a callback, and it makes writing the code a little bit simpler. However, if I'm going to perform an action where I'm reading and writing to files while a user is making an API request, I don't want to use the sync method because that will actually lock up the server while it's waiting to do this operation. I want to use the non-sync, asynchronous version, so a callback will happen and the server can still listen for other connections and that type of thing. So this is now a moment where right here, under add word, I want to write the data back to the file, but asynchronously. So let me show you how that works. So first of all, this is a little error handling that we built in last time, so I don't want to write the data if a score wasn't given. So I want to write the data right here. So I can say now, write file words. Let's look at the documentation. Let's look for write file. So it looks like write file, I need to give it the file name and the data, and there's some other options and that sort of thing. But I'm going to do it simply. I need to say write to words.json and now the data, which is words, and then a callback, finished, I'll call it. And then I can say function finished. Maybe it gets an error or something. I don't actually know. I should look this up. I'm just going to say console log all set. So let's look at this now and see what happens. Now, first of all, I've made a big mistake already, but let's just see what happens anyway, even with my mistake. Probably going to get an error or something like that. So the server has restarted. It's listening and waiting. Let's go to the add route, and I'm going to say I want to add the word purple and the score three. Now, write file is not defined. Okay, oops, silly me. I actually just made a mistake in my code where I need to say fs. I need to refer to that file system module, that package, fs.writefile. That's not the error I was expecting. The server should restart. Okay, it has. Hit refresh. Thank you for your word, but let's look at, ah, crashed. Unexpected token, blah, blah, blah, object, object. It couldn't figure out how to write that to a file, right? Because once again, just as if I'm reading data from a file, I'm getting the raw bytes, I need to parse it as a JavaScript object before I can use it. Now what I need to do is I need to turn it into text-based data before I write it to the file. And the way to do that, I can say just var data equals json. The opposite of parse or the inverse is stringify. So I can say stringify words and then write that data to the file. So now that I've done that, now one thing I want to do actually is I want to stop using NodeMon because NodeMon restarts the server every time, oops, I have, oops, what's going on here? Error, undefined, one, unexpected token, json. Oh, you know what? I messed up the file. So this is what I wrote to the file because when I made my mistake. So that's why it's not working. So the reason why I don't want to use NodeMon right now is because every time I rewrite that file, it thinks like, oh, something changed, it's going to restart the server, which will mess things up. So right now I just want to manually stop and start the server myself to make sure things are good. So, okay, so now the server starts, it reads the data from the file. Then what I'm going to do here is I'm going to now go to this route again and I'm going to hit enter. Thank you for your word. I'm going to go back and I'm going to look and look. It's there. Oh, but I lost the formatting. Like my json file is all just one long thing. So one thing that's – I mean this is sort of like a small point and sometimes it could matter in various scenarios, but since we're talking about it, I might as well talk about it. This stringify function takes the JavaScript object and kind of makes it a string with as few characters as possible. So no white space to make it kind of human readable. But I can use some other arguments and I can add like – I forget why you put null there to look at the documentation for stringify, but two meaning that I want to use two spaces for an indent. So if I do this and I restart the server – and by the way, purple is already there, so purple is now there forever. And I can go to pink and add the number six. Thank you for your word. And if I go back and I look at that, we can see there we go. So every time I go to that route, it rewrites the entire file with the current list of words. Every time I quit the server and start the server back up, it reads the list of words. So this is the full round trip. There's lots of inefficiencies and issues again with scalability and privacy, but this works for a simple project where you just want to save a high score list or a table of words in their sentiment score. You can do something like this. I'm sure you can imagine some other scenarios where just this basic idea is plenty good enough. Let me say another few things about this though before I move to the end of this video. One is that I've kind of made a little bit of a mistake here, which is that even if something goes wrong here, I still send the reply like, thank you for your word. So really probably I should wait to send a reply to the client who added this word until that file has finished being written. So I would say it probably makes sense to put that in here, and I'm going to send the reply actually. And because I had this error checking, I have to send the reply up here. I can think about if there's a better way, but I'm going to have if there's no score, I send back a message, score is required. And if it gets the data, if it gets the word, adds it, writes the file, and all that is successful, then I'm going to say, and you know what I think is useful in an API, is for a word to actually, for an API to just send you back the data that you've sent it, and then I could say something like status success. So in other words, sometimes when you're making an API request or you're adding something, you're sending some data to an API, and you're doing that like many, many times, as a client, when you get a reply back, you need to match it with which one you sent. So if you get some information back that you can match, that can often be helpful. So even though this is redundant, and I don't personally need this information, I think it's useful to add. So I did sort of a very awkward thing where my variables all have the same name, but this will actually, should work. So let's restart the server one more time. We can see I've got all the words that I added before, and now if I go back and I say add flower, 7, and I hit enter, success. The word flower was added, and if I go to all, we can see flower is in there, pink is in there, purple is in there, and I can even restart the server. I restart the server, and there it all is again. So this is the full round trip of how to receive from a get request through a route data from a user, save that data to a file, and have the server always keep track of that data. So I've still got more to do in terms of building this API, which is actually like get some text and produce a sentiment score. I need to look at how would I build a client, a front end, that would actually interface and interact with the API, but at least now we've seen a little bit about saving data. Thanks for watching. Okay. Did that make sense, everybody? We've got one little extra tutorial in. I have a half an hour. I think what I want to do in the next one is make a client for it, because that's going to be necessary once we look at doing a post. Electron tutorial, that is a great idea. I would love to do an electron tutorial. If only I had so much more time. Okay. So let me just keep moving here. It's a little bit warm in here with the light on. So what I'm going to do now, in a way, is kind of like the easy part for me at least. And I'm going to go into here, and we're going to start working on the client, the front end. So I'm going to use p5 for this, and I'm thinking about the best way to do this. So let me go to desktop, A to Z. I'm sure I have some. Actually, I'm going to do the ridiculous thing that I always do, which is p5.js.org, download, p5.js complete. I'm going to do this. I want to get to the AFIN coding challenge today. Maybe if I can come back later and do it. I'm tempted to just do the coding challenge I had envisioned today instead, because that, in a way, could be the front end. Okay, fine. I'm going to do the interface. Yes, I can use p5 manager, Tutuber suggests. I'm kind of like a terrible – I have very bad habits, but I can't help them sometimes. Okay. Okay, so here we go. I am going to join Pranger. So how did I do? Okay. Okay, so this is probably going to be the last short little tutorial where I'm just going to add a little front end for this, and I still have a bunch of pieces to finish up with this, which if there's time actually later, I will in fact be able to – after there's a class that starts here at 3 right in the room next to me. So noise-wise, I can't be talking and broadcasting very loudly. But as soon as that class ends, I'm going to have an interview with Jane that I mentioned earlier, and then also if there's a little extra time, I might do one more tutorial about this as well. Okay, here we go. Let me cycle the cameras. Okay. Hello. Okay, so now what I would like to do in this video is actually add a front end client to this particular API. Now, there's a kind of question in my mind just floating around here, which is like, whoa, why am I doing any of this? And so on the one hand, I might be making kind of a build-your-own API in Node just for one person, and that's for myself. Like I might want to make an API as a way of storing data and communicating and doing server-side stuff for my particular front end. I also might want to make an API that is open for other clients to be able to connect to, and that's something that I've got to get to in this list. So at some point I'll show you. It's actually very easy to open up your API to other servers to make requests using a Node package called cores, but I'll come back to that. For right now, I'm almost thinking of this as just my own little project, and some of my project I need server-side programming, and some of my project I need client-side programming, but I need those two things to talk to each other. So the first thing that I want, if you recall, one of the pieces of this program that we've written actually uses Express's ability to host static files, and all the static files are in this directory called website. But I called it website just to call it something, but often it's called public, or you can call it whatever you want, unicorn, whatever you want to call it. You have a folder with files that you want to serve, and I have right in there, I have this index.html file, and all it says in it is, hello. So if I go back to the browser and I go to the root page, I see, hello. And so what I want to do now is I'm going to grab from my desktop a p5 sketch. So it has an index.html file, some JavaScript code, and the libraries that I want to use, and I'm going to actually go into this particular API example that I'm making, and I'm going to put that all in here, and I'm going to replace. So now if I hit refresh, one thing is I don't have to restart the server, by the way. The server is going to be able to just serve up those files as they change, and we can see now anything, and I go over here and I can add some code. I can say, you know, maybe no canvas. I don't want a canvas right now. And I can say console.log running. Is your refrigerator running? You better go and catch it. And I can see, aha. So that sketch is working. So now how do I do something to access the data that's part of this API? So one thing is actually, never mind that. Let me actually add a canvas. And what I'm going to do is I'm going to say create canvas, and I'm going to say 400, 400, and background 51, which is my background color of choice, and we can see I now have a canvas. It's huge. No, no, no, no. Stay large over there and small over here. Okay, so now I have this canvas, and what I want to do is I now want to say load JSON slash all. And I don't even know if I need that slash. Look at this. If you've ever done anything with p5 or jQuery where you're loading something from an API, openweathermap.org slash API slash city slash New York, what I'm doing here is I'm querying the API, but rather than the full URL, the API is running on the same server that's hosting this JavaScript sketch. So I could just say slash all, or I could say slash search slash rainbow. I can go to any of the routes simply from the load JSON function. So what I want to do is do slash all, and I'm going to then have a callback for when I've gotten the data called got data, and I'm going to write that function, and the data comes in as an argument to that function, and just to see that it's working, I'm going to say console.log data. So let's run this again, and we can see there it is. I now have accessed in my client-side code all the data that's running in the server. And one thing that I'll do here just out of curiosity, so I'm going to get rid of this slash. I think it works with absolute or relative paths, so you can see that works either way. Okay, now what could I do? Let's say I want to iterate all over these. There's kind of a trick. This is an object, so there's not an easy way to iterate over an object as if it's an array, although there are plenty of ways to do that. A way that I like to do it is I can say var keys equals object keys data, and I'm going to just show you what that gives you, console.log keys. What you can see is it gives you an array with just the keys in that object. So you can see this is the full object, but now I have an array with just the keys, and that's an easy thing for me to iterate over. So I can do something like for var i equals 0, and I know I could do a for each or whatever. Everybody always complains, but I just have an old-world style of programming. I like my for loops like this. And I'm going to say key equals keys index i. I'm going to say word, actually, and score equals data index word. And then I could say var x equals random width, and var y equals random height, and fill 255, and text word at x and y. And let's see what I get now. If we run this, we can see. And let's make it bigger. Text size 64. And you can see, there we go. So obviously I could... I'm seeing now all the words that are in the database kind of visualized in the canvas. And I could, of course, like color them. I could think about visualizing in a thoughtful way. I could make their font size and their color based on their sentiment score. But I'm just showing you that I can access a particular route and then visualize that route, visualize the results of the data that I'm getting through that route in a canvas. But ultimately, what I might want to do here, actually, even more importantly, is I might want to add input id equals word. And then input id equals score. So let's look at what that looks like. And I'm going to wrap that in a paragraph. And I'm going to say word. And I'm going to put a line break. And I'm going to say score and slash p. So now we can see on my web page, and something's driving me a little bit crazy here, which is this default styling. We can see here that I now have this little kind of basic form. It's barely a form, but it's like I made a little paragraph that has word and then a text input box, score, and a text input box. And I just put that in the HTML directly. And then I probably also maybe want to add some sort of button, submit button, and I can give that an id also, id equals submit. So what I'm doing here is I've made a little interface that has a place for me to type a word and a score, and I'm able to hit submit. So why am I doing this? Because what I want is the moment I click submit, I want to send what is in those two text fields to the route add. I need to go to, if I go right now to add sunflower43, we can see that that was added. And now if I go back to here, we're going to see that sunflower shows up there. I don't really like what I've done here with this visualization because it's sort of hard to see what's going on. So I'm going to make that a little bit smaller, and let's just make it a... I'm sorry, I'm going a little crazy here, but just bear with me for a second unnecessarily. There we go. So now I can see that sunflower was added there, but I added it manually only by going to the route in the address bar. But that's not really how anybody normally interacts with an API. I don't know, maybe I do that quite normally. So now what I need to do is I need to handle that submit button. So in p5, I can gain access to that through the select function. So this is me using... submit, sorry, this should say submit. This is me selecting the DOM element with the ID submit, and that button has the ID submit. And now I have it in a variable, and I can now attach an event, like whenever the mouse is clicked on that button, to, I can say submit word. And now I can write a function, submit word, where I get the word from the word element, and I can just say.value. I can get the score from the score element's value. So select looks for the text input box, word, and then score, and then the value function gives me the contents of what's in there. So just to see that this is doing what I want it to do, I'm going to say console.log word score. So let's go back. So I'm not submitting it yet, but let's go back, and I'm going to hit refresh. Oh, select is not defined. Guess what? These functions are part of the p5 DOM library, so I need to make sure I am referencing the p5 DOM library in my HTML, which now I am, p5.dom.js. And so now I can go back and hit refresh. And now I should be able to type in cherry blossom 2 and hit submit, and we can see that I'm able to access those two values. And now what do I want to do? All I need to do is go to load JSON. What's the route? Add slash plus word plus a slash plus a score. So I can dynamically create this route in my code based on what the user put into those two text boxes. So now I want to – now this is a little bit weird, and I'm going to get to this in a future video where I talk about get versus post. I'm actually doing something that's sort of against the traditional conventions. I'm using load JSON, which is a get request, to actually send data, the word and the score, to the server, but I'm really doing that out of convenience because it kind of works and it's easy and it's simple. You'll see in a lot of other scenarios if you want to send data to the server, images, large data, private data, you're going to need to use something called a post, which cannot be done through load JSON, but I'll get to that in a future video. And then I'm going to just add a function called finished as the callback. And then I can say function finished data console.log data. So I just want to see that it came back. So I'm going to send that data and see that it came back. And then I'm going to – so I'm going to hit refresh, and I'm going to add a blueberry, 10, and I'm going to hit submit, and we can see that this was sent to the database. Now, if I hit refresh again, we should see that blueberry is there. Why not, though, however, once it's done, ask the database for all the words again to redraw what's in there. So here, this is what I did to redraw everything. I could actually put this in a function. I could call this function draw data. And so when the program first starts, I want to draw the data. And then every time I submit a word and it's done, I also want to draw the data again. So now, if I do this, I can say, hey, let me add the word mango and give it a score of 3 and hit submit. And now, ooh, look at that. One thing I forgot in my draw data function was to clear the background because it drew it again over everything. So I'm going to take this background function and put it right here in the got data function, and I'll hit refresh again. And now we can see everything's in there, mango, flower, blueberry, sunflower, all these things. What's another fruit that is delicious? A raspberry. I only know how to spell raspberry now because of the raspberry pie, and that's like the password or something. Do you want to type it in all the time? Score 4, and I'm going to hit submit. And there we go. It runs, and we see the result. So now I have an interface where I can sit here and submit new words to the database, and I also have this sort of goofy front end, which just shows me a very poor visualization of all the words that are currently in this database. And if I go look in the server code, I should be able to see, hey, look at this. This words.json file, it has everything. So even if I now quit and restart the server and go here again, I'm still going to see all of those words. So now we have an API with routes that accept parameters. We have a persistence saving all the data to a JSON file, and now we have even an interface that allows us to interact with the API in one way. And so the next video that I'm going to do is look at how do I submit data to a server using a post and why would I need to use a post versus a get. What's a get? What's a post? So that's what I'm going to look at in the next video that I'll make, and then by the end I'll wrap it up and actually make this thing do some sort of sentiment analysis and give a score back when you post a large body of text to it. Okay, thanks for watching. I look forward to hearing what you think in the comments and all that sort of stuff. Okay, so that, I have about five or ten minutes left, so I'm not going to try to do the next piece of this. If I have time later today when I come back after the class is finished, I might try to do that. But I do have about five or ten minutes. If anyone wants to ask a short little question in the chat, I'm happy to answer them if I can. I see that there's been some, so Ariane writes, this is way beyond my head. So, yeah, so one thing that is tricky about what I'm doing, which I've definitely gotten this comment before, which is that I've heard from people, oh, I went to your YouTube channel, I found it, and it's all, it's too advanced for me, it's for advanced programmers. And really my goal is for this to be for, I would like my channel to be a place that complete and total beginners who have never done any coding before could come and learn and start to make stuff. The tricky thing is that, the tricky thing about this is that it's hard to find where to begin, and I need to figure out a better way of doing this. Maybe if I can eventually get my act together and get a title and a new logo and a new website. But one thing I will just mention is that if you're interested in web programming, JavaScript, HTML, CSS, at least through the lens of P5.js, I also get the other frequent comment I get is, why are you using this P5.js thing? I don't want to learn that. Well, sorry, I guess. But it's a platform that I'm invested in personally and also through the work that I do, and so I'm interested in making tutorials with it and making it better. So, but by no means do I completely restrict myself to that, but these tutorials here, one through six introduction, these are for complete beginners who have never done anything before. And then also this set of tutorials down here, learning processing, this is for complete and total beginners looking at learning a processing, which is a Java-based platform for doing different kind of programming things. I don't know enough about SC, SS, and SAS to answer that question. And I'll also mention here if you're interested in Git and GitHub, this is a playlist that is also for complete and total beginners if you've never used it before. And most of the other playlists, particular programming from A to Z, and I'm thinking of this WebSockets one, this Twitter one, nature of code, all assume kind of what's in those two beginner playlists. So if anybody has any ideas about how I can make this stuff more accessible and easy, easier for people to find or get started, and if you have a friend who's a beginner, send them my way. I want to see how it works for them. Because most of the core audience I'm finding at least tuning into the live stream are people who already know about programming. I saw a great question. It's two questions. One is, where is it? Where is it? I'm scrolling back. Oh, code it in a full IDE, Eclipse. So I really want to make a tutorial about how to make a processing library. And to do that, you need to use Eclipse. And also just program with processing in Eclipse. It's on my list. Please keep reminding me about that. I did an entire tutorial. I was asking about Markov chains. So I did a tutorial about Markov chains. It related to text-based Markov chains. And that's part of the A to Z playlist. And I believe it is, boy, I guess session 5? No, session 6. So if you go here to session 6, there are a set of videos about Ngram's Markov chains. And I do a couple different challenges or experiments with them. I don't know what's in these, but I did make them. Jason asks, are there any benefits to using JSON files versus something like Mongo? Now this is just what I think at this moment right now. But I would say that the advantage to using JSON file versus something like Mongo is you could just get started doing it really quickly and easily. So I have a little bit of data. I just want to save it. I just want to load it. I'm done in two seconds with just a few lines of code in the file system. A Mongo database is certainly going to have so much more robust and sophisticated functionality. Databases can be relational. They can be really fast to do sorting and searching through them. But you're going to have to spend a lot of time learning how the database works, how the particular node package for using a MongoDB works. So for a larger scale project and for a lot of time, but for something you're just making because you're making some quick game experiment and you have this other Arduino hooked over here and it's talking to a node server which is hooked up to a sensor. You just want to save a bunch of readings to it. Using a text file, a JSON file, I think is a great way of doing that. Do you ever plan on making games in p5.js or processing? So yes, this is a question from Minor Scotty. I do plan on doing that. I have a few. I've been doing this kind of A to Z course, so I'm quite behind on my mental list of what I would like to do. But if I go to my playlists and look for coding challenges. Where is that one? Oh, I'm logged in here. So you're seeing all my private. This is the video that I'm going to launch as soon as I turn this off, which is a guest tutorial from Tiga that I mentioned. I don't know why I'm not finding the coding challenges all of a sudden. Here they are. So this particular video, this particular playlist is where I will typically, if I'm going to do a coding challenge to implement a particular game, you'll find it. So I did Space Invaders 1 and the snake game for whatever reason. I don't understand. Wherever that is, that is my most watched video, which gives me sort of an inclination to do some more of them. And I've had requests for Frogger and there was another one. Oh, I did Flappy Bird also. I did a version where you clap too. I can certainly consider more videos about Markov chains. People are asking about Python. Python is a really amazing programming language to work with, in particular because of the access that you have to so many Python packages for data, machine learning, data science, text, natural language. It's not really an environment that I personally do a lot of work with, which is a bit of a fault of mine, but I do think it's an opportunity for me to look at how a lot of these kinds of algorithms and projects that are often made with Python work and can be programmed in other contexts like processing and JavaScript. But I certainly would, if you're interested in the kind of topics that I do in this channel, learning about Python, and there's a YouTube channel, Seraj's YouTube channel, which maybe somebody can post in the chat. He does a lot of data science and machine learning videos with Python. And I am planning to do some stuff on machine learning in the spring. Android development is not something on my list. It's not something I know a lot about, but I would love to have a guest come in and do some guest Android development tutorials for sure. Okay, so I think I am wrapping up for today. I'm sorry, this was a one-hour and five-minute livestream, which is much shorter than they usually are, so I apologize for that shortness. I am going to be back live in about three and a half hours with Jane Friedhoff, I mentioned, who's a game developer and artist. And she's going to just show a project, and you can ask her questions about it. But I might not be here, unfortunately, again next week due to the Thanksgiving holiday. So next week's schedule is all crazy, and things are a bit more tight now with the school schedule here and the NYU schedule that I have at NYU. But hopefully by the time I get to January, I'll be back up and running with full, weekly, longer livestreams. But I am really hoping to finish all the A to Z materials this fall. So hopefully that's going to happen. So thank you. It's nice to see all these friendly messages in the chat. And I will see you. Please come back. Everything I do will be archived, so you'll be able to watch the video interview with Jane any time later. But if you're around, not in Europe in a sleep, or some other country where it's the middle of the night in three or four hours, come back. And I'll post on Twitter time-wise, and I'll also try to make the YouTube stream page show the time until that's happening as well. Okay? Thanks, everybody. And last thing I'll say, because Robert Perez asks, is when are my normal livestreams? It was every Tuesday in the afternoon, but it's been a little haphazard. If you go to codingrainbow.com, I actually didn't send out an email notice for today because I've just been so... But I post to Twitter, and I also, if you sign up for this email list, you can...if you sign up for this email list, you can... I do try to send out email announcements about the schedule, and sometimes I just miss it. But the other...it's always archived, and also I'll just mention, too, subscribe, and if you're interested, there is an opportunity... I'm using a site called Patreon, which is a crowdfunding site. If you want to join that and join a Slack channel where we discuss a lot of the videos and stuff. Okay. Thanks, everybody. Oh, I'm going to play you out with my video trailer, since it's the edited one because of my legal trademark issues. But I'll play that for you at the end, since I didn't play it at the beginning, and then I'll be shutting the stream off. ♪ Did you think that learning coding would be really rough? Throw your hands up in the air and say, enough's enough. Do you want to learn to code and make some awesome stuff? Learn that anyone can when you're coding with Dan on... ♪ ♪ ♪ Write the colors of code. You can follow the road, too. ♪ ♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:54.184892Z",
  "started_at": "2023-09-26T21:21:03.846587Z",
  "completed_at": "2023-09-26T21:36:25.952377Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=HRBS_OtQupM",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 922.10579
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/eclwzcbbx44ynze3quziw4w3ra/cancel",
    "get": "https://api.replicate.com/v1/predictions/eclwzcbbx44ynze3quziw4w3ra"
  }
}