{
  "id": "w3qa4yzbo7rag2y6zbxp5c7xke",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/QEzRxnuaZCk.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/93186 [00:00<?, ?frames/s]\n  3%|▎         | 2940/93186 [00:08<04:15, 352.96frames/s]\n  6%|▋         | 5912/93186 [00:15<03:40, 395.49frames/s]\n  9%|▉         | 8644/93186 [00:19<02:59, 472.04frames/s]\n 12%|█▏        | 11540/93186 [00:26<02:58, 456.88frames/s]\n 15%|█▌        | 14220/93186 [00:33<03:07, 420.20frames/s]\n 18%|█▊        | 16952/93186 [00:41<03:14, 392.21frames/s]\n 21%|██▏       | 19844/93186 [00:49<03:13, 379.52frames/s]\n 24%|██▍       | 22728/93186 [00:58<03:16, 358.46frames/s]\n 28%|██▊       | 25716/93186 [01:07<03:10, 354.07frames/s]\n 31%|███       | 28624/93186 [01:14<02:53, 373.16frames/s]\n 34%|███▍      | 31552/93186 [01:21<02:41, 382.24frames/s]\n 37%|███▋      | 34444/93186 [01:29<02:36, 374.38frames/s]\n 40%|███▉      | 37252/93186 [01:38<02:37, 354.08frames/s]\n 43%|████▎     | 40252/93186 [01:46<02:29, 355.13frames/s]\n 46%|████▌     | 43012/93186 [01:56<02:30, 332.55frames/s]\n 49%|████▉     | 45912/93186 [02:05<02:21, 332.94frames/s]\n 52%|█████▏    | 48848/93186 [02:14<02:15, 326.86frames/s]\n 55%|█████▌    | 51682/93186 [02:21<02:01, 342.17frames/s]\n 58%|█████▊    | 54470/93186 [02:27<01:43, 374.18frames/s]\n 61%|██████▏   | 57226/93186 [02:34<01:34, 381.67frames/s]\n 64%|██████▍   | 60010/93186 [02:40<01:23, 397.16frames/s]\n 68%|██████▊   | 62918/93186 [02:46<01:11, 423.32frames/s]\n 71%|███████   | 65884/93186 [02:55<01:10, 389.81frames/s]\n 74%|███████▍  | 68882/93186 [03:04<01:05, 368.28frames/s]\n 77%|███████▋  | 71718/93186 [03:10<00:53, 401.72frames/s]\n 80%|███████▉  | 74498/93186 [03:16<00:46, 403.47frames/s]\n 83%|████████▎ | 77494/93186 [03:24<00:38, 407.12frames/s]\n 86%|████████▋ | 80386/93186 [03:32<00:33, 381.28frames/s]\n 89%|████████▉ | 83074/93186 [03:40<00:27, 367.21frames/s]\n 92%|█████████▏| 85978/93186 [03:48<00:19, 367.97frames/s]\n 95%|█████████▌| 88770/93186 [03:55<00:11, 377.69frames/s]\n 98%|█████████▊| 91598/93186 [04:04<00:04, 365.45frames/s]\n 99%|█████████▉| 92234/93186 [04:19<00:04, 213.14frames/s]\n99%|█████████▉| 92234/93186 [04:25<00:02, 347.35frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 1.08,
        "id": 0,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hi, everyone.",
        "tokens": [
          50364,
          2421,
          11,
          1518,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 3.42,
        "id": 1,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 1.08,
        "temperature": 0,
        "text": " Welcome to another ml5.js video.",
        "tokens": [
          50418,
          4027,
          281,
          1071,
          23271,
          20,
          13,
          25530,
          960,
          13,
          50535
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 6.6000000000000005,
        "id": 2,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 3.42,
        "temperature": 0,
        "text": " In this video, I am going to talk about the object",
        "tokens": [
          50535,
          682,
          341,
          960,
          11,
          286,
          669,
          516,
          281,
          751,
          466,
          264,
          2657,
          50694
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 11.74,
        "id": 3,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 6.6000000000000005,
        "temperature": 0,
        "text": " detector in ml5, which is a new feature as of 0.5.0.",
        "tokens": [
          50694,
          25712,
          294,
          23271,
          20,
          11,
          597,
          307,
          257,
          777,
          4111,
          382,
          295,
          1958,
          13,
          20,
          13,
          15,
          13,
          50951
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 14.48,
        "id": 4,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 11.74,
        "temperature": 0,
        "text": " So you want to make sure you are on at least that version",
        "tokens": [
          50951,
          407,
          291,
          528,
          281,
          652,
          988,
          291,
          366,
          322,
          412,
          1935,
          300,
          3037,
          51088
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 17.16,
        "id": 5,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 14.48,
        "temperature": 0,
        "text": " before you get started and try the same code that I'm",
        "tokens": [
          51088,
          949,
          291,
          483,
          1409,
          293,
          853,
          264,
          912,
          3089,
          300,
          286,
          478,
          51222
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 18.6,
        "id": 6,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 17.16,
        "temperature": 0,
        "text": " about to demonstrate to you.",
        "tokens": [
          51222,
          466,
          281,
          11698,
          281,
          291,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 20.88,
        "id": 7,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 18.6,
        "temperature": 0,
        "text": " What do I mean by object detection?",
        "tokens": [
          51294,
          708,
          360,
          286,
          914,
          538,
          2657,
          17784,
          30,
          51408
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 27.2,
        "id": 8,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 20.88,
        "temperature": 0,
        "text": " So far, I have covered image classification,",
        "tokens": [
          51408,
          407,
          1400,
          11,
          286,
          362,
          5343,
          3256,
          21538,
          11,
          51724
        ]
      },
      {
        "avg_logprob": -0.20506583141679524,
        "compression_ratio": 1.6244897959183673,
        "end": 29.400000000000002,
        "id": 9,
        "no_speech_prob": 0.0024334469344466925,
        "seek": 0,
        "start": 27.2,
        "temperature": 0,
        "text": " meaning we have an image.",
        "tokens": [
          51724,
          3620,
          321,
          362,
          364,
          3256,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 33,
        "id": 10,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 29.4,
        "temperature": 0,
        "text": " Maybe it has a cat in it.",
        "tokens": [
          50364,
          2704,
          309,
          575,
          257,
          3857,
          294,
          309,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 36.08,
        "id": 11,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 33,
        "temperature": 0,
        "text": " And when that image is sent into the machine learning model,",
        "tokens": [
          50544,
          400,
          562,
          300,
          3256,
          307,
          2279,
          666,
          264,
          3479,
          2539,
          2316,
          11,
          50698
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 37.68,
        "id": 12,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 36.08,
        "temperature": 0,
        "text": " in the case of the previous examples,",
        "tokens": [
          50698,
          294,
          264,
          1389,
          295,
          264,
          3894,
          5110,
          11,
          50778
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 42.08,
        "id": 13,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 37.68,
        "temperature": 0,
        "text": " a model called MobileNet, I get back a list of labels",
        "tokens": [
          50778,
          257,
          2316,
          1219,
          22625,
          31890,
          11,
          286,
          483,
          646,
          257,
          1329,
          295,
          16949,
          50998
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 43.2,
        "id": 14,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 42.08,
        "temperature": 0,
        "text": " and confidence scores.",
        "tokens": [
          50998,
          293,
          6687,
          13444,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 45.04,
        "id": 15,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 43.2,
        "temperature": 0,
        "text": " And most likely in this case, I would",
        "tokens": [
          51054,
          400,
          881,
          3700,
          294,
          341,
          1389,
          11,
          286,
          576,
          51146
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 48.32,
        "id": 16,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 45.04,
        "temperature": 0,
        "text": " get the label cat with hopefully a confidence",
        "tokens": [
          51146,
          483,
          264,
          7645,
          3857,
          365,
          4696,
          257,
          6687,
          51310
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 50.86,
        "id": 17,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 48.32,
        "temperature": 0,
        "text": " score of something like 95%.",
        "tokens": [
          51310,
          6175,
          295,
          746,
          411,
          13420,
          6856,
          51437
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 52.28,
        "id": 18,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 50.86,
        "temperature": 0,
        "text": " There might be some other guesses",
        "tokens": [
          51437,
          821,
          1062,
          312,
          512,
          661,
          42703,
          51508
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 55.44,
        "id": 19,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 52.28,
        "temperature": 0,
        "text": " with lower confidence scores, but ultimately, the goal",
        "tokens": [
          51508,
          365,
          3126,
          6687,
          13444,
          11,
          457,
          6284,
          11,
          264,
          3387,
          51666
        ]
      },
      {
        "avg_logprob": -0.21009522777492717,
        "compression_ratio": 1.700374531835206,
        "end": 59.12,
        "id": 20,
        "no_speech_prob": 0.000016187119399546646,
        "seek": 2940,
        "start": 55.44,
        "temperature": 0,
        "text": " is to have a single classification, a single label",
        "tokens": [
          51666,
          307,
          281,
          362,
          257,
          2167,
          21538,
          11,
          257,
          2167,
          7645,
          51850
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 61.76,
        "id": 21,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 59.32,
        "temperature": 0,
        "text": " come out and be assigned as the result",
        "tokens": [
          50374,
          808,
          484,
          293,
          312,
          13279,
          382,
          264,
          1874,
          50496
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 64,
        "id": 22,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 61.76,
        "temperature": 0,
        "text": " of the prediction of this image.",
        "tokens": [
          50496,
          295,
          264,
          17630,
          295,
          341,
          3256,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 69.39999999999999,
        "id": 23,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 64,
        "temperature": 0,
        "text": " Now, what happens in the case of object detection?",
        "tokens": [
          50608,
          823,
          11,
          437,
          2314,
          294,
          264,
          1389,
          295,
          2657,
          17784,
          30,
          50878
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 71.36,
        "id": 24,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 69.39999999999999,
        "temperature": 0,
        "text": " Let's say I have this same image.",
        "tokens": [
          50878,
          961,
          311,
          584,
          286,
          362,
          341,
          912,
          3256,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 77.47999999999999,
        "id": 25,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 73.96,
        "temperature": 0,
        "text": " An object detection model will not only",
        "tokens": [
          51106,
          1107,
          2657,
          17784,
          2316,
          486,
          406,
          787,
          51282
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 81.75999999999999,
        "id": 26,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 77.47999999999999,
        "temperature": 0,
        "text": " label something in the image, but give a bounding box",
        "tokens": [
          51282,
          7645,
          746,
          294,
          264,
          3256,
          11,
          457,
          976,
          257,
          5472,
          278,
          2424,
          51496
        ]
      },
      {
        "avg_logprob": -0.2511028051376343,
        "compression_ratio": 1.5966850828729282,
        "end": 86.44,
        "id": 27,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 5912,
        "start": 81.75999999999999,
        "temperature": 0,
        "text": " as to where that object it detects is.",
        "tokens": [
          51496,
          382,
          281,
          689,
          300,
          2657,
          309,
          5531,
          82,
          307,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 90.36,
        "id": 28,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 86.44,
        "temperature": 0,
        "text": " So instead of just saying this image is classified as cat,",
        "tokens": [
          50364,
          407,
          2602,
          295,
          445,
          1566,
          341,
          3256,
          307,
          20627,
          382,
          3857,
          11,
          50560
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 93.2,
        "id": 29,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 90.36,
        "temperature": 0,
        "text": " an object detection model will say in this image,",
        "tokens": [
          50560,
          364,
          2657,
          17784,
          2316,
          486,
          584,
          294,
          341,
          3256,
          11,
          50702
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 96.88,
        "id": 30,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 93.2,
        "temperature": 0,
        "text": " there is an object of type cat that",
        "tokens": [
          50702,
          456,
          307,
          364,
          2657,
          295,
          2010,
          3857,
          300,
          50886
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 101.4,
        "id": 31,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 96.88,
        "temperature": 0,
        "text": " is located at a particular xy location",
        "tokens": [
          50886,
          307,
          6870,
          412,
          257,
          1729,
          2031,
          88,
          4914,
          51112
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 105.4,
        "id": 32,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 101.4,
        "temperature": 0,
        "text": " with a particular width and a particular height.",
        "tokens": [
          51112,
          365,
          257,
          1729,
          11402,
          293,
          257,
          1729,
          6681,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 108.36,
        "id": 33,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 105.4,
        "temperature": 0,
        "text": " The model will also return a confidence score",
        "tokens": [
          51312,
          440,
          2316,
          486,
          611,
          2736,
          257,
          6687,
          6175,
          51460
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 110.16,
        "id": 34,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 108.36,
        "temperature": 0,
        "text": " for how certain it is that there is",
        "tokens": [
          51460,
          337,
          577,
          1629,
          309,
          307,
          300,
          456,
          307,
          51550
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 111.96,
        "id": 35,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 110.16,
        "temperature": 0,
        "text": " a cat at this exact location.",
        "tokens": [
          51550,
          257,
          3857,
          412,
          341,
          1900,
          4914,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.19700366973876954,
        "compression_ratio": 1.7657657657657657,
        "end": 115.4,
        "id": 36,
        "no_speech_prob": 0.000005255394626146881,
        "seek": 8644,
        "start": 111.96,
        "temperature": 0,
        "text": " So maybe that would also be something like 95%.",
        "tokens": [
          51640,
          407,
          1310,
          300,
          576,
          611,
          312,
          746,
          411,
          13420,
          6856,
          51812
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 117.48,
        "id": 37,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 115.4,
        "temperature": 0,
        "text": " And what's special about object detection,",
        "tokens": [
          50364,
          400,
          437,
          311,
          2121,
          466,
          2657,
          17784,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 121.04,
        "id": 38,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 117.48,
        "temperature": 0,
        "text": " instead of just classifying the image with one label,",
        "tokens": [
          50468,
          2602,
          295,
          445,
          1508,
          5489,
          264,
          3256,
          365,
          472,
          7645,
          11,
          50646
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 124.16000000000001,
        "id": 39,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 121.04,
        "temperature": 0,
        "text": " here, if you're detecting an object in an image,",
        "tokens": [
          50646,
          510,
          11,
          498,
          291,
          434,
          40237,
          364,
          2657,
          294,
          364,
          3256,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 126.4,
        "id": 40,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 124.16000000000001,
        "temperature": 0,
        "text": " it could detect more than one thing.",
        "tokens": [
          50802,
          309,
          727,
          5531,
          544,
          813,
          472,
          551,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 128.76,
        "id": 41,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 126.4,
        "temperature": 0,
        "text": " So maybe there's also, I don't know,",
        "tokens": [
          50914,
          407,
          1310,
          456,
          311,
          611,
          11,
          286,
          500,
          380,
          458,
          11,
          51032
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 131.48000000000002,
        "id": 42,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 128.76,
        "temperature": 0,
        "text": " I'm drawing the rest of the cat.",
        "tokens": [
          51032,
          286,
          478,
          6316,
          264,
          1472,
          295,
          264,
          3857,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 132.92000000000002,
        "id": 43,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 131.48000000000002,
        "temperature": 0,
        "text": " Maybe there's also a dog.",
        "tokens": [
          51168,
          2704,
          456,
          311,
          611,
          257,
          3000,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 137.56,
        "id": 44,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 136.48000000000002,
        "temperature": 0,
        "text": " There's my dog.",
        "tokens": [
          51418,
          821,
          311,
          452,
          3000,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 140.36,
        "id": 45,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 137.56,
        "temperature": 0,
        "text": " If the image is of a cat and a dog,",
        "tokens": [
          51472,
          759,
          264,
          3256,
          307,
          295,
          257,
          3857,
          293,
          257,
          3000,
          11,
          51612
        ]
      },
      {
        "avg_logprob": -0.2240844964981079,
        "compression_ratio": 1.665137614678899,
        "end": 142.20000000000002,
        "id": 46,
        "no_speech_prob": 0.00010071378346765414,
        "seek": 11540,
        "start": 140.36,
        "temperature": 0,
        "text": " we could get two bounding boxes.",
        "tokens": [
          51612,
          321,
          727,
          483,
          732,
          5472,
          278,
          9002,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 147.67999999999998,
        "id": 47,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 142.2,
        "temperature": 0,
        "text": " A second one with the label dog and another x, y, width,",
        "tokens": [
          50364,
          316,
          1150,
          472,
          365,
          264,
          7645,
          3000,
          293,
          1071,
          2031,
          11,
          288,
          11,
          11402,
          11,
          50638
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 150.16,
        "id": 48,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 147.67999999999998,
        "temperature": 0,
        "text": " and height for its bounding box.",
        "tokens": [
          50638,
          293,
          6681,
          337,
          1080,
          5472,
          278,
          2424,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 152.72,
        "id": 49,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 150.16,
        "temperature": 0,
        "text": " And right here on the ml5 reference page,",
        "tokens": [
          50762,
          400,
          558,
          510,
          322,
          264,
          23271,
          20,
          6408,
          3028,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 154.32,
        "id": 50,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 152.72,
        "temperature": 0,
        "text": " we can see an example of this.",
        "tokens": [
          50890,
          321,
          393,
          536,
          364,
          1365,
          295,
          341,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 155.64,
        "id": 51,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 154.32,
        "temperature": 0,
        "text": " Here's an image of a cat.",
        "tokens": [
          50970,
          1692,
          311,
          364,
          3256,
          295,
          257,
          3857,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 157.2,
        "id": 52,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 155.64,
        "temperature": 0,
        "text": " The bounding box is marked.",
        "tokens": [
          51036,
          440,
          5472,
          278,
          2424,
          307,
          12658,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 159.95999999999998,
        "id": 53,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 157.2,
        "temperature": 0,
        "text": " The label cat is indicated along with the confidence score",
        "tokens": [
          51114,
          440,
          7645,
          3857,
          307,
          16176,
          2051,
          365,
          264,
          6687,
          6175,
          51252
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 162.48,
        "id": 54,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 159.95999999999998,
        "temperature": 0,
        "text": " here of 65.41%.",
        "tokens": [
          51252,
          510,
          295,
          11624,
          13,
          17344,
          6856,
          51378
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 164.07999999999998,
        "id": 55,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 162.48,
        "temperature": 0,
        "text": " Now, this doesn't happen by magic.",
        "tokens": [
          51378,
          823,
          11,
          341,
          1177,
          380,
          1051,
          538,
          5585,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 167.12,
        "id": 56,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 164.07999999999998,
        "temperature": 0,
        "text": " This happens because there is a pre-trained model that",
        "tokens": [
          51458,
          639,
          2314,
          570,
          456,
          307,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          300,
          51610
        ]
      },
      {
        "avg_logprob": -0.23208147580506372,
        "compression_ratio": 1.622568093385214,
        "end": 169.51999999999998,
        "id": 57,
        "no_speech_prob": 0.0009547256049700081,
        "seek": 14220,
        "start": 167.12,
        "temperature": 0,
        "text": " presumably has been trained already",
        "tokens": [
          51610,
          26742,
          575,
          668,
          8895,
          1217,
          51730
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 173.96,
        "id": 58,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 170.24,
        "temperature": 0,
        "text": " many images of cats and dogs with those bounding boxes",
        "tokens": [
          50400,
          867,
          5267,
          295,
          11111,
          293,
          7197,
          365,
          729,
          5472,
          278,
          9002,
          50586
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 175.4,
        "id": 59,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 173.96,
        "temperature": 0,
        "text": " marked and labeled.",
        "tokens": [
          50586,
          12658,
          293,
          21335,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 178.60000000000002,
        "id": 60,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 175.4,
        "temperature": 0,
        "text": " How does a data set like that even exist?",
        "tokens": [
          50658,
          1012,
          775,
          257,
          1412,
          992,
          411,
          300,
          754,
          2514,
          30,
          50818
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 182.52,
        "id": 61,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 178.60000000000002,
        "temperature": 0,
        "text": " Something new that is now in the ml5 documentation",
        "tokens": [
          50818,
          6595,
          777,
          300,
          307,
          586,
          294,
          264,
          23271,
          20,
          14333,
          51014
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 185.76000000000002,
        "id": 62,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 182.52,
        "temperature": 0,
        "text": " is a section called Model and Data Providence.",
        "tokens": [
          51014,
          307,
          257,
          3541,
          1219,
          17105,
          293,
          11888,
          15685,
          2778,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 188.28,
        "id": 63,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 185.76000000000002,
        "temperature": 0,
        "text": " You'll find this for every single pre-trained model",
        "tokens": [
          51176,
          509,
          603,
          915,
          341,
          337,
          633,
          2167,
          659,
          12,
          17227,
          2001,
          2316,
          51302
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 190.4,
        "id": 64,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 188.28,
        "temperature": 0,
        "text": " that's in the ml5 library.",
        "tokens": [
          51302,
          300,
          311,
          294,
          264,
          23271,
          20,
          6405,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 192.88,
        "id": 65,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 190.4,
        "temperature": 0,
        "text": " This is a project that's been started by Ellen Nichols.",
        "tokens": [
          51408,
          639,
          307,
          257,
          1716,
          300,
          311,
          668,
          1409,
          538,
          20306,
          17102,
          19385,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 194.4,
        "id": 66,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 192.88,
        "temperature": 0,
        "text": " And I encourage you to click the link",
        "tokens": [
          51532,
          400,
          286,
          5373,
          291,
          281,
          2052,
          264,
          2113,
          51608
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 197.4,
        "id": 67,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 194.4,
        "temperature": 0,
        "text": " to find out more about Ellen and her work on Model and Data",
        "tokens": [
          51608,
          281,
          915,
          484,
          544,
          466,
          20306,
          293,
          720,
          589,
          322,
          17105,
          293,
          11888,
          51758
        ]
      },
      {
        "avg_logprob": -0.19620812128460596,
        "compression_ratio": 1.6392857142857142,
        "end": 198.44,
        "id": 68,
        "no_speech_prob": 0.003027796046808362,
        "seek": 16952,
        "start": 197.4,
        "temperature": 0,
        "text": " Providence.",
        "tokens": [
          51758,
          15685,
          2778,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 203.16,
        "id": 69,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 198.44,
        "temperature": 0,
        "text": " And what she has done here is created model biographies",
        "tokens": [
          50364,
          400,
          437,
          750,
          575,
          1096,
          510,
          307,
          2942,
          2316,
          3228,
          3108,
          530,
          50600
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 204.56,
        "id": 70,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 203.16,
        "temperature": 0,
        "text": " and data biographies.",
        "tokens": [
          50600,
          293,
          1412,
          3228,
          3108,
          530,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 207.07999999999998,
        "id": 71,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 204.56,
        "temperature": 0,
        "text": " Anytime you're using a machine learning model,",
        "tokens": [
          50670,
          39401,
          291,
          434,
          1228,
          257,
          3479,
          2539,
          2316,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 209.12,
        "id": 72,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 207.07999999999998,
        "temperature": 0,
        "text": " you want to ask yourself the question,",
        "tokens": [
          50796,
          291,
          528,
          281,
          1029,
          1803,
          264,
          1168,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 211.12,
        "id": 73,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 209.12,
        "temperature": 0,
        "text": " what data was used to train this model?",
        "tokens": [
          50898,
          437,
          1412,
          390,
          1143,
          281,
          3847,
          341,
          2316,
          30,
          50998
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 212.52,
        "id": 74,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 211.12,
        "temperature": 0,
        "text": " Who trained this model?",
        "tokens": [
          50998,
          2102,
          8895,
          341,
          2316,
          30,
          51068
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 214.64,
        "id": 75,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 212.52,
        "temperature": 0,
        "text": " In what context and for what reasons?",
        "tokens": [
          51068,
          682,
          437,
          4319,
          293,
          337,
          437,
          4112,
          30,
          51174
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 216.52,
        "id": 76,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 214.64,
        "temperature": 0,
        "text": " Anytime you're going to use a pre-trained model",
        "tokens": [
          51174,
          39401,
          291,
          434,
          516,
          281,
          764,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          51268
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 219.28,
        "id": 77,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 216.52,
        "temperature": 0,
        "text": " on a project, you want to think about the ethical implications",
        "tokens": [
          51268,
          322,
          257,
          1716,
          11,
          291,
          528,
          281,
          519,
          466,
          264,
          18890,
          16602,
          51406
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 221.64,
        "id": 78,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 219.28,
        "temperature": 0,
        "text": " of where that model came from and how you're using it.",
        "tokens": [
          51406,
          295,
          689,
          300,
          2316,
          1361,
          490,
          293,
          577,
          291,
          434,
          1228,
          309,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 225.2,
        "id": 79,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 221.64,
        "temperature": 0,
        "text": " And researching into the biography, so to speak,",
        "tokens": [
          51524,
          400,
          24176,
          666,
          264,
          37062,
          11,
          370,
          281,
          1710,
          11,
          51702
        ]
      },
      {
        "avg_logprob": -0.20646135069483476,
        "compression_ratio": 1.894927536231884,
        "end": 227.28,
        "id": 80,
        "no_speech_prob": 0.00019411261018831283,
        "seek": 19844,
        "start": 225.2,
        "temperature": 0,
        "text": " of the data behind the model and the model",
        "tokens": [
          51702,
          295,
          264,
          1412,
          2261,
          264,
          2316,
          293,
          264,
          2316,
          51806
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 229.12,
        "id": 81,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 227.28,
        "temperature": 0,
        "text": " itself is incredibly important when considering",
        "tokens": [
          50364,
          2564,
          307,
          6252,
          1021,
          562,
          8079,
          50456
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 230.36,
        "id": 82,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 229.12,
        "temperature": 0,
        "text": " those kinds of questions.",
        "tokens": [
          50456,
          729,
          3685,
          295,
          1651,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 233.08,
        "id": 83,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 230.36,
        "temperature": 0,
        "text": " In this case, the data set behind the object detection",
        "tokens": [
          50518,
          682,
          341,
          1389,
          11,
          264,
          1412,
          992,
          2261,
          264,
          2657,
          17784,
          50654
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 236.08,
        "id": 84,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 233.08,
        "temperature": 0,
        "text": " model that I'm going to use is a data set called COCO.",
        "tokens": [
          50654,
          2316,
          300,
          286,
          478,
          516,
          281,
          764,
          307,
          257,
          1412,
          992,
          1219,
          3002,
          12322,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 238.32,
        "id": 85,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 236.08,
        "temperature": 0,
        "text": " COCO, or Common Objects in Context,",
        "tokens": [
          50804,
          3002,
          12322,
          11,
          420,
          18235,
          24753,
          82,
          294,
          4839,
          3828,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 241.48,
        "id": 86,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 238.32,
        "temperature": 0,
        "text": " is a large scale object detection, segmentation,",
        "tokens": [
          50916,
          307,
          257,
          2416,
          4373,
          2657,
          17784,
          11,
          9469,
          399,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 242.6,
        "id": 87,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 241.48,
        "temperature": 0,
        "text": " and captioning data set.",
        "tokens": [
          51074,
          293,
          31974,
          278,
          1412,
          992,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 245.12,
        "id": 88,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 242.6,
        "temperature": 0,
        "text": " So before you watch the rest of this video, I would pause.",
        "tokens": [
          51130,
          407,
          949,
          291,
          1159,
          264,
          1472,
          295,
          341,
          960,
          11,
          286,
          576,
          10465,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 246.72,
        "id": 89,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 245.12,
        "temperature": 0,
        "text": " Go to the COCO data set website.",
        "tokens": [
          51256,
          1037,
          281,
          264,
          3002,
          12322,
          1412,
          992,
          3144,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 248.8,
        "id": 90,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 246.72,
        "temperature": 0,
        "text": " Click Explore and poke around a little bit.",
        "tokens": [
          51336,
          8230,
          12514,
          418,
          293,
          19712,
          926,
          257,
          707,
          857,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 250.2,
        "id": 91,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 248.8,
        "temperature": 0,
        "text": " Also in this video series, you'll",
        "tokens": [
          51440,
          2743,
          294,
          341,
          960,
          2638,
          11,
          291,
          603,
          51510
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 253.68,
        "id": 92,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 250.2,
        "temperature": 0,
        "text": " find videos about the PoseNet pre-trained model.",
        "tokens": [
          51510,
          915,
          2145,
          466,
          264,
          40174,
          31890,
          659,
          12,
          17227,
          2001,
          2316,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.19335960582563072,
        "compression_ratio": 1.7484472049689441,
        "end": 257.16,
        "id": 93,
        "no_speech_prob": 0.009267843328416348,
        "seek": 22728,
        "start": 253.68,
        "temperature": 0,
        "text": " In COCO, in addition to the object detection data,",
        "tokens": [
          51684,
          682,
          3002,
          12322,
          11,
          294,
          4500,
          281,
          264,
          2657,
          17784,
          1412,
          11,
          51858
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 259.48,
        "id": 94,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 258.04,
        "temperature": 0,
        "text": " there's also a set of 200,000 images",
        "tokens": [
          50408,
          456,
          311,
          611,
          257,
          992,
          295,
          2331,
          11,
          1360,
          5267,
          50480
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 263.84000000000003,
        "id": 95,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 259.48,
        "temperature": 0,
        "text": " with 250,000 instances of people labeled with particular key",
        "tokens": [
          50480,
          365,
          11650,
          11,
          1360,
          14519,
          295,
          561,
          21335,
          365,
          1729,
          2141,
          50698
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 265.36,
        "id": 96,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 263.84000000000003,
        "temperature": 0,
        "text": " points on their body.",
        "tokens": [
          50698,
          2793,
          322,
          641,
          1772,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 268.96000000000004,
        "id": 97,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 265.36,
        "temperature": 0,
        "text": " COCO also includes image segmentation,",
        "tokens": [
          50774,
          3002,
          12322,
          611,
          5974,
          3256,
          9469,
          399,
          11,
          50954
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 271.96000000000004,
        "id": 98,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 268.96000000000004,
        "temperature": 0,
        "text": " which is a very similar concept to object detection,",
        "tokens": [
          50954,
          597,
          307,
          257,
          588,
          2531,
          3410,
          281,
          2657,
          17784,
          11,
          51104
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 274.48,
        "id": 99,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 271.96000000000004,
        "temperature": 0,
        "text": " but instead of a particular bounding box,",
        "tokens": [
          51104,
          457,
          2602,
          295,
          257,
          1729,
          5472,
          278,
          2424,
          11,
          51230
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 279.40000000000003,
        "id": 100,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 274.48,
        "temperature": 0,
        "text": " every single pixel is labeled as part of a particular category.",
        "tokens": [
          51230,
          633,
          2167,
          19261,
          307,
          21335,
          382,
          644,
          295,
          257,
          1729,
          7719,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 281.8,
        "id": 101,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 279.40000000000003,
        "temperature": 0,
        "text": " So there are all the pixels for the giraffe",
        "tokens": [
          51476,
          407,
          456,
          366,
          439,
          264,
          18668,
          337,
          264,
          49897,
          51596
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 284.32000000000005,
        "id": 102,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 281.8,
        "temperature": 0,
        "text": " versus the pixels for the clouds in the sky,",
        "tokens": [
          51596,
          5717,
          264,
          18668,
          337,
          264,
          12193,
          294,
          264,
          5443,
          11,
          51722
        ]
      },
      {
        "avg_logprob": -0.20754098470232127,
        "compression_ratio": 1.6929133858267718,
        "end": 286.24,
        "id": 103,
        "no_speech_prob": 0.000005594329195446335,
        "seek": 25716,
        "start": 284.32000000000005,
        "temperature": 0,
        "text": " and so on and so forth.",
        "tokens": [
          51722,
          293,
          370,
          322,
          293,
          370,
          5220,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 288.16,
        "id": 104,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 286.24,
        "temperature": 0,
        "text": " I also want to suggest to you two readings",
        "tokens": [
          50364,
          286,
          611,
          528,
          281,
          3402,
          281,
          291,
          732,
          27319,
          50460
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 291.2,
        "id": 105,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 288.16,
        "temperature": 0,
        "text": " if you're interested in learning more about data",
        "tokens": [
          50460,
          498,
          291,
          434,
          3102,
          294,
          2539,
          544,
          466,
          1412,
          50612
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 293.24,
        "id": 106,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 291.2,
        "temperature": 0,
        "text": " sets for machine learning.",
        "tokens": [
          50612,
          6352,
          337,
          3479,
          2539,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 296,
        "id": 107,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 293.24,
        "temperature": 0,
        "text": " The Humans of AI project by Philip Schmidt",
        "tokens": [
          50714,
          440,
          35809,
          295,
          7318,
          1716,
          538,
          21144,
          42621,
          50852
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 299.04,
        "id": 108,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 296,
        "temperature": 0,
        "text": " is a project that explores specifically the COCO image",
        "tokens": [
          50852,
          307,
          257,
          1716,
          300,
          45473,
          4682,
          264,
          3002,
          12322,
          3256,
          51004
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 299.6,
        "id": 109,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 299.04,
        "temperature": 0,
        "text": " data set.",
        "tokens": [
          51004,
          1412,
          992,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 301.32,
        "id": 110,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 299.6,
        "temperature": 0,
        "text": " And you can learn a lot more about where",
        "tokens": [
          51032,
          400,
          291,
          393,
          1466,
          257,
          688,
          544,
          466,
          689,
          51118
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 304.56,
        "id": 111,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 301.32,
        "temperature": 0,
        "text": " did those images come from, who took those photos,",
        "tokens": [
          51118,
          630,
          729,
          5267,
          808,
          490,
          11,
          567,
          1890,
          729,
          5787,
          11,
          51280
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 306.8,
        "id": 112,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 304.56,
        "temperature": 0,
        "text": " and how Philip Schmidt puts it, exposing",
        "tokens": [
          51280,
          293,
          577,
          21144,
          42621,
          8137,
          309,
          11,
          33178,
          51392
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 309.64,
        "id": 113,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 306.8,
        "temperature": 0,
        "text": " the myth of magically intelligent machines.",
        "tokens": [
          51392,
          264,
          9474,
          295,
          39763,
          13232,
          8379,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 312.64,
        "id": 114,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 309.64,
        "temperature": 0,
        "text": " I also would highly suggest reading Excavating AI,",
        "tokens": [
          51534,
          286,
          611,
          576,
          5405,
          3402,
          3760,
          2111,
          496,
          85,
          990,
          7318,
          11,
          51684
        ]
      },
      {
        "avg_logprob": -0.21952947974205017,
        "compression_ratio": 1.7263513513513513,
        "end": 315.52,
        "id": 115,
        "no_speech_prob": 0.00332433870062232,
        "seek": 28624,
        "start": 312.64,
        "temperature": 0,
        "text": " the Politics of Images in Machine Learning Training Sets",
        "tokens": [
          51684,
          264,
          45348,
          295,
          4331,
          1660,
          294,
          22155,
          15205,
          20620,
          318,
          1385,
          51828
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 317.68,
        "id": 116,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 315.59999999999997,
        "temperature": 0,
        "text": " by Kate Crawford and Trevor Paglen.",
        "tokens": [
          50368,
          538,
          16251,
          37877,
          7404,
          293,
          26245,
          430,
          559,
          6698,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 321.71999999999997,
        "id": 117,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 317.68,
        "temperature": 0,
        "text": " This essay explores the ImageNet database, another very well",
        "tokens": [
          50472,
          639,
          16238,
          45473,
          264,
          29903,
          31890,
          8149,
          11,
          1071,
          588,
          731,
          50674
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 324.15999999999997,
        "id": 118,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 321.71999999999997,
        "temperature": 0,
        "text": " known image database that is the data",
        "tokens": [
          50674,
          2570,
          3256,
          8149,
          300,
          307,
          264,
          1412,
          50796
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 326.79999999999995,
        "id": 119,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 324.15999999999997,
        "temperature": 0,
        "text": " set behind the MobileNet model, which",
        "tokens": [
          50796,
          992,
          2261,
          264,
          22625,
          31890,
          2316,
          11,
          597,
          50928
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 330.84,
        "id": 120,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 326.79999999999995,
        "temperature": 0,
        "text": " serves as the foundation for many of the ML5 image",
        "tokens": [
          50928,
          13451,
          382,
          264,
          7030,
          337,
          867,
          295,
          264,
          21601,
          20,
          3256,
          51130
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 332.91999999999996,
        "id": 121,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 330.84,
        "temperature": 0,
        "text": " classification and transfer learning examples that",
        "tokens": [
          51130,
          21538,
          293,
          5003,
          2539,
          5110,
          300,
          51234
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 335.12,
        "id": 122,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 332.91999999999996,
        "temperature": 0,
        "text": " are throughout this particular playlist.",
        "tokens": [
          51234,
          366,
          3710,
          341,
          1729,
          16788,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 338.32,
        "id": 123,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 335.12,
        "temperature": 0,
        "text": " Circling back to ML5, if you use the object detector,",
        "tokens": [
          51344,
          13791,
          12455,
          646,
          281,
          21601,
          20,
          11,
          498,
          291,
          764,
          264,
          2657,
          25712,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 341.32,
        "id": 124,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 338.32,
        "temperature": 0,
        "text": " there are two pre-trained models you can select from at present.",
        "tokens": [
          51504,
          456,
          366,
          732,
          659,
          12,
          17227,
          2001,
          5245,
          291,
          393,
          3048,
          490,
          412,
          1974,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 342.9,
        "id": 125,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 341.32,
        "temperature": 0,
        "text": " Hopefully, in the future, maybe you'll",
        "tokens": [
          51654,
          10429,
          11,
          294,
          264,
          2027,
          11,
          1310,
          291,
          603,
          51733
        ]
      },
      {
        "avg_logprob": -0.23514780402183533,
        "compression_ratio": 1.625,
        "end": 344.44,
        "id": 126,
        "no_speech_prob": 0.00020027290156576782,
        "seek": 31552,
        "start": 342.9,
        "temperature": 0,
        "text": " even train your own model or will",
        "tokens": [
          51733,
          754,
          3847,
          428,
          1065,
          2316,
          420,
          486,
          51810
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 346.96,
        "id": 127,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 344.44,
        "temperature": 0,
        "text": " be able to incorporate other open source object detection",
        "tokens": [
          50364,
          312,
          1075,
          281,
          16091,
          661,
          1269,
          4009,
          2657,
          17784,
          50490
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 347.46,
        "id": 128,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 346.96,
        "temperature": 0,
        "text": " models.",
        "tokens": [
          50490,
          5245,
          13,
          50515
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 349.56,
        "id": 129,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 347.46,
        "temperature": 0,
        "text": " But right now, there's YOLO, which",
        "tokens": [
          50515,
          583,
          558,
          586,
          11,
          456,
          311,
          398,
          5046,
          46,
          11,
          597,
          50620
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 353,
        "id": 130,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 349.56,
        "temperature": 0,
        "text": " stands for You Only Look Once, and COCOSD.",
        "tokens": [
          50620,
          7382,
          337,
          509,
          5686,
          2053,
          3443,
          11,
          293,
          3002,
          12322,
          23969,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 355.56,
        "id": 131,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 353,
        "temperature": 0,
        "text": " In this video, I'm going to demonstrate using COCOSD,",
        "tokens": [
          50792,
          682,
          341,
          960,
          11,
          286,
          478,
          516,
          281,
          11698,
          1228,
          3002,
          12322,
          23969,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 357.6,
        "id": 132,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 355.56,
        "temperature": 0,
        "text": " but I encourage you to explore and experiment",
        "tokens": [
          50920,
          457,
          286,
          5373,
          291,
          281,
          6839,
          293,
          5120,
          51022
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 360.2,
        "id": 133,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 357.6,
        "temperature": 0,
        "text": " and do your research about the YOLO model as well.",
        "tokens": [
          51022,
          293,
          360,
          428,
          2132,
          466,
          264,
          398,
          5046,
          46,
          2316,
          382,
          731,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 363.44,
        "id": 134,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 360.2,
        "temperature": 0,
        "text": " The COCOSSD model comes from TensorFlow.",
        "tokens": [
          51152,
          440,
          3002,
          12322,
          21929,
          35,
          2316,
          1487,
          490,
          37624,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 367.76,
        "id": 135,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 363.44,
        "temperature": 0,
        "text": " So there's the TensorFlow.js port of the TensorFlow COCOSSD",
        "tokens": [
          51314,
          407,
          456,
          311,
          264,
          37624,
          13,
          25530,
          2436,
          295,
          264,
          37624,
          3002,
          12322,
          21929,
          35,
          51530
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 368.32,
        "id": 136,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 367.76,
        "temperature": 0,
        "text": " model.",
        "tokens": [
          51530,
          2316,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 369.76,
        "id": 137,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 368.32,
        "temperature": 0,
        "text": " That's what ML5 is using.",
        "tokens": [
          51558,
          663,
          311,
          437,
          21601,
          20,
          307,
          1228,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.2246673175266811,
        "compression_ratio": 1.6344827586206896,
        "end": 372.52,
        "id": 138,
        "no_speech_prob": 0.0019877415616065264,
        "seek": 34444,
        "start": 369.76,
        "temperature": 0,
        "text": " Certainly, on the GitHub page for that model,",
        "tokens": [
          51630,
          16628,
          11,
          322,
          264,
          23331,
          3028,
          337,
          300,
          2316,
          11,
          51768
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 374.64,
        "id": 139,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 372.52,
        "temperature": 0,
        "text": " you can find code for using it in JavaScript",
        "tokens": [
          50364,
          291,
          393,
          915,
          3089,
          337,
          1228,
          309,
          294,
          15778,
          50470
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 377.08,
        "id": 140,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 374.64,
        "temperature": 0,
        "text": " without the ML5 library that you could explore,",
        "tokens": [
          50470,
          1553,
          264,
          21601,
          20,
          6405,
          300,
          291,
          727,
          6839,
          11,
          50592
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 379.24,
        "id": 141,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 377.08,
        "temperature": 0,
        "text": " as well as more background about how it",
        "tokens": [
          50592,
          382,
          731,
          382,
          544,
          3678,
          466,
          577,
          309,
          50700
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 380.47999999999996,
        "id": 142,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 379.24,
        "temperature": 0,
        "text": " was trained and what it does.",
        "tokens": [
          50700,
          390,
          8895,
          293,
          437,
          309,
          775,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 382.12,
        "id": 143,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 380.47999999999996,
        "temperature": 0,
        "text": " Now, one thing I'll note is it only",
        "tokens": [
          50762,
          823,
          11,
          472,
          551,
          286,
          603,
          3637,
          307,
          309,
          787,
          50844
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 385.2,
        "id": 144,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 382.12,
        "temperature": 0,
        "text": " detects 80 classes of object, not a huge number",
        "tokens": [
          50844,
          5531,
          82,
          4688,
          5359,
          295,
          2657,
          11,
          406,
          257,
          2603,
          1230,
          50998
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 386.28,
        "id": 145,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 385.2,
        "temperature": 0,
        "text": " if you think about it.",
        "tokens": [
          50998,
          498,
          291,
          519,
          466,
          309,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 389.34,
        "id": 146,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 386.28,
        "temperature": 0,
        "text": " You can find that list of labels as part of the ML5 materials",
        "tokens": [
          51052,
          509,
          393,
          915,
          300,
          1329,
          295,
          16949,
          382,
          644,
          295,
          264,
          21601,
          20,
          5319,
          51205
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 390.52,
        "id": 147,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 389.34,
        "temperature": 0,
        "text": " themselves as well.",
        "tokens": [
          51205,
          2969,
          382,
          731,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 393.47999999999996,
        "id": 148,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 390.52,
        "temperature": 0,
        "text": " All right, it's time to write some code.",
        "tokens": [
          51264,
          1057,
          558,
          11,
          309,
          311,
          565,
          281,
          2464,
          512,
          3089,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 395.15999999999997,
        "id": 149,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 393.47999999999996,
        "temperature": 0,
        "text": " The first thing that I want to do",
        "tokens": [
          51412,
          440,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          51496
        ]
      },
      {
        "avg_logprob": -0.20757297971355382,
        "compression_ratio": 1.6275862068965516,
        "end": 398.03999999999996,
        "id": 150,
        "no_speech_prob": 0.02002253569662571,
        "seek": 37252,
        "start": 395.15999999999997,
        "temperature": 0,
        "text": " is have an image to try to detect objects in.",
        "tokens": [
          51496,
          307,
          362,
          364,
          3256,
          281,
          853,
          281,
          5531,
          6565,
          294,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 404.52,
        "id": 151,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 403.52,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50414,
          821,
          321,
          352,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 406.32,
        "id": 152,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 404.52,
        "temperature": 0,
        "text": " So I've made a simple P5 sketch that",
        "tokens": [
          50464,
          407,
          286,
          600,
          1027,
          257,
          2199,
          430,
          20,
          12325,
          300,
          50554
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 409.35999999999996,
        "id": 153,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 406.32,
        "temperature": 0,
        "text": " uses the preload function to load a particular image",
        "tokens": [
          50554,
          4960,
          264,
          659,
          2907,
          2445,
          281,
          3677,
          257,
          1729,
          3256,
          50706
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 411.4,
        "id": 154,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 409.35999999999996,
        "temperature": 0,
        "text": " that I've uploaded to the P5 web editor.",
        "tokens": [
          50706,
          300,
          286,
          600,
          17135,
          281,
          264,
          430,
          20,
          3670,
          9839,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 413.44,
        "id": 155,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 411.4,
        "temperature": 0,
        "text": " And in the setup function, I'm making a canvas",
        "tokens": [
          50808,
          400,
          294,
          264,
          8657,
          2445,
          11,
          286,
          478,
          1455,
          257,
          16267,
          50910
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 414.4,
        "id": 156,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 413.44,
        "temperature": 0,
        "text": " and drawing that image.",
        "tokens": [
          50910,
          293,
          6316,
          300,
          3256,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 415.84,
        "id": 157,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 414.4,
        "temperature": 0,
        "text": " You might recognize Gloria Pickle",
        "tokens": [
          50958,
          509,
          1062,
          5521,
          34288,
          14129,
          306,
          51030
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 419.59999999999997,
        "id": 158,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 415.84,
        "temperature": 0,
        "text": " from my Coding in the Cabana series,",
        "tokens": [
          51030,
          490,
          452,
          383,
          8616,
          294,
          264,
          14704,
          2095,
          2638,
          11,
          51218
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 422.2,
        "id": 159,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 419.59999999999997,
        "temperature": 0,
        "text": " along with her good friend, Greta Goose.",
        "tokens": [
          51218,
          2051,
          365,
          720,
          665,
          1277,
          11,
          14986,
          1328,
          1037,
          541,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 424.2,
        "id": 160,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 422.2,
        "temperature": 0,
        "text": " Unfortunately, Evie Mango is not pictured here,",
        "tokens": [
          51348,
          8590,
          11,
          5689,
          414,
          48588,
          307,
          406,
          49896,
          510,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 425.56,
        "id": 161,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 424.2,
        "temperature": 0,
        "text": " but you can learn more about them",
        "tokens": [
          51448,
          457,
          291,
          393,
          1466,
          544,
          466,
          552,
          51516
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 427.03999999999996,
        "id": 162,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 425.56,
        "temperature": 0,
        "text": " on their Instagram, which I'll link",
        "tokens": [
          51516,
          322,
          641,
          5281,
          11,
          597,
          286,
          603,
          2113,
          51590
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 428.52,
        "id": 163,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 427.03999999999996,
        "temperature": 0,
        "text": " to in the video's description.",
        "tokens": [
          51590,
          281,
          294,
          264,
          960,
          311,
          3855,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.35654189255063895,
        "compression_ratio": 1.5688073394495412,
        "end": 430.12,
        "id": 164,
        "no_speech_prob": 0.0004955240874551237,
        "seek": 40252,
        "start": 428.52,
        "temperature": 0,
        "text": " Now that I've got my image, I'm going",
        "tokens": [
          51664,
          823,
          300,
          286,
          600,
          658,
          452,
          3256,
          11,
          286,
          478,
          516,
          51744
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 433.52,
        "id": 165,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 431.12,
        "temperature": 0,
        "text": " Now that I've got my image, the next step",
        "tokens": [
          50414,
          823,
          300,
          286,
          600,
          658,
          452,
          3256,
          11,
          264,
          958,
          1823,
          50534
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 437.16,
        "id": 166,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 433.52,
        "temperature": 0,
        "text": " is for me to load the CocoaSD model itself.",
        "tokens": [
          50534,
          307,
          337,
          385,
          281,
          3677,
          264,
          29787,
          64,
          23969,
          2316,
          2564,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 443.36,
        "id": 167,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 441.04,
        "temperature": 0,
        "text": " For this basic example, I'm making heavy use",
        "tokens": [
          50910,
          1171,
          341,
          3875,
          1365,
          11,
          286,
          478,
          1455,
          4676,
          764,
          51026
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 445.08,
        "id": 168,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 443.36,
        "temperature": 0,
        "text": " of the preload function, which allows",
        "tokens": [
          51026,
          295,
          264,
          659,
          2907,
          2445,
          11,
          597,
          4045,
          51112
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 447.04,
        "id": 169,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 445.08,
        "temperature": 0,
        "text": " me to load images and pre-trained models",
        "tokens": [
          51112,
          385,
          281,
          3677,
          5267,
          293,
          659,
          12,
          17227,
          2001,
          5245,
          51210
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 448.2,
        "id": 170,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 447.04,
        "temperature": 0,
        "text": " without any callbacks.",
        "tokens": [
          51210,
          1553,
          604,
          818,
          17758,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 449.8,
        "id": 171,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 448.2,
        "temperature": 0,
        "text": " And everything is ready to go once I",
        "tokens": [
          51268,
          400,
          1203,
          307,
          1919,
          281,
          352,
          1564,
          286,
          51348
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 451,
        "id": 172,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 449.8,
        "temperature": 0,
        "text": " get to the setup function.",
        "tokens": [
          51348,
          483,
          281,
          264,
          8657,
          2445,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 452.5,
        "id": 173,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 451,
        "temperature": 0,
        "text": " But certainly in other contexts, you",
        "tokens": [
          51408,
          583,
          3297,
          294,
          661,
          30628,
          11,
          291,
          51483
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 454.2,
        "id": 174,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 452.5,
        "temperature": 0,
        "text": " might want to use a callback or write",
        "tokens": [
          51483,
          1062,
          528,
          281,
          764,
          257,
          818,
          3207,
          420,
          2464,
          51568
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 455.4,
        "id": 175,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 454.2,
        "temperature": 0,
        "text": " your code in a different way.",
        "tokens": [
          51568,
          428,
          3089,
          294,
          257,
          819,
          636,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 457.88,
        "id": 176,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 455.4,
        "temperature": 0,
        "text": " And you'll find all of that in the actual official ML5",
        "tokens": [
          51628,
          400,
          291,
          603,
          915,
          439,
          295,
          300,
          294,
          264,
          3539,
          4783,
          21601,
          20,
          51752
        ]
      },
      {
        "avg_logprob": -0.2585546952964616,
        "compression_ratio": 1.606060606060606,
        "end": 459.12,
        "id": 177,
        "no_speech_prob": 0.027583299204707146,
        "seek": 43012,
        "start": 457.88,
        "temperature": 0,
        "text": " examples themselves.",
        "tokens": [
          51752,
          5110,
          2969,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 461.36,
        "id": 178,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 459.2,
        "temperature": 0,
        "text": " Let's double check that things are working correctly",
        "tokens": [
          50368,
          961,
          311,
          3834,
          1520,
          300,
          721,
          366,
          1364,
          8944,
          50476
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 464.4,
        "id": 179,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 461.36,
        "temperature": 0,
        "text": " by just console logging the detector object.",
        "tokens": [
          50476,
          538,
          445,
          11076,
          27991,
          264,
          25712,
          2657,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 465.92,
        "id": 180,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 464.4,
        "temperature": 0,
        "text": " Oh, and I should put that in setup",
        "tokens": [
          50628,
          876,
          11,
          293,
          286,
          820,
          829,
          300,
          294,
          8657,
          50704
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 469.36,
        "id": 181,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 465.92,
        "temperature": 0,
        "text": " to see that it's loaded properly.",
        "tokens": [
          50704,
          281,
          536,
          300,
          309,
          311,
          13210,
          6108,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 469.96,
        "id": 182,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 469.36,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50876,
          45263,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 471.88,
        "id": 183,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 469.96,
        "temperature": 0,
        "text": " By accident, I put a capital O there.",
        "tokens": [
          50906,
          3146,
          6398,
          11,
          286,
          829,
          257,
          4238,
          422,
          456,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 473.84000000000003,
        "id": 184,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 471.88,
        "temperature": 0,
        "text": " It should be lowercase o, object detector.",
        "tokens": [
          51002,
          467,
          820,
          312,
          3126,
          9765,
          277,
          11,
          2657,
          25712,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 475.76,
        "id": 185,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 473.84000000000003,
        "temperature": 0,
        "text": " The console isn't necessarily going to show us",
        "tokens": [
          51100,
          440,
          11076,
          1943,
          380,
          4725,
          516,
          281,
          855,
          505,
          51196
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 478.12,
        "id": 186,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 475.76,
        "temperature": 0,
        "text": " anything useful here, just a lot of the stuff that's",
        "tokens": [
          51196,
          1340,
          4420,
          510,
          11,
          445,
          257,
          688,
          295,
          264,
          1507,
          300,
          311,
          51314
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 480.88,
        "id": 187,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 478.12,
        "temperature": 0,
        "text": " part of that detector object in ML5.",
        "tokens": [
          51314,
          644,
          295,
          300,
          25712,
          2657,
          294,
          21601,
          20,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 483.84000000000003,
        "id": 188,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 480.88,
        "temperature": 0,
        "text": " But it's more clear for us to look at the documentation",
        "tokens": [
          51452,
          583,
          309,
          311,
          544,
          1850,
          337,
          505,
          281,
          574,
          412,
          264,
          14333,
          51600
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 486.32,
        "id": 189,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 483.84000000000003,
        "temperature": 0,
        "text": " than see what's logged here in the console.",
        "tokens": [
          51600,
          813,
          536,
          437,
          311,
          27231,
          510,
          294,
          264,
          11076,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.20661614039172865,
        "compression_ratio": 1.705128205128205,
        "end": 488.48,
        "id": 190,
        "no_speech_prob": 0.0001823526545194909,
        "seek": 45912,
        "start": 486.32,
        "temperature": 0,
        "text": " I happen to know that what I need to do",
        "tokens": [
          51724,
          286,
          1051,
          281,
          458,
          300,
          437,
          286,
          643,
          281,
          360,
          51832
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 492.48,
        "id": 191,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 488.48,
        "temperature": 0,
        "text": " is call detector.predict, pass it the image, and then",
        "tokens": [
          50364,
          307,
          818,
          25712,
          13,
          79,
          24945,
          11,
          1320,
          309,
          264,
          3256,
          11,
          293,
          550,
          50564
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 495.32,
        "id": 192,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 492.48,
        "temperature": 0,
        "text": " a callback for when I've got the detections.",
        "tokens": [
          50564,
          257,
          818,
          3207,
          337,
          562,
          286,
          600,
          658,
          264,
          5531,
          626,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 500.16,
        "id": 193,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 495.32,
        "temperature": 0,
        "text": " So I'll say gotDetections as the name of my callback function.",
        "tokens": [
          50706,
          407,
          286,
          603,
          584,
          658,
          41444,
          557,
          626,
          382,
          264,
          1315,
          295,
          452,
          818,
          3207,
          2445,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 502.92,
        "id": 194,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 500.16,
        "temperature": 0,
        "text": " Let's write that function.",
        "tokens": [
          50948,
          961,
          311,
          2464,
          300,
          2445,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 505.6,
        "id": 195,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 502.92,
        "temperature": 0,
        "text": " And let's log the results.",
        "tokens": [
          51086,
          400,
          718,
          311,
          3565,
          264,
          3542,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 508.40000000000003,
        "id": 196,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 505.6,
        "temperature": 0,
        "text": " So this is the same pattern in many other ML5",
        "tokens": [
          51220,
          407,
          341,
          307,
          264,
          912,
          5102,
          294,
          867,
          661,
          21601,
          20,
          51360
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 509.96000000000004,
        "id": 197,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 508.40000000000003,
        "temperature": 0,
        "text": " pre-trained models.",
        "tokens": [
          51360,
          659,
          12,
          17227,
          2001,
          5245,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 513.96,
        "id": 198,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 509.96000000000004,
        "temperature": 0,
        "text": " Load the model, call predict, get a result,",
        "tokens": [
          51438,
          48408,
          264,
          2316,
          11,
          818,
          6069,
          11,
          483,
          257,
          1874,
          11,
          51638
        ]
      },
      {
        "avg_logprob": -0.21461377592168301,
        "compression_ratio": 1.7072072072072073,
        "end": 516.82,
        "id": 199,
        "no_speech_prob": 0.00038596498779952526,
        "seek": 48848,
        "start": 513.96,
        "temperature": 0,
        "text": " error first in the callback in case there's an error.",
        "tokens": [
          51638,
          6713,
          700,
          294,
          264,
          818,
          3207,
          294,
          1389,
          456,
          311,
          364,
          6713,
          13,
          51781
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 520.5400000000001,
        "id": 200,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 516.82,
        "temperature": 0,
        "text": " And maybe I should check for that.",
        "tokens": [
          50364,
          400,
          1310,
          286,
          820,
          1520,
          337,
          300,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 522.34,
        "id": 201,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 520.5400000000001,
        "temperature": 0,
        "text": " And then do something with the results.",
        "tokens": [
          50550,
          400,
          550,
          360,
          746,
          365,
          264,
          3542,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 523.86,
        "id": 202,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 522.34,
        "temperature": 0,
        "text": " I just want to log them right now.",
        "tokens": [
          50640,
          286,
          445,
          528,
          281,
          3565,
          552,
          558,
          586,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 527.22,
        "id": 203,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 523.86,
        "temperature": 0,
        "text": " Detector.predict is not a function.",
        "tokens": [
          50716,
          4237,
          20814,
          13,
          79,
          24945,
          307,
          406,
          257,
          2445,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 528.86,
        "id": 204,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 527.22,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50884,
          21726,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 531.74,
        "id": 205,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 528.86,
        "temperature": 0,
        "text": " Looking at the documentation, the function is not predict.",
        "tokens": [
          50966,
          11053,
          412,
          264,
          14333,
          11,
          264,
          2445,
          307,
          406,
          6069,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 532.9000000000001,
        "id": 206,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 531.74,
        "temperature": 0,
        "text": " It's detect.",
        "tokens": [
          51110,
          467,
          311,
          5531,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 536.6600000000001,
        "id": 207,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 532.9000000000001,
        "temperature": 0,
        "text": " So predict is a general word for when",
        "tokens": [
          51168,
          407,
          6069,
          307,
          257,
          2674,
          1349,
          337,
          562,
          51356
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 538.98,
        "id": 208,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 536.6600000000001,
        "temperature": 0,
        "text": " you want to ask a machine learning",
        "tokens": [
          51356,
          291,
          528,
          281,
          1029,
          257,
          3479,
          2539,
          51472
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 541.86,
        "id": 209,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 538.98,
        "temperature": 0,
        "text": " model to give you the output associated with a given input.",
        "tokens": [
          51472,
          2316,
          281,
          976,
          291,
          264,
          5598,
          6615,
          365,
          257,
          2212,
          4846,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.20432504299467644,
        "compression_ratio": 1.6129032258064515,
        "end": 544.7,
        "id": 210,
        "no_speech_prob": 0.0000917017605388537,
        "seek": 51682,
        "start": 541.86,
        "temperature": 0,
        "text": " But in this specific case, the ML5 function",
        "tokens": [
          51616,
          583,
          294,
          341,
          2685,
          1389,
          11,
          264,
          21601,
          20,
          2445,
          51758
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 547.5400000000001,
        "id": 211,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 544.7,
        "temperature": 0,
        "text": " is named detect because it's a more descriptive word of what",
        "tokens": [
          50364,
          307,
          4926,
          5531,
          570,
          309,
          311,
          257,
          544,
          42585,
          1349,
          295,
          437,
          50506
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 548.7,
        "id": 212,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 547.5400000000001,
        "temperature": 0,
        "text": " we're actually doing.",
        "tokens": [
          50506,
          321,
          434,
          767,
          884,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 550.3000000000001,
        "id": 213,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 548.7,
        "temperature": 0,
        "text": " I'm going to change this to detect.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          5531,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 554.0200000000001,
        "id": 214,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 550.3000000000001,
        "temperature": 0,
        "text": " Let's also comment out this unnecessary console log",
        "tokens": [
          50644,
          961,
          311,
          611,
          2871,
          484,
          341,
          19350,
          11076,
          3565,
          50830
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 557.5,
        "id": 215,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 554.0200000000001,
        "temperature": 0,
        "text": " and run it again.",
        "tokens": [
          50830,
          293,
          1190,
          309,
          797,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 558.82,
        "id": 216,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 557.5,
        "temperature": 0,
        "text": " Aha, look at this.",
        "tokens": [
          51004,
          27448,
          11,
          574,
          412,
          341,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 559.98,
        "id": 217,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 558.82,
        "temperature": 0,
        "text": " Three objects.",
        "tokens": [
          51070,
          6244,
          6565,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 561.98,
        "id": 218,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 559.98,
        "temperature": 0,
        "text": " OK, there is a cat.",
        "tokens": [
          51128,
          2264,
          11,
          456,
          307,
          257,
          3857,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 563.22,
        "id": 219,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 561.98,
        "temperature": 0,
        "text": " There is a dog.",
        "tokens": [
          51228,
          821,
          307,
          257,
          3000,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 564.82,
        "id": 220,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 563.22,
        "temperature": 0,
        "text": " What's the third one?",
        "tokens": [
          51290,
          708,
          311,
          264,
          2636,
          472,
          30,
          51370
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 568.1800000000001,
        "id": 221,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 564.82,
        "temperature": 0,
        "text": " It's something in this list of 80 things.",
        "tokens": [
          51370,
          467,
          311,
          746,
          294,
          341,
          1329,
          295,
          4688,
          721,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 569.5,
        "id": 222,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 568.1800000000001,
        "temperature": 0,
        "text": " Did you see it there?",
        "tokens": [
          51538,
          2589,
          291,
          536,
          309,
          456,
          30,
          51604
        ]
      },
      {
        "avg_logprob": -0.22485869970077124,
        "compression_ratio": 1.5466101694915255,
        "end": 572.26,
        "id": 223,
        "no_speech_prob": 0.00060707435477525,
        "seek": 54470,
        "start": 569.5,
        "temperature": 0,
        "text": " Object 0 is the dog.",
        "tokens": [
          51604,
          24753,
          1958,
          307,
          264,
          3000,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 575.54,
        "id": 224,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 572.26,
        "temperature": 0,
        "text": " Here's the confidence score and the x, y width and height.",
        "tokens": [
          50364,
          1692,
          311,
          264,
          6687,
          6175,
          293,
          264,
          2031,
          11,
          288,
          11402,
          293,
          6681,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 578.04,
        "id": 225,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 575.54,
        "temperature": 0,
        "text": " It also looks like it gives you something called normalized,",
        "tokens": [
          50528,
          467,
          611,
          1542,
          411,
          309,
          2709,
          291,
          746,
          1219,
          48704,
          11,
          50653
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 579.7,
        "id": 226,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 578.04,
        "temperature": 0,
        "text": " which are probably all of these values,",
        "tokens": [
          50653,
          597,
          366,
          1391,
          439,
          295,
          613,
          4190,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 583.22,
        "id": 227,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 579.7,
        "temperature": 0,
        "text": " but mapped to a range between 0 and 1.",
        "tokens": [
          50736,
          457,
          33318,
          281,
          257,
          3613,
          1296,
          1958,
          293,
          502,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 585.66,
        "id": 228,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 583.22,
        "temperature": 0,
        "text": " Object 1 is the couch.",
        "tokens": [
          50912,
          24753,
          502,
          307,
          264,
          16511,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 587.54,
        "id": 229,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 585.66,
        "temperature": 0,
        "text": " It detected the couch.",
        "tokens": [
          51034,
          467,
          21896,
          264,
          16511,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 591.1,
        "id": 230,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 587.54,
        "temperature": 0,
        "text": " And then object 3, I'm going to assume, is the cat.",
        "tokens": [
          51128,
          400,
          550,
          2657,
          805,
          11,
          286,
          478,
          516,
          281,
          6552,
          11,
          307,
          264,
          3857,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 592.98,
        "id": 231,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 591.1,
        "temperature": 0,
        "text": " Let's draw those bounding boxes.",
        "tokens": [
          51306,
          961,
          311,
          2642,
          729,
          5472,
          278,
          9002,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 595.14,
        "id": 232,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 592.98,
        "temperature": 0,
        "text": " So I can write a loop to look at all",
        "tokens": [
          51400,
          407,
          286,
          393,
          2464,
          257,
          6367,
          281,
          574,
          412,
          439,
          51508
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 598.34,
        "id": 233,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 595.14,
        "temperature": 0,
        "text": " of the elements of the array.",
        "tokens": [
          51508,
          295,
          264,
          4959,
          295,
          264,
          10225,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.20840014059712567,
        "compression_ratio": 1.6117216117216118,
        "end": 600.1,
        "id": 234,
        "no_speech_prob": 0.000056497843615943566,
        "seek": 57226,
        "start": 598.34,
        "temperature": 0,
        "text": " And of course, there's countless other ways",
        "tokens": [
          51668,
          400,
          295,
          1164,
          11,
          456,
          311,
          19223,
          661,
          2098,
          51756
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 602.98,
        "id": 235,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 600.1,
        "temperature": 0,
        "text": " you can do this with different types of array functionality.",
        "tokens": [
          50364,
          291,
          393,
          360,
          341,
          365,
          819,
          3467,
          295,
          10225,
          14980,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 604.86,
        "id": 236,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 602.98,
        "temperature": 0,
        "text": " But this simplest way, I'll just say",
        "tokens": [
          50508,
          583,
          341,
          22811,
          636,
          11,
          286,
          603,
          445,
          584,
          50602
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 608.78,
        "id": 237,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 604.86,
        "temperature": 0,
        "text": " let object equals results index i.",
        "tokens": [
          50602,
          718,
          2657,
          6915,
          3542,
          8186,
          741,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 613.26,
        "id": 238,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 608.78,
        "temperature": 0,
        "text": " Let's first just draw the bounding box at object x,",
        "tokens": [
          50798,
          961,
          311,
          700,
          445,
          2642,
          264,
          5472,
          278,
          2424,
          412,
          2657,
          2031,
          11,
          51022
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 616.14,
        "id": 239,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 613.26,
        "temperature": 0,
        "text": " object y with the width and height.",
        "tokens": [
          51022,
          2657,
          288,
          365,
          264,
          11402,
          293,
          6681,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 618.74,
        "id": 240,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 616.14,
        "temperature": 0,
        "text": " Let's give it a sort of distinctive color",
        "tokens": [
          51166,
          961,
          311,
          976,
          309,
          257,
          1333,
          295,
          27766,
          2017,
          51296
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 624.1800000000001,
        "id": 241,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 618.74,
        "temperature": 0,
        "text": " just so it really is emphasized with a given thickness.",
        "tokens": [
          51296,
          445,
          370,
          309,
          534,
          307,
          34068,
          365,
          257,
          2212,
          14855,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 627.02,
        "id": 242,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 624.1800000000001,
        "temperature": 0,
        "text": " And make sure there's no fill blocking it out.",
        "tokens": [
          51568,
          400,
          652,
          988,
          456,
          311,
          572,
          2836,
          17776,
          309,
          484,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 627.8000000000001,
        "id": 243,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 627.02,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51710,
          821,
          321,
          352,
          13,
          51749
        ]
      },
      {
        "avg_logprob": -0.2202204465866089,
        "compression_ratio": 1.588235294117647,
        "end": 629.1800000000001,
        "id": 244,
        "no_speech_prob": 0.00005829121801070869,
        "seek": 60010,
        "start": 627.8000000000001,
        "temperature": 0,
        "text": " I've got three rectangles.",
        "tokens": [
          51749,
          286,
          600,
          658,
          1045,
          24077,
          904,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 631.5,
        "id": 245,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 629.18,
        "temperature": 0,
        "text": " One drawn around the dog, one around the cat,",
        "tokens": [
          50364,
          1485,
          10117,
          926,
          264,
          3000,
          11,
          472,
          926,
          264,
          3857,
          11,
          50480
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 632.6999999999999,
        "id": 246,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 631.5,
        "temperature": 0,
        "text": " and one around the couch.",
        "tokens": [
          50480,
          293,
          472,
          926,
          264,
          16511,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 634.6999999999999,
        "id": 247,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 632.6999999999999,
        "temperature": 0,
        "text": " Let's add the labels just so we can see them.",
        "tokens": [
          50540,
          961,
          311,
          909,
          264,
          16949,
          445,
          370,
          321,
          393,
          536,
          552,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 640.6999999999999,
        "id": 248,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 639.02,
        "temperature": 0,
        "text": " And where do I want to draw it?",
        "tokens": [
          50856,
          400,
          689,
          360,
          286,
          528,
          281,
          2642,
          309,
          30,
          50940
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 642.5799999999999,
        "id": 249,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 640.6999999999999,
        "temperature": 0,
        "text": " The x location, but shift it a little over,",
        "tokens": [
          50940,
          440,
          2031,
          4914,
          11,
          457,
          5513,
          309,
          257,
          707,
          670,
          11,
          51034
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 644.7399999999999,
        "id": 250,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 642.5799999999999,
        "temperature": 0,
        "text": " and the y location, but shift it a little bit down.",
        "tokens": [
          51034,
          293,
          264,
          288,
          4914,
          11,
          457,
          5513,
          309,
          257,
          707,
          857,
          760,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 646.2399999999999,
        "id": 251,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 644.7399999999999,
        "temperature": 0,
        "text": " Maybe I want to put it in the center.",
        "tokens": [
          51142,
          2704,
          286,
          528,
          281,
          829,
          309,
          294,
          264,
          3056,
          13,
          51217
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 647.3399999999999,
        "id": 252,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 646.2399999999999,
        "temperature": 0,
        "text": " There's no rules here.",
        "tokens": [
          51217,
          821,
          311,
          572,
          4474,
          510,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 649.42,
        "id": 253,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 647.3399999999999,
        "temperature": 0,
        "text": " I'm just going to do it however I'm going to do it.",
        "tokens": [
          51272,
          286,
          478,
          445,
          516,
          281,
          360,
          309,
          4461,
          286,
          478,
          516,
          281,
          360,
          309,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 652.4599999999999,
        "id": 254,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 651.8199999999999,
        "temperature": 0,
        "text": " Run it again.",
        "tokens": [
          51496,
          8950,
          309,
          797,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 656.62,
        "id": 255,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 655.38,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51674,
          821,
          321,
          352,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.218792716069008,
        "compression_ratio": 1.8108108108108107,
        "end": 658.8399999999999,
        "id": 256,
        "no_speech_prob": 0.00002392348505964037,
        "seek": 62918,
        "start": 656.62,
        "temperature": 0,
        "text": " Couch, dog, cat.",
        "tokens": [
          51736,
          383,
          2220,
          11,
          3000,
          11,
          3857,
          13,
          51847
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 661.64,
        "id": 257,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 659,
        "temperature": 0,
        "text": " Now, of course, I want to think about visual design",
        "tokens": [
          50372,
          823,
          11,
          295,
          1164,
          11,
          286,
          528,
          281,
          519,
          466,
          5056,
          1715,
          50504
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 662.48,
        "id": 258,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 661.64,
        "temperature": 0,
        "text": " and contrast.",
        "tokens": [
          50504,
          293,
          8712,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 665.36,
        "id": 259,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 662.48,
        "temperature": 0,
        "text": " This isn't the best visualization of it,",
        "tokens": [
          50546,
          639,
          1943,
          380,
          264,
          1151,
          25801,
          295,
          309,
          11,
          50690
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 667.08,
        "id": 260,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 665.36,
        "temperature": 0,
        "text": " but you can see it's working.",
        "tokens": [
          50690,
          457,
          291,
          393,
          536,
          309,
          311,
          1364,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 669.44,
        "id": 261,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 667.08,
        "temperature": 0,
        "text": " Maybe if you're following along, pause this video,",
        "tokens": [
          50776,
          2704,
          498,
          291,
          434,
          3480,
          2051,
          11,
          10465,
          341,
          960,
          11,
          50894
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 671.08,
        "id": 262,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 669.44,
        "temperature": 0,
        "text": " try to add the confidence score.",
        "tokens": [
          50894,
          853,
          281,
          909,
          264,
          6687,
          6175,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 673.36,
        "id": 263,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 671.08,
        "temperature": 0,
        "text": " That's a nice little exercise for you to do.",
        "tokens": [
          50976,
          663,
          311,
          257,
          1481,
          707,
          5380,
          337,
          291,
          281,
          360,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 675.32,
        "id": 264,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 673.36,
        "temperature": 0,
        "text": " Hopefully, you have some creative ideas",
        "tokens": [
          51090,
          10429,
          11,
          291,
          362,
          512,
          5880,
          3487,
          51188
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 678.0400000000001,
        "id": 265,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 675.32,
        "temperature": 0,
        "text": " of how you might want to use this or experiment with this.",
        "tokens": [
          51188,
          295,
          577,
          291,
          1062,
          528,
          281,
          764,
          341,
          420,
          5120,
          365,
          341,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 680.48,
        "id": 266,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 678.0400000000001,
        "temperature": 0,
        "text": " An application that I would imagine you might want to try",
        "tokens": [
          51324,
          1107,
          3861,
          300,
          286,
          576,
          3811,
          291,
          1062,
          528,
          281,
          853,
          51446
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 683.24,
        "id": 267,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 680.48,
        "temperature": 0,
        "text": " is try this model out on a real-time video feed.",
        "tokens": [
          51446,
          307,
          853,
          341,
          2316,
          484,
          322,
          257,
          957,
          12,
          3766,
          960,
          3154,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 685.24,
        "id": 268,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 683.24,
        "temperature": 0,
        "text": " So I have a webcam here on this laptop.",
        "tokens": [
          51584,
          407,
          286,
          362,
          257,
          39490,
          510,
          322,
          341,
          10732,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2115384241577926,
        "compression_ratio": 1.7023809523809523,
        "end": 688.82,
        "id": 269,
        "no_speech_prob": 0.00011235249257879332,
        "seek": 65884,
        "start": 685.24,
        "temperature": 0,
        "text": " I can rewrite this code to use the p5 create capture object.",
        "tokens": [
          51684,
          286,
          393,
          28132,
          341,
          3089,
          281,
          764,
          264,
          280,
          20,
          1884,
          7983,
          2657,
          13,
          51863
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 691.1800000000001,
        "id": 270,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 688.82,
        "temperature": 0,
        "text": " And then pass the video as the thing",
        "tokens": [
          50364,
          400,
          550,
          1320,
          264,
          960,
          382,
          264,
          551,
          50482
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 694.38,
        "id": 271,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 691.1800000000001,
        "temperature": 0,
        "text": " we're looking at into the machine learning model.",
        "tokens": [
          50482,
          321,
          434,
          1237,
          412,
          666,
          264,
          3479,
          2539,
          2316,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 696.98,
        "id": 272,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 694.38,
        "temperature": 0,
        "text": " Same as we did with the MobileNet image classification",
        "tokens": [
          50642,
          10635,
          382,
          321,
          630,
          365,
          264,
          22625,
          31890,
          3256,
          21538,
          50772
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 697.74,
        "id": 273,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 696.98,
        "temperature": 0,
        "text": " examples.",
        "tokens": [
          50772,
          5110,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 699.62,
        "id": 274,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 697.74,
        "temperature": 0,
        "text": " So I'm going to save this code as is,",
        "tokens": [
          50810,
          407,
          286,
          478,
          516,
          281,
          3155,
          341,
          3089,
          382,
          307,
          11,
          50904
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 702.1400000000001,
        "id": 275,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 699.62,
        "temperature": 0,
        "text": " and you'll find it linked in the video's description.",
        "tokens": [
          50904,
          293,
          291,
          603,
          915,
          309,
          9408,
          294,
          264,
          960,
          311,
          3855,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 704.1,
        "id": 276,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 702.1400000000001,
        "temperature": 0,
        "text": " And I'm going to duplicate it and rewrite it",
        "tokens": [
          51030,
          400,
          286,
          478,
          516,
          281,
          23976,
          309,
          293,
          28132,
          309,
          51128
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 705.58,
        "id": 277,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 704.1,
        "temperature": 0,
        "text": " with the capture object.",
        "tokens": [
          51128,
          365,
          264,
          7983,
          2657,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 707.58,
        "id": 278,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 705.58,
        "temperature": 0,
        "text": " Call it webcam.",
        "tokens": [
          51202,
          7807,
          309,
          39490,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 710.0600000000001,
        "id": 279,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 707.58,
        "temperature": 0,
        "text": " Comment out the image and add a video instead.",
        "tokens": [
          51302,
          16328,
          484,
          264,
          3256,
          293,
          909,
          257,
          960,
          2602,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.22119226870329484,
        "compression_ratio": 1.640316205533597,
        "end": 717.1800000000001,
        "id": 280,
        "no_speech_prob": 0.00018814094073604792,
        "seek": 68882,
        "start": 714.9000000000001,
        "temperature": 0,
        "text": " I need a draw function because now I'm",
        "tokens": [
          51668,
          286,
          643,
          257,
          2642,
          2445,
          570,
          586,
          286,
          478,
          51782
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 719.4599999999999,
        "id": 281,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 717.2199999999999,
        "temperature": 0,
        "text": " going to be looping and drawing every frame of the video",
        "tokens": [
          50366,
          516,
          281,
          312,
          6367,
          278,
          293,
          6316,
          633,
          3920,
          295,
          264,
          960,
          50478
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 720.18,
        "id": 282,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 719.4599999999999,
        "temperature": 0,
        "text": " in real time.",
        "tokens": [
          50478,
          294,
          957,
          565,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 727.06,
        "id": 283,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 723.0999999999999,
        "temperature": 0,
        "text": " Let's make sure the video is the same size as the canvas.",
        "tokens": [
          50660,
          961,
          311,
          652,
          988,
          264,
          960,
          307,
          264,
          912,
          2744,
          382,
          264,
          16267,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 729.3399999999999,
        "id": 284,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 727.06,
        "temperature": 0,
        "text": " And let's run this and see what happens.",
        "tokens": [
          50858,
          400,
          718,
          311,
          1190,
          341,
          293,
          536,
          437,
          2314,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 731.06,
        "id": 285,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 729.3399999999999,
        "temperature": 0,
        "text": " So I see my video there.",
        "tokens": [
          50972,
          407,
          286,
          536,
          452,
          960,
          456,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 734.14,
        "id": 286,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 731.06,
        "temperature": 0,
        "text": " I console log the detections, but I only detected things once",
        "tokens": [
          51058,
          286,
          11076,
          3565,
          264,
          5531,
          626,
          11,
          457,
          286,
          787,
          21896,
          721,
          1564,
          51212
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 735.4599999999999,
        "id": 287,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 734.14,
        "temperature": 0,
        "text": " and I found nothing.",
        "tokens": [
          51212,
          293,
          286,
          1352,
          1825,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 736.78,
        "id": 288,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 735.4599999999999,
        "temperature": 0,
        "text": " Why is that?",
        "tokens": [
          51278,
          1545,
          307,
          300,
          30,
          51344
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 742.2199999999999,
        "id": 289,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 736.78,
        "temperature": 0,
        "text": " That's because I called detect in setup with the video once,",
        "tokens": [
          51344,
          663,
          311,
          570,
          286,
          1219,
          5531,
          294,
          8657,
          365,
          264,
          960,
          1564,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.22008840661299856,
        "compression_ratio": 1.6764705882352942,
        "end": 744.9799999999999,
        "id": 290,
        "no_speech_prob": 0.0008830426377244294,
        "seek": 71718,
        "start": 742.2199999999999,
        "temperature": 0,
        "text": " got the results, and never called detect again.",
        "tokens": [
          51616,
          658,
          264,
          3542,
          11,
          293,
          1128,
          1219,
          5531,
          797,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 748.9,
        "id": 291,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 744.98,
        "temperature": 0,
        "text": " So now I need to create this kind of loop system",
        "tokens": [
          50364,
          407,
          586,
          286,
          643,
          281,
          1884,
          341,
          733,
          295,
          6367,
          1185,
          50560
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 752.74,
        "id": 292,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 748.9,
        "temperature": 0,
        "text": " where I first call detect, I get the detections,",
        "tokens": [
          50560,
          689,
          286,
          700,
          818,
          5531,
          11,
          286,
          483,
          264,
          5531,
          626,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 756.74,
        "id": 293,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 752.74,
        "temperature": 0,
        "text": " and once I've gotten the detections, let's call it",
        "tokens": [
          50752,
          293,
          1564,
          286,
          600,
          5768,
          264,
          5531,
          626,
          11,
          718,
          311,
          818,
          309,
          50952
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 759.38,
        "id": 294,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 756.74,
        "temperature": 0,
        "text": " again.",
        "tokens": [
          50952,
          797,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 761.0600000000001,
        "id": 295,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 759.38,
        "temperature": 0,
        "text": " Oh, why did I say object?",
        "tokens": [
          51084,
          876,
          11,
          983,
          630,
          286,
          584,
          2657,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 763.94,
        "id": 296,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 761.0600000000001,
        "temperature": 0,
        "text": " I should be saying detector.",
        "tokens": [
          51168,
          286,
          820,
          312,
          1566,
          25712,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 766.46,
        "id": 297,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 763.94,
        "temperature": 0,
        "text": " And look, it's recognizing me.",
        "tokens": [
          51312,
          400,
          574,
          11,
          309,
          311,
          18538,
          385,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 769.22,
        "id": 298,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 766.46,
        "temperature": 0,
        "text": " Now, I don't love the way that I've written this",
        "tokens": [
          51438,
          823,
          11,
          286,
          500,
          380,
          959,
          264,
          636,
          300,
          286,
          600,
          3720,
          341,
          51576
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 772.46,
        "id": 299,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 769.22,
        "temperature": 0,
        "text": " because drawing the results here outside of draw",
        "tokens": [
          51576,
          570,
          6316,
          264,
          3542,
          510,
          2380,
          295,
          2642,
          51738
        ]
      },
      {
        "avg_logprob": -0.22020083402110413,
        "compression_ratio": 1.6188524590163935,
        "end": 774.94,
        "id": 300,
        "no_speech_prob": 0.000017778525943867862,
        "seek": 74498,
        "start": 772.46,
        "temperature": 0,
        "text": " and it happening in this sort of like separate sequence",
        "tokens": [
          51738,
          293,
          309,
          2737,
          294,
          341,
          1333,
          295,
          411,
          4994,
          8310,
          51862
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 777.3800000000001,
        "id": 301,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 775.9000000000001,
        "temperature": 0,
        "text": " is a little bit prone to error.",
        "tokens": [
          50412,
          307,
          257,
          707,
          857,
          25806,
          281,
          6713,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 780.0600000000001,
        "id": 302,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 777.3800000000001,
        "temperature": 0,
        "text": " So I want to just adjust the way I'm doing this.",
        "tokens": [
          50486,
          407,
          286,
          528,
          281,
          445,
          4369,
          264,
          636,
          286,
          478,
          884,
          341,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 782.6600000000001,
        "id": 303,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 780.0600000000001,
        "temperature": 0,
        "text": " I'm going to take this loop and I'm",
        "tokens": [
          50620,
          286,
          478,
          516,
          281,
          747,
          341,
          6367,
          293,
          286,
          478,
          50750
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 784.74,
        "id": 304,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 782.6600000000001,
        "temperature": 0,
        "text": " going to put it into draw.",
        "tokens": [
          50750,
          516,
          281,
          829,
          309,
          666,
          2642,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 787.3800000000001,
        "id": 305,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 784.74,
        "temperature": 0,
        "text": " This way I know my drawing sequence is always",
        "tokens": [
          50854,
          639,
          636,
          286,
          458,
          452,
          6316,
          8310,
          307,
          1009,
          50986
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 788.7800000000001,
        "id": 306,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 787.3800000000001,
        "temperature": 0,
        "text": " happening in the right order.",
        "tokens": [
          50986,
          2737,
          294,
          264,
          558,
          1668,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 791.1,
        "id": 307,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 788.7800000000001,
        "temperature": 0,
        "text": " Draw the video, draw the results on top of it.",
        "tokens": [
          51056,
          20386,
          264,
          960,
          11,
          2642,
          264,
          3542,
          322,
          1192,
          295,
          309,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 792.86,
        "id": 308,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 791.1,
        "temperature": 0,
        "text": " But this isn't where I got the results.",
        "tokens": [
          51172,
          583,
          341,
          1943,
          380,
          689,
          286,
          658,
          264,
          3542,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 796.1,
        "id": 309,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 792.86,
        "temperature": 0,
        "text": " Where I got the results is in the got detections function.",
        "tokens": [
          51260,
          2305,
          286,
          658,
          264,
          3542,
          307,
          294,
          264,
          658,
          5531,
          626,
          2445,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 797.94,
        "id": 310,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 796.1,
        "temperature": 0,
        "text": " So I'll just use a global variable",
        "tokens": [
          51422,
          407,
          286,
          603,
          445,
          764,
          257,
          4338,
          7006,
          51514
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 800.58,
        "id": 311,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 797.94,
        "temperature": 0,
        "text": " here to sort of link those two things.",
        "tokens": [
          51514,
          510,
          281,
          1333,
          295,
          2113,
          729,
          732,
          721,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.1938315858232214,
        "compression_ratio": 1.8029739776951672,
        "end": 803.86,
        "id": 312,
        "no_speech_prob": 0.00004331891977926716,
        "seek": 77494,
        "start": 800.58,
        "temperature": 0,
        "text": " So let's create a variable called detections.",
        "tokens": [
          51646,
          407,
          718,
          311,
          1884,
          257,
          7006,
          1219,
          5531,
          626,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 806.1800000000001,
        "id": 313,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 803.86,
        "temperature": 0,
        "text": " I'm going to make it an empty array to start.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          652,
          309,
          364,
          6707,
          10225,
          281,
          722,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 809.1,
        "id": 314,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 806.1800000000001,
        "temperature": 0,
        "text": " Then in the got detections function,",
        "tokens": [
          50480,
          1396,
          294,
          264,
          658,
          5531,
          626,
          2445,
          11,
          50626
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 812.5,
        "id": 315,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 809.1,
        "temperature": 0,
        "text": " I will just set detections equal to the results.",
        "tokens": [
          50626,
          286,
          486,
          445,
          992,
          5531,
          626,
          2681,
          281,
          264,
          3542,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 813.86,
        "id": 316,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 812.5,
        "temperature": 0,
        "text": " So now it's a global variable that",
        "tokens": [
          50796,
          407,
          586,
          309,
          311,
          257,
          4338,
          7006,
          300,
          50864
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 815.98,
        "id": 317,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 813.86,
        "temperature": 0,
        "text": " gets set whenever there are new detections.",
        "tokens": [
          50864,
          2170,
          992,
          5699,
          456,
          366,
          777,
          5531,
          626,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 817.86,
        "id": 318,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 815.98,
        "temperature": 0,
        "text": " And whatever the latest detections are,",
        "tokens": [
          50970,
          400,
          2035,
          264,
          6792,
          5531,
          626,
          366,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 822.86,
        "id": 319,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 817.86,
        "temperature": 0,
        "text": " they'll always be drawn in draw by me adding detections here.",
        "tokens": [
          51064,
          436,
          603,
          1009,
          312,
          10117,
          294,
          2642,
          538,
          385,
          5127,
          5531,
          626,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 824.58,
        "id": 320,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 822.86,
        "temperature": 0,
        "text": " Let's run this and let's see if I can get",
        "tokens": [
          51314,
          961,
          311,
          1190,
          341,
          293,
          718,
          311,
          536,
          498,
          286,
          393,
          483,
          51400
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 826.72,
        "id": 321,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 824.58,
        "temperature": 0,
        "text": " some object detecting going.",
        "tokens": [
          51400,
          512,
          2657,
          40237,
          516,
          13,
          51507
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 828.74,
        "id": 322,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 826.72,
        "temperature": 0,
        "text": " Oh, boy, things froze.",
        "tokens": [
          51507,
          876,
          11,
          3237,
          11,
          721,
          46077,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 829.38,
        "id": 323,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 828.74,
        "temperature": 0,
        "text": " Error.",
        "tokens": [
          51608,
          3300,
          2874,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.19749410133662187,
        "compression_ratio": 1.6412213740458015,
        "end": 830.74,
        "id": 324,
        "no_speech_prob": 0.000048325546231353655,
        "seek": 80386,
        "start": 829.38,
        "temperature": 0,
        "text": " What went wrong?",
        "tokens": [
          51640,
          708,
          1437,
          2085,
          30,
          51708
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 832.66,
        "id": 325,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 830.74,
        "temperature": 0,
        "text": " Results is not defined.",
        "tokens": [
          50364,
          5015,
          33361,
          307,
          406,
          7642,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 834.94,
        "id": 326,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 832.66,
        "temperature": 0,
        "text": " Sketch line 33.",
        "tokens": [
          50460,
          49245,
          1622,
          11816,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 838.22,
        "id": 327,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 834.94,
        "temperature": 0,
        "text": " Oh, detections is the global variable.",
        "tokens": [
          50574,
          876,
          11,
          5531,
          626,
          307,
          264,
          4338,
          7006,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 839.86,
        "id": 328,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 838.22,
        "temperature": 0,
        "text": " But I'm still using results here.",
        "tokens": [
          50738,
          583,
          286,
          478,
          920,
          1228,
          3542,
          510,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 843.82,
        "id": 329,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 839.86,
        "temperature": 0,
        "text": " I need to change that also to detections.",
        "tokens": [
          50820,
          286,
          643,
          281,
          1319,
          300,
          611,
          281,
          5531,
          626,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 845.7,
        "id": 330,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 843.82,
        "temperature": 0,
        "text": " Notice how when the error happened,",
        "tokens": [
          51018,
          13428,
          577,
          562,
          264,
          6713,
          2011,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 848.1800000000001,
        "id": 331,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 845.7,
        "temperature": 0,
        "text": " the sort of video element is still going.",
        "tokens": [
          51112,
          264,
          1333,
          295,
          960,
          4478,
          307,
          920,
          516,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 850.44,
        "id": 332,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 848.1800000000001,
        "temperature": 0,
        "text": " But the canvas where I'm separately drawing the video",
        "tokens": [
          51236,
          583,
          264,
          16267,
          689,
          286,
          478,
          14759,
          6316,
          264,
          960,
          51349
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 851.46,
        "id": 333,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 850.44,
        "temperature": 0,
        "text": " got frozen.",
        "tokens": [
          51349,
          658,
          12496,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 853.62,
        "id": 334,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 851.46,
        "temperature": 0,
        "text": " I probably only want to see one of those.",
        "tokens": [
          51400,
          286,
          1391,
          787,
          528,
          281,
          536,
          472,
          295,
          729,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 856.7,
        "id": 335,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 853.62,
        "temperature": 0,
        "text": " So I don't need to see the original video element.",
        "tokens": [
          51508,
          407,
          286,
          500,
          380,
          643,
          281,
          536,
          264,
          3380,
          960,
          4478,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.23034811401367186,
        "compression_ratio": 1.65,
        "end": 859.78,
        "id": 336,
        "no_speech_prob": 0.00011061139957746491,
        "seek": 83074,
        "start": 856.7,
        "temperature": 0,
        "text": " I can call video.hide to remove that.",
        "tokens": [
          51662,
          286,
          393,
          818,
          960,
          13,
          71,
          482,
          281,
          4159,
          300,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 861.3399999999999,
        "id": 337,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 859.8199999999999,
        "temperature": 0,
        "text": " Run it again.",
        "tokens": [
          50366,
          8950,
          309,
          797,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 863.98,
        "id": 338,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 861.3399999999999,
        "temperature": 0,
        "text": " All right, person, cell phone.",
        "tokens": [
          50442,
          1057,
          558,
          11,
          954,
          11,
          2815,
          2593,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 866.22,
        "id": 339,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 863.98,
        "temperature": 0,
        "text": " Oh, it still sees me.",
        "tokens": [
          50574,
          876,
          11,
          309,
          920,
          8194,
          385,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 866.9,
        "id": 340,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 866.22,
        "temperature": 0,
        "text": " How about book?",
        "tokens": [
          50686,
          1012,
          466,
          1446,
          30,
          50720
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 868.98,
        "id": 341,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 866.9,
        "temperature": 0,
        "text": " This is a book that I'm currently reading.",
        "tokens": [
          50720,
          639,
          307,
          257,
          1446,
          300,
          286,
          478,
          4362,
          3760,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 871.06,
        "id": 342,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 868.98,
        "temperature": 0,
        "text": " It's called Weapons of Math Destruction,",
        "tokens": [
          50824,
          467,
          311,
          1219,
          492,
          48071,
          295,
          15776,
          16339,
          3826,
          11,
          50928
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 873.62,
        "id": 343,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 871.06,
        "temperature": 0,
        "text": " also highly recommended when thinking about algorithms",
        "tokens": [
          50928,
          611,
          5405,
          9628,
          562,
          1953,
          466,
          14642,
          51056
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 875.18,
        "id": 344,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 873.62,
        "temperature": 0,
        "text": " and machine learning.",
        "tokens": [
          51056,
          293,
          3479,
          2539,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 877.9399999999999,
        "id": 345,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 875.18,
        "temperature": 0,
        "text": " I happen to have a paintbrush.",
        "tokens": [
          51134,
          286,
          1051,
          281,
          362,
          257,
          4225,
          21330,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 879.26,
        "id": 346,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 877.9399999999999,
        "temperature": 0,
        "text": " Scissors, baseball bat.",
        "tokens": [
          51272,
          2747,
          13839,
          11,
          14323,
          7362,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 880.74,
        "id": 347,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 879.26,
        "temperature": 0,
        "text": " OK, batter up.",
        "tokens": [
          51338,
          2264,
          11,
          4220,
          493,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 886.3,
        "id": 348,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 880.74,
        "temperature": 0,
        "text": " All right, so you get the idea.",
        "tokens": [
          51412,
          1057,
          558,
          11,
          370,
          291,
          483,
          264,
          1558,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.24204043852977264,
        "compression_ratio": 1.5019762845849802,
        "end": 887.6999999999999,
        "id": 349,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 85978,
        "start": 886.3,
        "temperature": 0,
        "text": " Something that I might want to add",
        "tokens": [
          51690,
          6595,
          300,
          286,
          1062,
          528,
          281,
          909,
          51760
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 890.74,
        "id": 350,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 887.7,
        "temperature": 0,
        "text": " to this is some kind of debouncing or interpolation.",
        "tokens": [
          50364,
          281,
          341,
          307,
          512,
          733,
          295,
          3001,
          1733,
          2175,
          420,
          44902,
          399,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 893.86,
        "id": 351,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 890.74,
        "temperature": 0,
        "text": " You can see that it's very, very, very noisy.",
        "tokens": [
          50516,
          509,
          393,
          536,
          300,
          309,
          311,
          588,
          11,
          588,
          11,
          588,
          24518,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 896.1800000000001,
        "id": 352,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 893.86,
        "temperature": 0,
        "text": " So that's something that I will also",
        "tokens": [
          50672,
          407,
          300,
          311,
          746,
          300,
          286,
          486,
          611,
          50788
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 898.46,
        "id": 353,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 896.1800000000001,
        "temperature": 0,
        "text": " include some references for in the video's description,",
        "tokens": [
          50788,
          4090,
          512,
          15400,
          337,
          294,
          264,
          960,
          311,
          3855,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 901.0200000000001,
        "id": 354,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 898.46,
        "temperature": 0,
        "text": " maybe even an extra example that adds that.",
        "tokens": [
          50902,
          1310,
          754,
          364,
          2857,
          1365,
          300,
          10860,
          300,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 902.62,
        "id": 355,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 901.0200000000001,
        "temperature": 0,
        "text": " But this wraps up this video.",
        "tokens": [
          51030,
          583,
          341,
          25831,
          493,
          341,
          960,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 904.46,
        "id": 356,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 902.62,
        "temperature": 0,
        "text": " So thank you for watching this video tutorial",
        "tokens": [
          51110,
          407,
          1309,
          291,
          337,
          1976,
          341,
          960,
          7073,
          51202
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 906.5400000000001,
        "id": 357,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 904.46,
        "temperature": 0,
        "text": " on the ML5 object detector.",
        "tokens": [
          51202,
          322,
          264,
          21601,
          20,
          2657,
          25712,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 908.9200000000001,
        "id": 358,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 906.5400000000001,
        "temperature": 0,
        "text": " If you have some creative ideas or things you want to try,",
        "tokens": [
          51306,
          759,
          291,
          362,
          512,
          5880,
          3487,
          420,
          721,
          291,
          528,
          281,
          853,
          11,
          51425
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 909.58,
        "id": 359,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 908.9200000000001,
        "temperature": 0,
        "text": " let me know.",
        "tokens": [
          51425,
          718,
          385,
          458,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 910.9000000000001,
        "id": 360,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 909.58,
        "temperature": 0,
        "text": " Write something in the comments.",
        "tokens": [
          51458,
          23499,
          746,
          294,
          264,
          3053,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 912.7,
        "id": 361,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 910.9000000000001,
        "temperature": 0,
        "text": " And you can also go to the Coding Train web",
        "tokens": [
          51524,
          400,
          291,
          393,
          611,
          352,
          281,
          264,
          383,
          8616,
          28029,
          3670,
          51614
        ]
      },
      {
        "avg_logprob": -0.2658442405805196,
        "compression_ratio": 1.7301587301587302,
        "end": 915.98,
        "id": 362,
        "no_speech_prob": 0.014502000994980335,
        "seek": 88770,
        "start": 912.7,
        "temperature": 0,
        "text": " page associated with this video and submit your creative",
        "tokens": [
          51614,
          3028,
          6615,
          365,
          341,
          960,
          293,
          10315,
          428,
          5880,
          51778
        ]
      },
      {
        "avg_logprob": -0.40783004760742186,
        "compression_ratio": 1.0204081632653061,
        "end": 918.22,
        "id": 363,
        "no_speech_prob": 0.000597650941926986,
        "seek": 91598,
        "start": 915.98,
        "temperature": 0.2,
        "text": " examples and experiments there.",
        "tokens": [
          50364,
          5110,
          293,
          12050,
          456,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.40783004760742186,
        "compression_ratio": 1.0204081632653061,
        "end": 921.46,
        "id": 364,
        "no_speech_prob": 0.000597650941926986,
        "seek": 91598,
        "start": 918.22,
        "temperature": 0.2,
        "text": " Thanks for watching, and I'll see you in another ML5 video.",
        "tokens": [
          50476,
          2561,
          337,
          1976,
          11,
          293,
          286,
          603,
          536,
          291,
          294,
          1071,
          21601,
          20,
          960,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.40783004760742186,
        "compression_ratio": 1.0204081632653061,
        "end": 922.34,
        "id": 365,
        "no_speech_prob": 0.000597650941926986,
        "seek": 91598,
        "start": 921.46,
        "temperature": 0.2,
        "text": " Goodbye.",
        "tokens": [
          50638,
          15528,
          13,
          50682
        ]
      }
    ],
    "transcription": " Hi, everyone. Welcome to another ml5.js video. In this video, I am going to talk about the object detector in ml5, which is a new feature as of 0.5.0. So you want to make sure you are on at least that version before you get started and try the same code that I'm about to demonstrate to you. What do I mean by object detection? So far, I have covered image classification, meaning we have an image. Maybe it has a cat in it. And when that image is sent into the machine learning model, in the case of the previous examples, a model called MobileNet, I get back a list of labels and confidence scores. And most likely in this case, I would get the label cat with hopefully a confidence score of something like 95%. There might be some other guesses with lower confidence scores, but ultimately, the goal is to have a single classification, a single label come out and be assigned as the result of the prediction of this image. Now, what happens in the case of object detection? Let's say I have this same image. An object detection model will not only label something in the image, but give a bounding box as to where that object it detects is. So instead of just saying this image is classified as cat, an object detection model will say in this image, there is an object of type cat that is located at a particular xy location with a particular width and a particular height. The model will also return a confidence score for how certain it is that there is a cat at this exact location. So maybe that would also be something like 95%. And what's special about object detection, instead of just classifying the image with one label, here, if you're detecting an object in an image, it could detect more than one thing. So maybe there's also, I don't know, I'm drawing the rest of the cat. Maybe there's also a dog. There's my dog. If the image is of a cat and a dog, we could get two bounding boxes. A second one with the label dog and another x, y, width, and height for its bounding box. And right here on the ml5 reference page, we can see an example of this. Here's an image of a cat. The bounding box is marked. The label cat is indicated along with the confidence score here of 65.41%. Now, this doesn't happen by magic. This happens because there is a pre-trained model that presumably has been trained already many images of cats and dogs with those bounding boxes marked and labeled. How does a data set like that even exist? Something new that is now in the ml5 documentation is a section called Model and Data Providence. You'll find this for every single pre-trained model that's in the ml5 library. This is a project that's been started by Ellen Nichols. And I encourage you to click the link to find out more about Ellen and her work on Model and Data Providence. And what she has done here is created model biographies and data biographies. Anytime you're using a machine learning model, you want to ask yourself the question, what data was used to train this model? Who trained this model? In what context and for what reasons? Anytime you're going to use a pre-trained model on a project, you want to think about the ethical implications of where that model came from and how you're using it. And researching into the biography, so to speak, of the data behind the model and the model itself is incredibly important when considering those kinds of questions. In this case, the data set behind the object detection model that I'm going to use is a data set called COCO. COCO, or Common Objects in Context, is a large scale object detection, segmentation, and captioning data set. So before you watch the rest of this video, I would pause. Go to the COCO data set website. Click Explore and poke around a little bit. Also in this video series, you'll find videos about the PoseNet pre-trained model. In COCO, in addition to the object detection data, there's also a set of 200,000 images with 250,000 instances of people labeled with particular key points on their body. COCO also includes image segmentation, which is a very similar concept to object detection, but instead of a particular bounding box, every single pixel is labeled as part of a particular category. So there are all the pixels for the giraffe versus the pixels for the clouds in the sky, and so on and so forth. I also want to suggest to you two readings if you're interested in learning more about data sets for machine learning. The Humans of AI project by Philip Schmidt is a project that explores specifically the COCO image data set. And you can learn a lot more about where did those images come from, who took those photos, and how Philip Schmidt puts it, exposing the myth of magically intelligent machines. I also would highly suggest reading Excavating AI, the Politics of Images in Machine Learning Training Sets by Kate Crawford and Trevor Paglen. This essay explores the ImageNet database, another very well known image database that is the data set behind the MobileNet model, which serves as the foundation for many of the ML5 image classification and transfer learning examples that are throughout this particular playlist. Circling back to ML5, if you use the object detector, there are two pre-trained models you can select from at present. Hopefully, in the future, maybe you'll even train your own model or will be able to incorporate other open source object detection models. But right now, there's YOLO, which stands for You Only Look Once, and COCOSD. In this video, I'm going to demonstrate using COCOSD, but I encourage you to explore and experiment and do your research about the YOLO model as well. The COCOSSD model comes from TensorFlow. So there's the TensorFlow.js port of the TensorFlow COCOSSD model. That's what ML5 is using. Certainly, on the GitHub page for that model, you can find code for using it in JavaScript without the ML5 library that you could explore, as well as more background about how it was trained and what it does. Now, one thing I'll note is it only detects 80 classes of object, not a huge number if you think about it. You can find that list of labels as part of the ML5 materials themselves as well. All right, it's time to write some code. The first thing that I want to do is have an image to try to detect objects in. There we go. So I've made a simple P5 sketch that uses the preload function to load a particular image that I've uploaded to the P5 web editor. And in the setup function, I'm making a canvas and drawing that image. You might recognize Gloria Pickle from my Coding in the Cabana series, along with her good friend, Greta Goose. Unfortunately, Evie Mango is not pictured here, but you can learn more about them on their Instagram, which I'll link to in the video's description. Now that I've got my image, I'm going Now that I've got my image, the next step is for me to load the CocoaSD model itself. For this basic example, I'm making heavy use of the preload function, which allows me to load images and pre-trained models without any callbacks. And everything is ready to go once I get to the setup function. But certainly in other contexts, you might want to use a callback or write your code in a different way. And you'll find all of that in the actual official ML5 examples themselves. Let's double check that things are working correctly by just console logging the detector object. Oh, and I should put that in setup to see that it's loaded properly. Whoops. By accident, I put a capital O there. It should be lowercase o, object detector. The console isn't necessarily going to show us anything useful here, just a lot of the stuff that's part of that detector object in ML5. But it's more clear for us to look at the documentation than see what's logged here in the console. I happen to know that what I need to do is call detector.predict, pass it the image, and then a callback for when I've got the detections. So I'll say gotDetections as the name of my callback function. Let's write that function. And let's log the results. So this is the same pattern in many other ML5 pre-trained models. Load the model, call predict, get a result, error first in the callback in case there's an error. And maybe I should check for that. And then do something with the results. I just want to log them right now. Detector.predict is not a function. Oops. Looking at the documentation, the function is not predict. It's detect. So predict is a general word for when you want to ask a machine learning model to give you the output associated with a given input. But in this specific case, the ML5 function is named detect because it's a more descriptive word of what we're actually doing. I'm going to change this to detect. Let's also comment out this unnecessary console log and run it again. Aha, look at this. Three objects. OK, there is a cat. There is a dog. What's the third one? It's something in this list of 80 things. Did you see it there? Object 0 is the dog. Here's the confidence score and the x, y width and height. It also looks like it gives you something called normalized, which are probably all of these values, but mapped to a range between 0 and 1. Object 1 is the couch. It detected the couch. And then object 3, I'm going to assume, is the cat. Let's draw those bounding boxes. So I can write a loop to look at all of the elements of the array. And of course, there's countless other ways you can do this with different types of array functionality. But this simplest way, I'll just say let object equals results index i. Let's first just draw the bounding box at object x, object y with the width and height. Let's give it a sort of distinctive color just so it really is emphasized with a given thickness. And make sure there's no fill blocking it out. There we go. I've got three rectangles. One drawn around the dog, one around the cat, and one around the couch. Let's add the labels just so we can see them. And where do I want to draw it? The x location, but shift it a little over, and the y location, but shift it a little bit down. Maybe I want to put it in the center. There's no rules here. I'm just going to do it however I'm going to do it. Run it again. There we go. Couch, dog, cat. Now, of course, I want to think about visual design and contrast. This isn't the best visualization of it, but you can see it's working. Maybe if you're following along, pause this video, try to add the confidence score. That's a nice little exercise for you to do. Hopefully, you have some creative ideas of how you might want to use this or experiment with this. An application that I would imagine you might want to try is try this model out on a real-time video feed. So I have a webcam here on this laptop. I can rewrite this code to use the p5 create capture object. And then pass the video as the thing we're looking at into the machine learning model. Same as we did with the MobileNet image classification examples. So I'm going to save this code as is, and you'll find it linked in the video's description. And I'm going to duplicate it and rewrite it with the capture object. Call it webcam. Comment out the image and add a video instead. I need a draw function because now I'm going to be looping and drawing every frame of the video in real time. Let's make sure the video is the same size as the canvas. And let's run this and see what happens. So I see my video there. I console log the detections, but I only detected things once and I found nothing. Why is that? That's because I called detect in setup with the video once, got the results, and never called detect again. So now I need to create this kind of loop system where I first call detect, I get the detections, and once I've gotten the detections, let's call it again. Oh, why did I say object? I should be saying detector. And look, it's recognizing me. Now, I don't love the way that I've written this because drawing the results here outside of draw and it happening in this sort of like separate sequence is a little bit prone to error. So I want to just adjust the way I'm doing this. I'm going to take this loop and I'm going to put it into draw. This way I know my drawing sequence is always happening in the right order. Draw the video, draw the results on top of it. But this isn't where I got the results. Where I got the results is in the got detections function. So I'll just use a global variable here to sort of link those two things. So let's create a variable called detections. I'm going to make it an empty array to start. Then in the got detections function, I will just set detections equal to the results. So now it's a global variable that gets set whenever there are new detections. And whatever the latest detections are, they'll always be drawn in draw by me adding detections here. Let's run this and let's see if I can get some object detecting going. Oh, boy, things froze. Error. What went wrong? Results is not defined. Sketch line 33. Oh, detections is the global variable. But I'm still using results here. I need to change that also to detections. Notice how when the error happened, the sort of video element is still going. But the canvas where I'm separately drawing the video got frozen. I probably only want to see one of those. So I don't need to see the original video element. I can call video.hide to remove that. Run it again. All right, person, cell phone. Oh, it still sees me. How about book? This is a book that I'm currently reading. It's called Weapons of Math Destruction, also highly recommended when thinking about algorithms and machine learning. I happen to have a paintbrush. Scissors, baseball bat. OK, batter up. All right, so you get the idea. Something that I might want to add to this is some kind of debouncing or interpolation. You can see that it's very, very, very noisy. So that's something that I will also include some references for in the video's description, maybe even an extra example that adds that. But this wraps up this video. So thank you for watching this video tutorial on the ML5 object detector. If you have some creative ideas or things you want to try, let me know. Write something in the comments. And you can also go to the Coding Train web page associated with this video and submit your creative examples and experiments there. Thanks for watching, and I'll see you in another ML5 video. Goodbye.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:35.753307Z",
  "started_at": "2023-09-26T21:15:38.937487Z",
  "completed_at": "2023-09-26T21:20:10.706965Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=QEzRxnuaZCk",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 271.769478
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/w3qa4yzbo7rag2y6zbxp5c7xke/cancel",
    "get": "https://api.replicate.com/v1/predictions/w3qa4yzbo7rag2y6zbxp5c7xke"
  }
}