{
  "id": "ek3wtdzbdzjls437xhwy5xpvuq",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/dLp10CFIvxI.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/262420 [00:00<?, ?frames/s]\n  1%|          | 2958/262420 [00:09<13:33, 319.14frames/s]\n  2%|▏         | 5794/262420 [00:17<13:01, 328.17frames/s]\n  3%|▎         | 8792/262420 [00:26<12:34, 336.21frames/s]\n  4%|▍         | 11430/262420 [00:32<11:36, 360.20frames/s]\n  5%|▌         | 14430/262420 [00:40<11:11, 369.58frames/s]\n  7%|▋         | 17296/262420 [00:47<10:42, 381.26frames/s]\n  8%|▊         | 20296/262420 [00:56<11:04, 364.47frames/s]\n  9%|▉         | 23294/262420 [01:05<11:10, 356.60frames/s]\n 10%|▉         | 26234/262420 [01:14<11:28, 343.03frames/s]\n 11%|█         | 29234/262420 [01:21<10:36, 366.16frames/s]\n 12%|█▏        | 31954/262420 [01:28<10:26, 367.78frames/s]\n 13%|█▎        | 34904/262420 [01:37<10:38, 356.19frames/s]\n 14%|█▍        | 37888/262420 [01:46<10:45, 348.02frames/s]\n 16%|█▌        | 40844/262420 [01:56<11:04, 333.67frames/s]\n 17%|█▋        | 43664/262420 [02:04<10:37, 343.25frames/s]\n 18%|█▊        | 46652/262420 [02:11<10:03, 357.27frames/s]\n 19%|█▉        | 49336/262420 [02:21<10:35, 335.53frames/s]\n 20%|█▉        | 52304/262420 [02:29<10:09, 344.91frames/s]\n 21%|██        | 55196/262420 [02:36<09:33, 361.29frames/s]\n 22%|██▏       | 57784/262420 [02:46<10:26, 326.57frames/s]\n 23%|██▎       | 60422/262420 [02:52<09:38, 349.19frames/s]\n 24%|██▍       | 63374/262420 [02:58<08:49, 376.12frames/s]\n 25%|██▌       | 66250/262420 [03:07<09:10, 356.45frames/s]\n 26%|██▋       | 69022/262420 [03:17<09:38, 334.57frames/s]\n 27%|██▋       | 71986/262420 [03:24<08:58, 353.72frames/s]\n 29%|██▊       | 74922/262420 [03:34<09:25, 331.68frames/s]\n 30%|██▉       | 77782/262420 [03:44<09:29, 324.06frames/s]\n 31%|███       | 80734/262420 [03:53<09:30, 318.51frames/s]\n 32%|███▏      | 83622/262420 [04:00<08:46, 339.79frames/s]\n 33%|███▎      | 86498/262420 [04:08<08:21, 350.44frames/s]\n 34%|███▍      | 89138/262420 [04:15<07:56, 363.47frames/s]\n 35%|███▍      | 91820/262420 [04:20<07:04, 401.65frames/s]\n 36%|███▌      | 94820/262420 [04:28<07:06, 393.08frames/s]\n 37%|███▋      | 97792/262420 [04:36<07:08, 384.37frames/s]\n 38%|███▊      | 100392/262420 [04:42<06:50, 394.40frames/s]\n 39%|███▉      | 103288/262420 [04:49<06:47, 390.35frames/s]\n 40%|████      | 106000/262420 [04:56<06:41, 389.77frames/s]\n 42%|████▏     | 108948/262420 [05:04<06:30, 392.96frames/s]\n 42%|████▏     | 111416/262420 [05:08<05:53, 426.89frames/s]\n 44%|████▎     | 114276/262420 [05:14<05:36, 440.23frames/s]\n 45%|████▍     | 117224/262420 [05:26<06:43, 360.02frames/s]\n 46%|████▌     | 120208/262420 [05:37<07:23, 320.64frames/s]\n 47%|████▋     | 123064/262420 [05:45<06:51, 338.90frames/s]\n 48%|████▊     | 125650/262420 [05:52<06:44, 338.22frames/s]\n 49%|████▉     | 128638/262420 [06:00<06:26, 346.11frames/s]\n 50%|█████     | 131506/262420 [06:10<06:30, 335.17frames/s]\n 51%|█████     | 134010/262420 [06:17<06:19, 338.12frames/s]\n 52%|█████▏    | 136970/262420 [06:25<06:01, 346.76frames/s]\n 53%|█████▎    | 139746/262420 [06:34<06:04, 336.94frames/s]\n 54%|█████▍    | 142706/262420 [06:41<05:30, 362.59frames/s]\n 55%|█████▌    | 145362/262420 [06:48<05:30, 354.70frames/s]\n 56%|█████▋    | 148174/262420 [06:56<05:11, 366.29frames/s]\n 58%|█████▊    | 151174/262420 [07:02<04:48, 385.99frames/s]\n 58%|█████▊    | 153506/262420 [07:10<05:00, 362.56frames/s]\n 60%|█████▉    | 156506/262420 [07:16<04:30, 391.54frames/s]\n 61%|██████    | 159506/262420 [07:24<04:19, 396.40frames/s]\n 62%|██████▏   | 162486/262420 [07:33<04:32, 367.30frames/s]\n 63%|██████▎   | 165388/262420 [07:43<04:48, 336.17frames/s]\n 64%|██████▍   | 168288/262420 [07:49<04:12, 372.31frames/s]\n 65%|██████▌   | 171140/262420 [07:55<03:46, 402.95frames/s]\n 66%|██████▋   | 174080/262420 [08:01<03:29, 421.96frames/s]\n 67%|██████▋   | 177080/262420 [08:08<03:23, 419.61frames/s]\n 68%|██████▊   | 179456/262420 [08:15<03:22, 410.00frames/s]\n 69%|██████▉   | 182380/262420 [08:21<03:11, 417.26frames/s]\n 71%|███████   | 185144/262420 [08:32<03:34, 360.10frames/s]\n 72%|███████▏  | 188080/262420 [08:40<03:25, 362.08frames/s]\n 73%|███████▎  | 191080/262420 [08:47<03:11, 373.35frames/s]\n 74%|███████▍  | 193912/262420 [08:52<02:45, 414.11frames/s]\n 75%|███████▍  | 196620/262420 [08:59<02:44, 399.69frames/s]\n 76%|███████▌  | 199208/262420 [09:05<02:32, 413.59frames/s]\n 77%|███████▋  | 202154/262420 [09:14<02:38, 379.91frames/s]\n 78%|███████▊  | 204774/262420 [09:21<02:31, 380.00frames/s]\n 79%|███████▉  | 207594/262420 [09:26<02:07, 429.80frames/s]\n 80%|████████  | 210098/262420 [09:33<02:11, 399.39frames/s]\n 81%|████████  | 212692/262420 [09:40<02:05, 397.52frames/s]\n 82%|████████▏ | 215440/262420 [09:48<02:05, 374.20frames/s]\n 83%|████████▎ | 218206/262420 [09:54<01:49, 402.51frames/s]\n 84%|████████▍ | 221138/262420 [10:01<01:42, 404.58frames/s]\n 85%|████████▌ | 223808/262420 [10:07<01:35, 406.42frames/s]\n 86%|████████▋ | 226708/262420 [10:13<01:20, 440.89frames/s]\n 87%|████████▋ | 229104/262420 [10:19<01:17, 430.45frames/s]\n 88%|████████▊ | 232088/262420 [10:26<01:12, 420.78frames/s]\n 89%|████████▉ | 234800/262420 [10:32<01:03, 432.33frames/s]\n 91%|█████████ | 237656/262420 [10:38<00:55, 443.97frames/s]\n 92%|█████████▏| 240436/262420 [10:45<00:50, 437.36frames/s]\n 93%|█████████▎| 243216/262420 [10:53<00:47, 400.88frames/s]\n 94%|█████████▍| 246076/262420 [11:01<00:42, 384.26frames/s]\n 95%|█████████▍| 248668/262420 [11:09<00:38, 361.61frames/s]\n 96%|█████████▌| 251428/262420 [11:16<00:29, 373.16frames/s]\n 97%|█████████▋| 254398/262420 [11:25<00:22, 363.41frames/s]\n 98%|█████████▊| 257398/262420 [11:33<00:13, 370.22frames/s]\n 99%|█████████▉| 260234/262420 [11:40<00:05, 373.80frames/s]\n 99%|█████████▉| 260234/262420 [11:54<00:05, 373.80frames/s]\n100%|█████████▉| 261406/262420 [11:56<00:04, 228.47frames/s]\n100%|█████████▉| 261406/262420 [12:14<00:04, 228.47frames/s]\n100%|█████████▉| 261406/262420 [12:20<00:02, 353.10frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 4.4,
        "id": 0,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, you are here watching another coding challenge",
        "tokens": [
          50364,
          2425,
          11,
          291,
          366,
          510,
          1976,
          1071,
          17720,
          3430,
          50584
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 8.4,
        "id": 1,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 4.4,
        "temperature": 0,
        "text": " and this coding challenge, maybe this should just fit",
        "tokens": [
          50584,
          293,
          341,
          17720,
          3430,
          11,
          1310,
          341,
          820,
          445,
          3318,
          50784
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 10.18,
        "id": 2,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 8.4,
        "temperature": 0,
        "text": " and be in one of my tutorial videos,",
        "tokens": [
          50784,
          293,
          312,
          294,
          472,
          295,
          452,
          7073,
          2145,
          11,
          50873
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 11.68,
        "id": 3,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 10.18,
        "temperature": 0,
        "text": " but I'm gonna make it a coding challenge",
        "tokens": [
          50873,
          457,
          286,
          478,
          799,
          652,
          309,
          257,
          17720,
          3430,
          50948
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 13.72,
        "id": 4,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 11.68,
        "temperature": 0,
        "text": " because I'm gonna attempt to do it in one video.",
        "tokens": [
          50948,
          570,
          286,
          478,
          799,
          5217,
          281,
          360,
          309,
          294,
          472,
          960,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 15.9,
        "id": 5,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 13.72,
        "temperature": 0,
        "text": " And what I'm doing is recreating something",
        "tokens": [
          51050,
          400,
          437,
          286,
          478,
          884,
          307,
          850,
          44613,
          746,
          51159
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 16.96,
        "id": 6,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 15.9,
        "temperature": 0,
        "text": " that I've done before in some",
        "tokens": [
          51159,
          300,
          286,
          600,
          1096,
          949,
          294,
          512,
          51212
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 19.04,
        "id": 7,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 16.96,
        "temperature": 0,
        "text": " of my machine learning tutorials.",
        "tokens": [
          51212,
          295,
          452,
          3479,
          2539,
          17616,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 21.6,
        "id": 8,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 19.04,
        "temperature": 0,
        "text": " And it was suggested here,",
        "tokens": [
          51316,
          400,
          309,
          390,
          10945,
          510,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 22.96,
        "id": 9,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 21.6,
        "temperature": 0,
        "text": " I don't know if it was suggested exactly,",
        "tokens": [
          51444,
          286,
          500,
          380,
          458,
          498,
          309,
          390,
          10945,
          2293,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 26.240000000000002,
        "id": 10,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 22.96,
        "temperature": 0,
        "text": " but a Twitter user, Calstube Old Podcar,",
        "tokens": [
          51512,
          457,
          257,
          5794,
          4195,
          11,
          3511,
          372,
          1977,
          8633,
          12646,
          6166,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.29771850020797164,
        "compression_ratio": 1.799283154121864,
        "end": 29.580000000000002,
        "id": 11,
        "no_speech_prob": 0.014279353432357311,
        "seek": 0,
        "start": 26.240000000000002,
        "temperature": 0,
        "text": " apologies if I'm pronouncing the name incorrectly,",
        "tokens": [
          51676,
          34929,
          498,
          286,
          478,
          14144,
          2175,
          264,
          1315,
          42892,
          11,
          51843
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 32.239999999999995,
        "id": 12,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 29.58,
        "temperature": 0,
        "text": " created this interactive simulation",
        "tokens": [
          50364,
          2942,
          341,
          15141,
          16575,
          50497
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 35.5,
        "id": 13,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 32.239999999999995,
        "temperature": 0,
        "text": " of linear regression using TensorFlow.js.",
        "tokens": [
          50497,
          295,
          8213,
          24590,
          1228,
          37624,
          13,
          25530,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 37.94,
        "id": 14,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 35.5,
        "temperature": 0,
        "text": " And so this is very similar",
        "tokens": [
          50660,
          400,
          370,
          341,
          307,
          588,
          2531,
          50782
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 39.739999999999995,
        "id": 15,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 37.94,
        "temperature": 0,
        "text": " to something that I've done previously, right?",
        "tokens": [
          50782,
          281,
          746,
          300,
          286,
          600,
          1096,
          8046,
          11,
          558,
          30,
          50872
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 42.46,
        "id": 16,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 39.739999999999995,
        "temperature": 0,
        "text": " I have this video, linear regression with gradient descent,",
        "tokens": [
          50872,
          286,
          362,
          341,
          960,
          11,
          8213,
          24590,
          365,
          16235,
          23475,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 44.86,
        "id": 17,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 42.46,
        "temperature": 0,
        "text": " where I just did this with plain JavaScript.",
        "tokens": [
          51008,
          689,
          286,
          445,
          630,
          341,
          365,
          11121,
          15778,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 47.3,
        "id": 18,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 44.86,
        "temperature": 0,
        "text": " And then you could also look at this other video,",
        "tokens": [
          51128,
          400,
          550,
          291,
          727,
          611,
          574,
          412,
          341,
          661,
          960,
          11,
          51250
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 48.72,
        "id": 19,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 47.3,
        "temperature": 0,
        "text": " which I go through the mathematics",
        "tokens": [
          51250,
          597,
          286,
          352,
          807,
          264,
          18666,
          51321
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 50.22,
        "id": 20,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 48.72,
        "temperature": 0,
        "text": " of gradient descent a little bit.",
        "tokens": [
          51321,
          295,
          16235,
          23475,
          257,
          707,
          857,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 53.459999999999994,
        "id": 21,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 50.22,
        "temperature": 0,
        "text": " But here's the thing, going through the mathematics,",
        "tokens": [
          51396,
          583,
          510,
          311,
          264,
          551,
          11,
          516,
          807,
          264,
          18666,
          11,
          51558
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 55.739999999999995,
        "id": 22,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 53.459999999999994,
        "temperature": 0,
        "text": " making this video where I implement the mathematics",
        "tokens": [
          51558,
          1455,
          341,
          960,
          689,
          286,
          4445,
          264,
          18666,
          51672
        ]
      },
      {
        "avg_logprob": -0.2241460612562836,
        "compression_ratio": 1.8178571428571428,
        "end": 57.94,
        "id": 23,
        "no_speech_prob": 0.00002796908484015148,
        "seek": 2958,
        "start": 55.739999999999995,
        "temperature": 0,
        "text": " in JavaScript while useful,",
        "tokens": [
          51672,
          294,
          15778,
          1339,
          4420,
          11,
          51782
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 59.68,
        "id": 24,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 57.94,
        "temperature": 0,
        "text": " and perhaps background for this video,",
        "tokens": [
          50364,
          293,
          4317,
          3678,
          337,
          341,
          960,
          11,
          50451
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 61.46,
        "id": 25,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 59.68,
        "temperature": 0,
        "text": " one of the exciting things about doing this",
        "tokens": [
          50451,
          472,
          295,
          264,
          4670,
          721,
          466,
          884,
          341,
          50540
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 66.34,
        "id": 26,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 61.46,
        "temperature": 0,
        "text": " with TensorFlow.js is TensorFlow.js has a nice API",
        "tokens": [
          50540,
          365,
          37624,
          13,
          25530,
          307,
          37624,
          13,
          25530,
          575,
          257,
          1481,
          9362,
          50784
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 70.66,
        "id": 27,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 66.34,
        "temperature": 0,
        "text": " for optimizing loss functions",
        "tokens": [
          50784,
          337,
          40425,
          4470,
          6828,
          51000
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 73.9,
        "id": 28,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 70.66,
        "temperature": 0,
        "text": " with the gradient descent algorithm built into it.",
        "tokens": [
          51000,
          365,
          264,
          16235,
          23475,
          9284,
          3094,
          666,
          309,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 75.25999999999999,
        "id": 29,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 73.9,
        "temperature": 0,
        "text": " So I could just do things.",
        "tokens": [
          51162,
          407,
          286,
          727,
          445,
          360,
          721,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 76.82,
        "id": 30,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 75.25999999999999,
        "temperature": 0,
        "text": " So let's make a, I gotta come back here,",
        "tokens": [
          51230,
          407,
          718,
          311,
          652,
          257,
          11,
          286,
          3428,
          808,
          646,
          510,
          11,
          51308
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 78.66,
        "id": 31,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 76.82,
        "temperature": 0,
        "text": " but let's make a list.",
        "tokens": [
          51308,
          457,
          718,
          311,
          652,
          257,
          1329,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 80.53999999999999,
        "id": 32,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 78.66,
        "temperature": 0,
        "text": " All right, so first of all,",
        "tokens": [
          51400,
          1057,
          558,
          11,
          370,
          700,
          295,
          439,
          11,
          51494
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 82.58,
        "id": 33,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 80.53999999999999,
        "temperature": 0,
        "text": " what is linear regression anyway?",
        "tokens": [
          51494,
          437,
          307,
          8213,
          24590,
          4033,
          30,
          51596
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 86.14,
        "id": 34,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 84.06,
        "temperature": 0,
        "text": " So let's say we have a space,",
        "tokens": [
          51670,
          407,
          718,
          311,
          584,
          321,
          362,
          257,
          1901,
          11,
          51774
        ]
      },
      {
        "avg_logprob": -0.2025138024360903,
        "compression_ratio": 1.6142322097378277,
        "end": 87.92,
        "id": 35,
        "no_speech_prob": 0.000002058049176412169,
        "seek": 5794,
        "start": 86.14,
        "temperature": 0,
        "text": " and I drew this as like a canvas,",
        "tokens": [
          51774,
          293,
          286,
          12804,
          341,
          382,
          411,
          257,
          16267,
          11,
          51863
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 91.24000000000001,
        "id": 36,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 88.9,
        "temperature": 0,
        "text": " but really I should be talking just about a generic",
        "tokens": [
          50413,
          457,
          534,
          286,
          820,
          312,
          1417,
          445,
          466,
          257,
          19577,
          50530
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 94,
        "id": 37,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 91.24000000000001,
        "temperature": 0,
        "text": " kind of two-dimensional Cartesian plane.",
        "tokens": [
          50530,
          733,
          295,
          732,
          12,
          18759,
          22478,
          42434,
          5720,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 96.94,
        "id": 38,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 94,
        "temperature": 0,
        "text": " In that plane, there are a bunch of points.",
        "tokens": [
          50668,
          682,
          300,
          5720,
          11,
          456,
          366,
          257,
          3840,
          295,
          2793,
          13,
          50815
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 101.92,
        "id": 39,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 97.92,
        "temperature": 0,
        "text": " The idea of linear regression is to figure out,",
        "tokens": [
          50864,
          440,
          1558,
          295,
          8213,
          24590,
          307,
          281,
          2573,
          484,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 105.6,
        "id": 40,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 101.92,
        "temperature": 0,
        "text": " can we fit, oh, this is a time for another colored marker.",
        "tokens": [
          51064,
          393,
          321,
          3318,
          11,
          1954,
          11,
          341,
          307,
          257,
          565,
          337,
          1071,
          14332,
          15247,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 111.48,
        "id": 41,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 106.48,
        "temperature": 0,
        "text": " Can we fit a line into this two-dimensional space",
        "tokens": [
          51292,
          1664,
          321,
          3318,
          257,
          1622,
          666,
          341,
          732,
          12,
          18759,
          1901,
          51542
        ]
      },
      {
        "avg_logprob": -0.23602769729938913,
        "compression_ratio": 1.591743119266055,
        "end": 114.3,
        "id": 42,
        "no_speech_prob": 1.4449800289639825e-7,
        "seek": 8792,
        "start": 111.48,
        "temperature": 0,
        "text": " that approximates all of these points as best we can?",
        "tokens": [
          51542,
          300,
          8542,
          1024,
          439,
          295,
          613,
          2793,
          382,
          1151,
          321,
          393,
          30,
          51683
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 117.62,
        "id": 43,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 114.34,
        "temperature": 0,
        "text": " And I can visually just kind of make myself",
        "tokens": [
          50366,
          400,
          286,
          393,
          19622,
          445,
          733,
          295,
          652,
          2059,
          50530
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 119.22,
        "id": 44,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 117.62,
        "temperature": 0,
        "text": " do this like this.",
        "tokens": [
          50530,
          360,
          341,
          411,
          341,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 122.39999999999999,
        "id": 45,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 119.22,
        "temperature": 0,
        "text": " So I can eyeball it and say, this line kind of gets close.",
        "tokens": [
          50610,
          407,
          286,
          393,
          38868,
          309,
          293,
          584,
          11,
          341,
          1622,
          733,
          295,
          2170,
          1998,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 125.5,
        "id": 46,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 122.39999999999999,
        "temperature": 0,
        "text": " What we're trying to do is minimize,",
        "tokens": [
          50769,
          708,
          321,
          434,
          1382,
          281,
          360,
          307,
          17522,
          11,
          50924
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 129.02,
        "id": 47,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 127.46,
        "temperature": 0,
        "text": " I've never, all of these,",
        "tokens": [
          51022,
          286,
          600,
          1128,
          11,
          439,
          295,
          613,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 131.14,
        "id": 48,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 129.02,
        "temperature": 0,
        "text": " this is the most beautiful diagram I've ever made,",
        "tokens": [
          51100,
          341,
          307,
          264,
          881,
          2238,
          10686,
          286,
          600,
          1562,
          1027,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 134.32,
        "id": 49,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 131.14,
        "temperature": 0,
        "text": " all of these distances of all of the points to the line.",
        "tokens": [
          51206,
          439,
          295,
          613,
          22182,
          295,
          439,
          295,
          264,
          2793,
          281,
          264,
          1622,
          13,
          51365
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 137.82,
        "id": 50,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 134.32,
        "temperature": 0,
        "text": " The idea here then is that we can make some predictions.",
        "tokens": [
          51365,
          440,
          1558,
          510,
          550,
          307,
          300,
          321,
          393,
          652,
          512,
          21264,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.24948077919208897,
        "compression_ratio": 1.6680672268907564,
        "end": 142.82,
        "id": 51,
        "no_speech_prob": 0.0000015534978956566192,
        "seek": 11430,
        "start": 137.82,
        "temperature": 0,
        "text": " If this data, if this x-axis represents height,",
        "tokens": [
          51540,
          759,
          341,
          1412,
          11,
          498,
          341,
          2031,
          12,
          24633,
          8855,
          6681,
          11,
          51790
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 150.3,
        "id": 52,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 145.3,
        "temperature": 0,
        "text": " we might predict on the y-axis weight.",
        "tokens": [
          50414,
          321,
          1062,
          6069,
          322,
          264,
          288,
          12,
          24633,
          3364,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 155.98000000000002,
        "id": 53,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 152.58,
        "temperature": 0,
        "text": " You can think of kinds of data sets,",
        "tokens": [
          50778,
          509,
          393,
          519,
          295,
          3685,
          295,
          1412,
          6352,
          11,
          50948
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 160.18,
        "id": 54,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 155.98000000000002,
        "temperature": 0,
        "text": " simple 2D data sets where there's a linear relationship",
        "tokens": [
          50948,
          2199,
          568,
          35,
          1412,
          6352,
          689,
          456,
          311,
          257,
          8213,
          2480,
          51158
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 164.66000000000003,
        "id": 55,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 160.18,
        "temperature": 0,
        "text": " between the one field of data and another field of data.",
        "tokens": [
          51158,
          1296,
          264,
          472,
          2519,
          295,
          1412,
          293,
          1071,
          2519,
          295,
          1412,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 168.10000000000002,
        "id": 56,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 164.66000000000003,
        "temperature": 0,
        "text": " So if we pick a new height, we can kind of make a guess",
        "tokens": [
          51382,
          407,
          498,
          321,
          1888,
          257,
          777,
          6681,
          11,
          321,
          393,
          733,
          295,
          652,
          257,
          2041,
          51554
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 170.14000000000001,
        "id": 57,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 168.10000000000002,
        "temperature": 0,
        "text": " approximately what that weight is gonna be.",
        "tokens": [
          51554,
          10447,
          437,
          300,
          3364,
          307,
          799,
          312,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 171.46,
        "id": 58,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 170.14000000000001,
        "temperature": 0,
        "text": " That's the idea of linear regression.",
        "tokens": [
          51656,
          663,
          311,
          264,
          1558,
          295,
          8213,
          24590,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.2345107396443685,
        "compression_ratio": 1.6055045871559632,
        "end": 172.96,
        "id": 59,
        "no_speech_prob": 0.0000035008526992896805,
        "seek": 14430,
        "start": 171.46,
        "temperature": 0,
        "text": " It's incredibly simple.",
        "tokens": [
          51722,
          467,
          311,
          6252,
          2199,
          13,
          51797
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 175.36,
        "id": 60,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 172.96,
        "temperature": 0,
        "text": " A lot of data isn't two-dimensional.",
        "tokens": [
          50364,
          316,
          688,
          295,
          1412,
          1943,
          380,
          732,
          12,
          18759,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 177.52,
        "id": 61,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 175.36,
        "temperature": 0,
        "text": " A lot of data doesn't fit a line.",
        "tokens": [
          50484,
          316,
          688,
          295,
          1412,
          1177,
          380,
          3318,
          257,
          1622,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 179.10000000000002,
        "id": 62,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 177.52,
        "temperature": 0,
        "text": " You know, maybe a curve fits it better.",
        "tokens": [
          50592,
          509,
          458,
          11,
          1310,
          257,
          7605,
          9001,
          309,
          1101,
          13,
          50671
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 181.96,
        "id": 63,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 179.10000000000002,
        "temperature": 0,
        "text": " And this is more complex scenarios will come",
        "tokens": [
          50671,
          400,
          341,
          307,
          544,
          3997,
          15077,
          486,
          808,
          50814
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 185.24,
        "id": 64,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 181.96,
        "temperature": 0,
        "text": " as we move forward and make more scenarios",
        "tokens": [
          50814,
          382,
          321,
          1286,
          2128,
          293,
          652,
          544,
          15077,
          50978
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 187.60000000000002,
        "id": 65,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 185.24,
        "temperature": 0,
        "text": " with complex polynomial equations",
        "tokens": [
          50978,
          365,
          3997,
          26110,
          11787,
          51096
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 189.16,
        "id": 66,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 187.60000000000002,
        "temperature": 0,
        "text": " or neural network-based learning",
        "tokens": [
          51096,
          420,
          18161,
          3209,
          12,
          6032,
          2539,
          51174
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 191,
        "id": 67,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 189.16,
        "temperature": 0,
        "text": " and other types of machine learning algorithms.",
        "tokens": [
          51174,
          293,
          661,
          3467,
          295,
          3479,
          2539,
          14642,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 193.36,
        "id": 68,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 191,
        "temperature": 0,
        "text": " But this is a good place for us to start.",
        "tokens": [
          51266,
          583,
          341,
          307,
          257,
          665,
          1081,
          337,
          505,
          281,
          722,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 194.64000000000001,
        "id": 69,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 193.36,
        "temperature": 0,
        "text": " So what do we need?",
        "tokens": [
          51384,
          407,
          437,
          360,
          321,
          643,
          30,
          51448
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 196.76000000000002,
        "id": 70,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 194.64000000000001,
        "temperature": 0,
        "text": " We need a data set.",
        "tokens": [
          51448,
          492,
          643,
          257,
          1412,
          992,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 199.84,
        "id": 71,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 196.76000000000002,
        "temperature": 0,
        "text": " So we need a set of x's and y's.",
        "tokens": [
          51554,
          407,
          321,
          643,
          257,
          992,
          295,
          2031,
          311,
          293,
          288,
          311,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.18878607316450638,
        "compression_ratio": 1.7374517374517375,
        "end": 201.20000000000002,
        "id": 72,
        "no_speech_prob": 0.000005862809302925598,
        "seek": 17296,
        "start": 199.84,
        "temperature": 0,
        "text": " This is the data set.",
        "tokens": [
          51708,
          639,
          307,
          264,
          1412,
          992,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 205.08,
        "id": 73,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 203.68,
        "temperature": 0,
        "text": " Right, we need x's and y's.",
        "tokens": [
          50400,
          1779,
          11,
          321,
          643,
          2031,
          311,
          293,
          288,
          311,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 207.48000000000002,
        "id": 74,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 205.08,
        "temperature": 0,
        "text": " And I'm gonna create that data set",
        "tokens": [
          50470,
          400,
          286,
          478,
          799,
          1884,
          300,
          1412,
          992,
          50590
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 209.20000000000002,
        "id": 75,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 207.48000000000002,
        "temperature": 0,
        "text": " through interactive clicking.",
        "tokens": [
          50590,
          807,
          15141,
          9697,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 211.9,
        "id": 76,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 210.08,
        "temperature": 0,
        "text": " Interactive clicking is the way I'm gonna create",
        "tokens": [
          50720,
          5751,
          12596,
          9697,
          307,
          264,
          636,
          286,
          478,
          799,
          1884,
          50811
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 213.5,
        "id": 77,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 211.9,
        "temperature": 0,
        "text": " that data set with the mouse.",
        "tokens": [
          50811,
          300,
          1412,
          992,
          365,
          264,
          9719,
          13,
          50891
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 219.96,
        "id": 78,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 215.06,
        "temperature": 0,
        "text": " I need to have something called a loss function.",
        "tokens": [
          50969,
          286,
          643,
          281,
          362,
          746,
          1219,
          257,
          4470,
          2445,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 223.4,
        "id": 79,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 219.96,
        "temperature": 0,
        "text": " The loss function is a way of computing the error.",
        "tokens": [
          51214,
          440,
          4470,
          2445,
          307,
          257,
          636,
          295,
          15866,
          264,
          6713,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 225.76000000000002,
        "id": 80,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 223.4,
        "temperature": 0,
        "text": " And there are a bunch of different loss functions,",
        "tokens": [
          51386,
          400,
          456,
          366,
          257,
          3840,
          295,
          819,
          4470,
          6828,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 228.44,
        "id": 81,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 225.76000000000002,
        "temperature": 0,
        "text": " and we'll see these as I use TensorFlow.js",
        "tokens": [
          51504,
          293,
          321,
          603,
          536,
          613,
          382,
          286,
          764,
          37624,
          13,
          25530,
          51638
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 229.60000000000002,
        "id": 82,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 228.44,
        "temperature": 0,
        "text": " in more tutorials.",
        "tokens": [
          51638,
          294,
          544,
          17616,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 231.60000000000002,
        "id": 83,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 229.60000000000002,
        "temperature": 0,
        "text": " I can select different kinds of loss functions",
        "tokens": [
          51696,
          286,
          393,
          3048,
          819,
          3685,
          295,
          4470,
          6828,
          51796
        ]
      },
      {
        "avg_logprob": -0.256456979891149,
        "compression_ratio": 1.8612244897959183,
        "end": 232.94,
        "id": 84,
        "no_speech_prob": 0.000017778538676793687,
        "seek": 20296,
        "start": 231.60000000000002,
        "temperature": 0,
        "text": " for different scenarios.",
        "tokens": [
          51796,
          337,
          819,
          15077,
          13,
          51863
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 235.26,
        "id": 85,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 233.78,
        "temperature": 0,
        "text": " But in this scenario, I'm gonna use a simple basic one,",
        "tokens": [
          50406,
          583,
          294,
          341,
          9005,
          11,
          286,
          478,
          799,
          764,
          257,
          2199,
          3875,
          472,
          11,
          50480
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 240.26,
        "id": 86,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 235.26,
        "temperature": 0,
        "text": " which I believe is called root mean squared error.",
        "tokens": [
          50480,
          597,
          286,
          1697,
          307,
          1219,
          5593,
          914,
          8889,
          6713,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 243.46,
        "id": 87,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 242.18,
        "temperature": 0,
        "text": " Did I say that correctly?",
        "tokens": [
          50826,
          2589,
          286,
          584,
          300,
          8944,
          30,
          50890
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 244.74,
        "id": 88,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 243.46,
        "temperature": 0,
        "text": " Is that the right name of it?",
        "tokens": [
          50890,
          1119,
          300,
          264,
          558,
          1315,
          295,
          309,
          30,
          50954
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 248.66,
        "id": 89,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 244.74,
        "temperature": 0,
        "text": " But the idea is that I wanna look at all of those distances.",
        "tokens": [
          50954,
          583,
          264,
          1558,
          307,
          300,
          286,
          1948,
          574,
          412,
          439,
          295,
          729,
          22182,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 249.57999999999998,
        "id": 90,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 248.66,
        "temperature": 0,
        "text": " Okay, I'm back,",
        "tokens": [
          51150,
          1033,
          11,
          286,
          478,
          646,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 251.54,
        "id": 91,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 249.57999999999998,
        "temperature": 0,
        "text": " because I started talking about the loss function,",
        "tokens": [
          51196,
          570,
          286,
          1409,
          1417,
          466,
          264,
          4470,
          2445,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 254.02,
        "id": 92,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 251.54,
        "temperature": 0,
        "text": " and I realized I really didn't draw.",
        "tokens": [
          51294,
          293,
          286,
          5334,
          286,
          534,
          994,
          380,
          2642,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 256.78,
        "id": 93,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 254.02,
        "temperature": 0,
        "text": " I'm not actually looking for the distance",
        "tokens": [
          51418,
          286,
          478,
          406,
          767,
          1237,
          337,
          264,
          4560,
          51556
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 259.34,
        "id": 94,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 256.78,
        "temperature": 0,
        "text": " from the point to that line, which would be perpendicular.",
        "tokens": [
          51556,
          490,
          264,
          935,
          281,
          300,
          1622,
          11,
          597,
          576,
          312,
          26734,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.20999808609485626,
        "compression_ratio": 1.6714285714285715,
        "end": 262.34,
        "id": 95,
        "no_speech_prob": 9.570823067406309e-7,
        "seek": 23294,
        "start": 259.34,
        "temperature": 0,
        "text": " I'm looking for this vertical distance,",
        "tokens": [
          51684,
          286,
          478,
          1237,
          337,
          341,
          9429,
          4560,
          11,
          51834
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 266.26,
        "id": 96,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 262.34,
        "temperature": 0,
        "text": " which is, so this is what I'm trying to minimize.",
        "tokens": [
          50364,
          597,
          307,
          11,
          370,
          341,
          307,
          437,
          286,
          478,
          1382,
          281,
          17522,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 269.5,
        "id": 97,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 266.26,
        "temperature": 0,
        "text": " Right, I'm trying to minimize and get a line that has,",
        "tokens": [
          50560,
          1779,
          11,
          286,
          478,
          1382,
          281,
          17522,
          293,
          483,
          257,
          1622,
          300,
          575,
          11,
          50722
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 271.5,
        "id": 98,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 269.5,
        "temperature": 0,
        "text": " and this, that is the least,",
        "tokens": [
          50722,
          293,
          341,
          11,
          300,
          307,
          264,
          1935,
          11,
          50822
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 276.62,
        "id": 99,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 273.7,
        "temperature": 0,
        "text": " the sum of all these distances is the smallest number,",
        "tokens": [
          50932,
          264,
          2408,
          295,
          439,
          613,
          22182,
          307,
          264,
          16998,
          1230,
          11,
          51078
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 278.5,
        "id": 100,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 276.62,
        "temperature": 0,
        "text": " minimizing the loss.",
        "tokens": [
          51078,
          46608,
          264,
          4470,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 280.9,
        "id": 101,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 278.5,
        "temperature": 0,
        "text": " So I have a loss function, I need that.",
        "tokens": [
          51172,
          407,
          286,
          362,
          257,
          4470,
          2445,
          11,
          286,
          643,
          300,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 283.73999999999995,
        "id": 102,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 280.9,
        "temperature": 0,
        "text": " I also need, in TensorFlow.js,",
        "tokens": [
          51292,
          286,
          611,
          643,
          11,
          294,
          37624,
          13,
          25530,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 286.85999999999996,
        "id": 103,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 283.73999999999995,
        "temperature": 0,
        "text": " something called an optimizer.",
        "tokens": [
          51434,
          746,
          1219,
          364,
          5028,
          6545,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.23728240538980358,
        "compression_ratio": 1.732394366197183,
        "end": 291.05999999999995,
        "id": 104,
        "no_speech_prob": 0.000001760342343004595,
        "seek": 26234,
        "start": 286.85999999999996,
        "temperature": 0,
        "text": " And the optimizer is the thing that allows me to minimize",
        "tokens": [
          51590,
          400,
          264,
          5028,
          6545,
          307,
          264,
          551,
          300,
          4045,
          385,
          281,
          17522,
          51800
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 293.9,
        "id": 105,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 292.5,
        "temperature": 0,
        "text": " the loss function.",
        "tokens": [
          50372,
          264,
          4470,
          2445,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 297.38,
        "id": 106,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 295.34,
        "temperature": 0,
        "text": " And in order to do that,",
        "tokens": [
          50514,
          400,
          294,
          1668,
          281,
          360,
          300,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 301.53999999999996,
        "id": 107,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 297.38,
        "temperature": 0,
        "text": " I also need to have a learning rate.",
        "tokens": [
          50616,
          286,
          611,
          643,
          281,
          362,
          257,
          2539,
          3314,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 302.38,
        "id": 108,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 301.53999999999996,
        "temperature": 0,
        "text": " So these are all,",
        "tokens": [
          50824,
          407,
          613,
          366,
          439,
          11,
          50866
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 304.17999999999995,
        "id": 109,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 302.38,
        "temperature": 0,
        "text": " I actually missed something very important here,",
        "tokens": [
          50866,
          286,
          767,
          6721,
          746,
          588,
          1021,
          510,
          11,
          50956
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 305.29999999999995,
        "id": 110,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 304.17999999999995,
        "temperature": 0,
        "text": " but these are all the pieces.",
        "tokens": [
          50956,
          457,
          613,
          366,
          439,
          264,
          3755,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 308.67999999999995,
        "id": 111,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 305.29999999999995,
        "temperature": 0,
        "text": " I need the data, I need to define a loss function,",
        "tokens": [
          51012,
          286,
          643,
          264,
          1412,
          11,
          286,
          643,
          281,
          6964,
          257,
          4470,
          2445,
          11,
          51181
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 310.34,
        "id": 112,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 308.67999999999995,
        "temperature": 0,
        "text": " I need to define an optimizer.",
        "tokens": [
          51181,
          286,
          643,
          281,
          6964,
          364,
          5028,
          6545,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 311.53999999999996,
        "id": 113,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 310.34,
        "temperature": 0,
        "text": " I say, hey, optimizer,",
        "tokens": [
          51264,
          286,
          584,
          11,
          4177,
          11,
          5028,
          6545,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 314.44,
        "id": 114,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 311.53999999999996,
        "temperature": 0,
        "text": " minimize the loss function with this learning rate.",
        "tokens": [
          51324,
          17522,
          264,
          4470,
          2445,
          365,
          341,
          2539,
          3314,
          13,
          51469
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 317.29999999999995,
        "id": 115,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 314.44,
        "temperature": 0,
        "text": " So keep tweaking the parameters, tweaking the parameters.",
        "tokens": [
          51469,
          407,
          1066,
          6986,
          2456,
          264,
          9834,
          11,
          6986,
          2456,
          264,
          9834,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 318.38,
        "id": 116,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 317.29999999999995,
        "temperature": 0,
        "text": " So that's the thing I forgot.",
        "tokens": [
          51612,
          407,
          300,
          311,
          264,
          551,
          286,
          5298,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.17716099105718483,
        "compression_ratio": 1.9437229437229437,
        "end": 319.53999999999996,
        "id": 117,
        "no_speech_prob": 0.00001045153294398915,
        "seek": 29234,
        "start": 318.38,
        "temperature": 0,
        "text": " What are those parameters?",
        "tokens": [
          51666,
          708,
          366,
          729,
          9834,
          30,
          51724
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 324.54,
        "id": 118,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 319.54,
        "temperature": 0,
        "text": " Well, the formula for a line is y equals mx plus b.",
        "tokens": [
          50364,
          1042,
          11,
          264,
          8513,
          337,
          257,
          1622,
          307,
          288,
          6915,
          275,
          87,
          1804,
          272,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 329.46000000000004,
        "id": 119,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 325.42,
        "temperature": 0,
        "text": " M is often referred to as the slope, b as the,",
        "tokens": [
          50658,
          376,
          307,
          2049,
          10839,
          281,
          382,
          264,
          13525,
          11,
          272,
          382,
          264,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 332.06,
        "id": 120,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 330.54,
        "temperature": 0,
        "text": " I'm back, because I looked it up.",
        "tokens": [
          50914,
          286,
          478,
          646,
          11,
          570,
          286,
          2956,
          309,
          493,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 337.06,
        "id": 121,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 332.06,
        "temperature": 0,
        "text": " M is the slope, and b referred to as the y-intercept.",
        "tokens": [
          50990,
          376,
          307,
          264,
          13525,
          11,
          293,
          272,
          10839,
          281,
          382,
          264,
          288,
          12,
          5106,
          1336,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 340.74,
        "id": 122,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 339.18,
        "temperature": 0,
        "text": " Kind of like bias, by the way,",
        "tokens": [
          51346,
          9242,
          295,
          411,
          12577,
          11,
          538,
          264,
          636,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 342.66,
        "id": 123,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 340.74,
        "temperature": 0,
        "text": " if you've watched some of my other neural network tutorials,",
        "tokens": [
          51424,
          498,
          291,
          600,
          6337,
          512,
          295,
          452,
          661,
          18161,
          3209,
          17616,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 344.54,
        "id": 124,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 342.66,
        "temperature": 0,
        "text": " because this is like the thing we're doing",
        "tokens": [
          51520,
          570,
          341,
          307,
          411,
          264,
          551,
          321,
          434,
          884,
          51614
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 345.38,
        "id": 125,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 344.54,
        "temperature": 0,
        "text": " with all the neurons.",
        "tokens": [
          51614,
          365,
          439,
          264,
          22027,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 346.42,
        "id": 126,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 345.38,
        "temperature": 0,
        "text": " Oh, it's all so connected,",
        "tokens": [
          51656,
          876,
          11,
          309,
          311,
          439,
          370,
          4582,
          11,
          51708
        ]
      },
      {
        "avg_logprob": -0.2506144010103666,
        "compression_ratio": 1.6626984126984128,
        "end": 349.04,
        "id": 127,
        "no_speech_prob": 6.681513582407206e-7,
        "seek": 31954,
        "start": 346.42,
        "temperature": 0,
        "text": " but we're just living in this very simple place.",
        "tokens": [
          51708,
          457,
          321,
          434,
          445,
          2647,
          294,
          341,
          588,
          2199,
          1081,
          13,
          51839
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 354.46000000000004,
        "id": 128,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 349.46000000000004,
        "temperature": 0,
        "text": " So I need these parameters, I need these variables,",
        "tokens": [
          50385,
          407,
          286,
          643,
          613,
          9834,
          11,
          286,
          643,
          613,
          9102,
          11,
          50635
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 356.8,
        "id": 129,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 354.76000000000005,
        "temperature": 0,
        "text": " because that's what's going to allow me",
        "tokens": [
          50650,
          570,
          300,
          311,
          437,
          311,
          516,
          281,
          2089,
          385,
          50752
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 360.28000000000003,
        "id": 130,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 356.8,
        "temperature": 0,
        "text": " to create the predictions that are on the line",
        "tokens": [
          50752,
          281,
          1884,
          264,
          21264,
          300,
          366,
          322,
          264,
          1622,
          50926
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 362.6,
        "id": 131,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 360.28000000000003,
        "temperature": 0,
        "text": " to compare with the actual points,",
        "tokens": [
          50926,
          281,
          6794,
          365,
          264,
          3539,
          2793,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 365.88,
        "id": 132,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 362.6,
        "temperature": 0,
        "text": " and compute the loss, minimize it, tweaking these values.",
        "tokens": [
          51042,
          293,
          14722,
          264,
          4470,
          11,
          17522,
          309,
          11,
          6986,
          2456,
          613,
          4190,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 368.24,
        "id": 133,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 365.88,
        "temperature": 0,
        "text": " So tweak these values, minimizing the loss.",
        "tokens": [
          51206,
          407,
          29879,
          613,
          4190,
          11,
          46608,
          264,
          4470,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 369.44,
        "id": 134,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 368.24,
        "temperature": 0,
        "text": " This is what we're doing.",
        "tokens": [
          51324,
          639,
          307,
          437,
          321,
          434,
          884,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 372.36,
        "id": 135,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 369.44,
        "temperature": 0,
        "text": " And I've done this before in great detail.",
        "tokens": [
          51384,
          400,
          286,
          600,
          1096,
          341,
          949,
          294,
          869,
          2607,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 373.8,
        "id": 136,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 372.36,
        "temperature": 0,
        "text": " This is gonna be in less detail,",
        "tokens": [
          51530,
          639,
          307,
          799,
          312,
          294,
          1570,
          2607,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 376.40000000000003,
        "id": 137,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 373.8,
        "temperature": 0,
        "text": " because TensorFlow.js is gonna do a lot of this for us.",
        "tokens": [
          51602,
          570,
          37624,
          13,
          25530,
          307,
          799,
          360,
          257,
          688,
          295,
          341,
          337,
          505,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2019572294959726,
        "compression_ratio": 1.8416988416988418,
        "end": 378.88,
        "id": 138,
        "no_speech_prob": 0.0000031875640615908196,
        "seek": 34904,
        "start": 376.40000000000003,
        "temperature": 0,
        "text": " The thing that's a little extra complicated",
        "tokens": [
          51732,
          440,
          551,
          300,
          311,
          257,
          707,
          2857,
          6179,
          51856
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 382.4,
        "id": 139,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 379.71999999999997,
        "temperature": 0,
        "text": " is we can't just work with arrays of numbers and variables",
        "tokens": [
          50406,
          307,
          321,
          393,
          380,
          445,
          589,
          365,
          41011,
          295,
          3547,
          293,
          9102,
          50540
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 384.2,
        "id": 140,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 382.4,
        "temperature": 0,
        "text": " in the way that we're used to in JavaScript.",
        "tokens": [
          50540,
          294,
          264,
          636,
          300,
          321,
          434,
          1143,
          281,
          294,
          15778,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 386.12,
        "id": 141,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 384.2,
        "temperature": 0,
        "text": " And so this is what brings me to,",
        "tokens": [
          50630,
          400,
          370,
          341,
          307,
          437,
          5607,
          385,
          281,
          11,
          50726
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 389.64,
        "id": 142,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 386.12,
        "temperature": 0,
        "text": " if you haven't looked at these particular videos",
        "tokens": [
          50726,
          498,
          291,
          2378,
          380,
          2956,
          412,
          613,
          1729,
          2145,
          50902
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 393.8,
        "id": 143,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 389.64,
        "temperature": 0,
        "text": " that I've made already, what's a TensorFlow tensor?",
        "tokens": [
          50902,
          300,
          286,
          600,
          1027,
          1217,
          11,
          437,
          311,
          257,
          37624,
          40863,
          30,
          51110
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 394.65999999999997,
        "id": 144,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 393.8,
        "temperature": 0,
        "text": " What's a variable?",
        "tokens": [
          51110,
          708,
          311,
          257,
          7006,
          30,
          51153
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 395.54,
        "id": 145,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 394.65999999999997,
        "temperature": 0,
        "text": " What's an operation?",
        "tokens": [
          51153,
          708,
          311,
          364,
          6916,
          30,
          51197
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 397.02,
        "id": 146,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 395.54,
        "temperature": 0,
        "text": " How's the memory management stuff?",
        "tokens": [
          51197,
          1012,
          311,
          264,
          4675,
          4592,
          1507,
          30,
          51271
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 398.96,
        "id": 147,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 397.02,
        "temperature": 0,
        "text": " This is stuff we're gonna have to lean on",
        "tokens": [
          51271,
          639,
          307,
          1507,
          321,
          434,
          799,
          362,
          281,
          11659,
          322,
          51368
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 400.4,
        "id": 148,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 398.96,
        "temperature": 0,
        "text": " while I build this example.",
        "tokens": [
          51368,
          1339,
          286,
          1322,
          341,
          1365,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 402.2,
        "id": 149,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 400.4,
        "temperature": 0,
        "text": " And this should be, by the way,",
        "tokens": [
          51440,
          400,
          341,
          820,
          312,
          11,
          538,
          264,
          636,
          11,
          51530
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 406.24,
        "id": 150,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 402.2,
        "temperature": 0,
        "text": " an actual practical example of where I need a tf variable.",
        "tokens": [
          51530,
          364,
          3539,
          8496,
          1365,
          295,
          689,
          286,
          643,
          257,
          256,
          69,
          7006,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 407.15999999999997,
        "id": 151,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 406.24,
        "temperature": 0,
        "text": " So I kind of, in this video,",
        "tokens": [
          51732,
          407,
          286,
          733,
          295,
          11,
          294,
          341,
          960,
          11,
          51778
        ]
      },
      {
        "avg_logprob": -0.20164997962213332,
        "compression_ratio": 1.6962025316455696,
        "end": 408.44,
        "id": 152,
        "no_speech_prob": 0.000005771911219198955,
        "seek": 37888,
        "start": 407.15999999999997,
        "temperature": 0,
        "text": " explained what a tf variable is,",
        "tokens": [
          51778,
          8825,
          437,
          257,
          256,
          69,
          7006,
          307,
          11,
          51842
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 409.84,
        "id": 153,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 409,
        "temperature": 0,
        "text": " and then people just kind of moved on",
        "tokens": [
          50392,
          293,
          550,
          561,
          445,
          733,
          295,
          4259,
          322,
          50434
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 410.71999999999997,
        "id": 154,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 409.84,
        "temperature": 0,
        "text": " and didn't use it for anything.",
        "tokens": [
          50434,
          293,
          994,
          380,
          764,
          309,
          337,
          1340,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 412.36,
        "id": 155,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 410.71999999999997,
        "temperature": 0,
        "text": " So hopefully this will show us that.",
        "tokens": [
          50478,
          407,
          4696,
          341,
          486,
          855,
          505,
          300,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 415.04,
        "id": 156,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 412.36,
        "temperature": 0,
        "text": " All right, how about we write some code now?",
        "tokens": [
          50560,
          1057,
          558,
          11,
          577,
          466,
          321,
          2464,
          512,
          3089,
          586,
          30,
          50694
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 418.02,
        "id": 157,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 415.04,
        "temperature": 0,
        "text": " So actually, I magically appeared over here for a second,",
        "tokens": [
          50694,
          407,
          767,
          11,
          286,
          39763,
          8516,
          670,
          510,
          337,
          257,
          1150,
          11,
          50843
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 421.68,
        "id": 158,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 418.02,
        "temperature": 0,
        "text": " because instead of, I did make a little mistake here.",
        "tokens": [
          50843,
          570,
          2602,
          295,
          11,
          286,
          630,
          652,
          257,
          707,
          6146,
          510,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 423.24,
        "id": 159,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 421.68,
        "temperature": 0,
        "text": " I mean, root mean squared",
        "tokens": [
          51026,
          286,
          914,
          11,
          5593,
          914,
          8889,
          51104
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 426.8,
        "id": 160,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 423.24,
        "temperature": 0,
        "text": " is a perfectly legitimate loss function,",
        "tokens": [
          51104,
          307,
          257,
          6239,
          17956,
          4470,
          2445,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 430.56,
        "id": 161,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 426.8,
        "temperature": 0,
        "text": " but most linear regression with gradient descent examples",
        "tokens": [
          51282,
          457,
          881,
          8213,
          24590,
          365,
          16235,
          23475,
          5110,
          51470
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 432.64,
        "id": 162,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 430.56,
        "temperature": 0,
        "text": " will not bother with the root.",
        "tokens": [
          51470,
          486,
          406,
          8677,
          365,
          264,
          5593,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 434.56,
        "id": 163,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 432.64,
        "temperature": 0,
        "text": " And the root refers to square root.",
        "tokens": [
          51574,
          400,
          264,
          5593,
          14942,
          281,
          3732,
          5593,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2536213896995367,
        "compression_ratio": 1.6677966101694914,
        "end": 436.64,
        "id": 164,
        "no_speech_prob": 0.000003785323997362866,
        "seek": 40844,
        "start": 434.56,
        "temperature": 0,
        "text": " We just want the mean squared error,",
        "tokens": [
          51670,
          492,
          445,
          528,
          264,
          914,
          8889,
          6713,
          11,
          51774
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 441,
        "id": 165,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 436.64,
        "temperature": 0,
        "text": " which means, if I say that this value is y,",
        "tokens": [
          50364,
          597,
          1355,
          11,
          498,
          286,
          584,
          300,
          341,
          2158,
          307,
          288,
          11,
          50582
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 443.68,
        "id": 166,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 441,
        "temperature": 0,
        "text": " and this value is the guess,",
        "tokens": [
          50582,
          293,
          341,
          2158,
          307,
          264,
          2041,
          11,
          50716
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 450.03999999999996,
        "id": 167,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 445.03999999999996,
        "temperature": 0,
        "text": " the error is guess minus y and squared.",
        "tokens": [
          50784,
          264,
          6713,
          307,
          2041,
          3175,
          288,
          293,
          8889,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 454.36,
        "id": 168,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 450.64,
        "temperature": 0,
        "text": " And if I do that for all of these, that's the mean.",
        "tokens": [
          51064,
          400,
          498,
          286,
          360,
          300,
          337,
          439,
          295,
          613,
          11,
          300,
          311,
          264,
          914,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 455.71999999999997,
        "id": 169,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 454.36,
        "temperature": 0,
        "text": " And average them, it's the mean.",
        "tokens": [
          51250,
          400,
          4274,
          552,
          11,
          309,
          311,
          264,
          914,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 457.36,
        "id": 170,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 455.71999999999997,
        "temperature": 0,
        "text": " So I can really sum them or mean them.",
        "tokens": [
          51318,
          407,
          286,
          393,
          534,
          2408,
          552,
          420,
          914,
          552,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 460.03999999999996,
        "id": 171,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 457.36,
        "temperature": 0,
        "text": " Well, it's gonna take care of that for us.",
        "tokens": [
          51400,
          1042,
          11,
          309,
          311,
          799,
          747,
          1127,
          295,
          300,
          337,
          505,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 462.47999999999996,
        "id": 172,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 460.03999999999996,
        "temperature": 0,
        "text": " So we're just gonna use the mean squared error.",
        "tokens": [
          51534,
          407,
          321,
          434,
          445,
          799,
          764,
          264,
          914,
          8889,
          6713,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 463.71999999999997,
        "id": 173,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 462.47999999999996,
        "temperature": 0,
        "text": " But that's the idea.",
        "tokens": [
          51656,
          583,
          300,
          311,
          264,
          1558,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 465,
        "id": 174,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 463.71999999999997,
        "temperature": 0,
        "text": " We take the differences.",
        "tokens": [
          51718,
          492,
          747,
          264,
          7300,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.22199883571890897,
        "compression_ratio": 1.8385650224215246,
        "end": 466.52,
        "id": 175,
        "no_speech_prob": 8.579235100114602e-7,
        "seek": 43664,
        "start": 465,
        "temperature": 0,
        "text": " The reason why we have to square it,",
        "tokens": [
          51782,
          440,
          1778,
          983,
          321,
          362,
          281,
          3732,
          309,
          11,
          51858
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 468.24,
        "id": 176,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 467.4,
        "temperature": 0,
        "text": " well, for a variety of reasons.",
        "tokens": [
          50408,
          731,
          11,
          337,
          257,
          5673,
          295,
          4112,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 469.91999999999996,
        "id": 177,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 468.24,
        "temperature": 0,
        "text": " One, it has to do with the derivative stuff",
        "tokens": [
          50450,
          1485,
          11,
          309,
          575,
          281,
          360,
          365,
          264,
          13760,
          1507,
          50534
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 471.18,
        "id": 178,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 469.91999999999996,
        "temperature": 0,
        "text": " that's in my other videos,",
        "tokens": [
          50534,
          300,
          311,
          294,
          452,
          661,
          2145,
          11,
          50597
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 473.74,
        "id": 179,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 471.18,
        "temperature": 0,
        "text": " but also just because positive or negative,",
        "tokens": [
          50597,
          457,
          611,
          445,
          570,
          3353,
          420,
          3671,
          11,
          50725
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 477.64,
        "id": 180,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 475.28,
        "temperature": 0,
        "text": " it's the distance, the size of the error,",
        "tokens": [
          50802,
          309,
          311,
          264,
          4560,
          11,
          264,
          2744,
          295,
          264,
          6713,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 480.24,
        "id": 181,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 477.64,
        "temperature": 0,
        "text": " whether it's up or down, which is key.",
        "tokens": [
          50920,
          1968,
          309,
          311,
          493,
          420,
          760,
          11,
          597,
          307,
          2141,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 482.12,
        "id": 182,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 480.24,
        "temperature": 0,
        "text": " All right, so here's the amount of code",
        "tokens": [
          51050,
          1057,
          558,
          11,
          370,
          510,
          311,
          264,
          2372,
          295,
          3089,
          51144
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 482.96,
        "id": 183,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 482.12,
        "temperature": 0,
        "text": " we're gonna start with.",
        "tokens": [
          51144,
          321,
          434,
          799,
          722,
          365,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 485.84,
        "id": 184,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 482.96,
        "temperature": 0,
        "text": " I'm using p5 so that I can draw stuff.",
        "tokens": [
          51186,
          286,
          478,
          1228,
          280,
          20,
          370,
          300,
          286,
          393,
          2642,
          1507,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 488.68,
        "id": 185,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 485.84,
        "temperature": 0,
        "text": " I'm making a canvas, and the background is zero,",
        "tokens": [
          51330,
          286,
          478,
          1455,
          257,
          16267,
          11,
          293,
          264,
          3678,
          307,
          4018,
          11,
          51472
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 491.32,
        "id": 186,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 488.68,
        "temperature": 0,
        "text": " which means it's black, and this is what I have so far.",
        "tokens": [
          51472,
          597,
          1355,
          309,
          311,
          2211,
          11,
          293,
          341,
          307,
          437,
          286,
          362,
          370,
          1400,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.20404884913196303,
        "compression_ratio": 1.656140350877193,
        "end": 493.35999999999996,
        "id": 187,
        "no_speech_prob": 0.000002190777649957454,
        "seek": 46652,
        "start": 491.32,
        "temperature": 0,
        "text": " So let's look at our list over here,",
        "tokens": [
          51604,
          407,
          718,
          311,
          574,
          412,
          527,
          1329,
          670,
          510,
          11,
          51706
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 497.04,
        "id": 188,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 493.40000000000003,
        "temperature": 0,
        "text": " and let's first add the data set, the Xs and Ys.",
        "tokens": [
          50366,
          293,
          718,
          311,
          700,
          909,
          264,
          1412,
          992,
          11,
          264,
          1783,
          82,
          293,
          398,
          82,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 498.88,
        "id": 189,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 497.04,
        "temperature": 0,
        "text": " So this is gonna be easy,",
        "tokens": [
          50548,
          407,
          341,
          307,
          799,
          312,
          1858,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 503.88,
        "id": 190,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 498.88,
        "temperature": 0,
        "text": " because I just wanna have Xs be an array,",
        "tokens": [
          50640,
          570,
          286,
          445,
          1948,
          362,
          1783,
          82,
          312,
          364,
          10225,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 506.24,
        "id": 191,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 504.40000000000003,
        "temperature": 0,
        "text": " Ys also be an array.",
        "tokens": [
          50916,
          398,
          82,
          611,
          312,
          364,
          10225,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 510.22,
        "id": 192,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 506.24,
        "temperature": 0,
        "text": " So, and then, whenever I click the mouse,",
        "tokens": [
          51008,
          407,
          11,
          293,
          550,
          11,
          5699,
          286,
          2052,
          264,
          9719,
          11,
          51207
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 513.44,
        "id": 193,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 512.04,
        "temperature": 0,
        "text": " I wanna say, oh, you know what I could do?",
        "tokens": [
          51298,
          286,
          1948,
          584,
          11,
          1954,
          11,
          291,
          458,
          437,
          286,
          727,
          360,
          30,
          51368
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 515.16,
        "id": 194,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 513.44,
        "temperature": 0,
        "text": " I could make those vectors,",
        "tokens": [
          51368,
          286,
          727,
          652,
          729,
          18875,
          11,
          51454
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 516.92,
        "id": 195,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 515.16,
        "temperature": 0,
        "text": " let's make them separate arrays.",
        "tokens": [
          51454,
          718,
          311,
          652,
          552,
          4994,
          41011,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 518.28,
        "id": 196,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 516.92,
        "temperature": 0,
        "text": " I think we're gonna, actually, I know we're gonna,",
        "tokens": [
          51542,
          286,
          519,
          321,
          434,
          799,
          11,
          767,
          11,
          286,
          458,
          321,
          434,
          799,
          11,
          51610
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 519.94,
        "id": 197,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 518.28,
        "temperature": 0,
        "text": " we're gonna wanna do that for a variety of reasons.",
        "tokens": [
          51610,
          321,
          434,
          799,
          1948,
          360,
          300,
          337,
          257,
          5673,
          295,
          4112,
          13,
          51693
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 521.16,
        "id": 198,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 519.94,
        "temperature": 0,
        "text": " We're gonna keep those as separate arrays.",
        "tokens": [
          51693,
          492,
          434,
          799,
          1066,
          729,
          382,
          4994,
          41011,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.21298168467826584,
        "compression_ratio": 1.855421686746988,
        "end": 523.04,
        "id": 199,
        "no_speech_prob": 0.0000189251295523718,
        "seek": 49336,
        "start": 521.16,
        "temperature": 0,
        "text": " So every time I click the mouse,",
        "tokens": [
          51754,
          407,
          633,
          565,
          286,
          2052,
          264,
          9719,
          11,
          51848
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 527.24,
        "id": 200,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 523.68,
        "temperature": 0,
        "text": " I'm going to say Xs, push mouse X,",
        "tokens": [
          50396,
          286,
          478,
          516,
          281,
          584,
          1783,
          82,
          11,
          2944,
          9719,
          1783,
          11,
          50574
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 528.92,
        "id": 201,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 527.24,
        "temperature": 0,
        "text": " Ys, push mouse Y.",
        "tokens": [
          50574,
          398,
          82,
          11,
          2944,
          9719,
          398,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 530.12,
        "id": 202,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 528.92,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          50658,
          2438,
          11,
          1392,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 533.06,
        "id": 203,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 531.4,
        "temperature": 0,
        "text": " Here's a little thing.",
        "tokens": [
          50782,
          1692,
          311,
          257,
          707,
          551,
          13,
          50865
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 537.0799999999999,
        "id": 204,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 534.5999999999999,
        "temperature": 0,
        "text": " So this is our canvas, right?",
        "tokens": [
          50942,
          407,
          341,
          307,
          527,
          16267,
          11,
          558,
          30,
          51066
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 538.36,
        "id": 205,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 537.0799999999999,
        "temperature": 0,
        "text": " This is my drawing of the canvas.",
        "tokens": [
          51066,
          639,
          307,
          452,
          6316,
          295,
          264,
          16267,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 540.56,
        "id": 206,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 538.36,
        "temperature": 0,
        "text": " I know, now I'm having like a deja vu thing.",
        "tokens": [
          51130,
          286,
          458,
          11,
          586,
          286,
          478,
          1419,
          411,
          257,
          38260,
          9732,
          551,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 542.54,
        "id": 207,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 540.56,
        "temperature": 0,
        "text": " I totally talked about this in the other video.",
        "tokens": [
          51240,
          286,
          3879,
          2825,
          466,
          341,
          294,
          264,
          661,
          960,
          13,
          51339
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 545.64,
        "id": 208,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 542.54,
        "temperature": 0,
        "text": " The width is like 400, the height is 400,",
        "tokens": [
          51339,
          440,
          11402,
          307,
          411,
          8423,
          11,
          264,
          6681,
          307,
          8423,
          11,
          51494
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 547.9599999999999,
        "id": 209,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 545.64,
        "temperature": 0,
        "text": " but I really wanna think of this as,",
        "tokens": [
          51494,
          457,
          286,
          534,
          1948,
          519,
          295,
          341,
          382,
          11,
          51610
        ]
      },
      {
        "avg_logprob": -0.2726220231715257,
        "compression_ratio": 1.6457399103139014,
        "end": 551.9599999999999,
        "id": 210,
        "no_speech_prob": 0.00001342000177828595,
        "seek": 52304,
        "start": 549.36,
        "temperature": 0,
        "text": " I really wanna think of zero, zero down here,",
        "tokens": [
          51680,
          286,
          534,
          1948,
          519,
          295,
          4018,
          11,
          4018,
          760,
          510,
          11,
          51810
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 553.44,
        "id": 211,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 551.96,
        "temperature": 0,
        "text": " and maybe one being over here.",
        "tokens": [
          50364,
          293,
          1310,
          472,
          885,
          670,
          510,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 555.76,
        "id": 212,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 553.44,
        "temperature": 0,
        "text": " I wanna normalize everything between zero and one.",
        "tokens": [
          50438,
          286,
          1948,
          2710,
          1125,
          1203,
          1296,
          4018,
          293,
          472,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 557.9200000000001,
        "id": 213,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 555.76,
        "temperature": 0,
        "text": " Everything's just gonna work better if we do that.",
        "tokens": [
          50554,
          5471,
          311,
          445,
          799,
          589,
          1101,
          498,
          321,
          360,
          300,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 559.6800000000001,
        "id": 214,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 557.9200000000001,
        "temperature": 0,
        "text": " So with Y pointing up.",
        "tokens": [
          50662,
          407,
          365,
          398,
          12166,
          493,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 561.2800000000001,
        "id": 215,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 559.6800000000001,
        "temperature": 0,
        "text": " So I'm gonna do a mapping.",
        "tokens": [
          50750,
          407,
          286,
          478,
          799,
          360,
          257,
          18350,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 565.1,
        "id": 216,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 561.2800000000001,
        "temperature": 0,
        "text": " So every Y value, that's pixel value between zero and height,",
        "tokens": [
          50830,
          407,
          633,
          398,
          2158,
          11,
          300,
          311,
          19261,
          2158,
          1296,
          4018,
          293,
          6681,
          11,
          51021
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 567.08,
        "id": 217,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 565.1,
        "temperature": 0,
        "text": " I'm gonna map between one and zero,",
        "tokens": [
          51021,
          286,
          478,
          799,
          4471,
          1296,
          472,
          293,
          4018,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 569.32,
        "id": 218,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 567.08,
        "temperature": 0,
        "text": " and every X value that's between zero and width,",
        "tokens": [
          51120,
          293,
          633,
          1783,
          2158,
          300,
          311,
          1296,
          4018,
          293,
          11402,
          11,
          51232
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 571.2800000000001,
        "id": 219,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 569.32,
        "temperature": 0,
        "text": " I'm gonna map between zero and one.",
        "tokens": [
          51232,
          286,
          478,
          799,
          4471,
          1296,
          4018,
          293,
          472,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 572.84,
        "id": 220,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 571.2800000000001,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51330,
          407,
          718,
          311,
          360,
          300,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.18493613901064376,
        "compression_ratio": 1.9324324324324325,
        "end": 577.84,
        "id": 221,
        "no_speech_prob": 0.000006643431788688758,
        "seek": 55196,
        "start": 572.84,
        "temperature": 0,
        "text": " So I'm going to say, let X equal map mouse X,",
        "tokens": [
          51408,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          718,
          1783,
          2681,
          4471,
          9719,
          1783,
          11,
          51658
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 580.96,
        "id": 222,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 578.0400000000001,
        "temperature": 0,
        "text": " which goes between zero and width,",
        "tokens": [
          50374,
          597,
          1709,
          1296,
          4018,
          293,
          11402,
          11,
          50520
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 583.1600000000001,
        "id": 223,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 580.96,
        "temperature": 0,
        "text": " to between zero and one.",
        "tokens": [
          50520,
          281,
          1296,
          4018,
          293,
          472,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 589.2,
        "id": 224,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 584.2,
        "temperature": 0,
        "text": " Let Y, which is mouse Y, between zero and height,",
        "tokens": [
          50682,
          961,
          398,
          11,
          597,
          307,
          9719,
          398,
          11,
          1296,
          4018,
          293,
          6681,
          11,
          50932
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 592.6,
        "id": 225,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 589.64,
        "temperature": 0,
        "text": " and have that go between one and zero,",
        "tokens": [
          50954,
          293,
          362,
          300,
          352,
          1296,
          472,
          293,
          4018,
          11,
          51102
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 595.08,
        "id": 226,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 592.6,
        "temperature": 0,
        "text": " and then push X and push Y.",
        "tokens": [
          51102,
          293,
          550,
          2944,
          1783,
          293,
          2944,
          398,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 599.4,
        "id": 227,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 596.64,
        "temperature": 0,
        "text": " The other thing I wanna do is I just want to,",
        "tokens": [
          51304,
          440,
          661,
          551,
          286,
          1948,
          360,
          307,
          286,
          445,
          528,
          281,
          11,
          51442
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 602.44,
        "id": 228,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 599.4,
        "temperature": 0,
        "text": " you know, I'm gonna add a draw loop,",
        "tokens": [
          51442,
          291,
          458,
          11,
          286,
          478,
          799,
          909,
          257,
          2642,
          6367,
          11,
          51594
        ]
      },
      {
        "avg_logprob": -0.2389915715093198,
        "compression_ratio": 1.68,
        "end": 604.22,
        "id": 229,
        "no_speech_prob": 1.944432739264812e-7,
        "seek": 57784,
        "start": 602.44,
        "temperature": 0,
        "text": " and I wanna draw all those points.",
        "tokens": [
          51594,
          293,
          286,
          1948,
          2642,
          439,
          729,
          2793,
          13,
          51683
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 607.3000000000001,
        "id": 230,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 605.14,
        "temperature": 0,
        "text": " So I'm also now gonna say,",
        "tokens": [
          50410,
          407,
          286,
          478,
          611,
          586,
          799,
          584,
          11,
          50518
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 612.78,
        "id": 231,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 608.9,
        "temperature": 0,
        "text": " stroke 255, stroke weight four,",
        "tokens": [
          50598,
          12403,
          3552,
          20,
          11,
          12403,
          3364,
          1451,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 617.34,
        "id": 232,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 612.78,
        "temperature": 0,
        "text": " for let I equal, what, huh?",
        "tokens": [
          50792,
          337,
          718,
          286,
          2681,
          11,
          437,
          11,
          7020,
          30,
          51020
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 622.34,
        "id": 233,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 617.34,
        "temperature": 0,
        "text": " Let I equal zero, I is less than X dot length, I plus plus,",
        "tokens": [
          51020,
          961,
          286,
          2681,
          4018,
          11,
          286,
          307,
          1570,
          813,
          1783,
          5893,
          4641,
          11,
          286,
          1804,
          1804,
          11,
          51270
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 626.86,
        "id": 234,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 623.14,
        "temperature": 0,
        "text": " and those are actually called Xs, Xs dot length.",
        "tokens": [
          51310,
          293,
          729,
          366,
          767,
          1219,
          1783,
          82,
          11,
          1783,
          82,
          5893,
          4641,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 630.26,
        "id": 235,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 628.5400000000001,
        "temperature": 0,
        "text": " And what I'm gonna do is I'm gonna say,",
        "tokens": [
          51580,
          400,
          437,
          286,
          478,
          799,
          360,
          307,
          286,
          478,
          799,
          584,
          11,
          51666
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 632.14,
        "id": 236,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 630.26,
        "temperature": 0,
        "text": " let pixel X equal map.",
        "tokens": [
          51666,
          718,
          19261,
          1783,
          2681,
          4471,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2951297370754943,
        "compression_ratio": 1.5425531914893618,
        "end": 633.74,
        "id": 237,
        "no_speech_prob": 0.000031693241908214986,
        "seek": 60422,
        "start": 632.14,
        "temperature": 0,
        "text": " I really should make just like,",
        "tokens": [
          51760,
          286,
          534,
          820,
          652,
          445,
          411,
          11,
          51840
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 635.08,
        "id": 238,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 634.26,
        "temperature": 0,
        "text": " I'm probably gonna have to do this a lot,",
        "tokens": [
          50390,
          286,
          478,
          1391,
          799,
          362,
          281,
          360,
          341,
          257,
          688,
          11,
          50431
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 636.34,
        "id": 239,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 635.08,
        "temperature": 0,
        "text": " so I should probably make a function",
        "tokens": [
          50431,
          370,
          286,
          820,
          1391,
          652,
          257,
          2445,
          50494
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 640.26,
        "id": 240,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 636.34,
        "temperature": 0,
        "text": " that just like normalize and un-normalize or de-normalize.",
        "tokens": [
          50494,
          300,
          445,
          411,
          2710,
          1125,
          293,
          517,
          12,
          23157,
          1125,
          420,
          368,
          12,
          23157,
          1125,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 643.58,
        "id": 241,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 640.26,
        "temperature": 0,
        "text": " Pix, PX equals map X's index I,",
        "tokens": [
          50690,
          18652,
          11,
          430,
          55,
          6915,
          4471,
          1783,
          311,
          8186,
          286,
          11,
          50856
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 646.0600000000001,
        "id": 242,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 643.58,
        "temperature": 0,
        "text": " which goes between zero and one, back to zero and width.",
        "tokens": [
          50856,
          597,
          1709,
          1296,
          4018,
          293,
          472,
          11,
          646,
          281,
          4018,
          293,
          11402,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 647.94,
        "id": 243,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 646.0600000000001,
        "temperature": 0,
        "text": " So this is the reverse.",
        "tokens": [
          50980,
          407,
          341,
          307,
          264,
          9943,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 652.82,
        "id": 244,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 647.94,
        "temperature": 0,
        "text": " PY, which maps Y, which goes between zero and one",
        "tokens": [
          51074,
          430,
          56,
          11,
          597,
          11317,
          398,
          11,
          597,
          1709,
          1296,
          4018,
          293,
          472,
          51318
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 657.34,
        "id": 245,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 652.82,
        "temperature": 0,
        "text": " to height comma zero.",
        "tokens": [
          51318,
          281,
          6681,
          22117,
          4018,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 660.9,
        "id": 246,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 657.34,
        "temperature": 0,
        "text": " And then I wanna say, point PX, PY.",
        "tokens": [
          51544,
          400,
          550,
          286,
          1948,
          584,
          11,
          935,
          430,
          55,
          11,
          430,
          56,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.2418242609778116,
        "compression_ratio": 1.703862660944206,
        "end": 662.5,
        "id": 247,
        "no_speech_prob": 0.000002156816208298551,
        "seek": 63374,
        "start": 660.9,
        "temperature": 0,
        "text": " So I haven't done any, I haven't even,",
        "tokens": [
          51722,
          407,
          286,
          2378,
          380,
          1096,
          604,
          11,
          286,
          2378,
          380,
          754,
          11,
          51802
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 665.34,
        "id": 248,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 662.5,
        "temperature": 0,
        "text": " I'm not even using TensorFlow.js yet.",
        "tokens": [
          50364,
          286,
          478,
          406,
          754,
          1228,
          37624,
          13,
          25530,
          1939,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 668.62,
        "id": 249,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 665.34,
        "temperature": 0,
        "text": " I'm just kind of doing the stuff with P5 to draw things.",
        "tokens": [
          50506,
          286,
          478,
          445,
          733,
          295,
          884,
          264,
          1507,
          365,
          430,
          20,
          281,
          2642,
          721,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 671.38,
        "id": 250,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 668.62,
        "temperature": 0,
        "text": " So let's see if I'm getting the results that I want,",
        "tokens": [
          50670,
          407,
          718,
          311,
          536,
          498,
          286,
          478,
          1242,
          264,
          3542,
          300,
          286,
          528,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 673.98,
        "id": 251,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 671.38,
        "temperature": 0,
        "text": " which is whenever I click, I get the points there.",
        "tokens": [
          50808,
          597,
          307,
          5699,
          286,
          2052,
          11,
          286,
          483,
          264,
          2793,
          456,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 674.86,
        "id": 252,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 673.98,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          50938,
          10246,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 676.58,
        "id": 253,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 674.86,
        "temperature": 0,
        "text": " And I kind of wanna see them a bit more.",
        "tokens": [
          50982,
          400,
          286,
          733,
          295,
          1948,
          536,
          552,
          257,
          857,
          544,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 678.42,
        "id": 254,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 676.58,
        "temperature": 0,
        "text": " Let's like really make it bigger.",
        "tokens": [
          51068,
          961,
          311,
          411,
          534,
          652,
          309,
          3801,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 679.78,
        "id": 255,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 678.42,
        "temperature": 0,
        "text": " Great, that's like too big.",
        "tokens": [
          51160,
          3769,
          11,
          300,
          311,
          411,
          886,
          955,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 682.42,
        "id": 256,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 680.62,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          51270,
          1033,
          11,
          869,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 684.74,
        "id": 257,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 682.42,
        "temperature": 0,
        "text": " So we can see, those are the points I'm clicking on.",
        "tokens": [
          51360,
          407,
          321,
          393,
          536,
          11,
          729,
          366,
          264,
          2793,
          286,
          478,
          9697,
          322,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 687.54,
        "id": 258,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 684.74,
        "temperature": 0,
        "text": " Okay, so what's next?",
        "tokens": [
          51476,
          1033,
          11,
          370,
          437,
          311,
          958,
          30,
          51616
        ]
      },
      {
        "avg_logprob": -0.19079572504216974,
        "compression_ratio": 1.6407407407407408,
        "end": 690.22,
        "id": 259,
        "no_speech_prob": 0.000012029629942844622,
        "seek": 66250,
        "start": 687.54,
        "temperature": 0,
        "text": " I need a loss function, I need an optimizer.",
        "tokens": [
          51616,
          286,
          643,
          257,
          4470,
          2445,
          11,
          286,
          643,
          364,
          5028,
          6545,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 692.62,
        "id": 260,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 690.22,
        "temperature": 0,
        "text": " Ah, oh, I need these.",
        "tokens": [
          50364,
          2438,
          11,
          1954,
          11,
          286,
          643,
          613,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 693.94,
        "id": 261,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 692.62,
        "temperature": 0,
        "text": " Let's make these.",
        "tokens": [
          50484,
          961,
          311,
          652,
          613,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 695.4200000000001,
        "id": 262,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 693.94,
        "temperature": 0,
        "text": " So, cause I'm looking for somewhere",
        "tokens": [
          50550,
          407,
          11,
          3082,
          286,
          478,
          1237,
          337,
          4079,
          50624
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 698.72,
        "id": 263,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 695.4200000000001,
        "temperature": 0,
        "text": " where I need to get some TensorFlow.js stuff working.",
        "tokens": [
          50624,
          689,
          286,
          643,
          281,
          483,
          512,
          37624,
          13,
          25530,
          1507,
          1364,
          13,
          50789
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 702.62,
        "id": 264,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 698.72,
        "temperature": 0,
        "text": " So what I need is I need to have M and B.",
        "tokens": [
          50789,
          407,
          437,
          286,
          643,
          307,
          286,
          643,
          281,
          362,
          376,
          293,
          363,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 704.38,
        "id": 265,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 702.62,
        "temperature": 0,
        "text": " So let's figure that out.",
        "tokens": [
          50984,
          407,
          718,
          311,
          2573,
          300,
          484,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 709.38,
        "id": 266,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 704.38,
        "temperature": 0,
        "text": " So I'm going to create an M and a B.",
        "tokens": [
          51072,
          407,
          286,
          478,
          516,
          281,
          1884,
          364,
          376,
          293,
          257,
          363,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 714.62,
        "id": 267,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 710.5400000000001,
        "temperature": 0,
        "text": " And I'm not gonna initialize them in setup, up here.",
        "tokens": [
          51380,
          400,
          286,
          478,
          406,
          799,
          5883,
          1125,
          552,
          294,
          8657,
          11,
          493,
          510,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 717.4200000000001,
        "id": 268,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 714.62,
        "temperature": 0,
        "text": " And I probably should be using const in various places here",
        "tokens": [
          51584,
          400,
          286,
          1391,
          820,
          312,
          1228,
          1817,
          294,
          3683,
          3190,
          510,
          51724
        ]
      },
      {
        "avg_logprob": -0.19950297621429944,
        "compression_ratio": 1.6265060240963856,
        "end": 719.86,
        "id": 269,
        "no_speech_prob": 0.000013846001820638776,
        "seek": 69022,
        "start": 717.4200000000001,
        "temperature": 0,
        "text": " to protect myself from reassigning something by accident,",
        "tokens": [
          51724,
          281,
          2371,
          2059,
          490,
          19486,
          9676,
          746,
          538,
          6398,
          11,
          51846
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 722.86,
        "id": 270,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 720.5,
        "temperature": 0,
        "text": " but I'm gonna be loosey goosey and just use let.",
        "tokens": [
          50396,
          457,
          286,
          478,
          799,
          312,
          9612,
          88,
          24717,
          88,
          293,
          445,
          764,
          718,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 726.42,
        "id": 271,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 725.3000000000001,
        "temperature": 0,
        "text": " You know, these could be const.",
        "tokens": [
          50636,
          509,
          458,
          11,
          613,
          727,
          312,
          1817,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 728.1800000000001,
        "id": 272,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 726.42,
        "temperature": 0,
        "text": " But anyway, I'm not gonna get into the whole let",
        "tokens": [
          50692,
          583,
          4033,
          11,
          286,
          478,
          406,
          799,
          483,
          666,
          264,
          1379,
          718,
          50780
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 730.3000000000001,
        "id": 273,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 728.1800000000001,
        "temperature": 0,
        "text": " versus const thing, it makes me crazy.",
        "tokens": [
          50780,
          5717,
          1817,
          551,
          11,
          309,
          1669,
          385,
          3219,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 735.3000000000001,
        "id": 274,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 730.3000000000001,
        "temperature": 0,
        "text": " I'm gonna say up here, M equals TF scalar random one.",
        "tokens": [
          50886,
          286,
          478,
          799,
          584,
          493,
          510,
          11,
          376,
          6915,
          40964,
          39684,
          4974,
          472,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 739.46,
        "id": 275,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 736.94,
        "temperature": 0,
        "text": " So I'm gonna use the P5 random function",
        "tokens": [
          51218,
          407,
          286,
          478,
          799,
          764,
          264,
          430,
          20,
          4974,
          2445,
          51344
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 741.1,
        "id": 276,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 739.46,
        "temperature": 0,
        "text": " to give me a random number between zero and one,",
        "tokens": [
          51344,
          281,
          976,
          385,
          257,
          4974,
          1230,
          1296,
          4018,
          293,
          472,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 742.46,
        "id": 277,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 741.1,
        "temperature": 0,
        "text": " cause I gotta start somewhere.",
        "tokens": [
          51426,
          3082,
          286,
          3428,
          722,
          4079,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 744.72,
        "id": 278,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 742.46,
        "temperature": 0,
        "text": " So this is kind of like initializing the weights",
        "tokens": [
          51494,
          407,
          341,
          307,
          733,
          295,
          411,
          5883,
          3319,
          264,
          17443,
          51607
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 745.5600000000001,
        "id": 279,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 744.72,
        "temperature": 0,
        "text": " of a neural network.",
        "tokens": [
          51607,
          295,
          257,
          18161,
          3209,
          13,
          51649
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 746.38,
        "id": 280,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 745.5600000000001,
        "temperature": 0,
        "text": " There is no neural network,",
        "tokens": [
          51649,
          821,
          307,
          572,
          18161,
          3209,
          11,
          51690
        ]
      },
      {
        "avg_logprob": -0.2618025154903017,
        "compression_ratio": 1.7206896551724138,
        "end": 749.22,
        "id": 281,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 71986,
        "start": 746.38,
        "temperature": 0,
        "text": " I'm just doing, I'm just kind of optimizing this function,",
        "tokens": [
          51690,
          286,
          478,
          445,
          884,
          11,
          286,
          478,
          445,
          733,
          295,
          40425,
          341,
          2445,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 752.6600000000001,
        "id": 282,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 749.22,
        "temperature": 0,
        "text": " Y equals MX plus B, but those are like weights, M and B.",
        "tokens": [
          50364,
          398,
          6915,
          47509,
          1804,
          363,
          11,
          457,
          729,
          366,
          411,
          17443,
          11,
          376,
          293,
          363,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 754.1,
        "id": 283,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 752.6600000000001,
        "temperature": 0,
        "text": " So I'm gonna initialize them randomly",
        "tokens": [
          50536,
          407,
          286,
          478,
          799,
          5883,
          1125,
          552,
          16979,
          50608
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 756.14,
        "id": 284,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 754.1,
        "temperature": 0,
        "text": " and scalar cause it's a single number.",
        "tokens": [
          50608,
          293,
          39684,
          3082,
          309,
          311,
          257,
          2167,
          1230,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 759.4200000000001,
        "id": 285,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 756.14,
        "temperature": 0,
        "text": " So go back to my TensorFlow.js intro videos and you'll see.",
        "tokens": [
          50710,
          407,
          352,
          646,
          281,
          452,
          37624,
          13,
          25530,
          12897,
          2145,
          293,
          291,
          603,
          536,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 762.82,
        "id": 286,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 759.4200000000001,
        "temperature": 0,
        "text": " Then B, I'm gonna say the same thing, ah, but,",
        "tokens": [
          50874,
          1396,
          363,
          11,
          286,
          478,
          799,
          584,
          264,
          912,
          551,
          11,
          3716,
          11,
          457,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 766.38,
        "id": 287,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 763.86,
        "temperature": 0,
        "text": " these are the things that have to change, right?",
        "tokens": [
          51096,
          613,
          366,
          264,
          721,
          300,
          362,
          281,
          1319,
          11,
          558,
          30,
          51222
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 769.7,
        "id": 288,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 766.38,
        "temperature": 0,
        "text": " The data never changes, it's sort of fixed.",
        "tokens": [
          51222,
          440,
          1412,
          1128,
          2962,
          11,
          309,
          311,
          1333,
          295,
          6806,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 771.74,
        "id": 289,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 769.7,
        "temperature": 0,
        "text": " M and B change over time.",
        "tokens": [
          51388,
          376,
          293,
          363,
          1319,
          670,
          565,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 775.14,
        "id": 290,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 771.74,
        "temperature": 0,
        "text": " I need to tweak those, which means they have to be variable.",
        "tokens": [
          51490,
          286,
          643,
          281,
          29879,
          729,
          11,
          597,
          1355,
          436,
          362,
          281,
          312,
          7006,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.2417110744997752,
        "compression_ratio": 1.684782608695652,
        "end": 777.82,
        "id": 291,
        "no_speech_prob": 0.000011125604032713454,
        "seek": 74922,
        "start": 775.14,
        "temperature": 0,
        "text": " They have to be able to change, which means,",
        "tokens": [
          51660,
          814,
          362,
          281,
          312,
          1075,
          281,
          1319,
          11,
          597,
          1355,
          11,
          51794
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 781.1,
        "id": 292,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 777.82,
        "temperature": 0,
        "text": " when I over here, I think what I write is TF variable,",
        "tokens": [
          50364,
          562,
          286,
          670,
          510,
          11,
          286,
          519,
          437,
          286,
          2464,
          307,
          40964,
          7006,
          11,
          50528
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 783.1800000000001,
        "id": 293,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 781.1,
        "temperature": 0,
        "text": " I wrap them in the TF variable.",
        "tokens": [
          50528,
          286,
          7019,
          552,
          294,
          264,
          40964,
          7006,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 789.0600000000001,
        "id": 294,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 784.1,
        "temperature": 0,
        "text": " So now I have M and B as TF variable, right?",
        "tokens": [
          50678,
          407,
          586,
          286,
          362,
          376,
          293,
          363,
          382,
          40964,
          7006,
          11,
          558,
          30,
          50926
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 790.86,
        "id": 295,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 789.0600000000001,
        "temperature": 0,
        "text": " Isn't it crazy, like you see this kind of code",
        "tokens": [
          50926,
          6998,
          380,
          309,
          3219,
          11,
          411,
          291,
          536,
          341,
          733,
          295,
          3089,
          51016
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 791.7800000000001,
        "id": 296,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 790.86,
        "temperature": 0,
        "text": " and you're like, that looks like",
        "tokens": [
          51016,
          293,
          291,
          434,
          411,
          11,
          300,
          1542,
          411,
          51062
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 793.46,
        "id": 297,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 791.7800000000001,
        "temperature": 0,
        "text": " the craziest, scariest thing,",
        "tokens": [
          51062,
          264,
          46339,
          11,
          47755,
          551,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 795.7,
        "id": 298,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 793.46,
        "temperature": 0,
        "text": " but you realize like it's just like, make a number,",
        "tokens": [
          51146,
          457,
          291,
          4325,
          411,
          309,
          311,
          445,
          411,
          11,
          652,
          257,
          1230,
          11,
          51258
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 798.5400000000001,
        "id": 299,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 795.7,
        "temperature": 0,
        "text": " and because we're in this like kind of lower level,",
        "tokens": [
          51258,
          293,
          570,
          321,
          434,
          294,
          341,
          411,
          733,
          295,
          3126,
          1496,
          11,
          51400
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 801.74,
        "id": 300,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 798.5400000000001,
        "temperature": 0,
        "text": " working on the GPU land, I've gotta be very like specific.",
        "tokens": [
          51400,
          1364,
          322,
          264,
          18407,
          2117,
          11,
          286,
          600,
          3428,
          312,
          588,
          411,
          2685,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 804.62,
        "id": 301,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 801.74,
        "temperature": 0,
        "text": " Like this is a single number and it's gonna be variable,",
        "tokens": [
          51560,
          1743,
          341,
          307,
          257,
          2167,
          1230,
          293,
          309,
          311,
          799,
          312,
          7006,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.232750461526113,
        "compression_ratio": 1.726643598615917,
        "end": 807.34,
        "id": 302,
        "no_speech_prob": 0.0000029944405923743034,
        "seek": 77782,
        "start": 804.62,
        "temperature": 0,
        "text": " but really it's just a random number.",
        "tokens": [
          51704,
          457,
          534,
          309,
          311,
          445,
          257,
          4974,
          1230,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 810.4200000000001,
        "id": 303,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 808.1800000000001,
        "temperature": 0,
        "text": " Now, what do we need to do?",
        "tokens": [
          50406,
          823,
          11,
          437,
          360,
          321,
          643,
          281,
          360,
          30,
          50518
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 813.94,
        "id": 304,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 810.4200000000001,
        "temperature": 0,
        "text": " We need to write, I don't think I actually said this,",
        "tokens": [
          50518,
          492,
          643,
          281,
          2464,
          11,
          286,
          500,
          380,
          519,
          286,
          767,
          848,
          341,
          11,
          50694
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 818.7800000000001,
        "id": 305,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 813.94,
        "temperature": 0,
        "text": " but I need to write a function called predict maybe,",
        "tokens": [
          50694,
          457,
          286,
          643,
          281,
          2464,
          257,
          2445,
          1219,
          6069,
          1310,
          11,
          50936
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 825.1,
        "id": 306,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 820.1,
        "temperature": 0,
        "text": " which takes in all of the Xs, just the Xs,",
        "tokens": [
          51002,
          597,
          2516,
          294,
          439,
          295,
          264,
          1783,
          82,
          11,
          445,
          264,
          1783,
          82,
          11,
          51252
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 828.58,
        "id": 307,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 825.26,
        "temperature": 0,
        "text": " and gives me the Y predictions based on where the line is.",
        "tokens": [
          51260,
          293,
          2709,
          385,
          264,
          398,
          21264,
          2361,
          322,
          689,
          264,
          1622,
          307,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 830.34,
        "id": 308,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 828.58,
        "temperature": 0,
        "text": " Because I need to compare the Y predictions",
        "tokens": [
          51426,
          1436,
          286,
          643,
          281,
          6794,
          264,
          398,
          21264,
          51514
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 833.4200000000001,
        "id": 309,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 830.34,
        "temperature": 0,
        "text": " to the actual Y values to get the mean squared error.",
        "tokens": [
          51514,
          281,
          264,
          3539,
          398,
          4190,
          281,
          483,
          264,
          914,
          8889,
          6713,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2019420659767007,
        "compression_ratio": 1.7009345794392523,
        "end": 836.22,
        "id": 310,
        "no_speech_prob": 3.41258612479578e-7,
        "seek": 80734,
        "start": 834.6600000000001,
        "temperature": 0,
        "text": " So let's write that function.",
        "tokens": [
          51730,
          407,
          718,
          311,
          2464,
          300,
          2445,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 838.5,
        "id": 311,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 836.78,
        "temperature": 0,
        "text": " I'm putting these in like arbitrary places,",
        "tokens": [
          50392,
          286,
          478,
          3372,
          613,
          294,
          411,
          23211,
          3190,
          11,
          50478
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 841.7,
        "id": 312,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 838.5,
        "temperature": 0,
        "text": " but I'm gonna write a function called predict.",
        "tokens": [
          50478,
          457,
          286,
          478,
          799,
          2464,
          257,
          2445,
          1219,
          6069,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 846.7,
        "id": 313,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 841.7,
        "temperature": 0,
        "text": " And there what I need to do is I need to have some Xs",
        "tokens": [
          50638,
          400,
          456,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          362,
          512,
          1783,
          82,
          50888
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 852.1600000000001,
        "id": 314,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 849.74,
        "temperature": 0,
        "text": " and I need to return some Ys.",
        "tokens": [
          51040,
          293,
          286,
          643,
          281,
          2736,
          512,
          398,
          82,
          13,
          51161
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 855.22,
        "id": 315,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 854.02,
        "temperature": 0,
        "text": " I think that's the idea, right?",
        "tokens": [
          51254,
          286,
          519,
          300,
          311,
          264,
          1558,
          11,
          558,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 858.5400000000001,
        "id": 316,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 855.22,
        "temperature": 0,
        "text": " Yes, so I don't wanna just predict one value,",
        "tokens": [
          51314,
          1079,
          11,
          370,
          286,
          500,
          380,
          1948,
          445,
          6069,
          472,
          2158,
          11,
          51480
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 859.6600000000001,
        "id": 317,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 858.5400000000001,
        "temperature": 0,
        "text": " I wanna predict a bunch.",
        "tokens": [
          51480,
          286,
          1948,
          6069,
          257,
          3840,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 861.4200000000001,
        "id": 318,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 859.6600000000001,
        "temperature": 0,
        "text": " So the Xs, here's the thing.",
        "tokens": [
          51536,
          407,
          264,
          1783,
          82,
          11,
          510,
          311,
          264,
          551,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.21877328339997712,
        "compression_ratio": 1.6208530805687205,
        "end": 864.98,
        "id": 319,
        "no_speech_prob": 0.000013845998182659969,
        "seek": 83622,
        "start": 861.4200000000001,
        "temperature": 0,
        "text": " So if I call this function, the Xs,",
        "tokens": [
          51624,
          407,
          498,
          286,
          818,
          341,
          2445,
          11,
          264,
          1783,
          82,
          11,
          51802
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 866.78,
        "id": 320,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 864.98,
        "temperature": 0,
        "text": " if they're just a plain array,",
        "tokens": [
          50364,
          498,
          436,
          434,
          445,
          257,
          11121,
          10225,
          11,
          50454
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 869.22,
        "id": 321,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 866.78,
        "temperature": 0,
        "text": " I need to make it into a tensor.",
        "tokens": [
          50454,
          286,
          643,
          281,
          652,
          309,
          666,
          257,
          40863,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 873.34,
        "id": 322,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 869.22,
        "temperature": 0,
        "text": " So I'm gonna call it const TF Xs.",
        "tokens": [
          50576,
          407,
          286,
          478,
          799,
          818,
          309,
          1817,
          40964,
          1783,
          82,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 875.74,
        "id": 323,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 873.34,
        "temperature": 0,
        "text": " That might be a bad, it's tensor.",
        "tokens": [
          50782,
          663,
          1062,
          312,
          257,
          1578,
          11,
          309,
          311,
          40863,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 880.58,
        "id": 324,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 876.7,
        "temperature": 0,
        "text": " And this is a 1D tensor, tensor 1D.",
        "tokens": [
          50950,
          400,
          341,
          307,
          257,
          502,
          35,
          40863,
          11,
          40863,
          502,
          35,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 888.46,
        "id": 325,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 883.46,
        "temperature": 0,
        "text": " Oh, TF, tensor 1D, I think this will do it, Xs, right?",
        "tokens": [
          51288,
          876,
          11,
          40964,
          11,
          40863,
          502,
          35,
          11,
          286,
          519,
          341,
          486,
          360,
          309,
          11,
          1783,
          82,
          11,
          558,
          30,
          51538
        ]
      },
      {
        "avg_logprob": -0.30145972402472243,
        "compression_ratio": 1.536144578313253,
        "end": 891.38,
        "id": 326,
        "no_speech_prob": 0.000004860447006649338,
        "seek": 86498,
        "start": 889.46,
        "temperature": 0,
        "text": " I need to turn it into a tensor.",
        "tokens": [
          51588,
          286,
          643,
          281,
          1261,
          309,
          666,
          257,
          40863,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2663939570037412,
        "compression_ratio": 1.4055944055944056,
        "end": 897.38,
        "id": 327,
        "no_speech_prob": 0.00000139254632358643,
        "seek": 89138,
        "start": 892.38,
        "temperature": 0,
        "text": " And then I need to have the formula for a line.",
        "tokens": [
          50414,
          400,
          550,
          286,
          643,
          281,
          362,
          264,
          8513,
          337,
          257,
          1622,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2663939570037412,
        "compression_ratio": 1.4055944055944056,
        "end": 905.18,
        "id": 328,
        "no_speech_prob": 0.00000139254632358643,
        "seek": 89138,
        "start": 900.18,
        "temperature": 0,
        "text": " So I need to say, which is Y equals MX plus B.",
        "tokens": [
          50804,
          407,
          286,
          643,
          281,
          584,
          11,
          597,
          307,
          398,
          6915,
          47509,
          1804,
          363,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.2663939570037412,
        "compression_ratio": 1.4055944055944056,
        "end": 911.26,
        "id": 329,
        "no_speech_prob": 0.00000139254632358643,
        "seek": 89138,
        "start": 906.26,
        "temperature": 0,
        "text": " So what I would be doing is I would be saying TF Xs",
        "tokens": [
          51108,
          407,
          437,
          286,
          576,
          312,
          884,
          307,
          286,
          576,
          312,
          1566,
          40964,
          1783,
          82,
          51358
        ]
      },
      {
        "avg_logprob": -0.2663939570037412,
        "compression_ratio": 1.4055944055944056,
        "end": 915.74,
        "id": 330,
        "no_speech_prob": 0.00000139254632358643,
        "seek": 89138,
        "start": 911.34,
        "temperature": 0,
        "text": " multiplied, is it MUL or MULT?",
        "tokens": [
          51362,
          17207,
          11,
          307,
          309,
          376,
          10253,
          420,
          376,
          10253,
          51,
          30,
          51582
        ]
      },
      {
        "avg_logprob": -0.2663939570037412,
        "compression_ratio": 1.4055944055944056,
        "end": 918.2,
        "id": 331,
        "no_speech_prob": 0.00000139254632358643,
        "seek": 89138,
        "start": 915.74,
        "temperature": 0,
        "text": " Multiplied by M plus B.",
        "tokens": [
          51582,
          29238,
          564,
          1091,
          538,
          376,
          1804,
          363,
          13,
          51705
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 922.88,
        "id": 332,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 919.12,
        "temperature": 0,
        "text": " Right, this is the idea.",
        "tokens": [
          50410,
          1779,
          11,
          341,
          307,
          264,
          1558,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 926.72,
        "id": 333,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 924,
        "temperature": 0,
        "text": " If I'm getting just a plain array of numbers,",
        "tokens": [
          50654,
          759,
          286,
          478,
          1242,
          445,
          257,
          11121,
          10225,
          295,
          3547,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 928.96,
        "id": 334,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 926.72,
        "temperature": 0,
        "text": " I turn them into a tensor,",
        "tokens": [
          50790,
          286,
          1261,
          552,
          666,
          257,
          40863,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 931.2,
        "id": 335,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 928.96,
        "temperature": 0,
        "text": " then I apply the formula for a line,",
        "tokens": [
          50902,
          550,
          286,
          3079,
          264,
          8513,
          337,
          257,
          1622,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 933.2800000000001,
        "id": 336,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 931.2,
        "temperature": 0,
        "text": " and these are the predictions, the Ys.",
        "tokens": [
          51014,
          293,
          613,
          366,
          264,
          21264,
          11,
          264,
          398,
          82,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 935.7,
        "id": 337,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 933.2800000000001,
        "temperature": 0,
        "text": " I guess, I don't like my naming here.",
        "tokens": [
          51118,
          286,
          2041,
          11,
          286,
          500,
          380,
          411,
          452,
          25290,
          510,
          13,
          51239
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 940.36,
        "id": 338,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 939.24,
        "temperature": 0,
        "text": " I'm just gonna call this X,",
        "tokens": [
          51416,
          286,
          478,
          445,
          799,
          818,
          341,
          1783,
          11,
          51472
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 942.46,
        "id": 339,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 940.36,
        "temperature": 0,
        "text": " and maybe I'll call this Xs, I don't know.",
        "tokens": [
          51472,
          293,
          1310,
          286,
          603,
          818,
          341,
          1783,
          82,
          11,
          286,
          500,
          380,
          458,
          13,
          51577
        ]
      },
      {
        "avg_logprob": -0.24654494198885832,
        "compression_ratio": 1.6105769230769231,
        "end": 947.5600000000001,
        "id": 340,
        "no_speech_prob": 0.00000788925990491407,
        "seek": 91820,
        "start": 944.08,
        "temperature": 0,
        "text": " I have to think about, I'll come back to this later.",
        "tokens": [
          51658,
          286,
          362,
          281,
          519,
          466,
          11,
          286,
          603,
          808,
          646,
          281,
          341,
          1780,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 951.2,
        "id": 341,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 949.2,
        "temperature": 0,
        "text": " Okay, so I have that.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          286,
          362,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 959.0400000000001,
        "id": 342,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 954.0400000000001,
        "temperature": 0,
        "text": " Now, let's go back and look at the things that I need.",
        "tokens": [
          50656,
          823,
          11,
          718,
          311,
          352,
          646,
          293,
          574,
          412,
          264,
          721,
          300,
          286,
          643,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 963.5200000000001,
        "id": 343,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 960.0400000000001,
        "temperature": 0,
        "text": " So I have this predict function, I have a data set.",
        "tokens": [
          50956,
          407,
          286,
          362,
          341,
          6069,
          2445,
          11,
          286,
          362,
          257,
          1412,
          992,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 966.08,
        "id": 344,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 963.5200000000001,
        "temperature": 0,
        "text": " Ah, I need a loss function.",
        "tokens": [
          51130,
          2438,
          11,
          286,
          643,
          257,
          4470,
          2445,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 967.6800000000001,
        "id": 345,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 966.08,
        "temperature": 0,
        "text": " Need a loss function, and I need a,",
        "tokens": [
          51258,
          16984,
          257,
          4470,
          2445,
          11,
          293,
          286,
          643,
          257,
          11,
          51338
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 969.72,
        "id": 346,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 967.6800000000001,
        "temperature": 0,
        "text": " oh, before we do the loss function,",
        "tokens": [
          51338,
          1954,
          11,
          949,
          321,
          360,
          264,
          4470,
          2445,
          11,
          51440
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 972.12,
        "id": 347,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 969.72,
        "temperature": 0,
        "text": " let's create the optimizer and the learning rate.",
        "tokens": [
          51440,
          718,
          311,
          1884,
          264,
          5028,
          6545,
          293,
          264,
          2539,
          3314,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 973.76,
        "id": 348,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 972.12,
        "temperature": 0,
        "text": " So this is what's wonderful about",
        "tokens": [
          51560,
          407,
          341,
          307,
          437,
          311,
          3715,
          466,
          51642
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 976.44,
        "id": 349,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 973.76,
        "temperature": 0,
        "text": " working with TensorFlow.js.",
        "tokens": [
          51642,
          1364,
          365,
          37624,
          13,
          25530,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.21463894021922145,
        "compression_ratio": 1.7255813953488373,
        "end": 977.9200000000001,
        "id": 350,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 94820,
        "start": 976.44,
        "temperature": 0,
        "text": " When I say make the optimizer,",
        "tokens": [
          51776,
          1133,
          286,
          584,
          652,
          264,
          5028,
          6545,
          11,
          51850
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 981.04,
        "id": 351,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 978.64,
        "temperature": 0,
        "text": " I just mean make a tf.optimizer.",
        "tokens": [
          50400,
          286,
          445,
          914,
          652,
          257,
          256,
          69,
          13,
          5747,
          332,
          6545,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 983.4399999999999,
        "id": 352,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 981.04,
        "temperature": 0,
        "text": " It exists, it'll do this math for us.",
        "tokens": [
          50520,
          467,
          8198,
          11,
          309,
          603,
          360,
          341,
          5221,
          337,
          505,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 984.7199999999999,
        "id": 353,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 983.4399999999999,
        "temperature": 0,
        "text": " So let's go to the,",
        "tokens": [
          50640,
          407,
          718,
          311,
          352,
          281,
          264,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 987.1999999999999,
        "id": 354,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 984.7199999999999,
        "temperature": 0,
        "text": " this is not something that I covered in my other videos,",
        "tokens": [
          50704,
          341,
          307,
          406,
          746,
          300,
          286,
          5343,
          294,
          452,
          661,
          2145,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 989.4799999999999,
        "id": 355,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 987.1999999999999,
        "temperature": 0,
        "text": " so let's go look for optimizer,",
        "tokens": [
          50828,
          370,
          718,
          311,
          352,
          574,
          337,
          5028,
          6545,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 991.7199999999999,
        "id": 356,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 989.4799999999999,
        "temperature": 0,
        "text": " and I want an optimizer.",
        "tokens": [
          50942,
          293,
          286,
          528,
          364,
          5028,
          6545,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 994.5999999999999,
        "id": 357,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 991.7199999999999,
        "temperature": 0,
        "text": " Now, there's all these different kinds of optimizers.",
        "tokens": [
          51054,
          823,
          11,
          456,
          311,
          439,
          613,
          819,
          3685,
          295,
          5028,
          22525,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 998.92,
        "id": 358,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 994.5999999999999,
        "temperature": 0,
        "text": " SGD, stochastic gradient descent.",
        "tokens": [
          51198,
          34520,
          35,
          11,
          342,
          8997,
          2750,
          16235,
          23475,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2288155162006343,
        "compression_ratio": 1.5740740740740742,
        "end": 1003.92,
        "id": 359,
        "no_speech_prob": 0.000003288748985141865,
        "seek": 97792,
        "start": 998.92,
        "temperature": 0,
        "text": " This means the idea of slowly adjusting M and B",
        "tokens": [
          51414,
          639,
          1355,
          264,
          1558,
          295,
          5692,
          23559,
          376,
          293,
          363,
          51664
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1008.9599999999999,
        "id": 360,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1004.76,
        "temperature": 0,
        "text": " to minimize the loss function,",
        "tokens": [
          50406,
          281,
          17522,
          264,
          4470,
          2445,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1011.5999999999999,
        "id": 361,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1008.9599999999999,
        "temperature": 0,
        "text": " and I've covered this in more detail in the other videos.",
        "tokens": [
          50616,
          293,
          286,
          600,
          5343,
          341,
          294,
          544,
          2607,
          294,
          264,
          661,
          2145,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1015.4799999999999,
        "id": 362,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1011.5999999999999,
        "temperature": 0,
        "text": " So I'm gonna click on that, and I'm gonna look here,",
        "tokens": [
          50748,
          407,
          286,
          478,
          799,
          2052,
          322,
          300,
          11,
          293,
          286,
          478,
          799,
          574,
          510,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1016.88,
        "id": 363,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1015.4799999999999,
        "temperature": 0,
        "text": " and this is basically what I need to do.",
        "tokens": [
          50942,
          293,
          341,
          307,
          1936,
          437,
          286,
          643,
          281,
          360,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1018.16,
        "id": 364,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1016.88,
        "temperature": 0,
        "text": " All right, we got the code right here.",
        "tokens": [
          51012,
          1057,
          558,
          11,
          321,
          658,
          264,
          3089,
          558,
          510,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1020.12,
        "id": 365,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1018.16,
        "temperature": 0,
        "text": " Look, there's even a, look at this.",
        "tokens": [
          51076,
          2053,
          11,
          456,
          311,
          754,
          257,
          11,
          574,
          412,
          341,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1021.8,
        "id": 366,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1020.12,
        "temperature": 0,
        "text": " Oh my goodness, there's like some stuff here",
        "tokens": [
          51174,
          876,
          452,
          8387,
          11,
          456,
          311,
          411,
          512,
          1507,
          510,
          51258
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1023.4,
        "id": 367,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1021.8,
        "temperature": 0,
        "text": " we can really use.",
        "tokens": [
          51258,
          321,
          393,
          534,
          764,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1025.36,
        "id": 368,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1023.4,
        "temperature": 0,
        "text": " So I'm gonna grab this,",
        "tokens": [
          51338,
          407,
          286,
          478,
          799,
          4444,
          341,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1029.8799999999999,
        "id": 369,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1028.04,
        "temperature": 0,
        "text": " and I'm gonna put this up here.",
        "tokens": [
          51570,
          293,
          286,
          478,
          799,
          829,
          341,
          493,
          510,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1031,
        "id": 370,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1029.8799999999999,
        "temperature": 0,
        "text": " So I want a learning rate,",
        "tokens": [
          51662,
          407,
          286,
          528,
          257,
          2539,
          3314,
          11,
          51718
        ]
      },
      {
        "avg_logprob": -0.21143638830390765,
        "compression_ratio": 1.804,
        "end": 1032.8799999999999,
        "id": 371,
        "no_speech_prob": 0.0000822017464088276,
        "seek": 100392,
        "start": 1031,
        "temperature": 0,
        "text": " and I'm gonna have a much bigger learning rate",
        "tokens": [
          51718,
          293,
          286,
          478,
          799,
          362,
          257,
          709,
          3801,
          2539,
          3314,
          51812
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1034.7600000000002,
        "id": 372,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1032.88,
        "temperature": 0,
        "text": " to start with, and I want an optimizer.",
        "tokens": [
          50364,
          281,
          722,
          365,
          11,
          293,
          286,
          528,
          364,
          5028,
          6545,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1036.8000000000002,
        "id": 373,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1034.7600000000002,
        "temperature": 0,
        "text": " So now I have a learning rate and an optimizer,",
        "tokens": [
          50458,
          407,
          586,
          286,
          362,
          257,
          2539,
          3314,
          293,
          364,
          5028,
          6545,
          11,
          50560
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1040.24,
        "id": 374,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1036.8000000000002,
        "temperature": 0,
        "text": " and the optimizer is doing stochastic gradient descent.",
        "tokens": [
          50560,
          293,
          264,
          5028,
          6545,
          307,
          884,
          342,
          8997,
          2750,
          16235,
          23475,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1042.8400000000001,
        "id": 375,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1040.24,
        "temperature": 0,
        "text": " So I have learning rate, optimizer.",
        "tokens": [
          50732,
          407,
          286,
          362,
          2539,
          3314,
          11,
          5028,
          6545,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1044.48,
        "id": 376,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1042.8400000000001,
        "temperature": 0,
        "text": " Now I need that loss function.",
        "tokens": [
          50862,
          823,
          286,
          643,
          300,
          4470,
          2445,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1047.5600000000002,
        "id": 377,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1045.96,
        "temperature": 0,
        "text": " I need the loss function.",
        "tokens": [
          51018,
          286,
          643,
          264,
          4470,
          2445,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1052.5600000000002,
        "id": 378,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1047.5600000000002,
        "temperature": 0,
        "text": " Okay, the loss function is something I'm gonna write, loss,",
        "tokens": [
          51098,
          1033,
          11,
          264,
          4470,
          2445,
          307,
          746,
          286,
          478,
          799,
          2464,
          11,
          4470,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1055.8000000000002,
        "id": 379,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1053.9,
        "temperature": 0,
        "text": " and actually, let's go back to here.",
        "tokens": [
          51415,
          293,
          767,
          11,
          718,
          311,
          352,
          646,
          281,
          510,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1056.8000000000002,
        "id": 380,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1055.8000000000002,
        "temperature": 0,
        "text": " So look at this.",
        "tokens": [
          51510,
          407,
          574,
          412,
          341,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.17006885118720946,
        "compression_ratio": 1.8272727272727274,
        "end": 1060,
        "id": 381,
        "no_speech_prob": 0.00000624093036094564,
        "seek": 103288,
        "start": 1056.8000000000002,
        "temperature": 0,
        "text": " So this is the fancy ES6 way of writing a function,",
        "tokens": [
          51560,
          407,
          341,
          307,
          264,
          10247,
          12564,
          21,
          636,
          295,
          3579,
          257,
          2445,
          11,
          51720
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1063.68,
        "id": 382,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1060,
        "temperature": 0,
        "text": " but I'm gonna write it in a less fancy way,",
        "tokens": [
          50364,
          457,
          286,
          478,
          799,
          2464,
          309,
          294,
          257,
          1570,
          10247,
          636,
          11,
          50548
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1065.96,
        "id": 383,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1064.72,
        "temperature": 0,
        "text": " and I'm gonna do this.",
        "tokens": [
          50600,
          293,
          286,
          478,
          799,
          360,
          341,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1069.56,
        "id": 384,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1067.48,
        "temperature": 0,
        "text": " So what I want is I need the loss function.",
        "tokens": [
          50738,
          407,
          437,
          286,
          528,
          307,
          286,
          643,
          264,
          4470,
          2445,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1072.76,
        "id": 385,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1069.56,
        "temperature": 0,
        "text": " I have some predictions, and I have some labels.",
        "tokens": [
          50842,
          286,
          362,
          512,
          21264,
          11,
          293,
          286,
          362,
          512,
          16949,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1077.66,
        "id": 386,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1072.76,
        "temperature": 0,
        "text": " So these are, the predictions are the y values I'm getting",
        "tokens": [
          51002,
          407,
          613,
          366,
          11,
          264,
          21264,
          366,
          264,
          288,
          4190,
          286,
          478,
          1242,
          51247
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1079.32,
        "id": 387,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1077.66,
        "temperature": 0,
        "text": " from the predict function.",
        "tokens": [
          51247,
          490,
          264,
          6069,
          2445,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1084.16,
        "id": 388,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1079.32,
        "temperature": 0,
        "text": " The labels are the actual y values that are part of this,",
        "tokens": [
          51330,
          440,
          16949,
          366,
          264,
          3539,
          288,
          4190,
          300,
          366,
          644,
          295,
          341,
          11,
          51572
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1086.28,
        "id": 389,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1084.16,
        "temperature": 0,
        "text": " and by the way, I'm gonna have to do memory management.",
        "tokens": [
          51572,
          293,
          538,
          264,
          636,
          11,
          286,
          478,
          799,
          362,
          281,
          360,
          4675,
          4592,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1087.76,
        "id": 390,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1086.28,
        "temperature": 0,
        "text": " Don't worry, if you're screaming at me",
        "tokens": [
          51678,
          1468,
          380,
          3292,
          11,
          498,
          291,
          434,
          12636,
          412,
          385,
          51752
        ]
      },
      {
        "avg_logprob": -0.1892900091456616,
        "compression_ratio": 1.9017094017094016,
        "end": 1089.48,
        "id": 391,
        "no_speech_prob": 9.874638635665178e-7,
        "seek": 106000,
        "start": 1087.76,
        "temperature": 0,
        "text": " that I haven't worked about memory management,",
        "tokens": [
          51752,
          300,
          286,
          2378,
          380,
          2732,
          466,
          4675,
          4592,
          11,
          51838
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1091.72,
        "id": 392,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1090.32,
        "temperature": 0,
        "text": " I'm just gonna do that later.",
        "tokens": [
          50406,
          286,
          478,
          445,
          799,
          360,
          300,
          1780,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1096.2,
        "id": 393,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1091.72,
        "temperature": 0,
        "text": " So what I wanna do is say return",
        "tokens": [
          50476,
          407,
          437,
          286,
          1948,
          360,
          307,
          584,
          2736,
          50700
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1098.3,
        "id": 394,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1096.2,
        "temperature": 0,
        "text": " the predictions minus the labels.",
        "tokens": [
          50700,
          264,
          21264,
          3175,
          264,
          16949,
          13,
          50805
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1099.72,
        "id": 395,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1098.3,
        "temperature": 0,
        "text": " That makes sense, right?",
        "tokens": [
          50805,
          663,
          1669,
          2020,
          11,
          558,
          30,
          50876
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1103.22,
        "id": 396,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1099.72,
        "temperature": 0,
        "text": " Because I said here, when I said mean squared error",
        "tokens": [
          50876,
          1436,
          286,
          848,
          510,
          11,
          562,
          286,
          848,
          914,
          8889,
          6713,
          51051
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1106.48,
        "id": 397,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1103.22,
        "temperature": 0,
        "text": " is the predictions, like the guess, minus the labels,",
        "tokens": [
          51051,
          307,
          264,
          21264,
          11,
          411,
          264,
          2041,
          11,
          3175,
          264,
          16949,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1108.72,
        "id": 398,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1106.48,
        "temperature": 0,
        "text": " which is the actual y squared.",
        "tokens": [
          51214,
          597,
          307,
          264,
          3539,
          288,
          8889,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.2634195467320884,
        "compression_ratio": 1.7396449704142012,
        "end": 1114.16,
        "id": 399,
        "no_speech_prob": 0.0000042228330130456015,
        "seek": 108948,
        "start": 1111.1200000000001,
        "temperature": 0,
        "text": " And so predictions minus the labels",
        "tokens": [
          51446,
          400,
          370,
          21264,
          3175,
          264,
          16949,
          51598
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1117.52,
        "id": 400,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1114.4,
        "temperature": 0,
        "text": " is the predictions squared,",
        "tokens": [
          50376,
          307,
          264,
          21264,
          8889,
          11,
          50532
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1121.4,
        "id": 401,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1118.92,
        "temperature": 0,
        "text": " and then take the mean of them.",
        "tokens": [
          50602,
          293,
          550,
          747,
          264,
          914,
          295,
          552,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1122.64,
        "id": 402,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1121.4,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50726,
          2053,
          412,
          341,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1125.16,
        "id": 403,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1122.64,
        "temperature": 0,
        "text": " All of these mathematical operations",
        "tokens": [
          50788,
          1057,
          295,
          613,
          18894,
          7705,
          50914
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1128.92,
        "id": 404,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1125.16,
        "temperature": 0,
        "text": " are inside of TensorFlow.js, and you can chain them.",
        "tokens": [
          50914,
          366,
          1854,
          295,
          37624,
          13,
          25530,
          11,
          293,
          291,
          393,
          5021,
          552,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1133.92,
        "id": 405,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1128.92,
        "temperature": 0,
        "text": " So predictions is a tensor, labels is a tensor.",
        "tokens": [
          51102,
          407,
          21264,
          307,
          257,
          40863,
          11,
          16949,
          307,
          257,
          40863,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1137.16,
        "id": 406,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1134.6000000000001,
        "temperature": 0,
        "text": " All of these, remember, they're just gonna keep producing",
        "tokens": [
          51386,
          1057,
          295,
          613,
          11,
          1604,
          11,
          436,
          434,
          445,
          799,
          1066,
          10501,
          51514
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1139.8400000000001,
        "id": 407,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1137.16,
        "temperature": 0,
        "text": " new tensors, and I'm gonna have to tidy and clean",
        "tokens": [
          51514,
          777,
          10688,
          830,
          11,
          293,
          286,
          478,
          799,
          362,
          281,
          34646,
          293,
          2541,
          51648
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1141.3600000000001,
        "id": 408,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1139.8400000000001,
        "temperature": 0,
        "text": " all this stuff up for memory management,",
        "tokens": [
          51648,
          439,
          341,
          1507,
          493,
          337,
          4675,
          4592,
          11,
          51724
        ]
      },
      {
        "avg_logprob": -0.2821443231256158,
        "compression_ratio": 1.6736401673640167,
        "end": 1142.76,
        "id": 409,
        "no_speech_prob": 0.000008801101103017572,
        "seek": 111416,
        "start": 1141.3600000000001,
        "temperature": 0,
        "text": " but again, I'll worry about that later.",
        "tokens": [
          51724,
          457,
          797,
          11,
          286,
          603,
          3292,
          466,
          300,
          1780,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1144.6,
        "id": 410,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1142.76,
        "temperature": 0,
        "text": " So now I have the loss function.",
        "tokens": [
          50364,
          407,
          586,
          286,
          362,
          264,
          4470,
          2445,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1147,
        "id": 411,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1144.6,
        "temperature": 0,
        "text": " All right, well, what is it that I wanna do?",
        "tokens": [
          50456,
          1057,
          558,
          11,
          731,
          11,
          437,
          307,
          309,
          300,
          286,
          1948,
          360,
          30,
          50576
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1150.52,
        "id": 412,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1147,
        "temperature": 0,
        "text": " Every time, so let's say, I think I'm actually like,",
        "tokens": [
          50576,
          2048,
          565,
          11,
          370,
          718,
          311,
          584,
          11,
          286,
          519,
          286,
          478,
          767,
          411,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1152.2,
        "id": 413,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1150.52,
        "temperature": 0,
        "text": " I have everything.",
        "tokens": [
          50752,
          286,
          362,
          1203,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1155.52,
        "id": 414,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1152.2,
        "temperature": 0,
        "text": " I have the loss function, I have the data,",
        "tokens": [
          50836,
          286,
          362,
          264,
          4470,
          2445,
          11,
          286,
          362,
          264,
          1412,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1157.5,
        "id": 415,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1155.52,
        "temperature": 0,
        "text": " I have the optimizer, I have a predict function,",
        "tokens": [
          51002,
          286,
          362,
          264,
          5028,
          6545,
          11,
          286,
          362,
          257,
          6069,
          2445,
          11,
          51101
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1159,
        "id": 416,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1157.5,
        "temperature": 0,
        "text": " I have a learning rate, I can minimize,",
        "tokens": [
          51101,
          286,
          362,
          257,
          2539,
          3314,
          11,
          286,
          393,
          17522,
          11,
          51176
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1160.94,
        "id": 417,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1159,
        "temperature": 0,
        "text": " well, oh, this I haven't done.",
        "tokens": [
          51176,
          731,
          11,
          1954,
          11,
          341,
          286,
          2378,
          380,
          1096,
          13,
          51273
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1163.68,
        "id": 418,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1160.94,
        "temperature": 0,
        "text": " So the training, the actual training,",
        "tokens": [
          51273,
          407,
          264,
          3097,
          11,
          264,
          3539,
          3097,
          11,
          51410
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1165.32,
        "id": 419,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1163.68,
        "temperature": 0,
        "text": " what does it mean to train it?",
        "tokens": [
          51410,
          437,
          775,
          309,
          914,
          281,
          3847,
          309,
          30,
          51492
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1168.2,
        "id": 420,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1165.32,
        "temperature": 0,
        "text": " To train it means minimize the loss function",
        "tokens": [
          51492,
          1407,
          3847,
          309,
          1355,
          17522,
          264,
          4470,
          2445,
          51636
        ]
      },
      {
        "avg_logprob": -0.18143631660774961,
        "compression_ratio": 1.9357429718875503,
        "end": 1172.24,
        "id": 421,
        "no_speech_prob": 0.000004565965809888439,
        "seek": 114276,
        "start": 1168.2,
        "temperature": 0,
        "text": " with the optimizer and adjusting M and B based on that.",
        "tokens": [
          51636,
          365,
          264,
          5028,
          6545,
          293,
          23559,
          376,
          293,
          363,
          2361,
          322,
          300,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1175,
        "id": 422,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1172.24,
        "temperature": 0,
        "text": " All right, so let's see if we can make that.",
        "tokens": [
          50364,
          1057,
          558,
          11,
          370,
          718,
          311,
          536,
          498,
          321,
          393,
          652,
          300,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1177.4,
        "id": 423,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1175,
        "temperature": 0,
        "text": " I have a feeling that was in that page that I went to,",
        "tokens": [
          50502,
          286,
          362,
          257,
          2633,
          300,
          390,
          294,
          300,
          3028,
          300,
          286,
          1437,
          281,
          11,
          50622
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1179.24,
        "id": 424,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1177.4,
        "temperature": 0,
        "text": " so maybe I could just copy it from there.",
        "tokens": [
          50622,
          370,
          1310,
          286,
          727,
          445,
          5055,
          309,
          490,
          456,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1181.72,
        "id": 425,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1179.24,
        "temperature": 0,
        "text": " I'm kind of, this is like, it totally is.",
        "tokens": [
          50714,
          286,
          478,
          733,
          295,
          11,
          341,
          307,
          411,
          11,
          309,
          3879,
          307,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1184.4,
        "id": 426,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1181.72,
        "temperature": 0,
        "text": " That's fine, I'm gonna happily cheat here.",
        "tokens": [
          50838,
          663,
          311,
          2489,
          11,
          286,
          478,
          799,
          19909,
          17470,
          510,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1186.16,
        "id": 427,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1184.4,
        "temperature": 0,
        "text": " It was in that example, thank you very much.",
        "tokens": [
          50972,
          467,
          390,
          294,
          300,
          1365,
          11,
          1309,
          291,
          588,
          709,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1188.1200000000001,
        "id": 428,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1186.16,
        "temperature": 0,
        "text": " Thank you, TensorFlow.js documentation.",
        "tokens": [
          51060,
          1044,
          291,
          11,
          37624,
          13,
          25530,
          14333,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1192.28,
        "id": 429,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1190.68,
        "temperature": 0,
        "text": " And so I'm gonna just put this in draw.",
        "tokens": [
          51286,
          400,
          370,
          286,
          478,
          799,
          445,
          829,
          341,
          294,
          2642,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1194.5,
        "id": 430,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1192.28,
        "temperature": 0,
        "text": " Like, every time through draw, I'm gonna minimize.",
        "tokens": [
          51366,
          1743,
          11,
          633,
          565,
          807,
          2642,
          11,
          286,
          478,
          799,
          17522,
          13,
          51477
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1195.88,
        "id": 431,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1194.5,
        "temperature": 0,
        "text": " So let's look at this, oh, look at this.",
        "tokens": [
          51477,
          407,
          718,
          311,
          574,
          412,
          341,
          11,
          1954,
          11,
          574,
          412,
          341,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1197.36,
        "id": 432,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1195.88,
        "temperature": 0,
        "text": " Okay, so this is a little different.",
        "tokens": [
          51546,
          1033,
          11,
          370,
          341,
          307,
          257,
          707,
          819,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.24103608188858952,
        "compression_ratio": 1.7151898734177216,
        "end": 1202.08,
        "id": 433,
        "no_speech_prob": 0.00002247403608635068,
        "seek": 117224,
        "start": 1197.36,
        "temperature": 0,
        "text": " So first of all, this is using nice, fancy ES6 arrow notation",
        "tokens": [
          51620,
          407,
          700,
          295,
          439,
          11,
          341,
          307,
          1228,
          1481,
          11,
          10247,
          12564,
          21,
          11610,
          24657,
          51856
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1203.76,
        "id": 434,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1202.9199999999998,
        "temperature": 0,
        "text": " which I'm somewhat happy about.",
        "tokens": [
          50406,
          597,
          286,
          478,
          8344,
          2055,
          466,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1207.52,
        "id": 435,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1203.76,
        "temperature": 0,
        "text": " But let me just write a function here called train.",
        "tokens": [
          50448,
          583,
          718,
          385,
          445,
          2464,
          257,
          2445,
          510,
          1219,
          3847,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1212.48,
        "id": 436,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1207.52,
        "temperature": 0,
        "text": " And the idea of the train function is to execute the loss",
        "tokens": [
          50636,
          400,
          264,
          1558,
          295,
          264,
          3847,
          2445,
          307,
          281,
          14483,
          264,
          4470,
          50884
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1217.48,
        "id": 437,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1212.48,
        "temperature": 0,
        "text": " with the predictions and the actual y's.",
        "tokens": [
          50884,
          365,
          264,
          21264,
          293,
          264,
          3539,
          288,
          311,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1222.52,
        "id": 438,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1220.12,
        "temperature": 0,
        "text": " Okay, so here, what I'm really doing",
        "tokens": [
          51266,
          1033,
          11,
          370,
          510,
          11,
          437,
          286,
          478,
          534,
          884,
          51386
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1224.4399999999998,
        "id": 439,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1222.52,
        "temperature": 0,
        "text": " is minimizing the train.",
        "tokens": [
          51386,
          307,
          46608,
          264,
          3847,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1227.1599999999999,
        "id": 440,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1226.08,
        "temperature": 0,
        "text": " That's weird, this isn't really,",
        "tokens": [
          51564,
          663,
          311,
          3657,
          11,
          341,
          1943,
          380,
          534,
          11,
          51618
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1228.8,
        "id": 441,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1227.1599999999999,
        "temperature": 0,
        "text": " no, training would be doing this.",
        "tokens": [
          51618,
          572,
          11,
          3097,
          576,
          312,
          884,
          341,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.24326780319213867,
        "compression_ratio": 1.6036866359447004,
        "end": 1230.6399999999999,
        "id": 442,
        "no_speech_prob": 0.000007766951057419647,
        "seek": 120208,
        "start": 1228.8,
        "temperature": 0,
        "text": " So this is a terrible name for this.",
        "tokens": [
          51700,
          407,
          341,
          307,
          257,
          6237,
          1315,
          337,
          341,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1233.5600000000002,
        "id": 443,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1230.72,
        "temperature": 0,
        "text": " And actually, this is silly for me to even name this.",
        "tokens": [
          50368,
          400,
          767,
          11,
          341,
          307,
          11774,
          337,
          385,
          281,
          754,
          1315,
          341,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1235.88,
        "id": 444,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1233.5600000000002,
        "temperature": 0,
        "text": " It really makes sense for me to just make this",
        "tokens": [
          50510,
          467,
          534,
          1669,
          2020,
          337,
          385,
          281,
          445,
          652,
          341,
          50626
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1240.88,
        "id": 445,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1235.88,
        "temperature": 0,
        "text": " an anonymous function and that what I'm minimizing is this.",
        "tokens": [
          50626,
          364,
          24932,
          2445,
          293,
          300,
          437,
          286,
          478,
          46608,
          307,
          341,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1244.92,
        "id": 446,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1241.8400000000001,
        "temperature": 0,
        "text": " This is what I wanna minimize, the loss function.",
        "tokens": [
          50924,
          639,
          307,
          437,
          286,
          1948,
          17522,
          11,
          264,
          4470,
          2445,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1248.7,
        "id": 447,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1244.92,
        "temperature": 0,
        "text": " But if I wanna be nice and ES6-like with my arrow notation,",
        "tokens": [
          51078,
          583,
          498,
          286,
          1948,
          312,
          1481,
          293,
          12564,
          21,
          12,
          4092,
          365,
          452,
          11610,
          24657,
          11,
          51267
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1251.92,
        "id": 448,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1248.7,
        "temperature": 0,
        "text": " which I think by the fact that I'm using TensorFlow.js",
        "tokens": [
          51267,
          597,
          286,
          519,
          538,
          264,
          1186,
          300,
          286,
          478,
          1228,
          37624,
          13,
          25530,
          51428
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1253.72,
        "id": 449,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1251.92,
        "temperature": 0,
        "text": " and you can watch my arrow notation function",
        "tokens": [
          51428,
          293,
          291,
          393,
          1159,
          452,
          11610,
          24657,
          2445,
          51518
        ]
      },
      {
        "avg_logprob": -0.22061465079324288,
        "compression_ratio": 1.7280334728033473,
        "end": 1256.5,
        "id": 450,
        "no_speech_prob": 0.000012219073141750414,
        "seek": 123064,
        "start": 1253.72,
        "temperature": 0,
        "text": " if this is, I can kind of get rid of a lot",
        "tokens": [
          51518,
          498,
          341,
          307,
          11,
          286,
          393,
          733,
          295,
          483,
          3973,
          295,
          257,
          688,
          51657
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1261.26,
        "id": 451,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1256.54,
        "temperature": 0,
        "text": " of the extra stuff here and this should be good.",
        "tokens": [
          50366,
          295,
          264,
          2857,
          1507,
          510,
          293,
          341,
          820,
          312,
          665,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1263.58,
        "id": 452,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1261.26,
        "temperature": 0,
        "text": " So I just wanna minimize the loss function.",
        "tokens": [
          50602,
          407,
          286,
          445,
          1948,
          17522,
          264,
          4470,
          2445,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1264.66,
        "id": 453,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1263.58,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          50718,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1268.82,
        "id": 454,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1266.14,
        "temperature": 0,
        "text": " These have to be tensors, right?",
        "tokens": [
          50846,
          1981,
          362,
          281,
          312,
          10688,
          830,
          11,
          558,
          30,
          50980
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1273.16,
        "id": 455,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1268.82,
        "temperature": 0,
        "text": " The loss function requires predictions and labels.",
        "tokens": [
          50980,
          440,
          4470,
          2445,
          7029,
          21264,
          293,
          16949,
          13,
          51197
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1274.18,
        "id": 456,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1273.16,
        "temperature": 0,
        "text": " They have to be tensors.",
        "tokens": [
          51197,
          814,
          362,
          281,
          312,
          10688,
          830,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1278.02,
        "id": 457,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1274.18,
        "temperature": 0,
        "text": " And if you remember, my x's and y's aren't tensors.",
        "tokens": [
          51248,
          400,
          498,
          291,
          1604,
          11,
          452,
          2031,
          311,
          293,
          288,
          311,
          3212,
          380,
          10688,
          830,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1280.3,
        "id": 458,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1278.02,
        "temperature": 0,
        "text": " When I call the predict function with the x's,",
        "tokens": [
          51440,
          1133,
          286,
          818,
          264,
          6069,
          2445,
          365,
          264,
          2031,
          311,
          11,
          51554
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1282.7,
        "id": 459,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1280.3,
        "temperature": 0,
        "text": " it gives me back a tensor.",
        "tokens": [
          51554,
          309,
          2709,
          385,
          646,
          257,
          40863,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.20779941121085746,
        "compression_ratio": 1.6833333333333333,
        "end": 1286.38,
        "id": 460,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 125650,
        "start": 1283.58,
        "temperature": 0,
        "text": " So that, I can't believe I haven't run this code yet.",
        "tokens": [
          51718,
          407,
          300,
          11,
          286,
          393,
          380,
          1697,
          286,
          2378,
          380,
          1190,
          341,
          3089,
          1939,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1288.1000000000001,
        "id": 461,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1287.2600000000002,
        "temperature": 0,
        "text": " This is a terrible thing.",
        "tokens": [
          50408,
          639,
          307,
          257,
          6237,
          551,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1290.6200000000001,
        "id": 462,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1288.1000000000001,
        "temperature": 0,
        "text": " Usually I try to run my code incrementally all the time.",
        "tokens": [
          50450,
          11419,
          286,
          853,
          281,
          1190,
          452,
          3089,
          26200,
          379,
          439,
          264,
          565,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1292.22,
        "id": 463,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1290.6200000000001,
        "temperature": 0,
        "text": " I guess I've forgotten to do that.",
        "tokens": [
          50576,
          286,
          2041,
          286,
          600,
          11832,
          281,
          360,
          300,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1293.8200000000002,
        "id": 464,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1292.22,
        "temperature": 0,
        "text": " So probably people in the chat are telling me",
        "tokens": [
          50656,
          407,
          1391,
          561,
          294,
          264,
          5081,
          366,
          3585,
          385,
          50736
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1295.0200000000002,
        "id": 465,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1293.8200000000002,
        "temperature": 0,
        "text": " about mistakes I'm making.",
        "tokens": [
          50736,
          466,
          8038,
          286,
          478,
          1455,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1299.38,
        "id": 466,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1295.0200000000002,
        "temperature": 0,
        "text": " So this is a tensor, but this is still a plain array.",
        "tokens": [
          50796,
          407,
          341,
          307,
          257,
          40863,
          11,
          457,
          341,
          307,
          920,
          257,
          11121,
          10225,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1301.66,
        "id": 467,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1299.38,
        "temperature": 0,
        "text": " So what I need to do is say constant",
        "tokens": [
          51014,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          584,
          5754,
          51128
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1303.0600000000002,
        "id": 468,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1301.66,
        "temperature": 0,
        "text": " and I gotta rethink the naming.",
        "tokens": [
          51128,
          293,
          286,
          3428,
          34595,
          264,
          25290,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1305.3600000000001,
        "id": 469,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1303.0600000000002,
        "temperature": 0,
        "text": " Maybe somebody in the chat has an idea for me.",
        "tokens": [
          51198,
          2704,
          2618,
          294,
          264,
          5081,
          575,
          364,
          1558,
          337,
          385,
          13,
          51313
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1309.6200000000001,
        "id": 470,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1306.96,
        "temperature": 0,
        "text": " I think what I actually should do, I have an idea.",
        "tokens": [
          51393,
          286,
          519,
          437,
          286,
          767,
          820,
          360,
          11,
          286,
          362,
          364,
          1558,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1312.22,
        "id": 471,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1309.6200000000001,
        "temperature": 0,
        "text": " Permit me a moment of refactoring.",
        "tokens": [
          51526,
          41006,
          270,
          385,
          257,
          1623,
          295,
          1895,
          578,
          3662,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.20640578844868546,
        "compression_ratio": 1.6884057971014492,
        "end": 1315.0600000000002,
        "id": 472,
        "no_speech_prob": 0.000024682893126737326,
        "seek": 128638,
        "start": 1312.22,
        "temperature": 0,
        "text": " X valves, y valves.",
        "tokens": [
          51656,
          1783,
          371,
          304,
          977,
          11,
          288,
          34950,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1316.76,
        "id": 473,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1315.1,
        "temperature": 0,
        "text": " So I think when it's not a tensor,",
        "tokens": [
          50366,
          407,
          286,
          519,
          562,
          309,
          311,
          406,
          257,
          40863,
          11,
          50449
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1319.1399999999999,
        "id": 474,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1316.76,
        "temperature": 0,
        "text": " I'm just gonna call it like x underscore valves",
        "tokens": [
          50449,
          286,
          478,
          445,
          799,
          818,
          309,
          411,
          2031,
          37556,
          34950,
          50568
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1324.1799999999998,
        "id": 475,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1320.46,
        "temperature": 0,
        "text": " because that's gonna help me remember.",
        "tokens": [
          50634,
          570,
          300,
          311,
          799,
          854,
          385,
          1604,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1327.7,
        "id": 476,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1324.1799999999998,
        "temperature": 0,
        "text": " So x valves, y valves.",
        "tokens": [
          50820,
          407,
          2031,
          34950,
          11,
          288,
          34950,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1331.46,
        "id": 477,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1327.7,
        "temperature": 0,
        "text": " And then whenever I say, and this should be x.",
        "tokens": [
          50996,
          400,
          550,
          5699,
          286,
          584,
          11,
          293,
          341,
          820,
          312,
          2031,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1334.58,
        "id": 478,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1331.46,
        "temperature": 0,
        "text": " Whenever I say xs or ys, that's really a tensor.",
        "tokens": [
          51184,
          14159,
          286,
          584,
          2031,
          82,
          420,
          288,
          82,
          11,
          300,
          311,
          534,
          257,
          40863,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1336.1,
        "id": 479,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1334.58,
        "temperature": 0,
        "text": " I guess I could have done txs.",
        "tokens": [
          51340,
          286,
          2041,
          286,
          727,
          362,
          1096,
          256,
          87,
          82,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.1806561183003546,
        "compression_ratio": 1.587378640776699,
        "end": 1340.1,
        "id": 480,
        "no_speech_prob": 8.714333716852707e-7,
        "seek": 131506,
        "start": 1336.1,
        "temperature": 0,
        "text": " So here, what I'm doing is predicting from the x valves",
        "tokens": [
          51416,
          407,
          510,
          11,
          437,
          286,
          478,
          884,
          307,
          32884,
          490,
          264,
          2031,
          34950,
          51616
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1345.1,
        "id": 481,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1340.1,
        "temperature": 0,
        "text": " and then ys is tf.tensor1dy valves.",
        "tokens": [
          50364,
          293,
          550,
          288,
          82,
          307,
          256,
          69,
          13,
          83,
          23153,
          16,
          3173,
          34950,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1347.9399999999998,
        "id": 482,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1345.8999999999999,
        "temperature": 0,
        "text": " So I need to create that tensor",
        "tokens": [
          50654,
          407,
          286,
          643,
          281,
          1884,
          300,
          40863,
          50756
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1350.06,
        "id": 483,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1347.9399999999998,
        "temperature": 0,
        "text": " and now I can minimize the loss",
        "tokens": [
          50756,
          293,
          586,
          286,
          393,
          17522,
          264,
          4470,
          50862
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1353.58,
        "id": 484,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1350.06,
        "temperature": 0,
        "text": " with predicting from the x valves and the y valves.",
        "tokens": [
          50862,
          365,
          32884,
          490,
          264,
          2031,
          34950,
          293,
          264,
          288,
          34950,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1356.54,
        "id": 485,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1353.58,
        "temperature": 0,
        "text": " Okay, so this is good.",
        "tokens": [
          51038,
          1033,
          11,
          370,
          341,
          307,
          665,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1357.84,
        "id": 486,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1356.54,
        "temperature": 0,
        "text": " Let's just run this.",
        "tokens": [
          51186,
          961,
          311,
          445,
          1190,
          341,
          13,
          51251
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1362.1,
        "id": 487,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1359.1,
        "temperature": 0,
        "text": " All right, I'm from the future, different day,",
        "tokens": [
          51314,
          1057,
          558,
          11,
          286,
          478,
          490,
          264,
          2027,
          11,
          819,
          786,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1363.86,
        "id": 488,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1362.1,
        "temperature": 0,
        "text": " different clothes, I'm breaking into this video",
        "tokens": [
          51464,
          819,
          5534,
          11,
          286,
          478,
          7697,
          666,
          341,
          960,
          51552
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1365.3,
        "id": 489,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1363.86,
        "temperature": 0,
        "text": " to mention something really important",
        "tokens": [
          51552,
          281,
          2152,
          746,
          534,
          1021,
          51624
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1367.3799999999999,
        "id": 490,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1365.3,
        "temperature": 0,
        "text": " that I didn't actually mention",
        "tokens": [
          51624,
          300,
          286,
          994,
          380,
          767,
          2152,
          51728
        ]
      },
      {
        "avg_logprob": -0.2200645742745235,
        "compression_ratio": 1.6451612903225807,
        "end": 1369.6999999999998,
        "id": 491,
        "no_speech_prob": 0.000002642585513967788,
        "seek": 134010,
        "start": 1367.3799999999999,
        "temperature": 0,
        "text": " when I recorded the coding challenge originally.",
        "tokens": [
          51728,
          562,
          286,
          8287,
          264,
          17720,
          3430,
          7993,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1371.5800000000002,
        "id": 492,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1370.26,
        "temperature": 0,
        "text": " What is that optimize function doing?",
        "tokens": [
          50392,
          708,
          307,
          300,
          19719,
          2445,
          884,
          30,
          50458
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1372.74,
        "id": 493,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1371.5800000000002,
        "temperature": 0,
        "text": " How does it actually work?",
        "tokens": [
          50458,
          1012,
          775,
          309,
          767,
          589,
          30,
          50516
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1375.5,
        "id": 494,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1372.74,
        "temperature": 0,
        "text": " And we need to look at the TensorFlow.js documentation",
        "tokens": [
          50516,
          400,
          321,
          643,
          281,
          574,
          412,
          264,
          37624,
          13,
          25530,
          14333,
          50654
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1378.18,
        "id": 495,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1375.5,
        "temperature": 0,
        "text": " to see, so let me, I'm bringing my laptop back up here",
        "tokens": [
          50654,
          281,
          536,
          11,
          370,
          718,
          385,
          11,
          286,
          478,
          5062,
          452,
          10732,
          646,
          493,
          510,
          50788
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1379.3,
        "id": 496,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1378.18,
        "temperature": 0,
        "text": " and I'm gonna switch over here.",
        "tokens": [
          50788,
          293,
          286,
          478,
          799,
          3679,
          670,
          510,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1382.02,
        "id": 497,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1379.3,
        "temperature": 0,
        "text": " So I've got the code from the past, me in the future.",
        "tokens": [
          50844,
          407,
          286,
          600,
          658,
          264,
          3089,
          490,
          264,
          1791,
          11,
          385,
          294,
          264,
          2027,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1383.98,
        "id": 498,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1382.02,
        "temperature": 0,
        "text": " This is the part that I'm talking about.",
        "tokens": [
          50980,
          639,
          307,
          264,
          644,
          300,
          286,
          478,
          1417,
          466,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1388.26,
        "id": 499,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1383.98,
        "temperature": 0,
        "text": " Well, how is this going to adjust m and b?",
        "tokens": [
          51078,
          1042,
          11,
          577,
          307,
          341,
          516,
          281,
          4369,
          275,
          293,
          272,
          30,
          51292
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1392.26,
        "id": 500,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1388.26,
        "temperature": 0,
        "text": " Those are the, these are the parameters,",
        "tokens": [
          51292,
          3950,
          366,
          264,
          11,
          613,
          366,
          264,
          9834,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1395.18,
        "id": 501,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1392.26,
        "temperature": 0,
        "text": " the weights, the variables that we need to adjust",
        "tokens": [
          51492,
          264,
          17443,
          11,
          264,
          9102,
          300,
          321,
          643,
          281,
          4369,
          51638
        ]
      },
      {
        "avg_logprob": -0.21882133197067374,
        "compression_ratio": 1.6560283687943262,
        "end": 1397.46,
        "id": 502,
        "no_speech_prob": 0.00028685349388979375,
        "seek": 136970,
        "start": 1395.18,
        "temperature": 0,
        "text": " to minimize that loss function.",
        "tokens": [
          51638,
          281,
          17522,
          300,
          4470,
          2445,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1400.26,
        "id": 503,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1397.5,
        "temperature": 0,
        "text": " But I'm not anywhere in here saying,",
        "tokens": [
          50366,
          583,
          286,
          478,
          406,
          4992,
          294,
          510,
          1566,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1401.74,
        "id": 504,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1400.26,
        "temperature": 0,
        "text": " those are the variables to work with.",
        "tokens": [
          50504,
          729,
          366,
          264,
          9102,
          281,
          589,
          365,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1405.3,
        "id": 505,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1401.74,
        "temperature": 0,
        "text": " Well, this is part of what TensorFlow.js does natively.",
        "tokens": [
          50578,
          1042,
          11,
          341,
          307,
          644,
          295,
          437,
          37624,
          13,
          25530,
          775,
          8470,
          356,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1409.96,
        "id": 506,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1405.3,
        "temperature": 0,
        "text": " The fact that I made these up here, tf variables,",
        "tokens": [
          50756,
          440,
          1186,
          300,
          286,
          1027,
          613,
          493,
          510,
          11,
          256,
          69,
          9102,
          11,
          50989
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1413.3400000000001,
        "id": 507,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1409.96,
        "temperature": 0,
        "text": " means those are variables that can be adjusted.",
        "tokens": [
          50989,
          1355,
          729,
          366,
          9102,
          300,
          393,
          312,
          19871,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1417,
        "id": 508,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1413.3400000000001,
        "temperature": 0,
        "text": " And if we look here at the TensorFlow documentation,",
        "tokens": [
          51158,
          400,
          498,
          321,
          574,
          510,
          412,
          264,
          37624,
          14333,
          11,
          51341
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1418.8600000000001,
        "id": 509,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1417,
        "temperature": 0,
        "text": " you'll see what does minimize do?",
        "tokens": [
          51341,
          291,
          603,
          536,
          437,
          775,
          17522,
          360,
          30,
          51434
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1422.82,
        "id": 510,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1418.8600000000001,
        "temperature": 0,
        "text": " It executes this function f, that is,",
        "tokens": [
          51434,
          467,
          4454,
          1819,
          341,
          2445,
          283,
          11,
          300,
          307,
          11,
          51632
        ]
      },
      {
        "avg_logprob": -0.23500591624866832,
        "compression_ratio": 1.638655462184874,
        "end": 1427.06,
        "id": 511,
        "no_speech_prob": 0.000021782647309009917,
        "seek": 139746,
        "start": 1423.78,
        "temperature": 0,
        "text": " sorry, that is this function, right?",
        "tokens": [
          51680,
          2597,
          11,
          300,
          307,
          341,
          2445,
          11,
          558,
          30,
          51844
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1428.46,
        "id": 512,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1427.62,
        "temperature": 0,
        "text": " This whole function here.",
        "tokens": [
          50392,
          639,
          1379,
          2445,
          510,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1431.22,
        "id": 513,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1428.46,
        "temperature": 0,
        "text": " And by the way, the return here is implicit",
        "tokens": [
          50434,
          400,
          538,
          264,
          636,
          11,
          264,
          2736,
          510,
          307,
          26947,
          50572
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1432.78,
        "id": 514,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1431.22,
        "temperature": 0,
        "text": " because I'm using the arrow function.",
        "tokens": [
          50572,
          570,
          286,
          478,
          1228,
          264,
          11610,
          2445,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1435.6599999999999,
        "id": 515,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1432.78,
        "temperature": 0,
        "text": " So it minimizes the output of that function,",
        "tokens": [
          50650,
          407,
          309,
          4464,
          5660,
          264,
          5598,
          295,
          300,
          2445,
          11,
          50794
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1438.62,
        "id": 516,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1435.6599999999999,
        "temperature": 0,
        "text": " tries to get it lower by computing the gradients",
        "tokens": [
          50794,
          9898,
          281,
          483,
          309,
          3126,
          538,
          15866,
          264,
          2771,
          2448,
          50942
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1441.8999999999999,
        "id": 517,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1438.62,
        "temperature": 0,
        "text": " with respect to a list of all trainable variables",
        "tokens": [
          50942,
          365,
          3104,
          281,
          257,
          1329,
          295,
          439,
          3847,
          712,
          9102,
          51106
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1443.58,
        "id": 518,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1441.8999999999999,
        "temperature": 0,
        "text": " provided by var list.",
        "tokens": [
          51106,
          5649,
          538,
          1374,
          1329,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1444.4199999999998,
        "id": 519,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1443.58,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          51190,
          17795,
          437,
          30,
          51232
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1446.8799999999999,
        "id": 520,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1444.4199999999998,
        "temperature": 0,
        "text": " I didn't provide a list of trainable variables.",
        "tokens": [
          51232,
          286,
          994,
          380,
          2893,
          257,
          1329,
          295,
          3847,
          712,
          9102,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1448.62,
        "id": 521,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1446.8799999999999,
        "temperature": 0,
        "text": " If no list is provided,",
        "tokens": [
          51355,
          759,
          572,
          1329,
          307,
          5649,
          11,
          51442
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1450.82,
        "id": 522,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1448.62,
        "temperature": 0,
        "text": " it defaults to all trainable variables.",
        "tokens": [
          51442,
          309,
          7576,
          82,
          281,
          439,
          3847,
          712,
          9102,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1451.86,
        "id": 523,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1450.82,
        "temperature": 0,
        "text": " And that's what's going on.",
        "tokens": [
          51552,
          400,
          300,
          311,
          437,
          311,
          516,
          322,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.18044970806379965,
        "compression_ratio": 1.8464566929133859,
        "end": 1453.62,
        "id": 524,
        "no_speech_prob": 0.00008888079173630103,
        "seek": 142706,
        "start": 1451.86,
        "temperature": 0,
        "text": " That's what I did in this coding challenge.",
        "tokens": [
          51604,
          663,
          311,
          437,
          286,
          630,
          294,
          341,
          17720,
          3430,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1457.8999999999999,
        "id": 525,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1453.62,
        "temperature": 0,
        "text": " These are all the trainable variables in my system.",
        "tokens": [
          50364,
          1981,
          366,
          439,
          264,
          3847,
          712,
          9102,
          294,
          452,
          1185,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1460.58,
        "id": 526,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1457.8999999999999,
        "temperature": 0,
        "text": " If I wanted to only use m or only use b,",
        "tokens": [
          50578,
          759,
          286,
          1415,
          281,
          787,
          764,
          275,
          420,
          787,
          764,
          272,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1462.06,
        "id": 527,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1460.58,
        "temperature": 0,
        "text": " I could put those in a list.",
        "tokens": [
          50712,
          286,
          727,
          829,
          729,
          294,
          257,
          1329,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1463.78,
        "id": 528,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1462.06,
        "temperature": 0,
        "text": " So that's all I have to say about that.",
        "tokens": [
          50786,
          407,
          300,
          311,
          439,
          286,
          362,
          281,
          584,
          466,
          300,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1467.82,
        "id": 529,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1463.78,
        "temperature": 0,
        "text": " I'm going to fade now back into the other video,",
        "tokens": [
          50872,
          286,
          478,
          516,
          281,
          21626,
          586,
          646,
          666,
          264,
          661,
          960,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1469.4599999999998,
        "id": 530,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1467.82,
        "temperature": 0,
        "text": " lower this and back up,",
        "tokens": [
          51074,
          3126,
          341,
          293,
          646,
          493,
          11,
          51156
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1471.62,
        "id": 531,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1469.4599999999998,
        "temperature": 0,
        "text": " and it's going to keep going where I debug",
        "tokens": [
          51156,
          293,
          309,
          311,
          516,
          281,
          1066,
          516,
          689,
          286,
          24083,
          51264
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1472.62,
        "id": 532,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1471.62,
        "temperature": 0,
        "text": " and have all sorts of other problems.",
        "tokens": [
          51264,
          293,
          362,
          439,
          7527,
          295,
          661,
          2740,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1473.4599999999998,
        "id": 533,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1472.62,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51314,
          15528,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1480.1799999999998,
        "id": 534,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1476.5,
        "temperature": 0,
        "text": " Okay, predict.sub.squared is not a function at loss",
        "tokens": [
          51508,
          1033,
          11,
          6069,
          13,
          30131,
          13,
          33292,
          1642,
          307,
          406,
          257,
          2445,
          412,
          4470,
          51692
        ]
      },
      {
        "avg_logprob": -0.20585432285215796,
        "compression_ratio": 1.5912698412698412,
        "end": 1481.7399999999998,
        "id": 535,
        "no_speech_prob": 0.0000023320740183407906,
        "seek": 145362,
        "start": 1480.1799999999998,
        "temperature": 0,
        "text": " at optimize or minimize.",
        "tokens": [
          51692,
          412,
          19719,
          420,
          17522,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1483.76,
        "id": 536,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1481.74,
        "temperature": 0,
        "text": " So what do I have wrong here?",
        "tokens": [
          50364,
          407,
          437,
          360,
          286,
          362,
          2085,
          510,
          30,
          50465
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1486.46,
        "id": 537,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1484.78,
        "temperature": 0,
        "text": " In my loss function,",
        "tokens": [
          50516,
          682,
          452,
          4470,
          2445,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1492.42,
        "id": 538,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1487.42,
        "temperature": 0,
        "text": " sub labels.squared.mean.",
        "tokens": [
          50648,
          1422,
          16949,
          13,
          33292,
          1642,
          13,
          1398,
          282,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1496.1200000000001,
        "id": 539,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1494.58,
        "temperature": 0,
        "text": " Oh, you know what it is?",
        "tokens": [
          51006,
          876,
          11,
          291,
          458,
          437,
          309,
          307,
          30,
          51083
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1500.42,
        "id": 540,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1498.34,
        "temperature": 0,
        "text": " There's nothing in the arrays at the beginning.",
        "tokens": [
          51194,
          821,
          311,
          1825,
          294,
          264,
          41011,
          412,
          264,
          2863,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1501.84,
        "id": 541,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1500.42,
        "temperature": 0,
        "text": " They have zero things in them.",
        "tokens": [
          51298,
          814,
          362,
          4018,
          721,
          294,
          552,
          13,
          51369
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1504,
        "id": 542,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1501.84,
        "temperature": 0,
        "text": " So a couple of things, one is I could put something in it,",
        "tokens": [
          51369,
          407,
          257,
          1916,
          295,
          721,
          11,
          472,
          307,
          286,
          727,
          829,
          746,
          294,
          309,
          11,
          51477
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1505.94,
        "id": 543,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1504,
        "temperature": 0,
        "text": " but I think I probably should just say,",
        "tokens": [
          51477,
          457,
          286,
          519,
          286,
          1391,
          820,
          445,
          584,
          11,
          51574
        ]
      },
      {
        "avg_logprob": -0.27009698776971724,
        "compression_ratio": 1.5296803652968036,
        "end": 1510.94,
        "id": 544,
        "no_speech_prob": 0.0000011911081401194679,
        "seek": 148174,
        "start": 1505.94,
        "temperature": 0,
        "text": " I shouldn't do it only if x.length is greater than zero.",
        "tokens": [
          51574,
          286,
          4659,
          380,
          360,
          309,
          787,
          498,
          2031,
          13,
          45390,
          307,
          5044,
          813,
          4018,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1515.06,
        "id": 545,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1512.02,
        "temperature": 0,
        "text": " So this is definitely, then do I want to bother with,",
        "tokens": [
          50378,
          407,
          341,
          307,
          2138,
          11,
          550,
          360,
          286,
          528,
          281,
          8677,
          365,
          11,
          50530
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1516.66,
        "id": 546,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1515.06,
        "temperature": 0,
        "text": " do I want to bother with doing any of this?",
        "tokens": [
          50530,
          360,
          286,
          528,
          281,
          8677,
          365,
          884,
          604,
          295,
          341,
          30,
          50610
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1518.02,
        "id": 547,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1516.66,
        "temperature": 0,
        "text": " If there's no values in there,",
        "tokens": [
          50610,
          759,
          456,
          311,
          572,
          4190,
          294,
          456,
          11,
          50678
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1520.66,
        "id": 548,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1518.02,
        "temperature": 0,
        "text": " like calling predict and stuff with an empty array,",
        "tokens": [
          50678,
          411,
          5141,
          6069,
          293,
          1507,
          365,
          364,
          6707,
          10225,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1522.14,
        "id": 549,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1520.66,
        "temperature": 0,
        "text": " I think it's going to cause problems.",
        "tokens": [
          50810,
          286,
          519,
          309,
          311,
          516,
          281,
          3082,
          2740,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1523.38,
        "id": 550,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1522.14,
        "temperature": 0,
        "text": " That makes sense.",
        "tokens": [
          50884,
          663,
          1669,
          2020,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1524.68,
        "id": 551,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1523.38,
        "temperature": 0,
        "text": " All right, let's try this.",
        "tokens": [
          50946,
          1057,
          558,
          11,
          718,
          311,
          853,
          341,
          13,
          51011
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1528.88,
        "id": 552,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1525.58,
        "temperature": 0,
        "text": " X is not defined, x vals, my naming.",
        "tokens": [
          51056,
          1783,
          307,
          406,
          7642,
          11,
          2031,
          371,
          1124,
          11,
          452,
          25290,
          13,
          51221
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1533.66,
        "id": 553,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1530.16,
        "temperature": 0,
        "text": " Okay, sketch 45.",
        "tokens": [
          51285,
          1033,
          11,
          12325,
          6905,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.31761880354447797,
        "compression_ratio": 1.5674418604651164,
        "end": 1535.06,
        "id": 554,
        "no_speech_prob": 0.000005594337380898651,
        "seek": 151174,
        "start": 1533.66,
        "temperature": 0,
        "text": " Ah, this is x vals.",
        "tokens": [
          51460,
          2438,
          11,
          341,
          307,
          2031,
          371,
          1124,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1540.62,
        "id": 555,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1535.62,
        "temperature": 0,
        "text": " And this is x vals, y vals.",
        "tokens": [
          50392,
          400,
          341,
          307,
          2031,
          371,
          1124,
          11,
          288,
          371,
          1124,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1543.8999999999999,
        "id": 556,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1542.46,
        "temperature": 0,
        "text": " Okay, that should be good.",
        "tokens": [
          50734,
          1033,
          11,
          300,
          820,
          312,
          665,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1547,
        "id": 557,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1544.82,
        "temperature": 0,
        "text": " All right, let's try this.",
        "tokens": [
          50852,
          1057,
          558,
          11,
          718,
          311,
          853,
          341,
          13,
          50961
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1553.02,
        "id": 558,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1550.7,
        "temperature": 0,
        "text": " This is not square, being told in the chat,",
        "tokens": [
          51146,
          639,
          307,
          406,
          3732,
          11,
          885,
          1907,
          294,
          264,
          5081,
          11,
          51262
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1556.8999999999999,
        "id": 559,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1553.02,
        "temperature": 0,
        "text": " breaking news, that this is actually.squared,",
        "tokens": [
          51262,
          7697,
          2583,
          11,
          300,
          341,
          307,
          767,
          2411,
          33292,
          1642,
          11,
          51456
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1558.8999999999999,
        "id": 560,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1556.8999999999999,
        "temperature": 0,
        "text": " not.squared, is that right?",
        "tokens": [
          51456,
          406,
          2411,
          33292,
          1642,
          11,
          307,
          300,
          558,
          30,
          51556
        ]
      },
      {
        "avg_logprob": -0.3430559662566788,
        "compression_ratio": 1.5256410256410255,
        "end": 1564.7,
        "id": 561,
        "no_speech_prob": 0.000013211956684244797,
        "seek": 153506,
        "start": 1561.6599999999999,
        "temperature": 0,
        "text": " Yeah, oh, it's square, a.square, okay.",
        "tokens": [
          51694,
          865,
          11,
          1954,
          11,
          309,
          311,
          3732,
          11,
          257,
          13,
          33292,
          543,
          11,
          1392,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1566.4199999999998,
        "id": 562,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1565.58,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50390,
          1033,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1571.02,
        "id": 563,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1570.1799999999998,
        "temperature": 0,
        "text": " There we go, okay.",
        "tokens": [
          50620,
          821,
          321,
          352,
          11,
          1392,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1573.74,
        "id": 564,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1571.02,
        "temperature": 0,
        "text": " So things are going and there's no, I don't have any,",
        "tokens": [
          50662,
          407,
          721,
          366,
          516,
          293,
          456,
          311,
          572,
          11,
          286,
          500,
          380,
          362,
          604,
          11,
          50798
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1578.74,
        "id": 565,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1573.74,
        "temperature": 0,
        "text": " like I could look at, that's m, m, m.print, right?",
        "tokens": [
          50798,
          411,
          286,
          727,
          574,
          412,
          11,
          300,
          311,
          275,
          11,
          275,
          11,
          275,
          13,
          14030,
          11,
          558,
          30,
          51048
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1583.34,
        "id": 566,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1581.94,
        "temperature": 0,
        "text": " So you can see it's changing.",
        "tokens": [
          51208,
          407,
          291,
          393,
          536,
          309,
          311,
          4473,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1584.8999999999999,
        "id": 567,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1583.34,
        "temperature": 0,
        "text": " It's actually like training it.",
        "tokens": [
          51278,
          467,
          311,
          767,
          411,
          3097,
          309,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1586.3999999999999,
        "id": 568,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1584.8999999999999,
        "temperature": 0,
        "text": " Like the value of m is changing.",
        "tokens": [
          51356,
          1743,
          264,
          2158,
          295,
          275,
          307,
          4473,
          13,
          51431
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1588.1399999999999,
        "id": 569,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1586.3999999999999,
        "temperature": 0,
        "text": " So everything's going and working.",
        "tokens": [
          51431,
          407,
          1203,
          311,
          516,
          293,
          1364,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1591.06,
        "id": 570,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1588.1399999999999,
        "temperature": 0,
        "text": " The problem is I'm not seeing the results.",
        "tokens": [
          51518,
          440,
          1154,
          307,
          286,
          478,
          406,
          2577,
          264,
          3542,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25013566900182654,
        "compression_ratio": 1.5555555555555556,
        "end": 1592.3999999999999,
        "id": 571,
        "no_speech_prob": 0.0000042228321035509,
        "seek": 156506,
        "start": 1591.06,
        "temperature": 0,
        "text": " Let's just check b.",
        "tokens": [
          51664,
          961,
          311,
          445,
          1520,
          272,
          13,
          51731
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1598.98,
        "id": 572,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1595.8999999999999,
        "temperature": 0,
        "text": " And I haven't done any memory cleanup.",
        "tokens": [
          50406,
          400,
          286,
          2378,
          380,
          1096,
          604,
          4675,
          40991,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1602.8,
        "id": 573,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1598.98,
        "temperature": 0,
        "text": " So if I say memory.numTensors, is that what it is?",
        "tokens": [
          50560,
          407,
          498,
          286,
          584,
          4675,
          13,
          77,
          449,
          51,
          694,
          830,
          11,
          307,
          300,
          437,
          309,
          307,
          30,
          50751
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1605.22,
        "id": 574,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1604.1399999999999,
        "temperature": 0,
        "text": " No, what is it again?",
        "tokens": [
          50818,
          883,
          11,
          437,
          307,
          309,
          797,
          30,
          50872
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1607.12,
        "id": 575,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1605.22,
        "temperature": 0,
        "text": " So let's look under memory management.",
        "tokens": [
          50872,
          407,
          718,
          311,
          574,
          833,
          4675,
          4592,
          13,
          50967
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1612.48,
        "id": 576,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1609.7,
        "temperature": 0,
        "text": " Memory, oh, memory num, oh, this, tf.",
        "tokens": [
          51096,
          38203,
          11,
          1954,
          11,
          4675,
          1031,
          11,
          1954,
          11,
          341,
          11,
          256,
          69,
          13,
          51235
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1614.58,
        "id": 577,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1612.48,
        "temperature": 0,
        "text": " So I know you can't see this, but this is what I want.",
        "tokens": [
          51235,
          407,
          286,
          458,
          291,
          393,
          380,
          536,
          341,
          11,
          457,
          341,
          307,
          437,
          286,
          528,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1617.6599999999999,
        "id": 578,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1614.58,
        "temperature": 0,
        "text": " I want to check how much, I want to check and see",
        "tokens": [
          51340,
          286,
          528,
          281,
          1520,
          577,
          709,
          11,
          286,
          528,
          281,
          1520,
          293,
          536,
          51494
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1620.94,
        "id": 579,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1617.6599999999999,
        "temperature": 0,
        "text": " like how, if I have cleaned up stuff.",
        "tokens": [
          51494,
          411,
          577,
          11,
          498,
          286,
          362,
          16146,
          493,
          1507,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1623.4199999999998,
        "id": 580,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1620.94,
        "temperature": 0,
        "text": " You can see I have 1,147 tensors.",
        "tokens": [
          51658,
          509,
          393,
          536,
          286,
          362,
          502,
          11,
          7271,
          22,
          10688,
          830,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.20871982021608215,
        "compression_ratio": 1.7210300429184548,
        "end": 1624.86,
        "id": 581,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 159506,
        "start": 1623.4199999999998,
        "temperature": 0,
        "text": " So I need to do the memory cleanup.",
        "tokens": [
          51782,
          407,
          286,
          643,
          281,
          360,
          264,
          4675,
          40991,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1626.54,
        "id": 582,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1625.6599999999999,
        "temperature": 0,
        "text": " I don't know, probably better practice would be",
        "tokens": [
          50404,
          286,
          500,
          380,
          458,
          11,
          1391,
          1101,
          3124,
          576,
          312,
          50448
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1627.84,
        "id": 583,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1626.54,
        "temperature": 0,
        "text": " for me to clean up as I'm going,",
        "tokens": [
          50448,
          337,
          385,
          281,
          2541,
          493,
          382,
          286,
          478,
          516,
          11,
          50513
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1630.4199999999998,
        "id": 584,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1627.84,
        "temperature": 0,
        "text": " but I'm kind of going to clean up at the end.",
        "tokens": [
          50513,
          457,
          286,
          478,
          733,
          295,
          516,
          281,
          2541,
          493,
          412,
          264,
          917,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1633.4599999999998,
        "id": 585,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1630.4199999999998,
        "temperature": 0,
        "text": " All right, so let's, I just want to click back here",
        "tokens": [
          50642,
          1057,
          558,
          11,
          370,
          718,
          311,
          11,
          286,
          445,
          528,
          281,
          2052,
          646,
          510,
          50794
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1635.62,
        "id": 586,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1633.4599999999998,
        "temperature": 0,
        "text": " for a second, oops, no.",
        "tokens": [
          50794,
          337,
          257,
          1150,
          11,
          34166,
          11,
          572,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1638.6999999999998,
        "id": 587,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1635.62,
        "temperature": 0,
        "text": " I'm just going to click no loop to shut this off.",
        "tokens": [
          50902,
          286,
          478,
          445,
          516,
          281,
          2052,
          572,
          6367,
          281,
          5309,
          341,
          766,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1639.54,
        "id": 588,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1638.6999999999998,
        "temperature": 0,
        "text": " And let's go here.",
        "tokens": [
          51056,
          400,
          718,
          311,
          352,
          510,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1640.4199999999998,
        "id": 589,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1639.54,
        "temperature": 0,
        "text": " So what do I need to do?",
        "tokens": [
          51098,
          407,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          51142
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1642.56,
        "id": 590,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1640.4199999999998,
        "temperature": 0,
        "text": " Ah, I need to visualize what's going on.",
        "tokens": [
          51142,
          2438,
          11,
          286,
          643,
          281,
          23273,
          437,
          311,
          516,
          322,
          13,
          51249
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1645.5,
        "id": 591,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1643.56,
        "temperature": 0,
        "text": " All right, so how do I do that?",
        "tokens": [
          51299,
          1057,
          558,
          11,
          370,
          577,
          360,
          286,
          360,
          300,
          30,
          51396
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1648.1599999999999,
        "id": 592,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1645.5,
        "temperature": 0,
        "text": " So I need to draw a line.",
        "tokens": [
          51396,
          407,
          286,
          643,
          281,
          2642,
          257,
          1622,
          13,
          51529
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1652.1599999999999,
        "id": 593,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1649.32,
        "temperature": 0,
        "text": " So the way that I would draw the line is first,",
        "tokens": [
          51587,
          407,
          264,
          636,
          300,
          286,
          576,
          2642,
          264,
          1622,
          307,
          700,
          11,
          51729
        ]
      },
      {
        "avg_logprob": -0.20754034519195558,
        "compression_ratio": 1.839080459770115,
        "end": 1653.8799999999999,
        "id": 594,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 162486,
        "start": 1652.1599999999999,
        "temperature": 0,
        "text": " what I would do is all I really need",
        "tokens": [
          51729,
          437,
          286,
          576,
          360,
          307,
          439,
          286,
          534,
          643,
          51815
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1657.2,
        "id": 595,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1653.88,
        "temperature": 0,
        "text": " is to give myself the X value of zero",
        "tokens": [
          50364,
          307,
          281,
          976,
          2059,
          264,
          1783,
          2158,
          295,
          4018,
          50530
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1660.6000000000001,
        "id": 596,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1657.2,
        "temperature": 0,
        "text": " and the X value of one, get the two Y values",
        "tokens": [
          50530,
          293,
          264,
          1783,
          2158,
          295,
          472,
          11,
          483,
          264,
          732,
          398,
          4190,
          50700
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1662.94,
        "id": 597,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1660.6000000000001,
        "temperature": 0,
        "text": " and draw a line between those two points.",
        "tokens": [
          50700,
          293,
          2642,
          257,
          1622,
          1296,
          729,
          732,
          2793,
          13,
          50817
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1667.94,
        "id": 598,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1662.94,
        "temperature": 0,
        "text": " So if I were to say, let X equal TF scalar.",
        "tokens": [
          50817,
          407,
          498,
          286,
          645,
          281,
          584,
          11,
          718,
          1783,
          2681,
          40964,
          39684,
          13,
          51067
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1675.1000000000001,
        "id": 599,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1671.22,
        "temperature": 0,
        "text": " This is silly for me to use the predict function.",
        "tokens": [
          51231,
          639,
          307,
          11774,
          337,
          385,
          281,
          764,
          264,
          6069,
          2445,
          13,
          51425
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1675.94,
        "id": 600,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1675.1000000000001,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51425,
          1545,
          406,
          30,
          51467
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1676.7600000000002,
        "id": 601,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1675.94,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51467,
          1545,
          406,
          30,
          51508
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1678.0400000000002,
        "id": 602,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1676.7600000000002,
        "temperature": 0,
        "text": " Let's use the predict function.",
        "tokens": [
          51508,
          961,
          311,
          764,
          264,
          6069,
          2445,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1680.16,
        "id": 603,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1678.0400000000002,
        "temperature": 0,
        "text": " TF scalar zero.",
        "tokens": [
          51572,
          40964,
          39684,
          4018,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.23580554924388925,
        "compression_ratio": 1.7049180327868851,
        "end": 1682.88,
        "id": 604,
        "no_speech_prob": 8.579232257943659e-7,
        "seek": 165388,
        "start": 1680.16,
        "temperature": 0,
        "text": " So X one is TF scalar zero.",
        "tokens": [
          51678,
          407,
          1783,
          472,
          307,
          40964,
          39684,
          4018,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1688.0400000000002,
        "id": 605,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1683.0400000000002,
        "temperature": 0,
        "text": " Y one equals TF equals predict X one.",
        "tokens": [
          50372,
          398,
          472,
          6915,
          40964,
          6915,
          6069,
          1783,
          472,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1693.9,
        "id": 606,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1690.68,
        "temperature": 0,
        "text": " X two equals TF scalar one.",
        "tokens": [
          50754,
          1783,
          732,
          6915,
          40964,
          39684,
          472,
          13,
          50915
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1698.72,
        "id": 607,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1694.8400000000001,
        "temperature": 0,
        "text": " Y two equals predict X two.",
        "tokens": [
          50962,
          398,
          732,
          6915,
          6069,
          1783,
          732,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1700.1200000000001,
        "id": 608,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1698.72,
        "temperature": 0,
        "text": " Right, so this should give me,",
        "tokens": [
          51156,
          1779,
          11,
          370,
          341,
          820,
          976,
          385,
          11,
          51226
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1702.7600000000002,
        "id": 609,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1700.1200000000001,
        "temperature": 0,
        "text": " I mean, it's a little bit silly for me to not just do this,",
        "tokens": [
          51226,
          286,
          914,
          11,
          309,
          311,
          257,
          707,
          857,
          11774,
          337,
          385,
          281,
          406,
          445,
          360,
          341,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1706,
        "id": 610,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1702.7600000000002,
        "temperature": 0,
        "text": " keep an extra copy of like M and B as regular numbers,",
        "tokens": [
          51358,
          1066,
          364,
          2857,
          5055,
          295,
          411,
          376,
          293,
          363,
          382,
          3890,
          3547,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1707.5200000000002,
        "id": 611,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1706,
        "temperature": 0,
        "text": " but let's keep going with this.",
        "tokens": [
          51520,
          457,
          718,
          311,
          1066,
          516,
          365,
          341,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1708.8200000000002,
        "id": 612,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1707.5200000000002,
        "temperature": 0,
        "text": " Will this work?",
        "tokens": [
          51596,
          3099,
          341,
          589,
          30,
          51661
        ]
      },
      {
        "avg_logprob": -0.20810660575200052,
        "compression_ratio": 1.5497630331753554,
        "end": 1711.4,
        "id": 613,
        "no_speech_prob": 0.0000019638039248093264,
        "seek": 168288,
        "start": 1708.8200000000002,
        "temperature": 0,
        "text": " Is it going to be able to take a scalar",
        "tokens": [
          51661,
          1119,
          309,
          516,
          281,
          312,
          1075,
          281,
          747,
          257,
          39684,
          51790
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1712.76,
        "id": 614,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1711.4,
        "temperature": 0,
        "text": " and make a 1D tensor?",
        "tokens": [
          50364,
          293,
          652,
          257,
          502,
          35,
          40863,
          30,
          50432
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1714.1200000000001,
        "id": 615,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1712.76,
        "temperature": 0,
        "text": " I think so.",
        "tokens": [
          50432,
          286,
          519,
          370,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1716.2,
        "id": 616,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1714.1200000000001,
        "temperature": 0,
        "text": " So let me just see here.",
        "tokens": [
          50500,
          407,
          718,
          385,
          445,
          536,
          510,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1721.1200000000001,
        "id": 617,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1716.2,
        "temperature": 0,
        "text": " So let me do X one dot print, Y one dot print.",
        "tokens": [
          50604,
          407,
          718,
          385,
          360,
          1783,
          472,
          5893,
          4482,
          11,
          398,
          472,
          5893,
          4482,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1722.2800000000002,
        "id": 618,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1721.1200000000001,
        "temperature": 0,
        "text": " So let's see that.",
        "tokens": [
          50850,
          407,
          718,
          311,
          536,
          300,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1726.98,
        "id": 619,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1723.92,
        "temperature": 0,
        "text": " Tensor 1D requires values to be a flat typed array.",
        "tokens": [
          50990,
          34306,
          502,
          35,
          7029,
          4190,
          281,
          312,
          257,
          4962,
          33941,
          10225,
          13,
          51143
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1729.5600000000002,
        "id": 620,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1728.5600000000002,
        "temperature": 0,
        "text": " All right, so one thing I could do",
        "tokens": [
          51222,
          1057,
          558,
          11,
          370,
          472,
          551,
          286,
          727,
          360,
          51272
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1734.5600000000002,
        "id": 621,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1729.5600000000002,
        "temperature": 0,
        "text": " is instead of making it a scalar,",
        "tokens": [
          51272,
          307,
          2602,
          295,
          1455,
          309,
          257,
          39684,
          11,
          51522
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1736.38,
        "id": 622,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1734.88,
        "temperature": 0,
        "text": " I can make it a 1D tensor.",
        "tokens": [
          51538,
          286,
          393,
          652,
          309,
          257,
          502,
          35,
          40863,
          13,
          51613
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1738.96,
        "id": 623,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1736.38,
        "temperature": 0,
        "text": " That's what it wants and do the same thing here.",
        "tokens": [
          51613,
          663,
          311,
          437,
          309,
          2738,
          293,
          360,
          264,
          912,
          551,
          510,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.21366976153466008,
        "compression_ratio": 1.6575342465753424,
        "end": 1740.8000000000002,
        "id": 624,
        "no_speech_prob": 0.0000054222177823248785,
        "seek": 171140,
        "start": 1738.96,
        "temperature": 0,
        "text": " And I have to put it in as an array then,",
        "tokens": [
          51742,
          400,
          286,
          362,
          281,
          829,
          309,
          294,
          382,
          364,
          10225,
          550,
          11,
          51834
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1742.12,
        "id": 625,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1741.2,
        "temperature": 0,
        "text": " but it's just one value.",
        "tokens": [
          50384,
          457,
          309,
          311,
          445,
          472,
          2158,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1743.52,
        "id": 626,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1742.12,
        "temperature": 0,
        "text": " Oh, this is so silly.",
        "tokens": [
          50430,
          876,
          11,
          341,
          307,
          370,
          11774,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1745,
        "id": 627,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1743.52,
        "temperature": 0,
        "text": " Why am I doing X one and one?",
        "tokens": [
          50500,
          1545,
          669,
          286,
          884,
          1783,
          472,
          293,
          472,
          30,
          50574
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1748.52,
        "id": 628,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1746.1599999999999,
        "temperature": 0,
        "text": " I could just do this, right?",
        "tokens": [
          50632,
          286,
          727,
          445,
          360,
          341,
          11,
          558,
          30,
          50750
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1751.76,
        "id": 629,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1748.52,
        "temperature": 0,
        "text": " Xs, once again, can I use Xs?",
        "tokens": [
          50750,
          1783,
          82,
          11,
          1564,
          797,
          11,
          393,
          286,
          764,
          1783,
          82,
          30,
          50912
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1753.32,
        "id": 630,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1751.76,
        "temperature": 0,
        "text": " Yeah, yeah, yeah.",
        "tokens": [
          50912,
          865,
          11,
          1338,
          11,
          1338,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1756.8,
        "id": 631,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1753.32,
        "temperature": 0,
        "text": " So I could just do it with zero and one.",
        "tokens": [
          50990,
          407,
          286,
          727,
          445,
          360,
          309,
          365,
          4018,
          293,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1761.8,
        "id": 632,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1756.8,
        "temperature": 0,
        "text": " Constant Xs and then constant Ys equals predict Xs.",
        "tokens": [
          51164,
          37413,
          1783,
          82,
          293,
          550,
          5754,
          398,
          82,
          6915,
          6069,
          1783,
          82,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1765.54,
        "id": 633,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1763.24,
        "temperature": 0,
        "text": " Right, so I could have both these points now.",
        "tokens": [
          51486,
          1779,
          11,
          370,
          286,
          727,
          362,
          1293,
          613,
          2793,
          586,
          13,
          51601
        ]
      },
      {
        "avg_logprob": -0.2284960866976185,
        "compression_ratio": 1.580188679245283,
        "end": 1770.54,
        "id": 634,
        "no_speech_prob": 0.0000017061830703823944,
        "seek": 174080,
        "start": 1765.54,
        "temperature": 0,
        "text": " Then let's say Xs dot print, Ys dot print.",
        "tokens": [
          51601,
          1396,
          718,
          311,
          584,
          1783,
          82,
          5893,
          4482,
          11,
          398,
          82,
          5893,
          4482,
          13,
          51851
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1772.48,
        "id": 635,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1771.6399999999999,
        "temperature": 0,
        "text": " Let's look at that.",
        "tokens": [
          50406,
          961,
          311,
          574,
          412,
          300,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1773.68,
        "id": 636,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1772.48,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          50448,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1779.12,
        "id": 637,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1776.2,
        "temperature": 0,
        "text": " Predict is not defined because my E key doesn't work",
        "tokens": [
          50634,
          430,
          24945,
          307,
          406,
          7642,
          570,
          452,
          462,
          2141,
          1177,
          380,
          589,
          50780
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1780.96,
        "id": 638,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1779.12,
        "temperature": 0,
        "text": " and I have to type it several times.",
        "tokens": [
          50780,
          293,
          286,
          362,
          281,
          2010,
          309,
          2940,
          1413,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1787,
        "id": 639,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1782.5,
        "temperature": 0,
        "text": " Tensor 1D requires values to be a flat typed array.",
        "tokens": [
          50949,
          34306,
          502,
          35,
          7029,
          4190,
          281,
          312,
          257,
          4962,
          33941,
          10225,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1790.72,
        "id": 640,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1787,
        "temperature": 0,
        "text": " Oh, silly, silly me.",
        "tokens": [
          51174,
          876,
          11,
          11774,
          11,
          11774,
          385,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1792.6399999999999,
        "id": 641,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1790.72,
        "temperature": 0,
        "text": " Predict doesn't want a tensor.",
        "tokens": [
          51360,
          430,
          24945,
          1177,
          380,
          528,
          257,
          40863,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2449091967414407,
        "compression_ratio": 1.4685714285714286,
        "end": 1794.56,
        "id": 642,
        "no_speech_prob": 0.00002078516445180867,
        "seek": 177080,
        "start": 1792.6399999999999,
        "temperature": 0,
        "text": " Oh, it wants this.",
        "tokens": [
          51456,
          876,
          11,
          309,
          2738,
          341,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1800.56,
        "id": 643,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1795.56,
        "temperature": 0,
        "text": " So line X equal, let me just,",
        "tokens": [
          50414,
          407,
          1622,
          1783,
          2681,
          11,
          718,
          385,
          445,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1806.72,
        "id": 644,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1803.44,
        "temperature": 0,
        "text": " this is a little bit silly, but I'm gonna do this.",
        "tokens": [
          50808,
          341,
          307,
          257,
          707,
          857,
          11774,
          11,
          457,
          286,
          478,
          799,
          360,
          341,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1809.2,
        "id": 645,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1806.72,
        "temperature": 0,
        "text": " So I'm gonna make the, oh,",
        "tokens": [
          50972,
          407,
          286,
          478,
          799,
          652,
          264,
          11,
          1954,
          11,
          51096
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1811.6,
        "id": 646,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1809.2,
        "temperature": 0,
        "text": " oh, but I don't need to know the Xs.",
        "tokens": [
          51096,
          1954,
          11,
          457,
          286,
          500,
          380,
          643,
          281,
          458,
          264,
          1783,
          82,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1815.2,
        "id": 647,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1811.6,
        "temperature": 0,
        "text": " I don't need to have the Xs as a tensor because, yeah.",
        "tokens": [
          51216,
          286,
          500,
          380,
          643,
          281,
          362,
          264,
          1783,
          82,
          382,
          257,
          40863,
          570,
          11,
          1338,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1817.84,
        "id": 648,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1816.6399999999999,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51468,
          4919,
          11,
          2201,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1820.5,
        "id": 649,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1818.8799999999999,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51580,
          821,
          321,
          352,
          13,
          51661
        ]
      },
      {
        "avg_logprob": -0.29554858960603414,
        "compression_ratio": 1.5027932960893855,
        "end": 1823.8,
        "id": 650,
        "no_speech_prob": 0.00005144220631336793,
        "seek": 179456,
        "start": 1820.5,
        "temperature": 0,
        "text": " My predict function, I totally forgot.",
        "tokens": [
          51661,
          1222,
          6069,
          2445,
          11,
          286,
          3879,
          5298,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1825,
        "id": 651,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1824.1599999999999,
        "temperature": 0,
        "text": " See, this is just,",
        "tokens": [
          50382,
          3008,
          11,
          341,
          307,
          445,
          11,
          50424
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1826.6399999999999,
        "id": 652,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1825,
        "temperature": 0,
        "text": " there's so many different ways you could do this.",
        "tokens": [
          50424,
          456,
          311,
          370,
          867,
          819,
          2098,
          291,
          727,
          360,
          341,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1829.52,
        "id": 653,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1826.6399999999999,
        "temperature": 0,
        "text": " Like I could enforce you to convert to a tensor",
        "tokens": [
          50506,
          1743,
          286,
          727,
          24825,
          291,
          281,
          7620,
          281,
          257,
          40863,
          50650
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1831.08,
        "id": 654,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1829.52,
        "temperature": 0,
        "text": " before you pass it into predict,",
        "tokens": [
          50650,
          949,
          291,
          1320,
          309,
          666,
          6069,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1834.52,
        "id": 655,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1831.08,
        "temperature": 0,
        "text": " but a lot of these decisions are completely arbitrary.",
        "tokens": [
          50728,
          457,
          257,
          688,
          295,
          613,
          5327,
          366,
          2584,
          23211,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1836,
        "id": 656,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1834.52,
        "temperature": 0,
        "text": " So you might have a better way of doing it,",
        "tokens": [
          50900,
          407,
          291,
          1062,
          362,
          257,
          1101,
          636,
          295,
          884,
          309,
          11,
          50974
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1837.76,
        "id": 657,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1836,
        "temperature": 0,
        "text": " but still I'm gonna do this.",
        "tokens": [
          50974,
          457,
          920,
          286,
          478,
          799,
          360,
          341,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1840.44,
        "id": 658,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1837.76,
        "temperature": 0,
        "text": " So now I have the Xs and the Ys,",
        "tokens": [
          51062,
          407,
          586,
          286,
          362,
          264,
          1783,
          82,
          293,
          264,
          398,
          82,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1842.46,
        "id": 659,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1840.44,
        "temperature": 0,
        "text": " and I don't even need to say Xs print.",
        "tokens": [
          51196,
          293,
          286,
          500,
          380,
          754,
          643,
          281,
          584,
          1783,
          82,
          4482,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1844.8799999999999,
        "id": 660,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1843.48,
        "temperature": 0,
        "text": " So we can see, okay, great.",
        "tokens": [
          51348,
          407,
          321,
          393,
          536,
          11,
          1392,
          11,
          869,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1846.48,
        "id": 661,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1844.8799999999999,
        "temperature": 0,
        "text": " So I'm getting these points.",
        "tokens": [
          51418,
          407,
          286,
          478,
          1242,
          613,
          2793,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.23438641703720633,
        "compression_ratio": 1.6334519572953736,
        "end": 1851.44,
        "id": 662,
        "no_speech_prob": 0.00004198628448648378,
        "seek": 182380,
        "start": 1846.48,
        "temperature": 0,
        "text": " Kate Wieckmann in the chat makes an excellent point,",
        "tokens": [
          51498,
          16251,
          9233,
          547,
          14912,
          294,
          264,
          5081,
          1669,
          364,
          7103,
          935,
          11,
          51746
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1856.44,
        "id": 663,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1851.44,
        "temperature": 0,
        "text": " which is that I should think about actually mapping it",
        "tokens": [
          50364,
          597,
          307,
          300,
          286,
          820,
          519,
          466,
          767,
          18350,
          309,
          50614
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1860.88,
        "id": 664,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1857.24,
        "temperature": 0,
        "text": " between negative one and one with zero, zero in the center.",
        "tokens": [
          50654,
          1296,
          3671,
          472,
          293,
          472,
          365,
          4018,
          11,
          4018,
          294,
          264,
          3056,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1862.8,
        "id": 665,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1860.88,
        "temperature": 0,
        "text": " That's not such a bad idea.",
        "tokens": [
          50836,
          663,
          311,
          406,
          1270,
          257,
          1578,
          1558,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1865.26,
        "id": 666,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1864,
        "temperature": 0,
        "text": " Let me just keep going with this,",
        "tokens": [
          50992,
          961,
          385,
          445,
          1066,
          516,
          365,
          341,
          11,
          51055
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1866.88,
        "id": 667,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1865.26,
        "temperature": 0,
        "text": " and then maybe I'll change that after the fact,",
        "tokens": [
          51055,
          293,
          550,
          1310,
          286,
          603,
          1319,
          300,
          934,
          264,
          1186,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1868.04,
        "id": 668,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1866.88,
        "temperature": 0,
        "text": " because this should work anyway.",
        "tokens": [
          51136,
          570,
          341,
          820,
          589,
          4033,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1869.6000000000001,
        "id": 669,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1868.04,
        "temperature": 0,
        "text": " So now here's the thing.",
        "tokens": [
          51194,
          407,
          586,
          510,
          311,
          264,
          551,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1870.9,
        "id": 670,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1869.6000000000001,
        "temperature": 0,
        "text": " Here's the awkward thing.",
        "tokens": [
          51272,
          1692,
          311,
          264,
          11411,
          551,
          13,
          51337
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1874.52,
        "id": 671,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1872.3200000000002,
        "temperature": 0,
        "text": " In order for me, all I need to do now",
        "tokens": [
          51408,
          682,
          1668,
          337,
          385,
          11,
          439,
          286,
          643,
          281,
          360,
          586,
          51518
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1876.24,
        "id": 672,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1874.52,
        "temperature": 0,
        "text": " is basically say this.",
        "tokens": [
          51518,
          307,
          1936,
          584,
          341,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.23648250709145757,
        "compression_ratio": 1.58,
        "end": 1880.8,
        "id": 673,
        "no_speech_prob": 0.000001653689423619653,
        "seek": 185144,
        "start": 1877.3200000000002,
        "temperature": 0,
        "text": " Let X1 equal map Xs zero,",
        "tokens": [
          51658,
          961,
          1783,
          16,
          2681,
          4471,
          1783,
          82,
          4018,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1882.56,
        "id": 674,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1880.8,
        "temperature": 0,
        "text": " which goes between zero and one,",
        "tokens": [
          50364,
          597,
          1709,
          1296,
          4018,
          293,
          472,
          11,
          50452
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1884.36,
        "id": 675,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1882.56,
        "temperature": 0,
        "text": " one between zero and with.",
        "tokens": [
          50452,
          472,
          1296,
          4018,
          293,
          365,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1885.2,
        "id": 676,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1884.36,
        "temperature": 0,
        "text": " And this is kind of silly",
        "tokens": [
          50542,
          400,
          341,
          307,
          733,
          295,
          11774,
          50584
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1887.3999999999999,
        "id": 677,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1885.2,
        "temperature": 0,
        "text": " because I could just multiply it times with.",
        "tokens": [
          50584,
          570,
          286,
          727,
          445,
          12972,
          309,
          1413,
          365,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1891.9199999999998,
        "id": 678,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1889.24,
        "temperature": 0,
        "text": " But I'm gonna just go with the normalizing,",
        "tokens": [
          50786,
          583,
          286,
          478,
          799,
          445,
          352,
          365,
          264,
          2710,
          3319,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1893.96,
        "id": 679,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1891.9199999999998,
        "temperature": 0,
        "text": " the full normalizing.",
        "tokens": [
          50920,
          264,
          1577,
          2710,
          3319,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1898.6,
        "id": 680,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1893.96,
        "temperature": 0,
        "text": " Y1 equals map X, oh, sorry, X2,",
        "tokens": [
          51022,
          398,
          16,
          6915,
          4471,
          1783,
          11,
          1954,
          11,
          2597,
          11,
          1783,
          17,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1900.68,
        "id": 681,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1898.6,
        "temperature": 0,
        "text": " which map Xs index one.",
        "tokens": [
          51254,
          597,
          4471,
          1783,
          82,
          8186,
          472,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1904.3,
        "id": 682,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1900.68,
        "temperature": 0,
        "text": " So this gives me X1, which is just zero and with.",
        "tokens": [
          51358,
          407,
          341,
          2709,
          385,
          1783,
          16,
          11,
          597,
          307,
          445,
          4018,
          293,
          365,
          13,
          51539
        ]
      },
      {
        "avg_logprob": -0.30515660372647374,
        "compression_ratio": 1.6666666666666667,
        "end": 1909.3,
        "id": 683,
        "no_speech_prob": 0.000002090458337988821,
        "seek": 188080,
        "start": 1904.3,
        "temperature": 0,
        "text": " Now, Y1 equals map Xs index one.",
        "tokens": [
          51539,
          823,
          11,
          398,
          16,
          6915,
          4471,
          1783,
          82,
          8186,
          472,
          13,
          51789
        ]
      },
      {
        "avg_logprob": -0.29242855228789866,
        "compression_ratio": 1.2789115646258504,
        "end": 1916.76,
        "id": 684,
        "no_speech_prob": 8.059445235630847e-7,
        "seek": 191080,
        "start": 1911.76,
        "temperature": 0,
        "text": " And Y2, I wanna map Ys,",
        "tokens": [
          50412,
          400,
          398,
          17,
          11,
          286,
          1948,
          4471,
          398,
          82,
          11,
          50662
        ]
      },
      {
        "avg_logprob": -0.29242855228789866,
        "compression_ratio": 1.2789115646258504,
        "end": 1919.8,
        "id": 685,
        "no_speech_prob": 8.059445235630847e-7,
        "seek": 191080,
        "start": 1916.8,
        "temperature": 0,
        "text": " the Y value is between height and zero,",
        "tokens": [
          50664,
          264,
          398,
          2158,
          307,
          1296,
          6681,
          293,
          4018,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.29242855228789866,
        "compression_ratio": 1.2789115646258504,
        "end": 1925.74,
        "id": 686,
        "no_speech_prob": 8.059445235630847e-7,
        "seek": 191080,
        "start": 1924.44,
        "temperature": 0,
        "text": " because I'm flipping it.",
        "tokens": [
          51046,
          570,
          286,
          478,
          26886,
          309,
          13,
          51111
        ]
      },
      {
        "avg_logprob": -0.29242855228789866,
        "compression_ratio": 1.2789115646258504,
        "end": 1932.3999999999999,
        "id": 687,
        "no_speech_prob": 8.059445235630847e-7,
        "seek": 191080,
        "start": 1928.78,
        "temperature": 0,
        "text": " The problem is, and then I just wanna say line,",
        "tokens": [
          51263,
          440,
          1154,
          307,
          11,
          293,
          550,
          286,
          445,
          1948,
          584,
          1622,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.29242855228789866,
        "compression_ratio": 1.2789115646258504,
        "end": 1936.36,
        "id": 688,
        "no_speech_prob": 8.059445235630847e-7,
        "seek": 191080,
        "start": 1932.3999999999999,
        "temperature": 0,
        "text": " X1, Y1, X2, Y2.",
        "tokens": [
          51444,
          1783,
          16,
          11,
          398,
          16,
          11,
          1783,
          17,
          11,
          398,
          17,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.29242855228789866,
        "compression_ratio": 1.2789115646258504,
        "end": 1939.12,
        "id": 689,
        "no_speech_prob": 8.059445235630847e-7,
        "seek": 191080,
        "start": 1936.36,
        "temperature": 0,
        "text": " So this is really all I need to do.",
        "tokens": [
          51642,
          407,
          341,
          307,
          534,
          439,
          286,
          643,
          281,
          360,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1943.7199999999998,
        "id": 690,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1939.12,
        "temperature": 0,
        "text": " I just wanna get the sort of two points on the line",
        "tokens": [
          50364,
          286,
          445,
          1948,
          483,
          264,
          1333,
          295,
          732,
          2793,
          322,
          264,
          1622,
          50594
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1945.9199999999998,
        "id": 691,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1943.7199999999998,
        "temperature": 0,
        "text": " and then draw a line between them.",
        "tokens": [
          50594,
          293,
          550,
          2642,
          257,
          1622,
          1296,
          552,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1949.12,
        "id": 692,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1945.9199999999998,
        "temperature": 0,
        "text": " This is fine because my Xs are not tensors.",
        "tokens": [
          50704,
          639,
          307,
          2489,
          570,
          452,
          1783,
          82,
          366,
          406,
          10688,
          830,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1954.02,
        "id": 693,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1949.12,
        "temperature": 0,
        "text": " And I can use plain numbers right here, X1, X2.",
        "tokens": [
          50864,
          400,
          286,
          393,
          764,
          11121,
          3547,
          558,
          510,
          11,
          1783,
          16,
          11,
          1783,
          17,
          13,
          51109
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1957.7399999999998,
        "id": 694,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1954.02,
        "temperature": 0,
        "text": " But my Ys, and here, but my Ys are tensors.",
        "tokens": [
          51109,
          583,
          452,
          398,
          82,
          11,
          293,
          510,
          11,
          457,
          452,
          398,
          82,
          366,
          10688,
          830,
          13,
          51295
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1959.52,
        "id": 695,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1957.7399999999998,
        "temperature": 0,
        "text": " So for me to be able to,",
        "tokens": [
          51295,
          407,
          337,
          385,
          281,
          312,
          1075,
          281,
          11,
          51384
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1961.6399999999999,
        "id": 696,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1959.52,
        "temperature": 0,
        "text": " I really need to get the values back.",
        "tokens": [
          51384,
          286,
          534,
          643,
          281,
          483,
          264,
          4190,
          646,
          13,
          51490
        ]
      },
      {
        "avg_logprob": -0.20596820384532483,
        "compression_ratio": 1.5740740740740742,
        "end": 1966.1999999999998,
        "id": 697,
        "no_speech_prob": 0.000007889262633398175,
        "seek": 193912,
        "start": 1961.6399999999999,
        "temperature": 0,
        "text": " And a way to do that is with the function called data.",
        "tokens": [
          51490,
          400,
          257,
          636,
          281,
          360,
          300,
          307,
          365,
          264,
          2445,
          1219,
          1412,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2231709389459519,
        "compression_ratio": 1.535294117647059,
        "end": 1972.16,
        "id": 698,
        "no_speech_prob": 0.0000022603242086915998,
        "seek": 196620,
        "start": 1967.16,
        "temperature": 0,
        "text": " So I'm gonna say, let line Y equal Ys.data.",
        "tokens": [
          50412,
          407,
          286,
          478,
          799,
          584,
          11,
          718,
          1622,
          398,
          2681,
          398,
          82,
          13,
          67,
          3274,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.2231709389459519,
        "compression_ratio": 1.535294117647059,
        "end": 1979.72,
        "id": 699,
        "no_speech_prob": 0.0000022603242086915998,
        "seek": 196620,
        "start": 1976.88,
        "temperature": 0,
        "text": " And I'm just gonna say data sync right now.",
        "tokens": [
          50898,
          400,
          286,
          478,
          445,
          799,
          584,
          1412,
          20271,
          558,
          586,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2231709389459519,
        "compression_ratio": 1.535294117647059,
        "end": 1981.64,
        "id": 700,
        "no_speech_prob": 0.0000022603242086915998,
        "seek": 196620,
        "start": 1979.72,
        "temperature": 0,
        "text": " And let me comment all this out.",
        "tokens": [
          51040,
          400,
          718,
          385,
          2871,
          439,
          341,
          484,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2231709389459519,
        "compression_ratio": 1.535294117647059,
        "end": 1986.96,
        "id": 701,
        "no_speech_prob": 0.0000022603242086915998,
        "seek": 196620,
        "start": 1982.6200000000001,
        "temperature": 0,
        "text": " And let me console log that and see if this comes.",
        "tokens": [
          51185,
          400,
          718,
          385,
          11076,
          3565,
          300,
          293,
          536,
          498,
          341,
          1487,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.2231709389459519,
        "compression_ratio": 1.535294117647059,
        "end": 1990.28,
        "id": 702,
        "no_speech_prob": 0.0000022603242086915998,
        "seek": 196620,
        "start": 1986.96,
        "temperature": 0,
        "text": " So this is kind of a bad idea for a variety of reasons,",
        "tokens": [
          51402,
          407,
          341,
          307,
          733,
          295,
          257,
          1578,
          1558,
          337,
          257,
          5673,
          295,
          4112,
          11,
          51568
        ]
      },
      {
        "avg_logprob": -0.2231709389459519,
        "compression_ratio": 1.535294117647059,
        "end": 1992.0800000000002,
        "id": 703,
        "no_speech_prob": 0.0000022603242086915998,
        "seek": 196620,
        "start": 1990.28,
        "temperature": 0,
        "text": " but I think it's gonna work okay.",
        "tokens": [
          51568,
          457,
          286,
          519,
          309,
          311,
          799,
          589,
          1392,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 1996.56,
        "id": 704,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 1992.36,
        "temperature": 0,
        "text": " So you can see I'm getting those numbers back",
        "tokens": [
          50378,
          407,
          291,
          393,
          536,
          286,
          478,
          1242,
          729,
          3547,
          646,
          50588
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 1998.12,
        "id": 705,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 1996.56,
        "temperature": 0,
        "text": " as a float array.",
        "tokens": [
          50588,
          382,
          257,
          15706,
          10225,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 1999.1999999999998,
        "id": 706,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 1998.12,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50666,
          407,
          510,
          311,
          264,
          551,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2002.4399999999998,
        "id": 707,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 1999.1999999999998,
        "temperature": 0,
        "text": " This really requires not a callback, but a promise.",
        "tokens": [
          50720,
          639,
          534,
          7029,
          406,
          257,
          818,
          3207,
          11,
          457,
          257,
          6228,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2004.74,
        "id": 708,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2002.4399999999998,
        "temperature": 0,
        "text": " And I'm so happy I just did a whole video series",
        "tokens": [
          50882,
          400,
          286,
          478,
          370,
          2055,
          286,
          445,
          630,
          257,
          1379,
          960,
          2638,
          50997
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2005.6,
        "id": 709,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2004.74,
        "temperature": 0,
        "text": " on promises.",
        "tokens": [
          50997,
          322,
          16403,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2008.32,
        "id": 710,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2005.6,
        "temperature": 0,
        "text": " I really should be saying data.then.",
        "tokens": [
          51040,
          286,
          534,
          820,
          312,
          1566,
          1412,
          13,
          19096,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2011.36,
        "id": 711,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2008.32,
        "temperature": 0,
        "text": " And there's even something called tf.nextframe,",
        "tokens": [
          51176,
          400,
          456,
          311,
          754,
          746,
          1219,
          256,
          69,
          13,
          716,
          734,
          17265,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2012.96,
        "id": 712,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2011.36,
        "temperature": 0,
        "text": " which allows me to sort of think about",
        "tokens": [
          51328,
          597,
          4045,
          385,
          281,
          1333,
          295,
          519,
          466,
          51408
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2015.52,
        "id": 713,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2012.96,
        "temperature": 0,
        "text": " the asynchronous nature of pulling the data",
        "tokens": [
          51408,
          264,
          49174,
          3687,
          295,
          8407,
          264,
          1412,
          51536
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2017.1599999999999,
        "id": 714,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2015.52,
        "temperature": 0,
        "text": " out of a tensor into a number",
        "tokens": [
          51536,
          484,
          295,
          257,
          40863,
          666,
          257,
          1230,
          51618
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2018.6999999999998,
        "id": 715,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2017.1599999999999,
        "temperature": 0,
        "text": " that I can use in an animation.",
        "tokens": [
          51618,
          300,
          286,
          393,
          764,
          294,
          364,
          9603,
          13,
          51695
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2019.76,
        "id": 716,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2018.6999999999998,
        "temperature": 0,
        "text": " These are key things,",
        "tokens": [
          51695,
          1981,
          366,
          2141,
          721,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.23822235734495398,
        "compression_ratio": 1.6533333333333333,
        "end": 2021.54,
        "id": 717,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 199208,
        "start": 2019.76,
        "temperature": 0,
        "text": " and I'm definitely gonna have to get to them.",
        "tokens": [
          51748,
          293,
          286,
          478,
          2138,
          799,
          362,
          281,
          483,
          281,
          552,
          13,
          51837
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2023.22,
        "id": 718,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2022.3799999999999,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          50406,
          583,
          510,
          311,
          264,
          551,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2024.18,
        "id": 719,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2023.22,
        "temperature": 0,
        "text": " This is just two numbers.",
        "tokens": [
          50448,
          639,
          307,
          445,
          732,
          3547,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2027.74,
        "id": 720,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2024.18,
        "temperature": 0,
        "text": " I think my animation can handle using data sync.",
        "tokens": [
          50496,
          286,
          519,
          452,
          9603,
          393,
          4813,
          1228,
          1412,
          20271,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2030.98,
        "id": 721,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2027.74,
        "temperature": 0,
        "text": " And maybe somebody from the TensorFlow.js team",
        "tokens": [
          50674,
          400,
          1310,
          2618,
          490,
          264,
          37624,
          13,
          25530,
          1469,
          50836
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2034.06,
        "id": 722,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2030.98,
        "temperature": 0,
        "text": " is gonna wanna say, actually, this is not just a bad idea,",
        "tokens": [
          50836,
          307,
          799,
          1948,
          584,
          11,
          767,
          11,
          341,
          307,
          406,
          445,
          257,
          1578,
          1558,
          11,
          50990
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2035.98,
        "id": 723,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2034.06,
        "temperature": 0,
        "text": " but a really bad idea, I'm not so sure.",
        "tokens": [
          50990,
          457,
          257,
          534,
          1578,
          1558,
          11,
          286,
          478,
          406,
          370,
          988,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2037.6599999999999,
        "id": 724,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2035.98,
        "temperature": 0,
        "text": " But I think it's gonna, let's just get it to work",
        "tokens": [
          51086,
          583,
          286,
          519,
          309,
          311,
          799,
          11,
          718,
          311,
          445,
          483,
          309,
          281,
          589,
          51170
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2039.58,
        "id": 725,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2037.6599999999999,
        "temperature": 0,
        "text": " and see if this demonstrates the idea.",
        "tokens": [
          51170,
          293,
          536,
          498,
          341,
          31034,
          264,
          1558,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2042.22,
        "id": 726,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2039.58,
        "temperature": 0,
        "text": " So now, and I'm gonna call this line Y,",
        "tokens": [
          51266,
          407,
          586,
          11,
          293,
          286,
          478,
          799,
          818,
          341,
          1622,
          398,
          11,
          51398
        ]
      },
      {
        "avg_logprob": -0.24406411912706164,
        "compression_ratio": 1.592885375494071,
        "end": 2047.74,
        "id": 727,
        "no_speech_prob": 0.0000030415963010455016,
        "seek": 202154,
        "start": 2043.1399999999999,
        "temperature": 0,
        "text": " I should be able to say Y1, Y2,",
        "tokens": [
          51444,
          286,
          820,
          312,
          1075,
          281,
          584,
          398,
          16,
          11,
          398,
          17,
          11,
          51674
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2051.48,
        "id": 728,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2047.74,
        "temperature": 0,
        "text": " and I should get zero and one from line Y.",
        "tokens": [
          50364,
          293,
          286,
          820,
          483,
          4018,
          293,
          472,
          490,
          1622,
          398,
          13,
          50551
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2057.06,
        "id": 729,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2053.06,
        "temperature": 0,
        "text": " And now, we should see, we should be done.",
        "tokens": [
          50630,
          400,
          586,
          11,
          321,
          820,
          536,
          11,
          321,
          820,
          312,
          1096,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2061.6,
        "id": 730,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2059.5,
        "temperature": 0,
        "text": " Oh, line Y is not defined.",
        "tokens": [
          50952,
          876,
          11,
          1622,
          398,
          307,
          406,
          7642,
          13,
          51057
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2063.4,
        "id": 731,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2062.56,
        "temperature": 0,
        "text": " Where?",
        "tokens": [
          51105,
          2305,
          30,
          51147
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2066.4,
        "id": 732,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2064.38,
        "temperature": 0,
        "text": " Sketch.js line 61.",
        "tokens": [
          51196,
          49245,
          13,
          25530,
          1622,
          28294,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2069.08,
        "id": 733,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2067.54,
        "temperature": 0,
        "text": " I think I just didn't hit save.",
        "tokens": [
          51354,
          286,
          519,
          286,
          445,
          994,
          380,
          2045,
          3155,
          13,
          51431
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2071.02,
        "id": 734,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2070.18,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51486,
          865,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2075.06,
        "id": 735,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2072.94,
        "temperature": 0,
        "text": " Oh, I haven't clicked any points.",
        "tokens": [
          51624,
          876,
          11,
          286,
          2378,
          380,
          23370,
          604,
          2793,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.280200127994313,
        "compression_ratio": 1.387878787878788,
        "end": 2075.94,
        "id": 736,
        "no_speech_prob": 0.000014285512406786438,
        "seek": 204774,
        "start": 2075.06,
        "temperature": 0,
        "text": " Hey, look at that.",
        "tokens": [
          51730,
          1911,
          11,
          574,
          412,
          300,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2078.82,
        "id": 737,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2076.86,
        "temperature": 0,
        "text": " Oh, hey, look, it's working.",
        "tokens": [
          50410,
          876,
          11,
          4177,
          11,
          574,
          11,
          309,
          311,
          1364,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2080.7400000000002,
        "id": 738,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2078.82,
        "temperature": 0,
        "text": " Oh, that's so exciting.",
        "tokens": [
          50508,
          876,
          11,
          300,
          311,
          370,
          4670,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2081.58,
        "id": 739,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2080.7400000000002,
        "temperature": 0,
        "text": " Ding.",
        "tokens": [
          50604,
          20558,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2082.98,
        "id": 740,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2081.58,
        "temperature": 0,
        "text": " All right, for a couple things.",
        "tokens": [
          50646,
          1057,
          558,
          11,
          337,
          257,
          1916,
          721,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2086.62,
        "id": 741,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2082.98,
        "temperature": 0,
        "text": " Number one is, let's say stroke weight two.",
        "tokens": [
          50716,
          5118,
          472,
          307,
          11,
          718,
          311,
          584,
          12403,
          3364,
          732,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2091.7400000000002,
        "id": 742,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2090.06,
        "temperature": 0,
        "text": " And by the way, we can now start to play",
        "tokens": [
          51070,
          400,
          538,
          264,
          636,
          11,
          321,
          393,
          586,
          722,
          281,
          862,
          51154
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2092.66,
        "id": 743,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2091.7400000000002,
        "temperature": 0,
        "text": " with the learning rate.",
        "tokens": [
          51154,
          365,
          264,
          2539,
          3314,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2094.86,
        "id": 744,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2092.66,
        "temperature": 0,
        "text": " I don't have to clean up the memory stuff.",
        "tokens": [
          51200,
          286,
          500,
          380,
          362,
          281,
          2541,
          493,
          264,
          4675,
          1507,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2098.38,
        "id": 745,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2096.26,
        "temperature": 0,
        "text": " I have to, we can play with the learning rate.",
        "tokens": [
          51380,
          286,
          362,
          281,
          11,
          321,
          393,
          862,
          365,
          264,
          2539,
          3314,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.31270721855513545,
        "compression_ratio": 1.592964824120603,
        "end": 2100.98,
        "id": 746,
        "no_speech_prob": 0.0000028573153940669727,
        "seek": 207594,
        "start": 2098.38,
        "temperature": 0,
        "text": " Like, let's make this 0.01.",
        "tokens": [
          51486,
          1743,
          11,
          718,
          311,
          652,
          341,
          1958,
          13,
          10607,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2106.46,
        "id": 747,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2101.46,
        "temperature": 0,
        "text": " So you can see what happens with this lower learning rate.",
        "tokens": [
          50388,
          407,
          291,
          393,
          536,
          437,
          2314,
          365,
          341,
          3126,
          2539,
          3314,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2108.3,
        "id": 748,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2107.18,
        "temperature": 0,
        "text": " I don't know if it's...",
        "tokens": [
          50674,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          485,
          50730
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2113.7,
        "id": 749,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2112.46,
        "temperature": 0,
        "text": " Let's see, is it really working?",
        "tokens": [
          50938,
          961,
          311,
          536,
          11,
          307,
          309,
          534,
          1364,
          30,
          51000
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2115.44,
        "id": 750,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2113.7,
        "temperature": 0,
        "text": " Well, I shouldn't use such a low learning rate.",
        "tokens": [
          51000,
          1042,
          11,
          286,
          4659,
          380,
          764,
          1270,
          257,
          2295,
          2539,
          3314,
          13,
          51087
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2116.5,
        "id": 751,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2115.44,
        "temperature": 0,
        "text": " Let's make it 0.5.",
        "tokens": [
          51087,
          961,
          311,
          652,
          309,
          1958,
          13,
          20,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2121.98,
        "id": 752,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2118.9,
        "temperature": 0,
        "text": " Yeah, it's definitely happy.",
        "tokens": [
          51260,
          865,
          11,
          309,
          311,
          2138,
          2055,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2123.58,
        "id": 753,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2121.98,
        "temperature": 0,
        "text": " Okay, so this is working.",
        "tokens": [
          51414,
          1033,
          11,
          370,
          341,
          307,
          1364,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2125.26,
        "id": 754,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2123.58,
        "temperature": 0,
        "text": " Linear regression with gradient descent.",
        "tokens": [
          51494,
          14670,
          289,
          24590,
          365,
          16235,
          23475,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.26411532372543495,
        "compression_ratio": 1.4759615384615385,
        "end": 2126.92,
        "id": 755,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 210098,
        "start": 2125.26,
        "temperature": 0,
        "text": " But I have a severe problem.",
        "tokens": [
          51578,
          583,
          286,
          362,
          257,
          8922,
          1154,
          13,
          51661
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2132.04,
        "id": 756,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2127.76,
        "temperature": 0,
        "text": " I am just filling the GPU with tensors and tensors",
        "tokens": [
          50406,
          286,
          669,
          445,
          10623,
          264,
          18407,
          365,
          10688,
          830,
          293,
          10688,
          830,
          50620
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2135.48,
        "id": 757,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2132.04,
        "temperature": 0,
        "text": " and tensors and tensors and never cleaning them up.",
        "tokens": [
          50620,
          293,
          10688,
          830,
          293,
          10688,
          830,
          293,
          1128,
          8924,
          552,
          493,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2137.84,
        "id": 758,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2135.48,
        "temperature": 0,
        "text": " So now it's my job to go through",
        "tokens": [
          50792,
          407,
          586,
          309,
          311,
          452,
          1691,
          281,
          352,
          807,
          50910
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2139.96,
        "id": 759,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2137.84,
        "temperature": 0,
        "text": " and find every place I'm creating a tensor",
        "tokens": [
          50910,
          293,
          915,
          633,
          1081,
          286,
          478,
          4084,
          257,
          40863,
          51016
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2141.2200000000003,
        "id": 760,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2139.96,
        "temperature": 0,
        "text": " and dispose of it.",
        "tokens": [
          51016,
          293,
          42537,
          295,
          309,
          13,
          51079
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2143.92,
        "id": 761,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2141.2200000000003,
        "temperature": 0,
        "text": " So I can use tftidy to do that automatically,",
        "tokens": [
          51079,
          407,
          286,
          393,
          764,
          256,
          844,
          38836,
          281,
          360,
          300,
          6772,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2146.2000000000003,
        "id": 762,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2143.92,
        "temperature": 0,
        "text": " or I can just use the actual dispose function,",
        "tokens": [
          51214,
          420,
          286,
          393,
          445,
          764,
          264,
          3539,
          42537,
          2445,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2147.88,
        "id": 763,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2146.2000000000003,
        "temperature": 0,
        "text": " which I might be inclined to do at first.",
        "tokens": [
          51328,
          597,
          286,
          1062,
          312,
          28173,
          281,
          360,
          412,
          700,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2149.32,
        "id": 764,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2147.88,
        "temperature": 0,
        "text": " All right, so let's go through.",
        "tokens": [
          51412,
          1057,
          558,
          11,
          370,
          718,
          311,
          352,
          807,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2152.76,
        "id": 765,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2149.32,
        "temperature": 0,
        "text": " So here, these, I do not, I always want to keep them.",
        "tokens": [
          51484,
          407,
          510,
          11,
          613,
          11,
          286,
          360,
          406,
          11,
          286,
          1009,
          528,
          281,
          1066,
          552,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2018570416215537,
        "compression_ratio": 1.7624521072796935,
        "end": 2154.4,
        "id": 766,
        "no_speech_prob": 0.0000044254902604734525,
        "seek": 212692,
        "start": 2152.76,
        "temperature": 0,
        "text": " m and b are variables that I need to keep",
        "tokens": [
          51656,
          275,
          293,
          272,
          366,
          9102,
          300,
          286,
          643,
          281,
          1066,
          51738
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2157.14,
        "id": 767,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2154.4,
        "temperature": 0,
        "text": " throughout the course of this program.",
        "tokens": [
          50364,
          3710,
          264,
          1164,
          295,
          341,
          1461,
          13,
          50501
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2162.6600000000003,
        "id": 768,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2157.98,
        "temperature": 0,
        "text": " Loss, do I just put tidy in here?",
        "tokens": [
          50543,
          441,
          772,
          11,
          360,
          286,
          445,
          829,
          34646,
          294,
          510,
          30,
          50777
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2165.44,
        "id": 769,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2162.6600000000003,
        "temperature": 0,
        "text": " Or should I, let's predict.",
        "tokens": [
          50777,
          1610,
          820,
          286,
          11,
          718,
          311,
          6069,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2166.96,
        "id": 770,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2165.44,
        "temperature": 0,
        "text": " So do I put tidy in here?",
        "tokens": [
          50916,
          407,
          360,
          286,
          829,
          34646,
          294,
          510,
          30,
          50992
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2169.02,
        "id": 771,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2166.96,
        "temperature": 0,
        "text": " Do I wrap tidy here?",
        "tokens": [
          50992,
          1144,
          286,
          7019,
          34646,
          510,
          30,
          51095
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2171.32,
        "id": 772,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2169.02,
        "temperature": 0,
        "text": " What if I just put tidy here?",
        "tokens": [
          51095,
          708,
          498,
          286,
          445,
          829,
          34646,
          510,
          30,
          51210
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2174.6800000000003,
        "id": 773,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2171.32,
        "temperature": 0,
        "text": " Like, what if I say tf.tidy",
        "tokens": [
          51210,
          1743,
          11,
          437,
          498,
          286,
          584,
          256,
          69,
          13,
          83,
          38836,
          51378
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2180.2000000000003,
        "id": 774,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2178.84,
        "temperature": 0,
        "text": " and put all of this?",
        "tokens": [
          51586,
          293,
          829,
          439,
          295,
          341,
          30,
          51654
        ]
      },
      {
        "avg_logprob": -0.2571292453342014,
        "compression_ratio": 1.588235294117647,
        "end": 2182.06,
        "id": 775,
        "no_speech_prob": 0.000009223469533026218,
        "seek": 215440,
        "start": 2180.2000000000003,
        "temperature": 0,
        "text": " Will this do it?",
        "tokens": [
          51654,
          3099,
          341,
          360,
          309,
          30,
          51747
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2185.2599999999998,
        "id": 776,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2182.06,
        "temperature": 0,
        "text": " And then here, I also need to,",
        "tokens": [
          50364,
          400,
          550,
          510,
          11,
          286,
          611,
          643,
          281,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2189.02,
        "id": 777,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2186.44,
        "temperature": 0,
        "text": " well, here maybe what I'm gonna do is just dispose these.",
        "tokens": [
          50583,
          731,
          11,
          510,
          1310,
          437,
          286,
          478,
          799,
          360,
          307,
          445,
          42537,
          613,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2190.94,
        "id": 778,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2189.02,
        "temperature": 0,
        "text": " There's no logic to what I'm doing,",
        "tokens": [
          50712,
          821,
          311,
          572,
          9952,
          281,
          437,
          286,
          478,
          884,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2193.2999999999997,
        "id": 779,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2190.94,
        "temperature": 0,
        "text": " but I'm just gonna dispose these manually.",
        "tokens": [
          50808,
          457,
          286,
          478,
          445,
          799,
          42537,
          613,
          16945,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2198.2999999999997,
        "id": 780,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2193.2999999999997,
        "temperature": 0,
        "text": " Oh, and that's just the y's, right?",
        "tokens": [
          50926,
          876,
          11,
          293,
          300,
          311,
          445,
          264,
          288,
          311,
          11,
          558,
          30,
          51176
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2202.2599999999998,
        "id": 781,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2198.42,
        "temperature": 0,
        "text": " Line y is just, ys is the only thing that's a tensor here.",
        "tokens": [
          51182,
          14670,
          288,
          307,
          445,
          11,
          288,
          82,
          307,
          264,
          787,
          551,
          300,
          311,
          257,
          40863,
          510,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2204.86,
        "id": 782,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2202.2599999999998,
        "temperature": 0,
        "text": " So this should tidy everything,",
        "tokens": [
          51374,
          407,
          341,
          820,
          34646,
          1203,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2208.02,
        "id": 783,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2204.86,
        "temperature": 0,
        "text": " but hopefully not the variables that I need to keep,",
        "tokens": [
          51504,
          457,
          4696,
          406,
          264,
          9102,
          300,
          286,
          643,
          281,
          1066,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.19417423312946902,
        "compression_ratio": 1.7016806722689075,
        "end": 2211.38,
        "id": 784,
        "no_speech_prob": 0.0000012679280416705296,
        "seek": 218206,
        "start": 2208.02,
        "temperature": 0,
        "text": " rather than individually figuring out what to dispose of.",
        "tokens": [
          51662,
          2831,
          813,
          16652,
          15213,
          484,
          437,
          281,
          42537,
          295,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2215.7000000000003,
        "id": 785,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2211.38,
        "temperature": 0,
        "text": " And down here, I kind of know that this is my only tensor.",
        "tokens": [
          50364,
          400,
          760,
          510,
          11,
          286,
          733,
          295,
          458,
          300,
          341,
          307,
          452,
          787,
          40863,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2218.86,
        "id": 786,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2215.7000000000003,
        "temperature": 0,
        "text": " This, by the way, I should call this line x,",
        "tokens": [
          50580,
          639,
          11,
          538,
          264,
          636,
          11,
          286,
          820,
          818,
          341,
          1622,
          2031,
          11,
          50738
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2221.36,
        "id": 787,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2218.86,
        "temperature": 0,
        "text": " just to be consistent with my variable naming.",
        "tokens": [
          50738,
          445,
          281,
          312,
          8398,
          365,
          452,
          7006,
          25290,
          13,
          50863
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2229.02,
        "id": 788,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2224.6600000000003,
        "temperature": 0,
        "text": " You know, I'm only using the ys and xs variable name",
        "tokens": [
          51028,
          509,
          458,
          11,
          286,
          478,
          787,
          1228,
          264,
          288,
          82,
          293,
          2031,
          82,
          7006,
          1315,
          51246
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2230.98,
        "id": 789,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2229.02,
        "temperature": 0,
        "text": " when I have something that's actually a tensor,",
        "tokens": [
          51246,
          562,
          286,
          362,
          746,
          300,
          311,
          767,
          257,
          40863,
          11,
          51344
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2233.02,
        "id": 790,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2230.98,
        "temperature": 0,
        "text": " which helps me remember what I need to clean up and not.",
        "tokens": [
          51344,
          597,
          3665,
          385,
          1604,
          437,
          286,
          643,
          281,
          2541,
          493,
          293,
          406,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2234.98,
        "id": 791,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2233.02,
        "temperature": 0,
        "text": " Let's see if this goes.",
        "tokens": [
          51446,
          961,
          311,
          536,
          498,
          341,
          1709,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.22371217246367553,
        "compression_ratio": 1.536480686695279,
        "end": 2238.08,
        "id": 792,
        "no_speech_prob": 4.11636420949435e-7,
        "seek": 221138,
        "start": 2236.1800000000003,
        "temperature": 0,
        "text": " Okay, it's still running.",
        "tokens": [
          51604,
          1033,
          11,
          309,
          311,
          920,
          2614,
          13,
          51699
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2241.84,
        "id": 793,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2239.08,
        "temperature": 0,
        "text": " 221, oh no, okay.",
        "tokens": [
          50414,
          568,
          4436,
          11,
          1954,
          572,
          11,
          1392,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2245.3199999999997,
        "id": 794,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2241.84,
        "temperature": 0,
        "text": " So I'm better, there's fewer tensors,",
        "tokens": [
          50552,
          407,
          286,
          478,
          1101,
          11,
          456,
          311,
          13366,
          10688,
          830,
          11,
          50726
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2247.08,
        "id": 795,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2245.3199999999997,
        "temperature": 0,
        "text": " but I haven't cleaned up everything.",
        "tokens": [
          50726,
          457,
          286,
          2378,
          380,
          16146,
          493,
          1203,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2248.44,
        "id": 796,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2247.08,
        "temperature": 0,
        "text": " So what could I be missing?",
        "tokens": [
          50814,
          407,
          437,
          727,
          286,
          312,
          5361,
          30,
          50882
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2262.42,
        "id": 797,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2257.42,
        "temperature": 0,
        "text": " Maybe the call to predict, wouldn't tidy clean that up?",
        "tokens": [
          51331,
          2704,
          264,
          818,
          281,
          6069,
          11,
          2759,
          380,
          34646,
          2541,
          300,
          493,
          30,
          51581
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2264.44,
        "id": 798,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2263.04,
        "temperature": 0,
        "text": " All right, I need to debug this somehow.",
        "tokens": [
          51612,
          1057,
          558,
          11,
          286,
          643,
          281,
          24083,
          341,
          6063,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.23410374285226845,
        "compression_ratio": 1.4031413612565444,
        "end": 2267.08,
        "id": 799,
        "no_speech_prob": 0.00000853031815495342,
        "seek": 223808,
        "start": 2264.44,
        "temperature": 0,
        "text": " One thing I could do is start commenting stuff out",
        "tokens": [
          51682,
          1485,
          551,
          286,
          727,
          360,
          307,
          722,
          29590,
          1507,
          484,
          51814
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2269.2799999999997,
        "id": 800,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2267.08,
        "temperature": 0,
        "text": " to see like where is the memory leak?",
        "tokens": [
          50364,
          281,
          536,
          411,
          689,
          307,
          264,
          4675,
          17143,
          30,
          50474
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2272.36,
        "id": 801,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2269.2799999999997,
        "temperature": 0,
        "text": " So one worry I have, I really think loss and predict,",
        "tokens": [
          50474,
          407,
          472,
          3292,
          286,
          362,
          11,
          286,
          534,
          519,
          4470,
          293,
          6069,
          11,
          50628
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2274.92,
        "id": 802,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2272.36,
        "temperature": 0,
        "text": " those functions generate a lot of tensors.",
        "tokens": [
          50628,
          729,
          6828,
          8460,
          257,
          688,
          295,
          10688,
          830,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2277.7,
        "id": 803,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2274.92,
        "temperature": 0,
        "text": " I believe tftidy should clean up anything,",
        "tokens": [
          50756,
          286,
          1697,
          256,
          844,
          38836,
          820,
          2541,
          493,
          1340,
          11,
          50895
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2282.46,
        "id": 804,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2277.7,
        "temperature": 0,
        "text": " but let's just, for the sake of argument, comment this out.",
        "tokens": [
          50895,
          457,
          718,
          311,
          445,
          11,
          337,
          264,
          9717,
          295,
          6770,
          11,
          2871,
          341,
          484,
          13,
          51133
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2288.58,
        "id": 805,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2284.74,
        "temperature": 0,
        "text": " And now, of course, the learning is no longer happening.",
        "tokens": [
          51247,
          400,
          586,
          11,
          295,
          1164,
          11,
          264,
          2539,
          307,
          572,
          2854,
          2737,
          13,
          51439
        ]
      },
      {
        "avg_logprob": -0.23393769515188118,
        "compression_ratio": 1.518018018018018,
        "end": 2291.04,
        "id": 806,
        "no_speech_prob": 0.0000025215731511707418,
        "seek": 226708,
        "start": 2288.58,
        "temperature": 0,
        "text": " And what I might as well do is console log",
        "tokens": [
          51439,
          400,
          437,
          286,
          1062,
          382,
          731,
          360,
          307,
          11076,
          3565,
          51562
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2297.04,
        "id": 807,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2292.04,
        "temperature": 0,
        "text": " the amount of tensors, not have to like ask for it.",
        "tokens": [
          50414,
          264,
          2372,
          295,
          10688,
          830,
          11,
          406,
          362,
          281,
          411,
          1029,
          337,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2302.04,
        "id": 808,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2298.88,
        "temperature": 0,
        "text": " Whoops, what did I do wrong?",
        "tokens": [
          50756,
          45263,
          11,
          437,
          630,
          286,
          360,
          2085,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2304.8,
        "id": 809,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2302.04,
        "temperature": 0,
        "text": " TF memory num tensors, what is it?",
        "tokens": [
          50914,
          40964,
          4675,
          1031,
          10688,
          830,
          11,
          437,
          307,
          309,
          30,
          51052
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2306.72,
        "id": 810,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2304.8,
        "temperature": 0,
        "text": " How come I can't remember what it is?",
        "tokens": [
          51052,
          1012,
          808,
          286,
          393,
          380,
          1604,
          437,
          309,
          307,
          30,
          51148
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2308.12,
        "id": 811,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2306.72,
        "temperature": 0,
        "text": " Num tensors, no.",
        "tokens": [
          51148,
          22592,
          10688,
          830,
          11,
          572,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2312.44,
        "id": 812,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2310,
        "temperature": 0,
        "text": " Yes, it's not a function, it's just num tensors.",
        "tokens": [
          51312,
          1079,
          11,
          309,
          311,
          406,
          257,
          2445,
          11,
          309,
          311,
          445,
          1031,
          10688,
          830,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2313.74,
        "id": 813,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2312.44,
        "temperature": 0,
        "text": " Sorry, everybody, okay.",
        "tokens": [
          51434,
          4919,
          11,
          2201,
          11,
          1392,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2316.56,
        "id": 814,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2314.6,
        "temperature": 0,
        "text": " So, and I need another parentheses here.",
        "tokens": [
          51542,
          407,
          11,
          293,
          286,
          643,
          1071,
          34153,
          510,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2318.52,
        "id": 815,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2316.56,
        "temperature": 0,
        "text": " Ah, little digression there, all right.",
        "tokens": [
          51640,
          2438,
          11,
          707,
          2528,
          2775,
          456,
          11,
          439,
          558,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.2601776753575349,
        "compression_ratio": 1.5851528384279476,
        "end": 2320.88,
        "id": 816,
        "no_speech_prob": 0.00004611273107002489,
        "seek": 229104,
        "start": 2319.48,
        "temperature": 0,
        "text": " All right, so we can see it's growing.",
        "tokens": [
          51786,
          1057,
          558,
          11,
          370,
          321,
          393,
          536,
          309,
          311,
          4194,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2322.6400000000003,
        "id": 817,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2321.6800000000003,
        "temperature": 0,
        "text": " So let's keep commenting stuff out",
        "tokens": [
          50404,
          407,
          718,
          311,
          1066,
          29590,
          1507,
          484,
          50452
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2324.84,
        "id": 818,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2322.6400000000003,
        "temperature": 0,
        "text": " to see like what's causing the memory leak.",
        "tokens": [
          50452,
          281,
          536,
          411,
          437,
          311,
          9853,
          264,
          4675,
          17143,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2329.44,
        "id": 819,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2326.12,
        "temperature": 0,
        "text": " Let's comment out this whole area down here.",
        "tokens": [
          50626,
          961,
          311,
          2871,
          484,
          341,
          1379,
          1859,
          760,
          510,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2333.2400000000002,
        "id": 820,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2330.6800000000003,
        "temperature": 0,
        "text": " Ah, good news, everybody.",
        "tokens": [
          50854,
          2438,
          11,
          665,
          2583,
          11,
          2201,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2335.6800000000003,
        "id": 821,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2333.2400000000002,
        "temperature": 0,
        "text": " The memory leak is in that part.",
        "tokens": [
          50982,
          440,
          4675,
          17143,
          307,
          294,
          300,
          644,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2338.46,
        "id": 822,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2335.6800000000003,
        "temperature": 0,
        "text": " Let's put this back just to be sure.",
        "tokens": [
          51104,
          961,
          311,
          829,
          341,
          646,
          445,
          281,
          312,
          988,
          13,
          51243
        ]
      },
      {
        "avg_logprob": -0.2668749726848838,
        "compression_ratio": 1.6058823529411765,
        "end": 2348,
        "id": 823,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 232088,
        "start": 2344.08,
        "temperature": 0,
        "text": " Okay, ah, so the memory leak is definitely down here.",
        "tokens": [
          51524,
          1033,
          11,
          3716,
          11,
          370,
          264,
          4675,
          17143,
          307,
          2138,
          760,
          510,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2351.48,
        "id": 824,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2348,
        "temperature": 0,
        "text": " And I'm probably creating, oh my goodness.",
        "tokens": [
          50364,
          400,
          286,
          478,
          1391,
          4084,
          11,
          1954,
          452,
          8387,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2355.6,
        "id": 825,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2354.36,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          50682,
          876,
          452,
          8387,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2360.16,
        "id": 826,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2359.12,
        "temperature": 0,
        "text": " No, I'm not sure.",
        "tokens": [
          50920,
          883,
          11,
          286,
          478,
          406,
          988,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2361.84,
        "id": 827,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2360.16,
        "temperature": 0,
        "text": " Well, let's put this back in.",
        "tokens": [
          50972,
          1042,
          11,
          718,
          311,
          829,
          341,
          646,
          294,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2364.36,
        "id": 828,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2361.84,
        "temperature": 0,
        "text": " I thought I saw it, but then I didn't again.",
        "tokens": [
          51056,
          286,
          1194,
          286,
          1866,
          309,
          11,
          457,
          550,
          286,
          994,
          380,
          797,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2367.72,
        "id": 829,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2364.36,
        "temperature": 0,
        "text": " So this is a tensor and I'm disposing it.",
        "tokens": [
          51182,
          407,
          341,
          307,
          257,
          40863,
          293,
          286,
          478,
          4920,
          6110,
          309,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2373.68,
        "id": 830,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2370.4,
        "temperature": 0,
        "text": " Oh, predict, aha.",
        "tokens": [
          51484,
          876,
          11,
          6069,
          11,
          47340,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2185643733232871,
        "compression_ratio": 1.4540229885057472,
        "end": 2376.56,
        "id": 831,
        "no_speech_prob": 0.0000132119585032342,
        "seek": 234800,
        "start": 2373.68,
        "temperature": 0,
        "text": " The predict function makes other tensors.",
        "tokens": [
          51648,
          440,
          6069,
          2445,
          1669,
          661,
          10688,
          830,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2379.54,
        "id": 832,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2376.56,
        "temperature": 0,
        "text": " And predict got cleaned up because it was in tidy,",
        "tokens": [
          50364,
          400,
          6069,
          658,
          16146,
          493,
          570,
          309,
          390,
          294,
          34646,
          11,
          50513
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2383.2599999999998,
        "id": 833,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2379.54,
        "temperature": 0,
        "text": " but I'm just manually disposing the y's down there.",
        "tokens": [
          50513,
          457,
          286,
          478,
          445,
          16945,
          4920,
          6110,
          264,
          288,
          311,
          760,
          456,
          13,
          50699
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2384.4,
        "id": 834,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2383.2599999999998,
        "temperature": 0,
        "text": " That's what it is.",
        "tokens": [
          50699,
          663,
          311,
          437,
          309,
          307,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2386.2,
        "id": 835,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2384.4,
        "temperature": 0,
        "text": " So let me use tidy.",
        "tokens": [
          50756,
          407,
          718,
          385,
          764,
          34646,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2391.4,
        "id": 836,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2389,
        "temperature": 0,
        "text": " I guess, ah.",
        "tokens": [
          50986,
          286,
          2041,
          11,
          3716,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2393.64,
        "id": 837,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2392.44,
        "temperature": 0,
        "text": " So let me do this.",
        "tokens": [
          51158,
          407,
          718,
          385,
          360,
          341,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2395.2799999999997,
        "id": 838,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2393.64,
        "temperature": 0,
        "text": " Let me put this up here.",
        "tokens": [
          51218,
          961,
          385,
          829,
          341,
          493,
          510,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2399.48,
        "id": 839,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2395.2799999999997,
        "temperature": 0,
        "text": " So this is really what I need to tidy.",
        "tokens": [
          51300,
          407,
          341,
          307,
          534,
          437,
          286,
          643,
          281,
          34646,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.24302044543591175,
        "compression_ratio": 1.5664739884393064,
        "end": 2404.36,
        "id": 840,
        "no_speech_prob": 0.0000167014204635052,
        "seek": 237656,
        "start": 2401.84,
        "temperature": 0,
        "text": " So instead of disposing manually,",
        "tokens": [
          51628,
          407,
          2602,
          295,
          4920,
          6110,
          16945,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2407.8,
        "id": 841,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2405.36,
        "temperature": 0,
        "text": " I kind of like disposing things manually.",
        "tokens": [
          50414,
          286,
          733,
          295,
          411,
          4920,
          6110,
          721,
          16945,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2409.96,
        "id": 842,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2407.8,
        "temperature": 0,
        "text": " The tidy thing kind of freaks me out.",
        "tokens": [
          50536,
          440,
          34646,
          551,
          733,
          295,
          2130,
          5461,
          385,
          484,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2413.36,
        "id": 843,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2409.96,
        "temperature": 0,
        "text": " But the problem with this is I have a scope issue,",
        "tokens": [
          50644,
          583,
          264,
          1154,
          365,
          341,
          307,
          286,
          362,
          257,
          11923,
          2734,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2417.34,
        "id": 844,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2413.36,
        "temperature": 0,
        "text": " which is that line y, right?",
        "tokens": [
          50814,
          597,
          307,
          300,
          1622,
          288,
          11,
          558,
          30,
          51013
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2419.42,
        "id": 845,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2417.34,
        "temperature": 0,
        "text": " No matter what I do, if I take this out here,",
        "tokens": [
          51013,
          883,
          1871,
          437,
          286,
          360,
          11,
          498,
          286,
          747,
          341,
          484,
          510,
          11,
          51117
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2421.36,
        "id": 846,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2419.42,
        "temperature": 0,
        "text": " like this is gonna tidy everything.",
        "tokens": [
          51117,
          411,
          341,
          307,
          799,
          34646,
          1203,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2423.88,
        "id": 847,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2421.36,
        "temperature": 0,
        "text": " So I guess it's not the biggest deal,",
        "tokens": [
          51214,
          407,
          286,
          2041,
          309,
          311,
          406,
          264,
          3880,
          2028,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2424.96,
        "id": 848,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2423.88,
        "temperature": 0,
        "text": " at the moment at least,",
        "tokens": [
          51340,
          412,
          264,
          1623,
          412,
          1935,
          11,
          51394
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2429.6400000000003,
        "id": 849,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2424.96,
        "temperature": 0,
        "text": " for me to just put everything inside the tidy.",
        "tokens": [
          51394,
          337,
          385,
          281,
          445,
          829,
          1203,
          1854,
          264,
          34646,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.23860765980408255,
        "compression_ratio": 1.5897435897435896,
        "end": 2432.1600000000003,
        "id": 850,
        "no_speech_prob": 0.000005014734142605448,
        "seek": 240436,
        "start": 2429.6400000000003,
        "temperature": 0,
        "text": " Well, that's because,",
        "tokens": [
          51628,
          1042,
          11,
          300,
          311,
          570,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2435.3999999999996,
        "id": 851,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2432.16,
        "temperature": 0,
        "text": " let's put everything inside the tidy for right now.",
        "tokens": [
          50364,
          718,
          311,
          829,
          1203,
          1854,
          264,
          34646,
          337,
          558,
          586,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2437.72,
        "id": 852,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2435.3999999999996,
        "temperature": 0,
        "text": " There's probably a way I could simplify that,",
        "tokens": [
          50526,
          821,
          311,
          1391,
          257,
          636,
          286,
          727,
          20460,
          300,
          11,
          50642
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2438.6,
        "id": 853,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2437.72,
        "temperature": 0,
        "text": " but this should work.",
        "tokens": [
          50642,
          457,
          341,
          820,
          589,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2439.72,
        "id": 854,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2438.6,
        "temperature": 0,
        "text": " Let's give this a try.",
        "tokens": [
          50686,
          961,
          311,
          976,
          341,
          257,
          853,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2444.08,
        "id": 855,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2443.24,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50918,
          821,
          321,
          352,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2447.6,
        "id": 856,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2444.08,
        "temperature": 0,
        "text": " There's only ever five tensors all the time.",
        "tokens": [
          50960,
          821,
          311,
          787,
          1562,
          1732,
          10688,
          830,
          439,
          264,
          565,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2450.52,
        "id": 857,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2447.6,
        "temperature": 0,
        "text": " So there's no more memory leak, five tensors,",
        "tokens": [
          51136,
          407,
          456,
          311,
          572,
          544,
          4675,
          17143,
          11,
          1732,
          10688,
          830,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2452.92,
        "id": 858,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2450.52,
        "temperature": 0,
        "text": " linear regression with gradient descent,",
        "tokens": [
          51282,
          8213,
          24590,
          365,
          16235,
          23475,
          11,
          51402
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2455.44,
        "id": 859,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2452.92,
        "temperature": 0,
        "text": " TensorFlow.js, interactive, here it is.",
        "tokens": [
          51402,
          37624,
          13,
          25530,
          11,
          15141,
          11,
          510,
          309,
          307,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2457.3999999999996,
        "id": 860,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2455.44,
        "temperature": 0,
        "text": " So what's left here?",
        "tokens": [
          51528,
          407,
          437,
          311,
          1411,
          510,
          30,
          51626
        ]
      },
      {
        "avg_logprob": -0.1614675028570767,
        "compression_ratio": 1.6213991769547325,
        "end": 2460.7599999999998,
        "id": 861,
        "no_speech_prob": 0.0000024824794309097342,
        "seek": 243216,
        "start": 2457.3999999999996,
        "temperature": 0,
        "text": " So number one, things that could be improved.",
        "tokens": [
          51626,
          407,
          1230,
          472,
          11,
          721,
          300,
          727,
          312,
          9689,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2462.1600000000003,
        "id": 862,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2460.76,
        "temperature": 0,
        "text": " So I wanted to talk through some things",
        "tokens": [
          50364,
          407,
          286,
          1415,
          281,
          751,
          807,
          512,
          721,
          50434
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2463,
        "id": 863,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2462.1600000000003,
        "temperature": 0,
        "text": " that could be improved,",
        "tokens": [
          50434,
          300,
          727,
          312,
          9689,
          11,
          50476
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2465.1200000000003,
        "id": 864,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2463,
        "temperature": 0,
        "text": " but already, meiamsamy in the chat",
        "tokens": [
          50476,
          457,
          1217,
          11,
          385,
          2918,
          82,
          7804,
          294,
          264,
          5081,
          50582
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2466.0400000000004,
        "id": 865,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2465.1200000000003,
        "temperature": 0,
        "text": " made a very good suggestion.",
        "tokens": [
          50582,
          1027,
          257,
          588,
          665,
          16541,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2468.44,
        "id": 866,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2466.0400000000004,
        "temperature": 0,
        "text": " This is very awkward how I put everything in tidy.",
        "tokens": [
          50628,
          639,
          307,
          588,
          11411,
          577,
          286,
          829,
          1203,
          294,
          34646,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2469.76,
        "id": 867,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2468.44,
        "temperature": 0,
        "text": " So unnecessary.",
        "tokens": [
          50748,
          407,
          19350,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2472.5200000000004,
        "id": 868,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2471.0400000000004,
        "temperature": 0,
        "text": " Let me take that out.",
        "tokens": [
          50878,
          961,
          385,
          747,
          300,
          484,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2474.9,
        "id": 869,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2472.5200000000004,
        "temperature": 0,
        "text": " Because predict returns something,",
        "tokens": [
          50952,
          1436,
          6069,
          11247,
          746,
          11,
          51071
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2478.4,
        "id": 870,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2476.1200000000003,
        "temperature": 0,
        "text": " I can actually just put the tidy right here.",
        "tokens": [
          51132,
          286,
          393,
          767,
          445,
          829,
          264,
          34646,
          558,
          510,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2480.28,
        "id": 871,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2478.4,
        "temperature": 0,
        "text": " I don't know why I didn't think of that.",
        "tokens": [
          51246,
          286,
          500,
          380,
          458,
          983,
          286,
          994,
          380,
          519,
          295,
          300,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2481.4,
        "id": 872,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2480.28,
        "temperature": 0,
        "text": " Like I can actually just,",
        "tokens": [
          51340,
          1743,
          286,
          393,
          767,
          445,
          11,
          51396
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2484.5600000000004,
        "id": 873,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2481.4,
        "temperature": 0,
        "text": " it's only this predict function that,",
        "tokens": [
          51396,
          309,
          311,
          787,
          341,
          6069,
          2445,
          300,
          11,
          51554
        ]
      },
      {
        "avg_logprob": -0.27077779173851013,
        "compression_ratio": 1.7209302325581395,
        "end": 2486.6800000000003,
        "id": 874,
        "no_speech_prob": 0.0000010845166116268956,
        "seek": 246076,
        "start": 2484.5600000000004,
        "temperature": 0,
        "text": " so I can actually put the tidy right here,",
        "tokens": [
          51554,
          370,
          286,
          393,
          767,
          829,
          264,
          34646,
          558,
          510,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2492.52,
        "id": 875,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2487.52,
        "temperature": 0,
        "text": " and I can use my fancy ES6 arrow syntax,",
        "tokens": [
          50406,
          293,
          286,
          393,
          764,
          452,
          10247,
          12564,
          21,
          11610,
          28431,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2496.08,
        "id": 876,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2493.8399999999997,
        "temperature": 0,
        "text": " and the return is now assumed,",
        "tokens": [
          50722,
          293,
          264,
          2736,
          307,
          586,
          15895,
          11,
          50834
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2499.52,
        "id": 877,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2496.08,
        "temperature": 0,
        "text": " and then I can just say ys.dispose.",
        "tokens": [
          50834,
          293,
          550,
          286,
          393,
          445,
          584,
          288,
          82,
          13,
          67,
          7631,
          541,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2500.68,
        "id": 878,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2499.52,
        "temperature": 0,
        "text": " So this should work.",
        "tokens": [
          51006,
          407,
          341,
          820,
          589,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2505.08,
        "id": 879,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2500.68,
        "temperature": 0,
        "text": " Tidy's not going to tidy up this y value,",
        "tokens": [
          51064,
          314,
          38836,
          311,
          406,
          516,
          281,
          34646,
          493,
          341,
          288,
          2158,
          11,
          51284
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2508.52,
        "id": 880,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2505.08,
        "temperature": 0,
        "text": " but I can dispose that manually once I have the values.",
        "tokens": [
          51284,
          457,
          286,
          393,
          42537,
          300,
          16945,
          1564,
          286,
          362,
          264,
          4190,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2510,
        "id": 881,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2508.52,
        "temperature": 0,
        "text": " So I think this will do the trick.",
        "tokens": [
          51456,
          407,
          286,
          519,
          341,
          486,
          360,
          264,
          4282,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2511.9199999999996,
        "id": 882,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2510,
        "temperature": 0,
        "text": " Let me just take a look at this.",
        "tokens": [
          51530,
          961,
          385,
          445,
          747,
          257,
          574,
          412,
          341,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2512.7599999999998,
        "id": 883,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2511.9199999999996,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51626,
          865,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.20592479352597837,
        "compression_ratio": 1.5679611650485437,
        "end": 2514.2799999999997,
        "id": 884,
        "no_speech_prob": 6.083589596528327e-7,
        "seek": 248668,
        "start": 2512.7599999999998,
        "temperature": 0,
        "text": " So this I like better,",
        "tokens": [
          51668,
          407,
          341,
          286,
          411,
          1101,
          11,
          51744
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2516.7200000000003,
        "id": 885,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2514.28,
        "temperature": 0,
        "text": " and there's probably other styles or ways you could do it.",
        "tokens": [
          50364,
          293,
          456,
          311,
          1391,
          661,
          13273,
          420,
          2098,
          291,
          727,
          360,
          309,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2518.36,
        "id": 886,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2516.7200000000003,
        "temperature": 0,
        "text": " The point is you've got to keep track",
        "tokens": [
          50486,
          440,
          935,
          307,
          291,
          600,
          658,
          281,
          1066,
          2837,
          50568
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2521.44,
        "id": 887,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2518.36,
        "temperature": 0,
        "text": " of all the tensors you're making and dispose them.",
        "tokens": [
          50568,
          295,
          439,
          264,
          10688,
          830,
          291,
          434,
          1455,
          293,
          42537,
          552,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2523.76,
        "id": 888,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2521.44,
        "temperature": 0,
        "text": " Okay, so I think I'm going to wrap this video up.",
        "tokens": [
          50722,
          1033,
          11,
          370,
          286,
          519,
          286,
          478,
          516,
          281,
          7019,
          341,
          960,
          493,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2527.1600000000003,
        "id": 889,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2523.76,
        "temperature": 0,
        "text": " I'm getting all these great suggestions from the chat.",
        "tokens": [
          50838,
          286,
          478,
          1242,
          439,
          613,
          869,
          13396,
          490,
          264,
          5081,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2530.26,
        "id": 890,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2527.1600000000003,
        "temperature": 0,
        "text": " I could have tidied the tensors here in predict.",
        "tokens": [
          51008,
          286,
          727,
          362,
          9422,
          1091,
          264,
          10688,
          830,
          510,
          294,
          6069,
          13,
          51163
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2534.2000000000003,
        "id": 891,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2530.94,
        "temperature": 0,
        "text": " So number one is this code is going to get posted",
        "tokens": [
          51197,
          407,
          1230,
          472,
          307,
          341,
          3089,
          307,
          516,
          281,
          483,
          9437,
          51360
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2536.4,
        "id": 892,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2534.2000000000003,
        "temperature": 0,
        "text": " to the Coding Train website in Coding Challenges.",
        "tokens": [
          51360,
          281,
          264,
          383,
          8616,
          28029,
          3144,
          294,
          383,
          8616,
          14398,
          47077,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2537.5800000000004,
        "id": 893,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2536.4,
        "temperature": 0,
        "text": " Make your improvements",
        "tokens": [
          51470,
          4387,
          428,
          13797,
          51529
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2539.6000000000004,
        "id": 894,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2537.5800000000004,
        "temperature": 0,
        "text": " and add them as community contributions.",
        "tokens": [
          51529,
          293,
          909,
          552,
          382,
          1768,
          15725,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2541.5,
        "id": 895,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2539.6000000000004,
        "temperature": 0,
        "text": " Some things that I would love to see.",
        "tokens": [
          51630,
          2188,
          721,
          300,
          286,
          576,
          959,
          281,
          536,
          13,
          51725
        ]
      },
      {
        "avg_logprob": -0.22871824511054423,
        "compression_ratio": 1.6697819314641744,
        "end": 2543.98,
        "id": 896,
        "no_speech_prob": 0.000008530316335964017,
        "seek": 251428,
        "start": 2541.5,
        "temperature": 0,
        "text": " Visualize, graph the loss value.",
        "tokens": [
          51725,
          23187,
          1125,
          11,
          4295,
          264,
          4470,
          2158,
          13,
          51849
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2545.46,
        "id": 897,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2543.98,
        "temperature": 0,
        "text": " I think there's a way to get the loss.",
        "tokens": [
          50364,
          286,
          519,
          456,
          311,
          257,
          636,
          281,
          483,
          264,
          4470,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2547.02,
        "id": 898,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2545.46,
        "temperature": 0,
        "text": " I'm sure there's a way to get the loss value",
        "tokens": [
          50438,
          286,
          478,
          988,
          456,
          311,
          257,
          636,
          281,
          483,
          264,
          4470,
          2158,
          50516
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2548.06,
        "id": 899,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2547.02,
        "temperature": 0,
        "text": " out of that function.",
        "tokens": [
          50516,
          484,
          295,
          300,
          2445,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2550.02,
        "id": 900,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2548.06,
        "temperature": 0,
        "text": " That's one idea.",
        "tokens": [
          50568,
          663,
          311,
          472,
          1558,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2552.32,
        "id": 901,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2550.02,
        "temperature": 0,
        "text": " Kay Wieckmann suggested maybe trying",
        "tokens": [
          50666,
          14179,
          9233,
          547,
          14912,
          10945,
          1310,
          1382,
          50781
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2553.9,
        "id": 902,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2552.32,
        "temperature": 0,
        "text": " some of the other optimizers.",
        "tokens": [
          50781,
          512,
          295,
          264,
          661,
          5028,
          22525,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2557.7400000000002,
        "id": 903,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2553.9,
        "temperature": 0,
        "text": " So what happens if I go to the tensorflow.js documentation",
        "tokens": [
          50860,
          407,
          437,
          2314,
          498,
          286,
          352,
          281,
          264,
          40863,
          10565,
          13,
          25530,
          14333,
          51052
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2560.06,
        "id": 904,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2557.7400000000002,
        "temperature": 0,
        "text": " and just use some of these other optimizers?",
        "tokens": [
          51052,
          293,
          445,
          764,
          512,
          295,
          613,
          661,
          5028,
          22525,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2560.9,
        "id": 905,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2560.06,
        "temperature": 0,
        "text": " What are they?",
        "tokens": [
          51168,
          708,
          366,
          436,
          30,
          51210
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2561.72,
        "id": 906,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2560.9,
        "temperature": 0,
        "text": " What will they do?",
        "tokens": [
          51210,
          708,
          486,
          436,
          360,
          30,
          51251
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2563.34,
        "id": 907,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2561.72,
        "temperature": 0,
        "text": " Do you get better or worse results?",
        "tokens": [
          51251,
          1144,
          291,
          483,
          1101,
          420,
          5324,
          3542,
          30,
          51332
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2566.22,
        "id": 908,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2563.34,
        "temperature": 0,
        "text": " Can you make the learning rate somehow interactive?",
        "tokens": [
          51332,
          1664,
          291,
          652,
          264,
          2539,
          3314,
          6063,
          15141,
          30,
          51476
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2567.66,
        "id": 909,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2566.22,
        "temperature": 0,
        "text": " Adjust the learning rate?",
        "tokens": [
          51476,
          34049,
          264,
          2539,
          3314,
          30,
          51548
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2568.56,
        "id": 910,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2567.66,
        "temperature": 0,
        "text": " I don't know if you could come up",
        "tokens": [
          51548,
          286,
          500,
          380,
          458,
          498,
          291,
          727,
          808,
          493,
          51593
        ]
      },
      {
        "avg_logprob": -0.2580657907434412,
        "compression_ratio": 1.7655172413793103,
        "end": 2572.98,
        "id": 911,
        "no_speech_prob": 0.000003288747393526137,
        "seek": 254398,
        "start": 2568.56,
        "temperature": 0,
        "text": " with any really clever visual ideas.",
        "tokens": [
          51593,
          365,
          604,
          534,
          13494,
          5056,
          3487,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2576.3,
        "id": 912,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2574.54,
        "temperature": 0,
        "text": " With this.",
        "tokens": [
          50392,
          2022,
          341,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2579.52,
        "id": 913,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2576.3,
        "temperature": 0,
        "text": " But anyway, so but I think I'm good.",
        "tokens": [
          50480,
          583,
          4033,
          11,
          370,
          457,
          286,
          519,
          286,
          478,
          665,
          13,
          50641
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2581.34,
        "id": 914,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2579.52,
        "temperature": 0,
        "text": " I think I have the basic idea.",
        "tokens": [
          50641,
          286,
          519,
          286,
          362,
          264,
          3875,
          1558,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2584.5,
        "id": 915,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2581.34,
        "temperature": 0,
        "text": " So if you really want to dive as deeply as you can",
        "tokens": [
          50732,
          407,
          498,
          291,
          534,
          528,
          281,
          9192,
          382,
          8760,
          382,
          291,
          393,
          50890
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2586.66,
        "id": 916,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2584.5,
        "temperature": 0,
        "text": " into linear regression with gradient descent,",
        "tokens": [
          50890,
          666,
          8213,
          24590,
          365,
          16235,
          23475,
          11,
          50998
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2588.7400000000002,
        "id": 917,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2586.66,
        "temperature": 0,
        "text": " you can go back and watch my other videos",
        "tokens": [
          50998,
          291,
          393,
          352,
          646,
          293,
          1159,
          452,
          661,
          2145,
          51102
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2591.66,
        "id": 918,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2588.7400000000002,
        "temperature": 0,
        "text": " where I did this with just JavaScript and p5.js.",
        "tokens": [
          51102,
          689,
          286,
          630,
          341,
          365,
          445,
          15778,
          293,
          280,
          20,
          13,
          25530,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2594.42,
        "id": 919,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2591.66,
        "temperature": 0,
        "text": " Now you've seen it with JavaScript, p5.js,",
        "tokens": [
          51248,
          823,
          291,
          600,
          1612,
          309,
          365,
          15778,
          11,
          280,
          20,
          13,
          25530,
          11,
          51386
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2595.66,
        "id": 920,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2594.42,
        "temperature": 0,
        "text": " and tensorflow.js.",
        "tokens": [
          51386,
          293,
          40863,
          10565,
          13,
          25530,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2597.14,
        "id": 921,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2595.66,
        "temperature": 0,
        "text": " So I look forward to your feedback",
        "tokens": [
          51448,
          407,
          286,
          574,
          2128,
          281,
          428,
          5824,
          51522
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2598.54,
        "id": 922,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2597.14,
        "temperature": 0,
        "text": " and hearing more about it.",
        "tokens": [
          51522,
          293,
          4763,
          544,
          466,
          309,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2600.7,
        "id": 923,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2598.54,
        "temperature": 0,
        "text": " More tensorflow.js videos to come.",
        "tokens": [
          51592,
          5048,
          40863,
          10565,
          13,
          25530,
          2145,
          281,
          808,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.23717071960022398,
        "compression_ratio": 1.6607142857142858,
        "end": 2602.34,
        "id": 924,
        "no_speech_prob": 0.00009915238479152322,
        "seek": 257398,
        "start": 2600.7,
        "temperature": 0,
        "text": " You know, I want to get to some actual,",
        "tokens": [
          51700,
          509,
          458,
          11,
          286,
          528,
          281,
          483,
          281,
          512,
          3539,
          11,
          51782
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2604.02,
        "id": 925,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2602.38,
        "temperature": 0.2,
        "text": " more practical things that you might want to do",
        "tokens": [
          50366,
          544,
          8496,
          721,
          300,
          291,
          1062,
          528,
          281,
          360,
          50448
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2606.1200000000003,
        "id": 926,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2604.02,
        "temperature": 0.2,
        "text": " for interactive creative arts projects.",
        "tokens": [
          50448,
          337,
          15141,
          5880,
          8609,
          4455,
          13,
          50553
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2607.54,
        "id": 927,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2606.1200000000003,
        "temperature": 0.2,
        "text": " But I'm still in the weeds here",
        "tokens": [
          50553,
          583,
          286,
          478,
          920,
          294,
          264,
          26370,
          510,
          50624
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2609.34,
        "id": 928,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2607.54,
        "temperature": 0.2,
        "text": " of just trying to understand the nuts and bolts",
        "tokens": [
          50624,
          295,
          445,
          1382,
          281,
          1223,
          264,
          10483,
          293,
          18127,
          50714
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2610.42,
        "id": 929,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2609.34,
        "temperature": 0.2,
        "text": " of how the library works.",
        "tokens": [
          50714,
          295,
          577,
          264,
          6405,
          1985,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2611.3,
        "id": 930,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2610.42,
        "temperature": 0.2,
        "text": " So I hope you're enjoying that",
        "tokens": [
          50768,
          407,
          286,
          1454,
          291,
          434,
          9929,
          300,
          50812
        ]
      },
      {
        "avg_logprob": -0.3090815544128418,
        "compression_ratio": 1.4945652173913044,
        "end": 2614.06,
        "id": 931,
        "no_speech_prob": 0.011157015338540077,
        "seek": 260234,
        "start": 2611.3,
        "temperature": 0.2,
        "text": " and I look forward to seeing you in future videos.",
        "tokens": [
          50812,
          293,
          286,
          574,
          2128,
          281,
          2577,
          291,
          294,
          2027,
          2145,
          13,
          50950
        ]
      }
    ],
    "transcription": " Hello, you are here watching another coding challenge and this coding challenge, maybe this should just fit and be in one of my tutorial videos, but I'm gonna make it a coding challenge because I'm gonna attempt to do it in one video. And what I'm doing is recreating something that I've done before in some of my machine learning tutorials. And it was suggested here, I don't know if it was suggested exactly, but a Twitter user, Calstube Old Podcar, apologies if I'm pronouncing the name incorrectly, created this interactive simulation of linear regression using TensorFlow.js. And so this is very similar to something that I've done previously, right? I have this video, linear regression with gradient descent, where I just did this with plain JavaScript. And then you could also look at this other video, which I go through the mathematics of gradient descent a little bit. But here's the thing, going through the mathematics, making this video where I implement the mathematics in JavaScript while useful, and perhaps background for this video, one of the exciting things about doing this with TensorFlow.js is TensorFlow.js has a nice API for optimizing loss functions with the gradient descent algorithm built into it. So I could just do things. So let's make a, I gotta come back here, but let's make a list. All right, so first of all, what is linear regression anyway? So let's say we have a space, and I drew this as like a canvas, but really I should be talking just about a generic kind of two-dimensional Cartesian plane. In that plane, there are a bunch of points. The idea of linear regression is to figure out, can we fit, oh, this is a time for another colored marker. Can we fit a line into this two-dimensional space that approximates all of these points as best we can? And I can visually just kind of make myself do this like this. So I can eyeball it and say, this line kind of gets close. What we're trying to do is minimize, I've never, all of these, this is the most beautiful diagram I've ever made, all of these distances of all of the points to the line. The idea here then is that we can make some predictions. If this data, if this x-axis represents height, we might predict on the y-axis weight. You can think of kinds of data sets, simple 2D data sets where there's a linear relationship between the one field of data and another field of data. So if we pick a new height, we can kind of make a guess approximately what that weight is gonna be. That's the idea of linear regression. It's incredibly simple. A lot of data isn't two-dimensional. A lot of data doesn't fit a line. You know, maybe a curve fits it better. And this is more complex scenarios will come as we move forward and make more scenarios with complex polynomial equations or neural network-based learning and other types of machine learning algorithms. But this is a good place for us to start. So what do we need? We need a data set. So we need a set of x's and y's. This is the data set. Right, we need x's and y's. And I'm gonna create that data set through interactive clicking. Interactive clicking is the way I'm gonna create that data set with the mouse. I need to have something called a loss function. The loss function is a way of computing the error. And there are a bunch of different loss functions, and we'll see these as I use TensorFlow.js in more tutorials. I can select different kinds of loss functions for different scenarios. But in this scenario, I'm gonna use a simple basic one, which I believe is called root mean squared error. Did I say that correctly? Is that the right name of it? But the idea is that I wanna look at all of those distances. Okay, I'm back, because I started talking about the loss function, and I realized I really didn't draw. I'm not actually looking for the distance from the point to that line, which would be perpendicular. I'm looking for this vertical distance, which is, so this is what I'm trying to minimize. Right, I'm trying to minimize and get a line that has, and this, that is the least, the sum of all these distances is the smallest number, minimizing the loss. So I have a loss function, I need that. I also need, in TensorFlow.js, something called an optimizer. And the optimizer is the thing that allows me to minimize the loss function. And in order to do that, I also need to have a learning rate. So these are all, I actually missed something very important here, but these are all the pieces. I need the data, I need to define a loss function, I need to define an optimizer. I say, hey, optimizer, minimize the loss function with this learning rate. So keep tweaking the parameters, tweaking the parameters. So that's the thing I forgot. What are those parameters? Well, the formula for a line is y equals mx plus b. M is often referred to as the slope, b as the, I'm back, because I looked it up. M is the slope, and b referred to as the y-intercept. Kind of like bias, by the way, if you've watched some of my other neural network tutorials, because this is like the thing we're doing with all the neurons. Oh, it's all so connected, but we're just living in this very simple place. So I need these parameters, I need these variables, because that's what's going to allow me to create the predictions that are on the line to compare with the actual points, and compute the loss, minimize it, tweaking these values. So tweak these values, minimizing the loss. This is what we're doing. And I've done this before in great detail. This is gonna be in less detail, because TensorFlow.js is gonna do a lot of this for us. The thing that's a little extra complicated is we can't just work with arrays of numbers and variables in the way that we're used to in JavaScript. And so this is what brings me to, if you haven't looked at these particular videos that I've made already, what's a TensorFlow tensor? What's a variable? What's an operation? How's the memory management stuff? This is stuff we're gonna have to lean on while I build this example. And this should be, by the way, an actual practical example of where I need a tf variable. So I kind of, in this video, explained what a tf variable is, and then people just kind of moved on and didn't use it for anything. So hopefully this will show us that. All right, how about we write some code now? So actually, I magically appeared over here for a second, because instead of, I did make a little mistake here. I mean, root mean squared is a perfectly legitimate loss function, but most linear regression with gradient descent examples will not bother with the root. And the root refers to square root. We just want the mean squared error, which means, if I say that this value is y, and this value is the guess, the error is guess minus y and squared. And if I do that for all of these, that's the mean. And average them, it's the mean. So I can really sum them or mean them. Well, it's gonna take care of that for us. So we're just gonna use the mean squared error. But that's the idea. We take the differences. The reason why we have to square it, well, for a variety of reasons. One, it has to do with the derivative stuff that's in my other videos, but also just because positive or negative, it's the distance, the size of the error, whether it's up or down, which is key. All right, so here's the amount of code we're gonna start with. I'm using p5 so that I can draw stuff. I'm making a canvas, and the background is zero, which means it's black, and this is what I have so far. So let's look at our list over here, and let's first add the data set, the Xs and Ys. So this is gonna be easy, because I just wanna have Xs be an array, Ys also be an array. So, and then, whenever I click the mouse, I wanna say, oh, you know what I could do? I could make those vectors, let's make them separate arrays. I think we're gonna, actually, I know we're gonna, we're gonna wanna do that for a variety of reasons. We're gonna keep those as separate arrays. So every time I click the mouse, I'm going to say Xs, push mouse X, Ys, push mouse Y. Ah, okay. Here's a little thing. So this is our canvas, right? This is my drawing of the canvas. I know, now I'm having like a deja vu thing. I totally talked about this in the other video. The width is like 400, the height is 400, but I really wanna think of this as, I really wanna think of zero, zero down here, and maybe one being over here. I wanna normalize everything between zero and one. Everything's just gonna work better if we do that. So with Y pointing up. So I'm gonna do a mapping. So every Y value, that's pixel value between zero and height, I'm gonna map between one and zero, and every X value that's between zero and width, I'm gonna map between zero and one. So let's do that. So I'm going to say, let X equal map mouse X, which goes between zero and width, to between zero and one. Let Y, which is mouse Y, between zero and height, and have that go between one and zero, and then push X and push Y. The other thing I wanna do is I just want to, you know, I'm gonna add a draw loop, and I wanna draw all those points. So I'm also now gonna say, stroke 255, stroke weight four, for let I equal, what, huh? Let I equal zero, I is less than X dot length, I plus plus, and those are actually called Xs, Xs dot length. And what I'm gonna do is I'm gonna say, let pixel X equal map. I really should make just like, I'm probably gonna have to do this a lot, so I should probably make a function that just like normalize and un-normalize or de-normalize. Pix, PX equals map X's index I, which goes between zero and one, back to zero and width. So this is the reverse. PY, which maps Y, which goes between zero and one to height comma zero. And then I wanna say, point PX, PY. So I haven't done any, I haven't even, I'm not even using TensorFlow.js yet. I'm just kind of doing the stuff with P5 to draw things. So let's see if I'm getting the results that I want, which is whenever I click, I get the points there. Perfect. And I kind of wanna see them a bit more. Let's like really make it bigger. Great, that's like too big. Okay, great. So we can see, those are the points I'm clicking on. Okay, so what's next? I need a loss function, I need an optimizer. Ah, oh, I need these. Let's make these. So, cause I'm looking for somewhere where I need to get some TensorFlow.js stuff working. So what I need is I need to have M and B. So let's figure that out. So I'm going to create an M and a B. And I'm not gonna initialize them in setup, up here. And I probably should be using const in various places here to protect myself from reassigning something by accident, but I'm gonna be loosey goosey and just use let. You know, these could be const. But anyway, I'm not gonna get into the whole let versus const thing, it makes me crazy. I'm gonna say up here, M equals TF scalar random one. So I'm gonna use the P5 random function to give me a random number between zero and one, cause I gotta start somewhere. So this is kind of like initializing the weights of a neural network. There is no neural network, I'm just doing, I'm just kind of optimizing this function, Y equals MX plus B, but those are like weights, M and B. So I'm gonna initialize them randomly and scalar cause it's a single number. So go back to my TensorFlow.js intro videos and you'll see. Then B, I'm gonna say the same thing, ah, but, these are the things that have to change, right? The data never changes, it's sort of fixed. M and B change over time. I need to tweak those, which means they have to be variable. They have to be able to change, which means, when I over here, I think what I write is TF variable, I wrap them in the TF variable. So now I have M and B as TF variable, right? Isn't it crazy, like you see this kind of code and you're like, that looks like the craziest, scariest thing, but you realize like it's just like, make a number, and because we're in this like kind of lower level, working on the GPU land, I've gotta be very like specific. Like this is a single number and it's gonna be variable, but really it's just a random number. Now, what do we need to do? We need to write, I don't think I actually said this, but I need to write a function called predict maybe, which takes in all of the Xs, just the Xs, and gives me the Y predictions based on where the line is. Because I need to compare the Y predictions to the actual Y values to get the mean squared error. So let's write that function. I'm putting these in like arbitrary places, but I'm gonna write a function called predict. And there what I need to do is I need to have some Xs and I need to return some Ys. I think that's the idea, right? Yes, so I don't wanna just predict one value, I wanna predict a bunch. So the Xs, here's the thing. So if I call this function, the Xs, if they're just a plain array, I need to make it into a tensor. So I'm gonna call it const TF Xs. That might be a bad, it's tensor. And this is a 1D tensor, tensor 1D. Oh, TF, tensor 1D, I think this will do it, Xs, right? I need to turn it into a tensor. And then I need to have the formula for a line. So I need to say, which is Y equals MX plus B. So what I would be doing is I would be saying TF Xs multiplied, is it MUL or MULT? Multiplied by M plus B. Right, this is the idea. If I'm getting just a plain array of numbers, I turn them into a tensor, then I apply the formula for a line, and these are the predictions, the Ys. I guess, I don't like my naming here. I'm just gonna call this X, and maybe I'll call this Xs, I don't know. I have to think about, I'll come back to this later. Okay, so I have that. Now, let's go back and look at the things that I need. So I have this predict function, I have a data set. Ah, I need a loss function. Need a loss function, and I need a, oh, before we do the loss function, let's create the optimizer and the learning rate. So this is what's wonderful about working with TensorFlow.js. When I say make the optimizer, I just mean make a tf.optimizer. It exists, it'll do this math for us. So let's go to the, this is not something that I covered in my other videos, so let's go look for optimizer, and I want an optimizer. Now, there's all these different kinds of optimizers. SGD, stochastic gradient descent. This means the idea of slowly adjusting M and B to minimize the loss function, and I've covered this in more detail in the other videos. So I'm gonna click on that, and I'm gonna look here, and this is basically what I need to do. All right, we got the code right here. Look, there's even a, look at this. Oh my goodness, there's like some stuff here we can really use. So I'm gonna grab this, and I'm gonna put this up here. So I want a learning rate, and I'm gonna have a much bigger learning rate to start with, and I want an optimizer. So now I have a learning rate and an optimizer, and the optimizer is doing stochastic gradient descent. So I have learning rate, optimizer. Now I need that loss function. I need the loss function. Okay, the loss function is something I'm gonna write, loss, and actually, let's go back to here. So look at this. So this is the fancy ES6 way of writing a function, but I'm gonna write it in a less fancy way, and I'm gonna do this. So what I want is I need the loss function. I have some predictions, and I have some labels. So these are, the predictions are the y values I'm getting from the predict function. The labels are the actual y values that are part of this, and by the way, I'm gonna have to do memory management. Don't worry, if you're screaming at me that I haven't worked about memory management, I'm just gonna do that later. So what I wanna do is say return the predictions minus the labels. That makes sense, right? Because I said here, when I said mean squared error is the predictions, like the guess, minus the labels, which is the actual y squared. And so predictions minus the labels is the predictions squared, and then take the mean of them. Look at this. All of these mathematical operations are inside of TensorFlow.js, and you can chain them. So predictions is a tensor, labels is a tensor. All of these, remember, they're just gonna keep producing new tensors, and I'm gonna have to tidy and clean all this stuff up for memory management, but again, I'll worry about that later. So now I have the loss function. All right, well, what is it that I wanna do? Every time, so let's say, I think I'm actually like, I have everything. I have the loss function, I have the data, I have the optimizer, I have a predict function, I have a learning rate, I can minimize, well, oh, this I haven't done. So the training, the actual training, what does it mean to train it? To train it means minimize the loss function with the optimizer and adjusting M and B based on that. All right, so let's see if we can make that. I have a feeling that was in that page that I went to, so maybe I could just copy it from there. I'm kind of, this is like, it totally is. That's fine, I'm gonna happily cheat here. It was in that example, thank you very much. Thank you, TensorFlow.js documentation. And so I'm gonna just put this in draw. Like, every time through draw, I'm gonna minimize. So let's look at this, oh, look at this. Okay, so this is a little different. So first of all, this is using nice, fancy ES6 arrow notation which I'm somewhat happy about. But let me just write a function here called train. And the idea of the train function is to execute the loss with the predictions and the actual y's. Okay, so here, what I'm really doing is minimizing the train. That's weird, this isn't really, no, training would be doing this. So this is a terrible name for this. And actually, this is silly for me to even name this. It really makes sense for me to just make this an anonymous function and that what I'm minimizing is this. This is what I wanna minimize, the loss function. But if I wanna be nice and ES6-like with my arrow notation, which I think by the fact that I'm using TensorFlow.js and you can watch my arrow notation function if this is, I can kind of get rid of a lot of the extra stuff here and this should be good. So I just wanna minimize the loss function. Now, here's the thing. These have to be tensors, right? The loss function requires predictions and labels. They have to be tensors. And if you remember, my x's and y's aren't tensors. When I call the predict function with the x's, it gives me back a tensor. So that, I can't believe I haven't run this code yet. This is a terrible thing. Usually I try to run my code incrementally all the time. I guess I've forgotten to do that. So probably people in the chat are telling me about mistakes I'm making. So this is a tensor, but this is still a plain array. So what I need to do is say constant and I gotta rethink the naming. Maybe somebody in the chat has an idea for me. I think what I actually should do, I have an idea. Permit me a moment of refactoring. X valves, y valves. So I think when it's not a tensor, I'm just gonna call it like x underscore valves because that's gonna help me remember. So x valves, y valves. And then whenever I say, and this should be x. Whenever I say xs or ys, that's really a tensor. I guess I could have done txs. So here, what I'm doing is predicting from the x valves and then ys is tf.tensor1dy valves. So I need to create that tensor and now I can minimize the loss with predicting from the x valves and the y valves. Okay, so this is good. Let's just run this. All right, I'm from the future, different day, different clothes, I'm breaking into this video to mention something really important that I didn't actually mention when I recorded the coding challenge originally. What is that optimize function doing? How does it actually work? And we need to look at the TensorFlow.js documentation to see, so let me, I'm bringing my laptop back up here and I'm gonna switch over here. So I've got the code from the past, me in the future. This is the part that I'm talking about. Well, how is this going to adjust m and b? Those are the, these are the parameters, the weights, the variables that we need to adjust to minimize that loss function. But I'm not anywhere in here saying, those are the variables to work with. Well, this is part of what TensorFlow.js does natively. The fact that I made these up here, tf variables, means those are variables that can be adjusted. And if we look here at the TensorFlow documentation, you'll see what does minimize do? It executes this function f, that is, sorry, that is this function, right? This whole function here. And by the way, the return here is implicit because I'm using the arrow function. So it minimizes the output of that function, tries to get it lower by computing the gradients with respect to a list of all trainable variables provided by var list. Guess what? I didn't provide a list of trainable variables. If no list is provided, it defaults to all trainable variables. And that's what's going on. That's what I did in this coding challenge. These are all the trainable variables in my system. If I wanted to only use m or only use b, I could put those in a list. So that's all I have to say about that. I'm going to fade now back into the other video, lower this and back up, and it's going to keep going where I debug and have all sorts of other problems. Goodbye. Okay, predict.sub.squared is not a function at loss at optimize or minimize. So what do I have wrong here? In my loss function, sub labels.squared.mean. Oh, you know what it is? There's nothing in the arrays at the beginning. They have zero things in them. So a couple of things, one is I could put something in it, but I think I probably should just say, I shouldn't do it only if x.length is greater than zero. So this is definitely, then do I want to bother with, do I want to bother with doing any of this? If there's no values in there, like calling predict and stuff with an empty array, I think it's going to cause problems. That makes sense. All right, let's try this. X is not defined, x vals, my naming. Okay, sketch 45. Ah, this is x vals. And this is x vals, y vals. Okay, that should be good. All right, let's try this. This is not square, being told in the chat, breaking news, that this is actually.squared, not.squared, is that right? Yeah, oh, it's square, a.square, okay. Okay. There we go, okay. So things are going and there's no, I don't have any, like I could look at, that's m, m, m.print, right? So you can see it's changing. It's actually like training it. Like the value of m is changing. So everything's going and working. The problem is I'm not seeing the results. Let's just check b. And I haven't done any memory cleanup. So if I say memory.numTensors, is that what it is? No, what is it again? So let's look under memory management. Memory, oh, memory num, oh, this, tf. So I know you can't see this, but this is what I want. I want to check how much, I want to check and see like how, if I have cleaned up stuff. You can see I have 1,147 tensors. So I need to do the memory cleanup. I don't know, probably better practice would be for me to clean up as I'm going, but I'm kind of going to clean up at the end. All right, so let's, I just want to click back here for a second, oops, no. I'm just going to click no loop to shut this off. And let's go here. So what do I need to do? Ah, I need to visualize what's going on. All right, so how do I do that? So I need to draw a line. So the way that I would draw the line is first, what I would do is all I really need is to give myself the X value of zero and the X value of one, get the two Y values and draw a line between those two points. So if I were to say, let X equal TF scalar. This is silly for me to use the predict function. Why not? Why not? Let's use the predict function. TF scalar zero. So X one is TF scalar zero. Y one equals TF equals predict X one. X two equals TF scalar one. Y two equals predict X two. Right, so this should give me, I mean, it's a little bit silly for me to not just do this, keep an extra copy of like M and B as regular numbers, but let's keep going with this. Will this work? Is it going to be able to take a scalar and make a 1D tensor? I think so. So let me just see here. So let me do X one dot print, Y one dot print. So let's see that. Tensor 1D requires values to be a flat typed array. All right, so one thing I could do is instead of making it a scalar, I can make it a 1D tensor. That's what it wants and do the same thing here. And I have to put it in as an array then, but it's just one value. Oh, this is so silly. Why am I doing X one and one? I could just do this, right? Xs, once again, can I use Xs? Yeah, yeah, yeah. So I could just do it with zero and one. Constant Xs and then constant Ys equals predict Xs. Right, so I could have both these points now. Then let's say Xs dot print, Ys dot print. Let's look at that. Let's see if this works. Predict is not defined because my E key doesn't work and I have to type it several times. Tensor 1D requires values to be a flat typed array. Oh, silly, silly me. Predict doesn't want a tensor. Oh, it wants this. So line X equal, let me just, this is a little bit silly, but I'm gonna do this. So I'm gonna make the, oh, oh, but I don't need to know the Xs. I don't need to have the Xs as a tensor because, yeah. Sorry, everybody. There we go. My predict function, I totally forgot. See, this is just, there's so many different ways you could do this. Like I could enforce you to convert to a tensor before you pass it into predict, but a lot of these decisions are completely arbitrary. So you might have a better way of doing it, but still I'm gonna do this. So now I have the Xs and the Ys, and I don't even need to say Xs print. So we can see, okay, great. So I'm getting these points. Kate Wieckmann in the chat makes an excellent point, which is that I should think about actually mapping it between negative one and one with zero, zero in the center. That's not such a bad idea. Let me just keep going with this, and then maybe I'll change that after the fact, because this should work anyway. So now here's the thing. Here's the awkward thing. In order for me, all I need to do now is basically say this. Let X1 equal map Xs zero, which goes between zero and one, one between zero and with. And this is kind of silly because I could just multiply it times with. But I'm gonna just go with the normalizing, the full normalizing. Y1 equals map X, oh, sorry, X2, which map Xs index one. So this gives me X1, which is just zero and with. Now, Y1 equals map Xs index one. And Y2, I wanna map Ys, the Y value is between height and zero, because I'm flipping it. The problem is, and then I just wanna say line, X1, Y1, X2, Y2. So this is really all I need to do. I just wanna get the sort of two points on the line and then draw a line between them. This is fine because my Xs are not tensors. And I can use plain numbers right here, X1, X2. But my Ys, and here, but my Ys are tensors. So for me to be able to, I really need to get the values back. And a way to do that is with the function called data. So I'm gonna say, let line Y equal Ys.data. And I'm just gonna say data sync right now. And let me comment all this out. And let me console log that and see if this comes. So this is kind of a bad idea for a variety of reasons, but I think it's gonna work okay. So you can see I'm getting those numbers back as a float array. So here's the thing. This really requires not a callback, but a promise. And I'm so happy I just did a whole video series on promises. I really should be saying data.then. And there's even something called tf.nextframe, which allows me to sort of think about the asynchronous nature of pulling the data out of a tensor into a number that I can use in an animation. These are key things, and I'm definitely gonna have to get to them. But here's the thing. This is just two numbers. I think my animation can handle using data sync. And maybe somebody from the TensorFlow.js team is gonna wanna say, actually, this is not just a bad idea, but a really bad idea, I'm not so sure. But I think it's gonna, let's just get it to work and see if this demonstrates the idea. So now, and I'm gonna call this line Y, I should be able to say Y1, Y2, and I should get zero and one from line Y. And now, we should see, we should be done. Oh, line Y is not defined. Where? Sketch.js line 61. I think I just didn't hit save. Yeah. Oh, I haven't clicked any points. Hey, look at that. Oh, hey, look, it's working. Oh, that's so exciting. Ding. All right, for a couple things. Number one is, let's say stroke weight two. And by the way, we can now start to play with the learning rate. I don't have to clean up the memory stuff. I have to, we can play with the learning rate. Like, let's make this 0.01. So you can see what happens with this lower learning rate. I don't know if it's... Let's see, is it really working? Well, I shouldn't use such a low learning rate. Let's make it 0.5. Yeah, it's definitely happy. Okay, so this is working. Linear regression with gradient descent. But I have a severe problem. I am just filling the GPU with tensors and tensors and tensors and tensors and never cleaning them up. So now it's my job to go through and find every place I'm creating a tensor and dispose of it. So I can use tftidy to do that automatically, or I can just use the actual dispose function, which I might be inclined to do at first. All right, so let's go through. So here, these, I do not, I always want to keep them. m and b are variables that I need to keep throughout the course of this program. Loss, do I just put tidy in here? Or should I, let's predict. So do I put tidy in here? Do I wrap tidy here? What if I just put tidy here? Like, what if I say tf.tidy and put all of this? Will this do it? And then here, I also need to, well, here maybe what I'm gonna do is just dispose these. There's no logic to what I'm doing, but I'm just gonna dispose these manually. Oh, and that's just the y's, right? Line y is just, ys is the only thing that's a tensor here. So this should tidy everything, but hopefully not the variables that I need to keep, rather than individually figuring out what to dispose of. And down here, I kind of know that this is my only tensor. This, by the way, I should call this line x, just to be consistent with my variable naming. You know, I'm only using the ys and xs variable name when I have something that's actually a tensor, which helps me remember what I need to clean up and not. Let's see if this goes. Okay, it's still running. 221, oh no, okay. So I'm better, there's fewer tensors, but I haven't cleaned up everything. So what could I be missing? Maybe the call to predict, wouldn't tidy clean that up? All right, I need to debug this somehow. One thing I could do is start commenting stuff out to see like where is the memory leak? So one worry I have, I really think loss and predict, those functions generate a lot of tensors. I believe tftidy should clean up anything, but let's just, for the sake of argument, comment this out. And now, of course, the learning is no longer happening. And what I might as well do is console log the amount of tensors, not have to like ask for it. Whoops, what did I do wrong? TF memory num tensors, what is it? How come I can't remember what it is? Num tensors, no. Yes, it's not a function, it's just num tensors. Sorry, everybody, okay. So, and I need another parentheses here. Ah, little digression there, all right. All right, so we can see it's growing. So let's keep commenting stuff out to see like what's causing the memory leak. Let's comment out this whole area down here. Ah, good news, everybody. The memory leak is in that part. Let's put this back just to be sure. Okay, ah, so the memory leak is definitely down here. And I'm probably creating, oh my goodness. Oh my goodness. No, I'm not sure. Well, let's put this back in. I thought I saw it, but then I didn't again. So this is a tensor and I'm disposing it. Oh, predict, aha. The predict function makes other tensors. And predict got cleaned up because it was in tidy, but I'm just manually disposing the y's down there. That's what it is. So let me use tidy. I guess, ah. So let me do this. Let me put this up here. So this is really what I need to tidy. So instead of disposing manually, I kind of like disposing things manually. The tidy thing kind of freaks me out. But the problem with this is I have a scope issue, which is that line y, right? No matter what I do, if I take this out here, like this is gonna tidy everything. So I guess it's not the biggest deal, at the moment at least, for me to just put everything inside the tidy. Well, that's because, let's put everything inside the tidy for right now. There's probably a way I could simplify that, but this should work. Let's give this a try. There we go. There's only ever five tensors all the time. So there's no more memory leak, five tensors, linear regression with gradient descent, TensorFlow.js, interactive, here it is. So what's left here? So number one, things that could be improved. So I wanted to talk through some things that could be improved, but already, meiamsamy in the chat made a very good suggestion. This is very awkward how I put everything in tidy. So unnecessary. Let me take that out. Because predict returns something, I can actually just put the tidy right here. I don't know why I didn't think of that. Like I can actually just, it's only this predict function that, so I can actually put the tidy right here, and I can use my fancy ES6 arrow syntax, and the return is now assumed, and then I can just say ys.dispose. So this should work. Tidy's not going to tidy up this y value, but I can dispose that manually once I have the values. So I think this will do the trick. Let me just take a look at this. Yeah. So this I like better, and there's probably other styles or ways you could do it. The point is you've got to keep track of all the tensors you're making and dispose them. Okay, so I think I'm going to wrap this video up. I'm getting all these great suggestions from the chat. I could have tidied the tensors here in predict. So number one is this code is going to get posted to the Coding Train website in Coding Challenges. Make your improvements and add them as community contributions. Some things that I would love to see. Visualize, graph the loss value. I think there's a way to get the loss. I'm sure there's a way to get the loss value out of that function. That's one idea. Kay Wieckmann suggested maybe trying some of the other optimizers. So what happens if I go to the tensorflow.js documentation and just use some of these other optimizers? What are they? What will they do? Do you get better or worse results? Can you make the learning rate somehow interactive? Adjust the learning rate? I don't know if you could come up with any really clever visual ideas. With this. But anyway, so but I think I'm good. I think I have the basic idea. So if you really want to dive as deeply as you can into linear regression with gradient descent, you can go back and watch my other videos where I did this with just JavaScript and p5.js. Now you've seen it with JavaScript, p5.js, and tensorflow.js. So I look forward to your feedback and hearing more about it. More tensorflow.js videos to come. You know, I want to get to some actual, more practical things that you might want to do for interactive creative arts projects. But I'm still in the weeds here of just trying to understand the nuts and bolts of how the library works. So I hope you're enjoying that and I look forward to seeing you in future videos.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:43.986037Z",
  "started_at": "2023-09-26T21:16:26.937047Z",
  "completed_at": "2023-09-26T21:28:59.119275Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=dLp10CFIvxI",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 752.182228
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/ek3wtdzbdzjls437xhwy5xpvuq/cancel",
    "get": "https://api.replicate.com/v1/predictions/ek3wtdzbdzjls437xhwy5xpvuq"
  }
}