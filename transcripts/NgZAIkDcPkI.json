{
  "id": "ixttwmzbnvrfgnel6tcebj6tii",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/NgZAIkDcPkI.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/169094 [00:00<?, ?frames/s]\n  2%|▏         | 2686/169094 [00:03<03:57, 701.44frames/s]\n  3%|▎         | 5444/169094 [00:09<04:39, 584.71frames/s]\n  5%|▍         | 8252/169094 [00:15<05:09, 519.68frames/s]\n  7%|▋         | 11044/169094 [00:23<06:04, 433.77frames/s]\n  8%|▊         | 13812/169094 [00:30<06:17, 411.20frames/s]\n 10%|▉         | 16812/169094 [00:37<05:55, 427.93frames/s]\n 11%|█▏        | 19388/169094 [00:42<05:34, 447.23frames/s]\n 13%|█▎        | 22388/169094 [00:47<05:04, 482.14frames/s]\n 15%|█▍        | 24934/169094 [00:54<05:33, 432.66frames/s]\n 16%|█▌        | 27326/169094 [01:00<05:34, 424.38frames/s]\n 18%|█▊        | 29870/169094 [01:05<05:09, 449.41frames/s]\n 19%|█▉        | 32522/169094 [01:12<05:11, 437.89frames/s]\n 21%|██        | 34846/169094 [01:18<05:19, 420.35frames/s]\n 22%|██▏       | 37618/169094 [01:23<04:59, 438.54frames/s]\n 24%|██▍       | 40618/169094 [01:32<05:11, 412.98frames/s]\n 25%|██▌       | 43114/169094 [01:39<05:23, 389.03frames/s]\n 27%|██▋       | 45942/169094 [01:46<05:15, 390.90frames/s]\n 29%|██▉       | 48794/169094 [01:53<04:59, 401.32frames/s]\n 31%|███       | 51702/169094 [01:58<04:33, 429.56frames/s]\n 32%|███▏      | 54394/169094 [02:04<04:17, 445.17frames/s]\n 34%|███▎      | 57010/169094 [02:10<04:15, 439.09frames/s]\n 35%|███▌      | 59530/169094 [02:16<04:14, 431.05frames/s]\n 37%|███▋      | 62086/169094 [02:24<04:26, 401.34frames/s]\n 38%|███▊      | 64994/169094 [02:30<04:04, 425.03frames/s]\n 40%|████      | 67994/169094 [02:35<03:42, 453.75frames/s]\n 42%|████▏     | 70994/169094 [02:42<03:38, 449.94frames/s]\n 43%|████▎     | 73310/169094 [02:47<03:24, 468.10frames/s]\n 45%|████▍     | 75982/169094 [02:52<03:17, 472.31frames/s]\n 47%|████▋     | 78706/169094 [02:57<03:07, 481.69frames/s]\n 48%|████▊     | 81706/169094 [03:01<02:34, 564.03frames/s]\n 50%|█████     | 84706/169094 [03:06<02:25, 578.22frames/s]\n 52%|█████▏    | 87186/169094 [03:10<02:18, 592.59frames/s]\n 53%|█████▎    | 89842/169094 [03:15<02:24, 549.11frames/s]\n 55%|█████▍    | 92518/169094 [03:21<02:27, 518.85frames/s]\n 56%|█████▋    | 95254/169094 [03:26<02:15, 544.53frames/s]\n 58%|█████▊    | 98042/169094 [03:33<02:24, 492.35frames/s]\n 60%|█████▉    | 101042/169094 [03:38<02:15, 503.26frames/s]\n 62%|██████▏   | 104042/169094 [03:44<02:05, 520.33frames/s]\n 63%|██████▎   | 106402/169094 [03:48<01:59, 525.40frames/s]\n 64%|██████▍   | 108902/169094 [03:52<01:50, 543.66frames/s]\n 66%|██████▌   | 111898/169094 [03:59<01:54, 498.12frames/s]\n 68%|██████▊   | 114842/169094 [04:05<01:48, 500.42frames/s]\n 69%|██████▉   | 117202/169094 [04:09<01:42, 507.11frames/s]\n 71%|███████   | 119826/169094 [04:16<01:44, 471.42frames/s]\n 72%|███████▏  | 122550/169094 [04:20<01:28, 526.74frames/s]\n 74%|███████▍  | 125550/169094 [04:23<01:10, 615.11frames/s]\n 76%|███████▌  | 128550/169094 [04:26<01:00, 674.16frames/s]\n 78%|███████▊  | 131550/169094 [04:30<00:53, 699.99frames/s]\n 79%|███████▉  | 133926/169094 [04:35<00:53, 655.42frames/s]\n 81%|████████  | 136926/169094 [04:38<00:46, 692.72frames/s]\n 83%|████████▎ | 139926/169094 [04:45<00:49, 586.08frames/s]\n 84%|████████▍ | 142678/169094 [04:53<00:52, 501.72frames/s]\n 86%|████████▌ | 145678/169094 [04:59<00:47, 490.11frames/s]\n 88%|████████▊ | 148458/169094 [05:07<00:46, 439.67frames/s]\n 89%|████████▉ | 150878/169094 [05:11<00:38, 471.23frames/s]\n 91%|█████████ | 153486/169094 [05:18<00:34, 447.41frames/s]\n 92%|█████████▏| 156272/169094 [05:26<00:30, 413.77frames/s]\n 94%|█████████▍| 159144/169094 [05:32<00:23, 422.65frames/s]\n 96%|█████████▌| 161888/169094 [05:39<00:17, 422.11frames/s]\n 97%|█████████▋| 164620/169094 [05:45<00:10, 420.97frames/s]\n 99%|█████████▉| 167620/169094 [05:53<00:03, 403.39frames/s]\n100%|██████████| 169094/169094 [05:55<00:00, 444.29frames/s]\n100%|██████████| 169094/169094 [05:55<00:00, 475.61frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.3757005116296193,
        "compression_ratio": 1.5,
        "end": 4.28,
        "id": 0,
        "no_speech_prob": 0.03307940810918808,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " And we are here. This is the video in this playlist",
        "tokens": [
          50364,
          400,
          321,
          366,
          510,
          13,
          639,
          307,
          264,
          960,
          294,
          341,
          16788,
          50578
        ]
      },
      {
        "avg_logprob": -0.3757005116296193,
        "compression_ratio": 1.5,
        "end": 13.26,
        "id": 1,
        "no_speech_prob": 0.03307940810918808,
        "seek": 0,
        "start": 5.84,
        "temperature": 0,
        "text": " Which really comes right after 10.7 matrix max part 2 this is matrix math part 3 where I am finally going to look at",
        "tokens": [
          50656,
          3013,
          534,
          1487,
          558,
          934,
          1266,
          13,
          22,
          8141,
          11469,
          644,
          568,
          341,
          307,
          8141,
          5221,
          644,
          805,
          689,
          286,
          669,
          2721,
          516,
          281,
          574,
          412,
          51027
        ]
      },
      {
        "avg_logprob": -0.3757005116296193,
        "compression_ratio": 1.5,
        "end": 18.48,
        "id": 2,
        "no_speech_prob": 0.03307940810918808,
        "seek": 0,
        "start": 16.48,
        "temperature": 0,
        "text": " Can't hear it",
        "tokens": [
          51188,
          1664,
          380,
          1568,
          309,
          51288
        ]
      },
      {
        "avg_logprob": -0.3757005116296193,
        "compression_ratio": 1.5,
        "end": 21.68,
        "id": 3,
        "no_speech_prob": 0.03307940810918808,
        "seek": 0,
        "start": 19.54,
        "temperature": 0,
        "text": " Matrix multiplication or really I should say",
        "tokens": [
          51341,
          36274,
          27290,
          420,
          534,
          286,
          820,
          584,
          51448
        ]
      },
      {
        "avg_logprob": -0.3757005116296193,
        "compression_ratio": 1.5,
        "end": 26.86,
        "id": 4,
        "no_speech_prob": 0.03307940810918808,
        "seek": 0,
        "start": 24.86,
        "temperature": 0,
        "text": " Matrix multiplication",
        "tokens": [
          51607,
          36274,
          27290,
          51707
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 29.3,
        "id": 5,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 27.3,
        "temperature": 0,
        "text": " Okay, so if you recall",
        "tokens": [
          50386,
          1033,
          11,
          370,
          498,
          291,
          9901,
          50486
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 33.78,
        "id": 6,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 30.48,
        "temperature": 0,
        "text": " What I'm doing, I know I look quite different, but I already covered that",
        "tokens": [
          50545,
          708,
          286,
          478,
          884,
          11,
          286,
          458,
          286,
          574,
          1596,
          819,
          11,
          457,
          286,
          1217,
          5343,
          300,
          50710
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 37.379999999999995,
        "id": 7,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 35.379999999999995,
        "temperature": 0,
        "text": " Well previous one was made a while ago anyway",
        "tokens": [
          50790,
          1042,
          3894,
          472,
          390,
          1027,
          257,
          1339,
          2057,
          4033,
          50890
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 43.42,
        "id": 8,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 37.96,
        "temperature": 0,
        "text": " if I have a matrix right and what I mean by a matrix is a grid of",
        "tokens": [
          50919,
          498,
          286,
          362,
          257,
          8141,
          558,
          293,
          437,
          286,
          914,
          538,
          257,
          8141,
          307,
          257,
          10748,
          295,
          51192
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 45.82,
        "id": 9,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 44.22,
        "temperature": 0,
        "text": " values and",
        "tokens": [
          51232,
          4190,
          293,
          51312
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 48.06,
        "id": 10,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 45.82,
        "temperature": 0,
        "text": " Let's say I have one that looks like this a",
        "tokens": [
          51312,
          961,
          311,
          584,
          286,
          362,
          472,
          300,
          1542,
          411,
          341,
          257,
          51424
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 50.78,
        "id": 11,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 48.78,
        "temperature": 0,
        "text": " B C D E F",
        "tokens": [
          51460,
          363,
          383,
          413,
          462,
          479,
          51560
        ]
      },
      {
        "avg_logprob": -0.3530513463395365,
        "compression_ratio": 1.4595959595959596,
        "end": 54.44,
        "id": 12,
        "no_speech_prob": 0.00002212506478826981,
        "seek": 2686,
        "start": 52.34,
        "temperature": 0,
        "text": " This is a three",
        "tokens": [
          51638,
          639,
          307,
          257,
          1045,
          51743
        ]
      },
      {
        "avg_logprob": -0.3081754522120699,
        "compression_ratio": 1.5965665236051503,
        "end": 59.82,
        "id": 13,
        "no_speech_prob": 0.00013552000746130943,
        "seek": 5444,
        "start": 55.28,
        "temperature": 0,
        "text": " No, no, no, it is a 2 by 3 matrix",
        "tokens": [
          50406,
          883,
          11,
          572,
          11,
          572,
          11,
          309,
          307,
          257,
          568,
          538,
          805,
          8141,
          50633
        ]
      },
      {
        "avg_logprob": -0.3081754522120699,
        "compression_ratio": 1.5965665236051503,
        "end": 67.72,
        "id": 14,
        "no_speech_prob": 0.00013552000746130943,
        "seek": 5444,
        "start": 60.879999999999995,
        "temperature": 0,
        "text": " We always refer to the number of rows before the number of columns now. What does it mean and and previously with",
        "tokens": [
          50686,
          492,
          1009,
          2864,
          281,
          264,
          1230,
          295,
          13241,
          949,
          264,
          1230,
          295,
          13766,
          586,
          13,
          708,
          775,
          309,
          914,
          293,
          293,
          8046,
          365,
          51028
        ]
      },
      {
        "avg_logprob": -0.3081754522120699,
        "compression_ratio": 1.5965665236051503,
        "end": 73.32,
        "id": 15,
        "no_speech_prob": 0.00013552000746130943,
        "seek": 5444,
        "start": 68.72,
        "temperature": 0,
        "text": " When I made some videos just about vectors I talked about this thing called the dot product",
        "tokens": [
          51078,
          1133,
          286,
          1027,
          512,
          2145,
          445,
          466,
          18875,
          286,
          2825,
          466,
          341,
          551,
          1219,
          264,
          5893,
          1674,
          51308
        ]
      },
      {
        "avg_logprob": -0.3081754522120699,
        "compression_ratio": 1.5965665236051503,
        "end": 77.02,
        "id": 16,
        "no_speech_prob": 0.00013552000746130943,
        "seek": 5444,
        "start": 73.46,
        "temperature": 0,
        "text": " But I'm gonna change that here and write the matrix product",
        "tokens": [
          51315,
          583,
          286,
          478,
          799,
          1319,
          300,
          510,
          293,
          2464,
          264,
          8141,
          1674,
          51493
        ]
      },
      {
        "avg_logprob": -0.3081754522120699,
        "compression_ratio": 1.5965665236051503,
        "end": 82.52,
        "id": 17,
        "no_speech_prob": 0.00013552000746130943,
        "seek": 5444,
        "start": 77.08,
        "temperature": 0,
        "text": " So first of all, what does it mean to multiply a matrix by by something?",
        "tokens": [
          51496,
          407,
          700,
          295,
          439,
          11,
          437,
          775,
          309,
          914,
          281,
          12972,
          257,
          8141,
          538,
          538,
          746,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 87.39999999999999,
        "id": 18,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 82.52,
        "temperature": 0,
        "text": " I could just multiply this matrix by a single number and that's what's known as well",
        "tokens": [
          50364,
          286,
          727,
          445,
          12972,
          341,
          8141,
          538,
          257,
          2167,
          1230,
          293,
          300,
          311,
          437,
          311,
          2570,
          382,
          731,
          50608
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 89.16,
        "id": 19,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 87.39999999999999,
        "temperature": 0,
        "text": " It's not really that's what's known as scalar",
        "tokens": [
          50608,
          467,
          311,
          406,
          534,
          300,
          311,
          437,
          311,
          2570,
          382,
          39684,
          50696
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 91.8,
        "id": 20,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 89.16,
        "temperature": 0,
        "text": " Sorry scalar if I multiply this by a single number",
        "tokens": [
          50696,
          4919,
          39684,
          498,
          286,
          12972,
          341,
          538,
          257,
          2167,
          1230,
          50828
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 95.88,
        "id": 21,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 92.03999999999999,
        "temperature": 0,
        "text": " Then I just say if this was a whole bunch of ones multiply it by two",
        "tokens": [
          50840,
          1396,
          286,
          445,
          584,
          498,
          341,
          390,
          257,
          1379,
          3840,
          295,
          2306,
          12972,
          309,
          538,
          732,
          51032
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 97.36,
        "id": 22,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 95.88,
        "temperature": 0,
        "text": " I got a whole bunch of twos, you know",
        "tokens": [
          51032,
          286,
          658,
          257,
          1379,
          3840,
          295,
          683,
          329,
          11,
          291,
          458,
          51106
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 101.92,
        "id": 23,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 97.36,
        "temperature": 0,
        "text": " If I multiply by two double every value in the matrix and I think actually now I did that in the previous video. I",
        "tokens": [
          51106,
          759,
          286,
          12972,
          538,
          732,
          3834,
          633,
          2158,
          294,
          264,
          8141,
          293,
          286,
          519,
          767,
          586,
          286,
          630,
          300,
          294,
          264,
          3894,
          960,
          13,
          286,
          51334
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 105.69999999999999,
        "id": 24,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 102.67999999999999,
        "temperature": 0,
        "text": " Could also do what's known as element wise",
        "tokens": [
          51372,
          7497,
          611,
          360,
          437,
          311,
          2570,
          382,
          4478,
          10829,
          51523
        ]
      },
      {
        "avg_logprob": -0.26663866910067474,
        "compression_ratio": 1.9461538461538461,
        "end": 110.44,
        "id": 25,
        "no_speech_prob": 0.0001253369264304638,
        "seek": 8252,
        "start": 106.64,
        "temperature": 0,
        "text": " Multiplication and that is also referred to as the Hadamard",
        "tokens": [
          51570,
          29238,
          4770,
          399,
          293,
          300,
          307,
          611,
          10839,
          281,
          382,
          264,
          12298,
          335,
          515,
          51760
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 112.44,
        "id": 26,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 110.44,
        "temperature": 0,
        "text": " I don't know if I'm pronouncing that correctly and",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          498,
          286,
          478,
          14144,
          2175,
          300,
          8944,
          293,
          50464
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 115.28,
        "id": 27,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 112.67999999999999,
        "temperature": 0,
        "text": " Breaking news somebody in the live chat that's going on right now",
        "tokens": [
          50476,
          36715,
          2583,
          2618,
          294,
          264,
          1621,
          5081,
          300,
          311,
          516,
          322,
          558,
          586,
          50606
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 121.36,
        "id": 28,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 115.44,
        "temperature": 0,
        "text": " Told me that it also soon as called a sure product and what that means is imagine I have another matrix",
        "tokens": [
          50614,
          48220,
          385,
          300,
          309,
          611,
          2321,
          382,
          1219,
          257,
          988,
          1674,
          293,
          437,
          300,
          1355,
          307,
          3811,
          286,
          362,
          1071,
          8141,
          50910
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 125,
        "id": 29,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 121.48,
        "temperature": 0,
        "text": " That's exactly the same size as this one",
        "tokens": [
          50916,
          663,
          311,
          2293,
          264,
          912,
          2744,
          382,
          341,
          472,
          51092
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 129.38,
        "id": 30,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 125.56,
        "temperature": 0,
        "text": " And in fact, I could kind of do that little small over here and I could say",
        "tokens": [
          51120,
          400,
          294,
          1186,
          11,
          286,
          727,
          733,
          295,
          360,
          300,
          707,
          1359,
          670,
          510,
          293,
          286,
          727,
          584,
          51311
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 132.36,
        "id": 31,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 130.36,
        "temperature": 0,
        "text": " G H I J K L",
        "tokens": [
          51360,
          460,
          389,
          286,
          508,
          591,
          441,
          51460
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 134.96,
        "id": 32,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 133.28,
        "temperature": 0,
        "text": " Right, so I could have another matrix",
        "tokens": [
          51506,
          1779,
          11,
          370,
          286,
          727,
          362,
          1071,
          8141,
          51590
        ]
      },
      {
        "avg_logprob": -0.3845729026473871,
        "compression_ratio": 1.739463601532567,
        "end": 138.12,
        "id": 33,
        "no_speech_prob": 0.00008888012962415814,
        "seek": 11044,
        "start": 134.96,
        "temperature": 0,
        "text": " It's exactly the same size and my new if I multiply these together",
        "tokens": [
          51590,
          467,
          311,
          2293,
          264,
          912,
          2744,
          293,
          452,
          777,
          498,
          286,
          12972,
          613,
          1214,
          51748
        ]
      },
      {
        "avg_logprob": -0.32265065896390666,
        "compression_ratio": 1.7666666666666666,
        "end": 143.72,
        "id": 34,
        "no_speech_prob": 0.00008349605923285708,
        "seek": 13812,
        "start": 138.12,
        "temperature": 0,
        "text": " I have a new matrix which is has a times G B times H C times I D times J",
        "tokens": [
          50364,
          286,
          362,
          257,
          777,
          8141,
          597,
          307,
          575,
          257,
          1413,
          460,
          363,
          1413,
          389,
          383,
          1413,
          286,
          413,
          1413,
          508,
          50644
        ]
      },
      {
        "avg_logprob": -0.32265065896390666,
        "compression_ratio": 1.7666666666666666,
        "end": 149.68,
        "id": 35,
        "no_speech_prob": 0.00008349605923285708,
        "seek": 13812,
        "start": 143.88,
        "temperature": 0,
        "text": " element wise each L each element of the matrix get multiplied by its corresponding other element now I",
        "tokens": [
          50652,
          4478,
          10829,
          1184,
          441,
          1184,
          4478,
          295,
          264,
          8141,
          483,
          17207,
          538,
          1080,
          11760,
          661,
          4478,
          586,
          286,
          50942
        ]
      },
      {
        "avg_logprob": -0.32265065896390666,
        "compression_ratio": 1.7666666666666666,
        "end": 156.68,
        "id": 36,
        "no_speech_prob": 0.00008349605923285708,
        "seek": 13812,
        "start": 150.72,
        "temperature": 0,
        "text": " Don't those are perfectly valid. I'm looking for my eraser perfectly valid ways of doing multiplication",
        "tokens": [
          50994,
          1468,
          380,
          729,
          366,
          6239,
          7363,
          13,
          286,
          478,
          1237,
          337,
          452,
          46018,
          6239,
          7363,
          2098,
          295,
          884,
          27290,
          51292
        ]
      },
      {
        "avg_logprob": -0.32265065896390666,
        "compression_ratio": 1.7666666666666666,
        "end": 165.12,
        "id": 37,
        "no_speech_prob": 0.00008349605923285708,
        "seek": 13812,
        "start": 157.08,
        "temperature": 0,
        "text": " Oops, I don't need to but what I'm really interested in is the matrix product and the reason why I'm interested in the matrix",
        "tokens": [
          51312,
          21726,
          11,
          286,
          500,
          380,
          643,
          281,
          457,
          437,
          286,
          478,
          534,
          3102,
          294,
          307,
          264,
          8141,
          1674,
          293,
          264,
          1778,
          983,
          286,
          478,
          3102,
          294,
          264,
          8141,
          51714
        ]
      },
      {
        "avg_logprob": -0.32265065896390666,
        "compression_ratio": 1.7666666666666666,
        "end": 167.4,
        "id": 38,
        "no_speech_prob": 0.00008349605923285708,
        "seek": 13812,
        "start": 165.4,
        "temperature": 0,
        "text": " product is because",
        "tokens": [
          51728,
          1674,
          307,
          570,
          51828
        ]
      },
      {
        "avg_logprob": -0.29641560872395833,
        "compression_ratio": 2.156862745098039,
        "end": 174.20000000000002,
        "id": 39,
        "no_speech_prob": 0.000010953111086564604,
        "seek": 16812,
        "start": 169,
        "temperature": 0,
        "text": " I want to use the matrix product for a neural network for example this",
        "tokens": [
          50408,
          286,
          528,
          281,
          764,
          264,
          8141,
          1674,
          337,
          257,
          18161,
          3209,
          337,
          1365,
          341,
          50668
        ]
      },
      {
        "avg_logprob": -0.29641560872395833,
        "compression_ratio": 2.156862745098039,
        "end": 182.6,
        "id": 40,
        "no_speech_prob": 0.000010953111086564604,
        "seek": 16812,
        "start": 174.84,
        "temperature": 0,
        "text": " Node in a neural network is going to be the result of the weighted sum of all of the input nodes",
        "tokens": [
          50700,
          38640,
          294,
          257,
          18161,
          3209,
          307,
          516,
          281,
          312,
          264,
          1874,
          295,
          264,
          32807,
          2408,
          295,
          439,
          295,
          264,
          4846,
          13891,
          51088
        ]
      },
      {
        "avg_logprob": -0.29641560872395833,
        "compression_ratio": 2.156862745098039,
        "end": 185.96,
        "id": 41,
        "no_speech_prob": 0.000010953111086564604,
        "seek": 16812,
        "start": 183.6,
        "temperature": 0,
        "text": " multiplied by weighted connections and",
        "tokens": [
          51138,
          17207,
          538,
          32807,
          9271,
          293,
          51256
        ]
      },
      {
        "avg_logprob": -0.29641560872395833,
        "compression_ratio": 2.156862745098039,
        "end": 193.88,
        "id": 42,
        "no_speech_prob": 0.000010953111086564604,
        "seek": 16812,
        "start": 187.12,
        "temperature": 0,
        "text": " This one is also going to be the weighted sum of all of the input nodes multiplied by weighted connections and so on and so",
        "tokens": [
          51314,
          639,
          472,
          307,
          611,
          516,
          281,
          312,
          264,
          32807,
          2408,
          295,
          439,
          295,
          264,
          4846,
          13891,
          17207,
          538,
          32807,
          9271,
          293,
          370,
          322,
          293,
          370,
          51652
        ]
      },
      {
        "avg_logprob": -0.30729890798593495,
        "compression_ratio": 1.6443298969072164,
        "end": 199,
        "id": 43,
        "no_speech_prob": 0.000005955134383839322,
        "seek": 19388,
        "start": 193.88,
        "temperature": 0,
        "text": " forth and so these weights are stored in a matrix and the inputs",
        "tokens": [
          50364,
          5220,
          293,
          370,
          613,
          17443,
          366,
          12187,
          294,
          257,
          8141,
          293,
          264,
          15743,
          50620
        ]
      },
      {
        "avg_logprob": -0.30729890798593495,
        "compression_ratio": 1.6443298969072164,
        "end": 205.24,
        "id": 44,
        "no_speech_prob": 0.000005955134383839322,
        "seek": 19388,
        "start": 200.32,
        "temperature": 0,
        "text": " Come in in the matrix as well. So if this is how I'm representing the inputs",
        "tokens": [
          50686,
          2492,
          294,
          294,
          264,
          8141,
          382,
          731,
          13,
          407,
          498,
          341,
          307,
          577,
          286,
          478,
          13460,
          264,
          15743,
          50932
        ]
      },
      {
        "avg_logprob": -0.30729890798593495,
        "compression_ratio": 1.6443298969072164,
        "end": 212.28,
        "id": 45,
        "no_speech_prob": 0.000005955134383839322,
        "seek": 19388,
        "start": 208.64,
        "temperature": 0,
        "text": " Then you might discover that I have this matrix",
        "tokens": [
          51102,
          1396,
          291,
          1062,
          4411,
          300,
          286,
          362,
          341,
          8141,
          51284
        ]
      },
      {
        "avg_logprob": -0.30729890798593495,
        "compression_ratio": 1.6443298969072164,
        "end": 219,
        "id": 46,
        "no_speech_prob": 0.000005955134383839322,
        "seek": 19388,
        "start": 214.4,
        "temperature": 0,
        "text": " Of all these weights that I need to multiply those inputs by to get",
        "tokens": [
          51390,
          2720,
          439,
          613,
          17443,
          300,
          286,
          643,
          281,
          12972,
          729,
          15743,
          538,
          281,
          483,
          51620
        ]
      },
      {
        "avg_logprob": -0.30729890798593495,
        "compression_ratio": 1.6443298969072164,
        "end": 223.26,
        "id": 47,
        "no_speech_prob": 0.000005955134383839322,
        "seek": 19388,
        "start": 219.35999999999999,
        "temperature": 0,
        "text": " The new values of the outputs of this hidden layer now anyway",
        "tokens": [
          51638,
          440,
          777,
          4190,
          295,
          264,
          23930,
          295,
          341,
          7633,
          4583,
          586,
          4033,
          51833
        ]
      },
      {
        "avg_logprob": -0.2650292361224139,
        "compression_ratio": 1.8744588744588744,
        "end": 226.96,
        "id": 48,
        "no_speech_prob": 0.00003169317642459646,
        "seek": 22388,
        "start": 223.88,
        "temperature": 0,
        "text": " I kind of talked about that in a previous video",
        "tokens": [
          50364,
          286,
          733,
          295,
          2825,
          466,
          300,
          294,
          257,
          3894,
          960,
          50518
        ]
      },
      {
        "avg_logprob": -0.2650292361224139,
        "compression_ratio": 1.8744588744588744,
        "end": 232.92,
        "id": 49,
        "no_speech_prob": 0.00003169317642459646,
        "seek": 22388,
        "start": 226.96,
        "temperature": 0,
        "text": " And I'm going to talk about it a lot more in the next video when we look at this in more detail",
        "tokens": [
          50518,
          400,
          286,
          478,
          516,
          281,
          751,
          466,
          309,
          257,
          688,
          544,
          294,
          264,
          958,
          960,
          562,
          321,
          574,
          412,
          341,
          294,
          544,
          2607,
          50816
        ]
      },
      {
        "avg_logprob": -0.2650292361224139,
        "compression_ratio": 1.8744588744588744,
        "end": 238.12,
        "id": 50,
        "no_speech_prob": 0.00003169317642459646,
        "seek": 22388,
        "start": 232.96,
        "temperature": 0,
        "text": " But the point here is that this idea of a matrix product is something that I'm going to need",
        "tokens": [
          50818,
          583,
          264,
          935,
          510,
          307,
          300,
          341,
          1558,
          295,
          257,
          8141,
          1674,
          307,
          746,
          300,
          286,
          478,
          516,
          281,
          643,
          51076
        ]
      },
      {
        "avg_logprob": -0.2650292361224139,
        "compression_ratio": 1.8744588744588744,
        "end": 242.48,
        "id": 51,
        "no_speech_prob": 0.00003169317642459646,
        "seek": 22388,
        "start": 238.16,
        "temperature": 0,
        "text": " Don't worry about the whole neural network thing. I'm going to come back to that in",
        "tokens": [
          51078,
          1468,
          380,
          3292,
          466,
          264,
          1379,
          18161,
          3209,
          551,
          13,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          300,
          294,
          51294
        ]
      },
      {
        "avg_logprob": -0.2650292361224139,
        "compression_ratio": 1.8744588744588744,
        "end": 249.34,
        "id": 52,
        "no_speech_prob": 0.00003169317642459646,
        "seek": 22388,
        "start": 243.24,
        "temperature": 0,
        "text": " Next video go through that in detail what I need to do here is just understand. I know I need the matrix product",
        "tokens": [
          51332,
          3087,
          960,
          352,
          807,
          300,
          294,
          2607,
          437,
          286,
          643,
          281,
          360,
          510,
          307,
          445,
          1223,
          13,
          286,
          458,
          286,
          643,
          264,
          8141,
          1674,
          51637
        ]
      },
      {
        "avg_logprob": -0.2531015872955322,
        "compression_ratio": 1.586021505376344,
        "end": 254.18,
        "id": 53,
        "no_speech_prob": 0.00001544628139527049,
        "seek": 24934,
        "start": 249.82,
        "temperature": 0,
        "text": " How does it work and then we'll see how it's applied in the neural network example, okay",
        "tokens": [
          50388,
          1012,
          775,
          309,
          589,
          293,
          550,
          321,
          603,
          536,
          577,
          309,
          311,
          6456,
          294,
          264,
          18161,
          3209,
          1365,
          11,
          1392,
          50606
        ]
      },
      {
        "avg_logprob": -0.2531015872955322,
        "compression_ratio": 1.586021505376344,
        "end": 262.06,
        "id": 54,
        "no_speech_prob": 0.00001544628139527049,
        "seek": 24934,
        "start": 254.18,
        "temperature": 0,
        "text": " so let's say that I have another I have a matrix a and I have another matrix B and that matrix is equal to",
        "tokens": [
          50606,
          370,
          718,
          311,
          584,
          300,
          286,
          362,
          1071,
          286,
          362,
          257,
          8141,
          257,
          293,
          286,
          362,
          1071,
          8141,
          363,
          293,
          300,
          8141,
          307,
          2681,
          281,
          51000
        ]
      },
      {
        "avg_logprob": -0.2531015872955322,
        "compression_ratio": 1.586021505376344,
        "end": 265.5,
        "id": 55,
        "no_speech_prob": 0.00001544628139527049,
        "seek": 24934,
        "start": 263.5,
        "temperature": 0,
        "text": " G H I",
        "tokens": [
          51072,
          460,
          389,
          286,
          51172
        ]
      },
      {
        "avg_logprob": -0.2531015872955322,
        "compression_ratio": 1.586021505376344,
        "end": 267.9,
        "id": 56,
        "no_speech_prob": 0.00001544628139527049,
        "seek": 24934,
        "start": 265.9,
        "temperature": 0,
        "text": " J K L",
        "tokens": [
          51192,
          508,
          591,
          441,
          51292
        ]
      },
      {
        "avg_logprob": -0.2531015872955322,
        "compression_ratio": 1.586021505376344,
        "end": 273.26,
        "id": 57,
        "no_speech_prob": 0.00001544628139527049,
        "seek": 24934,
        "start": 267.94,
        "temperature": 0,
        "text": " I'm writing the L like that so that I can see that it's not a 1 or whatever. Okay, so I",
        "tokens": [
          51294,
          286,
          478,
          3579,
          264,
          441,
          411,
          300,
          370,
          300,
          286,
          393,
          536,
          300,
          309,
          311,
          406,
          257,
          502,
          420,
          2035,
          13,
          1033,
          11,
          370,
          286,
          51560
        ]
      },
      {
        "avg_logprob": -0.2738680945502387,
        "compression_ratio": 1.6650943396226414,
        "end": 280.5,
        "id": 58,
        "no_speech_prob": 0.00011412213643779978,
        "seek": 27326,
        "start": 273.78,
        "temperature": 0,
        "text": " Have these two matrices the way that I write the expression a matrix product B. I'm going to write it like this a",
        "tokens": [
          50390,
          3560,
          613,
          732,
          32284,
          264,
          636,
          300,
          286,
          2464,
          264,
          6114,
          257,
          8141,
          1674,
          363,
          13,
          286,
          478,
          516,
          281,
          2464,
          309,
          411,
          341,
          257,
          50726
        ]
      },
      {
        "avg_logprob": -0.2738680945502387,
        "compression_ratio": 1.6650943396226414,
        "end": 283.34,
        "id": 59,
        "no_speech_prob": 0.00011412213643779978,
        "seek": 27326,
        "start": 281.5,
        "temperature": 0,
        "text": " dot B",
        "tokens": [
          50776,
          5893,
          363,
          50868
        ]
      },
      {
        "avg_logprob": -0.2738680945502387,
        "compression_ratio": 1.6650943396226414,
        "end": 289.02,
        "id": 60,
        "no_speech_prob": 0.00011412213643779978,
        "seek": 27326,
        "start": 283.34,
        "temperature": 0,
        "text": " The dot as the indicator for the matrix product now what couple things that are really important here one",
        "tokens": [
          50868,
          440,
          5893,
          382,
          264,
          16961,
          337,
          264,
          8141,
          1674,
          586,
          437,
          1916,
          721,
          300,
          366,
          534,
          1021,
          510,
          472,
          51152
        ]
      },
      {
        "avg_logprob": -0.2738680945502387,
        "compression_ratio": 1.6650943396226414,
        "end": 296.65999999999997,
        "id": 61,
        "no_speech_prob": 0.00011412213643779978,
        "seek": 27326,
        "start": 289.82,
        "temperature": 0,
        "text": " The commutative property does not hold a dot B does not equal B. Dot a this is not true",
        "tokens": [
          51192,
          440,
          800,
          325,
          1166,
          4707,
          775,
          406,
          1797,
          257,
          5893,
          363,
          775,
          406,
          2681,
          363,
          13,
          38753,
          257,
          341,
          307,
          406,
          2074,
          51534
        ]
      },
      {
        "avg_logprob": -0.2738680945502387,
        "compression_ratio": 1.6650943396226414,
        "end": 298.7,
        "id": 62,
        "no_speech_prob": 0.00011412213643779978,
        "seek": 27326,
        "start": 296.65999999999997,
        "temperature": 0,
        "text": " And you're going to see why in a minute",
        "tokens": [
          51534,
          400,
          291,
          434,
          516,
          281,
          536,
          983,
          294,
          257,
          3456,
          51636
        ]
      },
      {
        "avg_logprob": -0.25805499766132617,
        "compression_ratio": 1.7309236947791165,
        "end": 303.74,
        "id": 63,
        "no_speech_prob": 0.0002653014671523124,
        "seek": 29870,
        "start": 298.7,
        "temperature": 0,
        "text": " You know if I were to say 3 times 4 that's equal to 4 times 3 they're both equal to 12",
        "tokens": [
          50364,
          509,
          458,
          498,
          286,
          645,
          281,
          584,
          805,
          1413,
          1017,
          300,
          311,
          2681,
          281,
          1017,
          1413,
          805,
          436,
          434,
          1293,
          2681,
          281,
          2272,
          50616
        ]
      },
      {
        "avg_logprob": -0.25805499766132617,
        "compression_ratio": 1.7309236947791165,
        "end": 310.46,
        "id": 64,
        "no_speech_prob": 0.0002653014671523124,
        "seek": 29870,
        "start": 303.74,
        "temperature": 0,
        "text": " But again this matrix product is a different kind of multiplication this commutative property does not hold so that's kind of key",
        "tokens": [
          50616,
          583,
          797,
          341,
          8141,
          1674,
          307,
          257,
          819,
          733,
          295,
          27290,
          341,
          800,
          325,
          1166,
          4707,
          775,
          406,
          1797,
          370,
          300,
          311,
          733,
          295,
          2141,
          50952
        ]
      },
      {
        "avg_logprob": -0.25805499766132617,
        "compression_ratio": 1.7309236947791165,
        "end": 319.46,
        "id": 65,
        "no_speech_prob": 0.0002653014671523124,
        "seek": 29870,
        "start": 313.18,
        "temperature": 0,
        "text": " Another thing that's really important is the matrix product is something you could only do if the",
        "tokens": [
          51088,
          3996,
          551,
          300,
          311,
          534,
          1021,
          307,
          264,
          8141,
          1674,
          307,
          746,
          291,
          727,
          787,
          360,
          498,
          264,
          51402
        ]
      },
      {
        "avg_logprob": -0.25805499766132617,
        "compression_ratio": 1.7309236947791165,
        "end": 325.21999999999997,
        "id": 66,
        "no_speech_prob": 0.0002653014671523124,
        "seek": 29870,
        "start": 319.82,
        "temperature": 0,
        "text": " sizes of the matrices match up and what do I mean by that now one thing you might have thought but realize like if I",
        "tokens": [
          51420,
          11602,
          295,
          264,
          32284,
          2995,
          493,
          293,
          437,
          360,
          286,
          914,
          538,
          300,
          586,
          472,
          551,
          291,
          1062,
          362,
          1194,
          457,
          4325,
          411,
          498,
          286,
          51690
        ]
      },
      {
        "avg_logprob": -0.30324878870883837,
        "compression_ratio": 1.8211382113821137,
        "end": 331.26000000000005,
        "id": 67,
        "no_speech_prob": 0.00044421746861189604,
        "seek": 32522,
        "start": 325.26000000000005,
        "temperature": 0,
        "text": " When I had that example the Hadamard product that's only going to work if I have two matrices with the same exact dimensions",
        "tokens": [
          50366,
          1133,
          286,
          632,
          300,
          1365,
          264,
          12298,
          335,
          515,
          1674,
          300,
          311,
          787,
          516,
          281,
          589,
          498,
          286,
          362,
          732,
          32284,
          365,
          264,
          912,
          1900,
          12819,
          50666
        ]
      },
      {
        "avg_logprob": -0.30324878870883837,
        "compression_ratio": 1.8211382113821137,
        "end": 334.22,
        "id": 68,
        "no_speech_prob": 0.00044421746861189604,
        "seek": 32522,
        "start": 331.26000000000005,
        "temperature": 0,
        "text": " right because if I if I don't have the same exact dimensions",
        "tokens": [
          50666,
          558,
          570,
          498,
          286,
          498,
          286,
          500,
          380,
          362,
          264,
          912,
          1900,
          12819,
          50814
        ]
      },
      {
        "avg_logprob": -0.30324878870883837,
        "compression_ratio": 1.8211382113821137,
        "end": 338.06,
        "id": 69,
        "no_speech_prob": 0.00044421746861189604,
        "seek": 32522,
        "start": 334.22,
        "temperature": 0,
        "text": " How can I multiply each element by the other element because there some elements might not exist in one of them?",
        "tokens": [
          50814,
          1012,
          393,
          286,
          12972,
          1184,
          4478,
          538,
          264,
          661,
          4478,
          570,
          456,
          512,
          4959,
          1062,
          406,
          2514,
          294,
          472,
          295,
          552,
          30,
          51006
        ]
      },
      {
        "avg_logprob": -0.30324878870883837,
        "compression_ratio": 1.8211382113821137,
        "end": 343.12,
        "id": 70,
        "no_speech_prob": 0.00044421746861189604,
        "seek": 32522,
        "start": 338.06,
        "temperature": 0,
        "text": " But something even completely different is going to go on here. I need to have for this to be valid",
        "tokens": [
          51006,
          583,
          746,
          754,
          2584,
          819,
          307,
          516,
          281,
          352,
          322,
          510,
          13,
          286,
          643,
          281,
          362,
          337,
          341,
          281,
          312,
          7363,
          51259
        ]
      },
      {
        "avg_logprob": -0.30324878870883837,
        "compression_ratio": 1.8211382113821137,
        "end": 345.34000000000003,
        "id": 71,
        "no_speech_prob": 0.00044421746861189604,
        "seek": 32522,
        "start": 343.12,
        "temperature": 0,
        "text": " I need to have the columns",
        "tokens": [
          51259,
          286,
          643,
          281,
          362,
          264,
          13766,
          51370
        ]
      },
      {
        "avg_logprob": -0.30324878870883837,
        "compression_ratio": 1.8211382113821137,
        "end": 348.46000000000004,
        "id": 72,
        "no_speech_prob": 0.00044421746861189604,
        "seek": 32522,
        "start": 346.34000000000003,
        "temperature": 0,
        "text": " right the columns of a",
        "tokens": [
          51420,
          558,
          264,
          13766,
          295,
          257,
          51526
        ]
      },
      {
        "avg_logprob": -0.2610954284667969,
        "compression_ratio": 1.819277108433735,
        "end": 351.58,
        "id": 73,
        "no_speech_prob": 0.02228561043739319,
        "seek": 34846,
        "start": 349.46,
        "temperature": 0,
        "text": " Equal to the rows of B",
        "tokens": [
          50414,
          15624,
          304,
          281,
          264,
          13241,
          295,
          363,
          50520
        ]
      },
      {
        "avg_logprob": -0.2610954284667969,
        "compression_ratio": 1.819277108433735,
        "end": 356.14,
        "id": 74,
        "no_speech_prob": 0.02228561043739319,
        "seek": 34846,
        "start": 351.58,
        "temperature": 0,
        "text": " And you'll notice I made these do that so I have to have however many columns",
        "tokens": [
          50520,
          400,
          291,
          603,
          3449,
          286,
          1027,
          613,
          360,
          300,
          370,
          286,
          362,
          281,
          362,
          4461,
          867,
          13766,
          50748
        ]
      },
      {
        "avg_logprob": -0.2610954284667969,
        "compression_ratio": 1.819277108433735,
        "end": 360.02,
        "id": 75,
        "no_speech_prob": 0.02228561043739319,
        "seek": 34846,
        "start": 356.14,
        "temperature": 0,
        "text": " I have here three I have to have exactly the same number of rows in B",
        "tokens": [
          50748,
          286,
          362,
          510,
          1045,
          286,
          362,
          281,
          362,
          2293,
          264,
          912,
          1230,
          295,
          13241,
          294,
          363,
          50942
        ]
      },
      {
        "avg_logprob": -0.2610954284667969,
        "compression_ratio": 1.819277108433735,
        "end": 362.7,
        "id": 76,
        "no_speech_prob": 0.02228561043739319,
        "seek": 34846,
        "start": 360.02,
        "temperature": 0,
        "text": " Otherwise this won't work and the reason is",
        "tokens": [
          50942,
          10328,
          341,
          1582,
          380,
          589,
          293,
          264,
          1778,
          307,
          51076
        ]
      },
      {
        "avg_logprob": -0.2610954284667969,
        "compression_ratio": 1.819277108433735,
        "end": 369.58,
        "id": 77,
        "no_speech_prob": 0.02228561043739319,
        "seek": 34846,
        "start": 364.18,
        "temperature": 0,
        "text": " What I'm actually going to do is the reason why I use this dot here is I'm going to use the vector dot product",
        "tokens": [
          51150,
          708,
          286,
          478,
          767,
          516,
          281,
          360,
          307,
          264,
          1778,
          983,
          286,
          764,
          341,
          5893,
          510,
          307,
          286,
          478,
          516,
          281,
          764,
          264,
          8062,
          5893,
          1674,
          51420
        ]
      },
      {
        "avg_logprob": -0.2610954284667969,
        "compression_ratio": 1.819277108433735,
        "end": 376.17999999999995,
        "id": 78,
        "no_speech_prob": 0.02228561043739319,
        "seek": 34846,
        "start": 370.09999999999997,
        "temperature": 0,
        "text": " Vector dot product so you might have to go back to one of my previous videos where I talked about the vector dot product course",
        "tokens": [
          51446,
          691,
          20814,
          5893,
          1674,
          370,
          291,
          1062,
          362,
          281,
          352,
          646,
          281,
          472,
          295,
          452,
          3894,
          2145,
          689,
          286,
          2825,
          466,
          264,
          8062,
          5893,
          1674,
          1164,
          51750
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 377.14,
        "id": 79,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 376.18,
        "temperature": 0,
        "text": " I'm going to do it here again",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          360,
          309,
          510,
          797,
          50412
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 384.1,
        "id": 80,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 377.14,
        "temperature": 0,
        "text": " But what the vector dot product does is it takes kind of like the sum of all the elements multiplied?",
        "tokens": [
          50412,
          583,
          437,
          264,
          8062,
          5893,
          1674,
          775,
          307,
          309,
          2516,
          733,
          295,
          411,
          264,
          2408,
          295,
          439,
          264,
          4959,
          17207,
          30,
          50760
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 387.78000000000003,
        "id": 81,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 384.42,
        "temperature": 0,
        "text": " The element wise elements both applied to each other. What do I mean by that?",
        "tokens": [
          50776,
          440,
          4478,
          10829,
          4959,
          1293,
          6456,
          281,
          1184,
          661,
          13,
          708,
          360,
          286,
          914,
          538,
          300,
          30,
          50944
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 390.42,
        "id": 82,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 388.18,
        "temperature": 0,
        "text": " so if I say a dot B",
        "tokens": [
          50964,
          370,
          498,
          286,
          584,
          257,
          5893,
          363,
          51076
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 393.38,
        "id": 83,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 391.26,
        "temperature": 0,
        "text": " I'm going to get when I when I take",
        "tokens": [
          51118,
          286,
          478,
          516,
          281,
          483,
          562,
          286,
          562,
          286,
          747,
          51224
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 399.86,
        "id": 84,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 393.86,
        "temperature": 0,
        "text": " One matrix the a matrix product B. The result is also going to be a matrix now",
        "tokens": [
          51248,
          1485,
          8141,
          264,
          257,
          8141,
          1674,
          363,
          13,
          440,
          1874,
          307,
          611,
          516,
          281,
          312,
          257,
          8141,
          586,
          51548
        ]
      },
      {
        "avg_logprob": -0.317799560025207,
        "compression_ratio": 1.763265306122449,
        "end": 405.42,
        "id": 85,
        "no_speech_prob": 0.00009610228153178468,
        "seek": 37618,
        "start": 399.86,
        "temperature": 0,
        "text": " How do I know the dimensions of that matrix? It's going to have the number of rows of a",
        "tokens": [
          51548,
          1012,
          360,
          286,
          458,
          264,
          12819,
          295,
          300,
          8141,
          30,
          467,
          311,
          516,
          281,
          362,
          264,
          1230,
          295,
          13241,
          295,
          257,
          51826
        ]
      },
      {
        "avg_logprob": -0.2789331418331538,
        "compression_ratio": 1.6693548387096775,
        "end": 408.58,
        "id": 86,
        "no_speech_prob": 0.0000023320708351093344,
        "seek": 40618,
        "start": 406.58,
        "temperature": 0,
        "text": " Which is how many two?",
        "tokens": [
          50384,
          3013,
          307,
          577,
          867,
          732,
          30,
          50484
        ]
      },
      {
        "avg_logprob": -0.2789331418331538,
        "compression_ratio": 1.6693548387096775,
        "end": 412.5,
        "id": 87,
        "no_speech_prob": 0.0000023320708351093344,
        "seek": 40618,
        "start": 410.22,
        "temperature": 0,
        "text": " Followed by the number of columns of B",
        "tokens": [
          50566,
          9876,
          292,
          538,
          264,
          1230,
          295,
          13766,
          295,
          363,
          50680
        ]
      },
      {
        "avg_logprob": -0.2789331418331538,
        "compression_ratio": 1.6693548387096775,
        "end": 417.06,
        "id": 88,
        "no_speech_prob": 0.0000023320708351093344,
        "seek": 40618,
        "start": 414.14,
        "temperature": 0,
        "text": " What two so in the end I'm in a two by two matrix now",
        "tokens": [
          50762,
          708,
          732,
          370,
          294,
          264,
          917,
          286,
          478,
          294,
          257,
          732,
          538,
          732,
          8141,
          586,
          50908
        ]
      },
      {
        "avg_logprob": -0.2789331418331538,
        "compression_ratio": 1.6693548387096775,
        "end": 419.82,
        "id": 89,
        "no_speech_prob": 0.0000023320708351093344,
        "seek": 40618,
        "start": 417.06,
        "temperature": 0,
        "text": " This is going to be different with any all different matrix",
        "tokens": [
          50908,
          639,
          307,
          516,
          281,
          312,
          819,
          365,
          604,
          439,
          819,
          8141,
          51046
        ]
      },
      {
        "avg_logprob": -0.2789331418331538,
        "compression_ratio": 1.6693548387096775,
        "end": 425.42,
        "id": 90,
        "no_speech_prob": 0.0000023320708351093344,
        "seek": 40618,
        "start": 420.06,
        "temperature": 0,
        "text": " Dimensions and after you watch this video you can make up lots of different matrices and play a game with yourself to like do this",
        "tokens": [
          51058,
          20975,
          8302,
          293,
          934,
          291,
          1159,
          341,
          960,
          291,
          393,
          652,
          493,
          3195,
          295,
          819,
          32284,
          293,
          862,
          257,
          1216,
          365,
          1803,
          281,
          411,
          360,
          341,
          51326
        ]
      },
      {
        "avg_logprob": -0.2789331418331538,
        "compression_ratio": 1.6693548387096775,
        "end": 431.14,
        "id": 91,
        "no_speech_prob": 0.0000023320708351093344,
        "seek": 40618,
        "start": 425.42,
        "temperature": 0,
        "text": " Matrix product with pencil and paper and boy won't that be fun. I'm gonna go do that later myself. I'm sure",
        "tokens": [
          51326,
          36274,
          1674,
          365,
          10985,
          293,
          3035,
          293,
          3237,
          1582,
          380,
          300,
          312,
          1019,
          13,
          286,
          478,
          799,
          352,
          360,
          300,
          1780,
          2059,
          13,
          286,
          478,
          988,
          51612
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 436.38,
        "id": 92,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 431.65999999999997,
        "temperature": 0,
        "text": " But here we can see I'm gonna get a square two by two matrix now. What am I doing here?",
        "tokens": [
          50390,
          583,
          510,
          321,
          393,
          536,
          286,
          478,
          799,
          483,
          257,
          3732,
          732,
          538,
          732,
          8141,
          586,
          13,
          708,
          669,
          286,
          884,
          510,
          30,
          50626
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 439.82,
        "id": 93,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 436.38,
        "temperature": 0,
        "text": " How do I fill in each of these blanks? So I'm gonna just",
        "tokens": [
          50626,
          1012,
          360,
          286,
          2836,
          294,
          1184,
          295,
          613,
          8247,
          82,
          30,
          407,
          286,
          478,
          799,
          445,
          50798
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 443.94,
        "id": 94,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 440.74,
        "temperature": 0,
        "text": " Put a little blank square here. I know I need two by two",
        "tokens": [
          50844,
          4935,
          257,
          707,
          8247,
          3732,
          510,
          13,
          286,
          458,
          286,
          643,
          732,
          538,
          732,
          51004
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 448.7,
        "id": 95,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 444.41999999999996,
        "temperature": 0,
        "text": " well, what I do is I take the dot product of",
        "tokens": [
          51028,
          731,
          11,
          437,
          286,
          360,
          307,
          286,
          747,
          264,
          5893,
          1674,
          295,
          51242
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 451.34,
        "id": 96,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 449.34,
        "temperature": 0,
        "text": " the row of the first one",
        "tokens": [
          51274,
          264,
          5386,
          295,
          264,
          700,
          472,
          51374
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 456.78,
        "id": 97,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 452.62,
        "temperature": 0,
        "text": " With the cup of the row of a with the column of B",
        "tokens": [
          51438,
          2022,
          264,
          4414,
          295,
          264,
          5386,
          295,
          257,
          365,
          264,
          7738,
          295,
          363,
          51646
        ]
      },
      {
        "avg_logprob": -0.2563610420570717,
        "compression_ratio": 1.6651785714285714,
        "end": 459.41999999999996,
        "id": 98,
        "no_speech_prob": 0.001187898451462388,
        "seek": 43114,
        "start": 457.41999999999996,
        "temperature": 0,
        "text": " Right, so it's almost kind of like the intersection",
        "tokens": [
          51678,
          1779,
          11,
          370,
          309,
          311,
          1920,
          733,
          295,
          411,
          264,
          15236,
          51778
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 465.90000000000003,
        "id": 99,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 460.18,
        "temperature": 0,
        "text": " This first element right I got to get the first row of a and the first column of B",
        "tokens": [
          50402,
          639,
          700,
          4478,
          558,
          286,
          658,
          281,
          483,
          264,
          700,
          5386,
          295,
          257,
          293,
          264,
          700,
          7738,
          295,
          363,
          50688
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 467.90000000000003,
        "id": 100,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 465.90000000000003,
        "temperature": 0,
        "text": " That's why they have to have the same number of",
        "tokens": [
          50688,
          663,
          311,
          983,
          436,
          362,
          281,
          362,
          264,
          912,
          1230,
          295,
          50788
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 474.58000000000004,
        "id": 101,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 468.3,
        "temperature": 0,
        "text": " Rows and B as columns in a so what this actually is this value here is the dot product of these two vectors",
        "tokens": [
          50808,
          497,
          1509,
          293,
          363,
          382,
          13766,
          294,
          257,
          370,
          437,
          341,
          767,
          307,
          341,
          2158,
          510,
          307,
          264,
          5893,
          1674,
          295,
          613,
          732,
          18875,
          51122
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 476.74,
        "id": 102,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 474.98,
        "temperature": 0,
        "text": " Which is?",
        "tokens": [
          51142,
          3013,
          307,
          30,
          51230
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 478.74,
        "id": 103,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 476.74,
        "temperature": 0,
        "text": " Actually, I'm just come over here",
        "tokens": [
          51230,
          5135,
          11,
          286,
          478,
          445,
          808,
          670,
          510,
          51330
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 481.78000000000003,
        "id": 104,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 479.78000000000003,
        "temperature": 0,
        "text": " Which is a?",
        "tokens": [
          51382,
          3013,
          307,
          257,
          30,
          51482
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 484.14,
        "id": 105,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 482.14,
        "temperature": 0,
        "text": " times G plus",
        "tokens": [
          51500,
          1413,
          460,
          1804,
          51600
        ]
      },
      {
        "avg_logprob": -0.3051085573561648,
        "compression_ratio": 1.5862068965517242,
        "end": 487.94,
        "id": 106,
        "no_speech_prob": 0.00003883108729496598,
        "seek": 45942,
        "start": 484.98,
        "temperature": 0,
        "text": " B times I plus",
        "tokens": [
          51642,
          363,
          1413,
          286,
          1804,
          51790
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 490.94,
        "id": 107,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 488.94,
        "temperature": 0,
        "text": " C times I",
        "tokens": [
          50414,
          383,
          1413,
          286,
          50514
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 497.21999999999997,
        "id": 108,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 491.54,
        "temperature": 0,
        "text": " Okay, so that's this element here now. Let's do this element here. Well. I'm in row one",
        "tokens": [
          50544,
          1033,
          11,
          370,
          300,
          311,
          341,
          4478,
          510,
          586,
          13,
          961,
          311,
          360,
          341,
          4478,
          510,
          13,
          1042,
          13,
          286,
          478,
          294,
          5386,
          472,
          50828
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 505.58,
        "id": 109,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 499.02,
        "temperature": 0,
        "text": " So I stay with row one of a but now I'm in column two so I go to column two of B",
        "tokens": [
          50918,
          407,
          286,
          1754,
          365,
          5386,
          472,
          295,
          257,
          457,
          586,
          286,
          478,
          294,
          7738,
          732,
          370,
          286,
          352,
          281,
          7738,
          732,
          295,
          363,
          51246
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 508.98,
        "id": 110,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 505.74,
        "temperature": 0,
        "text": " so now this particular value is a",
        "tokens": [
          51254,
          370,
          586,
          341,
          1729,
          2158,
          307,
          257,
          51416
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 511.7,
        "id": 111,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 509.86,
        "temperature": 0,
        "text": " times H",
        "tokens": [
          51460,
          1413,
          389,
          51552
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 513.06,
        "id": 112,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 511.7,
        "temperature": 0,
        "text": " plus",
        "tokens": [
          51552,
          1804,
          51620
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 515.06,
        "id": 113,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 513.06,
        "temperature": 0,
        "text": " B times J",
        "tokens": [
          51620,
          363,
          1413,
          508,
          51720
        ]
      },
      {
        "avg_logprob": -0.25126040854105136,
        "compression_ratio": 1.5384615384615385,
        "end": 517.02,
        "id": 114,
        "no_speech_prob": 0.00001451046955480706,
        "seek": 48794,
        "start": 515.7,
        "temperature": 0,
        "text": " plus",
        "tokens": [
          51752,
          1804,
          51818
        ]
      },
      {
        "avg_logprob": -0.2661184517734022,
        "compression_ratio": 1.8533333333333333,
        "end": 519.06,
        "id": 115,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 51702,
        "start": 517.06,
        "temperature": 0,
        "text": " C times L",
        "tokens": [
          50366,
          383,
          1413,
          441,
          50466
        ]
      },
      {
        "avg_logprob": -0.2661184517734022,
        "compression_ratio": 1.8533333333333333,
        "end": 525.8199999999999,
        "id": 116,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 51702,
        "start": 520.14,
        "temperature": 0,
        "text": " Okay, that's good. Now. Let me do this one this one is the second row",
        "tokens": [
          50520,
          1033,
          11,
          300,
          311,
          665,
          13,
          823,
          13,
          961,
          385,
          360,
          341,
          472,
          341,
          472,
          307,
          264,
          1150,
          5386,
          50804
        ]
      },
      {
        "avg_logprob": -0.2661184517734022,
        "compression_ratio": 1.8533333333333333,
        "end": 529.3,
        "id": 117,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 51702,
        "start": 527.3,
        "temperature": 0,
        "text": " times the first row",
        "tokens": [
          50878,
          1413,
          264,
          700,
          5386,
          50978
        ]
      },
      {
        "avg_logprob": -0.2661184517734022,
        "compression_ratio": 1.8533333333333333,
        "end": 534.9399999999999,
        "id": 118,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 51702,
        "start": 529.5799999999999,
        "temperature": 0,
        "text": " the first column of B D times G plus E times I plus F times K",
        "tokens": [
          50992,
          264,
          700,
          7738,
          295,
          363,
          413,
          1413,
          460,
          1804,
          462,
          1413,
          286,
          1804,
          479,
          1413,
          591,
          51260
        ]
      },
      {
        "avg_logprob": -0.2661184517734022,
        "compression_ratio": 1.8533333333333333,
        "end": 537.46,
        "id": 119,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 51702,
        "start": 534.9399999999999,
        "temperature": 0,
        "text": " And then this one here is going to be",
        "tokens": [
          51260,
          400,
          550,
          341,
          472,
          510,
          307,
          516,
          281,
          312,
          51386
        ]
      },
      {
        "avg_logprob": -0.2661184517734022,
        "compression_ratio": 1.8533333333333333,
        "end": 543.9399999999999,
        "id": 120,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 51702,
        "start": 538.02,
        "temperature": 0,
        "text": " The second row times the second column D times H plus E times J plus F times L",
        "tokens": [
          51414,
          440,
          1150,
          5386,
          1413,
          264,
          1150,
          7738,
          413,
          1413,
          389,
          1804,
          462,
          1413,
          508,
          1804,
          479,
          1413,
          441,
          51710
        ]
      },
      {
        "avg_logprob": -0.26937432911085046,
        "compression_ratio": 1.7136752136752136,
        "end": 548.94,
        "id": 121,
        "no_speech_prob": 0.00006922169995959848,
        "seek": 54394,
        "start": 543.94,
        "temperature": 0,
        "text": " Okay, so that's the math for any arbitrary set of matrices",
        "tokens": [
          50364,
          1033,
          11,
          370,
          300,
          311,
          264,
          5221,
          337,
          604,
          23211,
          992,
          295,
          32284,
          50614
        ]
      },
      {
        "avg_logprob": -0.26937432911085046,
        "compression_ratio": 1.7136752136752136,
        "end": 554.98,
        "id": 122,
        "no_speech_prob": 0.00006922169995959848,
        "seek": 54394,
        "start": 549.0200000000001,
        "temperature": 0,
        "text": " You take the dot product of all the rows with the columns to fill out your resulting matrix product",
        "tokens": [
          50618,
          509,
          747,
          264,
          5893,
          1674,
          295,
          439,
          264,
          13241,
          365,
          264,
          13766,
          281,
          2836,
          484,
          428,
          16505,
          8141,
          1674,
          50916
        ]
      },
      {
        "avg_logprob": -0.26937432911085046,
        "compression_ratio": 1.7136752136752136,
        "end": 559.82,
        "id": 123,
        "no_speech_prob": 0.00006922169995959848,
        "seek": 54394,
        "start": 554.98,
        "temperature": 0,
        "text": " And you must have the same number of columns in a as rows of B",
        "tokens": [
          50916,
          400,
          291,
          1633,
          362,
          264,
          912,
          1230,
          295,
          13766,
          294,
          257,
          382,
          13241,
          295,
          363,
          51158
        ]
      },
      {
        "avg_logprob": -0.26937432911085046,
        "compression_ratio": 1.7136752136752136,
        "end": 567.9000000000001,
        "id": 124,
        "no_speech_prob": 0.00006922169995959848,
        "seek": 54394,
        "start": 560.62,
        "temperature": 0,
        "text": " Okay, so pause this video if you want try to draw some diagram Google matrix product Google image search matrix product",
        "tokens": [
          51198,
          1033,
          11,
          370,
          10465,
          341,
          960,
          498,
          291,
          528,
          853,
          281,
          2642,
          512,
          10686,
          3329,
          8141,
          1674,
          3329,
          3256,
          3164,
          8141,
          1674,
          51562
        ]
      },
      {
        "avg_logprob": -0.26937432911085046,
        "compression_ratio": 1.7136752136752136,
        "end": 570.1,
        "id": 125,
        "no_speech_prob": 0.00006922169995959848,
        "seek": 54394,
        "start": 567.9000000000001,
        "temperature": 0,
        "text": " You probably come up with a million visual examples of this",
        "tokens": [
          51562,
          509,
          1391,
          808,
          493,
          365,
          257,
          2459,
          5056,
          5110,
          295,
          341,
          51672
        ]
      },
      {
        "avg_logprob": -0.3342997302179751,
        "compression_ratio": 1.5780590717299579,
        "end": 577.14,
        "id": 126,
        "no_speech_prob": 0.0010004965588450432,
        "seek": 57010,
        "start": 570.58,
        "temperature": 0,
        "text": " Watch three blue one Browns videos on linear algebra will probably teach this in a much more intuitive a nice way, but I",
        "tokens": [
          50388,
          7277,
          1045,
          3344,
          472,
          8030,
          82,
          2145,
          322,
          8213,
          21989,
          486,
          1391,
          2924,
          341,
          294,
          257,
          709,
          544,
          21769,
          257,
          1481,
          636,
          11,
          457,
          286,
          50716
        ]
      },
      {
        "avg_logprob": -0.3342997302179751,
        "compression_ratio": 1.5780590717299579,
        "end": 582.5400000000001,
        "id": 127,
        "no_speech_prob": 0.0010004965588450432,
        "seek": 57010,
        "start": 578.0600000000001,
        "temperature": 0,
        "text": " I'll link to that in this video's description. I'm now going to try to implement this matrix product in code",
        "tokens": [
          50762,
          286,
          603,
          2113,
          281,
          300,
          294,
          341,
          960,
          311,
          3855,
          13,
          286,
          478,
          586,
          516,
          281,
          853,
          281,
          4445,
          341,
          8141,
          1674,
          294,
          3089,
          50986
        ]
      },
      {
        "avg_logprob": -0.3342997302179751,
        "compression_ratio": 1.5780590717299579,
        "end": 585.86,
        "id": 128,
        "no_speech_prob": 0.0010004965588450432,
        "seek": 57010,
        "start": 583.38,
        "temperature": 0,
        "text": " Minor correction hopefully I said the right thing",
        "tokens": [
          51028,
          36117,
          19984,
          4696,
          286,
          848,
          264,
          558,
          551,
          51152
        ]
      },
      {
        "avg_logprob": -0.3342997302179751,
        "compression_ratio": 1.5780590717299579,
        "end": 592.02,
        "id": 129,
        "no_speech_prob": 0.0010004965588450432,
        "seek": 57010,
        "start": 586.26,
        "temperature": 0,
        "text": " But I do have something wrong here a times G B times I C times K",
        "tokens": [
          51172,
          583,
          286,
          360,
          362,
          746,
          2085,
          510,
          257,
          1413,
          460,
          363,
          1413,
          286,
          383,
          1413,
          591,
          51460
        ]
      },
      {
        "avg_logprob": -0.3342997302179751,
        "compression_ratio": 1.5780590717299579,
        "end": 595.3000000000001,
        "id": 130,
        "no_speech_prob": 0.0010004965588450432,
        "seek": 57010,
        "start": 592.74,
        "temperature": 0,
        "text": " This should be a K right here",
        "tokens": [
          51496,
          639,
          820,
          312,
          257,
          591,
          558,
          510,
          51624
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 597.38,
        "id": 131,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 595.38,
        "temperature": 0,
        "text": " Tada",
        "tokens": [
          50368,
          39303,
          50468
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 599.78,
        "id": 132,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 597.38,
        "temperature": 0,
        "text": " Okay, so let's try to implement the math for this",
        "tokens": [
          50468,
          1033,
          11,
          370,
          718,
          311,
          853,
          281,
          4445,
          264,
          5221,
          337,
          341,
          50588
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 605.3,
        "id": 133,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 599.9,
        "temperature": 0,
        "text": " So where I'm gonna do this is in the multiply function and I had written that before to do scalar",
        "tokens": [
          50594,
          407,
          689,
          286,
          478,
          799,
          360,
          341,
          307,
          294,
          264,
          12972,
          2445,
          293,
          286,
          632,
          3720,
          300,
          949,
          281,
          360,
          39684,
          50864
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 609.5,
        "id": 134,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 605.5799999999999,
        "temperature": 0,
        "text": " Multiplication and I'm gonna do the same thing I did an ad where I'm gonna check",
        "tokens": [
          50878,
          29238,
          4770,
          399,
          293,
          286,
          478,
          799,
          360,
          264,
          912,
          551,
          286,
          630,
          364,
          614,
          689,
          286,
          478,
          799,
          1520,
          51074
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 613.26,
        "id": 135,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 609.54,
        "temperature": 0,
        "text": " What is the thing coming in is it a matrix or is it a scalar or?",
        "tokens": [
          51076,
          708,
          307,
          264,
          551,
          1348,
          294,
          307,
          309,
          257,
          8141,
          420,
          307,
          309,
          257,
          39684,
          420,
          30,
          51262
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 617.06,
        "id": 136,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 614.3,
        "temperature": 0,
        "text": " Etc. So I'm not gonna bother with the Hadamard product",
        "tokens": [
          51314,
          3790,
          66,
          13,
          407,
          286,
          478,
          406,
          799,
          8677,
          365,
          264,
          12298,
          335,
          515,
          1674,
          51452
        ]
      },
      {
        "avg_logprob": -0.2945987203846807,
        "compression_ratio": 1.6942148760330578,
        "end": 620.8599999999999,
        "id": 137,
        "no_speech_prob": 0.0015487453201785684,
        "seek": 59530,
        "start": 617.8199999999999,
        "temperature": 0,
        "text": " I'll add that into this matrix library if I ever need it",
        "tokens": [
          51490,
          286,
          603,
          909,
          300,
          666,
          341,
          8141,
          6405,
          498,
          286,
          1562,
          643,
          309,
          51642
        ]
      },
      {
        "avg_logprob": -0.27653547922770183,
        "compression_ratio": 1.7216494845360826,
        "end": 628.54,
        "id": 138,
        "no_speech_prob": 0.000014510461369354744,
        "seek": 62086,
        "start": 621.38,
        "temperature": 0,
        "text": " But I'm just gonna check is n an instance of a matrix if that's so then I want to do matrix product",
        "tokens": [
          50390,
          583,
          286,
          478,
          445,
          799,
          1520,
          307,
          297,
          364,
          5197,
          295,
          257,
          8141,
          498,
          300,
          311,
          370,
          550,
          286,
          528,
          281,
          360,
          8141,
          1674,
          50748
        ]
      },
      {
        "avg_logprob": -0.27653547922770183,
        "compression_ratio": 1.7216494845360826,
        "end": 632.78,
        "id": 139,
        "no_speech_prob": 0.000014510461369354744,
        "seek": 62086,
        "start": 630.34,
        "temperature": 0,
        "text": " Otherwise I want to do a",
        "tokens": [
          50838,
          10328,
          286,
          528,
          281,
          360,
          257,
          50960
        ]
      },
      {
        "avg_logprob": -0.27653547922770183,
        "compression_ratio": 1.7216494845360826,
        "end": 637.34,
        "id": 140,
        "no_speech_prob": 0.000014510461369354744,
        "seek": 62086,
        "start": 635.46,
        "temperature": 0,
        "text": " Scalar product",
        "tokens": [
          51094,
          2747,
          12031,
          1674,
          51188
        ]
      },
      {
        "avg_logprob": -0.27653547922770183,
        "compression_ratio": 1.7216494845360826,
        "end": 641.14,
        "id": 141,
        "no_speech_prob": 0.000014510461369354744,
        "seek": 62086,
        "start": 637.34,
        "temperature": 0,
        "text": " Okay, so now I need to write the code for the matrix product right there",
        "tokens": [
          51188,
          1033,
          11,
          370,
          586,
          286,
          643,
          281,
          2464,
          264,
          3089,
          337,
          264,
          8141,
          1674,
          558,
          456,
          51378
        ]
      },
      {
        "avg_logprob": -0.27653547922770183,
        "compression_ratio": 1.7216494845360826,
        "end": 643.74,
        "id": 142,
        "no_speech_prob": 0.000014510461369354744,
        "seek": 62086,
        "start": 641.66,
        "temperature": 0,
        "text": " But first I must check",
        "tokens": [
          51404,
          583,
          700,
          286,
          1633,
          1520,
          51508
        ]
      },
      {
        "avg_logprob": -0.27653547922770183,
        "compression_ratio": 1.7216494845360826,
        "end": 649.94,
        "id": 143,
        "no_speech_prob": 0.000014510461369354744,
        "seek": 62086,
        "start": 644.54,
        "temperature": 0,
        "text": " Are the columns of a equal to the rows of B? Otherwise, I cannot perform the matrix product at all",
        "tokens": [
          51548,
          2014,
          264,
          13766,
          295,
          257,
          2681,
          281,
          264,
          13241,
          295,
          363,
          30,
          10328,
          11,
          286,
          2644,
          2042,
          264,
          8141,
          1674,
          412,
          439,
          51818
        ]
      },
      {
        "avg_logprob": -0.35249074300130206,
        "compression_ratio": 1.563157894736842,
        "end": 652.5400000000001,
        "id": 144,
        "no_speech_prob": 0.00007722166628809646,
        "seek": 64994,
        "start": 650.46,
        "temperature": 0,
        "text": " So I'm gonna come over here and I'm gonna say",
        "tokens": [
          50390,
          407,
          286,
          478,
          799,
          808,
          670,
          510,
          293,
          286,
          478,
          799,
          584,
          50494
        ]
      },
      {
        "avg_logprob": -0.35249074300130206,
        "compression_ratio": 1.563157894736842,
        "end": 657.82,
        "id": 145,
        "no_speech_prob": 0.00007722166628809646,
        "seek": 64994,
        "start": 654.94,
        "temperature": 0,
        "text": " If I'm in the right screen, yes if",
        "tokens": [
          50614,
          759,
          286,
          478,
          294,
          264,
          558,
          2568,
          11,
          2086,
          498,
          50758
        ]
      },
      {
        "avg_logprob": -0.35249074300130206,
        "compression_ratio": 1.563157894736842,
        "end": 664.3000000000001,
        "id": 146,
        "no_speech_prob": 0.00007722166628809646,
        "seek": 64994,
        "start": 659.4200000000001,
        "temperature": 0,
        "text": " The a is this matrix object if this dot rows",
        "tokens": [
          50838,
          440,
          257,
          307,
          341,
          8141,
          2657,
          498,
          341,
          5893,
          13241,
          51082
        ]
      },
      {
        "avg_logprob": -0.35249074300130206,
        "compression_ratio": 1.563157894736842,
        "end": 669.7,
        "id": 147,
        "no_speech_prob": 0.00007722166628809646,
        "seek": 64994,
        "start": 664.3000000000001,
        "temperature": 0,
        "text": " No, if this dot columns does not equal n dot rows. I",
        "tokens": [
          51082,
          883,
          11,
          498,
          341,
          5893,
          13766,
          775,
          406,
          2681,
          297,
          5893,
          13241,
          13,
          286,
          51352
        ]
      },
      {
        "avg_logprob": -0.35249074300130206,
        "compression_ratio": 1.563157894736842,
        "end": 673.2600000000001,
        "id": 148,
        "no_speech_prob": 0.00007722166628809646,
        "seek": 64994,
        "start": 670.7,
        "temperature": 0,
        "text": " Kind of don't like that. This is called n here, but whatever",
        "tokens": [
          51402,
          9242,
          295,
          500,
          380,
          411,
          300,
          13,
          639,
          307,
          1219,
          297,
          510,
          11,
          457,
          2035,
          51530
        ]
      },
      {
        "avg_logprob": -0.35249074300130206,
        "compression_ratio": 1.563157894736842,
        "end": 678.58,
        "id": 149,
        "no_speech_prob": 0.00007722166628809646,
        "seek": 64994,
        "start": 674.3000000000001,
        "temperature": 0,
        "text": " Does then and I'll use this more strict equals here then?",
        "tokens": [
          51582,
          4402,
          550,
          293,
          286,
          603,
          764,
          341,
          544,
          10910,
          6915,
          510,
          550,
          30,
          51796
        ]
      },
      {
        "avg_logprob": -0.2602035102494266,
        "compression_ratio": 1.6763485477178424,
        "end": 687.1400000000001,
        "id": 150,
        "no_speech_prob": 0.00029136918601579964,
        "seek": 67994,
        "start": 679.94,
        "temperature": 0,
        "text": " Id to return like undefined or something like just get out of here. This is no good and I'm going to console dot log",
        "tokens": [
          50364,
          11506,
          281,
          2736,
          411,
          674,
          5666,
          2001,
          420,
          746,
          411,
          445,
          483,
          484,
          295,
          510,
          13,
          639,
          307,
          572,
          665,
          293,
          286,
          478,
          516,
          281,
          11076,
          5893,
          3565,
          50724
        ]
      },
      {
        "avg_logprob": -0.2602035102494266,
        "compression_ratio": 1.6763485477178424,
        "end": 693.9000000000001,
        "id": 151,
        "no_speech_prob": 0.00029136918601579964,
        "seek": 67994,
        "start": 689.7800000000001,
        "temperature": 0,
        "text": " Columns of a must match rows of B",
        "tokens": [
          50856,
          4004,
          449,
          3695,
          295,
          257,
          1633,
          2995,
          13241,
          295,
          363,
          51062
        ]
      },
      {
        "avg_logprob": -0.2602035102494266,
        "compression_ratio": 1.6763485477178424,
        "end": 699.1,
        "id": 152,
        "no_speech_prob": 0.00029136918601579964,
        "seek": 67994,
        "start": 695.34,
        "temperature": 0,
        "text": " Columns now I could be more thoughtful and I can use a try catch and some error handling",
        "tokens": [
          51134,
          4004,
          449,
          3695,
          586,
          286,
          727,
          312,
          544,
          21566,
          293,
          286,
          393,
          764,
          257,
          853,
          3745,
          293,
          512,
          6713,
          13175,
          51322
        ]
      },
      {
        "avg_logprob": -0.2602035102494266,
        "compression_ratio": 1.6763485477178424,
        "end": 703.22,
        "id": 153,
        "no_speech_prob": 0.00029136918601579964,
        "seek": 67994,
        "start": 699.1,
        "temperature": 0,
        "text": " But I'm just gonna do this for right now just to be some and let's actually make sure this works",
        "tokens": [
          51322,
          583,
          286,
          478,
          445,
          799,
          360,
          341,
          337,
          558,
          586,
          445,
          281,
          312,
          512,
          293,
          718,
          311,
          767,
          652,
          988,
          341,
          1985,
          51528
        ]
      },
      {
        "avg_logprob": -0.2602035102494266,
        "compression_ratio": 1.6763485477178424,
        "end": 705.58,
        "id": 154,
        "no_speech_prob": 0.00029136918601579964,
        "seek": 67994,
        "start": 703.58,
        "temperature": 0,
        "text": " so if I go back to",
        "tokens": [
          51546,
          370,
          498,
          286,
          352,
          646,
          281,
          51646
        ]
      },
      {
        "avg_logprob": -0.2602035102494266,
        "compression_ratio": 1.6763485477178424,
        "end": 709.2600000000001,
        "id": 155,
        "no_speech_prob": 0.00029136918601579964,
        "seek": 67994,
        "start": 705.6600000000001,
        "temperature": 0,
        "text": " loading that code and I said something like a is",
        "tokens": [
          51650,
          15114,
          300,
          3089,
          293,
          286,
          848,
          746,
          411,
          257,
          307,
          51830
        ]
      },
      {
        "avg_logprob": -0.2701208808205344,
        "compression_ratio": 1.4087591240875912,
        "end": 711.94,
        "id": 156,
        "no_speech_prob": 0.00001723153945931699,
        "seek": 70994,
        "start": 709.94,
        "temperature": 0,
        "text": " matrix",
        "tokens": [
          50364,
          8141,
          50464
        ]
      },
      {
        "avg_logprob": -0.2701208808205344,
        "compression_ratio": 1.4087591240875912,
        "end": 718.5400000000001,
        "id": 157,
        "no_speech_prob": 0.00001723153945931699,
        "seek": 70994,
        "start": 712.3000000000001,
        "temperature": 0,
        "text": " That is 3 by 3 and B is a matrix that is 5 by 10",
        "tokens": [
          50482,
          663,
          307,
          805,
          538,
          805,
          293,
          363,
          307,
          257,
          8141,
          300,
          307,
          1025,
          538,
          1266,
          50794
        ]
      },
      {
        "avg_logprob": -0.2701208808205344,
        "compression_ratio": 1.4087591240875912,
        "end": 721.5,
        "id": 158,
        "no_speech_prob": 0.00001723153945931699,
        "seek": 70994,
        "start": 719.5,
        "temperature": 0,
        "text": " if I say a",
        "tokens": [
          50842,
          498,
          286,
          584,
          257,
          50942
        ]
      },
      {
        "avg_logprob": -0.2701208808205344,
        "compression_ratio": 1.4087591240875912,
        "end": 723.7,
        "id": 159,
        "no_speech_prob": 0.00001723153945931699,
        "seek": 70994,
        "start": 721.7,
        "temperature": 0,
        "text": " multiply B I",
        "tokens": [
          50952,
          12972,
          363,
          286,
          51052
        ]
      },
      {
        "avg_logprob": -0.2701208808205344,
        "compression_ratio": 1.4087591240875912,
        "end": 730.34,
        "id": 160,
        "no_speech_prob": 0.00001723153945931699,
        "seek": 70994,
        "start": 724.5400000000001,
        "temperature": 0,
        "text": " Get undefined and it says columns of a must match rows of B. So that's working and I could just say",
        "tokens": [
          51094,
          3240,
          674,
          5666,
          2001,
          293,
          309,
          1619,
          13766,
          295,
          257,
          1633,
          2995,
          13241,
          295,
          363,
          13,
          407,
          300,
          311,
          1364,
          293,
          286,
          727,
          445,
          584,
          51384
        ]
      },
      {
        "avg_logprob": -0.2701208808205344,
        "compression_ratio": 1.4087591240875912,
        "end": 733.1,
        "id": 161,
        "no_speech_prob": 0.00001723153945931699,
        "seek": 70994,
        "start": 731.1,
        "temperature": 0,
        "text": " B is a matrix",
        "tokens": [
          51422,
          363,
          307,
          257,
          8141,
          51522
        ]
      },
      {
        "avg_logprob": -0.34654217231564405,
        "compression_ratio": 1.4480874316939891,
        "end": 735.98,
        "id": 162,
        "no_speech_prob": 0.0002305055968463421,
        "seek": 73310,
        "start": 733.98,
        "temperature": 0,
        "text": " Of",
        "tokens": [
          50408,
          2720,
          50508
        ]
      },
      {
        "avg_logprob": -0.34654217231564405,
        "compression_ratio": 1.4480874316939891,
        "end": 742.34,
        "id": 163,
        "no_speech_prob": 0.0002305055968463421,
        "seek": 73310,
        "start": 737.5400000000001,
        "temperature": 0,
        "text": " 5 by sorry 3 by 3 also then they match and I'm say a multiply",
        "tokens": [
          50586,
          1025,
          538,
          2597,
          805,
          538,
          805,
          611,
          550,
          436,
          2995,
          293,
          286,
          478,
          584,
          257,
          12972,
          50826
        ]
      },
      {
        "avg_logprob": -0.34654217231564405,
        "compression_ratio": 1.4480874316939891,
        "end": 750.5,
        "id": 164,
        "no_speech_prob": 0.0002305055968463421,
        "seek": 73310,
        "start": 743.02,
        "temperature": 0,
        "text": " B I still get undefined because I haven't done it yet, but I don't get that error message. Okay, so now I need to create a",
        "tokens": [
          50860,
          363,
          286,
          920,
          483,
          674,
          5666,
          2001,
          570,
          286,
          2378,
          380,
          1096,
          309,
          1939,
          11,
          457,
          286,
          500,
          380,
          483,
          300,
          6713,
          3636,
          13,
          1033,
          11,
          370,
          586,
          286,
          643,
          281,
          1884,
          257,
          51234
        ]
      },
      {
        "avg_logprob": -0.34654217231564405,
        "compression_ratio": 1.4480874316939891,
        "end": 752.4200000000001,
        "id": 165,
        "no_speech_prob": 0.0002305055968463421,
        "seek": 73310,
        "start": 750.5400000000001,
        "temperature": 0,
        "text": " new matrix",
        "tokens": [
          51236,
          777,
          8141,
          51330
        ]
      },
      {
        "avg_logprob": -0.34654217231564405,
        "compression_ratio": 1.4480874316939891,
        "end": 754.4200000000001,
        "id": 166,
        "no_speech_prob": 0.0002305055968463421,
        "seek": 73310,
        "start": 752.4200000000001,
        "temperature": 0,
        "text": " So I'm gonna say the result",
        "tokens": [
          51330,
          407,
          286,
          478,
          799,
          584,
          264,
          1874,
          51430
        ]
      },
      {
        "avg_logprob": -0.34654217231564405,
        "compression_ratio": 1.4480874316939891,
        "end": 759.82,
        "id": 167,
        "no_speech_prob": 0.0002305055968463421,
        "seek": 73310,
        "start": 756.02,
        "temperature": 0,
        "text": " Is a new matrix that has the number of",
        "tokens": [
          51510,
          1119,
          257,
          777,
          8141,
          300,
          575,
          264,
          1230,
          295,
          51700
        ]
      },
      {
        "avg_logprob": -0.5091785528720953,
        "compression_ratio": 1.7483443708609272,
        "end": 766.38,
        "id": 168,
        "no_speech_prob": 0.000008013482329261024,
        "seek": 75982,
        "start": 759.98,
        "temperature": 0,
        "text": " What did I say it has the number of rows of a and the number of columns of B",
        "tokens": [
          50372,
          708,
          630,
          286,
          584,
          309,
          575,
          264,
          1230,
          295,
          13241,
          295,
          257,
          293,
          264,
          1230,
          295,
          13766,
          295,
          363,
          50692
        ]
      },
      {
        "avg_logprob": -0.5091785528720953,
        "compression_ratio": 1.7483443708609272,
        "end": 773.82,
        "id": 169,
        "no_speech_prob": 0.000008013482329261024,
        "seek": 75982,
        "start": 767.7800000000001,
        "temperature": 0,
        "text": " So it has the number of rows of a and the number of columns of B",
        "tokens": [
          50762,
          407,
          309,
          575,
          264,
          1230,
          295,
          13241,
          295,
          257,
          293,
          264,
          1230,
          295,
          13766,
          295,
          363,
          51064
        ]
      },
      {
        "avg_logprob": -0.5091785528720953,
        "compression_ratio": 1.7483443708609272,
        "end": 777.5400000000001,
        "id": 170,
        "no_speech_prob": 0.000008013482329261024,
        "seek": 75982,
        "start": 775.5400000000001,
        "temperature": 0,
        "text": " Come on",
        "tokens": [
          51150,
          2492,
          322,
          51250
        ]
      },
      {
        "avg_logprob": -0.5091785528720953,
        "compression_ratio": 1.7483443708609272,
        "end": 780.0600000000001,
        "id": 171,
        "no_speech_prob": 0.000008013482329261024,
        "seek": 75982,
        "start": 777.58,
        "temperature": 0,
        "text": " Adam keeps wanting me to put my password in okay",
        "tokens": [
          51252,
          7938,
          5965,
          7935,
          385,
          281,
          829,
          452,
          11524,
          294,
          1392,
          51376
        ]
      },
      {
        "avg_logprob": -0.5091785528720953,
        "compression_ratio": 1.7483443708609272,
        "end": 787.0600000000001,
        "id": 172,
        "no_speech_prob": 0.000008013482329261024,
        "seek": 75982,
        "start": 780.9000000000001,
        "temperature": 0,
        "text": " Alright, so that's good. Now. I need to do each spot. So for each",
        "tokens": [
          51418,
          2798,
          11,
          370,
          300,
          311,
          665,
          13,
          823,
          13,
          286,
          643,
          281,
          360,
          1184,
          4008,
          13,
          407,
          337,
          1184,
          51726
        ]
      },
      {
        "avg_logprob": -0.3338568870057451,
        "compression_ratio": 1.3457943925233644,
        "end": 791.2199999999999,
        "id": 173,
        "no_speech_prob": 0.00024536659475415945,
        "seek": 78706,
        "start": 787.66,
        "temperature": 0,
        "text": " For each row whoops",
        "tokens": [
          50394,
          1171,
          1184,
          5386,
          567,
          3370,
          50572
        ]
      },
      {
        "avg_logprob": -0.3338568870057451,
        "compression_ratio": 1.3457943925233644,
        "end": 803.8199999999999,
        "id": 174,
        "no_speech_prob": 0.00024536659475415945,
        "seek": 78706,
        "start": 797.6199999999999,
        "temperature": 0,
        "text": " For each row and for each column I",
        "tokens": [
          50892,
          1171,
          1184,
          5386,
          293,
          337,
          1184,
          7738,
          286,
          51202
        ]
      },
      {
        "avg_logprob": -0.3338568870057451,
        "compression_ratio": 1.3457943925233644,
        "end": 809.06,
        "id": 175,
        "no_speech_prob": 0.00024536659475415945,
        "seek": 78706,
        "start": 807.14,
        "temperature": 0,
        "text": " Need to",
        "tokens": [
          51368,
          16984,
          281,
          51464
        ]
      },
      {
        "avg_logprob": -0.3338568870057451,
        "compression_ratio": 1.3457943925233644,
        "end": 810.3399999999999,
        "id": 176,
        "no_speech_prob": 0.00024536659475415945,
        "seek": 78706,
        "start": 809.06,
        "temperature": 0,
        "text": " do",
        "tokens": [
          51464,
          360,
          51528
        ]
      },
      {
        "avg_logprob": -0.3338568870057451,
        "compression_ratio": 1.3457943925233644,
        "end": 812.3399999999999,
        "id": 177,
        "no_speech_prob": 0.00024536659475415945,
        "seek": 78706,
        "start": 810.3399999999999,
        "temperature": 0,
        "text": " the dot product of",
        "tokens": [
          51528,
          264,
          5893,
          1674,
          295,
          51628
        ]
      },
      {
        "avg_logprob": -0.3338568870057451,
        "compression_ratio": 1.3457943925233644,
        "end": 816.18,
        "id": 178,
        "no_speech_prob": 0.00024536659475415945,
        "seek": 78706,
        "start": 813.8599999999999,
        "temperature": 0,
        "text": " Whoops first of all, I have an error before I could do this",
        "tokens": [
          51704,
          45263,
          700,
          295,
          439,
          11,
          286,
          362,
          364,
          6713,
          949,
          286,
          727,
          360,
          341,
          51820
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 819.06,
        "id": 179,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 817.06,
        "temperature": 0,
        "text": " I have an error here and",
        "tokens": [
          50364,
          286,
          362,
          364,
          6713,
          510,
          293,
          50464
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 822.4599999999999,
        "id": 180,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 819.6999999999999,
        "temperature": 0,
        "text": " What I want is if I'm at 0 0 I",
        "tokens": [
          50496,
          708,
          286,
          528,
          307,
          498,
          286,
          478,
          412,
          1958,
          1958,
          286,
          50634
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 827.6199999999999,
        "id": 181,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 823.06,
        "temperature": 0,
        "text": " Want all of the values I'm going to do the sum of all of the values",
        "tokens": [
          50664,
          11773,
          439,
          295,
          264,
          4190,
          286,
          478,
          516,
          281,
          360,
          264,
          2408,
          295,
          439,
          295,
          264,
          4190,
          50892
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 830.14,
        "id": 182,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 828.14,
        "temperature": 0,
        "text": " Whoa, so I want",
        "tokens": [
          50918,
          7521,
          11,
          370,
          286,
          528,
          51018
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 836.7399999999999,
        "id": 183,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 831.9799999999999,
        "temperature": 0,
        "text": " Let's just do this manually in this case it would be",
        "tokens": [
          51110,
          961,
          311,
          445,
          360,
          341,
          16945,
          294,
          341,
          1389,
          309,
          576,
          312,
          51348
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 840.8599999999999,
        "id": 184,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 838.18,
        "temperature": 0,
        "text": " this dot matrix I",
        "tokens": [
          51420,
          341,
          5893,
          8141,
          286,
          51554
        ]
      },
      {
        "avg_logprob": -0.3447638846732475,
        "compression_ratio": 1.5472972972972974,
        "end": 845.66,
        "id": 185,
        "no_speech_prob": 0.0000021568155261775246,
        "seek": 81706,
        "start": 843.02,
        "temperature": 0,
        "text": " Times n dot matrix",
        "tokens": [
          51662,
          11366,
          297,
          5893,
          8141,
          51794
        ]
      },
      {
        "avg_logprob": -0.32620283535548616,
        "compression_ratio": 1.3615384615384616,
        "end": 849.2199999999999,
        "id": 186,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 84706,
        "start": 847.2199999999999,
        "temperature": 0,
        "text": " J",
        "tokens": [
          50372,
          508,
          50472
        ]
      },
      {
        "avg_logprob": -0.32620283535548616,
        "compression_ratio": 1.3615384615384616,
        "end": 851.3,
        "id": 187,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 84706,
        "start": 849.3,
        "temperature": 0,
        "text": " What sorry I I",
        "tokens": [
          50476,
          708,
          2597,
          286,
          286,
          50576
        ]
      },
      {
        "avg_logprob": -0.32620283535548616,
        "compression_ratio": 1.3615384615384616,
        "end": 859.0999999999999,
        "id": 188,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 84706,
        "start": 852.02,
        "temperature": 0,
        "text": " Need yeah, I need another double nested loop in here right because I'm gonna take this and add I",
        "tokens": [
          50612,
          16984,
          1338,
          11,
          286,
          643,
          1071,
          3834,
          15646,
          292,
          6367,
          294,
          510,
          558,
          570,
          286,
          478,
          799,
          747,
          341,
          293,
          909,
          286,
          50966
        ]
      },
      {
        "avg_logprob": -0.32620283535548616,
        "compression_ratio": 1.3615384615384616,
        "end": 864.9,
        "id": 189,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 84706,
        "start": 862.6199999999999,
        "temperature": 0,
        "text": " Plus plus one",
        "tokens": [
          51142,
          7721,
          1804,
          472,
          51256
        ]
      },
      {
        "avg_logprob": -0.32620283535548616,
        "compression_ratio": 1.3615384615384616,
        "end": 868.7399999999999,
        "id": 190,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 84706,
        "start": 866.7399999999999,
        "temperature": 0,
        "text": " But staying in J",
        "tokens": [
          51348,
          583,
          7939,
          294,
          508,
          51448
        ]
      },
      {
        "avg_logprob": -0.32620283535548616,
        "compression_ratio": 1.3615384615384616,
        "end": 871.8599999999999,
        "id": 191,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 84706,
        "start": 869.4599999999999,
        "temperature": 0,
        "text": " J plus one right is this right I",
        "tokens": [
          51484,
          508,
          1804,
          472,
          558,
          307,
          341,
          558,
          286,
          51604
        ]
      },
      {
        "avg_logprob": -0.2633791084749153,
        "compression_ratio": 1.6630434782608696,
        "end": 874.86,
        "id": 192,
        "no_speech_prob": 0.000014738950994797051,
        "seek": 87186,
        "start": 872.86,
        "temperature": 0,
        "text": " Plus two",
        "tokens": [
          50414,
          7721,
          732,
          50514
        ]
      },
      {
        "avg_logprob": -0.2633791084749153,
        "compression_ratio": 1.6630434782608696,
        "end": 881.46,
        "id": 193,
        "no_speech_prob": 0.000014738950994797051,
        "seek": 87186,
        "start": 875.0600000000001,
        "temperature": 0,
        "text": " J plus two I mean this isn't I'm making this up because I don't I'm doing this in an arbitrary way",
        "tokens": [
          50524,
          508,
          1804,
          732,
          286,
          914,
          341,
          1943,
          380,
          286,
          478,
          1455,
          341,
          493,
          570,
          286,
          500,
          380,
          286,
          478,
          884,
          341,
          294,
          364,
          23211,
          636,
          50844
        ]
      },
      {
        "avg_logprob": -0.2633791084749153,
        "compression_ratio": 1.6630434782608696,
        "end": 885.54,
        "id": 194,
        "no_speech_prob": 0.000014738950994797051,
        "seek": 87186,
        "start": 881.46,
        "temperature": 0,
        "text": " we don't know what the actual rows this this just goes up depending on the number of",
        "tokens": [
          50844,
          321,
          500,
          380,
          458,
          437,
          264,
          3539,
          13241,
          341,
          341,
          445,
          1709,
          493,
          5413,
          322,
          264,
          1230,
          295,
          51048
        ]
      },
      {
        "avg_logprob": -0.2633791084749153,
        "compression_ratio": 1.6630434782608696,
        "end": 891.5,
        "id": 195,
        "no_speech_prob": 0.000014738950994797051,
        "seek": 87186,
        "start": 888.94,
        "temperature": 0,
        "text": " Rows columns there are all right, right",
        "tokens": [
          51218,
          497,
          1509,
          13766,
          456,
          366,
          439,
          558,
          11,
          558,
          51346
        ]
      },
      {
        "avg_logprob": -0.2633791084749153,
        "compression_ratio": 1.6630434782608696,
        "end": 898.4200000000001,
        "id": 196,
        "no_speech_prob": 0.000014738950994797051,
        "seek": 87186,
        "start": 893.54,
        "temperature": 0,
        "text": " So maybe I only need one loop here because I need one loop so what's that",
        "tokens": [
          51448,
          407,
          1310,
          286,
          787,
          643,
          472,
          6367,
          510,
          570,
          286,
          643,
          472,
          6367,
          370,
          437,
          311,
          300,
          51692
        ]
      },
      {
        "avg_logprob": -0.3578145226766897,
        "compression_ratio": 1.64,
        "end": 902.26,
        "id": 197,
        "no_speech_prob": 0.00004832550621358678,
        "seek": 89842,
        "start": 898.9399999999999,
        "temperature": 0,
        "text": " Oh, no because these could be different yeah",
        "tokens": [
          50390,
          876,
          11,
          572,
          570,
          613,
          727,
          312,
          819,
          1338,
          50556
        ]
      },
      {
        "avg_logprob": -0.3578145226766897,
        "compression_ratio": 1.64,
        "end": 910.14,
        "id": 198,
        "no_speech_prob": 0.00004832550621358678,
        "seek": 89842,
        "start": 904.86,
        "temperature": 0,
        "text": " K weak man is telling me in the chat another way of thinking about this is I could say",
        "tokens": [
          50686,
          591,
          5336,
          587,
          307,
          3585,
          385,
          294,
          264,
          5081,
          1071,
          636,
          295,
          1953,
          466,
          341,
          307,
          286,
          727,
          584,
          50950
        ]
      },
      {
        "avg_logprob": -0.3578145226766897,
        "compression_ratio": 1.64,
        "end": 913.86,
        "id": 199,
        "no_speech_prob": 0.00004832550621358678,
        "seek": 89842,
        "start": 911.86,
        "temperature": 0,
        "text": " And you know what would might be nice actually",
        "tokens": [
          51036,
          400,
          291,
          458,
          437,
          576,
          1062,
          312,
          1481,
          767,
          51136
        ]
      },
      {
        "avg_logprob": -0.3578145226766897,
        "compression_ratio": 1.64,
        "end": 917.9,
        "id": 200,
        "no_speech_prob": 0.00004832550621358678,
        "seek": 89842,
        "start": 914.3,
        "temperature": 0,
        "text": " One thing that I could do here just at least I think this is gonna help me work this out",
        "tokens": [
          51158,
          1485,
          551,
          300,
          286,
          727,
          360,
          510,
          445,
          412,
          1935,
          286,
          519,
          341,
          307,
          799,
          854,
          385,
          589,
          341,
          484,
          51338
        ]
      },
      {
        "avg_logprob": -0.3578145226766897,
        "compression_ratio": 1.64,
        "end": 922.3399999999999,
        "id": 201,
        "no_speech_prob": 0.00004832550621358678,
        "seek": 89842,
        "start": 918.18,
        "temperature": 0,
        "text": " is I could say let a equal this dot matrix and",
        "tokens": [
          51352,
          307,
          286,
          727,
          584,
          718,
          257,
          2681,
          341,
          5893,
          8141,
          293,
          51560
        ]
      },
      {
        "avg_logprob": -0.3578145226766897,
        "compression_ratio": 1.64,
        "end": 925.18,
        "id": 202,
        "no_speech_prob": 0.00004832550621358678,
        "seek": 89842,
        "start": 923.18,
        "temperature": 0,
        "text": " Let B equal n",
        "tokens": [
          51602,
          961,
          363,
          2681,
          297,
          51702
        ]
      },
      {
        "avg_logprob": -0.30799978971481323,
        "compression_ratio": 1.3733333333333333,
        "end": 931.5,
        "id": 203,
        "no_speech_prob": 0.000011478742635517847,
        "seek": 92518,
        "start": 926.18,
        "temperature": 0,
        "text": " Just to have variables called a and B for the two different matrices",
        "tokens": [
          50414,
          1449,
          281,
          362,
          9102,
          1219,
          257,
          293,
          363,
          337,
          264,
          732,
          819,
          32284,
          50680
        ]
      },
      {
        "avg_logprob": -0.30799978971481323,
        "compression_ratio": 1.3733333333333333,
        "end": 938.3,
        "id": 204,
        "no_speech_prob": 0.000011478742635517847,
        "seek": 92518,
        "start": 932.42,
        "temperature": 0,
        "text": " And this is still the result, but in other words what I'm saying is a and this is B",
        "tokens": [
          50726,
          400,
          341,
          307,
          920,
          264,
          1874,
          11,
          457,
          294,
          661,
          2283,
          437,
          286,
          478,
          1566,
          307,
          257,
          293,
          341,
          307,
          363,
          51020
        ]
      },
      {
        "avg_logprob": -0.30799978971481323,
        "compression_ratio": 1.3733333333333333,
        "end": 944.9,
        "id": 205,
        "no_speech_prob": 0.000011478742635517847,
        "seek": 92518,
        "start": 940.0999999999999,
        "temperature": 0,
        "text": " So a I K B K J",
        "tokens": [
          51110,
          407,
          257,
          286,
          591,
          363,
          591,
          508,
          51350
        ]
      },
      {
        "avg_logprob": -0.30799978971481323,
        "compression_ratio": 1.3733333333333333,
        "end": 948.18,
        "id": 206,
        "no_speech_prob": 0.000011478742635517847,
        "seek": 92518,
        "start": 946.18,
        "temperature": 0,
        "text": " so",
        "tokens": [
          51414,
          370,
          51514
        ]
      },
      {
        "avg_logprob": -0.30799978971481323,
        "compression_ratio": 1.3733333333333333,
        "end": 952.54,
        "id": 207,
        "no_speech_prob": 0.000011478742635517847,
        "seek": 92518,
        "start": 948.5799999999999,
        "temperature": 0,
        "text": " So hold on let me with K sum over K",
        "tokens": [
          51534,
          407,
          1797,
          322,
          718,
          385,
          365,
          591,
          2408,
          670,
          591,
          51732
        ]
      },
      {
        "avg_logprob": -0.28758669799228886,
        "compression_ratio": 1.6160714285714286,
        "end": 960.3,
        "id": 208,
        "no_speech_prob": 0.000037052865081932396,
        "seek": 95254,
        "start": 953.14,
        "temperature": 0,
        "text": " So hold on so let me put this here did I get this wrong. This is B. Is it",
        "tokens": [
          50394,
          407,
          1797,
          322,
          370,
          718,
          385,
          829,
          341,
          510,
          630,
          286,
          483,
          341,
          2085,
          13,
          639,
          307,
          363,
          13,
          1119,
          309,
          50752
        ]
      },
      {
        "avg_logprob": -0.28758669799228886,
        "compression_ratio": 1.6160714285714286,
        "end": 966.98,
        "id": 209,
        "no_speech_prob": 0.000037052865081932396,
        "seek": 95254,
        "start": 964.98,
        "temperature": 0,
        "text": " Yes, so you know what's wrong about this",
        "tokens": [
          50986,
          1079,
          11,
          370,
          291,
          458,
          437,
          311,
          2085,
          466,
          341,
          51086
        ]
      },
      {
        "avg_logprob": -0.28758669799228886,
        "compression_ratio": 1.6160714285714286,
        "end": 973.5,
        "id": 210,
        "no_speech_prob": 0.000037052865081932396,
        "seek": 95254,
        "start": 967.54,
        "temperature": 0,
        "text": " So let's look now we can get this right. Here's what I'm doing here. I want a I want to be increasing",
        "tokens": [
          51114,
          407,
          718,
          311,
          574,
          586,
          321,
          393,
          483,
          341,
          558,
          13,
          1692,
          311,
          437,
          286,
          478,
          884,
          510,
          13,
          286,
          528,
          257,
          286,
          528,
          281,
          312,
          5662,
          51412
        ]
      },
      {
        "avg_logprob": -0.28758669799228886,
        "compression_ratio": 1.6160714285714286,
        "end": 977.06,
        "id": 211,
        "no_speech_prob": 0.000037052865081932396,
        "seek": 95254,
        "start": 973.5,
        "temperature": 0,
        "text": " Not the row, but the column. I did it wrong. I did it backwards",
        "tokens": [
          51412,
          1726,
          264,
          5386,
          11,
          457,
          264,
          7738,
          13,
          286,
          630,
          309,
          2085,
          13,
          286,
          630,
          309,
          12204,
          51590
        ]
      },
      {
        "avg_logprob": -0.28758669799228886,
        "compression_ratio": 1.6160714285714286,
        "end": 980.42,
        "id": 212,
        "no_speech_prob": 0.000037052865081932396,
        "seek": 95254,
        "start": 977.4599999999999,
        "temperature": 0,
        "text": " Do you guys like watching these videos where I try to figure it out? I don't know",
        "tokens": [
          51610,
          1144,
          291,
          1074,
          411,
          1976,
          613,
          2145,
          689,
          286,
          853,
          281,
          2573,
          309,
          484,
          30,
          286,
          500,
          380,
          458,
          51758
        ]
      },
      {
        "avg_logprob": -0.32008209228515627,
        "compression_ratio": 1.727810650887574,
        "end": 985.26,
        "id": 213,
        "no_speech_prob": 0.00002247405245725531,
        "seek": 98042,
        "start": 981.38,
        "temperature": 0,
        "text": " It could I could just get it right the first time I could just like start over and get it right",
        "tokens": [
          50412,
          467,
          727,
          286,
          727,
          445,
          483,
          309,
          558,
          264,
          700,
          565,
          286,
          727,
          445,
          411,
          722,
          670,
          293,
          483,
          309,
          558,
          50606
        ]
      },
      {
        "avg_logprob": -0.32008209228515627,
        "compression_ratio": 1.727810650887574,
        "end": 987.9399999999999,
        "id": 214,
        "no_speech_prob": 0.00002247405245725531,
        "seek": 98042,
        "start": 985.26,
        "temperature": 0,
        "text": " But what I'm doing is I'm every",
        "tokens": [
          50606,
          583,
          437,
          286,
          478,
          884,
          307,
          286,
          478,
          633,
          50740
        ]
      },
      {
        "avg_logprob": -0.32008209228515627,
        "compression_ratio": 1.727810650887574,
        "end": 991.5799999999999,
        "id": 215,
        "no_speech_prob": 0.00002247405245725531,
        "seek": 98042,
        "start": 988.5799999999999,
        "temperature": 0,
        "text": " Column of a which column is I'm actually using",
        "tokens": [
          50772,
          4004,
          16449,
          295,
          257,
          597,
          7738,
          307,
          286,
          478,
          767,
          1228,
          50922
        ]
      },
      {
        "avg_logprob": -0.32008209228515627,
        "compression_ratio": 1.727810650887574,
        "end": 1001.14,
        "id": 216,
        "no_speech_prob": 0.00002247405245725531,
        "seek": 98042,
        "start": 994.78,
        "temperature": 0,
        "text": " Yes, it's called it's all it's row I but I'm iterating over the columns of course of course of course",
        "tokens": [
          51082,
          1079,
          11,
          309,
          311,
          1219,
          309,
          311,
          439,
          309,
          311,
          5386,
          286,
          457,
          286,
          478,
          17138,
          990,
          670,
          264,
          13766,
          295,
          1164,
          295,
          1164,
          295,
          1164,
          51400
        ]
      },
      {
        "avg_logprob": -0.32008209228515627,
        "compression_ratio": 1.727810650887574,
        "end": 1003.42,
        "id": 217,
        "no_speech_prob": 0.00002247405245725531,
        "seek": 98042,
        "start": 1001.42,
        "temperature": 0,
        "text": " So it is this",
        "tokens": [
          51414,
          407,
          309,
          307,
          341,
          51514
        ]
      },
      {
        "avg_logprob": -0.32008209228515627,
        "compression_ratio": 1.727810650887574,
        "end": 1006.18,
        "id": 218,
        "no_speech_prob": 0.00002247405245725531,
        "seek": 98042,
        "start": 1004.18,
        "temperature": 0,
        "text": " J",
        "tokens": [
          51552,
          508,
          51652
        ]
      },
      {
        "avg_logprob": -0.33995109268381624,
        "compression_ratio": 1.5421686746987953,
        "end": 1013.3,
        "id": 219,
        "no_speech_prob": 0.000040694500057725236,
        "seek": 101042,
        "start": 1011.3,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50408,
          407,
          50508
        ]
      },
      {
        "avg_logprob": -0.33995109268381624,
        "compression_ratio": 1.5421686746987953,
        "end": 1019.26,
        "id": 220,
        "no_speech_prob": 0.000040694500057725236,
        "seek": 101042,
        "start": 1013.9,
        "temperature": 0,
        "text": " This is actually this is what I need so what I should be able to say is",
        "tokens": [
          50538,
          639,
          307,
          767,
          341,
          307,
          437,
          286,
          643,
          370,
          437,
          286,
          820,
          312,
          1075,
          281,
          584,
          307,
          50806
        ]
      },
      {
        "avg_logprob": -0.33995109268381624,
        "compression_ratio": 1.5421686746987953,
        "end": 1022.78,
        "id": 221,
        "no_speech_prob": 0.000040694500057725236,
        "seek": 101042,
        "start": 1020.0999999999999,
        "temperature": 0,
        "text": " Result I need another loop for let",
        "tokens": [
          50848,
          5015,
          723,
          286,
          643,
          1071,
          6367,
          337,
          718,
          50982
        ]
      },
      {
        "avg_logprob": -0.33995109268381624,
        "compression_ratio": 1.5421686746987953,
        "end": 1029.7,
        "id": 222,
        "no_speech_prob": 0.000040694500057725236,
        "seek": 101042,
        "start": 1024.06,
        "temperature": 0,
        "text": " K equals 0 K is less than and I can use remember I could use a's",
        "tokens": [
          51046,
          591,
          6915,
          1958,
          591,
          307,
          1570,
          813,
          293,
          286,
          393,
          764,
          1604,
          286,
          727,
          764,
          257,
          311,
          51328
        ]
      },
      {
        "avg_logprob": -0.33995109268381624,
        "compression_ratio": 1.5421686746987953,
        "end": 1034.74,
        "id": 223,
        "no_speech_prob": 0.000040694500057725236,
        "seek": 101042,
        "start": 1030.34,
        "temperature": 0,
        "text": " Columns or B's rows those have to be the same so I'm going to use a's columns",
        "tokens": [
          51360,
          4004,
          449,
          3695,
          420,
          363,
          311,
          13241,
          729,
          362,
          281,
          312,
          264,
          912,
          370,
          286,
          478,
          516,
          281,
          764,
          257,
          311,
          13766,
          51580
        ]
      },
      {
        "avg_logprob": -0.33995109268381624,
        "compression_ratio": 1.5421686746987953,
        "end": 1040.22,
        "id": 224,
        "no_speech_prob": 0.000040694500057725236,
        "seek": 101042,
        "start": 1038.22,
        "temperature": 0,
        "text": " Yes",
        "tokens": [
          51754,
          1079,
          51854
        ]
      },
      {
        "avg_logprob": -0.36505257137238034,
        "compression_ratio": 1.5648854961832062,
        "end": 1049.26,
        "id": 225,
        "no_speech_prob": 0.0000014823573337707785,
        "seek": 104042,
        "start": 1040.94,
        "temperature": 0,
        "text": " K plus plus and then I'm gonna first I need to say let sum equals 0 and then I'm gonna say sum plus equal",
        "tokens": [
          50390,
          591,
          1804,
          1804,
          293,
          550,
          286,
          478,
          799,
          700,
          286,
          643,
          281,
          584,
          718,
          2408,
          6915,
          1958,
          293,
          550,
          286,
          478,
          799,
          584,
          2408,
          1804,
          2681,
          50806
        ]
      },
      {
        "avg_logprob": -0.36505257137238034,
        "compression_ratio": 1.5648854961832062,
        "end": 1050.14,
        "id": 226,
        "no_speech_prob": 0.0000014823573337707785,
        "seek": 104042,
        "start": 1049.26,
        "temperature": 0,
        "text": " a",
        "tokens": [
          50806,
          257,
          50850
        ]
      },
      {
        "avg_logprob": -0.36505257137238034,
        "compression_ratio": 1.5648854961832062,
        "end": 1052.6200000000001,
        "id": 227,
        "no_speech_prob": 0.0000014823573337707785,
        "seek": 104042,
        "start": 1050.14,
        "temperature": 0,
        "text": " index I K plus B",
        "tokens": [
          50850,
          8186,
          286,
          591,
          1804,
          363,
          50974
        ]
      },
      {
        "avg_logprob": -0.36505257137238034,
        "compression_ratio": 1.5648854961832062,
        "end": 1055.3000000000002,
        "id": 228,
        "no_speech_prob": 0.0000014823573337707785,
        "seek": 104042,
        "start": 1053.3000000000002,
        "temperature": 0,
        "text": " index K J",
        "tokens": [
          51008,
          8186,
          591,
          508,
          51108
        ]
      },
      {
        "avg_logprob": -0.36505257137238034,
        "compression_ratio": 1.5648854961832062,
        "end": 1064.02,
        "id": 229,
        "no_speech_prob": 0.0000014823573337707785,
        "seek": 104042,
        "start": 1057.46,
        "temperature": 0,
        "text": " This I think is right and then I have to put that in the result result",
        "tokens": [
          51216,
          639,
          286,
          519,
          307,
          558,
          293,
          550,
          286,
          362,
          281,
          829,
          300,
          294,
          264,
          1874,
          1874,
          51544
        ]
      },
      {
        "avg_logprob": -0.3320142131740764,
        "compression_ratio": 1.412162162162162,
        "end": 1066.02,
        "id": 230,
        "no_speech_prob": 0.000010953114724543411,
        "seek": 106402,
        "start": 1064.02,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50364,
          286,
          50464
        ]
      },
      {
        "avg_logprob": -0.3320142131740764,
        "compression_ratio": 1.412162162162162,
        "end": 1074.86,
        "id": 231,
        "no_speech_prob": 0.000010953114724543411,
        "seek": 106402,
        "start": 1072.18,
        "temperature": 0,
        "text": " J equals some",
        "tokens": [
          50772,
          508,
          6915,
          512,
          50906
        ]
      },
      {
        "avg_logprob": -0.3320142131740764,
        "compression_ratio": 1.412162162162162,
        "end": 1081.7,
        "id": 232,
        "no_speech_prob": 0.000010953114724543411,
        "seek": 106402,
        "start": 1076.74,
        "temperature": 0,
        "text": " So if I was using like some other vector library I could like pull those out then do the dot product",
        "tokens": [
          51000,
          407,
          498,
          286,
          390,
          1228,
          411,
          512,
          661,
          8062,
          6405,
          286,
          727,
          411,
          2235,
          729,
          484,
          550,
          360,
          264,
          5893,
          1674,
          51248
        ]
      },
      {
        "avg_logprob": -0.3320142131740764,
        "compression_ratio": 1.412162162162162,
        "end": 1084.98,
        "id": 233,
        "no_speech_prob": 0.000010953114724543411,
        "seek": 106402,
        "start": 1081.86,
        "temperature": 0,
        "text": " But let's see here. Let's make sure this is right",
        "tokens": [
          51256,
          583,
          718,
          311,
          536,
          510,
          13,
          961,
          311,
          652,
          988,
          341,
          307,
          558,
          51412
        ]
      },
      {
        "avg_logprob": -0.3320142131740764,
        "compression_ratio": 1.412162162162162,
        "end": 1089.02,
        "id": 234,
        "no_speech_prob": 0.000010953114724543411,
        "seek": 106402,
        "start": 1084.98,
        "temperature": 0,
        "text": " I want to for every element in the results",
        "tokens": [
          51412,
          286,
          528,
          281,
          337,
          633,
          4478,
          294,
          264,
          3542,
          51614
        ]
      },
      {
        "avg_logprob": -0.2832957517753527,
        "compression_ratio": 1.646808510638298,
        "end": 1095.7,
        "id": 235,
        "no_speech_prob": 0.00018814177019521594,
        "seek": 108902,
        "start": 1089.02,
        "temperature": 0,
        "text": " I want to sum the dot product of all of the column spots in a",
        "tokens": [
          50364,
          286,
          528,
          281,
          2408,
          264,
          5893,
          1674,
          295,
          439,
          295,
          264,
          7738,
          10681,
          294,
          257,
          50698
        ]
      },
      {
        "avg_logprob": -0.2832957517753527,
        "compression_ratio": 1.646808510638298,
        "end": 1101.46,
        "id": 236,
        "no_speech_prob": 0.00018814177019521594,
        "seek": 108902,
        "start": 1095.9,
        "temperature": 0,
        "text": " that's K with all of the row spots in B, and then I've got the result and",
        "tokens": [
          50708,
          300,
          311,
          591,
          365,
          439,
          295,
          264,
          5386,
          10681,
          294,
          363,
          11,
          293,
          550,
          286,
          600,
          658,
          264,
          1874,
          293,
          50986
        ]
      },
      {
        "avg_logprob": -0.2832957517753527,
        "compression_ratio": 1.646808510638298,
        "end": 1110.26,
        "id": 237,
        "no_speech_prob": 0.00018814177019521594,
        "seek": 108902,
        "start": 1103.1399999999999,
        "temperature": 0,
        "text": " Line 50 times think deep space in the chat says line 57. Oh, yes, sorry this needs to be multiplied so these get multiplied",
        "tokens": [
          51070,
          14670,
          2625,
          1413,
          519,
          2452,
          1901,
          294,
          264,
          5081,
          1619,
          1622,
          21423,
          13,
          876,
          11,
          2086,
          11,
          2597,
          341,
          2203,
          281,
          312,
          17207,
          370,
          613,
          483,
          17207,
          51426
        ]
      },
      {
        "avg_logprob": -0.2832957517753527,
        "compression_ratio": 1.646808510638298,
        "end": 1112.26,
        "id": 238,
        "no_speech_prob": 0.00018814177019521594,
        "seek": 108902,
        "start": 1110.26,
        "temperature": 0,
        "text": " I'm summing the product of all those",
        "tokens": [
          51426,
          286,
          478,
          2408,
          2810,
          264,
          1674,
          295,
          439,
          729,
          51526
        ]
      },
      {
        "avg_logprob": -0.2832957517753527,
        "compression_ratio": 1.646808510638298,
        "end": 1118.98,
        "id": 239,
        "no_speech_prob": 0.00018814177019521594,
        "seek": 108902,
        "start": 1112.46,
        "temperature": 0,
        "text": " Yes, and of course there are much faster ways. I'm not looking for any any efficiency here",
        "tokens": [
          51536,
          1079,
          11,
          293,
          295,
          1164,
          456,
          366,
          709,
          4663,
          2098,
          13,
          286,
          478,
          406,
          1237,
          337,
          604,
          604,
          10493,
          510,
          51862
        ]
      },
      {
        "avg_logprob": -0.2970903957591337,
        "compression_ratio": 1.6288659793814433,
        "end": 1123.2,
        "id": 240,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 111898,
        "start": 1118.98,
        "temperature": 0,
        "text": " I'm just trying to understand the algorithm and make sure I have something that works",
        "tokens": [
          50364,
          286,
          478,
          445,
          1382,
          281,
          1223,
          264,
          9284,
          293,
          652,
          988,
          286,
          362,
          746,
          300,
          1985,
          50575
        ]
      },
      {
        "avg_logprob": -0.2970903957591337,
        "compression_ratio": 1.6288659793814433,
        "end": 1130.66,
        "id": 241,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 111898,
        "start": 1125.82,
        "temperature": 0,
        "text": " Okay, so now I need one more curly bracket, and I think",
        "tokens": [
          50706,
          1033,
          11,
          370,
          586,
          286,
          643,
          472,
          544,
          32066,
          16904,
          11,
          293,
          286,
          519,
          50948
        ]
      },
      {
        "avg_logprob": -0.2970903957591337,
        "compression_ratio": 1.6288659793814433,
        "end": 1137.24,
        "id": 242,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 111898,
        "start": 1134.14,
        "temperature": 0,
        "text": " If I zoom back out here, I think I am done",
        "tokens": [
          51122,
          759,
          286,
          8863,
          646,
          484,
          510,
          11,
          286,
          519,
          286,
          669,
          1096,
          51277
        ]
      },
      {
        "avg_logprob": -0.2970903957591337,
        "compression_ratio": 1.6288659793814433,
        "end": 1141.46,
        "id": 243,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 111898,
        "start": 1137.9,
        "temperature": 0,
        "text": " This is the algorithm right I have a new matrix",
        "tokens": [
          51310,
          639,
          307,
          264,
          9284,
          558,
          286,
          362,
          257,
          777,
          8141,
          51488
        ]
      },
      {
        "avg_logprob": -0.2970903957591337,
        "compression_ratio": 1.6288659793814433,
        "end": 1148.42,
        "id": 244,
        "no_speech_prob": 0.000007527985417254968,
        "seek": 111898,
        "start": 1141.94,
        "temperature": 0,
        "text": " That has that is of the size of and this I should do this down here the size of a's",
        "tokens": [
          51512,
          663,
          575,
          300,
          307,
          295,
          264,
          2744,
          295,
          293,
          341,
          286,
          820,
          360,
          341,
          760,
          510,
          264,
          2744,
          295,
          257,
          311,
          51836
        ]
      },
      {
        "avg_logprob": -0.3226181624771713,
        "compression_ratio": 1.5,
        "end": 1150.46,
        "id": 245,
        "no_speech_prob": 0.00008092744246823713,
        "seek": 114842,
        "start": 1148.46,
        "temperature": 0,
        "text": " rows and B's columns",
        "tokens": [
          50366,
          13241,
          293,
          363,
          311,
          13766,
          50466
        ]
      },
      {
        "avg_logprob": -0.3226181624771713,
        "compression_ratio": 1.5,
        "end": 1152.66,
        "id": 246,
        "no_speech_prob": 0.00008092744246823713,
        "seek": 114842,
        "start": 1151.02,
        "temperature": 0,
        "text": " Then I go through it",
        "tokens": [
          50494,
          1396,
          286,
          352,
          807,
          309,
          50576
        ]
      },
      {
        "avg_logprob": -0.3226181624771713,
        "compression_ratio": 1.5,
        "end": 1159.66,
        "id": 247,
        "no_speech_prob": 0.00008092744246823713,
        "seek": 114842,
        "start": 1152.66,
        "temperature": 0,
        "text": " And I do the dot product of a vector from of a row of a and a column of B store that result",
        "tokens": [
          50576,
          400,
          286,
          360,
          264,
          5893,
          1674,
          295,
          257,
          8062,
          490,
          295,
          257,
          5386,
          295,
          257,
          293,
          257,
          7738,
          295,
          363,
          3531,
          300,
          1874,
          50926
        ]
      },
      {
        "avg_logprob": -0.3226181624771713,
        "compression_ratio": 1.5,
        "end": 1162.54,
        "id": 248,
        "no_speech_prob": 0.00008092744246823713,
        "seek": 114842,
        "start": 1160.78,
        "temperature": 0,
        "text": " Okay, and be I yes",
        "tokens": [
          50982,
          1033,
          11,
          293,
          312,
          286,
          2086,
          51070
        ]
      },
      {
        "avg_logprob": -0.3226181624771713,
        "compression_ratio": 1.5,
        "end": 1168.3400000000001,
        "id": 249,
        "no_speech_prob": 0.00008092744246823713,
        "seek": 114842,
        "start": 1162.54,
        "temperature": 0,
        "text": " Here's another mistake B equals n dot matrix right because the actual two-dimensional array is",
        "tokens": [
          51070,
          1692,
          311,
          1071,
          6146,
          363,
          6915,
          297,
          5893,
          8141,
          558,
          570,
          264,
          3539,
          732,
          12,
          18759,
          10225,
          307,
          51360
        ]
      },
      {
        "avg_logprob": -0.3226181624771713,
        "compression_ratio": 1.5,
        "end": 1172.02,
        "id": 250,
        "no_speech_prob": 0.00008092744246823713,
        "seek": 114842,
        "start": 1168.8600000000001,
        "temperature": 0,
        "text": " stored in a variable called matrix",
        "tokens": [
          51386,
          12187,
          294,
          257,
          7006,
          1219,
          8141,
          51544
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1173.5,
        "id": 251,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1172.1399999999999,
        "temperature": 0,
        "text": " It's not",
        "tokens": [
          50370,
          467,
          311,
          406,
          50438
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1178.66,
        "id": 252,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1173.5,
        "temperature": 0,
        "text": " It's not the it's the object itself has the data inside a variable okay?",
        "tokens": [
          50438,
          467,
          311,
          406,
          264,
          309,
          311,
          264,
          2657,
          2564,
          575,
          264,
          1412,
          1854,
          257,
          7006,
          1392,
          30,
          50696
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1182.94,
        "id": 253,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1178.82,
        "temperature": 0,
        "text": " So how do we get a test this I actually have a sketch here?",
        "tokens": [
          50704,
          407,
          577,
          360,
          321,
          483,
          257,
          1500,
          341,
          286,
          767,
          362,
          257,
          12325,
          510,
          30,
          50910
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1189.74,
        "id": 254,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1183.5,
        "temperature": 0,
        "text": " So I'm gonna in that's a p5 sketch. I'm not gonna use anything about p5. I'm gonna have a be a new matrix",
        "tokens": [
          50938,
          407,
          286,
          478,
          799,
          294,
          300,
          311,
          257,
          280,
          20,
          12325,
          13,
          286,
          478,
          406,
          799,
          764,
          1340,
          466,
          280,
          20,
          13,
          286,
          478,
          799,
          362,
          257,
          312,
          257,
          777,
          8141,
          51250
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1191.74,
        "id": 255,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1189.74,
        "temperature": 0,
        "text": " That's 3 by 2 sorry",
        "tokens": [
          51250,
          663,
          311,
          805,
          538,
          568,
          2597,
          51350
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1194.3799999999999,
        "id": 256,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1192.54,
        "temperature": 0,
        "text": " 2 by 3",
        "tokens": [
          51390,
          568,
          538,
          805,
          51482
        ]
      },
      {
        "avg_logprob": -0.31978919619605656,
        "compression_ratio": 1.6,
        "end": 1198.26,
        "id": 257,
        "no_speech_prob": 0.0012843010481446981,
        "seek": 117202,
        "start": 1194.3799999999999,
        "temperature": 0,
        "text": " I'm gonna say the same for B. Which is 3 by 2",
        "tokens": [
          51482,
          286,
          478,
          799,
          584,
          264,
          912,
          337,
          363,
          13,
          3013,
          307,
          805,
          538,
          568,
          51676
        ]
      },
      {
        "avg_logprob": -0.48780074209537144,
        "compression_ratio": 1.5504587155963303,
        "end": 1204.58,
        "id": 258,
        "no_speech_prob": 0.00006814854714320973,
        "seek": 119826,
        "start": 1198.26,
        "temperature": 0,
        "text": " Then I'm gonna say a a dot randomize B dot randomize",
        "tokens": [
          50364,
          1396,
          286,
          478,
          799,
          584,
          257,
          257,
          5893,
          4974,
          1125,
          363,
          5893,
          4974,
          1125,
          50680
        ]
      },
      {
        "avg_logprob": -0.48780074209537144,
        "compression_ratio": 1.5504587155963303,
        "end": 1213.94,
        "id": 259,
        "no_speech_prob": 0.00006814854714320973,
        "seek": 119826,
        "start": 1209.58,
        "temperature": 0,
        "text": " Console dot log a dot matrix and console dot log",
        "tokens": [
          50930,
          44152,
          5893,
          3565,
          257,
          5893,
          8141,
          293,
          11076,
          5893,
          3565,
          51148
        ]
      },
      {
        "avg_logprob": -0.48780074209537144,
        "compression_ratio": 1.5504587155963303,
        "end": 1217.66,
        "id": 260,
        "no_speech_prob": 0.00006814854714320973,
        "seek": 119826,
        "start": 1215.66,
        "temperature": 0,
        "text": " And not dot log dot table",
        "tokens": [
          51234,
          400,
          406,
          5893,
          3565,
          5893,
          3199,
          51334
        ]
      },
      {
        "avg_logprob": -0.48780074209537144,
        "compression_ratio": 1.5504587155963303,
        "end": 1222.7,
        "id": 261,
        "no_speech_prob": 0.00006814854714320973,
        "seek": 119826,
        "start": 1220.7,
        "temperature": 0,
        "text": " B dot matrix",
        "tokens": [
          51486,
          363,
          5893,
          8141,
          51586
        ]
      },
      {
        "avg_logprob": -0.48780074209537144,
        "compression_ratio": 1.5504587155963303,
        "end": 1225.5,
        "id": 262,
        "no_speech_prob": 0.00006814854714320973,
        "seek": 119826,
        "start": 1223.5,
        "temperature": 0,
        "text": " So let's take a look at that",
        "tokens": [
          51626,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          300,
          51726
        ]
      },
      {
        "avg_logprob": -0.33019018173217773,
        "compression_ratio": 1.206896551724138,
        "end": 1233.7,
        "id": 263,
        "no_speech_prob": 0.00004400093530421145,
        "seek": 122550,
        "start": 1226.3,
        "temperature": 0,
        "text": " Okay, so now I have to make two matrices. This is one and they with random values in them, so now I'm gonna say",
        "tokens": [
          50404,
          1033,
          11,
          370,
          586,
          286,
          362,
          281,
          652,
          732,
          32284,
          13,
          639,
          307,
          472,
          293,
          436,
          365,
          4974,
          4190,
          294,
          552,
          11,
          370,
          586,
          286,
          478,
          799,
          584,
          50774
        ]
      },
      {
        "avg_logprob": -0.33019018173217773,
        "compression_ratio": 1.206896551724138,
        "end": 1237.02,
        "id": 264,
        "no_speech_prob": 0.00004400093530421145,
        "seek": 122550,
        "start": 1234.38,
        "temperature": 0,
        "text": " Let C equal a dot multiply",
        "tokens": [
          50808,
          961,
          383,
          2681,
          257,
          5893,
          12972,
          50940
        ]
      },
      {
        "avg_logprob": -0.33019018173217773,
        "compression_ratio": 1.206896551724138,
        "end": 1240.74,
        "id": 265,
        "no_speech_prob": 0.00004400093530421145,
        "seek": 122550,
        "start": 1238.74,
        "temperature": 0,
        "text": " B",
        "tokens": [
          51026,
          363,
          51126
        ]
      },
      {
        "avg_logprob": -0.4513975461324056,
        "compression_ratio": 1.3509933774834437,
        "end": 1260.86,
        "id": 266,
        "no_speech_prob": 0.0015730960294604301,
        "seek": 125550,
        "start": 1256.14,
        "temperature": 0,
        "text": " I didn't get anything there. Oh, oh, I didn't console log it oh",
        "tokens": [
          50396,
          286,
          994,
          380,
          483,
          1340,
          456,
          13,
          876,
          11,
          1954,
          11,
          286,
          994,
          380,
          11076,
          3565,
          309,
          1954,
          50632
        ]
      },
      {
        "avg_logprob": -0.4513975461324056,
        "compression_ratio": 1.3509933774834437,
        "end": 1265.5,
        "id": 267,
        "no_speech_prob": 0.0015730960294604301,
        "seek": 125550,
        "start": 1262.06,
        "temperature": 0,
        "text": " man console table C dot matrix I",
        "tokens": [
          50692,
          587,
          11076,
          3199,
          383,
          5893,
          8141,
          286,
          50864
        ]
      },
      {
        "avg_logprob": -0.4513975461324056,
        "compression_ratio": 1.3509933774834437,
        "end": 1269.02,
        "id": 268,
        "no_speech_prob": 0.0015730960294604301,
        "seek": 125550,
        "start": 1266.74,
        "temperature": 0,
        "text": " Forgot about that part okay here. We go again",
        "tokens": [
          50926,
          1171,
          13178,
          466,
          300,
          644,
          1392,
          510,
          13,
          492,
          352,
          797,
          51040
        ]
      },
      {
        "avg_logprob": -0.4513975461324056,
        "compression_ratio": 1.3509933774834437,
        "end": 1283.62,
        "id": 269,
        "no_speech_prob": 0.0015730960294604301,
        "seek": 125550,
        "start": 1277.06,
        "temperature": 0,
        "text": " Shoot all right, so what's this error sketch such as line 11?",
        "tokens": [
          51442,
          19760,
          439,
          558,
          11,
          370,
          437,
          311,
          341,
          6713,
          12325,
          1270,
          382,
          1622,
          2975,
          30,
          51770
        ]
      },
      {
        "avg_logprob": -0.3298732042312622,
        "compression_ratio": 1.5471698113207548,
        "end": 1291.1,
        "id": 270,
        "no_speech_prob": 0.00007141882088035345,
        "seek": 128550,
        "start": 1286.46,
        "temperature": 0,
        "text": " Cannot did I forget to return it I forgot to return it didn't I?",
        "tokens": [
          50412,
          29866,
          310,
          630,
          286,
          2870,
          281,
          2736,
          309,
          286,
          5298,
          281,
          2736,
          309,
          994,
          380,
          286,
          30,
          50644
        ]
      },
      {
        "avg_logprob": -0.3298732042312622,
        "compression_ratio": 1.5471698113207548,
        "end": 1300.22,
        "id": 271,
        "no_speech_prob": 0.00007141882088035345,
        "seek": 128550,
        "start": 1293.22,
        "temperature": 0,
        "text": " Okay, you know what would might be nice is if the end of this I said return result and this actually goes where here",
        "tokens": [
          50750,
          1033,
          11,
          291,
          458,
          437,
          576,
          1062,
          312,
          1481,
          307,
          498,
          264,
          917,
          295,
          341,
          286,
          848,
          2736,
          1874,
          293,
          341,
          767,
          1709,
          689,
          510,
          51100
        ]
      },
      {
        "avg_logprob": -0.3298732042312622,
        "compression_ratio": 1.5471698113207548,
        "end": 1305.38,
        "id": 272,
        "no_speech_prob": 0.00007141882088035345,
        "seek": 128550,
        "start": 1301.06,
        "temperature": 0,
        "text": " Right I got a return that result all right. Let's try this again",
        "tokens": [
          51142,
          1779,
          286,
          658,
          257,
          2736,
          300,
          1874,
          439,
          558,
          13,
          961,
          311,
          853,
          341,
          797,
          51358
        ]
      },
      {
        "avg_logprob": -0.3534724770522699,
        "compression_ratio": 1.633879781420765,
        "end": 1317.82,
        "id": 273,
        "no_speech_prob": 0.0007436986197717488,
        "seek": 131550,
        "start": 1315.82,
        "temperature": 0,
        "text": " So I forget hit save oh",
        "tokens": [
          50380,
          407,
          286,
          2870,
          2045,
          3155,
          1954,
          50480
        ]
      },
      {
        "avg_logprob": -0.3534724770522699,
        "compression_ratio": 1.633879781420765,
        "end": 1322.46,
        "id": 274,
        "no_speech_prob": 0.0007436986197717488,
        "seek": 131550,
        "start": 1319.94,
        "temperature": 0,
        "text": " I'm being told breaking news breaking news",
        "tokens": [
          50586,
          286,
          478,
          885,
          1907,
          7697,
          2583,
          7697,
          2583,
          50712
        ]
      },
      {
        "avg_logprob": -0.3534724770522699,
        "compression_ratio": 1.633879781420765,
        "end": 1327.28,
        "id": 275,
        "no_speech_prob": 0.0007436986197717488,
        "seek": 131550,
        "start": 1323.7,
        "temperature": 0,
        "text": " The return is in this for loop. That's not good. Oh",
        "tokens": [
          50774,
          440,
          2736,
          307,
          294,
          341,
          337,
          6367,
          13,
          663,
          311,
          406,
          665,
          13,
          876,
          50953
        ]
      },
      {
        "avg_logprob": -0.3534724770522699,
        "compression_ratio": 1.633879781420765,
        "end": 1334.72,
        "id": 276,
        "no_speech_prob": 0.0007436986197717488,
        "seek": 131550,
        "start": 1328.66,
        "temperature": 0,
        "text": " Right cuz this just the return was in the for loop. That's terrible and this says results, and it should say results, okay?",
        "tokens": [
          51022,
          1779,
          11910,
          341,
          445,
          264,
          2736,
          390,
          294,
          264,
          337,
          6367,
          13,
          663,
          311,
          6237,
          293,
          341,
          1619,
          3542,
          11,
          293,
          309,
          820,
          584,
          3542,
          11,
          1392,
          30,
          51325
        ]
      },
      {
        "avg_logprob": -0.3534724770522699,
        "compression_ratio": 1.633879781420765,
        "end": 1336.72,
        "id": 277,
        "no_speech_prob": 0.0007436986197717488,
        "seek": 131550,
        "start": 1334.72,
        "temperature": 0,
        "text": " I'm feeling a little bit a",
        "tokens": [
          51325,
          286,
          478,
          2633,
          257,
          707,
          857,
          257,
          51425
        ]
      },
      {
        "avg_logprob": -0.3534724770522699,
        "compression_ratio": 1.633879781420765,
        "end": 1339.26,
        "id": 278,
        "no_speech_prob": 0.0007436986197717488,
        "seek": 131550,
        "start": 1337.26,
        "temperature": 0,
        "text": " Little bit more confident now",
        "tokens": [
          51452,
          8022,
          857,
          544,
          6679,
          586,
          51552
        ]
      },
      {
        "avg_logprob": -0.36467880361220417,
        "compression_ratio": 1.5396825396825398,
        "end": 1341.26,
        "id": 279,
        "no_speech_prob": 0.00022693317441735417,
        "seek": 133926,
        "start": 1339.26,
        "temperature": 0,
        "text": " Oh",
        "tokens": [
          50364,
          876,
          50464
        ]
      },
      {
        "avg_logprob": -0.36467880361220417,
        "compression_ratio": 1.5396825396825398,
        "end": 1350.02,
        "id": 280,
        "no_speech_prob": 0.00022693317441735417,
        "seek": 133926,
        "start": 1348.02,
        "temperature": 0,
        "text": " My goodness",
        "tokens": [
          50802,
          1222,
          8387,
          50902
        ]
      },
      {
        "avg_logprob": -0.36467880361220417,
        "compression_ratio": 1.5396825396825398,
        "end": 1358.46,
        "id": 281,
        "no_speech_prob": 0.00022693317441735417,
        "seek": 133926,
        "start": 1351.34,
        "temperature": 0,
        "text": " I'm completely losing my mind here, so it's very important to realize that result is the matrix object",
        "tokens": [
          50968,
          286,
          478,
          2584,
          7027,
          452,
          1575,
          510,
          11,
          370,
          309,
          311,
          588,
          1021,
          281,
          4325,
          300,
          1874,
          307,
          264,
          8141,
          2657,
          51324
        ]
      },
      {
        "avg_logprob": -0.36467880361220417,
        "compression_ratio": 1.5396825396825398,
        "end": 1362.42,
        "id": 282,
        "no_speech_prob": 0.00022693317441735417,
        "seek": 133926,
        "start": 1358.46,
        "temperature": 0,
        "text": " Oh the matrix object has this array called",
        "tokens": [
          51324,
          876,
          264,
          8141,
          2657,
          575,
          341,
          10225,
          1219,
          51522
        ]
      },
      {
        "avg_logprob": -0.36467880361220417,
        "compression_ratio": 1.5396825396825398,
        "end": 1369.1,
        "id": 283,
        "no_speech_prob": 0.00022693317441735417,
        "seek": 133926,
        "start": 1362.7,
        "temperature": 0,
        "text": " Matrix which actually stores the values and there's no like set function or anything so what I actually really need to put here is",
        "tokens": [
          51536,
          36274,
          597,
          767,
          9512,
          264,
          4190,
          293,
          456,
          311,
          572,
          411,
          992,
          2445,
          420,
          1340,
          370,
          437,
          286,
          767,
          534,
          643,
          281,
          829,
          510,
          307,
          51856
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1371.26,
        "id": 284,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1369.26,
        "temperature": 0,
        "text": " result dot matrix",
        "tokens": [
          50364,
          1874,
          5893,
          8141,
          50464
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1375.22,
        "id": 285,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1371.62,
        "temperature": 0,
        "text": " Right equals this result dot matrix",
        "tokens": [
          50482,
          1779,
          6915,
          341,
          1874,
          5893,
          8141,
          50662
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1380.98,
        "id": 286,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1376.34,
        "temperature": 0,
        "text": " Equals oh no, and then return result right so I these values that I'm calculating",
        "tokens": [
          50718,
          15624,
          1124,
          1954,
          572,
          11,
          293,
          550,
          2736,
          1874,
          558,
          370,
          286,
          613,
          4190,
          300,
          286,
          478,
          28258,
          50950
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1383.18,
        "id": 287,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1380.98,
        "temperature": 0,
        "text": " There's probably should be like a set function or something like that",
        "tokens": [
          50950,
          821,
          311,
          1391,
          820,
          312,
          411,
          257,
          992,
          2445,
          420,
          746,
          411,
          300,
          51060
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1387.32,
        "id": 288,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1383.18,
        "temperature": 0,
        "text": " And I probably should just created the 2d array here, and then made a major, but whatever",
        "tokens": [
          51060,
          400,
          286,
          1391,
          820,
          445,
          2942,
          264,
          568,
          67,
          10225,
          510,
          11,
          293,
          550,
          1027,
          257,
          2563,
          11,
          457,
          2035,
          51267
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1391.3799999999999,
        "id": 289,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1387.32,
        "temperature": 0,
        "text": " This is what it needs to be I think we've got it now. Oh boy",
        "tokens": [
          51267,
          639,
          307,
          437,
          309,
          2203,
          281,
          312,
          286,
          519,
          321,
          600,
          658,
          309,
          586,
          13,
          876,
          3237,
          51470
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1394.54,
        "id": 290,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1392.54,
        "temperature": 0,
        "text": " Okay, wait wait wait oh",
        "tokens": [
          51528,
          1033,
          11,
          1699,
          1699,
          1699,
          1954,
          51628
        ]
      },
      {
        "avg_logprob": -0.3786702297701694,
        "compression_ratio": 1.6367521367521367,
        "end": 1396.98,
        "id": 291,
        "no_speech_prob": 0.00003219224890926853,
        "seek": 136926,
        "start": 1394.98,
        "temperature": 0,
        "text": " oh",
        "tokens": [
          51650,
          1954,
          51750
        ]
      },
      {
        "avg_logprob": -0.26462796155144186,
        "compression_ratio": 1.6933333333333334,
        "end": 1401.74,
        "id": 292,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 139926,
        "start": 1399.74,
        "temperature": 0,
        "text": " This is the worst",
        "tokens": [
          50388,
          639,
          307,
          264,
          5855,
          50488
        ]
      },
      {
        "avg_logprob": -0.26462796155144186,
        "compression_ratio": 1.6933333333333334,
        "end": 1409.22,
        "id": 293,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 139926,
        "start": 1403.34,
        "temperature": 0,
        "text": " I'm really doing a whore on so I've done something terrible here, but I hopefully you know you're watching this video",
        "tokens": [
          50568,
          286,
          478,
          534,
          884,
          257,
          315,
          418,
          322,
          370,
          286,
          600,
          1096,
          746,
          6237,
          510,
          11,
          457,
          286,
          4696,
          291,
          458,
          291,
          434,
          1976,
          341,
          960,
          50862
        ]
      },
      {
        "avg_logprob": -0.26462796155144186,
        "compression_ratio": 1.6933333333333334,
        "end": 1410.7,
        "id": 294,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 139926,
        "start": 1409.22,
        "temperature": 0,
        "text": " And maybe this is valuable to you",
        "tokens": [
          50862,
          400,
          1310,
          341,
          307,
          8263,
          281,
          291,
          50936
        ]
      },
      {
        "avg_logprob": -0.26462796155144186,
        "compression_ratio": 1.6933333333333334,
        "end": 1415.98,
        "id": 295,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 139926,
        "start": 1410.7,
        "temperature": 0,
        "text": " I have really conflated the idea of the 2d array that stores the values with the object",
        "tokens": [
          50936,
          286,
          362,
          534,
          1497,
          38539,
          264,
          1558,
          295,
          264,
          568,
          67,
          10225,
          300,
          9512,
          264,
          4190,
          365,
          264,
          2657,
          51200
        ]
      },
      {
        "avg_logprob": -0.26462796155144186,
        "compression_ratio": 1.6933333333333334,
        "end": 1419.74,
        "id": 296,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 139926,
        "start": 1415.98,
        "temperature": 0,
        "text": " And I'm using it all sorts of terrible ways, so let's think about this",
        "tokens": [
          51200,
          400,
          286,
          478,
          1228,
          309,
          439,
          7527,
          295,
          6237,
          2098,
          11,
          370,
          718,
          311,
          519,
          466,
          341,
          51388
        ]
      },
      {
        "avg_logprob": -0.26462796155144186,
        "compression_ratio": 1.6933333333333334,
        "end": 1426.78,
        "id": 297,
        "no_speech_prob": 0.00016346437041647732,
        "seek": 139926,
        "start": 1421.98,
        "temperature": 0,
        "text": " This is this is this is what I want a is this B is n",
        "tokens": [
          51500,
          639,
          307,
          341,
          307,
          341,
          307,
          437,
          286,
          528,
          257,
          307,
          341,
          363,
          307,
          297,
          51740
        ]
      },
      {
        "avg_logprob": -0.28668534128289475,
        "compression_ratio": 1.6743119266055047,
        "end": 1434.18,
        "id": 298,
        "no_speech_prob": 0.00003024190664291382,
        "seek": 142678,
        "start": 1427.42,
        "temperature": 0,
        "text": " Now I can get the rows and columns, but down here. I really need to say a dot matrix",
        "tokens": [
          50396,
          823,
          286,
          393,
          483,
          264,
          13241,
          293,
          13766,
          11,
          457,
          760,
          510,
          13,
          286,
          534,
          643,
          281,
          584,
          257,
          5893,
          8141,
          50734
        ]
      },
      {
        "avg_logprob": -0.28668534128289475,
        "compression_ratio": 1.6743119266055047,
        "end": 1436.82,
        "id": 299,
        "no_speech_prob": 0.00003024190664291382,
        "seek": 142678,
        "start": 1434.82,
        "temperature": 0,
        "text": " B dot matrix",
        "tokens": [
          50766,
          363,
          5893,
          8141,
          50866
        ]
      },
      {
        "avg_logprob": -0.28668534128289475,
        "compression_ratio": 1.6743119266055047,
        "end": 1441.22,
        "id": 300,
        "no_speech_prob": 0.00003024190664291382,
        "seek": 142678,
        "start": 1438.1399999999999,
        "temperature": 0,
        "text": " Right and and that goes into the result dot matrix",
        "tokens": [
          50932,
          1779,
          293,
          293,
          300,
          1709,
          666,
          264,
          1874,
          5893,
          8141,
          51086
        ]
      },
      {
        "avg_logprob": -0.28668534128289475,
        "compression_ratio": 1.6743119266055047,
        "end": 1446.42,
        "id": 301,
        "no_speech_prob": 0.00003024190664291382,
        "seek": 142678,
        "start": 1443.78,
        "temperature": 0,
        "text": " So I hopefully this is clear to you the issue",
        "tokens": [
          51214,
          407,
          286,
          4696,
          341,
          307,
          1850,
          281,
          291,
          264,
          2734,
          51346
        ]
      },
      {
        "avg_logprob": -0.28668534128289475,
        "compression_ratio": 1.6743119266055047,
        "end": 1449.54,
        "id": 302,
        "no_speech_prob": 0.00003024190664291382,
        "seek": 142678,
        "start": 1446.42,
        "temperature": 0,
        "text": " But let me try to rephrase it again in case it's not",
        "tokens": [
          51346,
          583,
          718,
          385,
          853,
          281,
          319,
          44598,
          651,
          309,
          797,
          294,
          1389,
          309,
          311,
          406,
          51502
        ]
      },
      {
        "avg_logprob": -0.28668534128289475,
        "compression_ratio": 1.6743119266055047,
        "end": 1456.66,
        "id": 303,
        "no_speech_prob": 0.00003024190664291382,
        "seek": 142678,
        "start": 1449.8999999999999,
        "temperature": 0,
        "text": " There is this idea of a matrix object it has three properties the number of rows the number of columns and the actual",
        "tokens": [
          51520,
          821,
          307,
          341,
          1558,
          295,
          257,
          8141,
          2657,
          309,
          575,
          1045,
          7221,
          264,
          1230,
          295,
          13241,
          264,
          1230,
          295,
          13766,
          293,
          264,
          3539,
          51858
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1460.78,
        "id": 304,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1456.98,
        "temperature": 0,
        "text": " 2d array so if I refer to the variable that's the matrix object",
        "tokens": [
          50374,
          568,
          67,
          10225,
          370,
          498,
          286,
          2864,
          281,
          264,
          7006,
          300,
          311,
          264,
          8141,
          2657,
          50564
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1462.42,
        "id": 305,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1460.78,
        "temperature": 0,
        "text": " And I want to actually do something to the data",
        "tokens": [
          50564,
          400,
          286,
          528,
          281,
          767,
          360,
          746,
          281,
          264,
          1412,
          50646
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1469.3,
        "id": 306,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1462.42,
        "temperature": 0,
        "text": " I have to say the name of the object dot matrix and some I'm forgetting to do that in so many different places",
        "tokens": [
          50646,
          286,
          362,
          281,
          584,
          264,
          1315,
          295,
          264,
          2657,
          5893,
          8141,
          293,
          512,
          286,
          478,
          25428,
          281,
          360,
          300,
          294,
          370,
          867,
          819,
          3190,
          50990
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1471.8999999999999,
        "id": 307,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1469.8999999999999,
        "temperature": 0,
        "text": " so",
        "tokens": [
          51020,
          370,
          51120
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1474.1399999999999,
        "id": 308,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1472.1399999999999,
        "temperature": 0,
        "text": " What I'm gonna do what I'm gonna look at down",
        "tokens": [
          51132,
          708,
          286,
          478,
          799,
          360,
          437,
          286,
          478,
          799,
          574,
          412,
          760,
          51232
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1478.54,
        "id": 309,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1474.1399999999999,
        "temperature": 0,
        "text": " Here's I think now everything is correct if a and B are the names of the objects",
        "tokens": [
          51232,
          1692,
          311,
          286,
          519,
          586,
          1203,
          307,
          3006,
          498,
          257,
          293,
          363,
          366,
          264,
          5288,
          295,
          264,
          6565,
          51452
        ]
      },
      {
        "avg_logprob": -0.24056447241917128,
        "compression_ratio": 1.8577235772357723,
        "end": 1484.58,
        "id": 310,
        "no_speech_prob": 0.000021444908270495944,
        "seek": 145678,
        "start": 1478.54,
        "temperature": 0,
        "text": " I can pull out the rows and columns from a and then I can pull up the values from a dot matrix and B dot",
        "tokens": [
          51452,
          286,
          393,
          2235,
          484,
          264,
          13241,
          293,
          13766,
          490,
          257,
          293,
          550,
          286,
          393,
          2235,
          493,
          264,
          4190,
          490,
          257,
          5893,
          8141,
          293,
          363,
          5893,
          51754
        ]
      },
      {
        "avg_logprob": -0.2829134666313559,
        "compression_ratio": 1.483221476510067,
        "end": 1487.74,
        "id": 311,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 148458,
        "start": 1484.58,
        "temperature": 0,
        "text": " Matrix and set the values in result dot matrix",
        "tokens": [
          50364,
          36274,
          293,
          992,
          264,
          4190,
          294,
          1874,
          5893,
          8141,
          50522
        ]
      },
      {
        "avg_logprob": -0.2829134666313559,
        "compression_ratio": 1.483221476510067,
        "end": 1490.34,
        "id": 312,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 148458,
        "start": 1488.34,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50552,
          1033,
          50652
        ]
      },
      {
        "avg_logprob": -0.2829134666313559,
        "compression_ratio": 1.483221476510067,
        "end": 1498.02,
        "id": 313,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 148458,
        "start": 1490.9399999999998,
        "temperature": 0,
        "text": " How I shouldn't be confident I really should not be confident. This is a terrible idea, but I'm confident",
        "tokens": [
          50682,
          1012,
          286,
          4659,
          380,
          312,
          6679,
          286,
          534,
          820,
          406,
          312,
          6679,
          13,
          639,
          307,
          257,
          6237,
          1558,
          11,
          457,
          286,
          478,
          6679,
          51036
        ]
      },
      {
        "avg_logprob": -0.2829134666313559,
        "compression_ratio": 1.483221476510067,
        "end": 1508.78,
        "id": 314,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 148458,
        "start": 1503.6399999999999,
        "temperature": 0,
        "text": " Okay, so we finally got three things if this is a and this is B",
        "tokens": [
          51317,
          1033,
          11,
          370,
          321,
          2721,
          658,
          1045,
          721,
          498,
          341,
          307,
          257,
          293,
          341,
          307,
          363,
          51574
        ]
      },
      {
        "avg_logprob": -0.33117978713091684,
        "compression_ratio": 1.640316205533597,
        "end": 1515.94,
        "id": 315,
        "no_speech_prob": 0.0010987221030518413,
        "seek": 150878,
        "start": 1509.06,
        "temperature": 0,
        "text": " This is a dot B anybody want to fact-check from me for this come to the chat I don't",
        "tokens": [
          50378,
          639,
          307,
          257,
          5893,
          363,
          4472,
          528,
          281,
          1186,
          12,
          15723,
          490,
          385,
          337,
          341,
          808,
          281,
          264,
          5081,
          286,
          500,
          380,
          50722
        ]
      },
      {
        "avg_logprob": -0.33117978713091684,
        "compression_ratio": 1.640316205533597,
        "end": 1520.26,
        "id": 316,
        "no_speech_prob": 0.0010987221030518413,
        "seek": 150878,
        "start": 1516.98,
        "temperature": 0,
        "text": " I'm gonna pop I'm gonna wait now this will get edited out",
        "tokens": [
          50774,
          286,
          478,
          799,
          1665,
          286,
          478,
          799,
          1699,
          586,
          341,
          486,
          483,
          23016,
          484,
          50938
        ]
      },
      {
        "avg_logprob": -0.33117978713091684,
        "compression_ratio": 1.640316205533597,
        "end": 1528.58,
        "id": 317,
        "no_speech_prob": 0.0010987221030518413,
        "seek": 150878,
        "start": 1523.42,
        "temperature": 0,
        "text": " Thank you, thank you these numbers are in fact correct. I took a little break there and check them. They are right",
        "tokens": [
          51096,
          1044,
          291,
          11,
          1309,
          291,
          613,
          3547,
          366,
          294,
          1186,
          3006,
          13,
          286,
          1890,
          257,
          707,
          1821,
          456,
          293,
          1520,
          552,
          13,
          814,
          366,
          558,
          51354
        ]
      },
      {
        "avg_logprob": -0.33117978713091684,
        "compression_ratio": 1.640316205533597,
        "end": 1532.94,
        "id": 318,
        "no_speech_prob": 0.0010987221030518413,
        "seek": 150878,
        "start": 1528.58,
        "temperature": 0,
        "text": " I encourage you to pause the video and check them yourself to see if you understand how the library is working",
        "tokens": [
          51354,
          286,
          5373,
          291,
          281,
          10465,
          264,
          960,
          293,
          1520,
          552,
          1803,
          281,
          536,
          498,
          291,
          1223,
          577,
          264,
          6405,
          307,
          1364,
          51572
        ]
      },
      {
        "avg_logprob": -0.33117978713091684,
        "compression_ratio": 1.640316205533597,
        "end": 1534.86,
        "id": 319,
        "no_speech_prob": 0.0010987221030518413,
        "seek": 150878,
        "start": 1533.22,
        "temperature": 0,
        "text": " One thing that actually could be really useful",
        "tokens": [
          51586,
          1485,
          551,
          300,
          767,
          727,
          312,
          534,
          4420,
          51668
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1539.9399999999998,
        "id": 320,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1534.86,
        "temperature": 0,
        "text": " I don't ever employ tests ever really, but I should learn about tests",
        "tokens": [
          50364,
          286,
          500,
          380,
          1562,
          3188,
          6921,
          1562,
          534,
          11,
          457,
          286,
          820,
          1466,
          466,
          6921,
          50618
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1542.1,
        "id": 321,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1539.9399999999998,
        "temperature": 0,
        "text": " And I should probably do some stuff with tests on this channel",
        "tokens": [
          50618,
          400,
          286,
          820,
          1391,
          360,
          512,
          1507,
          365,
          6921,
          322,
          341,
          2269,
          50726
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1544.58,
        "id": 322,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1542.1,
        "temperature": 0,
        "text": " So I think I might come back and try to do some tests",
        "tokens": [
          50726,
          407,
          286,
          519,
          286,
          1062,
          808,
          646,
          293,
          853,
          281,
          360,
          512,
          6921,
          50850
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1550.34,
        "id": 323,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1544.6999999999998,
        "temperature": 0,
        "text": " That would if I ever change the code for this matrix library to ensure that the math still works",
        "tokens": [
          50856,
          663,
          576,
          498,
          286,
          1562,
          1319,
          264,
          3089,
          337,
          341,
          8141,
          6405,
          281,
          5586,
          300,
          264,
          5221,
          920,
          1985,
          51138
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1552.5,
        "id": 324,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1550.34,
        "temperature": 0,
        "text": " So maybe someday I'll come back and do that",
        "tokens": [
          51138,
          407,
          1310,
          19412,
          286,
          603,
          808,
          646,
          293,
          360,
          300,
          51246
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1558.1,
        "id": 325,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1553.62,
        "temperature": 0,
        "text": " But and now yes, there needs to be a lot of tidying up and refactoring",
        "tokens": [
          51302,
          583,
          293,
          586,
          2086,
          11,
          456,
          2203,
          281,
          312,
          257,
          688,
          295,
          9422,
          1840,
          493,
          293,
          1895,
          578,
          3662,
          51526
        ]
      },
      {
        "avg_logprob": -0.2530208797905389,
        "compression_ratio": 1.710344827586207,
        "end": 1562.7199999999998,
        "id": 326,
        "no_speech_prob": 0.012624550610780716,
        "seek": 153486,
        "start": 1558.1,
        "temperature": 0,
        "text": " I can use these array functions, and I'm gonna get to all that but now we're ready the next video",
        "tokens": [
          51526,
          286,
          393,
          764,
          613,
          10225,
          6828,
          11,
          293,
          286,
          478,
          799,
          483,
          281,
          439,
          300,
          457,
          586,
          321,
          434,
          1919,
          264,
          958,
          960,
          51757
        ]
      },
      {
        "avg_logprob": -0.35853424850775273,
        "compression_ratio": 1.6177606177606179,
        "end": 1565.04,
        "id": 327,
        "no_speech_prob": 0.00008614626858616248,
        "seek": 156272,
        "start": 1562.84,
        "temperature": 0,
        "text": " I can take this matrix",
        "tokens": [
          50370,
          286,
          393,
          747,
          341,
          8141,
          50480
        ]
      },
      {
        "avg_logprob": -0.35853424850775273,
        "compression_ratio": 1.6177606177606179,
        "end": 1572.68,
        "id": 328,
        "no_speech_prob": 0.00008614626858616248,
        "seek": 156272,
        "start": 1565.72,
        "temperature": 0,
        "text": " Library this matrix class and use it in my neural network class to perform",
        "tokens": [
          50514,
          12806,
          341,
          8141,
          1508,
          293,
          764,
          309,
          294,
          452,
          18161,
          3209,
          1508,
          281,
          2042,
          50862
        ]
      },
      {
        "avg_logprob": -0.35853424850775273,
        "compression_ratio": 1.6177606177606179,
        "end": 1576.76,
        "id": 329,
        "no_speech_prob": 0.00008614626858616248,
        "seek": 156272,
        "start": 1573.1200000000001,
        "temperature": 0,
        "text": " the feed-forward algorithm of taking all these inputs",
        "tokens": [
          50884,
          264,
          3154,
          12,
          13305,
          9284,
          295,
          1940,
          439,
          613,
          15743,
          51066
        ]
      },
      {
        "avg_logprob": -0.35853424850775273,
        "compression_ratio": 1.6177606177606179,
        "end": 1582.52,
        "id": 330,
        "no_speech_prob": 0.00008614626858616248,
        "seek": 156272,
        "start": 1577.24,
        "temperature": 0,
        "text": " Multiplying them by weights and getting new outputs which then go into other node",
        "tokens": [
          51090,
          31150,
          7310,
          552,
          538,
          17443,
          293,
          1242,
          777,
          23930,
          597,
          550,
          352,
          666,
          661,
          9984,
          51354
        ]
      },
      {
        "avg_logprob": -0.35853424850775273,
        "compression_ratio": 1.6177606177606179,
        "end": 1587,
        "id": 331,
        "no_speech_prob": 0.00008614626858616248,
        "seek": 156272,
        "start": 1582.52,
        "temperature": 0,
        "text": " They become inputs to a hidden layer of nodes etc. So I've talked about that in the previous videos",
        "tokens": [
          51354,
          814,
          1813,
          15743,
          281,
          257,
          7633,
          4583,
          295,
          13891,
          5183,
          13,
          407,
          286,
          600,
          2825,
          466,
          300,
          294,
          264,
          3894,
          2145,
          51578
        ]
      },
      {
        "avg_logprob": -0.35853424850775273,
        "compression_ratio": 1.6177606177606179,
        "end": 1591.44,
        "id": 332,
        "no_speech_prob": 0.00008614626858616248,
        "seek": 156272,
        "start": 1587,
        "temperature": 0,
        "text": " And now I'm gonna come back and actually do that Simon in the chat makes a good point",
        "tokens": [
          51578,
          400,
          586,
          286,
          478,
          799,
          808,
          646,
          293,
          767,
          360,
          300,
          13193,
          294,
          264,
          5081,
          1669,
          257,
          665,
          935,
          51800
        ]
      },
      {
        "avg_logprob": -0.2884781630997805,
        "compression_ratio": 1.7746478873239437,
        "end": 1594.3200000000002,
        "id": 333,
        "no_speech_prob": 0.00017130729975178838,
        "seek": 159144,
        "start": 1592.2,
        "temperature": 0,
        "text": " Where if you look at this class",
        "tokens": [
          50402,
          2305,
          498,
          291,
          574,
          412,
          341,
          1508,
          50508
        ]
      },
      {
        "avg_logprob": -0.2884781630997805,
        "compression_ratio": 1.7746478873239437,
        "end": 1597.6000000000001,
        "id": 334,
        "no_speech_prob": 0.00017130729975178838,
        "seek": 159144,
        "start": 1595.2,
        "temperature": 0,
        "text": " all of these functions randomize add",
        "tokens": [
          50552,
          439,
          295,
          613,
          6828,
          4974,
          1125,
          909,
          50672
        ]
      },
      {
        "avg_logprob": -0.2884781630997805,
        "compression_ratio": 1.7746478873239437,
        "end": 1605.04,
        "id": 335,
        "no_speech_prob": 0.00017130729975178838,
        "seek": 159144,
        "start": 1599.0800000000002,
        "temperature": 0,
        "text": " Multiply what up to multiply they change the object that I'm calling the function on so if I say",
        "tokens": [
          50746,
          31150,
          356,
          437,
          493,
          281,
          12972,
          436,
          1319,
          264,
          2657,
          300,
          286,
          478,
          5141,
          264,
          2445,
          322,
          370,
          498,
          286,
          584,
          51044
        ]
      },
      {
        "avg_logprob": -0.2884781630997805,
        "compression_ratio": 1.7746478873239437,
        "end": 1613.16,
        "id": 336,
        "no_speech_prob": 0.00017130729975178838,
        "seek": 159144,
        "start": 1605.68,
        "temperature": 0,
        "text": " Matrix a I say a dot randomize that matrix object actually changes, but in this with this matrix product",
        "tokens": [
          51076,
          36274,
          257,
          286,
          584,
          257,
          5893,
          4974,
          1125,
          300,
          8141,
          2657,
          767,
          2962,
          11,
          457,
          294,
          341,
          365,
          341,
          8141,
          1674,
          51450
        ]
      },
      {
        "avg_logprob": -0.2884781630997805,
        "compression_ratio": 1.7746478873239437,
        "end": 1615.16,
        "id": 337,
        "no_speech_prob": 0.00017130729975178838,
        "seek": 159144,
        "start": 1613.16,
        "temperature": 0,
        "text": " I'm not actually affecting the object when I say a",
        "tokens": [
          51450,
          286,
          478,
          406,
          767,
          17476,
          264,
          2657,
          562,
          286,
          584,
          257,
          51550
        ]
      },
      {
        "avg_logprob": -0.2884781630997805,
        "compression_ratio": 1.7746478873239437,
        "end": 1618.88,
        "id": 338,
        "no_speech_prob": 0.00017130729975178838,
        "seek": 159144,
        "start": 1616,
        "temperature": 0,
        "text": " Multiply B. I don't change the value of a I create a new",
        "tokens": [
          51592,
          31150,
          356,
          363,
          13,
          286,
          500,
          380,
          1319,
          264,
          2158,
          295,
          257,
          286,
          1884,
          257,
          777,
          51736
        ]
      },
      {
        "avg_logprob": -0.2768899567273198,
        "compression_ratio": 1.6356275303643724,
        "end": 1621.6000000000001,
        "id": 339,
        "no_speech_prob": 0.000007296368949027965,
        "seek": 161888,
        "start": 1619.6000000000001,
        "temperature": 0,
        "text": " a new",
        "tokens": [
          50400,
          257,
          777,
          50500
        ]
      },
      {
        "avg_logprob": -0.2768899567273198,
        "compression_ratio": 1.6356275303643724,
        "end": 1629.44,
        "id": 340,
        "no_speech_prob": 0.000007296368949027965,
        "seek": 161888,
        "start": 1621.8000000000002,
        "temperature": 0,
        "text": " Matrix object and return that value so I probably should refactor the library to do maybe that",
        "tokens": [
          50510,
          36274,
          2657,
          293,
          2736,
          300,
          2158,
          370,
          286,
          1391,
          820,
          1895,
          15104,
          264,
          6405,
          281,
          360,
          1310,
          300,
          50892
        ]
      },
      {
        "avg_logprob": -0.2768899567273198,
        "compression_ratio": 1.6356275303643724,
        "end": 1636.16,
        "id": 341,
        "no_speech_prob": 0.000007296368949027965,
        "seek": 161888,
        "start": 1632.0400000000002,
        "temperature": 0,
        "text": " Matrix product in a slightly different way, and I could use something called a static method",
        "tokens": [
          51022,
          36274,
          1674,
          294,
          257,
          4748,
          819,
          636,
          11,
          293,
          286,
          727,
          764,
          746,
          1219,
          257,
          13437,
          3170,
          51228
        ]
      },
      {
        "avg_logprob": -0.2768899567273198,
        "compression_ratio": 1.6356275303643724,
        "end": 1639.4,
        "id": 342,
        "no_speech_prob": 0.000007296368949027965,
        "seek": 161888,
        "start": 1636.16,
        "temperature": 0,
        "text": " So I'm like I'll come back maybe in a later video when I refactor this a little bit",
        "tokens": [
          51228,
          407,
          286,
          478,
          411,
          286,
          603,
          808,
          646,
          1310,
          294,
          257,
          1780,
          960,
          562,
          286,
          1895,
          15104,
          341,
          257,
          707,
          857,
          51390
        ]
      },
      {
        "avg_logprob": -0.2768899567273198,
        "compression_ratio": 1.6356275303643724,
        "end": 1641.92,
        "id": 343,
        "no_speech_prob": 0.000007296368949027965,
        "seek": 161888,
        "start": 1639.4,
        "temperature": 0,
        "text": " I want to mention that now, but it also reminded me",
        "tokens": [
          51390,
          286,
          528,
          281,
          2152,
          300,
          586,
          11,
          457,
          309,
          611,
          15920,
          385,
          51516
        ]
      },
      {
        "avg_logprob": -0.2768899567273198,
        "compression_ratio": 1.6356275303643724,
        "end": 1646.2,
        "id": 344,
        "no_speech_prob": 0.000007296368949027965,
        "seek": 161888,
        "start": 1642.3200000000002,
        "temperature": 0,
        "text": " There's one more matrix operation that I need for the neural network stuff",
        "tokens": [
          51536,
          821,
          311,
          472,
          544,
          8141,
          6916,
          300,
          286,
          643,
          337,
          264,
          18161,
          3209,
          1507,
          51730
        ]
      },
      {
        "avg_logprob": -0.27097225977369577,
        "compression_ratio": 1.934108527131783,
        "end": 1649.8400000000001,
        "id": 345,
        "no_speech_prob": 0.00003535618816385977,
        "seek": 164620,
        "start": 1646.2,
        "temperature": 0,
        "text": " I think I don't actually need it for a feed forward so I could come back and do it after that",
        "tokens": [
          50364,
          286,
          519,
          286,
          500,
          380,
          767,
          643,
          309,
          337,
          257,
          3154,
          2128,
          370,
          286,
          727,
          808,
          646,
          293,
          360,
          309,
          934,
          300,
          50546
        ]
      },
      {
        "avg_logprob": -0.27097225977369577,
        "compression_ratio": 1.934108527131783,
        "end": 1656.24,
        "id": 346,
        "no_speech_prob": 0.00003535618816385977,
        "seek": 164620,
        "start": 1649.8400000000001,
        "temperature": 0,
        "text": " But I do need it for the training aspect when I adjust and tune it based on the what the guess is well",
        "tokens": [
          50546,
          583,
          286,
          360,
          643,
          309,
          337,
          264,
          3097,
          4171,
          562,
          286,
          4369,
          293,
          10864,
          309,
          2361,
          322,
          264,
          437,
          264,
          2041,
          307,
          731,
          50866
        ]
      },
      {
        "avg_logprob": -0.27097225977369577,
        "compression_ratio": 1.934108527131783,
        "end": 1660.52,
        "id": 347,
        "no_speech_prob": 0.00003535618816385977,
        "seek": 164620,
        "start": 1656.24,
        "temperature": 0,
        "text": " I get to all that later the thing that I need is to transpose a matrix",
        "tokens": [
          50866,
          286,
          483,
          281,
          439,
          300,
          1780,
          264,
          551,
          300,
          286,
          643,
          307,
          281,
          25167,
          257,
          8141,
          51080
        ]
      },
      {
        "avg_logprob": -0.27097225977369577,
        "compression_ratio": 1.934108527131783,
        "end": 1665.42,
        "id": 348,
        "no_speech_prob": 0.00003535618816385977,
        "seek": 164620,
        "start": 1660.6000000000001,
        "temperature": 0,
        "text": " So how do I transpose a matrix if I have a matrix a with a certain number of rows and columns?",
        "tokens": [
          51084,
          407,
          577,
          360,
          286,
          25167,
          257,
          8141,
          498,
          286,
          362,
          257,
          8141,
          257,
          365,
          257,
          1629,
          1230,
          295,
          13241,
          293,
          13766,
          30,
          51325
        ]
      },
      {
        "avg_logprob": -0.27097225977369577,
        "compression_ratio": 1.934108527131783,
        "end": 1671.68,
        "id": 349,
        "no_speech_prob": 0.00003535618816385977,
        "seek": 164620,
        "start": 1665.52,
        "temperature": 0,
        "text": " Sorry rows and columns the columns become the rows the rows become the columns so transposing this matrix",
        "tokens": [
          51330,
          4919,
          13241,
          293,
          13766,
          264,
          13766,
          1813,
          264,
          13241,
          264,
          13241,
          1813,
          264,
          13766,
          370,
          7132,
          6110,
          341,
          8141,
          51638
        ]
      },
      {
        "avg_logprob": -0.27097225977369577,
        "compression_ratio": 1.934108527131783,
        "end": 1675.76,
        "id": 350,
        "no_speech_prob": 0.00003535618816385977,
        "seek": 164620,
        "start": 1673.76,
        "temperature": 0,
        "text": " Would turn it into this matrix",
        "tokens": [
          51742,
          6068,
          1261,
          309,
          666,
          341,
          8141,
          51842
        ]
      },
      {
        "avg_logprob": -0.2656111717224121,
        "compression_ratio": 1.0609756097560976,
        "end": 1680.88,
        "id": 351,
        "no_speech_prob": 0.0000033930125482584117,
        "seek": 167620,
        "start": 1676.2,
        "temperature": 0,
        "text": " Okay, so I'm going to quickly in the next video write a function that does exactly that",
        "tokens": [
          50392,
          1033,
          11,
          370,
          286,
          478,
          516,
          281,
          2661,
          294,
          264,
          958,
          960,
          2464,
          257,
          2445,
          300,
          775,
          2293,
          300,
          50598
        ]
      }
    ],
    "transcription": " And we are here. This is the video in this playlist Which really comes right after 10.7 matrix max part 2 this is matrix math part 3 where I am finally going to look at Can't hear it Matrix multiplication or really I should say Matrix multiplication Okay, so if you recall What I'm doing, I know I look quite different, but I already covered that Well previous one was made a while ago anyway if I have a matrix right and what I mean by a matrix is a grid of values and Let's say I have one that looks like this a B C D E F This is a three No, no, no, it is a 2 by 3 matrix We always refer to the number of rows before the number of columns now. What does it mean and and previously with When I made some videos just about vectors I talked about this thing called the dot product But I'm gonna change that here and write the matrix product So first of all, what does it mean to multiply a matrix by by something? I could just multiply this matrix by a single number and that's what's known as well It's not really that's what's known as scalar Sorry scalar if I multiply this by a single number Then I just say if this was a whole bunch of ones multiply it by two I got a whole bunch of twos, you know If I multiply by two double every value in the matrix and I think actually now I did that in the previous video. I Could also do what's known as element wise Multiplication and that is also referred to as the Hadamard I don't know if I'm pronouncing that correctly and Breaking news somebody in the live chat that's going on right now Told me that it also soon as called a sure product and what that means is imagine I have another matrix That's exactly the same size as this one And in fact, I could kind of do that little small over here and I could say G H I J K L Right, so I could have another matrix It's exactly the same size and my new if I multiply these together I have a new matrix which is has a times G B times H C times I D times J element wise each L each element of the matrix get multiplied by its corresponding other element now I Don't those are perfectly valid. I'm looking for my eraser perfectly valid ways of doing multiplication Oops, I don't need to but what I'm really interested in is the matrix product and the reason why I'm interested in the matrix product is because I want to use the matrix product for a neural network for example this Node in a neural network is going to be the result of the weighted sum of all of the input nodes multiplied by weighted connections and This one is also going to be the weighted sum of all of the input nodes multiplied by weighted connections and so on and so forth and so these weights are stored in a matrix and the inputs Come in in the matrix as well. So if this is how I'm representing the inputs Then you might discover that I have this matrix Of all these weights that I need to multiply those inputs by to get The new values of the outputs of this hidden layer now anyway I kind of talked about that in a previous video And I'm going to talk about it a lot more in the next video when we look at this in more detail But the point here is that this idea of a matrix product is something that I'm going to need Don't worry about the whole neural network thing. I'm going to come back to that in Next video go through that in detail what I need to do here is just understand. I know I need the matrix product How does it work and then we'll see how it's applied in the neural network example, okay so let's say that I have another I have a matrix a and I have another matrix B and that matrix is equal to G H I J K L I'm writing the L like that so that I can see that it's not a 1 or whatever. Okay, so I Have these two matrices the way that I write the expression a matrix product B. I'm going to write it like this a dot B The dot as the indicator for the matrix product now what couple things that are really important here one The commutative property does not hold a dot B does not equal B. Dot a this is not true And you're going to see why in a minute You know if I were to say 3 times 4 that's equal to 4 times 3 they're both equal to 12 But again this matrix product is a different kind of multiplication this commutative property does not hold so that's kind of key Another thing that's really important is the matrix product is something you could only do if the sizes of the matrices match up and what do I mean by that now one thing you might have thought but realize like if I When I had that example the Hadamard product that's only going to work if I have two matrices with the same exact dimensions right because if I if I don't have the same exact dimensions How can I multiply each element by the other element because there some elements might not exist in one of them? But something even completely different is going to go on here. I need to have for this to be valid I need to have the columns right the columns of a Equal to the rows of B And you'll notice I made these do that so I have to have however many columns I have here three I have to have exactly the same number of rows in B Otherwise this won't work and the reason is What I'm actually going to do is the reason why I use this dot here is I'm going to use the vector dot product Vector dot product so you might have to go back to one of my previous videos where I talked about the vector dot product course I'm going to do it here again But what the vector dot product does is it takes kind of like the sum of all the elements multiplied? The element wise elements both applied to each other. What do I mean by that? so if I say a dot B I'm going to get when I when I take One matrix the a matrix product B. The result is also going to be a matrix now How do I know the dimensions of that matrix? It's going to have the number of rows of a Which is how many two? Followed by the number of columns of B What two so in the end I'm in a two by two matrix now This is going to be different with any all different matrix Dimensions and after you watch this video you can make up lots of different matrices and play a game with yourself to like do this Matrix product with pencil and paper and boy won't that be fun. I'm gonna go do that later myself. I'm sure But here we can see I'm gonna get a square two by two matrix now. What am I doing here? How do I fill in each of these blanks? So I'm gonna just Put a little blank square here. I know I need two by two well, what I do is I take the dot product of the row of the first one With the cup of the row of a with the column of B Right, so it's almost kind of like the intersection This first element right I got to get the first row of a and the first column of B That's why they have to have the same number of Rows and B as columns in a so what this actually is this value here is the dot product of these two vectors Which is? Actually, I'm just come over here Which is a? times G plus B times I plus C times I Okay, so that's this element here now. Let's do this element here. Well. I'm in row one So I stay with row one of a but now I'm in column two so I go to column two of B so now this particular value is a times H plus B times J plus C times L Okay, that's good. Now. Let me do this one this one is the second row times the first row the first column of B D times G plus E times I plus F times K And then this one here is going to be The second row times the second column D times H plus E times J plus F times L Okay, so that's the math for any arbitrary set of matrices You take the dot product of all the rows with the columns to fill out your resulting matrix product And you must have the same number of columns in a as rows of B Okay, so pause this video if you want try to draw some diagram Google matrix product Google image search matrix product You probably come up with a million visual examples of this Watch three blue one Browns videos on linear algebra will probably teach this in a much more intuitive a nice way, but I I'll link to that in this video's description. I'm now going to try to implement this matrix product in code Minor correction hopefully I said the right thing But I do have something wrong here a times G B times I C times K This should be a K right here Tada Okay, so let's try to implement the math for this So where I'm gonna do this is in the multiply function and I had written that before to do scalar Multiplication and I'm gonna do the same thing I did an ad where I'm gonna check What is the thing coming in is it a matrix or is it a scalar or? Etc. So I'm not gonna bother with the Hadamard product I'll add that into this matrix library if I ever need it But I'm just gonna check is n an instance of a matrix if that's so then I want to do matrix product Otherwise I want to do a Scalar product Okay, so now I need to write the code for the matrix product right there But first I must check Are the columns of a equal to the rows of B? Otherwise, I cannot perform the matrix product at all So I'm gonna come over here and I'm gonna say If I'm in the right screen, yes if The a is this matrix object if this dot rows No, if this dot columns does not equal n dot rows. I Kind of don't like that. This is called n here, but whatever Does then and I'll use this more strict equals here then? Id to return like undefined or something like just get out of here. This is no good and I'm going to console dot log Columns of a must match rows of B Columns now I could be more thoughtful and I can use a try catch and some error handling But I'm just gonna do this for right now just to be some and let's actually make sure this works so if I go back to loading that code and I said something like a is matrix That is 3 by 3 and B is a matrix that is 5 by 10 if I say a multiply B I Get undefined and it says columns of a must match rows of B. So that's working and I could just say B is a matrix Of 5 by sorry 3 by 3 also then they match and I'm say a multiply B I still get undefined because I haven't done it yet, but I don't get that error message. Okay, so now I need to create a new matrix So I'm gonna say the result Is a new matrix that has the number of What did I say it has the number of rows of a and the number of columns of B So it has the number of rows of a and the number of columns of B Come on Adam keeps wanting me to put my password in okay Alright, so that's good. Now. I need to do each spot. So for each For each row whoops For each row and for each column I Need to do the dot product of Whoops first of all, I have an error before I could do this I have an error here and What I want is if I'm at 0 0 I Want all of the values I'm going to do the sum of all of the values Whoa, so I want Let's just do this manually in this case it would be this dot matrix I Times n dot matrix J What sorry I I Need yeah, I need another double nested loop in here right because I'm gonna take this and add I Plus plus one But staying in J J plus one right is this right I Plus two J plus two I mean this isn't I'm making this up because I don't I'm doing this in an arbitrary way we don't know what the actual rows this this just goes up depending on the number of Rows columns there are all right, right So maybe I only need one loop here because I need one loop so what's that Oh, no because these could be different yeah K weak man is telling me in the chat another way of thinking about this is I could say And you know what would might be nice actually One thing that I could do here just at least I think this is gonna help me work this out is I could say let a equal this dot matrix and Let B equal n Just to have variables called a and B for the two different matrices And this is still the result, but in other words what I'm saying is a and this is B So a I K B K J so So hold on let me with K sum over K So hold on so let me put this here did I get this wrong. This is B. Is it Yes, so you know what's wrong about this So let's look now we can get this right. Here's what I'm doing here. I want a I want to be increasing Not the row, but the column. I did it wrong. I did it backwards Do you guys like watching these videos where I try to figure it out? I don't know It could I could just get it right the first time I could just like start over and get it right But what I'm doing is I'm every Column of a which column is I'm actually using Yes, it's called it's all it's row I but I'm iterating over the columns of course of course of course So it is this J So This is actually this is what I need so what I should be able to say is Result I need another loop for let K equals 0 K is less than and I can use remember I could use a's Columns or B's rows those have to be the same so I'm going to use a's columns Yes K plus plus and then I'm gonna first I need to say let sum equals 0 and then I'm gonna say sum plus equal a index I K plus B index K J This I think is right and then I have to put that in the result result I J equals some So if I was using like some other vector library I could like pull those out then do the dot product But let's see here. Let's make sure this is right I want to for every element in the results I want to sum the dot product of all of the column spots in a that's K with all of the row spots in B, and then I've got the result and Line 50 times think deep space in the chat says line 57. Oh, yes, sorry this needs to be multiplied so these get multiplied I'm summing the product of all those Yes, and of course there are much faster ways. I'm not looking for any any efficiency here I'm just trying to understand the algorithm and make sure I have something that works Okay, so now I need one more curly bracket, and I think If I zoom back out here, I think I am done This is the algorithm right I have a new matrix That has that is of the size of and this I should do this down here the size of a's rows and B's columns Then I go through it And I do the dot product of a vector from of a row of a and a column of B store that result Okay, and be I yes Here's another mistake B equals n dot matrix right because the actual two-dimensional array is stored in a variable called matrix It's not It's not the it's the object itself has the data inside a variable okay? So how do we get a test this I actually have a sketch here? So I'm gonna in that's a p5 sketch. I'm not gonna use anything about p5. I'm gonna have a be a new matrix That's 3 by 2 sorry 2 by 3 I'm gonna say the same for B. Which is 3 by 2 Then I'm gonna say a a dot randomize B dot randomize Console dot log a dot matrix and console dot log And not dot log dot table B dot matrix So let's take a look at that Okay, so now I have to make two matrices. This is one and they with random values in them, so now I'm gonna say Let C equal a dot multiply B I didn't get anything there. Oh, oh, I didn't console log it oh man console table C dot matrix I Forgot about that part okay here. We go again Shoot all right, so what's this error sketch such as line 11? Cannot did I forget to return it I forgot to return it didn't I? Okay, you know what would might be nice is if the end of this I said return result and this actually goes where here Right I got a return that result all right. Let's try this again So I forget hit save oh I'm being told breaking news breaking news The return is in this for loop. That's not good. Oh Right cuz this just the return was in the for loop. That's terrible and this says results, and it should say results, okay? I'm feeling a little bit a Little bit more confident now Oh My goodness I'm completely losing my mind here, so it's very important to realize that result is the matrix object Oh the matrix object has this array called Matrix which actually stores the values and there's no like set function or anything so what I actually really need to put here is result dot matrix Right equals this result dot matrix Equals oh no, and then return result right so I these values that I'm calculating There's probably should be like a set function or something like that And I probably should just created the 2d array here, and then made a major, but whatever This is what it needs to be I think we've got it now. Oh boy Okay, wait wait wait oh oh This is the worst I'm really doing a whore on so I've done something terrible here, but I hopefully you know you're watching this video And maybe this is valuable to you I have really conflated the idea of the 2d array that stores the values with the object And I'm using it all sorts of terrible ways, so let's think about this This is this is this is what I want a is this B is n Now I can get the rows and columns, but down here. I really need to say a dot matrix B dot matrix Right and and that goes into the result dot matrix So I hopefully this is clear to you the issue But let me try to rephrase it again in case it's not There is this idea of a matrix object it has three properties the number of rows the number of columns and the actual 2d array so if I refer to the variable that's the matrix object And I want to actually do something to the data I have to say the name of the object dot matrix and some I'm forgetting to do that in so many different places so What I'm gonna do what I'm gonna look at down Here's I think now everything is correct if a and B are the names of the objects I can pull out the rows and columns from a and then I can pull up the values from a dot matrix and B dot Matrix and set the values in result dot matrix Okay How I shouldn't be confident I really should not be confident. This is a terrible idea, but I'm confident Okay, so we finally got three things if this is a and this is B This is a dot B anybody want to fact-check from me for this come to the chat I don't I'm gonna pop I'm gonna wait now this will get edited out Thank you, thank you these numbers are in fact correct. I took a little break there and check them. They are right I encourage you to pause the video and check them yourself to see if you understand how the library is working One thing that actually could be really useful I don't ever employ tests ever really, but I should learn about tests And I should probably do some stuff with tests on this channel So I think I might come back and try to do some tests That would if I ever change the code for this matrix library to ensure that the math still works So maybe someday I'll come back and do that But and now yes, there needs to be a lot of tidying up and refactoring I can use these array functions, and I'm gonna get to all that but now we're ready the next video I can take this matrix Library this matrix class and use it in my neural network class to perform the feed-forward algorithm of taking all these inputs Multiplying them by weights and getting new outputs which then go into other node They become inputs to a hidden layer of nodes etc. So I've talked about that in the previous videos And now I'm gonna come back and actually do that Simon in the chat makes a good point Where if you look at this class all of these functions randomize add Multiply what up to multiply they change the object that I'm calling the function on so if I say Matrix a I say a dot randomize that matrix object actually changes, but in this with this matrix product I'm not actually affecting the object when I say a Multiply B. I don't change the value of a I create a new a new Matrix object and return that value so I probably should refactor the library to do maybe that Matrix product in a slightly different way, and I could use something called a static method So I'm like I'll come back maybe in a later video when I refactor this a little bit I want to mention that now, but it also reminded me There's one more matrix operation that I need for the neural network stuff I think I don't actually need it for a feed forward so I could come back and do it after that But I do need it for the training aspect when I adjust and tune it based on the what the guess is well I get to all that later the thing that I need is to transpose a matrix So how do I transpose a matrix if I have a matrix a with a certain number of rows and columns? Sorry rows and columns the columns become the rows the rows become the columns so transposing this matrix Would turn it into this matrix Okay, so I'm going to quickly in the next video write a function that does exactly that",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:33.749836Z",
  "started_at": "2023-09-26T21:14:50.717589Z",
  "completed_at": "2023-09-26T21:20:52.453026Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=NgZAIkDcPkI",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 361.735437
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/ixttwmzbnvrfgnel6tcebj6tii/cancel",
    "get": "https://api.replicate.com/v1/predictions/ixttwmzbnvrfgnel6tcebj6tii"
  }
}