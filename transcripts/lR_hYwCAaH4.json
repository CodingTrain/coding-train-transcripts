{
  "id": "dhemu2bblgs44btr5bhfzpom7y",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/lR_hYwCAaH4.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/83487 [00:00<?, ?frames/s]\n  3%|▎         | 2756/83487 [00:08<03:59, 337.74frames/s]\n  7%|▋         | 5584/83487 [00:16<03:57, 327.46frames/s]\n 10%|█         | 8542/83487 [00:26<03:49, 325.97frames/s]\n 14%|█▎        | 11370/83487 [00:35<03:43, 322.45frames/s]\n 17%|█▋        | 14162/83487 [00:41<03:12, 360.82frames/s]\n 21%|██        | 17130/83487 [00:48<02:56, 376.26frames/s]\n 24%|██▍       | 20014/83487 [00:55<02:41, 392.31frames/s]\n 27%|██▋       | 22752/83487 [01:02<02:35, 390.23frames/s]\n 31%|███       | 25668/83487 [01:09<02:29, 387.37frames/s]\n 34%|███▍      | 28668/83487 [01:17<02:20, 390.20frames/s]\n 38%|███▊      | 31442/83487 [01:24<02:16, 382.27frames/s]\n 41%|████      | 34330/83487 [01:35<02:23, 343.21frames/s]\n 45%|████▍     | 37190/83487 [01:46<02:28, 311.55frames/s]\n 48%|████▊     | 39882/83487 [01:54<02:16, 318.66frames/s]\n 51%|█████     | 42752/83487 [02:02<02:04, 325.98frames/s]\n 54%|█████▍    | 45436/83487 [02:09<01:48, 350.89frames/s]\n 58%|█████▊    | 48260/83487 [02:15<01:33, 378.51frames/s]\n 61%|██████    | 51108/83487 [02:26<01:38, 330.25frames/s]\n 65%|██████▍   | 54104/83487 [02:35<01:28, 333.25frames/s]\n 68%|██████▊   | 56942/83487 [02:43<01:18, 339.54frames/s]\n 72%|███████▏  | 59942/83487 [02:49<01:02, 377.66frames/s]\n 75%|███████▌  | 62898/83487 [02:57<00:56, 363.10frames/s]\n 79%|███████▊  | 65642/83487 [03:06<00:50, 350.90frames/s]\n 82%|████████▏ | 68402/83487 [03:12<00:40, 368.33frames/s]\n 85%|████████▍ | 70942/83487 [03:19<00:33, 375.90frames/s]\n 88%|████████▊ | 73742/83487 [03:24<00:23, 420.14frames/s]\n 92%|█████████▏| 76590/83487 [03:30<00:16, 421.76frames/s]\n 95%|█████████▌| 79562/83487 [03:37<00:09, 430.20frames/s]\n 99%|█████████▊| 82438/83487 [03:42<00:02, 460.26frames/s]\n 99%|█████████▊| 82438/83487 [04:02<00:02, 460.26frames/s]\n100%|██████████| 83487/83487 [04:15<00:00, 163.55frames/s]\n100%|██████████| 83487/83487 [04:15<00:00, 326.88frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 4,
        "id": 0,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, this is another video which is a tutorial",
        "tokens": [
          50364,
          2425,
          11,
          341,
          307,
          1071,
          960,
          597,
          307,
          257,
          7073,
          50564
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 6.72,
        "id": 1,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 4,
        "temperature": 0,
        "text": " about working with Git and GitHub.",
        "tokens": [
          50564,
          466,
          1364,
          365,
          16939,
          293,
          23331,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 10,
        "id": 2,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 6.72,
        "temperature": 0,
        "text": " And in this tutorial, I'm going to talk about remotes.",
        "tokens": [
          50700,
          400,
          294,
          341,
          7073,
          11,
          286,
          478,
          516,
          281,
          751,
          466,
          890,
          17251,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 11.88,
        "id": 3,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 10,
        "temperature": 0,
        "text": " Woohoo, yes.",
        "tokens": [
          50864,
          10468,
          19069,
          11,
          2086,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 14.64,
        "id": 4,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 11.88,
        "temperature": 0,
        "text": " So I'm in the middle of live streaming",
        "tokens": [
          50958,
          407,
          286,
          478,
          294,
          264,
          2808,
          295,
          1621,
          11791,
          51096
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 16.84,
        "id": 5,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 14.64,
        "temperature": 0,
        "text": " and I'm working on this project that has to do",
        "tokens": [
          51096,
          293,
          286,
          478,
          1364,
          322,
          341,
          1716,
          300,
          575,
          281,
          360,
          51206
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 18.52,
        "id": 6,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 16.84,
        "temperature": 0,
        "text": " with this Flappy Bird clone.",
        "tokens": [
          51206,
          365,
          341,
          479,
          875,
          7966,
          15931,
          26506,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 22.36,
        "id": 7,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 18.52,
        "temperature": 0,
        "text": " I'm going to train a bot using a genetic algorithm",
        "tokens": [
          51290,
          286,
          478,
          516,
          281,
          3847,
          257,
          10592,
          1228,
          257,
          12462,
          9284,
          51482
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 24.72,
        "id": 8,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 22.36,
        "temperature": 0,
        "text": " and a neural network to play Flappy Bird.",
        "tokens": [
          51482,
          293,
          257,
          18161,
          3209,
          281,
          862,
          479,
          875,
          7966,
          15931,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.28570672740106995,
        "compression_ratio": 1.6458333333333333,
        "end": 27.560000000000002,
        "id": 9,
        "no_speech_prob": 0.008186718448996544,
        "seek": 0,
        "start": 24.72,
        "temperature": 0,
        "text": " And I have a wonderful pull request",
        "tokens": [
          51600,
          400,
          286,
          362,
          257,
          3715,
          2235,
          5308,
          51742
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 32.36,
        "id": 10,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 27.56,
        "temperature": 0,
        "text": " from GitHub user Keegan M, who has added",
        "tokens": [
          50364,
          490,
          23331,
          4195,
          3189,
          43118,
          376,
          11,
          567,
          575,
          3869,
          50604
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 35.92,
        "id": 11,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 32.36,
        "temperature": 0,
        "text": " this particular image to be the Flappy Bird",
        "tokens": [
          50604,
          341,
          1729,
          3256,
          281,
          312,
          264,
          479,
          875,
          7966,
          15931,
          50782
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 38.8,
        "id": 12,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 35.92,
        "temperature": 0,
        "text": " and this particular background to be the background",
        "tokens": [
          50782,
          293,
          341,
          1729,
          3678,
          281,
          312,
          264,
          3678,
          50926
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 40.1,
        "id": 13,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 38.8,
        "temperature": 0,
        "text": " of the Flappy Bird game.",
        "tokens": [
          50926,
          295,
          264,
          479,
          875,
          7966,
          15931,
          1216,
          13,
          50991
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 42.28,
        "id": 14,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 40.1,
        "temperature": 0,
        "text": " And I really want to accept this pull request,",
        "tokens": [
          50991,
          400,
          286,
          534,
          528,
          281,
          3241,
          341,
          2235,
          5308,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 44.599999999999994,
        "id": 15,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 42.28,
        "temperature": 0,
        "text": " but what I want to do, and I can examine it",
        "tokens": [
          51100,
          457,
          437,
          286,
          528,
          281,
          360,
          11,
          293,
          286,
          393,
          17496,
          309,
          51216
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 46.08,
        "id": 16,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 44.599999999999994,
        "temperature": 0,
        "text": " through the GitHub interface.",
        "tokens": [
          51216,
          807,
          264,
          23331,
          9226,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 49.12,
        "id": 17,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 46.08,
        "temperature": 0,
        "text": " I can see, ah, this was deleted and this was added",
        "tokens": [
          51290,
          286,
          393,
          536,
          11,
          3716,
          11,
          341,
          390,
          22981,
          293,
          341,
          390,
          3869,
          51442
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 50.519999999999996,
        "id": 18,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 49.12,
        "temperature": 0,
        "text": " because now it's going to have an image",
        "tokens": [
          51442,
          570,
          586,
          309,
          311,
          516,
          281,
          362,
          364,
          3256,
          51512
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 54,
        "id": 19,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 50.519999999999996,
        "temperature": 0,
        "text": " and there's a icon variable which loads the image.",
        "tokens": [
          51512,
          293,
          456,
          311,
          257,
          6528,
          7006,
          597,
          12668,
          264,
          3256,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.23108724975585937,
        "compression_ratio": 1.7392996108949417,
        "end": 55.84,
        "id": 20,
        "no_speech_prob": 0.000010783239304146264,
        "seek": 2756,
        "start": 54,
        "temperature": 0,
        "text": " Those are some things,",
        "tokens": [
          51686,
          3950,
          366,
          512,
          721,
          11,
          51778
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 57.64,
        "id": 21,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 55.84,
        "temperature": 0,
        "text": " those are some wonderful things like that",
        "tokens": [
          50364,
          729,
          366,
          512,
          3715,
          721,
          411,
          300,
          50454
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 61.480000000000004,
        "id": 22,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 57.64,
        "temperature": 0,
        "text": " that I want to accept, but I don't have any unit testing",
        "tokens": [
          50454,
          300,
          286,
          528,
          281,
          3241,
          11,
          457,
          286,
          500,
          380,
          362,
          604,
          4985,
          4997,
          50646
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 64.12,
        "id": 23,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 61.480000000000004,
        "temperature": 0,
        "text": " and this isn't hosted anywhere,",
        "tokens": [
          50646,
          293,
          341,
          1943,
          380,
          19204,
          4992,
          11,
          50778
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 67.12,
        "id": 24,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 64.12,
        "temperature": 0,
        "text": " so I want to actually look at it locally on my computer",
        "tokens": [
          50778,
          370,
          286,
          528,
          281,
          767,
          574,
          412,
          309,
          16143,
          322,
          452,
          3820,
          50928
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 71.28,
        "id": 25,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 67.12,
        "temperature": 0,
        "text": " to run the code and see before I merge it.",
        "tokens": [
          50928,
          281,
          1190,
          264,
          3089,
          293,
          536,
          949,
          286,
          22183,
          309,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 74.08000000000001,
        "id": 26,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 71.28,
        "temperature": 0,
        "text": " And so there's a variety of ways that this can be done",
        "tokens": [
          51136,
          400,
          370,
          456,
          311,
          257,
          5673,
          295,
          2098,
          300,
          341,
          393,
          312,
          1096,
          51276
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 75.92,
        "id": 27,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 74.08000000000001,
        "temperature": 0,
        "text": " more efficiently than what I'm going to show you right now,",
        "tokens": [
          51276,
          544,
          19621,
          813,
          437,
          286,
          478,
          516,
          281,
          855,
          291,
          558,
          586,
          11,
          51368
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 78.88,
        "id": 28,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 75.92,
        "temperature": 0,
        "text": " but this is a good excuse to talk about remotes.",
        "tokens": [
          51368,
          457,
          341,
          307,
          257,
          665,
          8960,
          281,
          751,
          466,
          890,
          17251,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 80.48,
        "id": 29,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 78.88,
        "temperature": 0,
        "text": " So what is a remote?",
        "tokens": [
          51516,
          407,
          437,
          307,
          257,
          8607,
          30,
          51596
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 82.52000000000001,
        "id": 30,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 80.48,
        "temperature": 0,
        "text": " So right now, my terminal window,",
        "tokens": [
          51596,
          407,
          558,
          586,
          11,
          452,
          14709,
          4910,
          11,
          51698
        ]
      },
      {
        "avg_logprob": -0.20043955058076957,
        "compression_ratio": 1.6955017301038062,
        "end": 85.42,
        "id": 31,
        "no_speech_prob": 0.000004495172106544487,
        "seek": 5584,
        "start": 82.52000000000001,
        "temperature": 0,
        "text": " which I want to make a little bit bigger,",
        "tokens": [
          51698,
          597,
          286,
          528,
          281,
          652,
          257,
          707,
          857,
          3801,
          11,
          51843
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 88.04,
        "id": 32,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 86.26,
        "temperature": 0,
        "text": " is in the directory of this project.",
        "tokens": [
          50406,
          307,
          294,
          264,
          21120,
          295,
          341,
          1716,
          13,
          50495
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 90.48,
        "id": 33,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 88.04,
        "temperature": 0,
        "text": " I'm on the desktop, Flappy Bird clone.",
        "tokens": [
          50495,
          286,
          478,
          322,
          264,
          14502,
          11,
          479,
          875,
          7966,
          15931,
          26506,
          13,
          50617
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 95.02,
        "id": 34,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 90.48,
        "temperature": 0,
        "text": " If I say git remote, remote is a command dash v,",
        "tokens": [
          50617,
          759,
          286,
          584,
          18331,
          8607,
          11,
          8607,
          307,
          257,
          5622,
          8240,
          371,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 97.78,
        "id": 35,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 95.02,
        "temperature": 0,
        "text": " dash v for verbose, like I want to know as much as possible,",
        "tokens": [
          50844,
          8240,
          371,
          337,
          9595,
          541,
          11,
          411,
          286,
          528,
          281,
          458,
          382,
          709,
          382,
          1944,
          11,
          50982
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 99.82000000000001,
        "id": 36,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 97.78,
        "temperature": 0,
        "text": " I want to be very verbose about the remote,",
        "tokens": [
          50982,
          286,
          528,
          281,
          312,
          588,
          9595,
          541,
          466,
          264,
          8607,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 104.04,
        "id": 37,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 99.82000000000001,
        "temperature": 0,
        "text": " it's going to say, oh look, you have a remote",
        "tokens": [
          51084,
          309,
          311,
          516,
          281,
          584,
          11,
          1954,
          574,
          11,
          291,
          362,
          257,
          8607,
          51295
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 107.38,
        "id": 38,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 104.04,
        "temperature": 0,
        "text": " that is named origin that is tied to this URL",
        "tokens": [
          51295,
          300,
          307,
          4926,
          4957,
          300,
          307,
          9601,
          281,
          341,
          12905,
          51462
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 110.42,
        "id": 39,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 107.38,
        "temperature": 0,
        "text": " and that makes sense, that's my GitHub URL,",
        "tokens": [
          51462,
          293,
          300,
          1669,
          2020,
          11,
          300,
          311,
          452,
          23331,
          12905,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 112.52000000000001,
        "id": 40,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 110.42,
        "temperature": 0,
        "text": " coding train slash Flappy Bird clone.",
        "tokens": [
          51614,
          17720,
          3847,
          17330,
          479,
          875,
          7966,
          15931,
          26506,
          13,
          51719
        ]
      },
      {
        "avg_logprob": -0.25202592456613787,
        "compression_ratio": 1.6980392156862745,
        "end": 113.7,
        "id": 41,
        "no_speech_prob": 0.000015206829630187713,
        "seek": 8542,
        "start": 112.52000000000001,
        "temperature": 0,
        "text": " That's the GitHub repository.",
        "tokens": [
          51719,
          663,
          311,
          264,
          23331,
          25841,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 116.5,
        "id": 42,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 113.82000000000001,
        "temperature": 0,
        "text": " And this remote was automatically created",
        "tokens": [
          50370,
          400,
          341,
          8607,
          390,
          6772,
          2942,
          50504
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 119.02000000000001,
        "id": 43,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 116.5,
        "temperature": 0,
        "text": " because at some point in time, I said git clone",
        "tokens": [
          50504,
          570,
          412,
          512,
          935,
          294,
          565,
          11,
          286,
          848,
          18331,
          26506,
          50630
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 122.06,
        "id": 44,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 120.14,
        "temperature": 0,
        "text": " and I put this in.",
        "tokens": [
          50686,
          293,
          286,
          829,
          341,
          294,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 126.38,
        "id": 45,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 123,
        "temperature": 0,
        "text": " So when I did this, this default remote was created.",
        "tokens": [
          50829,
          407,
          562,
          286,
          630,
          341,
          11,
          341,
          7576,
          8607,
          390,
          2942,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 129.64000000000001,
        "id": 46,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 126.38,
        "temperature": 0,
        "text": " So the remote being another location",
        "tokens": [
          50998,
          407,
          264,
          8607,
          885,
          1071,
          4914,
          51161
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 132.94,
        "id": 47,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 129.64000000000001,
        "temperature": 0,
        "text": " where this git repository exists.",
        "tokens": [
          51161,
          689,
          341,
          18331,
          25841,
          8198,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 136.86,
        "id": 48,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 132.94,
        "temperature": 0,
        "text": " Now the word origin is kind of a default convention",
        "tokens": [
          51326,
          823,
          264,
          1349,
          4957,
          307,
          733,
          295,
          257,
          7576,
          10286,
          51522
        ]
      },
      {
        "avg_logprob": -0.23648479372956033,
        "compression_ratio": 1.6782178217821782,
        "end": 141.62,
        "id": 49,
        "no_speech_prob": 0.0000035008538361580577,
        "seek": 11370,
        "start": 136.86,
        "temperature": 0,
        "text": " for the original remote, the sort of canonical remote,",
        "tokens": [
          51522,
          337,
          264,
          3380,
          8607,
          11,
          264,
          1333,
          295,
          46491,
          8607,
          11,
          51760
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 145.18,
        "id": 50,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 141.62,
        "temperature": 0,
        "text": " being GitHub in this case, but it's just a made up thing.",
        "tokens": [
          50364,
          885,
          23331,
          294,
          341,
          1389,
          11,
          457,
          309,
          311,
          445,
          257,
          1027,
          493,
          551,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 147.74,
        "id": 51,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 145.18,
        "temperature": 0,
        "text": " Like I can say, and I do this actually",
        "tokens": [
          50542,
          1743,
          286,
          393,
          584,
          11,
          293,
          286,
          360,
          341,
          767,
          50670
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 150.58,
        "id": 52,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 147.74,
        "temperature": 0,
        "text": " with a lot of projects, I can say git remote delete,",
        "tokens": [
          50670,
          365,
          257,
          688,
          295,
          4455,
          11,
          286,
          393,
          584,
          18331,
          8607,
          12097,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 152.86,
        "id": 53,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 150.58,
        "temperature": 0,
        "text": " I think, origin.",
        "tokens": [
          50812,
          286,
          519,
          11,
          4957,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 154.02,
        "id": 54,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 152.86,
        "temperature": 0,
        "text": " Nope.",
        "tokens": [
          50926,
          12172,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 157.22,
        "id": 55,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 154.02,
        "temperature": 0,
        "text": " Git remote remove origin?",
        "tokens": [
          50984,
          16939,
          8607,
          4159,
          4957,
          30,
          51144
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 160.34,
        "id": 56,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 157.22,
        "temperature": 0,
        "text": " Yes, and now if I say git remote dash v,",
        "tokens": [
          51144,
          1079,
          11,
          293,
          586,
          498,
          286,
          584,
          18331,
          8607,
          8240,
          371,
          11,
          51300
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 161.5,
        "id": 57,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 160.34,
        "temperature": 0,
        "text": " there's no more remotes.",
        "tokens": [
          51300,
          456,
          311,
          572,
          544,
          890,
          17251,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 164.38,
        "id": 58,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 161.5,
        "temperature": 0,
        "text": " But I can say git remote add,",
        "tokens": [
          51358,
          583,
          286,
          393,
          584,
          18331,
          8607,
          909,
          11,
          51502
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 165.72,
        "id": 59,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 164.38,
        "temperature": 0,
        "text": " and instead of calling it origin,",
        "tokens": [
          51502,
          293,
          2602,
          295,
          5141,
          309,
          4957,
          11,
          51569
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 168.56,
        "id": 60,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 165.72,
        "temperature": 0,
        "text": " why not call it GitHub or unicorn?",
        "tokens": [
          51569,
          983,
          406,
          818,
          309,
          23331,
          420,
          28122,
          30,
          51711
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 169.70000000000002,
        "id": 61,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 168.56,
        "temperature": 0,
        "text": " I can call it anything I want.",
        "tokens": [
          51711,
          286,
          393,
          818,
          309,
          1340,
          286,
          528,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.23991510761317922,
        "compression_ratio": 1.7627118644067796,
        "end": 171.3,
        "id": 62,
        "no_speech_prob": 0.000035912984458263963,
        "seek": 14162,
        "start": 169.70000000000002,
        "temperature": 0,
        "text": " Let's call it GitHub.",
        "tokens": [
          51768,
          961,
          311,
          818,
          309,
          23331,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 173.46,
        "id": 63,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 171.98000000000002,
        "temperature": 0,
        "text": " And then I can paste in,",
        "tokens": [
          50398,
          400,
          550,
          286,
          393,
          9163,
          294,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 179.14000000000001,
        "id": 64,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 175.58,
        "temperature": 0,
        "text": " Flappy Bird clone, I'm just going to grab this URL here",
        "tokens": [
          50578,
          479,
          875,
          7966,
          15931,
          26506,
          11,
          286,
          478,
          445,
          516,
          281,
          4444,
          341,
          12905,
          510,
          50756
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 180.18,
        "id": 65,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 179.14000000000001,
        "temperature": 0,
        "text": " and I can paste this in here.",
        "tokens": [
          50756,
          293,
          286,
          393,
          9163,
          341,
          294,
          510,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 182.70000000000002,
        "id": 66,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 180.18,
        "temperature": 0,
        "text": " And now I am adding this remote.",
        "tokens": [
          50808,
          400,
          586,
          286,
          669,
          5127,
          341,
          8607,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 185.34,
        "id": 67,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 183.60000000000002,
        "temperature": 0,
        "text": " And I can say git remote dash v again,",
        "tokens": [
          50979,
          400,
          286,
          393,
          584,
          18331,
          8607,
          8240,
          371,
          797,
          11,
          51066
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 188.22000000000003,
        "id": 68,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 185.34,
        "temperature": 0,
        "text": " and we can see there it is back, but it's now called GitHub.",
        "tokens": [
          51066,
          293,
          321,
          393,
          536,
          456,
          309,
          307,
          646,
          11,
          457,
          309,
          311,
          586,
          1219,
          23331,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 192.3,
        "id": 69,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 188.22000000000003,
        "temperature": 0,
        "text": " So if I were ever to say git put pull origin master",
        "tokens": [
          51210,
          407,
          498,
          286,
          645,
          1562,
          281,
          584,
          18331,
          829,
          2235,
          4957,
          4505,
          51414
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 195.3,
        "id": 70,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 192.3,
        "temperature": 0,
        "text": " to grab some changes, master, by the way,",
        "tokens": [
          51414,
          281,
          4444,
          512,
          2962,
          11,
          4505,
          11,
          538,
          264,
          636,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 198.5,
        "id": 71,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 195.3,
        "temperature": 0,
        "text": " is this name of the core branch.",
        "tokens": [
          51564,
          307,
          341,
          1315,
          295,
          264,
          4965,
          9819,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.3020846149114173,
        "compression_ratio": 1.6324110671936758,
        "end": 200.14000000000001,
        "id": 72,
        "no_speech_prob": 0.000031201852834783494,
        "seek": 17130,
        "start": 198.5,
        "temperature": 0,
        "text": " It's also just a completely made up thing.",
        "tokens": [
          51724,
          467,
          311,
          611,
          445,
          257,
          2584,
          1027,
          493,
          551,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 202.33999999999997,
        "id": 73,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 200.14,
        "temperature": 0,
        "text": " I could have source branch or release branch",
        "tokens": [
          50364,
          286,
          727,
          362,
          4009,
          9819,
          420,
          4374,
          9819,
          50474
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 204.94,
        "id": 74,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 202.33999999999997,
        "temperature": 0,
        "text": " or development branch or experimental branch.",
        "tokens": [
          50474,
          420,
          3250,
          9819,
          420,
          17069,
          9819,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 206.48,
        "id": 75,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 204.94,
        "temperature": 0,
        "text": " That's a separate video about branches",
        "tokens": [
          50604,
          663,
          311,
          257,
          4994,
          960,
          466,
          14770,
          50681
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 207.66,
        "id": 76,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 206.48,
        "temperature": 0,
        "text": " that you can go and watch.",
        "tokens": [
          50681,
          300,
          291,
          393,
          352,
          293,
          1159,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 209.82,
        "id": 77,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 207.66,
        "temperature": 0,
        "text": " But if I say this, it'll say, ah,",
        "tokens": [
          50740,
          583,
          498,
          286,
          584,
          341,
          11,
          309,
          603,
          584,
          11,
          3716,
          11,
          50848
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 211.77999999999997,
        "id": 78,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 209.82,
        "temperature": 0,
        "text": " origin doesn't appear to be a Git repository",
        "tokens": [
          50848,
          4957,
          1177,
          380,
          4204,
          281,
          312,
          257,
          16939,
          25841,
          50946
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 213.33999999999997,
        "id": 79,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 211.77999999999997,
        "temperature": 0,
        "text": " because it's not there.",
        "tokens": [
          50946,
          570,
          309,
          311,
          406,
          456,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 217.61999999999998,
        "id": 80,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 213.33999999999997,
        "temperature": 0,
        "text": " But I can now say git pull GitHub master.",
        "tokens": [
          51024,
          583,
          286,
          393,
          586,
          584,
          18331,
          2235,
          23331,
          4505,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 221.14,
        "id": 81,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 218.66,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51290,
          400,
          456,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 222.14,
        "id": 82,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 221.14,
        "temperature": 0,
        "text": " Now I'm already up to date,",
        "tokens": [
          51414,
          823,
          286,
          478,
          1217,
          493,
          281,
          4002,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 223.48,
        "id": 83,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 222.14,
        "temperature": 0,
        "text": " so I don't have to worry about it.",
        "tokens": [
          51464,
          370,
          286,
          500,
          380,
          362,
          281,
          3292,
          466,
          309,
          13,
          51531
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 224.57999999999998,
        "id": 84,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 223.48,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          51531,
          823,
          510,
          311,
          264,
          551,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.22381563539858218,
        "compression_ratio": 1.661710037174721,
        "end": 227.51999999999998,
        "id": 85,
        "no_speech_prob": 0.00013135102926753461,
        "seek": 20014,
        "start": 224.57999999999998,
        "temperature": 0,
        "text": " I want, let's go back to this pull request,",
        "tokens": [
          51586,
          286,
          528,
          11,
          718,
          311,
          352,
          646,
          281,
          341,
          2235,
          5308,
          11,
          51733
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 232.06,
        "id": 86,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 227.52,
        "temperature": 0,
        "text": " which is once again from Kegan M.",
        "tokens": [
          50364,
          597,
          307,
          1564,
          797,
          490,
          591,
          43118,
          376,
          13,
          50591
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 235.68,
        "id": 87,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 232.06,
        "temperature": 0,
        "text": " So where is Kegan M's, and we can see here,",
        "tokens": [
          50591,
          407,
          689,
          307,
          591,
          43118,
          376,
          311,
          11,
          293,
          321,
          393,
          536,
          510,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 238,
        "id": 88,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 235.68,
        "temperature": 0,
        "text": " ah, Kegan M colon graphics.",
        "tokens": [
          50772,
          3716,
          11,
          591,
          43118,
          376,
          8255,
          11837,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 242.32000000000002,
        "id": 89,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 238,
        "temperature": 0,
        "text": " So Kegan M made these code changes",
        "tokens": [
          50888,
          407,
          591,
          43118,
          376,
          1027,
          613,
          3089,
          2962,
          51104
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 246.66000000000003,
        "id": 90,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 242.32000000000002,
        "temperature": 0,
        "text": " in a branch called graphics in their GitHub repository.",
        "tokens": [
          51104,
          294,
          257,
          9819,
          1219,
          11837,
          294,
          641,
          23331,
          25841,
          13,
          51321
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 248.24,
        "id": 91,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 246.66000000000003,
        "temperature": 0,
        "text": " So one thing I'm going to do is I'm just going to",
        "tokens": [
          51321,
          407,
          472,
          551,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          51400
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 249.52,
        "id": 92,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 248.24,
        "temperature": 0,
        "text": " copy paste this right here.",
        "tokens": [
          51400,
          5055,
          9163,
          341,
          558,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 250.72,
        "id": 93,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 249.52,
        "temperature": 0,
        "text": " There's probably a way I could link to it.",
        "tokens": [
          51464,
          821,
          311,
          1391,
          257,
          636,
          286,
          727,
          2113,
          281,
          309,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 252.48000000000002,
        "id": 94,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 250.72,
        "temperature": 0,
        "text": " And I'm going to go up to the URL,",
        "tokens": [
          51524,
          400,
          286,
          478,
          516,
          281,
          352,
          493,
          281,
          264,
          12905,
          11,
          51612
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 255.56,
        "id": 95,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 252.48000000000002,
        "temperature": 0,
        "text": " and I'm going to change coding train to Kegan M.",
        "tokens": [
          51612,
          293,
          286,
          478,
          516,
          281,
          1319,
          17720,
          3847,
          281,
          591,
          43118,
          376,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.2332827159336635,
        "compression_ratio": 1.7529411764705882,
        "end": 256.68,
        "id": 96,
        "no_speech_prob": 0.000003726635895873187,
        "seek": 22752,
        "start": 255.56,
        "temperature": 0,
        "text": " And I'm going to get rid of the pull request.",
        "tokens": [
          51766,
          400,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          2235,
          5308,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 259.2,
        "id": 97,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 256.68,
        "temperature": 0,
        "text": " I just want to go over there and see",
        "tokens": [
          50364,
          286,
          445,
          528,
          281,
          352,
          670,
          456,
          293,
          536,
          50490
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 262.24,
        "id": 98,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 259.2,
        "temperature": 0,
        "text": " that this is the fork of the repository.",
        "tokens": [
          50490,
          300,
          341,
          307,
          264,
          17716,
          295,
          264,
          25841,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 266.6,
        "id": 99,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 263.32,
        "temperature": 0,
        "text": " And so there we can see this is Kegan M's fork.",
        "tokens": [
          50696,
          400,
          370,
          456,
          321,
          393,
          536,
          341,
          307,
          591,
          43118,
          376,
          311,
          17716,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 268.46,
        "id": 100,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 266.6,
        "temperature": 0,
        "text": " We can see branch master.",
        "tokens": [
          50860,
          492,
          393,
          536,
          9819,
          4505,
          13,
          50953
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 269.72,
        "id": 101,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 268.46,
        "temperature": 0,
        "text": " We can see branch graphics.",
        "tokens": [
          50953,
          492,
          393,
          536,
          9819,
          11837,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 270.56,
        "id": 102,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 269.72,
        "temperature": 0,
        "text": " I could start looking around.",
        "tokens": [
          51016,
          286,
          727,
          722,
          1237,
          926,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 272.18,
        "id": 103,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 270.56,
        "temperature": 0,
        "text": " Now what I'm going to do is I'm going to go to clone,",
        "tokens": [
          51058,
          823,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          352,
          281,
          26506,
          11,
          51139
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 273.82,
        "id": 104,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 272.18,
        "temperature": 0,
        "text": " and I'm going to grab this.",
        "tokens": [
          51139,
          293,
          286,
          478,
          516,
          281,
          4444,
          341,
          13,
          51221
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 276.24,
        "id": 105,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 273.82,
        "temperature": 0,
        "text": " So I'm now going to grab Kegan M's",
        "tokens": [
          51221,
          407,
          286,
          478,
          586,
          516,
          281,
          4444,
          591,
          43118,
          376,
          311,
          51342
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 279.92,
        "id": 106,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 277.88,
        "temperature": 0,
        "text": " fork of my Flappy Bird clone.",
        "tokens": [
          51424,
          17716,
          295,
          452,
          479,
          875,
          7966,
          15931,
          26506,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 281.22,
        "id": 107,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 279.92,
        "temperature": 0,
        "text": " I'm going to grab that.",
        "tokens": [
          51526,
          286,
          478,
          516,
          281,
          4444,
          300,
          13,
          51591
        ]
      },
      {
        "avg_logprob": -0.22640914368114884,
        "compression_ratio": 1.8888888888888888,
        "end": 286.22,
        "id": 108,
        "no_speech_prob": 0.0000052553923524101265,
        "seek": 25668,
        "start": 281.22,
        "temperature": 0,
        "text": " And I'm going to say git remote add Kegan M.",
        "tokens": [
          51591,
          400,
          286,
          478,
          516,
          281,
          584,
          18331,
          8607,
          909,
          591,
          43118,
          376,
          13,
          51841
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 289.08,
        "id": 109,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 287.44,
        "temperature": 0,
        "text": " I can make up anything here.",
        "tokens": [
          50402,
          286,
          393,
          652,
          493,
          1340,
          510,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 290.04,
        "id": 110,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 289.08,
        "temperature": 0,
        "text": " I'm just going to say Kegan,",
        "tokens": [
          50484,
          286,
          478,
          445,
          516,
          281,
          584,
          591,
          43118,
          11,
          50532
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 292,
        "id": 111,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 290.04,
        "temperature": 0,
        "text": " because I think I can remember that.",
        "tokens": [
          50532,
          570,
          286,
          519,
          286,
          393,
          1604,
          300,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 294.44,
        "id": 112,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 292,
        "temperature": 0,
        "text": " And I'm going to then paste in",
        "tokens": [
          50630,
          400,
          286,
          478,
          516,
          281,
          550,
          9163,
          294,
          50752
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 296.6,
        "id": 113,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 294.44,
        "temperature": 0,
        "text": " that particular URL for Kegan M.",
        "tokens": [
          50752,
          300,
          1729,
          12905,
          337,
          591,
          43118,
          376,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 298.32,
        "id": 114,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 296.6,
        "temperature": 0,
        "text": " Now one thing you might notice,",
        "tokens": [
          50860,
          823,
          472,
          551,
          291,
          1062,
          3449,
          11,
          50946
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 301.36,
        "id": 115,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 298.32,
        "temperature": 0,
        "text": " these URLs say git at github.com.",
        "tokens": [
          50946,
          613,
          43267,
          584,
          18331,
          412,
          290,
          355,
          836,
          13,
          1112,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 304.84000000000003,
        "id": 116,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 301.36,
        "temperature": 0,
        "text": " You might actually, and this is because I have set up",
        "tokens": [
          51098,
          509,
          1062,
          767,
          11,
          293,
          341,
          307,
          570,
          286,
          362,
          992,
          493,
          51272
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 308.64,
        "id": 117,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 304.84000000000003,
        "temperature": 0,
        "text": " this very fancy way for my computer to be auto logged in",
        "tokens": [
          51272,
          341,
          588,
          10247,
          636,
          337,
          452,
          3820,
          281,
          312,
          8399,
          27231,
          294,
          51462
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 311.56,
        "id": 118,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 308.64,
        "temperature": 0,
        "text": " using an SHH key and a passphrase.",
        "tokens": [
          51462,
          1228,
          364,
          7405,
          39,
          2141,
          293,
          257,
          1320,
          44598,
          651,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 312.76,
        "id": 119,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 311.56,
        "temperature": 0,
        "text": " But if you don't have that set up,",
        "tokens": [
          51608,
          583,
          498,
          291,
          500,
          380,
          362,
          300,
          992,
          493,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.23486596259517947,
        "compression_ratio": 1.6258992805755397,
        "end": 314.42,
        "id": 120,
        "no_speech_prob": 0.000006048916020517936,
        "seek": 28668,
        "start": 312.76,
        "temperature": 0,
        "text": " and I should do a video tutorial that explains",
        "tokens": [
          51668,
          293,
          286,
          820,
          360,
          257,
          960,
          7073,
          300,
          13948,
          51751
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 318.7,
        "id": 121,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 314.42,
        "temperature": 0,
        "text": " how to do that, you might want to use HTTPS.",
        "tokens": [
          50364,
          577,
          281,
          360,
          300,
          11,
          291,
          1062,
          528,
          281,
          764,
          11751,
          51,
          6273,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 320.54,
        "id": 122,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 318.7,
        "temperature": 0,
        "text": " This is also a way that you can,",
        "tokens": [
          50578,
          639,
          307,
          611,
          257,
          636,
          300,
          291,
          393,
          11,
          50670
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 322.98,
        "id": 123,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 320.54,
        "temperature": 0,
        "text": " this is just the sort of standard URL",
        "tokens": [
          50670,
          341,
          307,
          445,
          264,
          1333,
          295,
          3832,
          12905,
          50792
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 325.06,
        "id": 124,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 322.98,
        "temperature": 0,
        "text": " without having the sort of secret keys",
        "tokens": [
          50792,
          1553,
          1419,
          264,
          1333,
          295,
          4054,
          9317,
          50896
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 326.26,
        "id": 125,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 325.06,
        "temperature": 0,
        "text": " that log you in automatically.",
        "tokens": [
          50896,
          300,
          3565,
          291,
          294,
          6772,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 328.20000000000005,
        "id": 126,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 326.26,
        "temperature": 0,
        "text": " But that's a little bit of an aside here.",
        "tokens": [
          50956,
          583,
          300,
          311,
          257,
          707,
          857,
          295,
          364,
          7359,
          510,
          13,
          51053
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 329.82,
        "id": 127,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 328.20000000000005,
        "temperature": 0,
        "text": " I'm going to add this remote.",
        "tokens": [
          51053,
          286,
          478,
          516,
          281,
          909,
          341,
          8607,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 333.02000000000004,
        "id": 128,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 330.82,
        "temperature": 0,
        "text": " And now I'm going to say git remote dash v,",
        "tokens": [
          51184,
          400,
          586,
          286,
          478,
          516,
          281,
          584,
          18331,
          8607,
          8240,
          371,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 334.5,
        "id": 129,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 333.02000000000004,
        "temperature": 0,
        "text": " and we can see, look at this.",
        "tokens": [
          51294,
          293,
          321,
          393,
          536,
          11,
          574,
          412,
          341,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 338.38,
        "id": 130,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 334.5,
        "temperature": 0,
        "text": " I have GitHub remote, which is tied to me, CodingTrain.",
        "tokens": [
          51368,
          286,
          362,
          23331,
          8607,
          11,
          597,
          307,
          9601,
          281,
          385,
          11,
          383,
          8616,
          51,
          7146,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 341.84000000000003,
        "id": 131,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 338.38,
        "temperature": 0,
        "text": " I have Kegan's remote, which is tied to Kegan M,",
        "tokens": [
          51562,
          286,
          362,
          591,
          43118,
          311,
          8607,
          11,
          597,
          307,
          9601,
          281,
          591,
          43118,
          376,
          11,
          51735
        ]
      },
      {
        "avg_logprob": -0.20618131286219546,
        "compression_ratio": 1.7925925925925925,
        "end": 343.3,
        "id": 132,
        "no_speech_prob": 0.00007967269630171359,
        "seek": 31442,
        "start": 341.84000000000003,
        "temperature": 0,
        "text": " which is tied to the GitHub repository Kegan M.",
        "tokens": [
          51735,
          597,
          307,
          9601,
          281,
          264,
          23331,
          25841,
          591,
          43118,
          376,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 346.1,
        "id": 133,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 343.3,
        "temperature": 0,
        "text": " Now, I'm going to say,",
        "tokens": [
          50364,
          823,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 347.62,
        "id": 134,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 346.1,
        "temperature": 0,
        "text": " there's a lot of different things that I can do,",
        "tokens": [
          50504,
          456,
          311,
          257,
          688,
          295,
          819,
          721,
          300,
          286,
          393,
          360,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 349.34000000000003,
        "id": 135,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 347.62,
        "temperature": 0,
        "text": " but what I'm going to do is I'm just going to say",
        "tokens": [
          50580,
          457,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          584,
          50666
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 351.32,
        "id": 136,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 349.34000000000003,
        "temperature": 0,
        "text": " git branch graphics.",
        "tokens": [
          50666,
          18331,
          9819,
          11837,
          13,
          50765
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 354.72,
        "id": 137,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 351.32,
        "temperature": 0,
        "text": " I'm going to make a branch locally called graphics,",
        "tokens": [
          50765,
          286,
          478,
          516,
          281,
          652,
          257,
          9819,
          16143,
          1219,
          11837,
          11,
          50935
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 356.48,
        "id": 138,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 354.72,
        "temperature": 0,
        "text": " and I'm going to quickly go into that branch.",
        "tokens": [
          50935,
          293,
          286,
          478,
          516,
          281,
          2661,
          352,
          666,
          300,
          9819,
          13,
          51023
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 358.6,
        "id": 139,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 356.48,
        "temperature": 0,
        "text": " Again, you should probably watch my branches tutorial",
        "tokens": [
          51023,
          3764,
          11,
          291,
          820,
          1391,
          1159,
          452,
          14770,
          7073,
          51129
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 361.1,
        "id": 140,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 358.6,
        "temperature": 0,
        "text": " about how this works, and I'm going to go into that branch",
        "tokens": [
          51129,
          466,
          577,
          341,
          1985,
          11,
          293,
          286,
          478,
          516,
          281,
          352,
          666,
          300,
          9819,
          51254
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 362.6,
        "id": 141,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 361.1,
        "temperature": 0,
        "text": " by using checkout.",
        "tokens": [
          51254,
          538,
          1228,
          37153,
          13,
          51329
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 365.42,
        "id": 142,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 362.6,
        "temperature": 0,
        "text": " Then what I'm going to do is I'm going to say git pull,",
        "tokens": [
          51329,
          1396,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          18331,
          2235,
          11,
          51470
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 367.90000000000003,
        "id": 143,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 365.42,
        "temperature": 0,
        "text": " and usually I almost reflectively just git pull",
        "tokens": [
          51470,
          293,
          2673,
          286,
          1920,
          5031,
          3413,
          445,
          18331,
          2235,
          51594
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 369.3,
        "id": 144,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 367.90000000000003,
        "temperature": 0,
        "text": " origin master, git pull origin master,",
        "tokens": [
          51594,
          4957,
          4505,
          11,
          18331,
          2235,
          4957,
          4505,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 370.98,
        "id": 145,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 369.3,
        "temperature": 0,
        "text": " git pull origin master, git pull origin master,",
        "tokens": [
          51664,
          18331,
          2235,
          4957,
          4505,
          11,
          18331,
          2235,
          4957,
          4505,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.2221426299124053,
        "compression_ratio": 2.3201581027667983,
        "end": 371.90000000000003,
        "id": 146,
        "no_speech_prob": 0.000013419987226370722,
        "seek": 34330,
        "start": 370.98,
        "temperature": 0,
        "text": " git pull origin master.",
        "tokens": [
          51748,
          18331,
          2235,
          4957,
          4505,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 374.21999999999997,
        "id": 147,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 372.65999999999997,
        "temperature": 0,
        "text": " I don't want to pull from origin,",
        "tokens": [
          50402,
          286,
          500,
          380,
          528,
          281,
          2235,
          490,
          4957,
          11,
          50480
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 375.78,
        "id": 148,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 374.21999999999997,
        "temperature": 0,
        "text": " I want to pull from Kegan,",
        "tokens": [
          50480,
          286,
          528,
          281,
          2235,
          490,
          591,
          43118,
          11,
          50558
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 377.2,
        "id": 149,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 375.78,
        "temperature": 0,
        "text": " and I don't want to pull from master,",
        "tokens": [
          50558,
          293,
          286,
          500,
          380,
          528,
          281,
          2235,
          490,
          4505,
          11,
          50629
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 378.82,
        "id": 150,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 377.2,
        "temperature": 0,
        "text": " I want to pull from graphics.",
        "tokens": [
          50629,
          286,
          528,
          281,
          2235,
          490,
          11837,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 381.78,
        "id": 151,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 378.82,
        "temperature": 0,
        "text": " Git pull Kegan graphics.",
        "tokens": [
          50710,
          16939,
          2235,
          591,
          43118,
          11837,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 384.29999999999995,
        "id": 152,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 381.78,
        "temperature": 0,
        "text": " Ah, ooh, interesting, hmm.",
        "tokens": [
          50858,
          2438,
          11,
          17024,
          11,
          1880,
          11,
          16478,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 387.23999999999995,
        "id": 153,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 384.29999999999995,
        "temperature": 0,
        "text": " So something has happened here,",
        "tokens": [
          50984,
          407,
          746,
          575,
          2011,
          510,
          11,
          51131
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 392.23999999999995,
        "id": 154,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 387.23999999999995,
        "temperature": 0,
        "text": " in that I have now been launched into a text editor",
        "tokens": [
          51131,
          294,
          300,
          286,
          362,
          586,
          668,
          8730,
          666,
          257,
          2487,
          9839,
          51381
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 393.5,
        "id": 155,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 392.46,
        "temperature": 0,
        "text": " known as VI.",
        "tokens": [
          51392,
          2570,
          382,
          27619,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 396.03999999999996,
        "id": 156,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 393.5,
        "temperature": 0,
        "text": " Whoa, this has been like way off the screen.",
        "tokens": [
          51444,
          7521,
          11,
          341,
          575,
          668,
          411,
          636,
          766,
          264,
          2568,
          13,
          51571
        ]
      },
      {
        "avg_logprob": -0.286659470919905,
        "compression_ratio": 1.7464114832535884,
        "end": 398.82,
        "id": 157,
        "no_speech_prob": 0.000018925102267530747,
        "seek": 37190,
        "start": 396.03999999999996,
        "temperature": 0,
        "text": " That's what's going on here, that's crazy.",
        "tokens": [
          51571,
          663,
          311,
          437,
          311,
          516,
          322,
          510,
          11,
          300,
          311,
          3219,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 402.78,
        "id": 158,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 398.82,
        "temperature": 0,
        "text": " And so there's some sort of merging that needs to happen",
        "tokens": [
          50364,
          400,
          370,
          456,
          311,
          512,
          1333,
          295,
          44559,
          300,
          2203,
          281,
          1051,
          50562
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 406.54,
        "id": 159,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 402.78,
        "temperature": 0,
        "text": " for Kegan M's branch graphics to come",
        "tokens": [
          50562,
          337,
          591,
          43118,
          376,
          311,
          9819,
          11837,
          281,
          808,
          50750
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 407.7,
        "id": 160,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 406.54,
        "temperature": 0,
        "text": " into my branch graphics,",
        "tokens": [
          50750,
          666,
          452,
          9819,
          11837,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 409.54,
        "id": 161,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 407.7,
        "temperature": 0,
        "text": " because I actually have made some other changes.",
        "tokens": [
          50808,
          570,
          286,
          767,
          362,
          1027,
          512,
          661,
          2962,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 411.14,
        "id": 162,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 409.54,
        "temperature": 0,
        "text": " It would have been nice if this didn't happen,",
        "tokens": [
          50900,
          467,
          576,
          362,
          668,
          1481,
          498,
          341,
          994,
          380,
          1051,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 413.02,
        "id": 163,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 411.14,
        "temperature": 0,
        "text": " but this is actually quite normal.",
        "tokens": [
          50980,
          457,
          341,
          307,
          767,
          1596,
          2710,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 416.44,
        "id": 164,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 413.02,
        "temperature": 0,
        "text": " This is a regular thing, and I have to deal with this.",
        "tokens": [
          51074,
          639,
          307,
          257,
          3890,
          551,
          11,
          293,
          286,
          362,
          281,
          2028,
          365,
          341,
          13,
          51245
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 419.86,
        "id": 165,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 416.44,
        "temperature": 0,
        "text": " So what I want to do is say that,",
        "tokens": [
          51245,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          584,
          300,
          11,
          51416
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 422.94,
        "id": 166,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 419.86,
        "temperature": 0,
        "text": " I'm going to say, what do I type in VI?",
        "tokens": [
          51416,
          286,
          478,
          516,
          281,
          584,
          11,
          437,
          360,
          286,
          2010,
          294,
          27619,
          30,
          51570
        ]
      },
      {
        "avg_logprob": -0.24081549644470215,
        "compression_ratio": 1.6385542168674698,
        "end": 427.52,
        "id": 167,
        "no_speech_prob": 0.000012411476745910477,
        "seek": 39882,
        "start": 422.94,
        "temperature": 0,
        "text": " So, ah, this always happens.",
        "tokens": [
          51570,
          407,
          11,
          3716,
          11,
          341,
          1009,
          2314,
          13,
          51799
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 432.52,
        "id": 168,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 427.52,
        "temperature": 0,
        "text": " So I think I'd say colon insert, no?",
        "tokens": [
          50364,
          407,
          286,
          519,
          286,
          1116,
          584,
          8255,
          8969,
          11,
          572,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 434.68,
        "id": 169,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 432.84,
        "temperature": 0,
        "text": " I for insert, I for insert.",
        "tokens": [
          50630,
          286,
          337,
          8969,
          11,
          286,
          337,
          8969,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 440.12,
        "id": 170,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 436.46,
        "temperature": 0,
        "text": " So again, you can link a different text editor",
        "tokens": [
          50811,
          407,
          797,
          11,
          291,
          393,
          2113,
          257,
          819,
          2487,
          9839,
          50994
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 443.28,
        "id": 171,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 440.12,
        "temperature": 0,
        "text": " to your Git work on your computer,",
        "tokens": [
          50994,
          281,
          428,
          16939,
          589,
          322,
          428,
          3820,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 445.71999999999997,
        "id": 172,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 443.28,
        "temperature": 0,
        "text": " but this is, and so now that I've been launched",
        "tokens": [
          51152,
          457,
          341,
          307,
          11,
          293,
          370,
          586,
          300,
          286,
          600,
          668,
          8730,
          51274
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 447.15999999999997,
        "id": 173,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 445.71999999999997,
        "temperature": 0,
        "text": " this text editor in,",
        "tokens": [
          51274,
          341,
          2487,
          9839,
          294,
          11,
          51346
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 449.84,
        "id": 174,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 448.12,
        "temperature": 0,
        "text": " in, I just want to say like,",
        "tokens": [
          51394,
          294,
          11,
          286,
          445,
          528,
          281,
          584,
          411,
          11,
          51480
        ]
      },
      {
        "avg_logprob": -0.34032344818115234,
        "compression_ratio": 1.5337078651685394,
        "end": 454.35999999999996,
        "id": 175,
        "no_speech_prob": 0.00002392340320511721,
        "seek": 42752,
        "start": 449.84,
        "temperature": 0,
        "text": " I'm making a tutorial video,",
        "tokens": [
          51480,
          286,
          478,
          1455,
          257,
          7073,
          960,
          11,
          51706
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 457.14,
        "id": 176,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 454.36,
        "temperature": 0,
        "text": " so I don't have a lot of time,",
        "tokens": [
          50364,
          370,
          286,
          500,
          380,
          362,
          257,
          688,
          295,
          565,
          11,
          50503
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 463.2,
        "id": 177,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 458.2,
        "temperature": 0,
        "text": " but this is here to merge Kegan's graphics",
        "tokens": [
          50556,
          457,
          341,
          307,
          510,
          281,
          22183,
          591,
          43118,
          311,
          11837,
          50806
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 468.6,
        "id": 178,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 464.44,
        "temperature": 0,
        "text": " with some recent changes I made.",
        "tokens": [
          50868,
          365,
          512,
          5162,
          2962,
          286,
          1027,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 473.68,
        "id": 179,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 469.96000000000004,
        "temperature": 0,
        "text": " And then I'm going to say, colon, oops,",
        "tokens": [
          51144,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          8255,
          11,
          34166,
          11,
          51330
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 476.52000000000004,
        "id": 180,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 473.68,
        "temperature": 0,
        "text": " oh no, I got to get rid of insert, escape maybe,",
        "tokens": [
          51330,
          1954,
          572,
          11,
          286,
          658,
          281,
          483,
          3973,
          295,
          8969,
          11,
          7615,
          1310,
          11,
          51472
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 480.64,
        "id": 181,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 476.52000000000004,
        "temperature": 0,
        "text": " escape colon QW, which I think will then",
        "tokens": [
          51472,
          7615,
          8255,
          1249,
          54,
          11,
          597,
          286,
          519,
          486,
          550,
          51678
        ]
      },
      {
        "avg_logprob": -0.25816641414866726,
        "compression_ratio": 1.4184782608695652,
        "end": 482.6,
        "id": 182,
        "no_speech_prob": 0.00013765363837592304,
        "seek": 45436,
        "start": 480.64,
        "temperature": 0,
        "text": " quit and write this out.",
        "tokens": [
          51678,
          10366,
          293,
          2464,
          341,
          484,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 485.12,
        "id": 183,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 482.6,
        "temperature": 0,
        "text": " I don't really know how to use VI,",
        "tokens": [
          50364,
          286,
          500,
          380,
          534,
          458,
          577,
          281,
          764,
          27619,
          11,
          50490
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 487.3,
        "id": 184,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 485.12,
        "temperature": 0,
        "text": " Vim or whatever, I don't know what to call it.",
        "tokens": [
          50490,
          691,
          332,
          420,
          2035,
          11,
          286,
          500,
          380,
          458,
          437,
          281,
          818,
          309,
          13,
          50599
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 491.6,
        "id": 185,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 487.3,
        "temperature": 0,
        "text": " Colon QW, and I'm going to just do that.",
        "tokens": [
          50599,
          21408,
          1249,
          54,
          11,
          293,
          286,
          478,
          516,
          281,
          445,
          360,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 493.32000000000005,
        "id": 186,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 491.6,
        "temperature": 0,
        "text": " No, not an editor command.",
        "tokens": [
          50814,
          883,
          11,
          406,
          364,
          9839,
          5622,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 496.44,
        "id": 187,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 493.32000000000005,
        "temperature": 0,
        "text": " Colon WQ, right, and then quit.",
        "tokens": [
          50900,
          21408,
          343,
          48,
          11,
          558,
          11,
          293,
          550,
          10366,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 500.24,
        "id": 188,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 496.44,
        "temperature": 0,
        "text": " There we go, and now it's fine.",
        "tokens": [
          51056,
          821,
          321,
          352,
          11,
          293,
          586,
          309,
          311,
          2489,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 501.52000000000004,
        "id": 189,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 500.24,
        "temperature": 0,
        "text": " It didn't commit it, that's fine.",
        "tokens": [
          51246,
          467,
          994,
          380,
          5599,
          309,
          11,
          300,
          311,
          2489,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 502.74,
        "id": 190,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 501.52000000000004,
        "temperature": 0,
        "text": " So now this is good.",
        "tokens": [
          51310,
          407,
          586,
          341,
          307,
          665,
          13,
          51371
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 503.58000000000004,
        "id": 191,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 502.74,
        "temperature": 0,
        "text": " I just really wanted to look at it.",
        "tokens": [
          51371,
          286,
          445,
          534,
          1415,
          281,
          574,
          412,
          309,
          13,
          51413
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 504.84000000000003,
        "id": 192,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 503.58000000000004,
        "temperature": 0,
        "text": " All I wanted to do was look at it.",
        "tokens": [
          51413,
          1057,
          286,
          1415,
          281,
          360,
          390,
          574,
          412,
          309,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 506.52000000000004,
        "id": 193,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 504.84000000000003,
        "temperature": 0,
        "text": " I don't need to commit this right now,",
        "tokens": [
          51476,
          286,
          500,
          380,
          643,
          281,
          5599,
          341,
          558,
          586,
          11,
          51560
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 508.20000000000005,
        "id": 194,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 506.52000000000004,
        "temperature": 0,
        "text": " because I'm not really worrying about merging.",
        "tokens": [
          51560,
          570,
          286,
          478,
          406,
          534,
          18788,
          466,
          44559,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.24938923799538915,
        "compression_ratio": 1.742537313432836,
        "end": 511.08000000000004,
        "id": 195,
        "no_speech_prob": 0.0029349366668611765,
        "seek": 48260,
        "start": 508.20000000000005,
        "temperature": 0,
        "text": " And so now I should, if I come over here,",
        "tokens": [
          51644,
          400,
          370,
          586,
          286,
          820,
          11,
          498,
          286,
          808,
          670,
          510,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 513.8199999999999,
        "id": 196,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 511.08,
        "temperature": 0,
        "text": " this is me looking at my code in the browser",
        "tokens": [
          50364,
          341,
          307,
          385,
          1237,
          412,
          452,
          3089,
          294,
          264,
          11185,
          50501
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 517.16,
        "id": 197,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 513.8199999999999,
        "temperature": 0,
        "text": " before I checked out and pulled from that other remote.",
        "tokens": [
          50501,
          949,
          286,
          10033,
          484,
          293,
          7373,
          490,
          300,
          661,
          8607,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 518.52,
        "id": 198,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 517.16,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50668,
          400,
          456,
          321,
          352,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 522.0799999999999,
        "id": 199,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 518.52,
        "temperature": 0,
        "text": " Look at this, and now we have the coding train,",
        "tokens": [
          50736,
          2053,
          412,
          341,
          11,
          293,
          586,
          321,
          362,
          264,
          17720,
          3847,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 524.76,
        "id": 200,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 522.0799999999999,
        "temperature": 0,
        "text": " the floppy bird, floppy coding train game",
        "tokens": [
          50914,
          264,
          25343,
          8200,
          5255,
          11,
          25343,
          8200,
          17720,
          3847,
          1216,
          51048
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 526.56,
        "id": 201,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 524.76,
        "temperature": 0,
        "text": " with our little unicorn train",
        "tokens": [
          51048,
          365,
          527,
          707,
          28122,
          3847,
          51138
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 530.4399999999999,
        "id": 202,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 526.56,
        "temperature": 0,
        "text": " and the scrolling background.",
        "tokens": [
          51138,
          293,
          264,
          29053,
          3678,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 532.28,
        "id": 203,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 530.4399999999999,
        "temperature": 0,
        "text": " Okay, wonderful, so this is good.",
        "tokens": [
          51332,
          1033,
          11,
          3715,
          11,
          370,
          341,
          307,
          665,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 534.4399999999999,
        "id": 204,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 532.28,
        "temperature": 0,
        "text": " So now I feel, I'm like, oh, this looks great.",
        "tokens": [
          51424,
          407,
          586,
          286,
          841,
          11,
          286,
          478,
          411,
          11,
          1954,
          11,
          341,
          1542,
          869,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 535.28,
        "id": 205,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 534.4399999999999,
        "temperature": 0,
        "text": " I'm done.",
        "tokens": [
          51532,
          286,
          478,
          1096,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 538,
        "id": 206,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 535.28,
        "temperature": 0,
        "text": " So interestingly enough, if I wanted to,",
        "tokens": [
          51574,
          407,
          25873,
          1547,
          11,
          498,
          286,
          1415,
          281,
          11,
          51710
        ]
      },
      {
        "avg_logprob": -0.23376823961734772,
        "compression_ratio": 1.6227106227106227,
        "end": 541.04,
        "id": 207,
        "no_speech_prob": 0.000008530310878995806,
        "seek": 51108,
        "start": 538,
        "temperature": 0,
        "text": " I could actually merge everything right now",
        "tokens": [
          51710,
          286,
          727,
          767,
          22183,
          1203,
          558,
          586,
          51862
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 542.7199999999999,
        "id": 208,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 541.88,
        "temperature": 0,
        "text": " from the command line.",
        "tokens": [
          50406,
          490,
          264,
          5622,
          1622,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 547,
        "id": 209,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 542.7199999999999,
        "temperature": 0,
        "text": " So normally I would just go to the pull request",
        "tokens": [
          50448,
          407,
          5646,
          286,
          576,
          445,
          352,
          281,
          264,
          2235,
          5308,
          50662
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 548.64,
        "id": 210,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 547,
        "temperature": 0,
        "text": " and I would scroll down here",
        "tokens": [
          50662,
          293,
          286,
          576,
          11369,
          760,
          510,
          50744
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 551.12,
        "id": 211,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 548.64,
        "temperature": 0,
        "text": " and I would just click on merge.",
        "tokens": [
          50744,
          293,
          286,
          576,
          445,
          2052,
          322,
          22183,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 552.4,
        "id": 212,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 551.12,
        "temperature": 0,
        "text": " And this would merge that pull request.",
        "tokens": [
          50868,
          400,
          341,
          576,
          22183,
          300,
          2235,
          5308,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 555.5999999999999,
        "id": 213,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 552.4,
        "temperature": 0,
        "text": " In fact, I'd write a comment, thank you so much.",
        "tokens": [
          50932,
          682,
          1186,
          11,
          286,
          1116,
          2464,
          257,
          2871,
          11,
          1309,
          291,
          370,
          709,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 558.4,
        "id": 214,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 555.5999999999999,
        "temperature": 0,
        "text": " I am going to merge this.",
        "tokens": [
          51092,
          286,
          669,
          516,
          281,
          22183,
          341,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 562.5999999999999,
        "id": 215,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 558.4,
        "temperature": 0,
        "text": " And what's wonderful about using GitHub as a service,",
        "tokens": [
          51232,
          400,
          437,
          311,
          3715,
          466,
          1228,
          23331,
          382,
          257,
          2643,
          11,
          51442
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 565.52,
        "id": 216,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 562.5999999999999,
        "temperature": 0,
        "text": " which is very different than the Git software itself,",
        "tokens": [
          51442,
          597,
          307,
          588,
          819,
          813,
          264,
          16939,
          4722,
          2564,
          11,
          51588
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 567,
        "id": 217,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 565.52,
        "temperature": 0,
        "text": " the version control software,",
        "tokens": [
          51588,
          264,
          3037,
          1969,
          4722,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.22929364080014436,
        "compression_ratio": 1.6758893280632412,
        "end": 569.42,
        "id": 218,
        "no_speech_prob": 0.00004400112447910942,
        "seek": 54104,
        "start": 567,
        "temperature": 0,
        "text": " is that it provides a visual interface",
        "tokens": [
          51662,
          307,
          300,
          309,
          6417,
          257,
          5056,
          9226,
          51783
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 571.4599999999999,
        "id": 219,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 569.42,
        "temperature": 0,
        "text": " to a lot of the common things that you might want to do,",
        "tokens": [
          50364,
          281,
          257,
          688,
          295,
          264,
          2689,
          721,
          300,
          291,
          1062,
          528,
          281,
          360,
          11,
          50466
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 573.2199999999999,
        "id": 220,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 571.4599999999999,
        "temperature": 0,
        "text": " like merging and looking at the differences",
        "tokens": [
          50466,
          411,
          44559,
          293,
          1237,
          412,
          264,
          7300,
          50554
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 575.5799999999999,
        "id": 221,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 573.2199999999999,
        "temperature": 0,
        "text": " between two files and that sort of thing.",
        "tokens": [
          50554,
          1296,
          732,
          7098,
          293,
          300,
          1333,
          295,
          551,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 579.5,
        "id": 222,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 578.02,
        "temperature": 0,
        "text": " But I think while I'm here,",
        "tokens": [
          50794,
          583,
          286,
          519,
          1339,
          286,
          478,
          510,
          11,
          50868
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 582.06,
        "id": 223,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 579.5,
        "temperature": 0,
        "text": " if you can tolerate continuing to watch this video,",
        "tokens": [
          50868,
          498,
          291,
          393,
          25773,
          9289,
          281,
          1159,
          341,
          960,
          11,
          50996
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 588.78,
        "id": 224,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 583.78,
        "temperature": 0,
        "text": " however, I am going to demonstrate,",
        "tokens": [
          51082,
          4461,
          11,
          286,
          669,
          516,
          281,
          11698,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 594.04,
        "id": 225,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 590.2199999999999,
        "temperature": 0,
        "text": " demonstrate merging from the command line for fun.",
        "tokens": [
          51404,
          11698,
          44559,
          490,
          264,
          5622,
          1622,
          337,
          1019,
          13,
          51595
        ]
      },
      {
        "avg_logprob": -0.23850396622058956,
        "compression_ratio": 1.6119402985074627,
        "end": 596.98,
        "id": 226,
        "no_speech_prob": 0.000016964397218544036,
        "seek": 56942,
        "start": 595.54,
        "temperature": 0,
        "text": " So stay tuned.",
        "tokens": [
          51670,
          407,
          1754,
          10870,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 601.6999999999999,
        "id": 227,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 600.02,
        "temperature": 0,
        "text": " I'm going to add that comment.",
        "tokens": [
          50394,
          286,
          478,
          516,
          281,
          909,
          300,
          2871,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 603.06,
        "id": 228,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 601.6999999999999,
        "temperature": 0,
        "text": " So I added that comment",
        "tokens": [
          50478,
          407,
          286,
          3869,
          300,
          2871,
          50546
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 604.86,
        "id": 229,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 603.06,
        "temperature": 0,
        "text": " and now I'm going to return to the command line.",
        "tokens": [
          50546,
          293,
          586,
          286,
          478,
          516,
          281,
          2736,
          281,
          264,
          5622,
          1622,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 607.54,
        "id": 230,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 604.86,
        "temperature": 0,
        "text": " Now I should say that I,",
        "tokens": [
          50636,
          823,
          286,
          820,
          584,
          300,
          286,
          11,
          50770
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 610.3199999999999,
        "id": 231,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 607.54,
        "temperature": 0,
        "text": " something about the way I really need to make a video",
        "tokens": [
          50770,
          746,
          466,
          264,
          636,
          286,
          534,
          643,
          281,
          652,
          257,
          960,
          50909
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 614.78,
        "id": 232,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 610.3199999999999,
        "temperature": 0,
        "text": " about setting up terminal or whatever you use",
        "tokens": [
          50909,
          466,
          3287,
          493,
          14709,
          420,
          2035,
          291,
          764,
          51132
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 616.78,
        "id": 233,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 614.78,
        "temperature": 0,
        "text": " as your terminal application",
        "tokens": [
          51132,
          382,
          428,
          14709,
          3861,
          51232
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 619.88,
        "id": 234,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 616.78,
        "temperature": 0,
        "text": " to work with Git more effectively,",
        "tokens": [
          51232,
          281,
          589,
          365,
          16939,
          544,
          8659,
          11,
          51387
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 621.3399999999999,
        "id": 235,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 619.88,
        "temperature": 0,
        "text": " because there's no reason why I couldn't see",
        "tokens": [
          51387,
          570,
          456,
          311,
          572,
          1778,
          983,
          286,
          2809,
          380,
          536,
          51460
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 623.5,
        "id": 236,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 621.3399999999999,
        "temperature": 0,
        "text": " things being syntax highlighted",
        "tokens": [
          51460,
          721,
          885,
          28431,
          17173,
          51568
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 625.4599999999999,
        "id": 237,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 623.5,
        "temperature": 0,
        "text": " or showing me what branch I'm currently on",
        "tokens": [
          51568,
          420,
          4099,
          385,
          437,
          9819,
          286,
          478,
          4362,
          322,
          51666
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 627.5,
        "id": 238,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 625.4599999999999,
        "temperature": 0,
        "text": " and there's also other terminal software",
        "tokens": [
          51666,
          293,
          456,
          311,
          611,
          661,
          14709,
          4722,
          51768
        ]
      },
      {
        "avg_logprob": -0.19999228417873383,
        "compression_ratio": 1.7275985663082438,
        "end": 628.98,
        "id": 239,
        "no_speech_prob": 0.000034808075724868104,
        "seek": 59942,
        "start": 627.5,
        "temperature": 0,
        "text": " like iTerm that I could use.",
        "tokens": [
          51768,
          411,
          30882,
          966,
          300,
          286,
          727,
          764,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 630.74,
        "id": 240,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 629.46,
        "temperature": 0,
        "text": " So I've got to come back for that.",
        "tokens": [
          50388,
          407,
          286,
          600,
          658,
          281,
          808,
          646,
          337,
          300,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 631.78,
        "id": 241,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 630.74,
        "temperature": 0,
        "text": " But right now I'm just going to say,",
        "tokens": [
          50452,
          583,
          558,
          586,
          286,
          478,
          445,
          516,
          281,
          584,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 634.02,
        "id": 242,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 631.78,
        "temperature": 0,
        "text": " I don't even remember where I am.",
        "tokens": [
          50504,
          286,
          500,
          380,
          754,
          1604,
          689,
          286,
          669,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 636.26,
        "id": 243,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 634.02,
        "temperature": 0,
        "text": " So I'm going to say git status",
        "tokens": [
          50616,
          407,
          286,
          478,
          516,
          281,
          584,
          18331,
          6558,
          50728
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 638.66,
        "id": 244,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 636.26,
        "temperature": 0,
        "text": " and I'm going to say, okay, all conflicts fixed",
        "tokens": [
          50728,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          1392,
          11,
          439,
          19807,
          6806,
          50848
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 640.22,
        "id": 245,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 638.66,
        "temperature": 0,
        "text": " but you are still merging.",
        "tokens": [
          50848,
          457,
          291,
          366,
          920,
          44559,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 643.98,
        "id": 246,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 640.22,
        "temperature": 0,
        "text": " So I didn't actually ultimately commit",
        "tokens": [
          50926,
          407,
          286,
          994,
          380,
          767,
          6284,
          5599,
          51114
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 645.82,
        "id": 247,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 643.98,
        "temperature": 0,
        "text": " that merge that I did.",
        "tokens": [
          51114,
          300,
          22183,
          300,
          286,
          630,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 647.76,
        "id": 248,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 645.82,
        "temperature": 0,
        "text": " So I'm going to say git commit.",
        "tokens": [
          51206,
          407,
          286,
          478,
          516,
          281,
          584,
          18331,
          5599,
          13,
          51303
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 649.54,
        "id": 249,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 648.66,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          51348,
          823,
          510,
          311,
          264,
          551,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 653.74,
        "id": 250,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 649.54,
        "temperature": 0,
        "text": " I have learned recently that using dash m",
        "tokens": [
          51392,
          286,
          362,
          3264,
          3938,
          300,
          1228,
          8240,
          275,
          51602
        ]
      },
      {
        "avg_logprob": -0.2527445351205221,
        "compression_ratio": 1.7056277056277056,
        "end": 656.4200000000001,
        "id": 251,
        "no_speech_prob": 0.000012805438018403947,
        "seek": 62898,
        "start": 653.74,
        "temperature": 0,
        "text": " is not as thoughtful or,",
        "tokens": [
          51602,
          307,
          406,
          382,
          21566,
          420,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 661.18,
        "id": 252,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 657.3,
        "temperature": 0,
        "text": " so I'm going to do a video about how to not use dash m",
        "tokens": [
          50408,
          370,
          286,
          478,
          516,
          281,
          360,
          257,
          960,
          466,
          577,
          281,
          406,
          764,
          8240,
          275,
          50602
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 663.42,
        "id": 253,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 661.18,
        "temperature": 0,
        "text": " and write more thoughtful, longer commit messages.",
        "tokens": [
          50602,
          293,
          2464,
          544,
          21566,
          11,
          2854,
          5599,
          7897,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 665.78,
        "id": 254,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 663.42,
        "temperature": 0,
        "text": " But for lack of a time right now,",
        "tokens": [
          50714,
          583,
          337,
          5011,
          295,
          257,
          565,
          558,
          586,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 667.8199999999999,
        "id": 255,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 665.78,
        "temperature": 0,
        "text": " I'm just going to say commit dash m",
        "tokens": [
          50832,
          286,
          478,
          445,
          516,
          281,
          584,
          5599,
          8240,
          275,
          50934
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 671.64,
        "id": 256,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 667.8199999999999,
        "temperature": 0,
        "text": " and I'm going to say merging changes from,",
        "tokens": [
          50934,
          293,
          286,
          478,
          516,
          281,
          584,
          44559,
          2962,
          490,
          11,
          51125
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 675.6999999999999,
        "id": 257,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 671.64,
        "temperature": 0,
        "text": " and I'm going to want to remember Keegan M",
        "tokens": [
          51125,
          293,
          286,
          478,
          516,
          281,
          528,
          281,
          1604,
          3189,
          43118,
          376,
          51328
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 679.52,
        "id": 258,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 677.9,
        "temperature": 0,
        "text": " from Keegan M.",
        "tokens": [
          51438,
          490,
          3189,
          43118,
          376,
          13,
          51519
        ]
      },
      {
        "avg_logprob": -0.25130291988975123,
        "compression_ratio": 1.7175141242937852,
        "end": 684.02,
        "id": 259,
        "no_speech_prob": 0.000011300793630653061,
        "seek": 65642,
        "start": 682.74,
        "temperature": 0,
        "text": " Okay, I'm going to do that.",
        "tokens": [
          51680,
          1033,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 685.5,
        "id": 260,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 684.02,
        "temperature": 0,
        "text": " So now,",
        "tokens": [
          50364,
          407,
          586,
          11,
          50438
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 690.9,
        "id": 261,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 688.48,
        "temperature": 0,
        "text": " I'm going to say git status again.",
        "tokens": [
          50587,
          286,
          478,
          516,
          281,
          584,
          18331,
          6558,
          797,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 692.4,
        "id": 262,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 690.9,
        "temperature": 0,
        "text": " Okay, on branch graphics.",
        "tokens": [
          50708,
          1033,
          11,
          322,
          9819,
          11837,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 694.06,
        "id": 263,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 692.4,
        "temperature": 0,
        "text": " So now I'm going to go to master.",
        "tokens": [
          50783,
          407,
          586,
          286,
          478,
          516,
          281,
          352,
          281,
          4505,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 699.34,
        "id": 264,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 697.38,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to say",
        "tokens": [
          51032,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          51130
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 701.38,
        "id": 265,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 699.34,
        "temperature": 0,
        "text": " git merge graphics.",
        "tokens": [
          51130,
          18331,
          22183,
          11837,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 703.98,
        "id": 266,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 701.38,
        "temperature": 0,
        "text": " And what that will do is we'll take the graphics branch",
        "tokens": [
          51232,
          400,
          437,
          300,
          486,
          360,
          307,
          321,
          603,
          747,
          264,
          11837,
          9819,
          51362
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 705.34,
        "id": 267,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 703.98,
        "temperature": 0,
        "text": " and merge it into master.",
        "tokens": [
          51362,
          293,
          22183,
          309,
          666,
          4505,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 707.98,
        "id": 268,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 705.34,
        "temperature": 0,
        "text": " It's exactly the same thing that would happen",
        "tokens": [
          51430,
          467,
          311,
          2293,
          264,
          912,
          551,
          300,
          576,
          1051,
          51562
        ]
      },
      {
        "avg_logprob": -0.23420377296976524,
        "compression_ratio": 1.7802197802197801,
        "end": 709.42,
        "id": 269,
        "no_speech_prob": 0.000010451545676914975,
        "seek": 68402,
        "start": 707.98,
        "temperature": 0,
        "text": " if I press this button here,",
        "tokens": [
          51562,
          498,
          286,
          1886,
          341,
          2960,
          510,
          11,
          51634
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 714.2199999999999,
        "id": 270,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 709.42,
        "temperature": 0,
        "text": " which would merge Keegan M graphics into master.",
        "tokens": [
          50364,
          597,
          576,
          22183,
          3189,
          43118,
          376,
          11837,
          666,
          4505,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 716.18,
        "id": 271,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 714.2199999999999,
        "temperature": 0,
        "text": " I'm just going to do that from the command line.",
        "tokens": [
          50604,
          286,
          478,
          445,
          516,
          281,
          360,
          300,
          490,
          264,
          5622,
          1622,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 719.86,
        "id": 272,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 716.18,
        "temperature": 0,
        "text": " Git merge graphics.",
        "tokens": [
          50702,
          16939,
          22183,
          11837,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 722.3399999999999,
        "id": 273,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 721.5,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50968,
          1033,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 726.14,
        "id": 274,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 724.74,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51130,
          1692,
          321,
          352,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 728.78,
        "id": 275,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 727.0999999999999,
        "temperature": 0,
        "text": " I'm getting some good feedback in the chat",
        "tokens": [
          51248,
          286,
          478,
          1242,
          512,
          665,
          5824,
          294,
          264,
          5081,
          51332
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 730.54,
        "id": 276,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 728.78,
        "temperature": 0,
        "text": " of other things to mention.",
        "tokens": [
          51332,
          295,
          661,
          721,
          281,
          2152,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 731.42,
        "id": 277,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 730.54,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          51420,
          13268,
          0,
          51464
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 732.86,
        "id": 278,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 731.42,
        "temperature": 0,
        "text": " Okay, it's merged.",
        "tokens": [
          51464,
          1033,
          11,
          309,
          311,
          36427,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 735.42,
        "id": 279,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 732.86,
        "temperature": 0,
        "text": " And now I can say git status.",
        "tokens": [
          51536,
          400,
          586,
          286,
          393,
          584,
          18331,
          6558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21838374932607016,
        "compression_ratio": 1.5364583333333333,
        "end": 737.42,
        "id": 280,
        "no_speech_prob": 0.00003219229620299302,
        "seek": 70942,
        "start": 735.42,
        "temperature": 0,
        "text": " I'm going to say git status again.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          584,
          18331,
          6558,
          797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 739.42,
        "id": 281,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 737.42,
        "temperature": 0,
        "text": " I type git status all the time.",
        "tokens": [
          50364,
          286,
          2010,
          18331,
          6558,
          439,
          264,
          565,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 741.14,
        "id": 282,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 739.42,
        "temperature": 0,
        "text": " I'm on branch master, nothing to commit,",
        "tokens": [
          50464,
          286,
          478,
          322,
          9819,
          4505,
          11,
          1825,
          281,
          5599,
          11,
          50550
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 742.5,
        "id": 283,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 741.14,
        "temperature": 0,
        "text": " working directory clean.",
        "tokens": [
          50550,
          1364,
          21120,
          2541,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 746.8199999999999,
        "id": 284,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 742.5,
        "temperature": 0,
        "text": " All right, so now let me put these changes back.",
        "tokens": [
          50618,
          1057,
          558,
          11,
          370,
          586,
          718,
          385,
          829,
          613,
          2962,
          646,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 750.8199999999999,
        "id": 285,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 746.8199999999999,
        "temperature": 0,
        "text": " They're here on master, but they are not here.",
        "tokens": [
          50834,
          814,
          434,
          510,
          322,
          4505,
          11,
          457,
          436,
          366,
          406,
          510,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 753.54,
        "id": 286,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 750.8199999999999,
        "temperature": 0,
        "text": " If I go here, we'll see what's the latest commit.",
        "tokens": [
          51034,
          759,
          286,
          352,
          510,
          11,
          321,
          603,
          536,
          437,
          311,
          264,
          6792,
          5599,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 755.66,
        "id": 287,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 753.54,
        "temperature": 0,
        "text": " It's still something else that I was working on.",
        "tokens": [
          51170,
          467,
          311,
          920,
          746,
          1646,
          300,
          286,
          390,
          1364,
          322,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 758.5799999999999,
        "id": 288,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 755.66,
        "temperature": 0,
        "text": " So I'm going to now say git push.",
        "tokens": [
          51276,
          407,
          286,
          478,
          516,
          281,
          586,
          584,
          18331,
          2944,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 761.38,
        "id": 289,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 759.66,
        "temperature": 0,
        "text": " I'm not going to say origin, I'm not going to say origin,",
        "tokens": [
          51476,
          286,
          478,
          406,
          516,
          281,
          584,
          4957,
          11,
          286,
          478,
          406,
          516,
          281,
          584,
          4957,
          11,
          51562
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 762.2199999999999,
        "id": 290,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 761.38,
        "temperature": 0,
        "text": " I'm not going to say origin,",
        "tokens": [
          51562,
          286,
          478,
          406,
          516,
          281,
          584,
          4957,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.25293975939853586,
        "compression_ratio": 1.8677685950413223,
        "end": 765.9,
        "id": 291,
        "no_speech_prob": 0.002359653590247035,
        "seek": 73742,
        "start": 762.2199999999999,
        "temperature": 0,
        "text": " because I renamed it to github master.",
        "tokens": [
          51604,
          570,
          286,
          40949,
          309,
          281,
          290,
          355,
          836,
          4505,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 770.4599999999999,
        "id": 292,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 765.9,
        "temperature": 0,
        "text": " And if I do that, now I have sent that up.",
        "tokens": [
          50364,
          400,
          498,
          286,
          360,
          300,
          11,
          586,
          286,
          362,
          2279,
          300,
          493,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 774.26,
        "id": 293,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 771.5,
        "temperature": 0,
        "text": " I'm going to hit refresh here,",
        "tokens": [
          50644,
          286,
          478,
          516,
          281,
          2045,
          15134,
          510,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 775.1,
        "id": 294,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 774.26,
        "temperature": 0,
        "text": " and I'm going to say look,",
        "tokens": [
          50782,
          293,
          286,
          478,
          516,
          281,
          584,
          574,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 778.66,
        "id": 295,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 775.1,
        "temperature": 0,
        "text": " all of those changes from Keegan M are now here.",
        "tokens": [
          50824,
          439,
          295,
          729,
          2962,
          490,
          3189,
          43118,
          376,
          366,
          586,
          510,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 780.74,
        "id": 296,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 778.66,
        "temperature": 0,
        "text": " We can see they're here, background version three.",
        "tokens": [
          51002,
          492,
          393,
          536,
          436,
          434,
          510,
          11,
          3678,
          3037,
          1045,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 783.3199999999999,
        "id": 297,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 780.74,
        "temperature": 0,
        "text": " This was me merging, this was me correcting the mistake.",
        "tokens": [
          51106,
          639,
          390,
          385,
          44559,
          11,
          341,
          390,
          385,
          47032,
          264,
          6146,
          13,
          51235
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 786.3,
        "id": 298,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 783.3199999999999,
        "temperature": 0,
        "text": " This was some other stuff, some other stuff.",
        "tokens": [
          51235,
          639,
          390,
          512,
          661,
          1507,
          11,
          512,
          661,
          1507,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 787.78,
        "id": 299,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 786.3,
        "temperature": 0,
        "text": " We can see all of that is here.",
        "tokens": [
          51384,
          492,
          393,
          536,
          439,
          295,
          300,
          307,
          510,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 790.64,
        "id": 300,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 787.78,
        "temperature": 0,
        "text": " Now the real question is if I go into pull requests,",
        "tokens": [
          51458,
          823,
          264,
          957,
          1168,
          307,
          498,
          286,
          352,
          666,
          2235,
          12475,
          11,
          51601
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 792.9,
        "id": 301,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 791.8199999999999,
        "temperature": 0,
        "text": " look at this.",
        "tokens": [
          51660,
          574,
          412,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 794.3,
        "id": 302,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 792.9,
        "temperature": 0,
        "text": " Where is that pull request?",
        "tokens": [
          51714,
          2305,
          307,
          300,
          2235,
          5308,
          30,
          51784
        ]
      },
      {
        "avg_logprob": -0.2332102782534857,
        "compression_ratio": 1.790513833992095,
        "end": 795.62,
        "id": 303,
        "no_speech_prob": 0.000023552540369564667,
        "seek": 76590,
        "start": 794.3,
        "temperature": 0,
        "text": " It's not there anymore.",
        "tokens": [
          51784,
          467,
          311,
          406,
          456,
          3602,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 801.34,
        "id": 304,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 796.34,
        "temperature": 0,
        "text": " GitHub was smart enough to realize that I merged this.",
        "tokens": [
          50400,
          23331,
          390,
          4069,
          1547,
          281,
          4325,
          300,
          286,
          36427,
          341,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 805.5,
        "id": 305,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 803.38,
        "temperature": 0,
        "text": " I merged this via the command line.",
        "tokens": [
          50752,
          286,
          36427,
          341,
          5766,
          264,
          5622,
          1622,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 809.9,
        "id": 306,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 805.5,
        "temperature": 0,
        "text": " So the merge button is gone, and it is now enclosed.",
        "tokens": [
          50858,
          407,
          264,
          22183,
          2960,
          307,
          2780,
          11,
          293,
          309,
          307,
          586,
          42089,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 810.74,
        "id": 307,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 809.9,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          51078,
          22768,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 812.54,
        "id": 308,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 810.74,
        "temperature": 0,
        "text": " So hopefully you learned something a little bit",
        "tokens": [
          51120,
          407,
          4696,
          291,
          3264,
          746,
          257,
          707,
          857,
          51210
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 817.54,
        "id": 309,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 812.54,
        "temperature": 0,
        "text": " about git remotes and about merging in this video tutorial.",
        "tokens": [
          51210,
          466,
          18331,
          890,
          17251,
          293,
          466,
          44559,
          294,
          341,
          960,
          7073,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 819.5600000000001,
        "id": 310,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 817.54,
        "temperature": 0,
        "text": " Thanks for watching, and I will come back",
        "tokens": [
          51460,
          2561,
          337,
          1976,
          11,
          293,
          286,
          486,
          808,
          646,
          51561
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 820.94,
        "id": 311,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 819.5600000000001,
        "temperature": 0,
        "text": " and make many more of these,",
        "tokens": [
          51561,
          293,
          652,
          867,
          544,
          295,
          613,
          11,
          51630
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 823.54,
        "id": 312,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 820.94,
        "temperature": 0,
        "text": " working with git and GitHub open source tutorial thingies.",
        "tokens": [
          51630,
          1364,
          365,
          18331,
          293,
          23331,
          1269,
          4009,
          7073,
          551,
          530,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.28221126772322747,
        "compression_ratio": 1.665289256198347,
        "end": 824.38,
        "id": 313,
        "no_speech_prob": 0.000027535646950127557,
        "seek": 79562,
        "start": 823.54,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51760,
          1044,
          291,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.9471288094153771,
        "compression_ratio": 0.6428571428571429,
        "end": 827.84,
        "id": 314,
        "no_speech_prob": 0.10895182192325592,
        "seek": 82438,
        "start": 824.38,
        "temperature": 0.6000000000000001,
        "text": " ♪♪♪",
        "tokens": [
          50414,
          220,
          158,
          247,
          103,
          158,
          247,
          103,
          158,
          247,
          103,
          50537
        ]
      }
    ],
    "transcription": " Hello, this is another video which is a tutorial about working with Git and GitHub. And in this tutorial, I'm going to talk about remotes. Woohoo, yes. So I'm in the middle of live streaming and I'm working on this project that has to do with this Flappy Bird clone. I'm going to train a bot using a genetic algorithm and a neural network to play Flappy Bird. And I have a wonderful pull request from GitHub user Keegan M, who has added this particular image to be the Flappy Bird and this particular background to be the background of the Flappy Bird game. And I really want to accept this pull request, but what I want to do, and I can examine it through the GitHub interface. I can see, ah, this was deleted and this was added because now it's going to have an image and there's a icon variable which loads the image. Those are some things, those are some wonderful things like that that I want to accept, but I don't have any unit testing and this isn't hosted anywhere, so I want to actually look at it locally on my computer to run the code and see before I merge it. And so there's a variety of ways that this can be done more efficiently than what I'm going to show you right now, but this is a good excuse to talk about remotes. So what is a remote? So right now, my terminal window, which I want to make a little bit bigger, is in the directory of this project. I'm on the desktop, Flappy Bird clone. If I say git remote, remote is a command dash v, dash v for verbose, like I want to know as much as possible, I want to be very verbose about the remote, it's going to say, oh look, you have a remote that is named origin that is tied to this URL and that makes sense, that's my GitHub URL, coding train slash Flappy Bird clone. That's the GitHub repository. And this remote was automatically created because at some point in time, I said git clone and I put this in. So when I did this, this default remote was created. So the remote being another location where this git repository exists. Now the word origin is kind of a default convention for the original remote, the sort of canonical remote, being GitHub in this case, but it's just a made up thing. Like I can say, and I do this actually with a lot of projects, I can say git remote delete, I think, origin. Nope. Git remote remove origin? Yes, and now if I say git remote dash v, there's no more remotes. But I can say git remote add, and instead of calling it origin, why not call it GitHub or unicorn? I can call it anything I want. Let's call it GitHub. And then I can paste in, Flappy Bird clone, I'm just going to grab this URL here and I can paste this in here. And now I am adding this remote. And I can say git remote dash v again, and we can see there it is back, but it's now called GitHub. So if I were ever to say git put pull origin master to grab some changes, master, by the way, is this name of the core branch. It's also just a completely made up thing. I could have source branch or release branch or development branch or experimental branch. That's a separate video about branches that you can go and watch. But if I say this, it'll say, ah, origin doesn't appear to be a Git repository because it's not there. But I can now say git pull GitHub master. And there we go. Now I'm already up to date, so I don't have to worry about it. Now here's the thing. I want, let's go back to this pull request, which is once again from Kegan M. So where is Kegan M's, and we can see here, ah, Kegan M colon graphics. So Kegan M made these code changes in a branch called graphics in their GitHub repository. So one thing I'm going to do is I'm just going to copy paste this right here. There's probably a way I could link to it. And I'm going to go up to the URL, and I'm going to change coding train to Kegan M. And I'm going to get rid of the pull request. I just want to go over there and see that this is the fork of the repository. And so there we can see this is Kegan M's fork. We can see branch master. We can see branch graphics. I could start looking around. Now what I'm going to do is I'm going to go to clone, and I'm going to grab this. So I'm now going to grab Kegan M's fork of my Flappy Bird clone. I'm going to grab that. And I'm going to say git remote add Kegan M. I can make up anything here. I'm just going to say Kegan, because I think I can remember that. And I'm going to then paste in that particular URL for Kegan M. Now one thing you might notice, these URLs say git at github.com. You might actually, and this is because I have set up this very fancy way for my computer to be auto logged in using an SHH key and a passphrase. But if you don't have that set up, and I should do a video tutorial that explains how to do that, you might want to use HTTPS. This is also a way that you can, this is just the sort of standard URL without having the sort of secret keys that log you in automatically. But that's a little bit of an aside here. I'm going to add this remote. And now I'm going to say git remote dash v, and we can see, look at this. I have GitHub remote, which is tied to me, CodingTrain. I have Kegan's remote, which is tied to Kegan M, which is tied to the GitHub repository Kegan M. Now, I'm going to say, there's a lot of different things that I can do, but what I'm going to do is I'm just going to say git branch graphics. I'm going to make a branch locally called graphics, and I'm going to quickly go into that branch. Again, you should probably watch my branches tutorial about how this works, and I'm going to go into that branch by using checkout. Then what I'm going to do is I'm going to say git pull, and usually I almost reflectively just git pull origin master, git pull origin master, git pull origin master, git pull origin master, git pull origin master. I don't want to pull from origin, I want to pull from Kegan, and I don't want to pull from master, I want to pull from graphics. Git pull Kegan graphics. Ah, ooh, interesting, hmm. So something has happened here, in that I have now been launched into a text editor known as VI. Whoa, this has been like way off the screen. That's what's going on here, that's crazy. And so there's some sort of merging that needs to happen for Kegan M's branch graphics to come into my branch graphics, because I actually have made some other changes. It would have been nice if this didn't happen, but this is actually quite normal. This is a regular thing, and I have to deal with this. So what I want to do is say that, I'm going to say, what do I type in VI? So, ah, this always happens. So I think I'd say colon insert, no? I for insert, I for insert. So again, you can link a different text editor to your Git work on your computer, but this is, and so now that I've been launched this text editor in, in, I just want to say like, I'm making a tutorial video, so I don't have a lot of time, but this is here to merge Kegan's graphics with some recent changes I made. And then I'm going to say, colon, oops, oh no, I got to get rid of insert, escape maybe, escape colon QW, which I think will then quit and write this out. I don't really know how to use VI, Vim or whatever, I don't know what to call it. Colon QW, and I'm going to just do that. No, not an editor command. Colon WQ, right, and then quit. There we go, and now it's fine. It didn't commit it, that's fine. So now this is good. I just really wanted to look at it. All I wanted to do was look at it. I don't need to commit this right now, because I'm not really worrying about merging. And so now I should, if I come over here, this is me looking at my code in the browser before I checked out and pulled from that other remote. And there we go. Look at this, and now we have the coding train, the floppy bird, floppy coding train game with our little unicorn train and the scrolling background. Okay, wonderful, so this is good. So now I feel, I'm like, oh, this looks great. I'm done. So interestingly enough, if I wanted to, I could actually merge everything right now from the command line. So normally I would just go to the pull request and I would scroll down here and I would just click on merge. And this would merge that pull request. In fact, I'd write a comment, thank you so much. I am going to merge this. And what's wonderful about using GitHub as a service, which is very different than the Git software itself, the version control software, is that it provides a visual interface to a lot of the common things that you might want to do, like merging and looking at the differences between two files and that sort of thing. But I think while I'm here, if you can tolerate continuing to watch this video, however, I am going to demonstrate, demonstrate merging from the command line for fun. So stay tuned. I'm going to add that comment. So I added that comment and now I'm going to return to the command line. Now I should say that I, something about the way I really need to make a video about setting up terminal or whatever you use as your terminal application to work with Git more effectively, because there's no reason why I couldn't see things being syntax highlighted or showing me what branch I'm currently on and there's also other terminal software like iTerm that I could use. So I've got to come back for that. But right now I'm just going to say, I don't even remember where I am. So I'm going to say git status and I'm going to say, okay, all conflicts fixed but you are still merging. So I didn't actually ultimately commit that merge that I did. So I'm going to say git commit. Now here's the thing. I have learned recently that using dash m is not as thoughtful or, so I'm going to do a video about how to not use dash m and write more thoughtful, longer commit messages. But for lack of a time right now, I'm just going to say commit dash m and I'm going to say merging changes from, and I'm going to want to remember Keegan M from Keegan M. Okay, I'm going to do that. So now, I'm going to say git status again. Okay, on branch graphics. So now I'm going to go to master. And what I'm going to do is I'm going to say git merge graphics. And what that will do is we'll take the graphics branch and merge it into master. It's exactly the same thing that would happen if I press this button here, which would merge Keegan M graphics into master. I'm just going to do that from the command line. Git merge graphics. Okay. Here we go. I'm getting some good feedback in the chat of other things to mention. Yay! Okay, it's merged. And now I can say git status. I'm going to say git status again. I type git status all the time. I'm on branch master, nothing to commit, working directory clean. All right, so now let me put these changes back. They're here on master, but they are not here. If I go here, we'll see what's the latest commit. It's still something else that I was working on. So I'm going to now say git push. I'm not going to say origin, I'm not going to say origin, I'm not going to say origin, because I renamed it to github master. And if I do that, now I have sent that up. I'm going to hit refresh here, and I'm going to say look, all of those changes from Keegan M are now here. We can see they're here, background version three. This was me merging, this was me correcting the mistake. This was some other stuff, some other stuff. We can see all of that is here. Now the real question is if I go into pull requests, look at this. Where is that pull request? It's not there anymore. GitHub was smart enough to realize that I merged this. I merged this via the command line. So the merge button is gone, and it is now enclosed. Wonderful. So hopefully you learned something a little bit about git remotes and about merging in this video tutorial. Thanks for watching, and I will come back and make many more of these, working with git and GitHub open source tutorial thingies. Thank you. ♪♪♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T20:41:45.578321Z",
  "started_at": "2023-09-26T20:49:35.971897Z",
  "completed_at": "2023-09-26T20:53:55.83377Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=lR_hYwCAaH4",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 259.861873
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/dhemu2bblgs44btr5bhfzpom7y/cancel",
    "get": "https://api.replicate.com/v1/predictions/dhemu2bblgs44btr5bhfzpom7y"
  }
}