{
  "id": "gxdaqujbde56w25zydxlyxrtsm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/ABN_DWnM5GQ.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/72299 [00:00<?, ?frames/s]\n  4%|▎         | 2692/72299 [00:09<03:52, 298.97frames/s]\n  8%|▊         | 5672/72299 [00:15<02:59, 371.90frames/s]\n 12%|█▏        | 8488/72299 [00:24<02:59, 355.08frames/s]\n 16%|█▌        | 11404/72299 [00:34<03:07, 324.03frames/s]\n 20%|█▉        | 14204/72299 [00:42<02:58, 326.07frames/s]\n 24%|██▍       | 17196/72299 [00:50<02:39, 344.70frames/s]\n 28%|██▊       | 20196/72299 [00:57<02:23, 363.38frames/s]\n 32%|███▏      | 23068/72299 [01:05<02:14, 366.53frames/s]\n 36%|███▌      | 26028/72299 [01:14<02:08, 359.65frames/s]\n 40%|███▉      | 28832/72299 [01:20<01:55, 375.73frames/s]\n 44%|████▍     | 31696/72299 [01:28<01:48, 373.00frames/s]\n 48%|████▊     | 34496/72299 [01:35<01:40, 378.03frames/s]\n 52%|█████▏    | 37496/72299 [01:45<01:36, 359.33frames/s]\n 56%|█████▌    | 40276/72299 [01:51<01:26, 372.14frames/s]\n 60%|█████▉    | 43080/72299 [01:59<01:18, 372.85frames/s]\n 63%|██████▎   | 45608/72299 [02:05<01:09, 386.41frames/s]\n 67%|██████▋   | 48352/72299 [02:13<01:03, 375.71frames/s]\n 71%|███████   | 51140/72299 [02:19<00:54, 391.45frames/s]\n 75%|███████▍  | 54060/72299 [02:26<00:46, 395.84frames/s]\n 79%|███████▉  | 57024/72299 [02:33<00:36, 414.49frames/s]\n 83%|████████▎ | 59980/72299 [02:38<00:27, 441.95frames/s]\n 87%|████████▋ | 62844/72299 [02:45<00:21, 444.68frames/s]\n 91%|█████████ | 65636/72299 [02:53<00:16, 404.18frames/s]\n 95%|█████████▍| 68542/72299 [03:01<00:09, 385.98frames/s]\n 99%|█████████▊| 71290/72299 [03:10<00:02, 367.27frames/s]\n100%|██████████| 72299/72299 [03:15<00:00, 325.66frames/s]\n100%|██████████| 72299/72299 [03:15<00:00, 369.47frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 2.84,
        "id": 0,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, and welcome to another ML5.js video tutorial.",
        "tokens": [
          50364,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          21601,
          20,
          13,
          25530,
          960,
          7073,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 5.72,
        "id": 1,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 2.84,
        "temperature": 0,
        "text": " In this video, I am going to attempt to classify",
        "tokens": [
          50506,
          682,
          341,
          960,
          11,
          286,
          669,
          516,
          281,
          5217,
          281,
          33872,
          50650
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 7.4,
        "id": 2,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 5.72,
        "temperature": 0,
        "text": " my drawing as a cat.",
        "tokens": [
          50650,
          452,
          6316,
          382,
          257,
          3857,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 8.56,
        "id": 3,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 7.4,
        "temperature": 0,
        "text": " So how am I going to do this?",
        "tokens": [
          50734,
          407,
          577,
          669,
          286,
          516,
          281,
          360,
          341,
          30,
          50792
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 11.040000000000001,
        "id": 4,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 8.56,
        "temperature": 0,
        "text": " And how come this video is so darn short?",
        "tokens": [
          50792,
          400,
          577,
          808,
          341,
          960,
          307,
          370,
          29063,
          2099,
          30,
          50916
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 14.040000000000001,
        "id": 5,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 11.040000000000001,
        "temperature": 0,
        "text": " Well, I'm going to make use of a pre-trained model called",
        "tokens": [
          50916,
          1042,
          11,
          286,
          478,
          516,
          281,
          652,
          764,
          295,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          1219,
          51066
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 17.28,
        "id": 6,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 14.040000000000001,
        "temperature": 0,
        "text": " DoodleNet that comes as part of the ML5 library.",
        "tokens": [
          51066,
          1144,
          30013,
          31890,
          300,
          1487,
          382,
          644,
          295,
          264,
          21601,
          20,
          6405,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 19.84,
        "id": 7,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 17.28,
        "temperature": 0,
        "text": " The DoodleNet model, which you can read more about",
        "tokens": [
          51228,
          440,
          1144,
          30013,
          31890,
          2316,
          11,
          597,
          291,
          393,
          1401,
          544,
          466,
          51356
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 22.14,
        "id": 8,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 19.84,
        "temperature": 0,
        "text": " on the documentation page, is a pre-trained model",
        "tokens": [
          51356,
          322,
          264,
          14333,
          3028,
          11,
          307,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          51471
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 24.560000000000002,
        "id": 9,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 22.14,
        "temperature": 0,
        "text": " that classifies and labels hand-drawn sketches",
        "tokens": [
          51471,
          300,
          1508,
          11221,
          293,
          16949,
          1011,
          12,
          67,
          29603,
          34547,
          51592
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 26.44,
        "id": 10,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 24.560000000000002,
        "temperature": 0,
        "text": " from 345 categories.",
        "tokens": [
          51592,
          490,
          805,
          8465,
          10479,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2214762983650997,
        "compression_ratio": 1.6550522648083623,
        "end": 26.92,
        "id": 11,
        "no_speech_prob": 0.009121637791395187,
        "seek": 0,
        "start": 26.44,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          51686,
          8063,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 30.560000000000002,
        "id": 12,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 27,
        "temperature": 0,
        "text": " I wonder, what might these 345 categories be?",
        "tokens": [
          50368,
          286,
          2441,
          11,
          437,
          1062,
          613,
          805,
          8465,
          10479,
          312,
          30,
          50546
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 33.120000000000005,
        "id": 13,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 30.560000000000002,
        "temperature": 0,
        "text": " Well, if I scroll down and take a look at the DoodleNet data",
        "tokens": [
          50546,
          1042,
          11,
          498,
          286,
          11369,
          760,
          293,
          747,
          257,
          574,
          412,
          264,
          1144,
          30013,
          31890,
          1412,
          50674
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 36.160000000000004,
        "id": 14,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 33.120000000000005,
        "temperature": 0,
        "text": " biography, you will find out that the data set comes",
        "tokens": [
          50674,
          37062,
          11,
          291,
          486,
          915,
          484,
          300,
          264,
          1412,
          992,
          1487,
          50826
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 38.72,
        "id": 15,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 36.160000000000004,
        "temperature": 0,
        "text": " from Google's Quick Draw, which was a game that",
        "tokens": [
          50826,
          490,
          3329,
          311,
          12101,
          20386,
          11,
          597,
          390,
          257,
          1216,
          300,
          50954
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 40.6,
        "id": 16,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 38.72,
        "temperature": 0,
        "text": " was created in 2016.",
        "tokens": [
          50954,
          390,
          2942,
          294,
          6549,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 43.96,
        "id": 17,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 40.6,
        "temperature": 0,
        "text": " And Yining Shi, who created and trained this model,",
        "tokens": [
          51048,
          400,
          398,
          1760,
          25580,
          11,
          567,
          2942,
          293,
          8895,
          341,
          2316,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 46.24,
        "id": 18,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 43.96,
        "temperature": 0,
        "text": " you can find out more about Yining by going to this link",
        "tokens": [
          51216,
          291,
          393,
          915,
          484,
          544,
          466,
          398,
          1760,
          538,
          516,
          281,
          341,
          2113,
          51330
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 49.52,
        "id": 19,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 46.24,
        "temperature": 0,
        "text": " here, collected the data in 2019.",
        "tokens": [
          51330,
          510,
          11,
          11087,
          264,
          1412,
          294,
          6071,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 51.84,
        "id": 20,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 49.52,
        "temperature": 0,
        "text": " This is what the Google Quick Draw data set is.",
        "tokens": [
          51494,
          639,
          307,
          437,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          307,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 53.58,
        "id": 21,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 51.84,
        "temperature": 0,
        "text": " It's 50 million drawings.",
        "tokens": [
          51610,
          467,
          311,
          2625,
          2459,
          18618,
          13,
          51697
        ]
      },
      {
        "avg_logprob": -0.218972042628697,
        "compression_ratio": 1.65993265993266,
        "end": 56.72,
        "id": 22,
        "no_speech_prob": 0.00014652944810222834,
        "seek": 2692,
        "start": 53.58,
        "temperature": 0,
        "text": " I don't expect that Yining used all 50 million.",
        "tokens": [
          51697,
          286,
          500,
          380,
          2066,
          300,
          398,
          1760,
          1143,
          439,
          2625,
          2459,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 58.76,
        "id": 23,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 56.72,
        "temperature": 0,
        "text": " We can see 50,000 per category.",
        "tokens": [
          50364,
          492,
          393,
          536,
          2625,
          11,
          1360,
          680,
          7719,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 61.48,
        "id": 24,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 58.76,
        "temperature": 0,
        "text": " So do the math, 50,000 times 345.",
        "tokens": [
          50466,
          407,
          360,
          264,
          5221,
          11,
          2625,
          11,
          1360,
          1413,
          805,
          8465,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 65.08,
        "id": 25,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 61.48,
        "temperature": 0,
        "text": " And you can find all of Yining's training source code",
        "tokens": [
          50602,
          400,
          291,
          393,
          915,
          439,
          295,
          398,
          1760,
          311,
          3097,
          4009,
          3089,
          50782
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 68.68,
        "id": 26,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 65.08,
        "temperature": 0,
        "text": " here in this DoodleNet repo itself and more information",
        "tokens": [
          50782,
          510,
          294,
          341,
          1144,
          30013,
          31890,
          49040,
          2564,
          293,
          544,
          1589,
          50962
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 70,
        "id": 27,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 68.68,
        "temperature": 0,
        "text": " about how the model is trained.",
        "tokens": [
          50962,
          466,
          577,
          264,
          2316,
          307,
          8895,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 71.03999999999999,
        "id": 28,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 70,
        "temperature": 0,
        "text": " But guess what?",
        "tokens": [
          51028,
          583,
          2041,
          437,
          30,
          51080
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 72.92,
        "id": 29,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 71.03999999999999,
        "temperature": 0,
        "text": " This video is actually really a follow-up",
        "tokens": [
          51080,
          639,
          960,
          307,
          767,
          534,
          257,
          1524,
          12,
          1010,
          51174
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 75.64,
        "id": 30,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 72.92,
        "temperature": 0,
        "text": " to my coding challenge about training a machine learning",
        "tokens": [
          51174,
          281,
          452,
          17720,
          3430,
          466,
          3097,
          257,
          3479,
          2539,
          51310
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 78.9,
        "id": 31,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 75.64,
        "temperature": 0,
        "text": " model to recognize drawings of shapes, circles, squares,",
        "tokens": [
          51310,
          2316,
          281,
          5521,
          18618,
          295,
          10854,
          11,
          13040,
          11,
          19368,
          11,
          51473
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 79.6,
        "id": 32,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 78.9,
        "temperature": 0,
        "text": " and triangles.",
        "tokens": [
          51473,
          293,
          29896,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 82.72,
        "id": 33,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 79.6,
        "temperature": 0,
        "text": " So I did this whole process of collecting a data set,",
        "tokens": [
          51508,
          407,
          286,
          630,
          341,
          1379,
          1399,
          295,
          12510,
          257,
          1412,
          992,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2339438253374242,
        "compression_ratio": 1.6478405315614617,
        "end": 84.88,
        "id": 34,
        "no_speech_prob": 0.0001313513348577544,
        "seek": 5672,
        "start": 82.72,
        "temperature": 0,
        "text": " training a model, and then deploying that model",
        "tokens": [
          51664,
          3097,
          257,
          2316,
          11,
          293,
          550,
          34198,
          300,
          2316,
          51772
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 86.83999999999999,
        "id": 35,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 84.88,
        "temperature": 0,
        "text": " all in the browser in a separate video.",
        "tokens": [
          50364,
          439,
          294,
          264,
          11185,
          294,
          257,
          4994,
          960,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 89.08,
        "id": 36,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 86.83999999999999,
        "temperature": 0,
        "text": " And in this one, I'm just going to quickly basically do",
        "tokens": [
          50462,
          400,
          294,
          341,
          472,
          11,
          286,
          478,
          445,
          516,
          281,
          2661,
          1936,
          360,
          50574
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 92.67999999999999,
        "id": 37,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 89.08,
        "temperature": 0,
        "text": " the same thing, but use a more sophisticated, more robust",
        "tokens": [
          50574,
          264,
          912,
          551,
          11,
          457,
          764,
          257,
          544,
          16950,
          11,
          544,
          13956,
          50754
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 95.16,
        "id": 38,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 92.67999999999999,
        "temperature": 0,
        "text": " pre-trained model created by Yining Shi.",
        "tokens": [
          50754,
          659,
          12,
          17227,
          2001,
          2316,
          2942,
          538,
          398,
          1760,
          25580,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 96.64,
        "id": 39,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 95.16,
        "temperature": 0,
        "text": " All right, here we go.",
        "tokens": [
          50878,
          1057,
          558,
          11,
          510,
          321,
          352,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 98.24,
        "id": 40,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 96.64,
        "temperature": 0,
        "text": " So this is my starter code.",
        "tokens": [
          50952,
          407,
          341,
          307,
          452,
          22465,
          3089,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 99.16,
        "id": 41,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 98.24,
        "temperature": 0,
        "text": " What is it doing?",
        "tokens": [
          51032,
          708,
          307,
          309,
          884,
          30,
          51078
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 100.6,
        "id": 42,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 99.16,
        "temperature": 0,
        "text": " You can see this is very simple.",
        "tokens": [
          51078,
          509,
          393,
          536,
          341,
          307,
          588,
          2199,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 101.75999999999999,
        "id": 43,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 100.6,
        "temperature": 0,
        "text": " It's just creating a canvas.",
        "tokens": [
          51150,
          467,
          311,
          445,
          4084,
          257,
          16267,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 102.82,
        "id": 44,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 101.75999999999999,
        "temperature": 0,
        "text": " It's 400 by 400.",
        "tokens": [
          51208,
          467,
          311,
          8423,
          538,
          8423,
          13,
          51261
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 103.96,
        "id": 45,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 102.82,
        "temperature": 0,
        "text": " I have a Clear button.",
        "tokens": [
          51261,
          286,
          362,
          257,
          14993,
          2960,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 105.36,
        "id": 46,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 103.96,
        "temperature": 0,
        "text": " So when I press that Clear button,",
        "tokens": [
          51318,
          407,
          562,
          286,
          1886,
          300,
          14993,
          2960,
          11,
          51388
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 107.64,
        "id": 47,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 105.36,
        "temperature": 0,
        "text": " it redraws the background, erasing the drawing.",
        "tokens": [
          51388,
          309,
          2182,
          5131,
          82,
          264,
          3678,
          11,
          1189,
          3349,
          264,
          6316,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 110.24,
        "id": 48,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 107.64,
        "temperature": 0,
        "text": " And then in the Draw function, whenever the mouse is pressed,",
        "tokens": [
          51502,
          400,
          550,
          294,
          264,
          20386,
          2445,
          11,
          5699,
          264,
          9719,
          307,
          17355,
          11,
          51632
        ]
      },
      {
        "avg_logprob": -0.22961104421904593,
        "compression_ratio": 1.688821752265861,
        "end": 114.03999999999999,
        "id": 49,
        "no_speech_prob": 0.001700688386335969,
        "seek": 8488,
        "start": 110.24,
        "temperature": 0,
        "text": " it leaves a trail from my current mouse position",
        "tokens": [
          51632,
          309,
          5510,
          257,
          9924,
          490,
          452,
          2190,
          9719,
          2535,
          51822
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 115.32000000000001,
        "id": 50,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 114.04,
        "temperature": 0,
        "text": " to my previous mouse position.",
        "tokens": [
          50364,
          281,
          452,
          3894,
          9719,
          2535,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 116.96000000000001,
        "id": 51,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 115.32000000000001,
        "temperature": 0,
        "text": " Or maybe I should say my previous mouse position",
        "tokens": [
          50428,
          1610,
          1310,
          286,
          820,
          584,
          452,
          3894,
          9719,
          2535,
          50510
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 118.16000000000001,
        "id": 52,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 116.96000000000001,
        "temperature": 0,
        "text": " to my current mouse position.",
        "tokens": [
          50510,
          281,
          452,
          2190,
          9719,
          2535,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 119.36000000000001,
        "id": 53,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 118.16000000000001,
        "temperature": 0,
        "text": " It's the same thing.",
        "tokens": [
          50570,
          467,
          311,
          264,
          912,
          551,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 123.32000000000001,
        "id": 54,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 119.36000000000001,
        "temperature": 0,
        "text": " I also should note that I have imported the ml5 library.",
        "tokens": [
          50630,
          286,
          611,
          820,
          3637,
          300,
          286,
          362,
          25524,
          264,
          23271,
          20,
          6405,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 126.48,
        "id": 55,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 123.32000000000001,
        "temperature": 0,
        "text": " I'm currently using version 0.6.0.",
        "tokens": [
          50828,
          286,
          478,
          4362,
          1228,
          3037,
          1958,
          13,
          21,
          13,
          15,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 128.08,
        "id": 56,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 126.48,
        "temperature": 0,
        "text": " So if you want to match that version,",
        "tokens": [
          50986,
          407,
          498,
          291,
          528,
          281,
          2995,
          300,
          3037,
          11,
          51066
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 129.76000000000002,
        "id": 57,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 128.08,
        "temperature": 0,
        "text": " if you're working trying to recreate this code,",
        "tokens": [
          51066,
          498,
          291,
          434,
          1364,
          1382,
          281,
          25833,
          341,
          3089,
          11,
          51150
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 130.96,
        "id": 58,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 129.76000000000002,
        "temperature": 0,
        "text": " that's the version I'm using.",
        "tokens": [
          51150,
          300,
          311,
          264,
          3037,
          286,
          478,
          1228,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 135.4,
        "id": 59,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 130.96,
        "temperature": 0,
        "text": " Step one, create a variable to hold the image classifier.",
        "tokens": [
          51210,
          5470,
          472,
          11,
          1884,
          257,
          7006,
          281,
          1797,
          264,
          3256,
          1508,
          9902,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 138.24,
        "id": 60,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 135.4,
        "temperature": 0,
        "text": " And I'll call it doodle classifier.",
        "tokens": [
          51432,
          400,
          286,
          603,
          818,
          309,
          360,
          30013,
          1508,
          9902,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.24819819132486978,
        "compression_ratio": 1.86,
        "end": 142.04000000000002,
        "id": 61,
        "no_speech_prob": 0.00013552051677834243,
        "seek": 11404,
        "start": 138.24,
        "temperature": 0,
        "text": " Step two, call image classifier.",
        "tokens": [
          51574,
          5470,
          732,
          11,
          818,
          3256,
          1508,
          9902,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 144.72,
        "id": 62,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 142.04,
        "temperature": 0,
        "text": " Give myself some more space here for the code.",
        "tokens": [
          50364,
          5303,
          2059,
          512,
          544,
          1901,
          510,
          337,
          264,
          3089,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 149.51999999999998,
        "id": 63,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 144.72,
        "temperature": 0,
        "text": " And indicate to ml5 that I want to load the doodle net",
        "tokens": [
          50498,
          400,
          13330,
          281,
          23271,
          20,
          300,
          286,
          528,
          281,
          3677,
          264,
          360,
          30013,
          2533,
          50738
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 151.07999999999998,
        "id": 64,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 149.51999999999998,
        "temperature": 0,
        "text": " pre-trained model.",
        "tokens": [
          50738,
          659,
          12,
          17227,
          2001,
          2316,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 154.35999999999999,
        "id": 65,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 151.07999999999998,
        "temperature": 0,
        "text": " And then I need a callback for when that model is ready.",
        "tokens": [
          50816,
          400,
          550,
          286,
          643,
          257,
          818,
          3207,
          337,
          562,
          300,
          2316,
          307,
          1919,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 159.12,
        "id": 66,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 154.35999999999999,
        "temperature": 0,
        "text": " I need to make sure I have all the indentation correct.",
        "tokens": [
          50980,
          286,
          643,
          281,
          652,
          988,
          286,
          362,
          439,
          264,
          44494,
          399,
          3006,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 161.16,
        "id": 67,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 159.12,
        "temperature": 0,
        "text": " Once the model is ready, I just want",
        "tokens": [
          51218,
          3443,
          264,
          2316,
          307,
          1919,
          11,
          286,
          445,
          528,
          51320
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 163.92,
        "id": 68,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 161.16,
        "temperature": 0,
        "text": " to take the canvas itself and pass it",
        "tokens": [
          51320,
          281,
          747,
          264,
          16267,
          2564,
          293,
          1320,
          309,
          51458
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 167.28,
        "id": 69,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 163.92,
        "temperature": 0,
        "text": " to the model for a prediction.",
        "tokens": [
          51458,
          281,
          264,
          2316,
          337,
          257,
          17630,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 169.23999999999998,
        "id": 70,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 167.28,
        "temperature": 0,
        "text": " Once it's gotten that canvas, sent it",
        "tokens": [
          51626,
          3443,
          309,
          311,
          5768,
          300,
          16267,
          11,
          2279,
          309,
          51724
        ]
      },
      {
        "avg_logprob": -0.23743294887855404,
        "compression_ratio": 1.72,
        "end": 171.95999999999998,
        "id": 71,
        "no_speech_prob": 0.00006014145037624985,
        "seek": 14204,
        "start": 169.23999999999998,
        "temperature": 0,
        "text": " through the neural network, it will get results back",
        "tokens": [
          51724,
          807,
          264,
          18161,
          3209,
          11,
          309,
          486,
          483,
          3542,
          646,
          51860
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 174.12,
        "id": 72,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 171.96,
        "temperature": 0,
        "text": " of a probability score, a confidence score,",
        "tokens": [
          50364,
          295,
          257,
          8482,
          6175,
          11,
          257,
          6687,
          6175,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 176,
        "id": 73,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 174.12,
        "temperature": 0,
        "text": " for every single one of those categories.",
        "tokens": [
          50472,
          337,
          633,
          2167,
          472,
          295,
          729,
          10479,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 178.64000000000001,
        "id": 74,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 176,
        "temperature": 0,
        "text": " And I can retrieve that in a callback, which",
        "tokens": [
          50566,
          400,
          286,
          393,
          30254,
          300,
          294,
          257,
          818,
          3207,
          11,
          597,
          50698
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 182,
        "id": 75,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 178.64000000000001,
        "temperature": 0,
        "text": " I am naming got results.",
        "tokens": [
          50698,
          286,
          669,
          25290,
          658,
          3542,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 185.12,
        "id": 76,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 182,
        "temperature": 0,
        "text": " ml5 follows an error first callback pattern,",
        "tokens": [
          50866,
          23271,
          20,
          10002,
          364,
          6713,
          700,
          818,
          3207,
          5102,
          11,
          51022
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 186.96,
        "id": 77,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 185.12,
        "temperature": 0,
        "text": " which means if something went wrong,",
        "tokens": [
          51022,
          597,
          1355,
          498,
          746,
          1437,
          2085,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 189.4,
        "id": 78,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 186.96,
        "temperature": 0,
        "text": " it will come back in the first argument as an error.",
        "tokens": [
          51114,
          309,
          486,
          808,
          646,
          294,
          264,
          700,
          6770,
          382,
          364,
          6713,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 191.96,
        "id": 79,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 189.4,
        "temperature": 0,
        "text": " If everything went well, I'll get the results",
        "tokens": [
          51236,
          759,
          1203,
          1437,
          731,
          11,
          286,
          603,
          483,
          264,
          3542,
          51364
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 193.72,
        "id": 80,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 191.96,
        "temperature": 0,
        "text": " in an object called results.",
        "tokens": [
          51364,
          294,
          364,
          2657,
          1219,
          3542,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 199.20000000000002,
        "id": 81,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 196.56,
        "temperature": 0,
        "text": " Handle the case of an error by just getting out of here",
        "tokens": [
          51594,
          8854,
          306,
          264,
          1389,
          295,
          364,
          6713,
          538,
          445,
          1242,
          484,
          295,
          510,
          51726
        ]
      },
      {
        "avg_logprob": -0.24966279665629068,
        "compression_ratio": 1.734375,
        "end": 200.12,
        "id": 82,
        "no_speech_prob": 0.0005884072161279619,
        "seek": 17196,
        "start": 199.20000000000002,
        "temperature": 0,
        "text": " and logging the error.",
        "tokens": [
          51726,
          293,
          27991,
          264,
          6713,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 204.56,
        "id": 83,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 202.28,
        "temperature": 0,
        "text": " And then let me just log the results.",
        "tokens": [
          50380,
          400,
          550,
          718,
          385,
          445,
          3565,
          264,
          3542,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 206.96,
        "id": 84,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 204.56,
        "temperature": 0,
        "text": " Run this sketch.",
        "tokens": [
          50494,
          8950,
          341,
          12325,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 210.16,
        "id": 85,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 206.96,
        "temperature": 0,
        "text": " In truth, I'm not so sure what this warning is.",
        "tokens": [
          50614,
          682,
          3494,
          11,
          286,
          478,
          406,
          370,
          988,
          437,
          341,
          9164,
          307,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 212.68,
        "id": 86,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 210.16,
        "temperature": 0,
        "text": " This happened to me in my own example",
        "tokens": [
          50774,
          639,
          2011,
          281,
          385,
          294,
          452,
          1065,
          1365,
          50900
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 215.52,
        "id": 87,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 212.68,
        "temperature": 0,
        "text": " where if you ever have your image resolution not matching",
        "tokens": [
          50900,
          689,
          498,
          291,
          1562,
          362,
          428,
          3256,
          8669,
          406,
          14324,
          51042
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 217.12,
        "id": 88,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 215.52,
        "temperature": 0,
        "text": " what the neural network is expecting,",
        "tokens": [
          51042,
          437,
          264,
          18161,
          3209,
          307,
          9650,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 218.08,
        "id": 89,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 217.12,
        "temperature": 0,
        "text": " you could get an error.",
        "tokens": [
          51122,
          291,
          727,
          483,
          364,
          6713,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 219.64000000000001,
        "id": 90,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 218.08,
        "temperature": 0,
        "text": " This is just a warning.",
        "tokens": [
          51170,
          639,
          307,
          445,
          257,
          9164,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 221.92000000000002,
        "id": 91,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 219.64000000000001,
        "temperature": 0,
        "text": " So I'm not entirely sure what's going on there,",
        "tokens": [
          51248,
          407,
          286,
          478,
          406,
          7696,
          988,
          437,
          311,
          516,
          322,
          456,
          11,
          51362
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 224.16,
        "id": 92,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 221.92000000000002,
        "temperature": 0,
        "text": " but I'm going to ignore it for right now.",
        "tokens": [
          51362,
          457,
          286,
          478,
          516,
          281,
          11200,
          309,
          337,
          558,
          586,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 226.12,
        "id": 93,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 224.16,
        "temperature": 0,
        "text": " And what I want to focus on is the results that",
        "tokens": [
          51474,
          400,
          437,
          286,
          528,
          281,
          1879,
          322,
          307,
          264,
          3542,
          300,
          51572
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 228.32,
        "id": 94,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 226.12,
        "temperature": 0,
        "text": " came back in a giant array.",
        "tokens": [
          51572,
          1361,
          646,
          294,
          257,
          7410,
          10225,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.23242495811148867,
        "compression_ratio": 1.8071428571428572,
        "end": 230.68,
        "id": 95,
        "no_speech_prob": 0.00019411205721553415,
        "seek": 20196,
        "start": 228.32,
        "temperature": 0,
        "text": " Object, object, object, object, object, object, object,",
        "tokens": [
          51682,
          24753,
          11,
          2657,
          11,
          2657,
          11,
          2657,
          11,
          2657,
          11,
          2657,
          11,
          2657,
          11,
          51800
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 232,
        "id": 96,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 230.68,
        "temperature": 0,
        "text": " thing, me, object, song.",
        "tokens": [
          50364,
          551,
          11,
          385,
          11,
          2657,
          11,
          2153,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 234.08,
        "id": 97,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 232,
        "temperature": 0,
        "text": " The way that this array is ordered",
        "tokens": [
          50430,
          440,
          636,
          300,
          341,
          10225,
          307,
          8866,
          50534
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 238,
        "id": 98,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 234.08,
        "temperature": 0,
        "text": " is whichever label has the highest confidence score,",
        "tokens": [
          50534,
          307,
          24123,
          7645,
          575,
          264,
          6343,
          6687,
          6175,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 239.52,
        "id": 99,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 238,
        "temperature": 0,
        "text": " it's going to come back first.",
        "tokens": [
          50730,
          309,
          311,
          516,
          281,
          808,
          646,
          700,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 241.92000000000002,
        "id": 100,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 239.52,
        "temperature": 0,
        "text": " So this is just a blank white canvas.",
        "tokens": [
          50806,
          407,
          341,
          307,
          445,
          257,
          8247,
          2418,
          16267,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 243.64000000000001,
        "id": 101,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 241.92000000000002,
        "temperature": 0,
        "text": " What does it think it is?",
        "tokens": [
          50926,
          708,
          775,
          309,
          519,
          309,
          307,
          30,
          51012
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 244.44,
        "id": 102,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 243.64000000000001,
        "temperature": 0,
        "text": " It's a line.",
        "tokens": [
          51012,
          467,
          311,
          257,
          1622,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 245.52,
        "id": 103,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 244.44,
        "temperature": 0,
        "text": " That kind of makes sense.",
        "tokens": [
          51052,
          663,
          733,
          295,
          1669,
          2020,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 248,
        "id": 104,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 245.52,
        "temperature": 0,
        "text": " The least amount of drawing would just be a line.",
        "tokens": [
          51106,
          440,
          1935,
          2372,
          295,
          6316,
          576,
          445,
          312,
          257,
          1622,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 250.08,
        "id": 105,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 248,
        "temperature": 0,
        "text": " The next one is a snowman.",
        "tokens": [
          51230,
          440,
          958,
          472,
          307,
          257,
          5756,
          1601,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 251,
        "id": 106,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 250.08,
        "temperature": 0,
        "text": " That also makes sense.",
        "tokens": [
          51334,
          663,
          611,
          1669,
          2020,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 252.8,
        "id": 107,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 251,
        "temperature": 0,
        "text": " Look, this is my art.",
        "tokens": [
          51380,
          2053,
          11,
          341,
          307,
          452,
          1523,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 255.36,
        "id": 108,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 252.8,
        "temperature": 0,
        "text": " I call it snowman.",
        "tokens": [
          51470,
          286,
          818,
          309,
          5756,
          1601,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 256.42,
        "id": 109,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 255.36,
        "temperature": 0,
        "text": " But let's see.",
        "tokens": [
          51598,
          583,
          718,
          311,
          536,
          13,
          51651
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 258.52,
        "id": 110,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 256.42,
        "temperature": 0,
        "text": " If I draw some stuff, I could classify it",
        "tokens": [
          51651,
          759,
          286,
          2642,
          512,
          1507,
          11,
          286,
          727,
          33872,
          309,
          51756
        ]
      },
      {
        "avg_logprob": -0.23398869333703534,
        "compression_ratio": 1.6655290102389078,
        "end": 260.28000000000003,
        "id": 111,
        "no_speech_prob": 0.0001334191911155358,
        "seek": 23068,
        "start": 258.52,
        "temperature": 0,
        "text": " and hopefully start to get things that make",
        "tokens": [
          51756,
          293,
          4696,
          722,
          281,
          483,
          721,
          300,
          652,
          51844
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 261.28,
        "id": 112,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 260.28,
        "temperature": 0,
        "text": " a little bit more sense.",
        "tokens": [
          50364,
          257,
          707,
          857,
          544,
          2020,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 263.23999999999995,
        "id": 113,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 261.28,
        "temperature": 0,
        "text": " So what I want to do is just display.",
        "tokens": [
          50414,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          445,
          4674,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 267,
        "id": 114,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 263.23999999999995,
        "temperature": 0,
        "text": " I think I'm just going to display the highest confidence.",
        "tokens": [
          50512,
          286,
          519,
          286,
          478,
          445,
          516,
          281,
          4674,
          264,
          6343,
          6687,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 268.53999999999996,
        "id": 115,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 267,
        "temperature": 0,
        "text": " Well, let's look at a couple of them.",
        "tokens": [
          50700,
          1042,
          11,
          718,
          311,
          574,
          412,
          257,
          1916,
          295,
          552,
          13,
          50777
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 273.11999999999995,
        "id": 116,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 268.53999999999996,
        "temperature": 0,
        "text": " Let's always look at the first two confidence scores.",
        "tokens": [
          50777,
          961,
          311,
          1009,
          574,
          412,
          264,
          700,
          732,
          6687,
          13444,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 276.88,
        "id": 117,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 273.11999999999995,
        "temperature": 0,
        "text": " So I'm going to make a variable for a div where I can not draw,",
        "tokens": [
          51006,
          407,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          337,
          257,
          3414,
          689,
          286,
          393,
          406,
          2642,
          11,
          51194
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 279.15999999999997,
        "id": 118,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 276.88,
        "temperature": 0,
        "text": " but I can pass the information from the results",
        "tokens": [
          51194,
          457,
          286,
          393,
          1320,
          264,
          1589,
          490,
          264,
          3542,
          51308
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 281.55999999999995,
        "id": 119,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 279.15999999999997,
        "temperature": 0,
        "text": " into an HTML element, a DOM element.",
        "tokens": [
          51308,
          666,
          364,
          17995,
          4478,
          11,
          257,
          35727,
          4478,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2412539843855233,
        "compression_ratio": 1.6290322580645162,
        "end": 288.32,
        "id": 120,
        "no_speech_prob": 0.00013135162589605898,
        "seek": 26028,
        "start": 284.35999999999996,
        "temperature": 0,
        "text": " Then when I get the results, now if I just",
        "tokens": [
          51568,
          1396,
          562,
          286,
          483,
          264,
          3542,
          11,
          586,
          498,
          286,
          445,
          51766
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 289.96,
        "id": 121,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 288.32,
        "temperature": 0,
        "text": " wanted to show the label, I could just",
        "tokens": [
          50364,
          1415,
          281,
          855,
          264,
          7645,
          11,
          286,
          727,
          445,
          50446
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 290.92,
        "id": 122,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 289.96,
        "temperature": 0,
        "text": " pass the label in there.",
        "tokens": [
          50446,
          1320,
          264,
          7645,
          294,
          456,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 293.68,
        "id": 123,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 290.92,
        "temperature": 0,
        "text": " But let me form something that has a bit more information",
        "tokens": [
          50494,
          583,
          718,
          385,
          1254,
          746,
          300,
          575,
          257,
          857,
          544,
          1589,
          50632
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 294.92,
        "id": 124,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 293.68,
        "temperature": 0,
        "text": " in it.",
        "tokens": [
          50632,
          294,
          309,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 296.76,
        "id": 125,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 294.92,
        "temperature": 0,
        "text": " I'm going to use the backtick for a template",
        "tokens": [
          50694,
          286,
          478,
          516,
          281,
          764,
          264,
          646,
          83,
          618,
          337,
          257,
          12379,
          50786
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 299.36,
        "id": 126,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 296.76,
        "temperature": 0,
        "text": " literal, which allows me to combine text and sort",
        "tokens": [
          50786,
          20411,
          11,
          597,
          4045,
          385,
          281,
          10432,
          2487,
          293,
          1333,
          50916
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 301.48,
        "id": 127,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 299.36,
        "temperature": 0,
        "text": " of the values of variables in one.",
        "tokens": [
          50916,
          295,
          264,
          4190,
          295,
          9102,
          294,
          472,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 309.88,
        "id": 128,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 301.48,
        "temperature": 0,
        "text": " And I will say results label followed by results confidence.",
        "tokens": [
          51022,
          400,
          286,
          486,
          584,
          3542,
          7645,
          6263,
          538,
          3542,
          6687,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 312,
        "id": 129,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 309.88,
        "temperature": 0,
        "text": " This actually lets me do it on multiple lines, which",
        "tokens": [
          51442,
          639,
          767,
          6653,
          385,
          360,
          309,
          322,
          3866,
          3876,
          11,
          597,
          51548
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 313.68,
        "id": 130,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 312,
        "temperature": 0,
        "text": " will be convenient here.",
        "tokens": [
          51548,
          486,
          312,
          10851,
          510,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.2414668374810337,
        "compression_ratio": 1.6286764705882353,
        "end": 316.96,
        "id": 131,
        "no_speech_prob": 0.0010162419639527798,
        "seek": 28832,
        "start": 313.68,
        "temperature": 0,
        "text": " And then I also want to multiply this by 100,",
        "tokens": [
          51632,
          400,
          550,
          286,
          611,
          528,
          281,
          12972,
          341,
          538,
          2319,
          11,
          51796
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 322.32,
        "id": 132,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 317,
        "temperature": 0,
        "text": " number format it to only have two digits,",
        "tokens": [
          50366,
          1230,
          7877,
          309,
          281,
          787,
          362,
          732,
          27011,
          11,
          50632
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 326.08,
        "id": 133,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 322.32,
        "temperature": 0,
        "text": " and then put a percent sign.",
        "tokens": [
          50632,
          293,
          550,
          829,
          257,
          3043,
          1465,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 329.2,
        "id": 134,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 326.08,
        "temperature": 0,
        "text": " So it's kind of like the percentage confidence.",
        "tokens": [
          50820,
          407,
          309,
          311,
          733,
          295,
          411,
          264,
          9668,
          6687,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 334.12,
        "id": 135,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 329.2,
        "temperature": 0,
        "text": " And then let's do the same for the next one.",
        "tokens": [
          50976,
          400,
          550,
          718,
          311,
          360,
          264,
          912,
          337,
          264,
          958,
          472,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 336.4,
        "id": 136,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 334.12,
        "temperature": 0,
        "text": " Put the final backtick in here.",
        "tokens": [
          51222,
          4935,
          264,
          2572,
          646,
          83,
          618,
          294,
          510,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 339.76,
        "id": 137,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 336.4,
        "temperature": 0,
        "text": " And then I probably should add a line break.",
        "tokens": [
          51336,
          400,
          550,
          286,
          1391,
          820,
          909,
          257,
          1622,
          1821,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 341.06,
        "id": 138,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 339.76,
        "temperature": 0,
        "text": " Is that how you do a line break?",
        "tokens": [
          51504,
          1119,
          300,
          577,
          291,
          360,
          257,
          1622,
          1821,
          30,
          51569
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 343.71999999999997,
        "id": 139,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 341.06,
        "temperature": 0,
        "text": " I sort of know how HTML works so that I see",
        "tokens": [
          51569,
          286,
          1333,
          295,
          458,
          577,
          17995,
          1985,
          370,
          300,
          286,
          536,
          51702
        ]
      },
      {
        "avg_logprob": -0.23863040590749204,
        "compression_ratio": 1.5585585585585586,
        "end": 344.96,
        "id": 140,
        "no_speech_prob": 0.000078437733463943,
        "seek": 31696,
        "start": 343.71999999999997,
        "temperature": 0,
        "text": " these on two separate lines.",
        "tokens": [
          51702,
          613,
          322,
          732,
          4994,
          3876,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 346.91999999999996,
        "id": 141,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 344.96,
        "temperature": 0,
        "text": " Let's just see what happens here.",
        "tokens": [
          50364,
          961,
          311,
          445,
          536,
          437,
          2314,
          510,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 348.84,
        "id": 142,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 346.91999999999996,
        "temperature": 0,
        "text": " Model loading, line.",
        "tokens": [
          50462,
          17105,
          15114,
          11,
          1622,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 351.08,
        "id": 143,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 348.84,
        "temperature": 0,
        "text": " Why do I only see line?",
        "tokens": [
          50558,
          1545,
          360,
          286,
          787,
          536,
          1622,
          30,
          50670
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 353.4,
        "id": 144,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 351.08,
        "temperature": 0,
        "text": " Oh!",
        "tokens": [
          50670,
          876,
          0,
          50786
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 355.88,
        "id": 145,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 353.4,
        "temperature": 0,
        "text": " I spent all this time making this content variable,",
        "tokens": [
          50786,
          286,
          4418,
          439,
          341,
          565,
          1455,
          341,
          2701,
          7006,
          11,
          50910
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 357.96,
        "id": 146,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 355.88,
        "temperature": 0,
        "text": " but I forgot to actually put it down there.",
        "tokens": [
          50910,
          457,
          286,
          5298,
          281,
          767,
          829,
          309,
          760,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 359.12,
        "id": 147,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 357.96,
        "temperature": 0,
        "text": " Apologies.",
        "tokens": [
          51014,
          8723,
          6204,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 360.84,
        "id": 148,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 359.12,
        "temperature": 0,
        "text": " So content should go here.",
        "tokens": [
          51072,
          407,
          2701,
          820,
          352,
          510,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 362.96,
        "id": 149,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 360.84,
        "temperature": 0,
        "text": " And I'm a person who likes to use semicolons.",
        "tokens": [
          51158,
          400,
          286,
          478,
          257,
          954,
          567,
          5902,
          281,
          764,
          27515,
          401,
          892,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 365.24,
        "id": 150,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 362.96,
        "temperature": 0,
        "text": " I'm sorry, but I just have to use the semicolons.",
        "tokens": [
          51264,
          286,
          478,
          2597,
          11,
          457,
          286,
          445,
          362,
          281,
          764,
          264,
          27515,
          401,
          892,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 366.71999999999997,
        "id": 151,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 365.24,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51378,
          1692,
          321,
          352,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 368.35999999999996,
        "id": 152,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 366.71999999999997,
        "temperature": 0,
        "text": " Model loading.",
        "tokens": [
          51452,
          17105,
          15114,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 369.4,
        "id": 153,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 368.35999999999996,
        "temperature": 0,
        "text": " Let's see what we got.",
        "tokens": [
          51534,
          961,
          311,
          536,
          437,
          321,
          658,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 370.32,
        "id": 154,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 369.4,
        "temperature": 0,
        "text": " Line 30.",
        "tokens": [
          51586,
          14670,
          2217,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 370.88,
        "id": 155,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 370.32,
        "temperature": 0,
        "text": " Oh, whoops.",
        "tokens": [
          51632,
          876,
          11,
          567,
          3370,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.2258544785635812,
        "compression_ratio": 1.624,
        "end": 372.12,
        "id": 156,
        "no_speech_prob": 0.0002378216595388949,
        "seek": 34496,
        "start": 370.88,
        "temperature": 0,
        "text": " I lost the line break.",
        "tokens": [
          51660,
          286,
          2731,
          264,
          1622,
          1821,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 376.47999999999996,
        "id": 157,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 375.64,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50398,
          821,
          321,
          352,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 380.23999999999995,
        "id": 158,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 376.47999999999996,
        "temperature": 0,
        "text": " Line 34 point percent.",
        "tokens": [
          50440,
          14670,
          12790,
          935,
          3043,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 382.64,
        "id": 159,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 380.23999999999995,
        "temperature": 0,
        "text": " No, I don't want that point percent.",
        "tokens": [
          50628,
          883,
          11,
          286,
          500,
          380,
          528,
          300,
          935,
          3043,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 384.08,
        "id": 160,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 382.64,
        "temperature": 0,
        "text": " Why is that showing up?",
        "tokens": [
          50748,
          1545,
          307,
          300,
          4099,
          493,
          30,
          50820
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 386.44,
        "id": 161,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 384.08,
        "temperature": 0,
        "text": " All right, let me give it one percentage point.",
        "tokens": [
          50820,
          1057,
          558,
          11,
          718,
          385,
          976,
          309,
          472,
          9668,
          935,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 389.4,
        "id": 162,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 386.44,
        "temperature": 0,
        "text": " And then, of course, by the way, once I",
        "tokens": [
          50938,
          400,
          550,
          11,
          295,
          1164,
          11,
          538,
          264,
          636,
          11,
          1564,
          286,
          51086
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 392.67999999999995,
        "id": 163,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 389.4,
        "temperature": 0,
        "text": " have gotten the results, just to get to the next step here,",
        "tokens": [
          51086,
          362,
          5768,
          264,
          3542,
          11,
          445,
          281,
          483,
          281,
          264,
          958,
          1823,
          510,
          11,
          51250
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 397.91999999999996,
        "id": 164,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 392.67999999999995,
        "temperature": 0,
        "text": " I also will then want to classify it again.",
        "tokens": [
          51250,
          286,
          611,
          486,
          550,
          528,
          281,
          33872,
          309,
          797,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.224283690679641,
        "compression_ratio": 1.5466666666666666,
        "end": 402.76,
        "id": 165,
        "no_speech_prob": 0.00002546639007050544,
        "seek": 37496,
        "start": 397.91999999999996,
        "temperature": 0,
        "text": " So this is a way that I can continuously loop over and over",
        "tokens": [
          51512,
          407,
          341,
          307,
          257,
          636,
          300,
          286,
          393,
          15684,
          6367,
          670,
          293,
          670,
          51754
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 404.71999999999997,
        "id": 166,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 403.03999999999996,
        "temperature": 0,
        "text": " again with the neural network model,",
        "tokens": [
          50378,
          797,
          365,
          264,
          18161,
          3209,
          2316,
          11,
          50462
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 406.59999999999997,
        "id": 167,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 404.71999999999997,
        "temperature": 0,
        "text": " classifying, classifying, classifying.",
        "tokens": [
          50462,
          1508,
          5489,
          11,
          1508,
          5489,
          11,
          1508,
          5489,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 407.59999999999997,
        "id": 168,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 406.59999999999997,
        "temperature": 0,
        "text": " Classify the canvas.",
        "tokens": [
          50556,
          9471,
          2505,
          264,
          16267,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 408.44,
        "id": 169,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 407.59999999999997,
        "temperature": 0,
        "text": " Show the results.",
        "tokens": [
          50606,
          6895,
          264,
          3542,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 409.2,
        "id": 170,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 408.44,
        "temperature": 0,
        "text": " Classify it again.",
        "tokens": [
          50648,
          9471,
          2505,
          309,
          797,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 409.96,
        "id": 171,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 409.2,
        "temperature": 0,
        "text": " Show the new results.",
        "tokens": [
          50686,
          6895,
          264,
          777,
          3542,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 410.71999999999997,
        "id": 172,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 409.96,
        "temperature": 0,
        "text": " Classify again.",
        "tokens": [
          50724,
          9471,
          2505,
          797,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 411.56,
        "id": 173,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 410.71999999999997,
        "temperature": 0,
        "text": " Show the new results.",
        "tokens": [
          50762,
          6895,
          264,
          777,
          3542,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 415.52,
        "id": 174,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 411.56,
        "temperature": 0,
        "text": " And I think now, here we go.",
        "tokens": [
          50804,
          400,
          286,
          519,
          586,
          11,
          510,
          321,
          352,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 416.56,
        "id": 175,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 415.52,
        "temperature": 0,
        "text": " Let's draw my cat.",
        "tokens": [
          51002,
          961,
          311,
          2642,
          452,
          3857,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 422.2,
        "id": 176,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 420.36,
        "temperature": 0,
        "text": " Let me try this again.",
        "tokens": [
          51244,
          961,
          385,
          853,
          341,
          797,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 423.68,
        "id": 177,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 422.2,
        "temperature": 0,
        "text": " Is there a cat even in there?",
        "tokens": [
          51336,
          1119,
          456,
          257,
          3857,
          754,
          294,
          456,
          30,
          51410
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 428.84,
        "id": 178,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 427,
        "temperature": 0,
        "text": " So I have a suspicion here.",
        "tokens": [
          51576,
          407,
          286,
          362,
          257,
          32020,
          510,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2280430916028145,
        "compression_ratio": 1.8453608247422681,
        "end": 430.8,
        "id": 179,
        "no_speech_prob": 0.0002305066300323233,
        "seek": 40276,
        "start": 428.84,
        "temperature": 0,
        "text": " And this is always really critical,",
        "tokens": [
          51668,
          400,
          341,
          307,
          1009,
          534,
          4924,
          11,
          51766
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 433.92,
        "id": 180,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 430.84000000000003,
        "temperature": 0,
        "text": " is the data set that was used to train this model",
        "tokens": [
          50366,
          307,
          264,
          1412,
          992,
          300,
          390,
          1143,
          281,
          3847,
          341,
          2316,
          50520
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 437.56,
        "id": 181,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 433.92,
        "temperature": 0,
        "text": " is incredibly consistent in that the line",
        "tokens": [
          50520,
          307,
          6252,
          8398,
          294,
          300,
          264,
          1622,
          50702
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 441.28000000000003,
        "id": 182,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 437.56,
        "temperature": 0,
        "text": " thickness of all the drawings is very uniform.",
        "tokens": [
          50702,
          14855,
          295,
          439,
          264,
          18618,
          307,
          588,
          9452,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 443.84000000000003,
        "id": 183,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 441.28000000000003,
        "temperature": 0,
        "text": " So I think maybe I haven't really gotten that right.",
        "tokens": [
          50888,
          407,
          286,
          519,
          1310,
          286,
          2378,
          380,
          534,
          5768,
          300,
          558,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 450.16,
        "id": 184,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 443.84000000000003,
        "temperature": 0,
        "text": " I arbitrarily decided, let me use a stroke weight of 8.",
        "tokens": [
          51016,
          286,
          19071,
          3289,
          3047,
          11,
          718,
          385,
          764,
          257,
          12403,
          3364,
          295,
          1649,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 453.24,
        "id": 185,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 450.16,
        "temperature": 0,
        "text": " My suspicion is if I make that a little bit thicker,",
        "tokens": [
          51332,
          1222,
          32020,
          307,
          498,
          286,
          652,
          300,
          257,
          707,
          857,
          18142,
          11,
          51486
        ]
      },
      {
        "avg_logprob": -0.21369556627775493,
        "compression_ratio": 1.5859030837004404,
        "end": 456.08000000000004,
        "id": 186,
        "no_speech_prob": 0.00003647845733212307,
        "seek": 43080,
        "start": 453.24,
        "temperature": 0,
        "text": " I might get results that are more like what I'm hoping for.",
        "tokens": [
          51486,
          286,
          1062,
          483,
          3542,
          300,
          366,
          544,
          411,
          437,
          286,
          478,
          7159,
          337,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 458.28,
        "id": 187,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 457.08,
        "temperature": 0,
        "text": " Look, it's a cat.",
        "tokens": [
          50414,
          2053,
          11,
          309,
          311,
          257,
          3857,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 459.15999999999997,
        "id": 188,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 458.28,
        "temperature": 0,
        "text": " It's a cat.",
        "tokens": [
          50474,
          467,
          311,
          257,
          3857,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 462.35999999999996,
        "id": 189,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 459.15999999999997,
        "temperature": 0,
        "text": " And that's raccoon-like cat.",
        "tokens": [
          50518,
          400,
          300,
          311,
          4129,
          48092,
          12,
          4092,
          3857,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 464.76,
        "id": 190,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 462.35999999999996,
        "temperature": 0,
        "text": " Oh, we're super confident now.",
        "tokens": [
          50678,
          876,
          11,
          321,
          434,
          1687,
          6679,
          586,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 465.8,
        "id": 191,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 464.76,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50798,
          2053,
          412,
          341,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 467.03999999999996,
        "id": 192,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 465.8,
        "temperature": 0,
        "text": " Oh, all right.",
        "tokens": [
          50850,
          876,
          11,
          439,
          558,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 469.52,
        "id": 193,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 467.03999999999996,
        "temperature": 0,
        "text": " So we can see this works quite well",
        "tokens": [
          50912,
          407,
          321,
          393,
          536,
          341,
          1985,
          1596,
          731,
          51036
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 473,
        "id": 194,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 469.52,
        "temperature": 0,
        "text": " if you happen to draw like the Google Quick Draw data set.",
        "tokens": [
          51036,
          498,
          291,
          1051,
          281,
          2642,
          411,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 474.4,
        "id": 195,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 473,
        "temperature": 0,
        "text": " I think it's an important question",
        "tokens": [
          51210,
          286,
          519,
          309,
          311,
          364,
          1021,
          1168,
          51280
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 476.68,
        "id": 196,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 474.4,
        "temperature": 0,
        "text": " to ask if you are classifying drawings",
        "tokens": [
          51280,
          281,
          1029,
          498,
          291,
          366,
          1508,
          5489,
          18618,
          51394
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 480.03999999999996,
        "id": 197,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 476.68,
        "temperature": 0,
        "text": " and there is an audience that is experiencing your web",
        "tokens": [
          51394,
          293,
          456,
          307,
          364,
          4034,
          300,
          307,
          11139,
          428,
          3670,
          51562
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 481.79999999999995,
        "id": 198,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 480.03999999999996,
        "temperature": 0,
        "text": " application or your project.",
        "tokens": [
          51562,
          3861,
          420,
          428,
          1716,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.39790291940012285,
        "compression_ratio": 1.6945606694560669,
        "end": 483.52,
        "id": 199,
        "no_speech_prob": 0.00019716864335350692,
        "seek": 45608,
        "start": 481.79999999999995,
        "temperature": 0,
        "text": " Is the Google Quick Draw data set",
        "tokens": [
          51650,
          1119,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          51736
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 486.08,
        "id": 200,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 483.96,
        "temperature": 0,
        "text": " is the Google Quick Draw data set",
        "tokens": [
          50386,
          307,
          264,
          3329,
          12101,
          20386,
          1412,
          992,
          50492
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 487.79999999999995,
        "id": 201,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 486.08,
        "temperature": 0,
        "text": " representative of that audience?",
        "tokens": [
          50492,
          12424,
          295,
          300,
          4034,
          30,
          50578
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 489.59999999999997,
        "id": 202,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 487.79999999999995,
        "temperature": 0,
        "text": " Are they represented in that data set?",
        "tokens": [
          50578,
          2014,
          436,
          10379,
          294,
          300,
          1412,
          992,
          30,
          50668
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 493,
        "id": 203,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 489.59999999999997,
        "temperature": 0,
        "text": " That's something that I talk a lot about over many videos,",
        "tokens": [
          50668,
          663,
          311,
          746,
          300,
          286,
          751,
          257,
          688,
          466,
          670,
          867,
          2145,
          11,
          50838
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 496.08,
        "id": 204,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 493,
        "temperature": 0,
        "text": " about thinking about the ethics and politics of data",
        "tokens": [
          50838,
          466,
          1953,
          466,
          264,
          19769,
          293,
          7341,
          295,
          1412,
          50992
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 497.32,
        "id": 205,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 496.08,
        "temperature": 0,
        "text": " collection.",
        "tokens": [
          50992,
          5765,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 499.59999999999997,
        "id": 206,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 497.32,
        "temperature": 0,
        "text": " And now for the next step.",
        "tokens": [
          51054,
          400,
          586,
          337,
          264,
          958,
          1823,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 503.03999999999996,
        "id": 207,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 499.59999999999997,
        "temperature": 0,
        "text": " Rather than draw onto a canvas, if I",
        "tokens": [
          51168,
          16571,
          813,
          2642,
          3911,
          257,
          16267,
          11,
          498,
          286,
          51340
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 507.03999999999996,
        "id": 208,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 503.03999999999996,
        "temperature": 0,
        "text": " use a notepad here with a document camera pointed at it,",
        "tokens": [
          51340,
          764,
          257,
          406,
          595,
          345,
          510,
          365,
          257,
          4166,
          2799,
          10932,
          412,
          309,
          11,
          51540
        ]
      },
      {
        "avg_logprob": -0.23205669795241313,
        "compression_ratio": 1.611336032388664,
        "end": 511.4,
        "id": 209,
        "no_speech_prob": 0.005911014508455992,
        "seek": 48352,
        "start": 507.03999999999996,
        "temperature": 0,
        "text": " can I get it to recognize my drawings on paper?",
        "tokens": [
          51540,
          393,
          286,
          483,
          309,
          281,
          5521,
          452,
          18618,
          322,
          3035,
          30,
          51758
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 513.36,
        "id": 210,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 511.4,
        "temperature": 0,
        "text": " I am going to duplicate this sketch,",
        "tokens": [
          50364,
          286,
          669,
          516,
          281,
          23976,
          341,
          12325,
          11,
          50462
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 515.4,
        "id": 211,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 513.36,
        "temperature": 0,
        "text": " call it doodle net video.",
        "tokens": [
          50462,
          818,
          309,
          360,
          30013,
          2533,
          960,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 517.1999999999999,
        "id": 212,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 515.4,
        "temperature": 0,
        "text": " I'm going to add a variable called video.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          909,
          257,
          7006,
          1219,
          960,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 521.72,
        "id": 213,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 520.24,
        "temperature": 0,
        "text": " I'm still going to use the canvas,",
        "tokens": [
          50806,
          286,
          478,
          920,
          516,
          281,
          764,
          264,
          16267,
          11,
          50880
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 523.68,
        "id": 214,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 521.72,
        "temperature": 0,
        "text": " and I'll show you why in a second.",
        "tokens": [
          50880,
          293,
          286,
          603,
          855,
          291,
          983,
          294,
          257,
          1150,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 525.72,
        "id": 215,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 523.68,
        "temperature": 0,
        "text": " I could pass the video directly, but I'm",
        "tokens": [
          50978,
          286,
          727,
          1320,
          264,
          960,
          3838,
          11,
          457,
          286,
          478,
          51080
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 530.72,
        "id": 216,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 525.72,
        "temperature": 0,
        "text": " going to draw the video on the canvas and resize it.",
        "tokens": [
          51080,
          516,
          281,
          2642,
          264,
          960,
          322,
          264,
          16267,
          293,
          50069,
          309,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 534.48,
        "id": 217,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 530.72,
        "temperature": 0,
        "text": " And this should be exactly the same now.",
        "tokens": [
          51330,
          400,
          341,
          820,
          312,
          2293,
          264,
          912,
          586,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 538,
        "id": 218,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 534.48,
        "temperature": 0,
        "text": " As you can see, it is now seeing my notepad over here.",
        "tokens": [
          51518,
          1018,
          291,
          393,
          536,
          11,
          309,
          307,
          586,
          2577,
          452,
          406,
          595,
          345,
          670,
          510,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.19211541748046876,
        "compression_ratio": 1.8201754385964912,
        "end": 540.6,
        "id": 219,
        "no_speech_prob": 0.000026688509024097584,
        "seek": 51140,
        "start": 538,
        "temperature": 0,
        "text": " I'm going to start by trying to draw a strawberry.",
        "tokens": [
          51694,
          286,
          478,
          516,
          281,
          722,
          538,
          1382,
          281,
          2642,
          257,
          20440,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 541.76,
        "id": 220,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 540.6,
        "temperature": 0,
        "text": " A strawberry.",
        "tokens": [
          50364,
          316,
          20440,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 546.28,
        "id": 221,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 541.76,
        "temperature": 0,
        "text": " That's sort of more like a heart.",
        "tokens": [
          50422,
          663,
          311,
          1333,
          295,
          544,
          411,
          257,
          1917,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 551.36,
        "id": 222,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 549.28,
        "temperature": 0,
        "text": " It's a beach again, or it's raining.",
        "tokens": [
          50798,
          467,
          311,
          257,
          7534,
          797,
          11,
          420,
          309,
          311,
          18441,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 552.9200000000001,
        "id": 223,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 551.36,
        "temperature": 0,
        "text": " So why is this not working?",
        "tokens": [
          50902,
          407,
          983,
          307,
          341,
          406,
          1364,
          30,
          50980
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 555.76,
        "id": 224,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 552.9200000000001,
        "temperature": 0,
        "text": " I'm not entirely sure, but let's see",
        "tokens": [
          50980,
          286,
          478,
          406,
          7696,
          988,
          11,
          457,
          718,
          311,
          536,
          51122
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 559.96,
        "id": 225,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 555.76,
        "temperature": 0,
        "text": " if I can, even with this exact same image, kind of adjust it.",
        "tokens": [
          51122,
          498,
          286,
          393,
          11,
          754,
          365,
          341,
          1900,
          912,
          3256,
          11,
          733,
          295,
          4369,
          309,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 563.16,
        "id": 226,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 559.96,
        "temperature": 0,
        "text": " So one thing that I might think about doing",
        "tokens": [
          51332,
          407,
          472,
          551,
          300,
          286,
          1062,
          519,
          466,
          884,
          51492
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 566.28,
        "id": 227,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 563.16,
        "temperature": 0,
        "text": " is applying some image processing to it.",
        "tokens": [
          51492,
          307,
          9275,
          512,
          3256,
          9007,
          281,
          309,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.26568300478926327,
        "compression_ratio": 1.5919282511210762,
        "end": 570.24,
        "id": 228,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 54060,
        "start": 566.28,
        "temperature": 0,
        "text": " So one thing that I could do very quickly is add a filter,",
        "tokens": [
          51648,
          407,
          472,
          551,
          300,
          286,
          727,
          360,
          588,
          2661,
          307,
          909,
          257,
          6608,
          11,
          51846
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 573.96,
        "id": 229,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 570.24,
        "temperature": 0,
        "text": " threshold filter with a threshold of 0.5.",
        "tokens": [
          50364,
          14678,
          6608,
          365,
          257,
          14678,
          295,
          1958,
          13,
          20,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 575.28,
        "id": 230,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 573.96,
        "temperature": 0,
        "text": " Let's try that.",
        "tokens": [
          50550,
          961,
          311,
          853,
          300,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 577.92,
        "id": 231,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 575.28,
        "temperature": 0,
        "text": " A threshold filter takes any image",
        "tokens": [
          50616,
          316,
          14678,
          6608,
          2516,
          604,
          3256,
          50748
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 580.92,
        "id": 232,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 577.92,
        "temperature": 0,
        "text": " and converts every pixel to either black or white",
        "tokens": [
          50748,
          293,
          38874,
          633,
          19261,
          281,
          2139,
          2211,
          420,
          2418,
          50898
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 584.48,
        "id": 233,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 580.92,
        "temperature": 0,
        "text": " based on some threshold value, in this case, 50%.",
        "tokens": [
          50898,
          2361,
          322,
          512,
          14678,
          2158,
          11,
          294,
          341,
          1389,
          11,
          2625,
          6856,
          51076
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 585.96,
        "id": 234,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 584.48,
        "temperature": 0,
        "text": " Let me try a thicker pen.",
        "tokens": [
          51076,
          961,
          385,
          853,
          257,
          18142,
          3435,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 586.96,
        "id": 235,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 585.96,
        "temperature": 0,
        "text": " Ha ha.",
        "tokens": [
          51150,
          4064,
          324,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 596.2,
        "id": 236,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 586.96,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51200,
          821,
          321,
          352,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 599.04,
        "id": 237,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 596.2,
        "temperature": 0,
        "text": " It's a strawberry.",
        "tokens": [
          51662,
          467,
          311,
          257,
          20440,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.31888444396271104,
        "compression_ratio": 1.4861878453038675,
        "end": 599.8,
        "id": 238,
        "no_speech_prob": 0.000017502909031463787,
        "seek": 57024,
        "start": 599.04,
        "temperature": 0,
        "text": " Let's draw.",
        "tokens": [
          51804,
          961,
          311,
          2642,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 601.7199999999999,
        "id": 239,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 599.8399999999999,
        "temperature": 0,
        "text": " I'm going to see if I can draw that cat now.",
        "tokens": [
          50366,
          286,
          478,
          516,
          281,
          536,
          498,
          286,
          393,
          2642,
          300,
          3857,
          586,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 612.5999999999999,
        "id": 240,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 601.7199999999999,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50460,
          286,
          500,
          380,
          458,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 615.56,
        "id": 241,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 612.5999999999999,
        "temperature": 0,
        "text": " It's either a cactus or a cat or maybe a hedgehog.",
        "tokens": [
          51004,
          467,
          311,
          2139,
          257,
          44287,
          420,
          257,
          3857,
          420,
          1310,
          257,
          25304,
          27084,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 617.4,
        "id": 242,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 615.56,
        "temperature": 0,
        "text": " But you can see that this is working.",
        "tokens": [
          51152,
          583,
          291,
          393,
          536,
          300,
          341,
          307,
          1364,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 621.16,
        "id": 243,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 617.4,
        "temperature": 0,
        "text": " We now have the ability to take input from a camera.",
        "tokens": [
          51244,
          492,
          586,
          362,
          264,
          3485,
          281,
          747,
          4846,
          490,
          257,
          2799,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 624.7199999999999,
        "id": 244,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 621.16,
        "temperature": 0,
        "text": " I don't know to what extent this filtering is altering it.",
        "tokens": [
          51432,
          286,
          500,
          380,
          458,
          281,
          437,
          8396,
          341,
          30822,
          307,
          11337,
          278,
          309,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.22820574827868528,
        "compression_ratio": 1.5404040404040404,
        "end": 628.4399999999999,
        "id": 245,
        "no_speech_prob": 0.0000235526076721726,
        "seek": 59980,
        "start": 624.7199999999999,
        "temperature": 0,
        "text": " Like, look, right now it says it's 52.4% cat.",
        "tokens": [
          51610,
          1743,
          11,
          574,
          11,
          558,
          586,
          309,
          1619,
          309,
          311,
          18079,
          13,
          19,
          4,
          3857,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 633.32,
        "id": 246,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 628.48,
        "temperature": 0,
        "text": " Let's actually try making the filter only apply",
        "tokens": [
          50366,
          961,
          311,
          767,
          853,
          1455,
          264,
          6608,
          787,
          3079,
          50608
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 634.8000000000001,
        "id": 247,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 633.32,
        "temperature": 0,
        "text": " if I press the mouse.",
        "tokens": [
          50608,
          498,
          286,
          1886,
          264,
          9719,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 637.6400000000001,
        "id": 248,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 634.8000000000001,
        "temperature": 0,
        "text": " And we'll see how that affects things.",
        "tokens": [
          50682,
          400,
          321,
          603,
          536,
          577,
          300,
          11807,
          721,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 640.24,
        "id": 249,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 637.6400000000001,
        "temperature": 0,
        "text": " This is what it looks like without the filter,",
        "tokens": [
          50824,
          639,
          307,
          437,
          309,
          1542,
          411,
          1553,
          264,
          6608,
          11,
          50954
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 641.1600000000001,
        "id": 250,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 640.24,
        "temperature": 0,
        "text": " with the filter.",
        "tokens": [
          50954,
          365,
          264,
          6608,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 643.6800000000001,
        "id": 251,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 641.1600000000001,
        "temperature": 0,
        "text": " You can see, first of all, it's much more stable.",
        "tokens": [
          51000,
          509,
          393,
          536,
          11,
          700,
          295,
          439,
          11,
          309,
          311,
          709,
          544,
          8351,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 646.6800000000001,
        "id": 252,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 643.6800000000001,
        "temperature": 0,
        "text": " With the threshold filter, I have a very consistent image.",
        "tokens": [
          51126,
          2022,
          264,
          14678,
          6608,
          11,
          286,
          362,
          257,
          588,
          8398,
          3256,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 649.8000000000001,
        "id": 253,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 646.6800000000001,
        "temperature": 0,
        "text": " But there's a lot of noise otherwise in the image.",
        "tokens": [
          51276,
          583,
          456,
          311,
          257,
          688,
          295,
          5658,
          5911,
          294,
          264,
          3256,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 650.9200000000001,
        "id": 254,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 649.8000000000001,
        "temperature": 0,
        "text": " I think it wants me.",
        "tokens": [
          51432,
          286,
          519,
          309,
          2738,
          385,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 652.2,
        "id": 255,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 650.9200000000001,
        "temperature": 0,
        "text": " It's like it's telling me.",
        "tokens": [
          51488,
          467,
          311,
          411,
          309,
          311,
          3585,
          385,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2067210548802426,
        "compression_ratio": 1.6477272727272727,
        "end": 656.36,
        "id": 256,
        "no_speech_prob": 0.0000031875633794697933,
        "seek": 62844,
        "start": 652.2,
        "temperature": 0,
        "text": " It's daring me to draw a snowman, to get that 1.8% up.",
        "tokens": [
          51552,
          467,
          311,
          43128,
          385,
          281,
          2642,
          257,
          5756,
          1601,
          11,
          281,
          483,
          300,
          502,
          13,
          23,
          4,
          493,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 656.86,
        "id": 257,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 656.36,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50364,
          961,
          311,
          536,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 663.8000000000001,
        "id": 258,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 662.8000000000001,
        "temperature": 0,
        "text": " This is a snowman.",
        "tokens": [
          50686,
          639,
          307,
          257,
          5756,
          1601,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 664.48,
        "id": 259,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 663.8000000000001,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          50736,
          2053,
          412,
          300,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 665.36,
        "id": 260,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 664.48,
        "temperature": 0,
        "text": " Look at that snowman.",
        "tokens": [
          50770,
          2053,
          412,
          300,
          5756,
          1601,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 665.88,
        "id": 261,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 665.36,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50814,
          821,
          321,
          352,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 667.04,
        "id": 262,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 665.88,
        "temperature": 0,
        "text": " Snowman.",
        "tokens": [
          50840,
          14827,
          1601,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 668.5600000000001,
        "id": 263,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 667.04,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50898,
          1057,
          558,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 671.36,
        "id": 264,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 668.5600000000001,
        "temperature": 0,
        "text": " Am I going to make it worse or better by adding some arms?",
        "tokens": [
          50974,
          2012,
          286,
          516,
          281,
          652,
          309,
          5324,
          420,
          1101,
          538,
          5127,
          512,
          5812,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 671.88,
        "id": 265,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 671.36,
        "temperature": 0,
        "text": " Snowman.",
        "tokens": [
          51114,
          14827,
          1601,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 672.64,
        "id": 266,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 671.88,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51140,
          821,
          321,
          352,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 673.28,
        "id": 267,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 672.64,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51178,
          2264,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 675.92,
        "id": 268,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 673.28,
        "temperature": 0,
        "text": " So I hope you enjoyed this particular video.",
        "tokens": [
          51210,
          407,
          286,
          1454,
          291,
          4626,
          341,
          1729,
          960,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 678.04,
        "id": 269,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 675.92,
        "temperature": 0,
        "text": " I would encourage you to experiment with this model.",
        "tokens": [
          51342,
          286,
          576,
          5373,
          291,
          281,
          5120,
          365,
          341,
          2316,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 680.12,
        "id": 270,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 678.04,
        "temperature": 0,
        "text": " I think there's a lot of creative possibilities",
        "tokens": [
          51448,
          286,
          519,
          456,
          311,
          257,
          688,
          295,
          5880,
          12178,
          51552
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 682.84,
        "id": 271,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 680.12,
        "temperature": 0,
        "text": " in terms of what this interaction might",
        "tokens": [
          51552,
          294,
          2115,
          295,
          437,
          341,
          9285,
          1062,
          51688
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 683.84,
        "id": 272,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 682.84,
        "temperature": 0,
        "text": " be applied to.",
        "tokens": [
          51688,
          312,
          6456,
          281,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.34705784741569967,
        "compression_ratio": 1.6317829457364341,
        "end": 685.4200000000001,
        "id": 273,
        "no_speech_prob": 0.0002098819095408544,
        "seek": 65636,
        "start": 683.84,
        "temperature": 0,
        "text": " Could you play a game where you have",
        "tokens": [
          51738,
          7497,
          291,
          862,
          257,
          1216,
          689,
          291,
          362,
          51817
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 687.9399999999999,
        "id": 274,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 685.4599999999999,
        "temperature": 0,
        "text": " to control a character by drawing?",
        "tokens": [
          50366,
          281,
          1969,
          257,
          2517,
          538,
          6316,
          30,
          50490
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 690.3,
        "id": 275,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 687.9399999999999,
        "temperature": 0,
        "text": " What happens when you pass images",
        "tokens": [
          50490,
          708,
          2314,
          562,
          291,
          1320,
          5267,
          50608
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 693.9,
        "id": 276,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 690.3,
        "temperature": 0,
        "text": " that come from fill in the blank to this model?",
        "tokens": [
          50608,
          300,
          808,
          490,
          2836,
          294,
          264,
          8247,
          281,
          341,
          2316,
          30,
          50788
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 695.3,
        "id": 277,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 693.9,
        "temperature": 0,
        "text": " I encourage you to play with that.",
        "tokens": [
          50788,
          286,
          5373,
          291,
          281,
          862,
          365,
          300,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 697.5,
        "id": 278,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 695.3,
        "temperature": 0,
        "text": " I encourage you to look at my shape classifier video",
        "tokens": [
          50858,
          286,
          5373,
          291,
          281,
          574,
          412,
          452,
          3909,
          1508,
          9902,
          960,
          50968
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 700.6999999999999,
        "id": 279,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 697.5,
        "temperature": 0,
        "text": " to train your own model that recognizes shapes and drawings",
        "tokens": [
          50968,
          281,
          3847,
          428,
          1065,
          2316,
          300,
          26564,
          10854,
          293,
          18618,
          51128
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 701.86,
        "id": 280,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 700.6999999999999,
        "temperature": 0,
        "text": " and that sort of thing.",
        "tokens": [
          51128,
          293,
          300,
          1333,
          295,
          551,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 703.0999999999999,
        "id": 281,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 701.86,
        "temperature": 0,
        "text": " Share it with me.",
        "tokens": [
          51186,
          14945,
          309,
          365,
          385,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 706.3,
        "id": 282,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 703.0999999999999,
        "temperature": 0,
        "text": " I would love to see what kinds of creative possible outcomes",
        "tokens": [
          51248,
          286,
          576,
          959,
          281,
          536,
          437,
          3685,
          295,
          5880,
          1944,
          10070,
          51408
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 707.62,
        "id": 283,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 706.3,
        "temperature": 0,
        "text": " come from this stuff.",
        "tokens": [
          51408,
          808,
          490,
          341,
          1507,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 708.12,
        "id": 284,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 707.62,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51474,
          2264,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 709.26,
        "id": 285,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 708.12,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51499,
          15528,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 711.3,
        "id": 286,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 709.26,
        "temperature": 0,
        "text": " Hopefully, there'll be more ml5 videos to come.",
        "tokens": [
          51556,
          10429,
          11,
          456,
          603,
          312,
          544,
          23271,
          20,
          2145,
          281,
          808,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.2549726132993345,
        "compression_ratio": 1.6723549488054608,
        "end": 712.9,
        "id": 287,
        "no_speech_prob": 0.004133894573897123,
        "seek": 68542,
        "start": 711.3,
        "temperature": 0,
        "text": " And I look forward to seeing you there.",
        "tokens": [
          51658,
          400,
          286,
          574,
          2128,
          281,
          2577,
          291,
          456,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 714.18,
        "id": 288,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 713.34,
        "temperature": 0.6000000000000001,
        "text": " Thank you.",
        "tokens": [
          50386,
          1044,
          291,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 715.5799999999999,
        "id": 289,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 714.18,
        "temperature": 0.6000000000000001,
        "text": " Bye bye.",
        "tokens": [
          50428,
          4621,
          6543,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 716.18,
        "id": 290,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 715.5799999999999,
        "temperature": 0.6000000000000001,
        "text": " Bye bye.",
        "tokens": [
          50498,
          4621,
          6543,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 717.18,
        "id": 291,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 716.18,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50528,
          4621,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 718.18,
        "id": 292,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 717.18,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50578,
          4621,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 719.18,
        "id": 293,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 718.18,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50628,
          4621,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 720.18,
        "id": 294,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 719.18,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50678,
          4621,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 721.18,
        "id": 295,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 720.18,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50728,
          4621,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 722.22,
        "id": 296,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 721.18,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50778,
          4621,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.9674256931651722,
        "compression_ratio": 2.1724137931034484,
        "end": 723.5799999999999,
        "id": 297,
        "no_speech_prob": 0.10189923644065857,
        "seek": 71290,
        "start": 722.22,
        "temperature": 0.6000000000000001,
        "text": " Bye.",
        "tokens": [
          50830,
          4621,
          13,
          50898
        ]
      }
    ],
    "transcription": " Hello, and welcome to another ML5.js video tutorial. In this video, I am going to attempt to classify my drawing as a cat. So how am I going to do this? And how come this video is so darn short? Well, I'm going to make use of a pre-trained model called DoodleNet that comes as part of the ML5 library. The DoodleNet model, which you can read more about on the documentation page, is a pre-trained model that classifies and labels hand-drawn sketches from 345 categories. Huh. I wonder, what might these 345 categories be? Well, if I scroll down and take a look at the DoodleNet data biography, you will find out that the data set comes from Google's Quick Draw, which was a game that was created in 2016. And Yining Shi, who created and trained this model, you can find out more about Yining by going to this link here, collected the data in 2019. This is what the Google Quick Draw data set is. It's 50 million drawings. I don't expect that Yining used all 50 million. We can see 50,000 per category. So do the math, 50,000 times 345. And you can find all of Yining's training source code here in this DoodleNet repo itself and more information about how the model is trained. But guess what? This video is actually really a follow-up to my coding challenge about training a machine learning model to recognize drawings of shapes, circles, squares, and triangles. So I did this whole process of collecting a data set, training a model, and then deploying that model all in the browser in a separate video. And in this one, I'm just going to quickly basically do the same thing, but use a more sophisticated, more robust pre-trained model created by Yining Shi. All right, here we go. So this is my starter code. What is it doing? You can see this is very simple. It's just creating a canvas. It's 400 by 400. I have a Clear button. So when I press that Clear button, it redraws the background, erasing the drawing. And then in the Draw function, whenever the mouse is pressed, it leaves a trail from my current mouse position to my previous mouse position. Or maybe I should say my previous mouse position to my current mouse position. It's the same thing. I also should note that I have imported the ml5 library. I'm currently using version 0.6.0. So if you want to match that version, if you're working trying to recreate this code, that's the version I'm using. Step one, create a variable to hold the image classifier. And I'll call it doodle classifier. Step two, call image classifier. Give myself some more space here for the code. And indicate to ml5 that I want to load the doodle net pre-trained model. And then I need a callback for when that model is ready. I need to make sure I have all the indentation correct. Once the model is ready, I just want to take the canvas itself and pass it to the model for a prediction. Once it's gotten that canvas, sent it through the neural network, it will get results back of a probability score, a confidence score, for every single one of those categories. And I can retrieve that in a callback, which I am naming got results. ml5 follows an error first callback pattern, which means if something went wrong, it will come back in the first argument as an error. If everything went well, I'll get the results in an object called results. Handle the case of an error by just getting out of here and logging the error. And then let me just log the results. Run this sketch. In truth, I'm not so sure what this warning is. This happened to me in my own example where if you ever have your image resolution not matching what the neural network is expecting, you could get an error. This is just a warning. So I'm not entirely sure what's going on there, but I'm going to ignore it for right now. And what I want to focus on is the results that came back in a giant array. Object, object, object, object, object, object, object, thing, me, object, song. The way that this array is ordered is whichever label has the highest confidence score, it's going to come back first. So this is just a blank white canvas. What does it think it is? It's a line. That kind of makes sense. The least amount of drawing would just be a line. The next one is a snowman. That also makes sense. Look, this is my art. I call it snowman. But let's see. If I draw some stuff, I could classify it and hopefully start to get things that make a little bit more sense. So what I want to do is just display. I think I'm just going to display the highest confidence. Well, let's look at a couple of them. Let's always look at the first two confidence scores. So I'm going to make a variable for a div where I can not draw, but I can pass the information from the results into an HTML element, a DOM element. Then when I get the results, now if I just wanted to show the label, I could just pass the label in there. But let me form something that has a bit more information in it. I'm going to use the backtick for a template literal, which allows me to combine text and sort of the values of variables in one. And I will say results label followed by results confidence. This actually lets me do it on multiple lines, which will be convenient here. And then I also want to multiply this by 100, number format it to only have two digits, and then put a percent sign. So it's kind of like the percentage confidence. And then let's do the same for the next one. Put the final backtick in here. And then I probably should add a line break. Is that how you do a line break? I sort of know how HTML works so that I see these on two separate lines. Let's just see what happens here. Model loading, line. Why do I only see line? Oh! I spent all this time making this content variable, but I forgot to actually put it down there. Apologies. So content should go here. And I'm a person who likes to use semicolons. I'm sorry, but I just have to use the semicolons. Here we go. Model loading. Let's see what we got. Line 30. Oh, whoops. I lost the line break. There we go. Line 34 point percent. No, I don't want that point percent. Why is that showing up? All right, let me give it one percentage point. And then, of course, by the way, once I have gotten the results, just to get to the next step here, I also will then want to classify it again. So this is a way that I can continuously loop over and over again with the neural network model, classifying, classifying, classifying. Classify the canvas. Show the results. Classify it again. Show the new results. Classify again. Show the new results. And I think now, here we go. Let's draw my cat. Let me try this again. Is there a cat even in there? So I have a suspicion here. And this is always really critical, is the data set that was used to train this model is incredibly consistent in that the line thickness of all the drawings is very uniform. So I think maybe I haven't really gotten that right. I arbitrarily decided, let me use a stroke weight of 8. My suspicion is if I make that a little bit thicker, I might get results that are more like what I'm hoping for. Look, it's a cat. It's a cat. And that's raccoon-like cat. Oh, we're super confident now. Look at this. Oh, all right. So we can see this works quite well if you happen to draw like the Google Quick Draw data set. I think it's an important question to ask if you are classifying drawings and there is an audience that is experiencing your web application or your project. Is the Google Quick Draw data set is the Google Quick Draw data set representative of that audience? Are they represented in that data set? That's something that I talk a lot about over many videos, about thinking about the ethics and politics of data collection. And now for the next step. Rather than draw onto a canvas, if I use a notepad here with a document camera pointed at it, can I get it to recognize my drawings on paper? I am going to duplicate this sketch, call it doodle net video. I'm going to add a variable called video. I'm still going to use the canvas, and I'll show you why in a second. I could pass the video directly, but I'm going to draw the video on the canvas and resize it. And this should be exactly the same now. As you can see, it is now seeing my notepad over here. I'm going to start by trying to draw a strawberry. A strawberry. That's sort of more like a heart. It's a beach again, or it's raining. So why is this not working? I'm not entirely sure, but let's see if I can, even with this exact same image, kind of adjust it. So one thing that I might think about doing is applying some image processing to it. So one thing that I could do very quickly is add a filter, threshold filter with a threshold of 0.5. Let's try that. A threshold filter takes any image and converts every pixel to either black or white based on some threshold value, in this case, 50%. Let me try a thicker pen. Ha ha. There we go. It's a strawberry. Let's draw. I'm going to see if I can draw that cat now. I don't know. It's either a cactus or a cat or maybe a hedgehog. But you can see that this is working. We now have the ability to take input from a camera. I don't know to what extent this filtering is altering it. Like, look, right now it says it's 52.4% cat. Let's actually try making the filter only apply if I press the mouse. And we'll see how that affects things. This is what it looks like without the filter, with the filter. You can see, first of all, it's much more stable. With the threshold filter, I have a very consistent image. But there's a lot of noise otherwise in the image. I think it wants me. It's like it's telling me. It's daring me to draw a snowman, to get that 1.8% up. Let's see. This is a snowman. Look at that. Look at that snowman. There we go. Snowman. All right. Am I going to make it worse or better by adding some arms? Snowman. There we go. OK. So I hope you enjoyed this particular video. I would encourage you to experiment with this model. I think there's a lot of creative possibilities in terms of what this interaction might be applied to. Could you play a game where you have to control a character by drawing? What happens when you pass images that come from fill in the blank to this model? I encourage you to play with that. I encourage you to look at my shape classifier video to train your own model that recognizes shapes and drawings and that sort of thing. Share it with me. I would love to see what kinds of creative possible outcomes come from this stuff. OK. Goodbye. Hopefully, there'll be more ml5 videos to come. And I look forward to seeing you there. Thank you. Bye bye. Bye bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:32.449267Z",
  "started_at": "2023-09-26T21:13:57.499196Z",
  "completed_at": "2023-09-26T21:17:18.387706Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=ABN_DWnM5GQ",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 200.88851
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/gxdaqujbde56w25zydxlyxrtsm/cancel",
    "get": "https://api.replicate.com/v1/predictions/gxdaqujbde56w25zydxlyxrtsm"
  }
}