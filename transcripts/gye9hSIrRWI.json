{
  "id": "sdi7zuzbxhxx2kgp7yudvceswe",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/gye9hSIrRWI.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/518803 [00:00<?, ?frames/s]\n  1%|          | 2800/518803 [00:04<15:06, 569.31frames/s]\n  1%|          | 5400/518803 [00:13<21:47, 392.58frames/s]\n  2%|▏         | 8100/518803 [00:20<23:02, 369.52frames/s]\n  2%|▏         | 11000/518803 [00:29<23:45, 356.29frames/s]\n  3%|▎         | 13400/518803 [00:37<24:50, 339.01frames/s]\n  3%|▎         | 15900/518803 [00:43<23:46, 352.50frames/s]\n  4%|▎         | 18700/518803 [00:51<23:37, 352.79frames/s]\n  4%|▍         | 21500/518803 [00:59<23:44, 349.09frames/s]\n  5%|▍         | 24300/518803 [01:06<22:43, 362.61frames/s]\n  5%|▌         | 27200/518803 [01:15<22:50, 358.82frames/s]\n  6%|▌         | 29800/518803 [01:20<20:50, 391.15frames/s]\n  6%|▌         | 32100/518803 [01:24<18:50, 430.68frames/s]\n  7%|▋         | 35000/518803 [01:28<16:27, 490.12frames/s]\n  7%|▋         | 37700/518803 [01:32<15:01, 533.54frames/s]\n  8%|▊         | 39900/518803 [01:35<13:50, 576.76frames/s]\n  8%|▊         | 42700/518803 [01:40<14:00, 566.35frames/s]\n  9%|▉         | 45500/518803 [01:44<13:11, 598.29frames/s]\n  9%|▉         | 48200/518803 [01:48<12:37, 621.20frames/s]\n 10%|▉         | 50900/518803 [01:52<11:49, 659.38frames/s]\n 10%|█         | 53700/518803 [01:55<11:20, 683.54frames/s]\n 11%|█         | 56300/518803 [01:59<11:08, 691.37frames/s]\n 11%|█▏        | 58500/518803 [02:03<11:26, 670.24frames/s]\n 12%|█▏        | 61300/518803 [02:07<11:19, 672.97frames/s]\n 12%|█▏        | 64000/518803 [02:11<11:24, 664.43frames/s]\n 13%|█▎        | 66500/518803 [02:15<11:46, 640.65frames/s]\n 13%|█▎        | 68800/518803 [02:19<11:25, 656.53frames/s]\n 14%|█▎        | 71000/518803 [02:21<10:50, 688.12frames/s]\n 14%|█▍        | 73800/518803 [02:24<09:57, 744.40frames/s]\n 15%|█▍        | 75700/518803 [02:27<09:51, 748.68frames/s]\n 15%|█▍        | 77200/518803 [02:29<10:06, 728.38frames/s]\n 15%|█▌        | 79400/518803 [02:33<11:07, 658.73frames/s]\n 16%|█▌        | 81400/518803 [02:36<10:48, 674.11frames/s]\n 16%|█▋        | 84400/518803 [02:40<10:07, 715.31frames/s]\n 17%|█▋        | 87100/518803 [02:44<10:48, 665.89frames/s]\n 17%|█▋        | 90100/518803 [02:49<10:47, 661.88frames/s]\n 18%|█▊        | 92100/518803 [02:52<10:58, 647.94frames/s]\n 18%|█▊        | 94800/518803 [02:57<11:25, 618.66frames/s]\n 19%|█▉        | 97800/518803 [03:02<11:08, 629.73frames/s]\n 19%|█▉        | 100800/518803 [03:06<11:03, 629.72frames/s]\n 20%|█▉        | 102300/518803 [03:09<11:25, 607.58frames/s]\n 20%|██        | 104400/518803 [03:13<11:09, 619.16frames/s]\n 21%|██        | 107400/518803 [03:17<10:54, 628.81frames/s]\n 21%|██        | 109700/518803 [03:20<10:00, 681.80frames/s]\n 22%|██▏       | 112300/518803 [03:24<09:53, 685.12frames/s]\n 22%|██▏       | 114300/518803 [03:28<11:13, 600.53frames/s]\n 23%|██▎       | 117100/518803 [03:32<10:31, 635.99frames/s]\n 23%|██▎       | 119600/518803 [03:36<10:14, 649.92frames/s]\n 24%|██▎       | 122100/518803 [03:40<10:11, 648.51frames/s]\n 24%|██▍       | 124000/518803 [03:42<09:55, 662.57frames/s]\n 24%|██▍       | 126800/518803 [03:46<09:53, 660.18frames/s]\n 25%|██▍       | 128900/518803 [03:51<10:52, 597.44frames/s]\n 25%|██▌       | 131200/518803 [03:55<10:40, 604.82frames/s]\n 26%|██▌       | 134000/518803 [03:59<10:46, 594.75frames/s]\n 26%|██▋       | 136300/518803 [04:03<10:19, 617.50frames/s]\n 27%|██▋       | 139200/518803 [04:08<10:21, 610.42frames/s]\n 27%|██▋       | 142000/518803 [04:13<10:49, 580.47frames/s]\n 28%|██▊       | 143500/518803 [04:16<11:21, 551.03frames/s]\n 28%|██▊       | 146000/518803 [04:21<11:17, 549.91frames/s]\n 29%|██▊       | 149000/518803 [04:25<10:28, 588.03frames/s]\n 29%|██▉       | 151800/518803 [04:30<10:23, 588.89frames/s]\n 30%|██▉       | 154400/518803 [04:35<10:36, 572.36frames/s]\n 30%|███       | 157300/518803 [04:41<10:53, 552.76frames/s]\n 31%|███       | 160200/518803 [04:46<11:14, 531.34frames/s]\n 31%|███▏      | 162700/518803 [04:52<11:36, 511.48frames/s]\n 32%|███▏      | 165500/518803 [04:58<12:08, 484.91frames/s]\n 32%|███▏      | 168500/518803 [05:04<12:00, 486.17frames/s]\n 33%|███▎      | 171200/518803 [05:10<11:59, 483.31frames/s]\n 34%|███▎      | 174100/518803 [05:16<11:40, 492.01frames/s]\n 34%|███▍      | 176800/518803 [05:19<10:24, 547.60frames/s]\n 35%|███▍      | 179500/518803 [05:24<09:55, 569.46frames/s]\n 35%|███▌      | 182200/518803 [05:28<09:39, 580.85frames/s]\n 36%|███▌      | 184600/518803 [05:32<09:26, 589.59frames/s]\n 36%|███▌      | 187600/518803 [05:35<08:18, 664.30frames/s]\n 37%|███▋      | 190600/518803 [05:39<07:52, 694.60frames/s]\n 37%|███▋      | 193000/518803 [05:44<08:38, 628.33frames/s]\n 38%|███▊      | 195900/518803 [05:49<08:54, 603.72frames/s]\n 38%|███▊      | 198800/518803 [05:54<09:00, 591.57frames/s]\n 39%|███▉      | 201100/518803 [06:01<10:54, 485.68frames/s]\n 39%|███▉      | 204100/518803 [06:04<08:53, 589.50frames/s]\n 40%|███▉      | 206900/518803 [06:09<08:38, 601.89frames/s]\n 40%|████      | 209200/518803 [06:13<08:52, 581.24frames/s]\n 41%|████      | 211800/518803 [06:17<08:44, 585.38frames/s]\n 41%|████▏     | 214500/518803 [06:20<07:44, 655.55frames/s]\n 42%|████▏     | 217100/518803 [06:25<07:58, 630.81frames/s]\n 42%|████▏     | 219800/518803 [06:30<08:10, 609.92frames/s]\n 43%|████▎     | 222600/518803 [06:35<08:17, 595.53frames/s]\n 43%|████▎     | 224900/518803 [06:40<08:56, 547.91frames/s]\n 44%|████▍     | 227200/518803 [06:43<08:14, 589.97frames/s]\n 44%|████▍     | 228600/518803 [06:46<08:34, 563.91frames/s]\n 45%|████▍     | 231000/518803 [06:49<07:47, 615.14frames/s]\n 45%|████▌     | 233900/518803 [06:52<07:00, 677.11frames/s]\n 46%|████▌     | 236500/518803 [06:57<07:13, 651.42frames/s]\n 46%|████▌     | 239000/518803 [07:01<07:28, 624.54frames/s]\n 47%|████▋     | 241400/518803 [07:05<07:25, 622.13frames/s]\n 47%|████▋     | 243600/518803 [07:08<07:13, 634.78frames/s]\n 47%|████▋     | 246300/518803 [07:13<07:30, 605.19frames/s]\n 48%|████▊     | 247900/518803 [07:16<07:33, 597.21frames/s]\n 48%|████▊     | 250600/518803 [07:19<06:29, 688.97frames/s]\n 49%|████▉     | 253100/518803 [07:22<06:10, 717.62frames/s]\n 49%|████▉     | 255800/518803 [07:26<06:01, 726.89frames/s]\n 50%|████▉     | 258200/518803 [07:29<05:57, 729.32frames/s]\n 50%|█████     | 261100/518803 [07:34<06:25, 668.80frames/s]\n 51%|█████     | 263600/518803 [07:38<06:42, 634.78frames/s]\n 51%|█████▏    | 266200/518803 [07:43<06:41, 628.40frames/s]\n 52%|█████▏    | 268100/518803 [07:46<07:08, 585.63frames/s]\n 52%|█████▏    | 270900/518803 [07:51<06:47, 607.89frames/s]\n 53%|█████▎    | 273900/518803 [07:55<06:26, 632.86frames/s]\n 53%|█████▎    | 276400/518803 [07:58<05:47, 698.51frames/s]\n 54%|█████▎    | 278600/518803 [08:02<06:21, 629.60frames/s]\n 54%|█████▍    | 281200/518803 [08:07<06:26, 615.24frames/s]\n 55%|█████▍    | 284200/518803 [08:11<06:13, 627.62frames/s]\n 55%|█████▌    | 286200/518803 [08:16<06:43, 576.64frames/s]\n 56%|█████▌    | 288500/518803 [08:20<07:01, 546.09frames/s]\n 56%|█████▌    | 290900/518803 [08:24<06:44, 563.88frames/s]\n 57%|█████▋    | 293400/518803 [08:28<06:16, 598.11frames/s]\n 57%|█████▋    | 295900/518803 [08:31<05:33, 667.67frames/s]\n 58%|█████▊    | 298800/518803 [08:36<06:01, 608.74frames/s]\n 58%|█████▊    | 301500/518803 [08:40<05:32, 653.68frames/s]\n 59%|█████▊    | 304300/518803 [08:44<05:18, 672.84frames/s]\n 59%|█████▉    | 306900/518803 [08:49<05:41, 621.30frames/s]\n 60%|█████▉    | 309400/518803 [08:53<05:42, 611.83frames/s]\n 60%|██████    | 312300/518803 [08:58<05:42, 603.15frames/s]\n 61%|██████    | 314100/518803 [09:00<05:26, 626.20frames/s]\n 61%|██████    | 316700/518803 [09:04<05:18, 634.91frames/s]\n 62%|██████▏   | 319700/518803 [09:09<05:08, 645.58frames/s]\n 62%|██████▏   | 322100/518803 [09:12<04:54, 667.87frames/s]\n 63%|██████▎   | 324800/518803 [09:14<04:11, 771.87frames/s]\n 63%|██████▎   | 327400/518803 [09:19<04:47, 665.72frames/s]\n 64%|██████▎   | 329800/518803 [09:23<04:37, 681.57frames/s]\n 64%|██████▍   | 332500/518803 [09:27<04:48, 645.84frames/s]\n 65%|██████▍   | 335100/518803 [09:32<04:49, 635.57frames/s]\n 65%|██████▌   | 337300/518803 [09:35<04:44, 637.54frames/s]\n 66%|██████▌   | 340200/518803 [09:40<04:38, 640.73frames/s]\n 66%|██████▌   | 342800/518803 [09:44<04:48, 609.08frames/s]\n 66%|██████▋   | 344500/518803 [09:46<04:29, 646.37frames/s]\n 67%|██████▋   | 346700/518803 [09:49<04:16, 670.16frames/s]\n 67%|██████▋   | 349000/518803 [09:53<04:19, 655.34frames/s]\n 68%|██████▊   | 351100/518803 [09:56<04:21, 641.08frames/s]\n 68%|██████▊   | 353200/518803 [09:59<04:08, 666.26frames/s]\n 69%|██████▊   | 356200/518803 [10:03<03:50, 704.07frames/s]\n 69%|██████▉   | 359100/518803 [10:09<04:20, 613.92frames/s]\n 70%|██████▉   | 361000/518803 [10:12<04:05, 641.85frames/s]\n 70%|███████   | 363200/518803 [10:15<04:01, 644.54frames/s]\n 71%|███████   | 366000/518803 [10:19<03:52, 656.40frames/s]\n 71%|███████   | 368900/518803 [10:23<03:34, 699.99frames/s]\n 72%|███████▏  | 371800/518803 [10:27<03:29, 703.20frames/s]\n 72%|███████▏  | 374800/518803 [10:31<03:23, 708.04frames/s]\n 73%|███████▎  | 377200/518803 [10:35<03:33, 661.71frames/s]\n 73%|███████▎  | 379800/518803 [10:39<03:33, 649.64frames/s]\n 74%|███████▎  | 382300/518803 [10:42<03:16, 694.47frames/s]\n 74%|███████▍  | 385000/518803 [10:47<03:23, 657.32frames/s]\n 75%|███████▍  | 387300/518803 [10:49<02:59, 733.16frames/s]\n 75%|███████▌  | 389600/518803 [10:51<02:33, 843.75frames/s]\n 76%|███████▌  | 392600/518803 [10:52<01:53, 1113.83frames/s]\n 76%|███████▌  | 393900/518803 [10:54<02:05, 997.60frames/s] \n 76%|███████▋  | 396300/518803 [10:57<02:22, 859.80frames/s]\n 77%|███████▋  | 398800/518803 [11:00<02:14, 891.22frames/s]\n 77%|███████▋  | 401400/518803 [11:03<02:18, 847.55frames/s]\n 78%|███████▊  | 403900/518803 [11:07<02:31, 759.99frames/s]\n 78%|███████▊  | 406900/518803 [11:11<02:18, 807.17frames/s]\n 79%|███████▉  | 409600/518803 [11:14<02:19, 780.61frames/s]\n 79%|███████▉  | 412400/518803 [11:20<02:38, 671.08frames/s]\n 80%|████████  | 415100/518803 [11:25<02:41, 643.11frames/s]\n 80%|████████  | 417100/518803 [11:29<02:49, 599.32frames/s]\n 81%|████████  | 419800/518803 [11:32<02:27, 670.46frames/s]\n 81%|████████▏ | 422500/518803 [11:37<02:43, 588.01frames/s]\n 82%|████████▏ | 425500/518803 [11:41<02:25, 639.98frames/s]\n 83%|████████▎ | 428200/518803 [11:47<02:35, 580.98frames/s]\n 83%|████████▎ | 430300/518803 [12:04<04:55, 299.29frames/s]\n 83%|████████▎ | 433100/518803 [12:10<04:15, 335.81frames/s]\n 84%|████████▍ | 435400/518803 [12:15<03:43, 372.72frames/s]\n 84%|████████▍ | 437700/518803 [12:18<03:04, 439.66frames/s]\n 85%|████████▍ | 440600/518803 [12:23<02:48, 465.25frames/s]\n 85%|████████▌ | 442600/518803 [12:28<02:50, 446.25frames/s]\n 86%|████████▌ | 444400/518803 [12:31<02:31, 490.24frames/s]\n 86%|████████▌ | 447100/518803 [12:35<02:16, 524.69frames/s]\n 87%|████████▋ | 449600/518803 [12:40<02:11, 526.85frames/s]\n 87%|████████▋ | 452300/518803 [12:44<01:56, 569.42frames/s]\n 88%|████████▊ | 454800/518803 [12:47<01:45, 604.26frames/s]\n 88%|████████▊ | 457700/518803 [12:51<01:32, 659.52frames/s]\n 89%|████████▉ | 460700/518803 [12:55<01:24, 686.98frames/s]\n 89%|████████▉ | 463400/518803 [13:00<01:30, 613.83frames/s]\n 90%|████████▉ | 465900/518803 [13:05<01:29, 589.65frames/s]\n 90%|█████████ | 468700/518803 [13:10<01:25, 583.58frames/s]\n 91%|█████████ | 471500/518803 [13:16<01:25, 554.99frames/s]\n 91%|█████████▏| 474400/518803 [13:21<01:20, 551.64frames/s]\n 92%|█████████▏| 477300/518803 [13:25<01:08, 605.79frames/s]\n 93%|█████████▎| 480100/518803 [13:32<01:16, 505.25frames/s]\n 93%|█████████▎| 483000/518803 [13:41<01:21, 437.94frames/s]\n 94%|█████████▎| 485700/518803 [13:46<01:10, 470.77frames/s]\n 94%|█████████▍| 488600/518803 [13:52<01:05, 460.11frames/s]\n 95%|█████████▍| 491400/518803 [14:00<01:05, 420.45frames/s]\n 95%|█████████▌| 494300/518803 [14:08<01:00, 401.98frames/s]\n 96%|█████████▌| 496900/518803 [14:14<00:53, 412.11frames/s]\n 96%|█████████▌| 499300/518803 [14:21<00:49, 393.28frames/s]\n 97%|█████████▋| 501400/518803 [14:26<00:42, 408.05frames/s]\n 97%|█████████▋| 504300/518803 [14:32<00:34, 423.30frames/s]\n 98%|█████████▊| 506900/518803 [14:38<00:27, 428.66frames/s]\n 98%|█████████▊| 509700/518803 [14:44<00:20, 439.09frames/s]\n 99%|█████████▉| 512600/518803 [14:52<00:15, 406.52frames/s]\n 99%|█████████▉| 515300/518803 [14:59<00:08, 394.52frames/s]\n100%|█████████▉| 518200/518803 [15:08<00:01, 374.15frames/s]\n100%|██████████| 518803/518803 [15:11<00:00, 354.44frames/s]\n100%|██████████| 518803/518803 [15:11<00:00, 569.37frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.32516615125868054,
        "compression_ratio": 1.4880382775119618,
        "end": 2,
        "id": 0,
        "no_speech_prob": 0.012813437730073929,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " They can hear anything you say.",
        "tokens": [
          50364,
          814,
          393,
          1568,
          1340,
          291,
          584,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.32516615125868054,
        "compression_ratio": 1.4880382775119618,
        "end": 4,
        "id": 1,
        "no_speech_prob": 0.012813437730073929,
        "seek": 0,
        "start": 2,
        "temperature": 0,
        "text": " Which I'm going to do.",
        "tokens": [
          50464,
          3013,
          286,
          478,
          516,
          281,
          360,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.32516615125868054,
        "compression_ratio": 1.4880382775119618,
        "end": 16,
        "id": 2,
        "no_speech_prob": 0.012813437730073929,
        "seek": 0,
        "start": 14,
        "temperature": 0,
        "text": " Hello, we're here.",
        "tokens": [
          51064,
          2425,
          11,
          321,
          434,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.32516615125868054,
        "compression_ratio": 1.4880382775119618,
        "end": 20,
        "id": 3,
        "no_speech_prob": 0.012813437730073929,
        "seek": 0,
        "start": 16,
        "temperature": 0,
        "text": " The chat is very small, so I just want to see a few messages from the chat that's like,",
        "tokens": [
          51164,
          440,
          5081,
          307,
          588,
          1359,
          11,
          370,
          286,
          445,
          528,
          281,
          536,
          257,
          1326,
          7897,
          490,
          264,
          5081,
          300,
          311,
          411,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.32516615125868054,
        "compression_ratio": 1.4880382775119618,
        "end": 24,
        "id": 4,
        "no_speech_prob": 0.012813437730073929,
        "seek": 0,
        "start": 20,
        "temperature": 0,
        "text": " I see you, things are working, I can hear you, because half the time I set up my mic incorrectly.",
        "tokens": [
          51364,
          286,
          536,
          291,
          11,
          721,
          366,
          1364,
          11,
          286,
          393,
          1568,
          291,
          11,
          570,
          1922,
          264,
          565,
          286,
          992,
          493,
          452,
          3123,
          42892,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.32516615125868054,
        "compression_ratio": 1.4880382775119618,
        "end": 28,
        "id": 5,
        "no_speech_prob": 0.012813437730073929,
        "seek": 0,
        "start": 24,
        "temperature": 0,
        "text": " Welcome to the special Friday Coding Train episode.",
        "tokens": [
          51564,
          4027,
          281,
          264,
          2121,
          6984,
          383,
          8616,
          28029,
          3500,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 30,
        "id": 6,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 28,
        "temperature": 0,
        "text": " My name is Dan Shiffman.",
        "tokens": [
          50364,
          1222,
          1315,
          307,
          3394,
          1160,
          3661,
          1601,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 34,
        "id": 7,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 30,
        "temperature": 0,
        "text": " There's a lot of things that are special and different and exciting about this episode.",
        "tokens": [
          50464,
          821,
          311,
          257,
          688,
          295,
          721,
          300,
          366,
          2121,
          293,
          819,
          293,
          4670,
          466,
          341,
          3500,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 37,
        "id": 8,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 34,
        "temperature": 0,
        "text": " I still don't see anybody saying anything in the chat.",
        "tokens": [
          50664,
          286,
          920,
          500,
          380,
          536,
          4472,
          1566,
          1340,
          294,
          264,
          5081,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 39,
        "id": 9,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 37,
        "temperature": 0,
        "text": " Oh, somebody said hi.",
        "tokens": [
          50814,
          876,
          11,
          2618,
          848,
          4879,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 41,
        "id": 10,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 39,
        "temperature": 0,
        "text": " Okay, so I'm going to take that as things are working.",
        "tokens": [
          50914,
          1033,
          11,
          370,
          286,
          478,
          516,
          281,
          747,
          300,
          382,
          721,
          366,
          1364,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 43,
        "id": 11,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 41,
        "temperature": 0,
        "text": " So today is a special episode.",
        "tokens": [
          51014,
          407,
          965,
          307,
          257,
          2121,
          3500,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 45,
        "id": 12,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 43,
        "temperature": 0,
        "text": " There's a few things about this episode that are special.",
        "tokens": [
          51114,
          821,
          311,
          257,
          1326,
          721,
          466,
          341,
          3500,
          300,
          366,
          2121,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 49,
        "id": 13,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 45,
        "temperature": 0,
        "text": " Number one, we're going to do a machine learning project from start to finish.",
        "tokens": [
          51214,
          5118,
          472,
          11,
          321,
          434,
          516,
          281,
          360,
          257,
          3479,
          2539,
          1716,
          490,
          722,
          281,
          2413,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19121408837986745,
        "compression_ratio": 1.7830882352941178,
        "end": 54,
        "id": 14,
        "no_speech_prob": 0.022622575983405113,
        "seek": 2800,
        "start": 49,
        "temperature": 0,
        "text": " Training a model entirely in the cloud, getting that trained model back,",
        "tokens": [
          51414,
          20620,
          257,
          2316,
          7696,
          294,
          264,
          4588,
          11,
          1242,
          300,
          8895,
          2316,
          646,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21422603053431358,
        "compression_ratio": 1.657718120805369,
        "end": 57,
        "id": 15,
        "no_speech_prob": 0.003481854684650898,
        "seek": 5400,
        "start": 54,
        "temperature": 0,
        "text": " and then implementing that model in the browser using JavaScript.",
        "tokens": [
          50364,
          293,
          550,
          18114,
          300,
          2316,
          294,
          264,
          11185,
          1228,
          15778,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21422603053431358,
        "compression_ratio": 1.657718120805369,
        "end": 62,
        "id": 16,
        "no_speech_prob": 0.003481854684650898,
        "seek": 5400,
        "start": 57,
        "temperature": 0,
        "text": " So all of those pieces, that's going to happen, and the whole thing is going to take maybe an hour and a half.",
        "tokens": [
          50514,
          407,
          439,
          295,
          729,
          3755,
          11,
          300,
          311,
          516,
          281,
          1051,
          11,
          293,
          264,
          1379,
          551,
          307,
          516,
          281,
          747,
          1310,
          364,
          1773,
          293,
          257,
          1922,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21422603053431358,
        "compression_ratio": 1.657718120805369,
        "end": 65,
        "id": 17,
        "no_speech_prob": 0.003481854684650898,
        "seek": 5400,
        "start": 62,
        "temperature": 0,
        "text": " To present all this to you, we have a guest.",
        "tokens": [
          50764,
          1407,
          1974,
          439,
          341,
          281,
          291,
          11,
          321,
          362,
          257,
          8341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21422603053431358,
        "compression_ratio": 1.657718120805369,
        "end": 73,
        "id": 18,
        "no_speech_prob": 0.003481854684650898,
        "seek": 5400,
        "start": 65,
        "temperature": 0,
        "text": " Yining Shi, you might remember her from the Coding Train brick breaker tutorial that she made.",
        "tokens": [
          50914,
          398,
          1760,
          25580,
          11,
          291,
          1062,
          1604,
          720,
          490,
          264,
          383,
          8616,
          28029,
          16725,
          35375,
          7073,
          300,
          750,
          1027,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21422603053431358,
        "compression_ratio": 1.657718120805369,
        "end": 76,
        "id": 19,
        "no_speech_prob": 0.003481854684650898,
        "seek": 5400,
        "start": 73,
        "temperature": 0,
        "text": " I will link to Yining as an artist and a researcher.",
        "tokens": [
          51314,
          286,
          486,
          2113,
          281,
          398,
          1760,
          382,
          364,
          5748,
          293,
          257,
          21751,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21422603053431358,
        "compression_ratio": 1.657718120805369,
        "end": 81,
        "id": 20,
        "no_speech_prob": 0.003481854684650898,
        "seek": 5400,
        "start": 76,
        "temperature": 0,
        "text": " She's a core contributor to the ML5 library, which is a machine learning library that will be used as part of this tutorial.",
        "tokens": [
          51464,
          1240,
          311,
          257,
          4965,
          42859,
          281,
          264,
          21601,
          20,
          6405,
          11,
          597,
          307,
          257,
          3479,
          2539,
          6405,
          300,
          486,
          312,
          1143,
          382,
          644,
          295,
          341,
          7073,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18629525312736853,
        "compression_ratio": 1.6293929712460065,
        "end": 85,
        "id": 21,
        "no_speech_prob": 0.029286906123161316,
        "seek": 8100,
        "start": 81,
        "temperature": 0,
        "text": " She's contributed to the P5.js library, which will also be used as part of this tutorial.",
        "tokens": [
          50364,
          1240,
          311,
          18434,
          281,
          264,
          430,
          20,
          13,
          25530,
          6405,
          11,
          597,
          486,
          611,
          312,
          1143,
          382,
          644,
          295,
          341,
          7073,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18629525312736853,
        "compression_ratio": 1.6293929712460065,
        "end": 93,
        "id": 22,
        "no_speech_prob": 0.029286906123161316,
        "seek": 8100,
        "start": 85,
        "temperature": 0,
        "text": " She wrote the whole style transfer module of ML5, which, so basically that's what she's going to do and present here.",
        "tokens": [
          50564,
          1240,
          4114,
          264,
          1379,
          3758,
          5003,
          10088,
          295,
          21601,
          20,
          11,
          597,
          11,
          370,
          1936,
          300,
          311,
          437,
          750,
          311,
          516,
          281,
          360,
          293,
          1974,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18629525312736853,
        "compression_ratio": 1.6293929712460065,
        "end": 97,
        "id": 23,
        "no_speech_prob": 0.029286906123161316,
        "seek": 8100,
        "start": 93,
        "temperature": 0,
        "text": " So Yining will be here in a minute after I do my long-winded introduction.",
        "tokens": [
          50964,
          407,
          398,
          1760,
          486,
          312,
          510,
          294,
          257,
          3456,
          934,
          286,
          360,
          452,
          938,
          12,
          12199,
          292,
          9339,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18629525312736853,
        "compression_ratio": 1.6293929712460065,
        "end": 101,
        "id": 24,
        "no_speech_prob": 0.029286906123161316,
        "seek": 8100,
        "start": 97,
        "temperature": 0,
        "text": " The other thing I want to mention is this video is sponsored by Spell.",
        "tokens": [
          51164,
          440,
          661,
          551,
          286,
          528,
          281,
          2152,
          307,
          341,
          960,
          307,
          16621,
          538,
          3550,
          285,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18629525312736853,
        "compression_ratio": 1.6293929712460065,
        "end": 104,
        "id": 25,
        "no_speech_prob": 0.029286906123161316,
        "seek": 8100,
        "start": 101,
        "temperature": 0,
        "text": " Spell is a cloud computing for machine learning service.",
        "tokens": [
          51364,
          3550,
          285,
          307,
          257,
          4588,
          15866,
          337,
          3479,
          2539,
          2643,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18629525312736853,
        "compression_ratio": 1.6293929712460065,
        "end": 110,
        "id": 26,
        "no_speech_prob": 0.029286906123161316,
        "seek": 8100,
        "start": 104,
        "temperature": 0,
        "text": " I did an entire introduction to Spell, how to set it up, what it does, what are the basic commands.",
        "tokens": [
          51514,
          286,
          630,
          364,
          2302,
          9339,
          281,
          3550,
          285,
          11,
          577,
          281,
          992,
          309,
          493,
          11,
          437,
          309,
          775,
          11,
          437,
          366,
          264,
          3875,
          16901,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19564197509269404,
        "compression_ratio": 1.7606177606177607,
        "end": 115,
        "id": 27,
        "no_speech_prob": 0.004904455039650202,
        "seek": 11000,
        "start": 110,
        "temperature": 0,
        "text": " If you're watching this as an archive, you might want to go back and watch that first and then return.",
        "tokens": [
          50364,
          759,
          291,
          434,
          1976,
          341,
          382,
          364,
          23507,
          11,
          291,
          1062,
          528,
          281,
          352,
          646,
          293,
          1159,
          300,
          700,
          293,
          550,
          2736,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19564197509269404,
        "compression_ratio": 1.7606177606177607,
        "end": 120,
        "id": 28,
        "no_speech_prob": 0.004904455039650202,
        "seek": 11000,
        "start": 115,
        "temperature": 0,
        "text": " But if you're watching this live, and you haven't seen that, we'll try to help you along and get you set up with that.",
        "tokens": [
          50614,
          583,
          498,
          291,
          434,
          1976,
          341,
          1621,
          11,
          293,
          291,
          2378,
          380,
          1612,
          300,
          11,
          321,
          603,
          853,
          281,
          854,
          291,
          2051,
          293,
          483,
          291,
          992,
          493,
          365,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19564197509269404,
        "compression_ratio": 1.7606177606177607,
        "end": 125,
        "id": 29,
        "no_speech_prob": 0.004904455039650202,
        "seek": 11000,
        "start": 120,
        "temperature": 0,
        "text": " If you want to sign up for an account to follow along, you can get $100 in free GPU credits,",
        "tokens": [
          50864,
          759,
          291,
          528,
          281,
          1465,
          493,
          337,
          364,
          2696,
          281,
          1524,
          2051,
          11,
          291,
          393,
          483,
          1848,
          6879,
          294,
          1737,
          18407,
          16816,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19564197509269404,
        "compression_ratio": 1.7606177606177607,
        "end": 128,
        "id": 30,
        "no_speech_prob": 0.004904455039650202,
        "seek": 11000,
        "start": 125,
        "temperature": 0,
        "text": " which should be enough to train your style transfer model, I think.",
        "tokens": [
          51114,
          597,
          820,
          312,
          1547,
          281,
          3847,
          428,
          3758,
          5003,
          2316,
          11,
          286,
          519,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19564197509269404,
        "compression_ratio": 1.7606177606177607,
        "end": 132,
        "id": 31,
        "no_speech_prob": 0.004904455039650202,
        "seek": 11000,
        "start": 128,
        "temperature": 0,
        "text": " You can go to spell.run slash coding train.",
        "tokens": [
          51264,
          509,
          393,
          352,
          281,
          9827,
          13,
          12997,
          17330,
          17720,
          3847,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19564197509269404,
        "compression_ratio": 1.7606177606177607,
        "end": 134,
        "id": 32,
        "no_speech_prob": 0.004904455039650202,
        "seek": 11000,
        "start": 132,
        "temperature": 0,
        "text": " Spell.run slash coding train.",
        "tokens": [
          51464,
          3550,
          285,
          13,
          12997,
          17330,
          17720,
          3847,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21886666615804037,
        "compression_ratio": 1.5991902834008098,
        "end": 137,
        "id": 33,
        "no_speech_prob": 0.31725066900253296,
        "seek": 13400,
        "start": 134,
        "temperature": 0,
        "text": " Okay, and also, thank you to Spell.",
        "tokens": [
          50364,
          1033,
          11,
          293,
          611,
          11,
          1309,
          291,
          281,
          3550,
          285,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21886666615804037,
        "compression_ratio": 1.5991902834008098,
        "end": 140,
        "id": 34,
        "no_speech_prob": 0.31725066900253296,
        "seek": 13400,
        "start": 137,
        "temperature": 0,
        "text": " If I think, somebody tell me, turn on those closed captioning.",
        "tokens": [
          50514,
          759,
          286,
          519,
          11,
          2618,
          980,
          385,
          11,
          1261,
          322,
          729,
          5395,
          31974,
          278,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21886666615804037,
        "compression_ratio": 1.5991902834008098,
        "end": 149,
        "id": 35,
        "no_speech_prob": 0.31725066900253296,
        "seek": 13400,
        "start": 140,
        "temperature": 0,
        "text": " For the first time, I am using real-time human written captions generated by a company called White Coat Captioning.",
        "tokens": [
          50664,
          1171,
          264,
          700,
          565,
          11,
          286,
          669,
          1228,
          957,
          12,
          3766,
          1952,
          3720,
          44832,
          10833,
          538,
          257,
          2237,
          1219,
          5552,
          3066,
          267,
          9480,
          313,
          278,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21886666615804037,
        "compression_ratio": 1.5991902834008098,
        "end": 152,
        "id": 36,
        "no_speech_prob": 0.31725066900253296,
        "seek": 13400,
        "start": 149,
        "temperature": 0,
        "text": " So YouTube has automated captions for live streaming, which I've used before,",
        "tokens": [
          51114,
          407,
          3088,
          575,
          18473,
          44832,
          337,
          1621,
          11791,
          11,
          597,
          286,
          600,
          1143,
          949,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.21886666615804037,
        "compression_ratio": 1.5991902834008098,
        "end": 159,
        "id": 37,
        "no_speech_prob": 0.31725066900253296,
        "seek": 13400,
        "start": 152,
        "temperature": 0,
        "text": " but these are actually being typed by a professional captioner in real-time as I'm speaking, I think.",
        "tokens": [
          51264,
          457,
          613,
          366,
          767,
          885,
          33941,
          538,
          257,
          4843,
          31974,
          260,
          294,
          957,
          12,
          3766,
          382,
          286,
          478,
          4124,
          11,
          286,
          519,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 164,
        "id": 38,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 159,
        "temperature": 0,
        "text": " This reminds me of the kids' book, The Elephant and Piggy Book by Mo Willems.",
        "tokens": [
          50364,
          639,
          12025,
          385,
          295,
          264,
          2301,
          6,
          1446,
          11,
          440,
          8024,
          15071,
          293,
          27322,
          1480,
          9476,
          538,
          3335,
          3099,
          9097,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 169,
        "id": 39,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 164,
        "temperature": 0,
        "text": " It's like, you are in a book, and the characters realize they can make the reader of the book say anything they want.",
        "tokens": [
          50614,
          467,
          311,
          411,
          11,
          291,
          366,
          294,
          257,
          1446,
          11,
          293,
          264,
          4342,
          4325,
          436,
          393,
          652,
          264,
          15149,
          295,
          264,
          1446,
          584,
          1340,
          436,
          528,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 175,
        "id": 40,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 169,
        "temperature": 0,
        "text": " I can make the captioner type, blueberry, mango, watermelon, right?",
        "tokens": [
          50864,
          286,
          393,
          652,
          264,
          31974,
          260,
          2010,
          11,
          48243,
          11,
          23481,
          11,
          26097,
          11,
          558,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 178,
        "id": 41,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 175,
        "temperature": 0,
        "text": " Those words should be appearing under me right now, I think.",
        "tokens": [
          51164,
          3950,
          2283,
          820,
          312,
          19870,
          833,
          385,
          558,
          586,
          11,
          286,
          519,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 180,
        "id": 42,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 178,
        "temperature": 0,
        "text": " Okay, sorry, I'm off track.",
        "tokens": [
          51314,
          1033,
          11,
          2597,
          11,
          286,
          478,
          766,
          2837,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 184,
        "id": 43,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 180,
        "temperature": 0,
        "text": " So thank you so much to Spell.run for the sponsorship.",
        "tokens": [
          51414,
          407,
          1309,
          291,
          370,
          709,
          281,
          3550,
          285,
          13,
          12997,
          337,
          264,
          42922,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22240992736816406,
        "compression_ratio": 1.570921985815603,
        "end": 187,
        "id": 44,
        "no_speech_prob": 0.055814411491155624,
        "seek": 15900,
        "start": 184,
        "temperature": 0,
        "text": " Thank you to Yining for being here.",
        "tokens": [
          51614,
          1044,
          291,
          281,
          398,
          1760,
          337,
          885,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 193,
        "id": 45,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 187,
        "temperature": 0,
        "text": " Thank you to White Coat Captioning for the captioning services and for Spell providing the funds for those.",
        "tokens": [
          50364,
          1044,
          291,
          281,
          5552,
          3066,
          267,
          9480,
          313,
          278,
          337,
          264,
          31974,
          278,
          3328,
          293,
          337,
          3550,
          285,
          6530,
          264,
          8271,
          337,
          729,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 197,
        "id": 46,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 193,
        "temperature": 0,
        "text": " And then I'm going to be off to the side looking at the YouTube chat.",
        "tokens": [
          50664,
          400,
          550,
          286,
          478,
          516,
          281,
          312,
          766,
          281,
          264,
          1252,
          1237,
          412,
          264,
          3088,
          5081,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 200,
        "id": 47,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 197,
        "temperature": 0,
        "text": " So you can ask questions, I will take them down, I'll try to answer them.",
        "tokens": [
          50864,
          407,
          291,
          393,
          1029,
          1651,
          11,
          286,
          486,
          747,
          552,
          760,
          11,
          286,
          603,
          853,
          281,
          1867,
          552,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 202,
        "id": 48,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 200,
        "temperature": 0,
        "text": " Other people in the chat, I'm sure, will be helpful.",
        "tokens": [
          51014,
          5358,
          561,
          294,
          264,
          5081,
          11,
          286,
          478,
          988,
          11,
          486,
          312,
          4961,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 205,
        "id": 49,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 202,
        "temperature": 0,
        "text": " Mostly, we're going to save questions to the end.",
        "tokens": [
          51114,
          29035,
          11,
          321,
          434,
          516,
          281,
          3155,
          1651,
          281,
          264,
          917,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 210,
        "id": 50,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 205,
        "temperature": 0,
        "text": " But if there's a sort of important key question, I might interrupt and ask that.",
        "tokens": [
          51264,
          583,
          498,
          456,
          311,
          257,
          1333,
          295,
          1021,
          2141,
          1168,
          11,
          286,
          1062,
          12729,
          293,
          1029,
          300,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 212,
        "id": 51,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 210,
        "temperature": 0,
        "text": " Ah, one other thing.",
        "tokens": [
          51514,
          2438,
          11,
          472,
          661,
          551,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19472288918661904,
        "compression_ratio": 1.6709677419354838,
        "end": 215,
        "id": 52,
        "no_speech_prob": 0.009552991017699242,
        "seek": 18700,
        "start": 212,
        "temperature": 0,
        "text": " Yining will probably tell you about this, but I can't resist.",
        "tokens": [
          51614,
          398,
          1760,
          486,
          1391,
          980,
          291,
          466,
          341,
          11,
          457,
          286,
          393,
          380,
          4597,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20547526335913288,
        "compression_ratio": 1.7027972027972027,
        "end": 222,
        "id": 53,
        "no_speech_prob": 0.0006361185223795474,
        "seek": 21500,
        "start": 215,
        "temperature": 0,
        "text": " To train a style transfer model, even in the cloud on a GPU computer, and we'll cover what that stuff means, it takes a very long time.",
        "tokens": [
          50364,
          1407,
          3847,
          257,
          3758,
          5003,
          2316,
          11,
          754,
          294,
          264,
          4588,
          322,
          257,
          18407,
          3820,
          11,
          293,
          321,
          603,
          2060,
          437,
          300,
          1507,
          1355,
          11,
          309,
          2516,
          257,
          588,
          938,
          565,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20547526335913288,
        "compression_ratio": 1.7027972027972027,
        "end": 226,
        "id": 54,
        "no_speech_prob": 0.0006361185223795474,
        "seek": 21500,
        "start": 222,
        "temperature": 0,
        "text": " So we're employing a cooking show-like mechanic here.",
        "tokens": [
          50714,
          407,
          321,
          434,
          3188,
          278,
          257,
          6361,
          855,
          12,
          4092,
          23860,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20547526335913288,
        "compression_ratio": 1.7027972027972027,
        "end": 233,
        "id": 55,
        "no_speech_prob": 0.0006361185223795474,
        "seek": 21500,
        "start": 226,
        "temperature": 0,
        "text": " We'll start the training process, but then have the pre-trained model in the oven already fully baked to bring out and show you how it works.",
        "tokens": [
          50914,
          492,
          603,
          722,
          264,
          3097,
          1399,
          11,
          457,
          550,
          362,
          264,
          659,
          12,
          17227,
          2001,
          2316,
          294,
          264,
          9090,
          1217,
          4498,
          19453,
          281,
          1565,
          484,
          293,
          855,
          291,
          577,
          309,
          1985,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20547526335913288,
        "compression_ratio": 1.7027972027972027,
        "end": 243,
        "id": 56,
        "no_speech_prob": 0.0006361185223795474,
        "seek": 21500,
        "start": 233,
        "temperature": 0,
        "text": " But if you watch today, if you follow this tutorial, you will be able to train your own style transfer machine learning model in the cloud using Spell.run.",
        "tokens": [
          51264,
          583,
          498,
          291,
          1159,
          965,
          11,
          498,
          291,
          1524,
          341,
          7073,
          11,
          291,
          486,
          312,
          1075,
          281,
          3847,
          428,
          1065,
          3758,
          5003,
          3479,
          2539,
          2316,
          294,
          264,
          4588,
          1228,
          3550,
          285,
          13,
          12997,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 249,
        "id": 57,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 243,
        "temperature": 0,
        "text": " And then implement that model in the browser, styling your own images.",
        "tokens": [
          50364,
          400,
          550,
          4445,
          300,
          2316,
          294,
          264,
          11185,
          11,
          27944,
          428,
          1065,
          5267,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 250,
        "id": 58,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 249,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 252,
        "id": 59,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 250,
        "temperature": 0,
        "text": " So I'm just looking at the chat.",
        "tokens": [
          50714,
          407,
          286,
          478,
          445,
          1237,
          412,
          264,
          5081,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 254,
        "id": 60,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 252,
        "temperature": 0,
        "text": " Oh, so I think that's everything.",
        "tokens": [
          50814,
          876,
          11,
          370,
          286,
          519,
          300,
          311,
          1203,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 256,
        "id": 61,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 254,
        "temperature": 0,
        "text": " That's all my introductory stuff, yes?",
        "tokens": [
          50914,
          663,
          311,
          439,
          452,
          39048,
          1507,
          11,
          2086,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 259,
        "id": 62,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 256,
        "temperature": 0,
        "text": " So I am just going to transfer it over to Yining.",
        "tokens": [
          51014,
          407,
          286,
          669,
          445,
          516,
          281,
          5003,
          309,
          670,
          281,
          398,
          1760,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 264,
        "id": 63,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 259,
        "temperature": 0,
        "text": " I'm going to mute my microphone, and then I will unmute it every once in a while if I have something really important to say.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          24523,
          452,
          10952,
          11,
          293,
          550,
          286,
          486,
          41445,
          309,
          633,
          1564,
          294,
          257,
          1339,
          498,
          286,
          362,
          746,
          534,
          1021,
          281,
          584,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 266,
        "id": 64,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 264,
        "temperature": 0,
        "text": " And of course, you can ask me a question if you need to.",
        "tokens": [
          51414,
          400,
          295,
          1164,
          11,
          291,
          393,
          1029,
          385,
          257,
          1168,
          498,
          291,
          643,
          281,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 268,
        "id": 65,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 266,
        "temperature": 0,
        "text": " And we'll just get started.",
        "tokens": [
          51514,
          400,
          321,
          603,
          445,
          483,
          1409,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 269,
        "id": 66,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 268,
        "temperature": 0,
        "text": " Okay? Great.",
        "tokens": [
          51614,
          1033,
          30,
          3769,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2039545774459839,
        "compression_ratio": 1.6587837837837838,
        "end": 272,
        "id": 67,
        "no_speech_prob": 0.10626514256000519,
        "seek": 24300,
        "start": 269,
        "temperature": 0,
        "text": " Thank you so much, Dan. Thank you.",
        "tokens": [
          51664,
          1044,
          291,
          370,
          709,
          11,
          3394,
          13,
          1044,
          291,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 273,
        "id": 68,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 272,
        "temperature": 0,
        "text": " Hi, everyone.",
        "tokens": [
          50364,
          2421,
          11,
          1518,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 281,
        "id": 69,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 273,
        "temperature": 0,
        "text": " My name is Yining, and I'm very excited to be here today to talk about style transfer.",
        "tokens": [
          50414,
          1222,
          1315,
          307,
          398,
          1760,
          11,
          293,
          286,
          478,
          588,
          2919,
          281,
          312,
          510,
          965,
          281,
          751,
          466,
          3758,
          5003,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 284,
        "id": 70,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 281,
        "temperature": 0,
        "text": " Thank you, Dan, for inviting me here.",
        "tokens": [
          50814,
          1044,
          291,
          11,
          3394,
          11,
          337,
          18202,
          385,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 288,
        "id": 71,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 284,
        "temperature": 0,
        "text": " And I also want to thank everyone for watching this video.",
        "tokens": [
          50964,
          400,
          286,
          611,
          528,
          281,
          1309,
          1518,
          337,
          1976,
          341,
          960,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 294,
        "id": 72,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 288,
        "temperature": 0,
        "text": " I hope you enjoy this video.",
        "tokens": [
          51164,
          286,
          1454,
          291,
          2103,
          341,
          960,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 296,
        "id": 73,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 294,
        "temperature": 0,
        "text": " Should we get started?",
        "tokens": [
          51464,
          6454,
          321,
          483,
          1409,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 297,
        "id": 74,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 296,
        "temperature": 0,
        "text": " Yeah, go for it.",
        "tokens": [
          51564,
          865,
          11,
          352,
          337,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1579983206356273,
        "compression_ratio": 1.431578947368421,
        "end": 298,
        "id": 75,
        "no_speech_prob": 0.0029296530410647392,
        "seek": 27200,
        "start": 297,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19510024270893614,
        "compression_ratio": 1.8170731707317074,
        "end": 302,
        "id": 76,
        "no_speech_prob": 0.12246951460838318,
        "seek": 29800,
        "start": 298,
        "temperature": 0,
        "text": " So today, we're going to talk about style transfer.",
        "tokens": [
          50364,
          407,
          965,
          11,
          321,
          434,
          516,
          281,
          751,
          466,
          3758,
          5003,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19510024270893614,
        "compression_ratio": 1.8170731707317074,
        "end": 304,
        "id": 77,
        "no_speech_prob": 0.12246951460838318,
        "seek": 29800,
        "start": 302,
        "temperature": 0,
        "text": " We're going to do four things today.",
        "tokens": [
          50564,
          492,
          434,
          516,
          281,
          360,
          1451,
          721,
          965,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19510024270893614,
        "compression_ratio": 1.8170731707317074,
        "end": 313,
        "id": 78,
        "no_speech_prob": 0.12246951460838318,
        "seek": 29800,
        "start": 304,
        "temperature": 0,
        "text": " We're going to talk about what is style transfer, how does it work, and we're going to train a style transfer model with Spell.",
        "tokens": [
          50664,
          492,
          434,
          516,
          281,
          751,
          466,
          437,
          307,
          3758,
          5003,
          11,
          577,
          775,
          309,
          589,
          11,
          293,
          321,
          434,
          516,
          281,
          3847,
          257,
          3758,
          5003,
          2316,
          365,
          3550,
          285,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19510024270893614,
        "compression_ratio": 1.8170731707317074,
        "end": 321,
        "id": 79,
        "no_speech_prob": 0.12246951460838318,
        "seek": 29800,
        "start": 313,
        "temperature": 0,
        "text": " And we're also going to port the model into ML5.js to create an interactive demo.",
        "tokens": [
          51114,
          400,
          321,
          434,
          611,
          516,
          281,
          2436,
          264,
          2316,
          666,
          21601,
          20,
          13,
          25530,
          281,
          1884,
          364,
          15141,
          10723,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.14890913031567102,
        "compression_ratio": 1.5594059405940595,
        "end": 331,
        "id": 80,
        "no_speech_prob": 0.05419020354747772,
        "seek": 32100,
        "start": 321,
        "temperature": 0,
        "text": " Spell and ML5.js are both tools that make machine learning more approachable for a broad range of audience.",
        "tokens": [
          50364,
          3550,
          285,
          293,
          21601,
          20,
          13,
          25530,
          366,
          1293,
          3873,
          300,
          652,
          3479,
          2539,
          544,
          3109,
          712,
          337,
          257,
          4152,
          3613,
          295,
          4034,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14890913031567102,
        "compression_ratio": 1.5594059405940595,
        "end": 337,
        "id": 81,
        "no_speech_prob": 0.05419020354747772,
        "seek": 32100,
        "start": 331,
        "temperature": 0,
        "text": " For our project today, ML5.js allows us to run our model in the browser.",
        "tokens": [
          50864,
          1171,
          527,
          1716,
          965,
          11,
          21601,
          20,
          13,
          25530,
          4045,
          505,
          281,
          1190,
          527,
          2316,
          294,
          264,
          11185,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14890913031567102,
        "compression_ratio": 1.5594059405940595,
        "end": 343,
        "id": 82,
        "no_speech_prob": 0.05419020354747772,
        "seek": 32100,
        "start": 337,
        "temperature": 0,
        "text": " By the way, ML5.js is a JavaScript library based on TensorFlow.js.",
        "tokens": [
          51164,
          3146,
          264,
          636,
          11,
          21601,
          20,
          13,
          25530,
          307,
          257,
          15778,
          6405,
          2361,
          322,
          37624,
          13,
          25530,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14890913031567102,
        "compression_ratio": 1.5594059405940595,
        "end": 350,
        "id": 83,
        "no_speech_prob": 0.05419020354747772,
        "seek": 32100,
        "start": 343,
        "temperature": 0,
        "text": " So our model that we got today will also work in the TensorFlow.js.",
        "tokens": [
          51464,
          407,
          527,
          2316,
          300,
          321,
          658,
          965,
          486,
          611,
          589,
          294,
          264,
          37624,
          13,
          25530,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1549523521872128,
        "compression_ratio": 1.5326633165829147,
        "end": 356,
        "id": 84,
        "no_speech_prob": 0.0005033176275901496,
        "seek": 35000,
        "start": 350,
        "temperature": 0,
        "text": " And Spell provides the computing power for us to train this model faster.",
        "tokens": [
          50364,
          400,
          3550,
          285,
          6417,
          264,
          15866,
          1347,
          337,
          505,
          281,
          3847,
          341,
          2316,
          4663,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1549523521872128,
        "compression_ratio": 1.5326633165829147,
        "end": 361,
        "id": 85,
        "no_speech_prob": 0.0005033176275901496,
        "seek": 35000,
        "start": 356,
        "temperature": 0,
        "text": " If I train this model on my own laptop, it might take a few days.",
        "tokens": [
          50664,
          759,
          286,
          3847,
          341,
          2316,
          322,
          452,
          1065,
          10732,
          11,
          309,
          1062,
          747,
          257,
          1326,
          1708,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1549523521872128,
        "compression_ratio": 1.5326633165829147,
        "end": 368,
        "id": 86,
        "no_speech_prob": 0.0005033176275901496,
        "seek": 35000,
        "start": 361,
        "temperature": 0,
        "text": " But with the remote GPU provided by Spell, it will only take a few hours.",
        "tokens": [
          50914,
          583,
          365,
          264,
          8607,
          18407,
          5649,
          538,
          3550,
          285,
          11,
          309,
          486,
          787,
          747,
          257,
          1326,
          2496,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1549523521872128,
        "compression_ratio": 1.5326633165829147,
        "end": 374,
        "id": 87,
        "no_speech_prob": 0.0005033176275901496,
        "seek": 35000,
        "start": 368,
        "temperature": 0,
        "text": " Let me show you what we're going to build today at the end of this video.",
        "tokens": [
          51264,
          961,
          385,
          855,
          291,
          437,
          321,
          434,
          516,
          281,
          1322,
          965,
          412,
          264,
          917,
          295,
          341,
          960,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1549523521872128,
        "compression_ratio": 1.5326633165829147,
        "end": 377,
        "id": 88,
        "no_speech_prob": 0.0005033176275901496,
        "seek": 35000,
        "start": 374,
        "temperature": 0,
        "text": " This is the demo.",
        "tokens": [
          51564,
          639,
          307,
          264,
          10723,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.29215393996820216,
        "compression_ratio": 1.2962962962962963,
        "end": 388,
        "id": 89,
        "no_speech_prob": 0.0016222652047872543,
        "seek": 37700,
        "start": 377,
        "temperature": 0,
        "text": " You can also see the demo at enington23.github.io.",
        "tokens": [
          50364,
          509,
          393,
          611,
          536,
          264,
          10723,
          412,
          465,
          20251,
          9356,
          13,
          70,
          355,
          836,
          13,
          1004,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.29215393996820216,
        "compression_ratio": 1.2962962962962963,
        "end": 399,
        "id": 90,
        "no_speech_prob": 0.0016222652047872543,
        "seek": 37700,
        "start": 388,
        "temperature": 0,
        "text": " So this demo reads the image from our webcam and transfers the image style into this art.",
        "tokens": [
          50914,
          407,
          341,
          10723,
          15700,
          264,
          3256,
          490,
          527,
          39490,
          293,
          29137,
          264,
          3256,
          3758,
          666,
          341,
          1523,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23047598306234782,
        "compression_ratio": 1.5319148936170213,
        "end": 405,
        "id": 91,
        "no_speech_prob": 0.008177409879863262,
        "seek": 39900,
        "start": 399,
        "temperature": 0,
        "text": " This painting is a Chinese ancient painting.",
        "tokens": [
          50364,
          639,
          5370,
          307,
          257,
          4649,
          7832,
          5370,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23047598306234782,
        "compression_ratio": 1.5319148936170213,
        "end": 408,
        "id": 92,
        "no_speech_prob": 0.008177409879863262,
        "seek": 39900,
        "start": 405,
        "temperature": 0,
        "text": " It's called Fushi Shanjitu.",
        "tokens": [
          50664,
          467,
          311,
          1219,
          479,
          16880,
          25536,
          73,
          6380,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23047598306234782,
        "compression_ratio": 1.5319148936170213,
        "end": 413,
        "id": 93,
        "no_speech_prob": 0.008177409879863262,
        "seek": 39900,
        "start": 408,
        "temperature": 0,
        "text": " The style is kind of subtle. It doesn't have too many colors.",
        "tokens": [
          50814,
          440,
          3758,
          307,
          733,
          295,
          13743,
          13,
          467,
          1177,
          380,
          362,
          886,
          867,
          4577,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23047598306234782,
        "compression_ratio": 1.5319148936170213,
        "end": 421,
        "id": 94,
        "no_speech_prob": 0.008177409879863262,
        "seek": 39900,
        "start": 413,
        "temperature": 0,
        "text": " But if you train the model with a really colorful and has really obvious style,",
        "tokens": [
          51064,
          583,
          498,
          291,
          3847,
          264,
          2316,
          365,
          257,
          534,
          18506,
          293,
          575,
          534,
          6322,
          3758,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.23047598306234782,
        "compression_ratio": 1.5319148936170213,
        "end": 427,
        "id": 95,
        "no_speech_prob": 0.008177409879863262,
        "seek": 39900,
        "start": 421,
        "temperature": 0,
        "text": " if you use those kind of style image, you will get a more obvious result.",
        "tokens": [
          51464,
          498,
          291,
          764,
          729,
          733,
          295,
          3758,
          3256,
          11,
          291,
          486,
          483,
          257,
          544,
          6322,
          1874,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25781229337056477,
        "compression_ratio": 1.513157894736842,
        "end": 432,
        "id": 96,
        "no_speech_prob": 0.00017130606283899397,
        "seek": 42700,
        "start": 427,
        "temperature": 0,
        "text": " But this is the demo that we're going to build today.",
        "tokens": [
          50364,
          583,
          341,
          307,
          264,
          10723,
          300,
          321,
          434,
          516,
          281,
          1322,
          965,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25781229337056477,
        "compression_ratio": 1.513157894736842,
        "end": 438,
        "id": 97,
        "no_speech_prob": 0.00017130606283899397,
        "seek": 42700,
        "start": 437,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25781229337056477,
        "compression_ratio": 1.513157894736842,
        "end": 444,
        "id": 98,
        "no_speech_prob": 0.00017130606283899397,
        "seek": 42700,
        "start": 438,
        "temperature": 0,
        "text": " So before we build anything, let's talk about what is style transfer.",
        "tokens": [
          50914,
          407,
          949,
          321,
          1322,
          1340,
          11,
          718,
          311,
          751,
          466,
          437,
          307,
          3758,
          5003,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25781229337056477,
        "compression_ratio": 1.513157894736842,
        "end": 455,
        "id": 99,
        "no_speech_prob": 0.00017130606283899397,
        "seek": 42700,
        "start": 444,
        "temperature": 0,
        "text": " Style transfer is the technique of free cast the content of one image in the style of another image.",
        "tokens": [
          51214,
          27004,
          5003,
          307,
          264,
          6532,
          295,
          1737,
          4193,
          264,
          2701,
          295,
          472,
          3256,
          294,
          264,
          3758,
          295,
          1071,
          3256,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23216654042728613,
        "compression_ratio": 1.6326530612244898,
        "end": 459,
        "id": 100,
        "no_speech_prob": 0.00020026358834002167,
        "seek": 45500,
        "start": 455,
        "temperature": 0,
        "text": " For example, here is a photo here.",
        "tokens": [
          50364,
          1171,
          1365,
          11,
          510,
          307,
          257,
          5052,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23216654042728613,
        "compression_ratio": 1.6326530612244898,
        "end": 462,
        "id": 101,
        "no_speech_prob": 0.00020026358834002167,
        "seek": 45500,
        "start": 459,
        "temperature": 0,
        "text": " And here is artistic.",
        "tokens": [
          50564,
          400,
          510,
          307,
          17090,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23216654042728613,
        "compression_ratio": 1.6326530612244898,
        "end": 464,
        "id": 102,
        "no_speech_prob": 0.00020026358834002167,
        "seek": 45500,
        "start": 462,
        "temperature": 0,
        "text": " This is artwork here.",
        "tokens": [
          50714,
          639,
          307,
          15829,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23216654042728613,
        "compression_ratio": 1.6326530612244898,
        "end": 476,
        "id": 103,
        "no_speech_prob": 0.00020026358834002167,
        "seek": 45500,
        "start": 464,
        "temperature": 0,
        "text": " And this technique can extract the content from this photo and also get the style from this artwork",
        "tokens": [
          50814,
          400,
          341,
          6532,
          393,
          8947,
          264,
          2701,
          490,
          341,
          5052,
          293,
          611,
          483,
          264,
          3758,
          490,
          341,
          15829,
          51414
        ]
      },
      {
        "avg_logprob": -0.23216654042728613,
        "compression_ratio": 1.6326530612244898,
        "end": 482,
        "id": 104,
        "no_speech_prob": 0.00020026358834002167,
        "seek": 45500,
        "start": 476,
        "temperature": 0,
        "text": " and then combine those two together to create this new image.",
        "tokens": [
          51414,
          293,
          550,
          10432,
          729,
          732,
          1214,
          281,
          1884,
          341,
          777,
          3256,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22866894542307092,
        "compression_ratio": 1.4475138121546962,
        "end": 484,
        "id": 105,
        "no_speech_prob": 0.000019525545212673023,
        "seek": 48200,
        "start": 482,
        "temperature": 0,
        "text": " And here are two more examples.",
        "tokens": [
          50364,
          400,
          510,
          366,
          732,
          544,
          5110,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22866894542307092,
        "compression_ratio": 1.4475138121546962,
        "end": 490,
        "id": 106,
        "no_speech_prob": 0.000019525545212673023,
        "seek": 48200,
        "start": 486,
        "temperature": 0,
        "text": " So how does the style transfer work?",
        "tokens": [
          50564,
          407,
          577,
          775,
          264,
          3758,
          5003,
          589,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.22866894542307092,
        "compression_ratio": 1.4475138121546962,
        "end": 495,
        "id": 107,
        "no_speech_prob": 0.000019525545212673023,
        "seek": 48200,
        "start": 490,
        "temperature": 0,
        "text": " Style transfer was first introduced in the paper,",
        "tokens": [
          50764,
          27004,
          5003,
          390,
          700,
          7268,
          294,
          264,
          3035,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.22866894542307092,
        "compression_ratio": 1.4475138121546962,
        "end": 501,
        "id": 108,
        "no_speech_prob": 0.000019525545212673023,
        "seek": 48200,
        "start": 495,
        "temperature": 0,
        "text": " A Neural Algorithm of Artistic Style by Gattis in 2015.",
        "tokens": [
          51014,
          316,
          1734,
          1807,
          35014,
          6819,
          76,
          295,
          5735,
          3142,
          27004,
          538,
          460,
          1591,
          271,
          294,
          7546,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22866894542307092,
        "compression_ratio": 1.4475138121546962,
        "end": 509,
        "id": 109,
        "no_speech_prob": 0.000019525545212673023,
        "seek": 48200,
        "start": 501,
        "temperature": 0,
        "text": " In the paper, they proposed a system that uses convolutional neural network to separate",
        "tokens": [
          51314,
          682,
          264,
          3035,
          11,
          436,
          10348,
          257,
          1185,
          300,
          4960,
          45216,
          304,
          18161,
          3209,
          281,
          4994,
          51714
        ]
      },
      {
        "avg_logprob": -0.1987851236907529,
        "compression_ratio": 1.6820809248554913,
        "end": 515,
        "id": 110,
        "no_speech_prob": 0.00013981970550958067,
        "seek": 50900,
        "start": 509,
        "temperature": 0,
        "text": " and then recombine the content and style of arbitrary images.",
        "tokens": [
          50364,
          293,
          550,
          850,
          3548,
          533,
          264,
          2701,
          293,
          3758,
          295,
          23211,
          5267,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1987851236907529,
        "compression_ratio": 1.6820809248554913,
        "end": 521,
        "id": 111,
        "no_speech_prob": 0.00013981970550958067,
        "seek": 50900,
        "start": 515,
        "temperature": 0,
        "text": " By the way, convolutional neural network is a deep feedforward neural network",
        "tokens": [
          50664,
          3146,
          264,
          636,
          11,
          45216,
          304,
          18161,
          3209,
          307,
          257,
          2452,
          3154,
          13305,
          18161,
          3209,
          50964
        ]
      },
      {
        "avg_logprob": -0.1987851236907529,
        "compression_ratio": 1.6820809248554913,
        "end": 524,
        "id": 112,
        "no_speech_prob": 0.00013981970550958067,
        "seek": 50900,
        "start": 521,
        "temperature": 0,
        "text": " mostly used to analyze images.",
        "tokens": [
          50964,
          5240,
          1143,
          281,
          12477,
          5267,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1987851236907529,
        "compression_ratio": 1.6820809248554913,
        "end": 531,
        "id": 113,
        "no_speech_prob": 0.00013981970550958067,
        "seek": 50900,
        "start": 524,
        "temperature": 0,
        "text": " The idea is to, if we take this convolutional neural network here,",
        "tokens": [
          51114,
          440,
          1558,
          307,
          281,
          11,
          498,
          321,
          747,
          341,
          45216,
          304,
          18161,
          3209,
          510,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1987851236907529,
        "compression_ratio": 1.6820809248554913,
        "end": 537,
        "id": 114,
        "no_speech_prob": 0.00013981970550958067,
        "seek": 50900,
        "start": 531,
        "temperature": 0,
        "text": " that is trained to recognize objects on those images,",
        "tokens": [
          51464,
          300,
          307,
          8895,
          281,
          5521,
          6565,
          322,
          729,
          5267,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.2604589303334554,
        "compression_ratio": 1.9182389937106918,
        "end": 545,
        "id": 115,
        "no_speech_prob": 0.0001559767551952973,
        "seek": 53700,
        "start": 537,
        "temperature": 0,
        "text": " then this network has already developed some internal representation of the content and the style of this image.",
        "tokens": [
          50364,
          550,
          341,
          3209,
          575,
          1217,
          4743,
          512,
          6920,
          10290,
          295,
          264,
          2701,
          293,
          264,
          3758,
          295,
          341,
          3256,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2604589303334554,
        "compression_ratio": 1.9182389937106918,
        "end": 557,
        "id": 116,
        "no_speech_prob": 0.0001559767551952973,
        "seek": 53700,
        "start": 545,
        "temperature": 0,
        "text": " And more importantly, this paper finds out the content representation and the style representation of an image can be separated,",
        "tokens": [
          50764,
          400,
          544,
          8906,
          11,
          341,
          3035,
          10704,
          484,
          264,
          2701,
          10290,
          293,
          264,
          3758,
          10290,
          295,
          364,
          3256,
          393,
          312,
          12005,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2604589303334554,
        "compression_ratio": 1.9182389937106918,
        "end": 563,
        "id": 117,
        "no_speech_prob": 0.0001559767551952973,
        "seek": 53700,
        "start": 557,
        "temperature": 0,
        "text": " which means we can take the content representation of one image",
        "tokens": [
          51364,
          597,
          1355,
          321,
          393,
          747,
          264,
          2701,
          10290,
          295,
          472,
          3256,
          51664
        ]
      },
      {
        "avg_logprob": -0.15173282073094294,
        "compression_ratio": 1.4193548387096775,
        "end": 569,
        "id": 118,
        "no_speech_prob": 0.00019410671666264534,
        "seek": 56300,
        "start": 563,
        "temperature": 0,
        "text": " and the style representation from another image to generate a brand new image.",
        "tokens": [
          50364,
          293,
          264,
          3758,
          10290,
          490,
          1071,
          3256,
          281,
          8460,
          257,
          3360,
          777,
          3256,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15173282073094294,
        "compression_ratio": 1.4193548387096775,
        "end": 577,
        "id": 119,
        "no_speech_prob": 0.00019410671666264534,
        "seek": 56300,
        "start": 569,
        "temperature": 0,
        "text": " The convolutional neural network that Gattis used is called VGG.",
        "tokens": [
          50664,
          440,
          45216,
          304,
          18161,
          3209,
          300,
          460,
          1591,
          271,
          1143,
          307,
          1219,
          691,
          27561,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15173282073094294,
        "compression_ratio": 1.4193548387096775,
        "end": 585,
        "id": 120,
        "no_speech_prob": 0.00019410671666264534,
        "seek": 56300,
        "start": 577,
        "temperature": 0,
        "text": " It's a neural network created by Visual Geometry Group at Oxford University.",
        "tokens": [
          51064,
          467,
          311,
          257,
          18161,
          3209,
          2942,
          538,
          23187,
          2876,
          34730,
          10500,
          412,
          24786,
          3535,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1841192706938713,
        "compression_ratio": 1.5393258426966292,
        "end": 597,
        "id": 121,
        "no_speech_prob": 0.0022514951415359974,
        "seek": 58500,
        "start": 585,
        "temperature": 0,
        "text": " This convolutional neural network is the winner of ImageNet and Object Recognition Challenge in 2014.",
        "tokens": [
          50364,
          639,
          45216,
          304,
          18161,
          3209,
          307,
          264,
          8507,
          295,
          29903,
          31890,
          293,
          24753,
          44682,
          849,
          17517,
          294,
          8227,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1841192706938713,
        "compression_ratio": 1.5393258426966292,
        "end": 603,
        "id": 122,
        "no_speech_prob": 0.0022514951415359974,
        "seek": 58500,
        "start": 597,
        "temperature": 0,
        "text": " So we will see the name of VGG again when we are training this model",
        "tokens": [
          50964,
          407,
          321,
          486,
          536,
          264,
          1315,
          295,
          691,
          27561,
          797,
          562,
          321,
          366,
          3097,
          341,
          2316,
          51264
        ]
      },
      {
        "avg_logprob": -0.1841192706938713,
        "compression_ratio": 1.5393258426966292,
        "end": 613,
        "id": 123,
        "no_speech_prob": 0.0022514951415359974,
        "seek": 58500,
        "start": 603,
        "temperature": 0,
        "text": " because we need to use this convolutional neural network to get the representation out from our images.",
        "tokens": [
          51264,
          570,
          321,
          643,
          281,
          764,
          341,
          45216,
          304,
          18161,
          3209,
          281,
          483,
          264,
          10290,
          484,
          490,
          527,
          5267,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17513550652398002,
        "compression_ratio": 1.6740331491712708,
        "end": 619,
        "id": 124,
        "no_speech_prob": 0.00010228824976366013,
        "seek": 61300,
        "start": 613,
        "temperature": 0,
        "text": " So next, let's talk about the convolutional neural network.",
        "tokens": [
          50364,
          407,
          958,
          11,
          718,
          311,
          751,
          466,
          264,
          45216,
          304,
          18161,
          3209,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17513550652398002,
        "compression_ratio": 1.6740331491712708,
        "end": 625,
        "id": 125,
        "no_speech_prob": 0.00010228824976366013,
        "seek": 61300,
        "start": 619,
        "temperature": 0,
        "text": " It works like filters on different layers of this network.",
        "tokens": [
          50664,
          467,
          1985,
          411,
          15995,
          322,
          819,
          7914,
          295,
          341,
          3209,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17513550652398002,
        "compression_ratio": 1.6740331491712708,
        "end": 629,
        "id": 126,
        "no_speech_prob": 0.00010228824976366013,
        "seek": 61300,
        "start": 625,
        "temperature": 0,
        "text": " There are different representations of these images.",
        "tokens": [
          50964,
          821,
          366,
          819,
          33358,
          295,
          613,
          5267,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17513550652398002,
        "compression_ratio": 1.6740331491712708,
        "end": 633,
        "id": 127,
        "no_speech_prob": 0.00010228824976366013,
        "seek": 61300,
        "start": 629,
        "temperature": 0,
        "text": " For example, if this is the input image, this photo here,",
        "tokens": [
          51164,
          1171,
          1365,
          11,
          498,
          341,
          307,
          264,
          4846,
          3256,
          11,
          341,
          5052,
          510,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17513550652398002,
        "compression_ratio": 1.6740331491712708,
        "end": 640,
        "id": 128,
        "no_speech_prob": 0.00010228824976366013,
        "seek": 61300,
        "start": 633,
        "temperature": 0,
        "text": " this photo can be represented by all those filtered images at each level.",
        "tokens": [
          51364,
          341,
          5052,
          393,
          312,
          10379,
          538,
          439,
          729,
          37111,
          5267,
          412,
          1184,
          1496,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17886650713184213,
        "compression_ratio": 1.6348314606741574,
        "end": 646,
        "id": 129,
        "no_speech_prob": 0.0006563264760188758,
        "seek": 64000,
        "start": 640,
        "temperature": 0,
        "text": " So for content representation, which is at the bottom of this image,",
        "tokens": [
          50364,
          407,
          337,
          2701,
          10290,
          11,
          597,
          307,
          412,
          264,
          2767,
          295,
          341,
          3256,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.17886650713184213,
        "compression_ratio": 1.6348314606741574,
        "end": 656,
        "id": 130,
        "no_speech_prob": 0.0006563264760188758,
        "seek": 64000,
        "start": 646,
        "temperature": 0,
        "text": " we can visualize the information at different layers in this network by recreating the input image from one of those filtered images.",
        "tokens": [
          50664,
          321,
          393,
          23273,
          264,
          1589,
          412,
          819,
          7914,
          294,
          341,
          3209,
          538,
          850,
          44613,
          264,
          4846,
          3256,
          490,
          472,
          295,
          729,
          37111,
          5267,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17886650713184213,
        "compression_ratio": 1.6348314606741574,
        "end": 661,
        "id": 131,
        "no_speech_prob": 0.0006563264760188758,
        "seek": 64000,
        "start": 656,
        "temperature": 0,
        "text": " And we can see image A, B, C, D, E here.",
        "tokens": [
          51164,
          400,
          321,
          393,
          536,
          3256,
          316,
          11,
          363,
          11,
          383,
          11,
          413,
          11,
          462,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17886650713184213,
        "compression_ratio": 1.6348314606741574,
        "end": 665,
        "id": 132,
        "no_speech_prob": 0.0006563264760188758,
        "seek": 64000,
        "start": 661,
        "temperature": 0,
        "text": " From the lower level, we can see image A, B, C.",
        "tokens": [
          51414,
          3358,
          264,
          3126,
          1496,
          11,
          321,
          393,
          536,
          3256,
          316,
          11,
          363,
          11,
          383,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22723873077876985,
        "compression_ratio": 1.5987261146496816,
        "end": 670,
        "id": 133,
        "no_speech_prob": 0.005138881970196962,
        "seek": 66500,
        "start": 665,
        "temperature": 0,
        "text": " They are almost perfect. Those recreated images, they're almost perfect.",
        "tokens": [
          50364,
          814,
          366,
          1920,
          2176,
          13,
          3950,
          850,
          26559,
          5267,
          11,
          436,
          434,
          1920,
          2176,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22723873077876985,
        "compression_ratio": 1.5987261146496816,
        "end": 680,
        "id": 134,
        "no_speech_prob": 0.005138881970196962,
        "seek": 66500,
        "start": 670,
        "temperature": 0,
        "text": " But as the level gets higher and higher, all those detailed pixel information is lost.",
        "tokens": [
          50614,
          583,
          382,
          264,
          1496,
          2170,
          2946,
          293,
          2946,
          11,
          439,
          729,
          9942,
          19261,
          1589,
          307,
          2731,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22723873077876985,
        "compression_ratio": 1.5987261146496816,
        "end": 684,
        "id": 135,
        "no_speech_prob": 0.005138881970196962,
        "seek": 66500,
        "start": 680,
        "temperature": 0,
        "text": " But the high level content of this image is still here.",
        "tokens": [
          51114,
          583,
          264,
          1090,
          1496,
          2701,
          295,
          341,
          3256,
          307,
          920,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22723873077876985,
        "compression_ratio": 1.5987261146496816,
        "end": 688,
        "id": 136,
        "no_speech_prob": 0.005138881970196962,
        "seek": 66500,
        "start": 684,
        "temperature": 0,
        "text": " For example, for this image E here.",
        "tokens": [
          51314,
          1171,
          1365,
          11,
          337,
          341,
          3256,
          462,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23195103732022374,
        "compression_ratio": 1.4689655172413794,
        "end": 695,
        "id": 137,
        "no_speech_prob": 0.0002131812070729211,
        "seek": 68800,
        "start": 689,
        "temperature": 0,
        "text": " Even though we cannot see it clearly, but we can see, oh, there is a house on this image.",
        "tokens": [
          50414,
          2754,
          1673,
          321,
          2644,
          536,
          309,
          4448,
          11,
          457,
          321,
          393,
          536,
          11,
          1954,
          11,
          456,
          307,
          257,
          1782,
          322,
          341,
          3256,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23195103732022374,
        "compression_ratio": 1.4689655172413794,
        "end": 701,
        "id": 138,
        "no_speech_prob": 0.0002131812070729211,
        "seek": 68800,
        "start": 695,
        "temperature": 0,
        "text": " So this is how content representation looks like in this network.",
        "tokens": [
          50714,
          407,
          341,
          307,
          577,
          2701,
          10290,
          1542,
          411,
          294,
          341,
          3209,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23195103732022374,
        "compression_ratio": 1.4689655172413794,
        "end": 710,
        "id": 139,
        "no_speech_prob": 0.0002131812070729211,
        "seek": 68800,
        "start": 701,
        "temperature": 0,
        "text": " And next, we're going to talk about style representation.",
        "tokens": [
          51014,
          400,
          958,
          11,
          321,
          434,
          516,
          281,
          751,
          466,
          3758,
          10290,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24419473111629486,
        "compression_ratio": 1.60752688172043,
        "end": 725,
        "id": 140,
        "no_speech_prob": 0.002714848378673196,
        "seek": 71000,
        "start": 711,
        "temperature": 0,
        "text": " So on top of this convolutional neural network, Gattis, they built a brand new feature space that captured the style of the input image.",
        "tokens": [
          50414,
          407,
          322,
          1192,
          295,
          341,
          45216,
          304,
          18161,
          3209,
          11,
          460,
          1591,
          271,
          11,
          436,
          3094,
          257,
          3360,
          777,
          4111,
          1901,
          300,
          11828,
          264,
          3758,
          295,
          264,
          4846,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24419473111629486,
        "compression_ratio": 1.60752688172043,
        "end": 734,
        "id": 141,
        "no_speech_prob": 0.002714848378673196,
        "seek": 71000,
        "start": 725,
        "temperature": 0,
        "text": " The style representation computes correlation between different features in different layers of this network.",
        "tokens": [
          51114,
          440,
          3758,
          10290,
          715,
          1819,
          20009,
          1296,
          819,
          4122,
          294,
          819,
          7914,
          295,
          341,
          3209,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24419473111629486,
        "compression_ratio": 1.60752688172043,
        "end": 738,
        "id": 142,
        "no_speech_prob": 0.002714848378673196,
        "seek": 71000,
        "start": 734,
        "temperature": 0,
        "text": " For detailed implementation, we can check the paper.",
        "tokens": [
          51564,
          1171,
          9942,
          11420,
          11,
          321,
          393,
          1520,
          264,
          3035,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19606254498163858,
        "compression_ratio": 1.5179856115107915,
        "end": 751,
        "id": 143,
        "no_speech_prob": 0.0001313497341470793,
        "seek": 73800,
        "start": 738,
        "temperature": 0,
        "text": " But basically, as the level getting higher and higher, we find the recreated style image can match the style of this artwork better and better.",
        "tokens": [
          50364,
          583,
          1936,
          11,
          382,
          264,
          1496,
          1242,
          2946,
          293,
          2946,
          11,
          321,
          915,
          264,
          850,
          26559,
          3758,
          3256,
          393,
          2995,
          264,
          3758,
          295,
          341,
          15829,
          1101,
          293,
          1101,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19606254498163858,
        "compression_ratio": 1.5179856115107915,
        "end": 757,
        "id": 144,
        "no_speech_prob": 0.0001313497341470793,
        "seek": 73800,
        "start": 751,
        "temperature": 0,
        "text": " But the information of the global arrangement of the scene is lost.",
        "tokens": [
          51014,
          583,
          264,
          1589,
          295,
          264,
          4338,
          17620,
          295,
          264,
          4145,
          307,
          2731,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21922619398250137,
        "compression_ratio": 1.3671875,
        "end": 772,
        "id": 145,
        "no_speech_prob": 0.037881966680288315,
        "seek": 75700,
        "start": 757,
        "temperature": 0,
        "text": " For example, for this image D and E, the style is very clear to us now, but we cannot see if there is a house on this photo anymore because the content representation is lost.",
        "tokens": [
          50364,
          1171,
          1365,
          11,
          337,
          341,
          3256,
          413,
          293,
          462,
          11,
          264,
          3758,
          307,
          588,
          1850,
          281,
          505,
          586,
          11,
          457,
          321,
          2644,
          536,
          498,
          456,
          307,
          257,
          1782,
          322,
          341,
          5052,
          3602,
          570,
          264,
          2701,
          10290,
          307,
          2731,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21213483002226233,
        "compression_ratio": 1.5732484076433122,
        "end": 783,
        "id": 146,
        "no_speech_prob": 0.01883087493479252,
        "seek": 77200,
        "start": 773,
        "temperature": 0,
        "text": " And then in the end, after we got the content representation of the photo and the style representation of this artwork,",
        "tokens": [
          50414,
          400,
          550,
          294,
          264,
          917,
          11,
          934,
          321,
          658,
          264,
          2701,
          10290,
          295,
          264,
          5052,
          293,
          264,
          3758,
          10290,
          295,
          341,
          15829,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.21213483002226233,
        "compression_ratio": 1.5732484076433122,
        "end": 790,
        "id": 147,
        "no_speech_prob": 0.01883087493479252,
        "seek": 77200,
        "start": 783,
        "temperature": 0,
        "text": " we're going to synthesize a new image that can match those two at the same time.",
        "tokens": [
          50914,
          321,
          434,
          516,
          281,
          26617,
          1125,
          257,
          777,
          3256,
          300,
          393,
          2995,
          729,
          732,
          412,
          264,
          912,
          565,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21213483002226233,
        "compression_ratio": 1.5732484076433122,
        "end": 794,
        "id": 148,
        "no_speech_prob": 0.01883087493479252,
        "seek": 77200,
        "start": 790,
        "temperature": 0,
        "text": " So this is basically how style transfer works.",
        "tokens": [
          51264,
          407,
          341,
          307,
          1936,
          577,
          3758,
          5003,
          1985,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2472677230834961,
        "compression_ratio": 1.2734375,
        "end": 814,
        "id": 149,
        "no_speech_prob": 0.0011877984507009387,
        "seek": 79400,
        "start": 794,
        "temperature": 0,
        "text": " And Gene Kogan, the creator of Machine Learning for Artists, he made this amazing demo video that talks about what convolutional neural networks see on each layer.",
        "tokens": [
          50364,
          400,
          18083,
          591,
          21576,
          11,
          264,
          14181,
          295,
          22155,
          15205,
          337,
          5735,
          1751,
          11,
          415,
          1027,
          341,
          2243,
          10723,
          960,
          300,
          6686,
          466,
          437,
          45216,
          304,
          18161,
          9590,
          536,
          322,
          1184,
          4583,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2565126419067383,
        "compression_ratio": 1.587878787878788,
        "end": 833,
        "id": 150,
        "no_speech_prob": 0.03621042147278786,
        "seek": 81400,
        "start": 814,
        "temperature": 0,
        "text": " So I think you would have a better understanding about how this convolutional neural network sees images and how it can filter out this image and get the feature representation out of one image after watching his video.",
        "tokens": [
          50364,
          407,
          286,
          519,
          291,
          576,
          362,
          257,
          1101,
          3701,
          466,
          577,
          341,
          45216,
          304,
          18161,
          3209,
          8194,
          5267,
          293,
          577,
          309,
          393,
          6608,
          484,
          341,
          3256,
          293,
          483,
          264,
          4111,
          10290,
          484,
          295,
          472,
          3256,
          934,
          1976,
          702,
          960,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2565126419067383,
        "compression_ratio": 1.587878787878788,
        "end": 836,
        "id": 151,
        "no_speech_prob": 0.03621042147278786,
        "seek": 81400,
        "start": 833,
        "temperature": 0,
        "text": " So I highly recommend you watch his video.",
        "tokens": [
          51314,
          407,
          286,
          5405,
          2748,
          291,
          1159,
          702,
          960,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22152368227640787,
        "compression_ratio": 1.5635359116022098,
        "end": 852,
        "id": 152,
        "no_speech_prob": 0.005468880292028189,
        "seek": 84400,
        "start": 845,
        "temperature": 0,
        "text": " And Gatti's paper opened up a brand new area of research.",
        "tokens": [
          50414,
          400,
          460,
          21515,
          311,
          3035,
          5625,
          493,
          257,
          3360,
          777,
          1859,
          295,
          2132,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22152368227640787,
        "compression_ratio": 1.5635359116022098,
        "end": 859,
        "id": 153,
        "no_speech_prob": 0.005468880292028189,
        "seek": 84400,
        "start": 852,
        "temperature": 0,
        "text": " So there are a lot of different kinds of style transfer appeared in the last three years.",
        "tokens": [
          50764,
          407,
          456,
          366,
          257,
          688,
          295,
          819,
          3685,
          295,
          3758,
          5003,
          8516,
          294,
          264,
          1036,
          1045,
          924,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22152368227640787,
        "compression_ratio": 1.5635359116022098,
        "end": 871,
        "id": 154,
        "no_speech_prob": 0.005468880292028189,
        "seek": 84400,
        "start": 859,
        "temperature": 0,
        "text": " We're going to quickly take a look at a few of them here, and then we're going to dive into train your style transfer model with Spell.",
        "tokens": [
          51114,
          492,
          434,
          516,
          281,
          2661,
          747,
          257,
          574,
          412,
          257,
          1326,
          295,
          552,
          510,
          11,
          293,
          550,
          321,
          434,
          516,
          281,
          9192,
          666,
          3847,
          428,
          3758,
          5003,
          2316,
          365,
          3550,
          285,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.25876445240444607,
        "compression_ratio": 1.535294117647059,
        "end": 872,
        "id": 155,
        "no_speech_prob": 0.0001233928051078692,
        "seek": 87100,
        "start": 871,
        "temperature": 0,
        "text": " So.",
        "tokens": [
          50364,
          407,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.25876445240444607,
        "compression_ratio": 1.535294117647059,
        "end": 878,
        "id": 156,
        "no_speech_prob": 0.0001233928051078692,
        "seek": 87100,
        "start": 875,
        "temperature": 0,
        "text": " In 2016, this paper came out.",
        "tokens": [
          50564,
          682,
          6549,
          11,
          341,
          3035,
          1361,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.25876445240444607,
        "compression_ratio": 1.535294117647059,
        "end": 883,
        "id": 157,
        "no_speech_prob": 0.0001233928051078692,
        "seek": 87100,
        "start": 880,
        "temperature": 0,
        "text": " It's called a fast style transfer.",
        "tokens": [
          50814,
          467,
          311,
          1219,
          257,
          2370,
          3758,
          5003,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25876445240444607,
        "compression_ratio": 1.535294117647059,
        "end": 891,
        "id": 158,
        "no_speech_prob": 0.0001233928051078692,
        "seek": 87100,
        "start": 884,
        "temperature": 0,
        "text": " It shows a neural network that can apply a fake style to any input image in real time.",
        "tokens": [
          51014,
          467,
          3110,
          257,
          18161,
          3209,
          300,
          393,
          3079,
          257,
          7592,
          3758,
          281,
          604,
          4846,
          3256,
          294,
          957,
          565,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.25876445240444607,
        "compression_ratio": 1.535294117647059,
        "end": 900,
        "id": 159,
        "no_speech_prob": 0.0001233928051078692,
        "seek": 87100,
        "start": 892,
        "temperature": 0,
        "text": " It builds on Gatti's style transfer model, but this network gives similar results, but it's a lot faster.",
        "tokens": [
          51414,
          467,
          15182,
          322,
          460,
          21515,
          311,
          3758,
          5003,
          2316,
          11,
          457,
          341,
          3209,
          2709,
          2531,
          3542,
          11,
          457,
          309,
          311,
          257,
          688,
          4663,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21978520373908841,
        "compression_ratio": 1.554054054054054,
        "end": 910,
        "id": 160,
        "no_speech_prob": 0.000570263946428895,
        "seek": 90100,
        "start": 901,
        "temperature": 0,
        "text": " This fast style transfer has image transformation network and a loss calculation network.",
        "tokens": [
          50364,
          639,
          2370,
          3758,
          5003,
          575,
          3256,
          9887,
          3209,
          293,
          257,
          4470,
          17108,
          3209,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21978520373908841,
        "compression_ratio": 1.554054054054054,
        "end": 921,
        "id": 161,
        "no_speech_prob": 0.000570263946428895,
        "seek": 90100,
        "start": 910,
        "temperature": 0,
        "text": " To train this network, we need to pick one fixed style image, and then we use a large batch of different content image as training examples.",
        "tokens": [
          50814,
          1407,
          3847,
          341,
          3209,
          11,
          321,
          643,
          281,
          1888,
          472,
          6806,
          3758,
          3256,
          11,
          293,
          550,
          321,
          764,
          257,
          2416,
          15245,
          295,
          819,
          2701,
          3256,
          382,
          3097,
          5110,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26989813108701965,
        "compression_ratio": 1.612565445026178,
        "end": 933,
        "id": 162,
        "no_speech_prob": 0.016655253246426582,
        "seek": 92100,
        "start": 922,
        "temperature": 0,
        "text": " So in their paper, they trained their network on this Microsoft Cocoa dataset, which is an object recognition dataset of 80,000 images.",
        "tokens": [
          50414,
          407,
          294,
          641,
          3035,
          11,
          436,
          8895,
          641,
          3209,
          322,
          341,
          8116,
          29787,
          64,
          28872,
          11,
          597,
          307,
          364,
          2657,
          11150,
          28872,
          295,
          4688,
          11,
          1360,
          5267,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26989813108701965,
        "compression_ratio": 1.612565445026178,
        "end": 943,
        "id": 163,
        "no_speech_prob": 0.016655253246426582,
        "seek": 92100,
        "start": 936,
        "temperature": 0,
        "text": " Today, we're going to use TensorFlow implementation of this fast style transfer.",
        "tokens": [
          51114,
          2692,
          11,
          321,
          434,
          516,
          281,
          764,
          37624,
          11420,
          295,
          341,
          2370,
          3758,
          5003,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26989813108701965,
        "compression_ratio": 1.612565445026178,
        "end": 946,
        "id": 164,
        "no_speech_prob": 0.016655253246426582,
        "seek": 92100,
        "start": 943,
        "temperature": 0,
        "text": " So we're also going to use this Cocoa dataset.",
        "tokens": [
          51464,
          407,
          321,
          434,
          611,
          516,
          281,
          764,
          341,
          29787,
          64,
          28872,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.26989813108701965,
        "compression_ratio": 1.612565445026178,
        "end": 948,
        "id": 165,
        "no_speech_prob": 0.016655253246426582,
        "seek": 92100,
        "start": 946,
        "temperature": 0,
        "text": " We are going to download this dataset later.",
        "tokens": [
          51614,
          492,
          366,
          516,
          281,
          5484,
          341,
          28872,
          1780,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24019391196114676,
        "compression_ratio": 1.564102564102564,
        "end": 953,
        "id": 166,
        "no_speech_prob": 0.00011774097947636619,
        "seek": 94800,
        "start": 949,
        "temperature": 0,
        "text": " And here is an image from their paper.",
        "tokens": [
          50414,
          400,
          510,
          307,
          364,
          3256,
          490,
          641,
          3035,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24019391196114676,
        "compression_ratio": 1.564102564102564,
        "end": 965,
        "id": 167,
        "no_speech_prob": 0.00011774097947636619,
        "seek": 94800,
        "start": 954,
        "temperature": 0,
        "text": " So this is the original photo, and this is Gatti's result, and this is the fast style transfer's result, and it works a lot faster.",
        "tokens": [
          50664,
          407,
          341,
          307,
          264,
          3380,
          5052,
          11,
          293,
          341,
          307,
          460,
          21515,
          311,
          1874,
          11,
          293,
          341,
          307,
          264,
          2370,
          3758,
          5003,
          311,
          1874,
          11,
          293,
          309,
          1985,
          257,
          688,
          4663,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24019391196114676,
        "compression_ratio": 1.564102564102564,
        "end": 968,
        "id": 168,
        "no_speech_prob": 0.00011774097947636619,
        "seek": 94800,
        "start": 967,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          51314,
          400,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24019391196114676,
        "compression_ratio": 1.564102564102564,
        "end": 973,
        "id": 169,
        "no_speech_prob": 0.00011774097947636619,
        "seek": 94800,
        "start": 970,
        "temperature": 0,
        "text": " The next style transfer is for videos.",
        "tokens": [
          51464,
          440,
          958,
          3758,
          5003,
          307,
          337,
          2145,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24019391196114676,
        "compression_ratio": 1.564102564102564,
        "end": 977,
        "id": 170,
        "no_speech_prob": 0.00011774097947636619,
        "seek": 94800,
        "start": 973,
        "temperature": 0,
        "text": " This model came in 2016, too.",
        "tokens": [
          51614,
          639,
          2316,
          1361,
          294,
          6549,
          11,
          886,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23036306782772667,
        "compression_ratio": 1.6230366492146597,
        "end": 994,
        "id": 171,
        "no_speech_prob": 0.00003647810444817878,
        "seek": 97800,
        "start": 978,
        "temperature": 0,
        "text": " We might think we already know how to transfer images, so for videos, we can just transfer each frame of the video one by one and then stitch all those images together to make a transferred video.",
        "tokens": [
          50364,
          492,
          1062,
          519,
          321,
          1217,
          458,
          577,
          281,
          5003,
          5267,
          11,
          370,
          337,
          2145,
          11,
          321,
          393,
          445,
          5003,
          1184,
          3920,
          295,
          264,
          960,
          472,
          538,
          472,
          293,
          550,
          5635,
          439,
          729,
          5267,
          1214,
          281,
          652,
          257,
          15809,
          960,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23036306782772667,
        "compression_ratio": 1.6230366492146597,
        "end": 1002,
        "id": 172,
        "no_speech_prob": 0.00003647810444817878,
        "seek": 97800,
        "start": 995,
        "temperature": 0,
        "text": " That could work, but if we do that, we can see the result is not good because.",
        "tokens": [
          51214,
          663,
          727,
          589,
          11,
          457,
          498,
          321,
          360,
          300,
          11,
          321,
          393,
          536,
          264,
          1874,
          307,
          406,
          665,
          570,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23036306782772667,
        "compression_ratio": 1.6230366492146597,
        "end": 1006,
        "id": 173,
        "no_speech_prob": 0.00003647810444817878,
        "seek": 97800,
        "start": 1004,
        "temperature": 0,
        "text": " The video will flicker a lot here.",
        "tokens": [
          51664,
          440,
          960,
          486,
          22774,
          260,
          257,
          688,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2764743902744391,
        "compression_ratio": 1.2586206896551724,
        "end": 1017,
        "id": 174,
        "no_speech_prob": 0.0001141220418503508,
        "seek": 100800,
        "start": 1008,
        "temperature": 0,
        "text": " That's because the machine doesn't know any information about the previous image.",
        "tokens": [
          50364,
          663,
          311,
          570,
          264,
          3479,
          1177,
          380,
          458,
          604,
          1589,
          466,
          264,
          3894,
          3256,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2764743902744391,
        "compression_ratio": 1.2586206896551724,
        "end": 1023,
        "id": 175,
        "no_speech_prob": 0.0001141220418503508,
        "seek": 100800,
        "start": 1018,
        "temperature": 0,
        "text": " So you can see if we just do that, the video will flicker a lot.",
        "tokens": [
          50864,
          407,
          291,
          393,
          536,
          498,
          321,
          445,
          360,
          300,
          11,
          264,
          960,
          486,
          22774,
          260,
          257,
          688,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2672475775082906,
        "compression_ratio": 1.4429530201342282,
        "end": 1025,
        "id": 176,
        "no_speech_prob": 0.018545502796769142,
        "seek": 102300,
        "start": 1024,
        "temperature": 0,
        "text": " But this model.",
        "tokens": [
          50414,
          583,
          341,
          2316,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2672475775082906,
        "compression_ratio": 1.4429530201342282,
        "end": 1041,
        "id": 177,
        "no_speech_prob": 0.018545502796769142,
        "seek": 102300,
        "start": 1028,
        "temperature": 0,
        "text": " This paper improved this frame to frame stability by adding an optical flow algorithm that tells the machine the possible motion from one frame to the next frame.",
        "tokens": [
          50614,
          639,
          3035,
          9689,
          341,
          3920,
          281,
          3920,
          11826,
          538,
          5127,
          364,
          20674,
          3095,
          9284,
          300,
          5112,
          264,
          3479,
          264,
          1944,
          5394,
          490,
          472,
          3920,
          281,
          264,
          958,
          3920,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2672475775082906,
        "compression_ratio": 1.4429530201342282,
        "end": 1044,
        "id": 178,
        "no_speech_prob": 0.018545502796769142,
        "seek": 102300,
        "start": 1042,
        "temperature": 0,
        "text": " It's also called temporary coherent.",
        "tokens": [
          51314,
          467,
          311,
          611,
          1219,
          13413,
          36239,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1046,
        "id": 179,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1045,
        "temperature": 0,
        "text": " So this transferred.",
        "tokens": [
          50414,
          407,
          341,
          15809,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1048,
        "id": 180,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1047,
        "temperature": 0,
        "text": " Also, this.",
        "tokens": [
          50514,
          2743,
          11,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1056,
        "id": 181,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1050,
        "temperature": 0,
        "text": " This transfer video wouldn't be flickered too much, so we can see some results here.",
        "tokens": [
          50664,
          639,
          5003,
          960,
          2759,
          380,
          312,
          22774,
          4073,
          886,
          709,
          11,
          370,
          321,
          393,
          536,
          512,
          3542,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1063,
        "id": 182,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1056,
        "temperature": 0,
        "text": " See, this video is not flickering at all, and they got amazing results.",
        "tokens": [
          50964,
          3008,
          11,
          341,
          960,
          307,
          406,
          22774,
          1794,
          412,
          439,
          11,
          293,
          436,
          658,
          2243,
          3542,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1066,
        "id": 183,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1065,
        "temperature": 0,
        "text": " From their model.",
        "tokens": [
          51414,
          3358,
          641,
          2316,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1069,
        "id": 184,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1067,
        "temperature": 0,
        "text": " This is the transferred video.",
        "tokens": [
          51514,
          639,
          307,
          264,
          15809,
          960,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.30960353645118505,
        "compression_ratio": 1.607361963190184,
        "end": 1071,
        "id": 185,
        "no_speech_prob": 0.007120911031961441,
        "seek": 104400,
        "start": 1070,
        "temperature": 0,
        "text": " The result looks great.",
        "tokens": [
          51664,
          440,
          1874,
          1542,
          869,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.33426214519299957,
        "compression_ratio": 1.1386138613861385,
        "end": 1075,
        "id": 186,
        "no_speech_prob": 0.00007602450205013156,
        "seek": 107400,
        "start": 1074,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.33426214519299957,
        "compression_ratio": 1.1386138613861385,
        "end": 1084,
        "id": 187,
        "no_speech_prob": 0.00007602450205013156,
        "seek": 107400,
        "start": 1082,
        "temperature": 0,
        "text": " Let's go to the next model.",
        "tokens": [
          50764,
          961,
          311,
          352,
          281,
          264,
          958,
          2316,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.33426214519299957,
        "compression_ratio": 1.1386138613861385,
        "end": 1094,
        "id": 188,
        "no_speech_prob": 0.00007602450205013156,
        "seek": 107400,
        "start": 1090,
        "temperature": 0,
        "text": " So this is a really cool model appeared in 2017.",
        "tokens": [
          51164,
          407,
          341,
          307,
          257,
          534,
          1627,
          2316,
          8516,
          294,
          6591,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.33426214519299957,
        "compression_ratio": 1.1386138613861385,
        "end": 1097,
        "id": 189,
        "no_speech_prob": 0.00007602450205013156,
        "seek": 107400,
        "start": 1095,
        "temperature": 0,
        "text": " It's called deep photo transfer.",
        "tokens": [
          51414,
          467,
          311,
          1219,
          2452,
          5052,
          5003,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.28205370903015137,
        "compression_ratio": 1.5989304812834224,
        "end": 1111,
        "id": 190,
        "no_speech_prob": 0.0002002716064453125,
        "seek": 109700,
        "start": 1097,
        "temperature": 0,
        "text": " The style transfer that we saw before work really well if we're looking for some artistic painting results because they always add some like distortion of the original image.",
        "tokens": [
          50364,
          440,
          3758,
          5003,
          300,
          321,
          1866,
          949,
          589,
          534,
          731,
          498,
          321,
          434,
          1237,
          337,
          512,
          17090,
          5370,
          3542,
          570,
          436,
          1009,
          909,
          512,
          411,
          28426,
          295,
          264,
          3380,
          3256,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.28205370903015137,
        "compression_ratio": 1.5989304812834224,
        "end": 1114,
        "id": 191,
        "no_speech_prob": 0.0002002716064453125,
        "seek": 109700,
        "start": 1112,
        "temperature": 0,
        "text": " So they don't really look realistic.",
        "tokens": [
          51114,
          407,
          436,
          500,
          380,
          534,
          574,
          12465,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.28205370903015137,
        "compression_ratio": 1.5989304812834224,
        "end": 1123,
        "id": 192,
        "no_speech_prob": 0.0002002716064453125,
        "seek": 109700,
        "start": 1114,
        "temperature": 0,
        "text": " But this model, this deep style, deep photo transfer can produce very realistic photos.",
        "tokens": [
          51214,
          583,
          341,
          2316,
          11,
          341,
          2452,
          3758,
          11,
          2452,
          5052,
          5003,
          393,
          5258,
          588,
          12465,
          5787,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24021766369159406,
        "compression_ratio": 1.6666666666666667,
        "end": 1129,
        "id": 193,
        "no_speech_prob": 0.0002492281491868198,
        "seek": 112300,
        "start": 1124,
        "temperature": 0,
        "text": " You can see this is the input image on the left.",
        "tokens": [
          50414,
          509,
          393,
          536,
          341,
          307,
          264,
          4846,
          3256,
          322,
          264,
          1411,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24021766369159406,
        "compression_ratio": 1.6666666666666667,
        "end": 1133,
        "id": 194,
        "no_speech_prob": 0.0002492281491868198,
        "seek": 112300,
        "start": 1130,
        "temperature": 0,
        "text": " And in the middle, this is the style image.",
        "tokens": [
          50714,
          400,
          294,
          264,
          2808,
          11,
          341,
          307,
          264,
          3758,
          3256,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24021766369159406,
        "compression_ratio": 1.6666666666666667,
        "end": 1138,
        "id": 195,
        "no_speech_prob": 0.0002492281491868198,
        "seek": 112300,
        "start": 1134,
        "temperature": 0,
        "text": " And then on the right, this is the output image.",
        "tokens": [
          50914,
          400,
          550,
          322,
          264,
          558,
          11,
          341,
          307,
          264,
          5598,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24021766369159406,
        "compression_ratio": 1.6666666666666667,
        "end": 1141,
        "id": 196,
        "no_speech_prob": 0.0002492281491868198,
        "seek": 112300,
        "start": 1138,
        "temperature": 0,
        "text": " The output image look like a regular photo to me.",
        "tokens": [
          51114,
          440,
          5598,
          3256,
          574,
          411,
          257,
          3890,
          5052,
          281,
          385,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24021766369159406,
        "compression_ratio": 1.6666666666666667,
        "end": 1143,
        "id": 197,
        "no_speech_prob": 0.0002492281491868198,
        "seek": 112300,
        "start": 1142,
        "temperature": 0,
        "text": " So the result is super good.",
        "tokens": [
          51314,
          407,
          264,
          1874,
          307,
          1687,
          665,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2198701131911505,
        "compression_ratio": 1.6785714285714286,
        "end": 1154,
        "id": 198,
        "no_speech_prob": 0.014502808451652527,
        "seek": 114300,
        "start": 1144,
        "temperature": 0,
        "text": " They use something called a fine transformation to make sure that the shapes are not distorted during the transformation process.",
        "tokens": [
          50414,
          814,
          764,
          746,
          1219,
          257,
          2489,
          9887,
          281,
          652,
          988,
          300,
          264,
          10854,
          366,
          406,
          33431,
          1830,
          264,
          9887,
          1399,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2198701131911505,
        "compression_ratio": 1.6785714285714286,
        "end": 1158,
        "id": 199,
        "no_speech_prob": 0.014502808451652527,
        "seek": 114300,
        "start": 1155,
        "temperature": 0,
        "text": " And the result is just amazing.",
        "tokens": [
          50964,
          400,
          264,
          1874,
          307,
          445,
          2243,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2198701131911505,
        "compression_ratio": 1.6785714285714286,
        "end": 1164,
        "id": 200,
        "no_speech_prob": 0.014502808451652527,
        "seek": 114300,
        "start": 1161,
        "temperature": 0,
        "text": " And this is the next style transfer.",
        "tokens": [
          51264,
          400,
          341,
          307,
          264,
          958,
          3758,
          5003,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2198701131911505,
        "compression_ratio": 1.6785714285714286,
        "end": 1166,
        "id": 201,
        "no_speech_prob": 0.014502808451652527,
        "seek": 114300,
        "start": 1164,
        "temperature": 0,
        "text": " It's called semantic style transfer.",
        "tokens": [
          51414,
          467,
          311,
          1219,
          47982,
          3758,
          5003,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2198701131911505,
        "compression_ratio": 1.6785714285714286,
        "end": 1171,
        "id": 202,
        "no_speech_prob": 0.014502808451652527,
        "seek": 114300,
        "start": 1168,
        "temperature": 0,
        "text": " It can produce semantically meaningful result.",
        "tokens": [
          51614,
          467,
          393,
          5258,
          4361,
          49505,
          10995,
          1874,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2503366955256058,
        "compression_ratio": 1.5454545454545454,
        "end": 1177,
        "id": 203,
        "no_speech_prob": 0.0001141194297815673,
        "seek": 117100,
        "start": 1172,
        "temperature": 0,
        "text": " The machine has an understanding of the objects on the images.",
        "tokens": [
          50414,
          440,
          3479,
          575,
          364,
          3701,
          295,
          264,
          6565,
          322,
          264,
          5267,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2503366955256058,
        "compression_ratio": 1.5454545454545454,
        "end": 1185,
        "id": 204,
        "no_speech_prob": 0.0001141194297815673,
        "seek": 117100,
        "start": 1177,
        "temperature": 0,
        "text": " For example, on this image, the machine recognize that both image have nodes.",
        "tokens": [
          50664,
          1171,
          1365,
          11,
          322,
          341,
          3256,
          11,
          264,
          3479,
          5521,
          300,
          1293,
          3256,
          362,
          13891,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2503366955256058,
        "compression_ratio": 1.5454545454545454,
        "end": 1191,
        "id": 205,
        "no_speech_prob": 0.0001141194297815673,
        "seek": 117100,
        "start": 1186,
        "temperature": 0,
        "text": " So it uses this information during the transformation process.",
        "tokens": [
          51114,
          407,
          309,
          4960,
          341,
          1589,
          1830,
          264,
          9887,
          1399,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2503366955256058,
        "compression_ratio": 1.5454545454545454,
        "end": 1196,
        "id": 206,
        "no_speech_prob": 0.0001141194297815673,
        "seek": 117100,
        "start": 1192,
        "temperature": 0,
        "text": " And there are a lot of applications for this model.",
        "tokens": [
          51414,
          400,
          456,
          366,
          257,
          688,
          295,
          5821,
          337,
          341,
          2316,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21324820085005328,
        "compression_ratio": 1.4893617021276595,
        "end": 1202,
        "id": 207,
        "no_speech_prob": 0.00008614340185886249,
        "seek": 119600,
        "start": 1196,
        "temperature": 0,
        "text": " You can convert a sketch or painting to a photo.",
        "tokens": [
          50364,
          509,
          393,
          7620,
          257,
          12325,
          420,
          5370,
          281,
          257,
          5052,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21324820085005328,
        "compression_ratio": 1.4893617021276595,
        "end": 1207,
        "id": 208,
        "no_speech_prob": 0.00008614340185886249,
        "seek": 119600,
        "start": 1203,
        "temperature": 0,
        "text": " And I think the output is pretty good.",
        "tokens": [
          50714,
          400,
          286,
          519,
          264,
          5598,
          307,
          1238,
          665,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21324820085005328,
        "compression_ratio": 1.4893617021276595,
        "end": 1210,
        "id": 209,
        "no_speech_prob": 0.00008614340185886249,
        "seek": 119600,
        "start": 1208,
        "temperature": 0,
        "text": " So this is semantic style transfer.",
        "tokens": [
          50964,
          407,
          341,
          307,
          47982,
          3758,
          5003,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21324820085005328,
        "compression_ratio": 1.4893617021276595,
        "end": 1216,
        "id": 210,
        "no_speech_prob": 0.00008614340185886249,
        "seek": 119600,
        "start": 1213,
        "temperature": 0,
        "text": " The last style transfer is very special.",
        "tokens": [
          51214,
          440,
          1036,
          3758,
          5003,
          307,
          588,
          2121,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21324820085005328,
        "compression_ratio": 1.4893617021276595,
        "end": 1221,
        "id": 211,
        "no_speech_prob": 0.00008614340185886249,
        "seek": 119600,
        "start": 1217,
        "temperature": 0,
        "text": " It is called universal neural style transfer.",
        "tokens": [
          51414,
          467,
          307,
          1219,
          11455,
          18161,
          3758,
          5003,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2657826940218608,
        "compression_ratio": 1.4133333333333333,
        "end": 1232,
        "id": 212,
        "no_speech_prob": 0.0017819362692534924,
        "seek": 122100,
        "start": 1221,
        "temperature": 0,
        "text": " Almost all the previous style transfer that we talked about, there are always some abstract style image that doesn't really work well.",
        "tokens": [
          50364,
          12627,
          439,
          264,
          3894,
          3758,
          5003,
          300,
          321,
          2825,
          466,
          11,
          456,
          366,
          1009,
          512,
          12649,
          3758,
          3256,
          300,
          1177,
          380,
          534,
          589,
          731,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2657826940218608,
        "compression_ratio": 1.4133333333333333,
        "end": 1240,
        "id": 213,
        "no_speech_prob": 0.0017819362692534924,
        "seek": 122100,
        "start": 1233,
        "temperature": 0,
        "text": " For example, if the style image is just a black line with a white background,",
        "tokens": [
          50964,
          1171,
          1365,
          11,
          498,
          264,
          3758,
          3256,
          307,
          445,
          257,
          2211,
          1622,
          365,
          257,
          2418,
          3678,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.22995463504066951,
        "compression_ratio": 1.7,
        "end": 1251,
        "id": 214,
        "no_speech_prob": 0.003075108164921403,
        "seek": 124000,
        "start": 1240,
        "temperature": 0,
        "text": " because our model is trained on a lot of objects, images, it cannot get too much information from a line.",
        "tokens": [
          50364,
          570,
          527,
          2316,
          307,
          8895,
          322,
          257,
          688,
          295,
          6565,
          11,
          5267,
          11,
          309,
          2644,
          483,
          886,
          709,
          1589,
          490,
          257,
          1622,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22995463504066951,
        "compression_ratio": 1.7,
        "end": 1253,
        "id": 215,
        "no_speech_prob": 0.003075108164921403,
        "seek": 124000,
        "start": 1251,
        "temperature": 0,
        "text": " Because it's trained on objects.",
        "tokens": [
          50914,
          1436,
          309,
          311,
          8895,
          322,
          6565,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22995463504066951,
        "compression_ratio": 1.7,
        "end": 1257,
        "id": 216,
        "no_speech_prob": 0.003075108164921403,
        "seek": 124000,
        "start": 1254,
        "temperature": 0,
        "text": " But this model can solve this issue.",
        "tokens": [
          51064,
          583,
          341,
          2316,
          393,
          5039,
          341,
          2734,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22995463504066951,
        "compression_ratio": 1.7,
        "end": 1265,
        "id": 217,
        "no_speech_prob": 0.003075108164921403,
        "seek": 124000,
        "start": 1257,
        "temperature": 0,
        "text": " This new model is also based on neural networks, but it doesn't need to be trained on any images.",
        "tokens": [
          51214,
          639,
          777,
          2316,
          307,
          611,
          2361,
          322,
          18161,
          9590,
          11,
          457,
          309,
          1177,
          380,
          643,
          281,
          312,
          8895,
          322,
          604,
          5267,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22995463504066951,
        "compression_ratio": 1.7,
        "end": 1268,
        "id": 218,
        "no_speech_prob": 0.003075108164921403,
        "seek": 124000,
        "start": 1265,
        "temperature": 0,
        "text": " It works on any arbitrary image.",
        "tokens": [
          51614,
          467,
          1985,
          322,
          604,
          23211,
          3256,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.24888602547023608,
        "compression_ratio": 1.6402877697841727,
        "end": 1272,
        "id": 219,
        "no_speech_prob": 0.00045824903645552695,
        "seek": 126800,
        "start": 1268,
        "temperature": 0,
        "text": " It uses something called auto encoder.",
        "tokens": [
          50364,
          467,
          4960,
          746,
          1219,
          8399,
          2058,
          19866,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24888602547023608,
        "compression_ratio": 1.6402877697841727,
        "end": 1275,
        "id": 220,
        "no_speech_prob": 0.00045824903645552695,
        "seek": 126800,
        "start": 1273,
        "temperature": 0,
        "text": " The encoder has two parts.",
        "tokens": [
          50614,
          440,
          2058,
          19866,
          575,
          732,
          3166,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24888602547023608,
        "compression_ratio": 1.6402877697841727,
        "end": 1280,
        "id": 221,
        "no_speech_prob": 0.00045824903645552695,
        "seek": 126800,
        "start": 1275,
        "temperature": 0,
        "text": " It can encode something and then it can decode it.",
        "tokens": [
          50714,
          467,
          393,
          2058,
          1429,
          746,
          293,
          550,
          309,
          393,
          979,
          1429,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24888602547023608,
        "compression_ratio": 1.6402877697841727,
        "end": 1284,
        "id": 222,
        "no_speech_prob": 0.00045824903645552695,
        "seek": 126800,
        "start": 1280,
        "temperature": 0,
        "text": " So we put our input image in and then it will encode it.",
        "tokens": [
          50964,
          407,
          321,
          829,
          527,
          4846,
          3256,
          294,
          293,
          550,
          309,
          486,
          2058,
          1429,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24888602547023608,
        "compression_ratio": 1.6402877697841727,
        "end": 1289,
        "id": 223,
        "no_speech_prob": 0.00045824903645552695,
        "seek": 126800,
        "start": 1284,
        "temperature": 0,
        "text": " And then after it decoded, it can give back the image.",
        "tokens": [
          51164,
          400,
          550,
          934,
          309,
          979,
          12340,
          11,
          309,
          393,
          976,
          646,
          264,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24593642905906396,
        "compression_ratio": 1.5078125,
        "end": 1301,
        "id": 224,
        "no_speech_prob": 0.0008830279111862183,
        "seek": 128900,
        "start": 1290,
        "temperature": 0,
        "text": " The idea is to use the encoder on both this style image and also this input image.",
        "tokens": [
          50414,
          440,
          1558,
          307,
          281,
          764,
          264,
          2058,
          19866,
          322,
          1293,
          341,
          3758,
          3256,
          293,
          611,
          341,
          4846,
          3256,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24593642905906396,
        "compression_ratio": 1.5078125,
        "end": 1309,
        "id": 225,
        "no_speech_prob": 0.0008830279111862183,
        "seek": 128900,
        "start": 1301,
        "temperature": 0,
        "text": " And then use the decoder to decode a compressed version of those two.",
        "tokens": [
          50964,
          400,
          550,
          764,
          264,
          979,
          19866,
          281,
          979,
          1429,
          257,
          30353,
          3037,
          295,
          729,
          732,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24593642905906396,
        "compression_ratio": 1.5078125,
        "end": 1312,
        "id": 226,
        "no_speech_prob": 0.0008830279111862183,
        "seek": 128900,
        "start": 1309,
        "temperature": 0,
        "text": " And in the end, you can get this result.",
        "tokens": [
          51364,
          400,
          294,
          264,
          917,
          11,
          291,
          393,
          483,
          341,
          1874,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2460878160264757,
        "compression_ratio": 1.443298969072165,
        "end": 1316,
        "id": 227,
        "no_speech_prob": 0.0001881387288449332,
        "seek": 131200,
        "start": 1313,
        "temperature": 0,
        "text": " And this is truly amazing.",
        "tokens": [
          50414,
          400,
          341,
          307,
          4908,
          2243,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2460878160264757,
        "compression_ratio": 1.443298969072165,
        "end": 1322,
        "id": 228,
        "no_speech_prob": 0.0001881387288449332,
        "seek": 131200,
        "start": 1316,
        "temperature": 0,
        "text": " And I think in the future, we should port this to ML5.js so we can all play with it.",
        "tokens": [
          50564,
          400,
          286,
          519,
          294,
          264,
          2027,
          11,
          321,
          820,
          2436,
          341,
          281,
          21601,
          20,
          13,
          25530,
          370,
          321,
          393,
          439,
          862,
          365,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2460878160264757,
        "compression_ratio": 1.443298969072165,
        "end": 1332,
        "id": 229,
        "no_speech_prob": 0.0001881387288449332,
        "seek": 131200,
        "start": 1326,
        "temperature": 0,
        "text": " So here are all those style transfer models that we talked about.",
        "tokens": [
          51064,
          407,
          510,
          366,
          439,
          729,
          3758,
          5003,
          5245,
          300,
          321,
          2825,
          466,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2460878160264757,
        "compression_ratio": 1.443298969072165,
        "end": 1340,
        "id": 230,
        "no_speech_prob": 0.0001881387288449332,
        "seek": 131200,
        "start": 1332,
        "temperature": 0,
        "text": " Today we're going to use the TensorFlow implementation that is a combination of Getty's style transfer",
        "tokens": [
          51364,
          2692,
          321,
          434,
          516,
          281,
          764,
          264,
          37624,
          11420,
          300,
          307,
          257,
          6562,
          295,
          3240,
          874,
          311,
          3758,
          5003,
          51764
        ]
      },
      {
        "avg_logprob": -0.27130722999572754,
        "compression_ratio": 1.3695652173913044,
        "end": 1346,
        "id": 231,
        "no_speech_prob": 0.00010229848703602329,
        "seek": 134000,
        "start": 1340,
        "temperature": 0,
        "text": " and the FastL transfer and the instance normalization.",
        "tokens": [
          50364,
          293,
          264,
          15968,
          43,
          5003,
          293,
          264,
          5197,
          2710,
          2144,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.27130722999572754,
        "compression_ratio": 1.3695652173913044,
        "end": 1354,
        "id": 232,
        "no_speech_prob": 0.00010229848703602329,
        "seek": 134000,
        "start": 1346,
        "temperature": 0,
        "text": " This TensorFlow implementation of FastL transfer is made by Logan Inkstorm.",
        "tokens": [
          50664,
          639,
          37624,
          11420,
          295,
          15968,
          43,
          5003,
          307,
          1027,
          538,
          22689,
          31147,
          17367,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.27130722999572754,
        "compression_ratio": 1.3695652173913044,
        "end": 1363,
        "id": 233,
        "no_speech_prob": 0.00010229848703602329,
        "seek": 134000,
        "start": 1354,
        "temperature": 0,
        "text": " Make sure if we use this code, we can give credits to him.",
        "tokens": [
          51064,
          4387,
          988,
          498,
          321,
          764,
          341,
          3089,
          11,
          321,
          393,
          976,
          16816,
          281,
          796,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24452342725779913,
        "compression_ratio": 1.617283950617284,
        "end": 1373,
        "id": 234,
        "no_speech_prob": 0.0004583053814712912,
        "seek": 136300,
        "start": 1363,
        "temperature": 0,
        "text": " And finally, we're going to train our style transfer model with Spell.",
        "tokens": [
          50364,
          400,
          2721,
          11,
          321,
          434,
          516,
          281,
          3847,
          527,
          3758,
          5003,
          2316,
          365,
          3550,
          285,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24452342725779913,
        "compression_ratio": 1.617283950617284,
        "end": 1379,
        "id": 235,
        "no_speech_prob": 0.0004583053814712912,
        "seek": 136300,
        "start": 1377,
        "temperature": 0,
        "text": " There are four steps.",
        "tokens": [
          51064,
          821,
          366,
          1451,
          4439,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24452342725779913,
        "compression_ratio": 1.617283950617284,
        "end": 1383,
        "id": 236,
        "no_speech_prob": 0.0004583053814712912,
        "seek": 136300,
        "start": 1379,
        "temperature": 0,
        "text": " So at first, we're going to prepare our environment.",
        "tokens": [
          51164,
          407,
          412,
          700,
          11,
          321,
          434,
          516,
          281,
          5940,
          527,
          2823,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24452342725779913,
        "compression_ratio": 1.617283950617284,
        "end": 1385,
        "id": 237,
        "no_speech_prob": 0.0004583053814712912,
        "seek": 136300,
        "start": 1383,
        "temperature": 0,
        "text": " We're going to download the dataset.",
        "tokens": [
          51364,
          492,
          434,
          516,
          281,
          5484,
          264,
          28872,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24452342725779913,
        "compression_ratio": 1.617283950617284,
        "end": 1392,
        "id": 238,
        "no_speech_prob": 0.0004583053814712912,
        "seek": 136300,
        "start": 1385,
        "temperature": 0,
        "text": " Because we use the VGG model and the Cocoa dataset, the Cocoa dataset is large.",
        "tokens": [
          51464,
          1436,
          321,
          764,
          264,
          691,
          27561,
          2316,
          293,
          264,
          29787,
          64,
          28872,
          11,
          264,
          29787,
          64,
          28872,
          307,
          2416,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19241572589409062,
        "compression_ratio": 1.5794871794871794,
        "end": 1396,
        "id": 239,
        "no_speech_prob": 0.00014201969315763563,
        "seek": 139200,
        "start": 1392,
        "temperature": 0,
        "text": " So it might take like one hour to finish this run.",
        "tokens": [
          50364,
          407,
          309,
          1062,
          747,
          411,
          472,
          1773,
          281,
          2413,
          341,
          1190,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19241572589409062,
        "compression_ratio": 1.5794871794871794,
        "end": 1403,
        "id": 240,
        "no_speech_prob": 0.00014201969315763563,
        "seek": 139200,
        "start": 1396,
        "temperature": 0,
        "text": " And then we're going to run this style Python script to train the model.",
        "tokens": [
          50564,
          400,
          550,
          321,
          434,
          516,
          281,
          1190,
          341,
          3758,
          15329,
          5755,
          281,
          3847,
          264,
          2316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19241572589409062,
        "compression_ratio": 1.5794871794871794,
        "end": 1410,
        "id": 241,
        "no_speech_prob": 0.00014201969315763563,
        "seek": 139200,
        "start": 1403,
        "temperature": 0,
        "text": " I think it will take about two hours and six minutes.",
        "tokens": [
          50914,
          286,
          519,
          309,
          486,
          747,
          466,
          732,
          2496,
          293,
          2309,
          2077,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19241572589409062,
        "compression_ratio": 1.5794871794871794,
        "end": 1420,
        "id": 242,
        "no_speech_prob": 0.00014201969315763563,
        "seek": 139200,
        "start": 1410,
        "temperature": 0,
        "text": " And then in the end, we're going to convert this TensorFlow saved model into a format that we can use in TensorFlow.js and ML5.js.",
        "tokens": [
          51264,
          400,
          550,
          294,
          264,
          917,
          11,
          321,
          434,
          516,
          281,
          7620,
          341,
          37624,
          6624,
          2316,
          666,
          257,
          7877,
          300,
          321,
          393,
          764,
          294,
          37624,
          13,
          25530,
          293,
          21601,
          20,
          13,
          25530,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.27296557029088336,
        "compression_ratio": 1.3697478991596639,
        "end": 1425,
        "id": 243,
        "no_speech_prob": 0.0019264330621808767,
        "seek": 142000,
        "start": 1421,
        "temperature": 0,
        "text": " And here is a detailed instruction here.",
        "tokens": [
          50414,
          400,
          510,
          307,
          257,
          9942,
          10951,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27296557029088336,
        "compression_ratio": 1.3697478991596639,
        "end": 1430,
        "id": 244,
        "no_speech_prob": 0.0019264330621808767,
        "seek": 142000,
        "start": 1425,
        "temperature": 0,
        "text": " If you're curious, you can go there and read the readme there.",
        "tokens": [
          50614,
          759,
          291,
          434,
          6369,
          11,
          291,
          393,
          352,
          456,
          293,
          1401,
          264,
          1401,
          1398,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.27296557029088336,
        "compression_ratio": 1.3697478991596639,
        "end": 1435,
        "id": 245,
        "no_speech_prob": 0.0019264330621808767,
        "seek": 142000,
        "start": 1430,
        "temperature": 0,
        "text": " And for step one, two, three, you can also check out the...",
        "tokens": [
          50864,
          400,
          337,
          1823,
          472,
          11,
          732,
          11,
          1045,
          11,
          291,
          393,
          611,
          1520,
          484,
          264,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.39859460039836603,
        "compression_ratio": 1.6836158192090396,
        "end": 1436,
        "id": 246,
        "no_speech_prob": 0.003123061964288354,
        "seek": 143500,
        "start": 1435,
        "temperature": 0,
        "text": " Quick break here.",
        "tokens": [
          50364,
          12101,
          1821,
          510,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.39859460039836603,
        "compression_ratio": 1.6836158192090396,
        "end": 1437,
        "id": 247,
        "no_speech_prob": 0.003123061964288354,
        "seek": 143500,
        "start": 1436,
        "temperature": 0,
        "text": " There you go.",
        "tokens": [
          50414,
          821,
          291,
          352,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.39859460039836603,
        "compression_ratio": 1.6836158192090396,
        "end": 1445,
        "id": 248,
        "no_speech_prob": 0.003123061964288354,
        "seek": 143500,
        "start": 1437,
        "temperature": 0,
        "text": " And for step one, two, three, you can also check out Spell's transferring style transfer tutorial.",
        "tokens": [
          50464,
          400,
          337,
          1823,
          472,
          11,
          732,
          11,
          1045,
          11,
          291,
          393,
          611,
          1520,
          484,
          3550,
          285,
          311,
          31437,
          3758,
          5003,
          7073,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.39859460039836603,
        "compression_ratio": 1.6836158192090396,
        "end": 1454,
        "id": 249,
        "no_speech_prob": 0.003123061964288354,
        "seek": 143500,
        "start": 1445,
        "temperature": 0,
        "text": " And you can also set notifications on Spell to tell you if the run takes a long time.",
        "tokens": [
          50864,
          400,
          291,
          393,
          611,
          992,
          13426,
          322,
          3550,
          285,
          281,
          980,
          291,
          498,
          264,
          1190,
          2516,
          257,
          938,
          565,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.39859460039836603,
        "compression_ratio": 1.6836158192090396,
        "end": 1456,
        "id": 250,
        "no_speech_prob": 0.003123061964288354,
        "seek": 143500,
        "start": 1454,
        "temperature": 0,
        "text": " But I will talk about this later.",
        "tokens": [
          51314,
          583,
          286,
          486,
          751,
          466,
          341,
          1780,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.39859460039836603,
        "compression_ratio": 1.6836158192090396,
        "end": 1460,
        "id": 251,
        "no_speech_prob": 0.003123061964288354,
        "seek": 143500,
        "start": 1456,
        "temperature": 0,
        "text": " And you can also set notifications on the code.",
        "tokens": [
          51414,
          400,
          291,
          393,
          611,
          992,
          13426,
          322,
          264,
          3089,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2645248868572178,
        "compression_ratio": 1.481012658227848,
        "end": 1464,
        "id": 252,
        "no_speech_prob": 0.07262393087148666,
        "seek": 146000,
        "start": 1460,
        "temperature": 0,
        "text": " The run takes a long time, but I will talk about this later.",
        "tokens": [
          50364,
          440,
          1190,
          2516,
          257,
          938,
          565,
          11,
          457,
          286,
          486,
          751,
          466,
          341,
          1780,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2645248868572178,
        "compression_ratio": 1.481012658227848,
        "end": 1469,
        "id": 253,
        "no_speech_prob": 0.07262393087148666,
        "seek": 146000,
        "start": 1464,
        "temperature": 0,
        "text": " And you can also customize environment on Spell, too.",
        "tokens": [
          50564,
          400,
          291,
          393,
          611,
          19734,
          2823,
          322,
          3550,
          285,
          11,
          886,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2645248868572178,
        "compression_ratio": 1.481012658227848,
        "end": 1472,
        "id": 254,
        "no_speech_prob": 0.07262393087148666,
        "seek": 146000,
        "start": 1469,
        "temperature": 0,
        "text": " But I will also talk about that later.",
        "tokens": [
          50814,
          583,
          286,
          486,
          611,
          751,
          466,
          300,
          1780,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2645248868572178,
        "compression_ratio": 1.481012658227848,
        "end": 1476,
        "id": 255,
        "no_speech_prob": 0.07262393087148666,
        "seek": 146000,
        "start": 1472,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50964,
          407,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2645248868572178,
        "compression_ratio": 1.481012658227848,
        "end": 1485,
        "id": 256,
        "no_speech_prob": 0.07262393087148666,
        "seek": 146000,
        "start": 1476,
        "temperature": 0,
        "text": " I guess we're going to try to train the style transfer model on the Spell.",
        "tokens": [
          51164,
          286,
          2041,
          321,
          434,
          516,
          281,
          853,
          281,
          3847,
          264,
          3758,
          5003,
          2316,
          322,
          264,
          3550,
          285,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20622494485643175,
        "compression_ratio": 1.4911242603550297,
        "end": 1494,
        "id": 257,
        "no_speech_prob": 0.021944299340248108,
        "seek": 149000,
        "start": 1491,
        "temperature": 0,
        "text": " Let me make this bigger.",
        "tokens": [
          50414,
          961,
          385,
          652,
          341,
          3801,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20622494485643175,
        "compression_ratio": 1.4911242603550297,
        "end": 1505,
        "id": 258,
        "no_speech_prob": 0.021944299340248108,
        "seek": 149000,
        "start": 1499,
        "temperature": 0,
        "text": " I'm just going to one of my empty folders here.",
        "tokens": [
          50814,
          286,
          478,
          445,
          516,
          281,
          472,
          295,
          452,
          6707,
          31082,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20622494485643175,
        "compression_ratio": 1.4911242603550297,
        "end": 1509,
        "id": 259,
        "no_speech_prob": 0.021944299340248108,
        "seek": 149000,
        "start": 1505,
        "temperature": 0,
        "text": " Can you guys all see my terminal?",
        "tokens": [
          51114,
          1664,
          291,
          1074,
          439,
          536,
          452,
          14709,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.20622494485643175,
        "compression_ratio": 1.4911242603550297,
        "end": 1510,
        "id": 260,
        "no_speech_prob": 0.021944299340248108,
        "seek": 149000,
        "start": 1509,
        "temperature": 0,
        "text": " Should I make it bigger?",
        "tokens": [
          51314,
          6454,
          286,
          652,
          309,
          3801,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.20622494485643175,
        "compression_ratio": 1.4911242603550297,
        "end": 1512,
        "id": 261,
        "no_speech_prob": 0.021944299340248108,
        "seek": 149000,
        "start": 1510,
        "temperature": 0,
        "text": " I think it probably should still be bigger.",
        "tokens": [
          51364,
          286,
          519,
          309,
          1391,
          820,
          920,
          312,
          3801,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20622494485643175,
        "compression_ratio": 1.4911242603550297,
        "end": 1518,
        "id": 262,
        "no_speech_prob": 0.021944299340248108,
        "seek": 149000,
        "start": 1512,
        "temperature": 0,
        "text": " I would go as big as you can reasonably without it being able to still work.",
        "tokens": [
          51464,
          286,
          576,
          352,
          382,
          955,
          382,
          291,
          393,
          23551,
          1553,
          309,
          885,
          1075,
          281,
          920,
          589,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1521,
        "id": 263,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1519,
        "temperature": 0,
        "text": " Like this?",
        "tokens": [
          50414,
          1743,
          341,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1522,
        "id": 264,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1521,
        "temperature": 0,
        "text": " I think that's good, yeah.",
        "tokens": [
          50514,
          286,
          519,
          300,
          311,
          665,
          11,
          1338,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1523,
        "id": 265,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1522,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50564,
          865,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1524,
        "id": 266,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1523,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1531,
        "id": 267,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1526,
        "temperature": 0,
        "text": " Yes, so the first step is to set up the environment.",
        "tokens": [
          50764,
          1079,
          11,
          370,
          264,
          700,
          1823,
          307,
          281,
          992,
          493,
          264,
          2823,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1538,
        "id": 268,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1535,
        "temperature": 0,
        "text": " So we're going to go to our terminal.",
        "tokens": [
          51214,
          407,
          321,
          434,
          516,
          281,
          352,
          281,
          527,
          14709,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1542,
        "id": 269,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1538,
        "temperature": 0,
        "text": " And we can go to one of the directories.",
        "tokens": [
          51364,
          400,
          321,
          393,
          352,
          281,
          472,
          295,
          264,
          5391,
          530,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20873560970776703,
        "compression_ratio": 1.3624161073825503,
        "end": 1544,
        "id": 270,
        "no_speech_prob": 0.00012146171502536163,
        "seek": 151800,
        "start": 1542,
        "temperature": 0,
        "text": " We can find a folder.",
        "tokens": [
          51564,
          492,
          393,
          915,
          257,
          10820,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1551,
        "id": 271,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1544,
        "temperature": 0,
        "text": " On my computer, I would just go to cd dev slash live stream.",
        "tokens": [
          50364,
          1282,
          452,
          3820,
          11,
          286,
          576,
          445,
          352,
          281,
          269,
          67,
          1905,
          17330,
          1621,
          4309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1552,
        "id": 272,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1551,
        "temperature": 0,
        "text": " And it's an empty folder.",
        "tokens": [
          50714,
          400,
          309,
          311,
          364,
          6707,
          10820,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1554,
        "id": 273,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1552,
        "temperature": 0,
        "text": " There's nothing there yet.",
        "tokens": [
          50764,
          821,
          311,
          1825,
          456,
          1939,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1560,
        "id": 274,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1554,
        "temperature": 0,
        "text": " And at first, I need to install Spell.",
        "tokens": [
          50864,
          400,
          412,
          700,
          11,
          286,
          643,
          281,
          3625,
          3550,
          285,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1565,
        "id": 275,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1560,
        "temperature": 0,
        "text": " Before I can install Spell, I need to install pip.",
        "tokens": [
          51164,
          4546,
          286,
          393,
          3625,
          3550,
          285,
          11,
          286,
          643,
          281,
          3625,
          8489,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1570,
        "id": 276,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1565,
        "temperature": 0,
        "text": " Pip is a package management system for Python.",
        "tokens": [
          51414,
          35396,
          307,
          257,
          7372,
          4592,
          1185,
          337,
          15329,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19143659418279474,
        "compression_ratio": 1.469387755102041,
        "end": 1573,
        "id": 277,
        "no_speech_prob": 0.0013249581679701805,
        "seek": 154400,
        "start": 1570,
        "temperature": 0,
        "text": " It's kind of like NPM for JavaScript.",
        "tokens": [
          51664,
          467,
          311,
          733,
          295,
          411,
          426,
          18819,
          337,
          15778,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1583,
        "id": 278,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1574,
        "temperature": 0,
        "text": " Sorry to interrupt you, but you should move the bottom where you're typing higher up.",
        "tokens": [
          50414,
          4919,
          281,
          12729,
          291,
          11,
          457,
          291,
          820,
          1286,
          264,
          2767,
          689,
          291,
          434,
          18444,
          2946,
          493,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1586,
        "id": 279,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1583,
        "temperature": 0,
        "text": " Because the captions are actually covering where you're typing.",
        "tokens": [
          50864,
          1436,
          264,
          44832,
          366,
          767,
          10322,
          689,
          291,
          434,
          18444,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1590,
        "id": 280,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1586,
        "temperature": 0,
        "text": " So if you just make your terminal window go to the top.",
        "tokens": [
          51014,
          407,
          498,
          291,
          445,
          652,
          428,
          14709,
          4910,
          352,
          281,
          264,
          1192,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1592,
        "id": 281,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1590,
        "temperature": 0,
        "text": " That works too, yes.",
        "tokens": [
          51214,
          663,
          1985,
          886,
          11,
          2086,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1594,
        "id": 282,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1592,
        "temperature": 0,
        "text": " It doesn't have to be that high up.",
        "tokens": [
          51314,
          467,
          1177,
          380,
          362,
          281,
          312,
          300,
          1090,
          493,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1599,
        "id": 283,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1597,
        "temperature": 0,
        "text": " How can I make this higher?",
        "tokens": [
          51564,
          1012,
          393,
          286,
          652,
          341,
          2946,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2530063338901686,
        "compression_ratio": 1.588785046728972,
        "end": 1602,
        "id": 284,
        "no_speech_prob": 0.017980806529521942,
        "seek": 157300,
        "start": 1599,
        "temperature": 0,
        "text": " You should be able to drag from the bottom right.",
        "tokens": [
          51664,
          509,
          820,
          312,
          1075,
          281,
          5286,
          490,
          264,
          2767,
          558,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1606,
        "id": 285,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1602,
        "temperature": 0,
        "text": " Like drag from the bottom right of the iTerm window.",
        "tokens": [
          50364,
          1743,
          5286,
          490,
          264,
          2767,
          558,
          295,
          264,
          30882,
          966,
          4910,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1609,
        "id": 286,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1608,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50664,
          876,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1610,
        "id": 287,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1609,
        "temperature": 0,
        "text": " Yeah, just like that.",
        "tokens": [
          50714,
          865,
          11,
          445,
          411,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1612,
        "id": 288,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1610,
        "temperature": 0,
        "text": " You can go two-thirds of the way down.",
        "tokens": [
          50764,
          509,
          393,
          352,
          732,
          12,
          38507,
          295,
          264,
          636,
          760,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1615,
        "id": 289,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1614,
        "temperature": 0,
        "text": " Perfect. That's good.",
        "tokens": [
          50964,
          10246,
          13,
          663,
          311,
          665,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1616,
        "id": 290,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1615,
        "temperature": 0,
        "text": " Okay, cool.",
        "tokens": [
          51014,
          1033,
          11,
          1627,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1619,
        "id": 291,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1616,
        "temperature": 0,
        "text": " So this is my terminal window.",
        "tokens": [
          51064,
          407,
          341,
          307,
          452,
          14709,
          4910,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23846864700317383,
        "compression_ratio": 1.4126984126984128,
        "end": 1627,
        "id": 292,
        "no_speech_prob": 0.0011159564601257443,
        "seek": 160200,
        "start": 1619,
        "temperature": 0,
        "text": " And before I install Spell, I need to install the pip package management for Python.",
        "tokens": [
          51214,
          400,
          949,
          286,
          3625,
          3550,
          285,
          11,
          286,
          643,
          281,
          3625,
          264,
          8489,
          7372,
          4592,
          337,
          15329,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17503033432306028,
        "compression_ratio": 1.5132743362831858,
        "end": 1633,
        "id": 293,
        "no_speech_prob": 0.0013670077314600348,
        "seek": 162700,
        "start": 1628,
        "temperature": 0,
        "text": " It's kind of like NPM for JavaScript, the node package management.",
        "tokens": [
          50414,
          467,
          311,
          733,
          295,
          411,
          426,
          18819,
          337,
          15778,
          11,
          264,
          9984,
          7372,
          4592,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17503033432306028,
        "compression_ratio": 1.5132743362831858,
        "end": 1637,
        "id": 294,
        "no_speech_prob": 0.0013670077314600348,
        "seek": 162700,
        "start": 1633,
        "temperature": 0,
        "text": " So if you don't have pip installed, we need to do that.",
        "tokens": [
          50664,
          407,
          498,
          291,
          500,
          380,
          362,
          8489,
          8899,
          11,
          321,
          643,
          281,
          360,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17503033432306028,
        "compression_ratio": 1.5132743362831858,
        "end": 1639,
        "id": 295,
        "no_speech_prob": 0.0013670077314600348,
        "seek": 162700,
        "start": 1637,
        "temperature": 0,
        "text": " We can do it together.",
        "tokens": [
          50864,
          492,
          393,
          360,
          309,
          1214,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17503033432306028,
        "compression_ratio": 1.5132743362831858,
        "end": 1642,
        "id": 296,
        "no_speech_prob": 0.0013670077314600348,
        "seek": 162700,
        "start": 1639,
        "temperature": 0,
        "text": " But I think I already did it, so it might be faster for me.",
        "tokens": [
          50964,
          583,
          286,
          519,
          286,
          1217,
          630,
          309,
          11,
          370,
          309,
          1062,
          312,
          4663,
          337,
          385,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17503033432306028,
        "compression_ratio": 1.5132743362831858,
        "end": 1648,
        "id": 297,
        "no_speech_prob": 0.0013670077314600348,
        "seek": 162700,
        "start": 1642,
        "temperature": 0,
        "text": " So I'm just going to switch to this page to see all those steps.",
        "tokens": [
          51114,
          407,
          286,
          478,
          445,
          516,
          281,
          3679,
          281,
          341,
          3028,
          281,
          536,
          439,
          729,
          4439,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17503033432306028,
        "compression_ratio": 1.5132743362831858,
        "end": 1655,
        "id": 298,
        "no_speech_prob": 0.0013670077314600348,
        "seek": 162700,
        "start": 1648,
        "temperature": 0,
        "text": " So at first, to install the pip, we are going to download this get-pip.",
        "tokens": [
          51414,
          407,
          412,
          700,
          11,
          281,
          3625,
          264,
          8489,
          11,
          321,
          366,
          516,
          281,
          5484,
          341,
          483,
          12,
          79,
          647,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1657,
        "id": 299,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1655,
        "temperature": 0,
        "text": " I will make this bigger, too.",
        "tokens": [
          50364,
          286,
          486,
          652,
          341,
          3801,
          11,
          886,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1659,
        "id": 300,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1657,
        "temperature": 0,
        "text": " Oh, too big.",
        "tokens": [
          50464,
          876,
          11,
          886,
          955,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1663,
        "id": 301,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1659,
        "temperature": 0,
        "text": " We are going to download this get-pip Python script.",
        "tokens": [
          50564,
          492,
          366,
          516,
          281,
          5484,
          341,
          483,
          12,
          79,
          647,
          15329,
          5755,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1667,
        "id": 302,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1663,
        "temperature": 0,
        "text": " So in my terminal, I'm going to...",
        "tokens": [
          50764,
          407,
          294,
          452,
          14709,
          11,
          286,
          478,
          516,
          281,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1669,
        "id": 303,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1668,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51014,
          876,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1671,
        "id": 304,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1669,
        "temperature": 0,
        "text": " I have a dot at the end.",
        "tokens": [
          51064,
          286,
          362,
          257,
          5893,
          412,
          264,
          917,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1678,
        "id": 305,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1672,
        "temperature": 0,
        "text": " So this will download this get-pip Python script.",
        "tokens": [
          51214,
          407,
          341,
          486,
          5484,
          341,
          483,
          12,
          79,
          647,
          15329,
          5755,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1854670246442159,
        "compression_ratio": 1.7195121951219512,
        "end": 1684,
        "id": 306,
        "no_speech_prob": 0.00030061317374929786,
        "seek": 165500,
        "start": 1678,
        "temperature": 0,
        "text": " And now if I take a look at my folder, there is a get-pip Python script.",
        "tokens": [
          51514,
          400,
          586,
          498,
          286,
          747,
          257,
          574,
          412,
          452,
          10820,
          11,
          456,
          307,
          257,
          483,
          12,
          79,
          647,
          15329,
          5755,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15262030471454968,
        "compression_ratio": 1.516304347826087,
        "end": 1689,
        "id": 307,
        "no_speech_prob": 0.00002014563142438419,
        "seek": 168500,
        "start": 1685,
        "temperature": 0,
        "text": " And then I'm just going to run my script.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          445,
          516,
          281,
          1190,
          452,
          5755,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15262030471454968,
        "compression_ratio": 1.516304347826087,
        "end": 1694,
        "id": 308,
        "no_speech_prob": 0.00002014563142438419,
        "seek": 168500,
        "start": 1691,
        "temperature": 0,
        "text": " Python get-pip.py.",
        "tokens": [
          50664,
          15329,
          483,
          12,
          79,
          647,
          13,
          8200,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15262030471454968,
        "compression_ratio": 1.516304347826087,
        "end": 1700,
        "id": 309,
        "no_speech_prob": 0.00002014563142438419,
        "seek": 168500,
        "start": 1694,
        "temperature": 0,
        "text": " If you're using Python 3, you can do Python 3 get-pip.py.",
        "tokens": [
          50814,
          759,
          291,
          434,
          1228,
          15329,
          805,
          11,
          291,
          393,
          360,
          15329,
          805,
          483,
          12,
          79,
          647,
          13,
          8200,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15262030471454968,
        "compression_ratio": 1.516304347826087,
        "end": 1706,
        "id": 310,
        "no_speech_prob": 0.00002014563142438419,
        "seek": 168500,
        "start": 1700,
        "temperature": 0,
        "text": " And I guess because I already installed pip, so it doesn't take too long.",
        "tokens": [
          51114,
          400,
          286,
          2041,
          570,
          286,
          1217,
          8899,
          8489,
          11,
          370,
          309,
          1177,
          380,
          747,
          886,
          938,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15262030471454968,
        "compression_ratio": 1.516304347826087,
        "end": 1712,
        "id": 311,
        "no_speech_prob": 0.00002014563142438419,
        "seek": 168500,
        "start": 1706,
        "temperature": 0,
        "text": " But if this is the first time that you install pip, it might take one minute, I guess.",
        "tokens": [
          51414,
          583,
          498,
          341,
          307,
          264,
          700,
          565,
          300,
          291,
          3625,
          8489,
          11,
          309,
          1062,
          747,
          472,
          3456,
          11,
          286,
          2041,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18711607483611709,
        "compression_ratio": 1.575609756097561,
        "end": 1719,
        "id": 312,
        "no_speech_prob": 0.00004683874431066215,
        "seek": 171200,
        "start": 1712,
        "temperature": 0,
        "text": " And after this is successfully installed, we are going to pip install spell.",
        "tokens": [
          50364,
          400,
          934,
          341,
          307,
          10727,
          8899,
          11,
          321,
          366,
          516,
          281,
          8489,
          3625,
          9827,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18711607483611709,
        "compression_ratio": 1.575609756097561,
        "end": 1725,
        "id": 313,
        "no_speech_prob": 0.00004683874431066215,
        "seek": 171200,
        "start": 1719,
        "temperature": 0,
        "text": " I also have done this, so it might be faster for me.",
        "tokens": [
          50714,
          286,
          611,
          362,
          1096,
          341,
          11,
          370,
          309,
          1062,
          312,
          4663,
          337,
          385,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18711607483611709,
        "compression_ratio": 1.575609756097561,
        "end": 1732,
        "id": 314,
        "no_speech_prob": 0.00004683874431066215,
        "seek": 171200,
        "start": 1727,
        "temperature": 0,
        "text": " So here it said, oh, requirement already satisfied because I already did it once.",
        "tokens": [
          51114,
          407,
          510,
          309,
          848,
          11,
          1954,
          11,
          11695,
          1217,
          11239,
          570,
          286,
          1217,
          630,
          309,
          1564,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18711607483611709,
        "compression_ratio": 1.575609756097561,
        "end": 1734,
        "id": 315,
        "no_speech_prob": 0.00004683874431066215,
        "seek": 171200,
        "start": 1732,
        "temperature": 0,
        "text": " So now we have spell installed.",
        "tokens": [
          51364,
          407,
          586,
          321,
          362,
          9827,
          8899,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18711607483611709,
        "compression_ratio": 1.575609756097561,
        "end": 1741,
        "id": 316,
        "no_speech_prob": 0.00004683874431066215,
        "seek": 171200,
        "start": 1734,
        "temperature": 0,
        "text": " So if I type in spell, I should be able to see a set of commands that I can do.",
        "tokens": [
          51464,
          407,
          498,
          286,
          2010,
          294,
          9827,
          11,
          286,
          820,
          312,
          1075,
          281,
          536,
          257,
          992,
          295,
          16901,
          300,
          286,
          393,
          360,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24183116853237152,
        "compression_ratio": 1.5348837209302326,
        "end": 1746,
        "id": 317,
        "no_speech_prob": 0.000535742670763284,
        "seek": 174100,
        "start": 1741,
        "temperature": 0,
        "text": " I can do spell cp to copy a file.",
        "tokens": [
          50364,
          286,
          393,
          360,
          9827,
          269,
          79,
          281,
          5055,
          257,
          3991,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24183116853237152,
        "compression_ratio": 1.5348837209302326,
        "end": 1753,
        "id": 318,
        "no_speech_prob": 0.000535742670763284,
        "seek": 174100,
        "start": 1746,
        "temperature": 0,
        "text": " Or I can do spell run to start a new run.",
        "tokens": [
          50614,
          1610,
          286,
          393,
          360,
          9827,
          1190,
          281,
          722,
          257,
          777,
          1190,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24183116853237152,
        "compression_ratio": 1.5348837209302326,
        "end": 1760,
        "id": 319,
        "no_speech_prob": 0.000535742670763284,
        "seek": 174100,
        "start": 1753,
        "temperature": 0,
        "text": " And I also can do spell login to log in to spell from my local computer.",
        "tokens": [
          50964,
          400,
          286,
          611,
          393,
          360,
          9827,
          24276,
          281,
          3565,
          294,
          281,
          9827,
          490,
          452,
          2654,
          3820,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24183116853237152,
        "compression_ratio": 1.5348837209302326,
        "end": 1764,
        "id": 320,
        "no_speech_prob": 0.000535742670763284,
        "seek": 174100,
        "start": 1761,
        "temperature": 0,
        "text": " My spell username is yining.",
        "tokens": [
          51364,
          1222,
          9827,
          30351,
          307,
          288,
          1760,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24183116853237152,
        "compression_ratio": 1.5348837209302326,
        "end": 1768,
        "id": 321,
        "no_speech_prob": 0.000535742670763284,
        "seek": 174100,
        "start": 1764,
        "temperature": 0,
        "text": " My password is this.",
        "tokens": [
          51514,
          1222,
          11524,
          307,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.28933205475678314,
        "compression_ratio": 1.5838509316770186,
        "end": 1772,
        "id": 322,
        "no_speech_prob": 0.0006877934793010354,
        "seek": 176800,
        "start": 1769,
        "temperature": 0,
        "text": " And now I can say, hello, yining.",
        "tokens": [
          50414,
          400,
          586,
          286,
          393,
          584,
          11,
          7751,
          11,
          288,
          1760,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28933205475678314,
        "compression_ratio": 1.5838509316770186,
        "end": 1775,
        "id": 323,
        "no_speech_prob": 0.0006877934793010354,
        "seek": 176800,
        "start": 1772,
        "temperature": 0,
        "text": " So I am successfully logged into spell.",
        "tokens": [
          50564,
          407,
          286,
          669,
          10727,
          27231,
          666,
          9827,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.28933205475678314,
        "compression_ratio": 1.5838509316770186,
        "end": 1782,
        "id": 324,
        "no_speech_prob": 0.0006877934793010354,
        "seek": 176800,
        "start": 1775,
        "temperature": 0,
        "text": " And I also can do spell who am I to check who is logged into spell.",
        "tokens": [
          50714,
          400,
          286,
          611,
          393,
          360,
          9827,
          567,
          669,
          286,
          281,
          1520,
          567,
          307,
          27231,
          666,
          9827,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.28933205475678314,
        "compression_ratio": 1.5838509316770186,
        "end": 1790,
        "id": 325,
        "no_speech_prob": 0.0006877934793010354,
        "seek": 176800,
        "start": 1782,
        "temperature": 0,
        "text": " And it says username yining, and this is my email created August 13th.",
        "tokens": [
          51064,
          400,
          309,
          1619,
          30351,
          288,
          1760,
          11,
          293,
          341,
          307,
          452,
          3796,
          2942,
          6897,
          3705,
          392,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.28933205475678314,
        "compression_ratio": 1.5838509316770186,
        "end": 1795,
        "id": 326,
        "no_speech_prob": 0.0006877934793010354,
        "seek": 176800,
        "start": 1790,
        "temperature": 0,
        "text": " And now we have successfully set up spell.",
        "tokens": [
          51464,
          400,
          586,
          321,
          362,
          10727,
          992,
          493,
          9827,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2620315828185151,
        "compression_ratio": 1.4382022471910112,
        "end": 1799,
        "id": 327,
        "no_speech_prob": 0.000060140482673887163,
        "seek": 179500,
        "start": 1795,
        "temperature": 0,
        "text": " And then we can do prepare our environment.",
        "tokens": [
          50364,
          400,
          550,
          321,
          393,
          360,
          5940,
          527,
          2823,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2620315828185151,
        "compression_ratio": 1.4382022471910112,
        "end": 1808,
        "id": 328,
        "no_speech_prob": 0.000060140482673887163,
        "seek": 179500,
        "start": 1799,
        "temperature": 0,
        "text": " As I mentioned before, we are going to use this TensorFlow implementation of FastL transfer made by Logan.",
        "tokens": [
          50564,
          1018,
          286,
          2835,
          949,
          11,
          321,
          366,
          516,
          281,
          764,
          341,
          37624,
          11420,
          295,
          15968,
          43,
          5003,
          1027,
          538,
          22689,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2620315828185151,
        "compression_ratio": 1.4382022471910112,
        "end": 1814,
        "id": 329,
        "no_speech_prob": 0.000060140482673887163,
        "seek": 179500,
        "start": 1808,
        "temperature": 0,
        "text": " So now I'm just going to go ahead and to clone his GitHub repository.",
        "tokens": [
          51014,
          407,
          586,
          286,
          478,
          445,
          516,
          281,
          352,
          2286,
          293,
          281,
          26506,
          702,
          23331,
          25841,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2620315828185151,
        "compression_ratio": 1.4382022471910112,
        "end": 1818,
        "id": 330,
        "no_speech_prob": 0.000060140482673887163,
        "seek": 179500,
        "start": 1814,
        "temperature": 0,
        "text": " So I'm going to do git clone.",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          281,
          360,
          18331,
          26506,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2620315828185151,
        "compression_ratio": 1.4382022471910112,
        "end": 1822,
        "id": 331,
        "no_speech_prob": 0.000060140482673887163,
        "seek": 179500,
        "start": 1821,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          51664,
          8561,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2501296143033611,
        "compression_ratio": 1.5,
        "end": 1829,
        "id": 332,
        "no_speech_prob": 0.00021654024021700025,
        "seek": 182200,
        "start": 1822,
        "temperature": 0,
        "text": " And then I'm going to go to his folder, cd fastl transfer.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          702,
          10820,
          11,
          269,
          67,
          2370,
          75,
          5003,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2501296143033611,
        "compression_ratio": 1.5,
        "end": 1832,
        "id": 333,
        "no_speech_prob": 0.00021654024021700025,
        "seek": 182200,
        "start": 1831,
        "temperature": 0,
        "text": " And now I'm here.",
        "tokens": [
          50814,
          400,
          586,
          286,
          478,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2501296143033611,
        "compression_ratio": 1.5,
        "end": 1840,
        "id": 334,
        "no_speech_prob": 0.00021654024021700025,
        "seek": 182200,
        "start": 1833,
        "temperature": 0,
        "text": " The next step is to create some folders and then put in our style image.",
        "tokens": [
          50914,
          440,
          958,
          1823,
          307,
          281,
          1884,
          512,
          31082,
          293,
          550,
          829,
          294,
          527,
          3758,
          3256,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2501296143033611,
        "compression_ratio": 1.5,
        "end": 1846,
        "id": 335,
        "no_speech_prob": 0.00021654024021700025,
        "seek": 182200,
        "start": 1840,
        "temperature": 0,
        "text": " So at first I'm going to create a folder that is called ckpt checkpoint.",
        "tokens": [
          51264,
          407,
          412,
          700,
          286,
          478,
          516,
          281,
          1884,
          257,
          10820,
          300,
          307,
          1219,
          269,
          74,
          662,
          42269,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18546818975192397,
        "compression_ratio": 1.841726618705036,
        "end": 1853,
        "id": 336,
        "no_speech_prob": 0.0009399087284691632,
        "seek": 184600,
        "start": 1847,
        "temperature": 0,
        "text": " And I'm going to create a git ignore file inside of ckpt folder.",
        "tokens": [
          50414,
          400,
          286,
          478,
          516,
          281,
          1884,
          257,
          18331,
          11200,
          3991,
          1854,
          295,
          269,
          74,
          662,
          10820,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18546818975192397,
        "compression_ratio": 1.841726618705036,
        "end": 1861,
        "id": 337,
        "no_speech_prob": 0.0009399087284691632,
        "seek": 184600,
        "start": 1855,
        "temperature": 0,
        "text": " And I'm also going to create a folder called images here.",
        "tokens": [
          50814,
          400,
          286,
          478,
          611,
          516,
          281,
          1884,
          257,
          10820,
          1219,
          5267,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18546818975192397,
        "compression_ratio": 1.841726618705036,
        "end": 1871,
        "id": 338,
        "no_speech_prob": 0.0009399087284691632,
        "seek": 184600,
        "start": 1863,
        "temperature": 0,
        "text": " And I'm also going to create another folder inside of the images called style.",
        "tokens": [
          51214,
          400,
          286,
          478,
          611,
          516,
          281,
          1884,
          1071,
          10820,
          1854,
          295,
          264,
          5267,
          1219,
          3758,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18546818975192397,
        "compression_ratio": 1.841726618705036,
        "end": 1874,
        "id": 339,
        "no_speech_prob": 0.0009399087284691632,
        "seek": 184600,
        "start": 1871,
        "temperature": 0,
        "text": " This is the folder where our style image will live in.",
        "tokens": [
          51614,
          639,
          307,
          264,
          10820,
          689,
          527,
          3758,
          3256,
          486,
          1621,
          294,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2003225355005976,
        "compression_ratio": 1.6503496503496504,
        "end": 1878,
        "id": 340,
        "no_speech_prob": 0.00004985850682714954,
        "seek": 187600,
        "start": 1877,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2003225355005976,
        "compression_ratio": 1.6503496503496504,
        "end": 1887,
        "id": 341,
        "no_speech_prob": 0.00004985850682714954,
        "seek": 187600,
        "start": 1878,
        "temperature": 0,
        "text": " So now if I take a look at this repo, I can see this is the new folder that we just created.",
        "tokens": [
          50464,
          407,
          586,
          498,
          286,
          747,
          257,
          574,
          412,
          341,
          49040,
          11,
          286,
          393,
          536,
          341,
          307,
          264,
          777,
          10820,
          300,
          321,
          445,
          2942,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2003225355005976,
        "compression_ratio": 1.6503496503496504,
        "end": 1891,
        "id": 342,
        "no_speech_prob": 0.00004985850682714954,
        "seek": 187600,
        "start": 1887,
        "temperature": 0,
        "text": " And this is also the new folder that we created images.",
        "tokens": [
          50914,
          400,
          341,
          307,
          611,
          264,
          777,
          10820,
          300,
          321,
          2942,
          5267,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2003225355005976,
        "compression_ratio": 1.6503496503496504,
        "end": 1900,
        "id": 343,
        "no_speech_prob": 0.00004985850682714954,
        "seek": 187600,
        "start": 1892,
        "temperature": 0,
        "text": " And the next step is to find a style image that we train, that can be trained on.",
        "tokens": [
          51164,
          400,
          264,
          958,
          1823,
          307,
          281,
          915,
          257,
          3758,
          3256,
          300,
          321,
          3847,
          11,
          300,
          393,
          312,
          8895,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2363853999546596,
        "compression_ratio": 1.5502958579881656,
        "end": 1916,
        "id": 344,
        "no_speech_prob": 0.00035696051781997085,
        "seek": 190600,
        "start": 1907,
        "temperature": 0,
        "text": " Oh, and when we're choosing style images, we need to make sure that we could use this artwork.",
        "tokens": [
          50414,
          876,
          11,
          293,
          562,
          321,
          434,
          10875,
          3758,
          5267,
          11,
          321,
          643,
          281,
          652,
          988,
          300,
          321,
          727,
          764,
          341,
          15829,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2363853999546596,
        "compression_ratio": 1.5502958579881656,
        "end": 1923,
        "id": 345,
        "no_speech_prob": 0.00035696051781997085,
        "seek": 190600,
        "start": 1916,
        "temperature": 0,
        "text": " And also we can use that image because, and we need to give credit to all those images.",
        "tokens": [
          50864,
          400,
          611,
          321,
          393,
          764,
          300,
          3256,
          570,
          11,
          293,
          321,
          643,
          281,
          976,
          5397,
          281,
          439,
          729,
          5267,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2363853999546596,
        "compression_ratio": 1.5502958579881656,
        "end": 1927,
        "id": 346,
        "no_speech_prob": 0.00035696051781997085,
        "seek": 190600,
        "start": 1923,
        "temperature": 0,
        "text": " Because we don't want to run into any copyright problem.",
        "tokens": [
          51214,
          1436,
          321,
          500,
          380,
          528,
          281,
          1190,
          666,
          604,
          17996,
          1154,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2363853999546596,
        "compression_ratio": 1.5502958579881656,
        "end": 1930,
        "id": 347,
        "no_speech_prob": 0.00035696051781997085,
        "seek": 190600,
        "start": 1928,
        "temperature": 0,
        "text": " I have one image here.",
        "tokens": [
          51464,
          286,
          362,
          472,
          3256,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3182687880117682,
        "compression_ratio": 1.5310734463276836,
        "end": 1938,
        "id": 348,
        "no_speech_prob": 0.0025861714966595173,
        "seek": 193000,
        "start": 1930,
        "temperature": 0,
        "text": " This is an Asian Chinese painting called Fuchun Shanjitu.",
        "tokens": [
          50364,
          639,
          307,
          364,
          10645,
          4649,
          5370,
          1219,
          479,
          625,
          409,
          25536,
          73,
          6380,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3182687880117682,
        "compression_ratio": 1.5310734463276836,
        "end": 1942,
        "id": 349,
        "no_speech_prob": 0.0025861714966595173,
        "seek": 193000,
        "start": 1939,
        "temperature": 0,
        "text": " And I got this image from Wikipedia.",
        "tokens": [
          50814,
          400,
          286,
          658,
          341,
          3256,
          490,
          28999,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3182687880117682,
        "compression_ratio": 1.5310734463276836,
        "end": 1945,
        "id": 350,
        "no_speech_prob": 0.0025861714966595173,
        "seek": 193000,
        "start": 1943,
        "temperature": 0,
        "text": " So I can use this image.",
        "tokens": [
          51014,
          407,
          286,
          393,
          764,
          341,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3182687880117682,
        "compression_ratio": 1.5310734463276836,
        "end": 1954,
        "id": 351,
        "no_speech_prob": 0.0025861714966595173,
        "seek": 193000,
        "start": 1945,
        "temperature": 0,
        "text": " But if any of you guys have an artwork that I can use, you could share it with me.",
        "tokens": [
          51114,
          583,
          498,
          604,
          295,
          291,
          1074,
          362,
          364,
          15829,
          300,
          286,
          393,
          764,
          11,
          291,
          727,
          2073,
          309,
          365,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3182687880117682,
        "compression_ratio": 1.5310734463276836,
        "end": 1959,
        "id": 352,
        "no_speech_prob": 0.0025861714966595173,
        "seek": 193000,
        "start": 1954,
        "temperature": 0,
        "text": " And I can train it with Spell and then send back the artwork to you.",
        "tokens": [
          51564,
          400,
          286,
          393,
          3847,
          309,
          365,
          3550,
          285,
          293,
          550,
          2845,
          646,
          264,
          15829,
          281,
          291,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.25948187021108776,
        "compression_ratio": 1.5588235294117647,
        "end": 1965,
        "id": 353,
        "no_speech_prob": 0.0002823956310749054,
        "seek": 195900,
        "start": 1959,
        "temperature": 0,
        "text": " And then I send back the model to you if you allow me to use your artwork.",
        "tokens": [
          50364,
          400,
          550,
          286,
          2845,
          646,
          264,
          2316,
          281,
          291,
          498,
          291,
          2089,
          385,
          281,
          764,
          428,
          15829,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25948187021108776,
        "compression_ratio": 1.5588235294117647,
        "end": 1976,
        "id": 354,
        "no_speech_prob": 0.0002823956310749054,
        "seek": 195900,
        "start": 1969,
        "temperature": 0,
        "text": " But if there's no other artwork, we are just going to use this image.",
        "tokens": [
          50864,
          583,
          498,
          456,
          311,
          572,
          661,
          15829,
          11,
          321,
          366,
          445,
          516,
          281,
          764,
          341,
          3256,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25948187021108776,
        "compression_ratio": 1.5588235294117647,
        "end": 1977,
        "id": 355,
        "no_speech_prob": 0.0002823956310749054,
        "seek": 195900,
        "start": 1976,
        "temperature": 0,
        "text": " We're going to train it again.",
        "tokens": [
          51214,
          492,
          434,
          516,
          281,
          3847,
          309,
          797,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.25948187021108776,
        "compression_ratio": 1.5588235294117647,
        "end": 1980,
        "id": 356,
        "no_speech_prob": 0.0002823956310749054,
        "seek": 195900,
        "start": 1977,
        "temperature": 0,
        "text": " I already trained a model on this image.",
        "tokens": [
          51264,
          286,
          1217,
          8895,
          257,
          2316,
          322,
          341,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.25948187021108776,
        "compression_ratio": 1.5588235294117647,
        "end": 1985,
        "id": 357,
        "no_speech_prob": 0.0002823956310749054,
        "seek": 195900,
        "start": 1982,
        "temperature": 0,
        "text": " Let me check the...",
        "tokens": [
          51514,
          961,
          385,
          1520,
          264,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.25948187021108776,
        "compression_ratio": 1.5588235294117647,
        "end": 1988,
        "id": 358,
        "no_speech_prob": 0.0002823956310749054,
        "seek": 195900,
        "start": 1985,
        "temperature": 0,
        "text": " They're behind in real time.",
        "tokens": [
          51664,
          814,
          434,
          2261,
          294,
          957,
          565,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 1991,
        "id": 359,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 1988,
        "temperature": 0,
        "text": " I think maybe you should probably move forward with that image.",
        "tokens": [
          50364,
          286,
          519,
          1310,
          291,
          820,
          1391,
          1286,
          2128,
          365,
          300,
          3256,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 1992,
        "id": 360,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 1991,
        "temperature": 0,
        "text": " And I'll see if people...",
        "tokens": [
          50514,
          400,
          286,
          603,
          536,
          498,
          561,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 1996,
        "id": 361,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 1992,
        "temperature": 0,
        "text": " Because then people will do their own images following along.",
        "tokens": [
          50564,
          1436,
          550,
          561,
          486,
          360,
          641,
          1065,
          5267,
          3480,
          2051,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 1999,
        "id": 362,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 1996,
        "temperature": 0,
        "text": " And then maybe we'll come up with a hashtag or something at the end.",
        "tokens": [
          50764,
          400,
          550,
          1310,
          321,
          603,
          808,
          493,
          365,
          257,
          20379,
          420,
          746,
          412,
          264,
          917,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 2003,
        "id": 363,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 1999,
        "temperature": 0,
        "text": " That people can share their style transfer models on Twitter or in the comments.",
        "tokens": [
          50914,
          663,
          561,
          393,
          2073,
          641,
          3758,
          5003,
          5245,
          322,
          5794,
          420,
          294,
          264,
          3053,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 2006,
        "id": 364,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 2003,
        "temperature": 0,
        "text": " Or whatever social media place is a good place to share.",
        "tokens": [
          51114,
          1610,
          2035,
          2093,
          3021,
          1081,
          307,
          257,
          665,
          1081,
          281,
          2073,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 2007,
        "id": 365,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 2006,
        "temperature": 0,
        "text": " Yeah, that sounds good.",
        "tokens": [
          51264,
          865,
          11,
          300,
          3263,
          665,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24148654062813574,
        "compression_ratio": 1.6450381679389312,
        "end": 2011,
        "id": 366,
        "no_speech_prob": 0.0007306814077310264,
        "seek": 198800,
        "start": 2008,
        "temperature": 0,
        "text": " Okay, so we have decided to just use this image.",
        "tokens": [
          51364,
          1033,
          11,
          370,
          321,
          362,
          3047,
          281,
          445,
          764,
          341,
          3256,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22942182494372856,
        "compression_ratio": 1.3936170212765957,
        "end": 2020,
        "id": 367,
        "no_speech_prob": 0.00020986759045626968,
        "seek": 201100,
        "start": 2012,
        "temperature": 0,
        "text": " What I'm going to do is to put this image into images slash style.",
        "tokens": [
          50414,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          281,
          829,
          341,
          3256,
          666,
          5267,
          17330,
          3758,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22942182494372856,
        "compression_ratio": 1.3936170212765957,
        "end": 2026,
        "id": 368,
        "no_speech_prob": 0.00020986759045626968,
        "seek": 201100,
        "start": 2020,
        "temperature": 0,
        "text": " So I'm going to go to the folder.",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          10820,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22942182494372856,
        "compression_ratio": 1.3936170212765957,
        "end": 2035,
        "id": 369,
        "no_speech_prob": 0.00020986759045626968,
        "seek": 201100,
        "start": 2032,
        "temperature": 0,
        "text": " I'm going to make this bigger.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          652,
          341,
          3801,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17004424578522984,
        "compression_ratio": 1.5192307692307692,
        "end": 2044,
        "id": 370,
        "no_speech_prob": 0.00015836310922168195,
        "seek": 204100,
        "start": 2042,
        "temperature": 0,
        "text": " I don't think I can make this window bigger.",
        "tokens": [
          50414,
          286,
          500,
          380,
          519,
          286,
          393,
          652,
          341,
          4910,
          3801,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17004424578522984,
        "compression_ratio": 1.5192307692307692,
        "end": 2053,
        "id": 371,
        "no_speech_prob": 0.00015836310922168195,
        "seek": 204100,
        "start": 2044,
        "temperature": 0,
        "text": " But I will just quickly put that style image into images style.",
        "tokens": [
          50514,
          583,
          286,
          486,
          445,
          2661,
          829,
          300,
          3758,
          3256,
          666,
          5267,
          3758,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17004424578522984,
        "compression_ratio": 1.5192307692307692,
        "end": 2056,
        "id": 372,
        "no_speech_prob": 0.00015836310922168195,
        "seek": 204100,
        "start": 2054,
        "temperature": 0,
        "text": " I'm going to copy this image.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          5055,
          341,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17004424578522984,
        "compression_ratio": 1.5192307692307692,
        "end": 2060,
        "id": 373,
        "no_speech_prob": 0.00015836310922168195,
        "seek": 204100,
        "start": 2056,
        "temperature": 0,
        "text": " This image is called fuchun.jpg.",
        "tokens": [
          51114,
          639,
          3256,
          307,
          1219,
          283,
          625,
          409,
          13,
          73,
          49861,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17004424578522984,
        "compression_ratio": 1.5192307692307692,
        "end": 2063,
        "id": 374,
        "no_speech_prob": 0.00015836310922168195,
        "seek": 204100,
        "start": 2061,
        "temperature": 0,
        "text": " And I just copied this image here.",
        "tokens": [
          51364,
          400,
          286,
          445,
          25365,
          341,
          3256,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17004424578522984,
        "compression_ratio": 1.5192307692307692,
        "end": 2069,
        "id": 375,
        "no_speech_prob": 0.00015836310922168195,
        "seek": 204100,
        "start": 2066,
        "temperature": 0,
        "text": " So now we got our style image.",
        "tokens": [
          51614,
          407,
          586,
          321,
          658,
          527,
          3758,
          3256,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22230354944864908,
        "compression_ratio": 1.7483443708609272,
        "end": 2074,
        "id": 376,
        "no_speech_prob": 0.0009398593683727086,
        "seek": 206900,
        "start": 2069,
        "temperature": 0,
        "text": " The one thing that we need to do is to get at those two folders.",
        "tokens": [
          50364,
          440,
          472,
          551,
          300,
          321,
          643,
          281,
          360,
          307,
          281,
          483,
          412,
          729,
          732,
          31082,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22230354944864908,
        "compression_ratio": 1.7483443708609272,
        "end": 2080,
        "id": 377,
        "no_speech_prob": 0.0009398593683727086,
        "seek": 206900,
        "start": 2074,
        "temperature": 0,
        "text": " And also commit these changes to let spell know that we made all those changes.",
        "tokens": [
          50614,
          400,
          611,
          5599,
          613,
          2962,
          281,
          718,
          9827,
          458,
          300,
          321,
          1027,
          439,
          729,
          2962,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22230354944864908,
        "compression_ratio": 1.7483443708609272,
        "end": 2085,
        "id": 378,
        "no_speech_prob": 0.0009398593683727086,
        "seek": 206900,
        "start": 2081,
        "temperature": 0,
        "text": " So here I'm going to do get at images.",
        "tokens": [
          50964,
          407,
          510,
          286,
          478,
          516,
          281,
          360,
          483,
          412,
          5267,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22230354944864908,
        "compression_ratio": 1.7483443708609272,
        "end": 2088,
        "id": 379,
        "no_speech_prob": 0.0009398593683727086,
        "seek": 206900,
        "start": 2085,
        "temperature": 0,
        "text": " And also add that folder checkpoint.",
        "tokens": [
          51164,
          400,
          611,
          909,
          300,
          10820,
          42269,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22230354944864908,
        "compression_ratio": 1.7483443708609272,
        "end": 2092,
        "id": 380,
        "no_speech_prob": 0.0009398593683727086,
        "seek": 206900,
        "start": 2089,
        "temperature": 0,
        "text": " And then I'm going to commit these changes.",
        "tokens": [
          51364,
          400,
          550,
          286,
          478,
          516,
          281,
          5599,
          613,
          2962,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2977827556097685,
        "compression_ratio": 1.4509803921568627,
        "end": 2094,
        "id": 381,
        "no_speech_prob": 0.000053910593123873696,
        "seek": 209200,
        "start": 2093,
        "temperature": 0,
        "text": " Cool.",
        "tokens": [
          50414,
          8561,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2977827556097685,
        "compression_ratio": 1.4509803921568627,
        "end": 2097,
        "id": 382,
        "no_speech_prob": 0.000053910593123873696,
        "seek": 209200,
        "start": 2094,
        "temperature": 0,
        "text": " So now we have prepared our environment.",
        "tokens": [
          50464,
          407,
          586,
          321,
          362,
          4927,
          527,
          2823,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2977827556097685,
        "compression_ratio": 1.4509803921568627,
        "end": 2098,
        "id": 383,
        "no_speech_prob": 0.000053910593123873696,
        "seek": 209200,
        "start": 2097,
        "temperature": 0,
        "text": " This is done.",
        "tokens": [
          50614,
          639,
          307,
          1096,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2977827556097685,
        "compression_ratio": 1.4509803921568627,
        "end": 2101,
        "id": 384,
        "no_speech_prob": 0.000053910593123873696,
        "seek": 209200,
        "start": 2098,
        "temperature": 0,
        "text": " We can move to the next step.",
        "tokens": [
          50664,
          492,
          393,
          1286,
          281,
          264,
          958,
          1823,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2977827556097685,
        "compression_ratio": 1.4509803921568627,
        "end": 2105,
        "id": 385,
        "no_speech_prob": 0.000053910593123873696,
        "seek": 209200,
        "start": 2102,
        "temperature": 0,
        "text": " It's to, we need to download the data set.",
        "tokens": [
          50864,
          467,
          311,
          281,
          11,
          321,
          643,
          281,
          5484,
          264,
          1412,
          992,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2977827556097685,
        "compression_ratio": 1.4509803921568627,
        "end": 2118,
        "id": 386,
        "no_speech_prob": 0.000053910593123873696,
        "seek": 209200,
        "start": 2112,
        "temperature": 0,
        "text": " So in order to train this model, we need some required data set for fast style transfer.",
        "tokens": [
          51364,
          407,
          294,
          1668,
          281,
          3847,
          341,
          2316,
          11,
          321,
          643,
          512,
          4739,
          1412,
          992,
          337,
          2370,
          3758,
          5003,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.5118090765816825,
        "compression_ratio": 1.3135593220338984,
        "end": 2122,
        "id": 387,
        "no_speech_prob": 0.001838379423134029,
        "seek": 211800,
        "start": 2118,
        "temperature": 0,
        "text": " We need everything is in the setup script.",
        "tokens": [
          50364,
          492,
          643,
          1203,
          307,
          294,
          264,
          8657,
          5755,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.5118090765816825,
        "compression_ratio": 1.3135593220338984,
        "end": 2129,
        "id": 388,
        "no_speech_prob": 0.001838379423134029,
        "seek": 211800,
        "start": 2123,
        "temperature": 0,
        "text": " So we can actually open the fast style transfer GitHub repo here.",
        "tokens": [
          50614,
          407,
          321,
          393,
          767,
          1269,
          264,
          2370,
          3758,
          5003,
          23331,
          49040,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.5118090765816825,
        "compression_ratio": 1.3135593220338984,
        "end": 2145,
        "id": 389,
        "no_speech_prob": 0.001838379423134029,
        "seek": 211800,
        "start": 2140,
        "temperature": 0,
        "text": " So next we are going to create a new data set.",
        "tokens": [
          51464,
          407,
          958,
          321,
          366,
          516,
          281,
          1884,
          257,
          777,
          1412,
          992,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23148646283505567,
        "compression_ratio": 1.5612903225806452,
        "end": 2152,
        "id": 390,
        "no_speech_prob": 0.00006014093378325924,
        "seek": 214500,
        "start": 2145,
        "temperature": 0,
        "text": " So next we are going to run this script setup.",
        "tokens": [
          50364,
          407,
          958,
          321,
          366,
          516,
          281,
          1190,
          341,
          5755,
          8657,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23148646283505567,
        "compression_ratio": 1.5612903225806452,
        "end": 2159,
        "id": 391,
        "no_speech_prob": 0.00006014093378325924,
        "seek": 214500,
        "start": 2154,
        "temperature": 0,
        "text": " As you can see in this setup, we are going to create a folder called data.",
        "tokens": [
          50814,
          1018,
          291,
          393,
          536,
          294,
          341,
          8657,
          11,
          321,
          366,
          516,
          281,
          1884,
          257,
          10820,
          1219,
          1412,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23148646283505567,
        "compression_ratio": 1.5612903225806452,
        "end": 2164,
        "id": 392,
        "no_speech_prob": 0.00006014093378325924,
        "seek": 214500,
        "start": 2159,
        "temperature": 0,
        "text": " And then go inside, go into that data folder.",
        "tokens": [
          51064,
          400,
          550,
          352,
          1854,
          11,
          352,
          666,
          300,
          1412,
          10820,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23148646283505567,
        "compression_ratio": 1.5612903225806452,
        "end": 2171,
        "id": 393,
        "no_speech_prob": 0.00006014093378325924,
        "seek": 214500,
        "start": 2164,
        "temperature": 0,
        "text": " And then get this, the VGG model, convolutional neural network model back.",
        "tokens": [
          51314,
          400,
          550,
          483,
          341,
          11,
          264,
          691,
          27561,
          2316,
          11,
          45216,
          304,
          18161,
          3209,
          2316,
          646,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2847631749972491,
        "compression_ratio": 1.5380116959064327,
        "end": 2176,
        "id": 394,
        "no_speech_prob": 0.00005307381070451811,
        "seek": 217100,
        "start": 2172,
        "temperature": 0,
        "text": " And then make, also make a folder called bin.",
        "tokens": [
          50414,
          400,
          550,
          652,
          11,
          611,
          652,
          257,
          10820,
          1219,
          5171,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2847631749972491,
        "compression_ratio": 1.5380116959064327,
        "end": 2180,
        "id": 395,
        "no_speech_prob": 0.00005307381070451811,
        "seek": 217100,
        "start": 2176,
        "temperature": 0,
        "text": " And then download this Cocoa data set.",
        "tokens": [
          50614,
          400,
          550,
          5484,
          341,
          29787,
          64,
          1412,
          992,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2847631749972491,
        "compression_ratio": 1.5380116959064327,
        "end": 2183,
        "id": 396,
        "no_speech_prob": 0.00005307381070451811,
        "seek": 217100,
        "start": 2180,
        "temperature": 0,
        "text": " And then unzip this Cocoa data set.",
        "tokens": [
          50814,
          400,
          550,
          517,
          27268,
          341,
          29787,
          64,
          1412,
          992,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2847631749972491,
        "compression_ratio": 1.5380116959064327,
        "end": 2189,
        "id": 397,
        "no_speech_prob": 0.00005307381070451811,
        "seek": 217100,
        "start": 2183,
        "temperature": 0,
        "text": " So do you remember, before we have talked about the VGG here.",
        "tokens": [
          50964,
          407,
          360,
          291,
          1604,
          11,
          949,
          321,
          362,
          2825,
          466,
          264,
          691,
          27561,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2847631749972491,
        "compression_ratio": 1.5380116959064327,
        "end": 2198,
        "id": 398,
        "no_speech_prob": 0.00005307381070451811,
        "seek": 217100,
        "start": 2191,
        "temperature": 0,
        "text": " This is the convolutional neural network that is trained for object recognition.",
        "tokens": [
          51364,
          639,
          307,
          264,
          45216,
          304,
          18161,
          3209,
          300,
          307,
          8895,
          337,
          2657,
          11150,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15825418422096654,
        "compression_ratio": 1.5449438202247192,
        "end": 2203,
        "id": 399,
        "no_speech_prob": 0.000046837936679366976,
        "seek": 219800,
        "start": 2198,
        "temperature": 0,
        "text": " It can get the internal representation of the image for us.",
        "tokens": [
          50364,
          467,
          393,
          483,
          264,
          6920,
          10290,
          295,
          264,
          3256,
          337,
          505,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15825418422096654,
        "compression_ratio": 1.5449438202247192,
        "end": 2207,
        "id": 400,
        "no_speech_prob": 0.000046837936679366976,
        "seek": 219800,
        "start": 2203,
        "temperature": 0,
        "text": " That's why we are going to use this VGG model.",
        "tokens": [
          50614,
          663,
          311,
          983,
          321,
          366,
          516,
          281,
          764,
          341,
          691,
          27561,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15825418422096654,
        "compression_ratio": 1.5449438202247192,
        "end": 2212,
        "id": 401,
        "no_speech_prob": 0.000046837936679366976,
        "seek": 219800,
        "start": 2207,
        "temperature": 0,
        "text": " And also fast style transfer uses this Cocoa data set.",
        "tokens": [
          50814,
          400,
          611,
          2370,
          3758,
          5003,
          4960,
          341,
          29787,
          64,
          1412,
          992,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15825418422096654,
        "compression_ratio": 1.5449438202247192,
        "end": 2219,
        "id": 402,
        "no_speech_prob": 0.000046837936679366976,
        "seek": 219800,
        "start": 2212,
        "temperature": 0,
        "text": " It is trained on a large batch of images.",
        "tokens": [
          51064,
          467,
          307,
          8895,
          322,
          257,
          2416,
          15245,
          295,
          5267,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15825418422096654,
        "compression_ratio": 1.5449438202247192,
        "end": 2226,
        "id": 403,
        "no_speech_prob": 0.000046837936679366976,
        "seek": 219800,
        "start": 2219,
        "temperature": 0,
        "text": " This Cocoa data set is an object recognition data set of 80,000 images.",
        "tokens": [
          51414,
          639,
          29787,
          64,
          1412,
          992,
          307,
          364,
          2657,
          11150,
          1412,
          992,
          295,
          4688,
          11,
          1360,
          5267,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2228,
        "id": 404,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2226,
        "temperature": 0,
        "text": " So we also need this.",
        "tokens": [
          50364,
          407,
          321,
          611,
          643,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2233,
        "id": 405,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2228,
        "temperature": 0,
        "text": " Because this Cocoa data set is huge, so it might take a while.",
        "tokens": [
          50464,
          1436,
          341,
          29787,
          64,
          1412,
          992,
          307,
          2603,
          11,
          370,
          309,
          1062,
          747,
          257,
          1339,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2236,
        "id": 406,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2233,
        "temperature": 0,
        "text": " But we are just going to do it.",
        "tokens": [
          50714,
          583,
          321,
          366,
          445,
          516,
          281,
          360,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2241,
        "id": 407,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2236,
        "temperature": 0,
        "text": " So this is what it looks like in the setup script.",
        "tokens": [
          50864,
          407,
          341,
          307,
          437,
          309,
          1542,
          411,
          294,
          264,
          8657,
          5755,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2244,
        "id": 408,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2241,
        "temperature": 0,
        "text": " And next we are just going to run this setup.",
        "tokens": [
          51114,
          400,
          958,
          321,
          366,
          445,
          516,
          281,
          1190,
          341,
          8657,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2246,
        "id": 409,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2244,
        "temperature": 0,
        "text": " I'm just adjusting the volume.",
        "tokens": [
          51264,
          286,
          478,
          445,
          23559,
          264,
          5523,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2728137969970703,
        "compression_ratio": 1.5786516853932584,
        "end": 2249,
        "id": 410,
        "no_speech_prob": 0.00004908604751108214,
        "seek": 222600,
        "start": 2246,
        "temperature": 0,
        "text": " I will speak up a little bit. Sorry.",
        "tokens": [
          51364,
          286,
          486,
          1710,
          493,
          257,
          707,
          857,
          13,
          4919,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24789848662259287,
        "compression_ratio": 1.7407407407407407,
        "end": 2255,
        "id": 411,
        "no_speech_prob": 0.0002652920666150749,
        "seek": 224900,
        "start": 2250,
        "temperature": 0,
        "text": " So next we are going to run this setup script.",
        "tokens": [
          50414,
          407,
          958,
          321,
          366,
          516,
          281,
          1190,
          341,
          8657,
          5755,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24789848662259287,
        "compression_ratio": 1.7407407407407407,
        "end": 2261,
        "id": 412,
        "no_speech_prob": 0.0002652920666150749,
        "seek": 224900,
        "start": 2255,
        "temperature": 0,
        "text": " And we are going to use spell to run this.",
        "tokens": [
          50664,
          400,
          321,
          366,
          516,
          281,
          764,
          9827,
          281,
          1190,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24789848662259287,
        "compression_ratio": 1.7407407407407407,
        "end": 2267,
        "id": 413,
        "no_speech_prob": 0.0002652920666150749,
        "seek": 224900,
        "start": 2261,
        "temperature": 0,
        "text": " So in our terminal, we are going to do spell run.",
        "tokens": [
          50964,
          407,
          294,
          527,
          14709,
          11,
          321,
          366,
          516,
          281,
          360,
          9827,
          1190,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24789848662259287,
        "compression_ratio": 1.7407407407407407,
        "end": 2272,
        "id": 414,
        "no_speech_prob": 0.0002652920666150749,
        "seek": 224900,
        "start": 2267,
        "temperature": 0,
        "text": " And this is the script that we are going to run.",
        "tokens": [
          51264,
          400,
          341,
          307,
          264,
          5755,
          300,
          321,
          366,
          516,
          281,
          1190,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2984087923739819,
        "compression_ratio": 1.3083333333333333,
        "end": 2281,
        "id": 415,
        "no_speech_prob": 0.0016484138322994113,
        "seek": 227200,
        "start": 2272,
        "temperature": 0,
        "text": " But here we can also specify the machine type by using this flag, dash, dash, machine type, CPU.",
        "tokens": [
          50364,
          583,
          510,
          321,
          393,
          611,
          16500,
          264,
          3479,
          2010,
          538,
          1228,
          341,
          7166,
          11,
          8240,
          11,
          8240,
          11,
          3479,
          2010,
          11,
          13199,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2984087923739819,
        "compression_ratio": 1.3083333333333333,
        "end": 2283,
        "id": 416,
        "no_speech_prob": 0.0016484138322994113,
        "seek": 227200,
        "start": 2281,
        "temperature": 0,
        "text": " CPU is free to use.",
        "tokens": [
          50814,
          13199,
          307,
          1737,
          281,
          764,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2984087923739819,
        "compression_ratio": 1.3083333333333333,
        "end": 2286,
        "id": 417,
        "no_speech_prob": 0.0016484138322994113,
        "seek": 227200,
        "start": 2283,
        "temperature": 0,
        "text": " So we are just going to run this script.",
        "tokens": [
          50914,
          407,
          321,
          366,
          445,
          516,
          281,
          1190,
          341,
          5755,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.25421592463617737,
        "compression_ratio": 1.373134328358209,
        "end": 2301,
        "id": 418,
        "no_speech_prob": 0.006487530190497637,
        "seek": 228600,
        "start": 2287,
        "temperature": 0,
        "text": " And then you can see this emoji casting spell 15, number 15.",
        "tokens": [
          50414,
          400,
          550,
          291,
          393,
          536,
          341,
          31595,
          17301,
          9827,
          2119,
          11,
          1230,
          2119,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25421592463617737,
        "compression_ratio": 1.373134328358209,
        "end": 2310,
        "id": 419,
        "no_speech_prob": 0.006487530190497637,
        "seek": 228600,
        "start": 2301,
        "temperature": 0,
        "text": " This number is really important to us because later we are going to use the output of this run to do our next training run.",
        "tokens": [
          51114,
          639,
          1230,
          307,
          534,
          1021,
          281,
          505,
          570,
          1780,
          321,
          366,
          516,
          281,
          764,
          264,
          5598,
          295,
          341,
          1190,
          281,
          360,
          527,
          958,
          3097,
          1190,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2762052445184617,
        "compression_ratio": 1.5070422535211268,
        "end": 2317,
        "id": 420,
        "no_speech_prob": 0.0004373274277895689,
        "seek": 231000,
        "start": 2311,
        "temperature": 0,
        "text": " So it's downloading this VGG model.",
        "tokens": [
          50414,
          407,
          309,
          311,
          32529,
          341,
          691,
          27561,
          2316,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2762052445184617,
        "compression_ratio": 1.5070422535211268,
        "end": 2321,
        "id": 421,
        "no_speech_prob": 0.0004373274277895689,
        "seek": 231000,
        "start": 2317,
        "temperature": 0,
        "text": " Let me make it a little bit smaller.",
        "tokens": [
          50714,
          961,
          385,
          652,
          309,
          257,
          707,
          857,
          4356,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2762052445184617,
        "compression_ratio": 1.5070422535211268,
        "end": 2334,
        "id": 422,
        "no_speech_prob": 0.0004373274277895689,
        "seek": 231000,
        "start": 2321,
        "temperature": 0,
        "text": " And I think after downloading the VGG model, it's also going to download the Cocoa data set.",
        "tokens": [
          50914,
          400,
          286,
          519,
          934,
          32529,
          264,
          691,
          27561,
          2316,
          11,
          309,
          311,
          611,
          516,
          281,
          5484,
          264,
          29787,
          64,
          1412,
          992,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2762052445184617,
        "compression_ratio": 1.5070422535211268,
        "end": 2339,
        "id": 423,
        "no_speech_prob": 0.0004373274277895689,
        "seek": 231000,
        "start": 2334,
        "temperature": 0,
        "text": " But here I'm just going to do control C to exit.",
        "tokens": [
          51564,
          583,
          510,
          286,
          478,
          445,
          516,
          281,
          360,
          1969,
          383,
          281,
          11043,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23158130398044338,
        "compression_ratio": 1.558659217877095,
        "end": 2341,
        "id": 424,
        "no_speech_prob": 0.0000760240582167171,
        "seek": 233900,
        "start": 2339,
        "temperature": 0,
        "text": " It wouldn't stop this run.",
        "tokens": [
          50364,
          467,
          2759,
          380,
          1590,
          341,
          1190,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23158130398044338,
        "compression_ratio": 1.558659217877095,
        "end": 2345,
        "id": 425,
        "no_speech_prob": 0.0000760240582167171,
        "seek": 233900,
        "start": 2341,
        "temperature": 0,
        "text": " It would just stop printing all those logs.",
        "tokens": [
          50464,
          467,
          576,
          445,
          1590,
          14699,
          439,
          729,
          20820,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23158130398044338,
        "compression_ratio": 1.558659217877095,
        "end": 2354,
        "id": 426,
        "no_speech_prob": 0.0000760240582167171,
        "seek": 233900,
        "start": 2345,
        "temperature": 0,
        "text": " I tried to run this run on spell and it takes me one hour and 30 minutes to finish it.",
        "tokens": [
          50664,
          286,
          3031,
          281,
          1190,
          341,
          1190,
          322,
          9827,
          293,
          309,
          2516,
          385,
          472,
          1773,
          293,
          2217,
          2077,
          281,
          2413,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23158130398044338,
        "compression_ratio": 1.558659217877095,
        "end": 2360,
        "id": 427,
        "no_speech_prob": 0.0000760240582167171,
        "seek": 233900,
        "start": 2354,
        "temperature": 0,
        "text": " I can also log in to spell to see more detailed information about each run.",
        "tokens": [
          51114,
          286,
          393,
          611,
          3565,
          294,
          281,
          9827,
          281,
          536,
          544,
          9942,
          1589,
          466,
          1184,
          1190,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23158130398044338,
        "compression_ratio": 1.558659217877095,
        "end": 2365,
        "id": 428,
        "no_speech_prob": 0.0000760240582167171,
        "seek": 233900,
        "start": 2360,
        "temperature": 0,
        "text": " But also in the terminal, we can do spell PS.",
        "tokens": [
          51414,
          583,
          611,
          294,
          264,
          14709,
          11,
          321,
          393,
          360,
          9827,
          8168,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21646206719534739,
        "compression_ratio": 1.4683544303797469,
        "end": 2370,
        "id": 429,
        "no_speech_prob": 0.002148922299966216,
        "seek": 236500,
        "start": 2366,
        "temperature": 0,
        "text": " It will list all those runs that I have done before.",
        "tokens": [
          50414,
          467,
          486,
          1329,
          439,
          729,
          6676,
          300,
          286,
          362,
          1096,
          949,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21646206719534739,
        "compression_ratio": 1.4683544303797469,
        "end": 2377,
        "id": 430,
        "no_speech_prob": 0.002148922299966216,
        "seek": 236500,
        "start": 2370,
        "temperature": 0,
        "text": " So I have 15 runs and the last one is running.",
        "tokens": [
          50614,
          407,
          286,
          362,
          2119,
          6676,
          293,
          264,
          1036,
          472,
          307,
          2614,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21646206719534739,
        "compression_ratio": 1.4683544303797469,
        "end": 2381,
        "id": 431,
        "no_speech_prob": 0.002148922299966216,
        "seek": 236500,
        "start": 2377,
        "temperature": 0,
        "text": " And this is the command that I put.",
        "tokens": [
          50964,
          400,
          341,
          307,
          264,
          5622,
          300,
          286,
          829,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21646206719534739,
        "compression_ratio": 1.4683544303797469,
        "end": 2383,
        "id": 432,
        "no_speech_prob": 0.002148922299966216,
        "seek": 236500,
        "start": 2381,
        "temperature": 0,
        "text": " And this is the machine type.",
        "tokens": [
          51164,
          400,
          341,
          307,
          264,
          3479,
          2010,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21646206719534739,
        "compression_ratio": 1.4683544303797469,
        "end": 2385,
        "id": 433,
        "no_speech_prob": 0.002148922299966216,
        "seek": 236500,
        "start": 2383,
        "temperature": 0,
        "text": " We are just using CPU.",
        "tokens": [
          51264,
          492,
          366,
          445,
          1228,
          13199,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21646206719534739,
        "compression_ratio": 1.4683544303797469,
        "end": 2390,
        "id": 434,
        "no_speech_prob": 0.002148922299966216,
        "seek": 236500,
        "start": 2385,
        "temperature": 0,
        "text": " But we can also log into the spell website.",
        "tokens": [
          51364,
          583,
          321,
          393,
          611,
          3565,
          666,
          264,
          9827,
          3144,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22593878026594194,
        "compression_ratio": 1.4148148148148147,
        "end": 2402,
        "id": 435,
        "no_speech_prob": 0.0013670098269358277,
        "seek": 239000,
        "start": 2390,
        "temperature": 0,
        "text": " And here I can click on this run and I can see all the information about each run.",
        "tokens": [
          50364,
          400,
          510,
          286,
          393,
          2052,
          322,
          341,
          1190,
          293,
          286,
          393,
          536,
          439,
          264,
          1589,
          466,
          1184,
          1190,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22593878026594194,
        "compression_ratio": 1.4148148148148147,
        "end": 2407,
        "id": 436,
        "no_speech_prob": 0.0013670098269358277,
        "seek": 239000,
        "start": 2402,
        "temperature": 0,
        "text": " This is the run that we just did, run 15.",
        "tokens": [
          50964,
          639,
          307,
          264,
          1190,
          300,
          321,
          445,
          630,
          11,
          1190,
          2119,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22593878026594194,
        "compression_ratio": 1.4148148148148147,
        "end": 2412,
        "id": 437,
        "no_speech_prob": 0.0013670098269358277,
        "seek": 239000,
        "start": 2407,
        "temperature": 0,
        "text": " And it will output a folder called data.",
        "tokens": [
          51214,
          400,
          309,
          486,
          5598,
          257,
          10820,
          1219,
          1412,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22593878026594194,
        "compression_ratio": 1.4148148148148147,
        "end": 2414,
        "id": 438,
        "no_speech_prob": 0.0013670098269358277,
        "seek": 239000,
        "start": 2412,
        "temperature": 0,
        "text": " And this is all the logs.",
        "tokens": [
          51464,
          400,
          341,
          307,
          439,
          264,
          20820,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17537378228229025,
        "compression_ratio": 1.1570247933884297,
        "end": 2420,
        "id": 439,
        "no_speech_prob": 0.00043055324931629,
        "seek": 241400,
        "start": 2415,
        "temperature": 0,
        "text": " And this is the CPU usage, CPU memory.",
        "tokens": [
          50414,
          400,
          341,
          307,
          264,
          13199,
          14924,
          11,
          13199,
          4675,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17537378228229025,
        "compression_ratio": 1.1570247933884297,
        "end": 2429,
        "id": 440,
        "no_speech_prob": 0.00043055324931629,
        "seek": 241400,
        "start": 2424,
        "temperature": 0,
        "text": " So this run will take about 1.5 hours.",
        "tokens": [
          50864,
          407,
          341,
          1190,
          486,
          747,
          466,
          502,
          13,
          20,
          2496,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17537378228229025,
        "compression_ratio": 1.1570247933884297,
        "end": 2433,
        "id": 441,
        "no_speech_prob": 0.00043055324931629,
        "seek": 241400,
        "start": 2429,
        "temperature": 0,
        "text": " But luckily we have another complete run.",
        "tokens": [
          51114,
          583,
          22880,
          321,
          362,
          1071,
          3566,
          1190,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17537378228229025,
        "compression_ratio": 1.1570247933884297,
        "end": 2436,
        "id": 442,
        "no_speech_prob": 0.00043055324931629,
        "seek": 241400,
        "start": 2433,
        "temperature": 0,
        "text": " I think it's run 13.",
        "tokens": [
          51314,
          286,
          519,
          309,
          311,
          1190,
          3705,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2308531460696704,
        "compression_ratio": 1.4523809523809523,
        "end": 2444,
        "id": 443,
        "no_speech_prob": 0.00034062215127050877,
        "seek": 243600,
        "start": 2436,
        "temperature": 0,
        "text": " So on run 13, I run the same command setup here.",
        "tokens": [
          50364,
          407,
          322,
          1190,
          3705,
          11,
          286,
          1190,
          264,
          912,
          5622,
          8657,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2308531460696704,
        "compression_ratio": 1.4523809523809523,
        "end": 2450,
        "id": 444,
        "no_speech_prob": 0.00034062215127050877,
        "seek": 243600,
        "start": 2444,
        "temperature": 0,
        "text": " And it's already completed and it outputs a folder called data.",
        "tokens": [
          50764,
          400,
          309,
          311,
          1217,
          7365,
          293,
          309,
          23930,
          257,
          10820,
          1219,
          1412,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2308531460696704,
        "compression_ratio": 1.4523809523809523,
        "end": 2455,
        "id": 445,
        "no_speech_prob": 0.00034062215127050877,
        "seek": 243600,
        "start": 2450,
        "temperature": 0,
        "text": " And we can click on this data to see what kind of output did we get.",
        "tokens": [
          51064,
          400,
          321,
          393,
          2052,
          322,
          341,
          1412,
          281,
          536,
          437,
          733,
          295,
          5598,
          630,
          321,
          483,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2308531460696704,
        "compression_ratio": 1.4523809523809523,
        "end": 2459,
        "id": 446,
        "no_speech_prob": 0.00034062215127050877,
        "seek": 243600,
        "start": 2455,
        "temperature": 0,
        "text": " See we got this, let me make it bigger.",
        "tokens": [
          51314,
          3008,
          321,
          658,
          341,
          11,
          718,
          385,
          652,
          309,
          3801,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2308531460696704,
        "compression_ratio": 1.4523809523809523,
        "end": 2463,
        "id": 447,
        "no_speech_prob": 0.00034062215127050877,
        "seek": 243600,
        "start": 2460,
        "temperature": 0,
        "text": " We got this VGG model.",
        "tokens": [
          51564,
          492,
          658,
          341,
          691,
          27561,
          2316,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.27645852565765383,
        "compression_ratio": 1.1801801801801801,
        "end": 2468,
        "id": 448,
        "no_speech_prob": 0.00010390928946435452,
        "seek": 246300,
        "start": 2463,
        "temperature": 0,
        "text": " We also got the Cocoa dataset.",
        "tokens": [
          50364,
          492,
          611,
          658,
          264,
          29787,
          64,
          28872,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27645852565765383,
        "compression_ratio": 1.1801801801801801,
        "end": 2471,
        "id": 449,
        "no_speech_prob": 0.00010390928946435452,
        "seek": 246300,
        "start": 2468,
        "temperature": 0,
        "text": " Here it's called train 2014.",
        "tokens": [
          50614,
          1692,
          309,
          311,
          1219,
          3847,
          8227,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.27645852565765383,
        "compression_ratio": 1.1801801801801801,
        "end": 2479,
        "id": 450,
        "no_speech_prob": 0.00010390928946435452,
        "seek": 246300,
        "start": 2471,
        "temperature": 0,
        "text": " So next we're going to use the output from this run to train our model.",
        "tokens": [
          50764,
          407,
          958,
          321,
          434,
          516,
          281,
          764,
          264,
          5598,
          490,
          341,
          1190,
          281,
          3847,
          527,
          2316,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2449185371398926,
        "compression_ratio": 1.4461538461538461,
        "end": 2495,
        "id": 451,
        "no_speech_prob": 0.002115456620231271,
        "seek": 247900,
        "start": 2479,
        "temperature": 0,
        "text": " Okay, so we finished this second step, downloading the dataset.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          321,
          4335,
          341,
          1150,
          1823,
          11,
          32529,
          264,
          28872,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2449185371398926,
        "compression_ratio": 1.4461538461538461,
        "end": 2503,
        "id": 452,
        "no_speech_prob": 0.002115456620231271,
        "seek": 247900,
        "start": 2495,
        "temperature": 0,
        "text": " And we're going to move to the next step, training with style script.",
        "tokens": [
          51164,
          400,
          321,
          434,
          516,
          281,
          1286,
          281,
          264,
          958,
          1823,
          11,
          3097,
          365,
          3758,
          5755,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2449185371398926,
        "compression_ratio": 1.4461538461538461,
        "end": 2506,
        "id": 453,
        "no_speech_prob": 0.002115456620231271,
        "seek": 247900,
        "start": 2503,
        "temperature": 0,
        "text": " And this is the whole command that we're going to run.",
        "tokens": [
          51564,
          400,
          341,
          307,
          264,
          1379,
          5622,
          300,
          321,
          434,
          516,
          281,
          1190,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22587783634662628,
        "compression_ratio": 1.4968152866242037,
        "end": 2511,
        "id": 454,
        "no_speech_prob": 0.00046552071580663323,
        "seek": 250600,
        "start": 2507,
        "temperature": 0,
        "text": " But let's talk about this command before we actually run it.",
        "tokens": [
          50414,
          583,
          718,
          311,
          751,
          466,
          341,
          5622,
          949,
          321,
          767,
          1190,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22587783634662628,
        "compression_ratio": 1.4968152866242037,
        "end": 2516,
        "id": 455,
        "no_speech_prob": 0.00046552071580663323,
        "seek": 250600,
        "start": 2513,
        "temperature": 0,
        "text": " This command starts a new run.",
        "tokens": [
          50714,
          639,
          5622,
          3719,
          257,
          777,
          1190,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22587783634662628,
        "compression_ratio": 1.4968152866242037,
        "end": 2526,
        "id": 456,
        "no_speech_prob": 0.00046552071580663323,
        "seek": 250600,
        "start": 2516,
        "temperature": 0,
        "text": " And it uses this dash dash mount flag to mount the output of our previous run, which is run 13.",
        "tokens": [
          50864,
          400,
          309,
          4960,
          341,
          8240,
          8240,
          3746,
          7166,
          281,
          3746,
          264,
          5598,
          295,
          527,
          3894,
          1190,
          11,
          597,
          307,
          1190,
          3705,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22587783634662628,
        "compression_ratio": 1.4968152866242037,
        "end": 2531,
        "id": 457,
        "no_speech_prob": 0.00046552071580663323,
        "seek": 250600,
        "start": 2526,
        "temperature": 0,
        "text": " For run 13, the output is a folder called data.",
        "tokens": [
          51364,
          1171,
          1190,
          3705,
          11,
          264,
          5598,
          307,
          257,
          10820,
          1219,
          1412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19955459594726563,
        "compression_ratio": 1.6818181818181819,
        "end": 2541,
        "id": 458,
        "no_speech_prob": 0.00041083915857598186,
        "seek": 253100,
        "start": 2531,
        "temperature": 0,
        "text": " And we're going to use this mount flag to copy this data folder into the file system of our next run.",
        "tokens": [
          50364,
          400,
          321,
          434,
          516,
          281,
          764,
          341,
          3746,
          7166,
          281,
          5055,
          341,
          1412,
          10820,
          666,
          264,
          3991,
          1185,
          295,
          527,
          958,
          1190,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19955459594726563,
        "compression_ratio": 1.6818181818181819,
        "end": 2546,
        "id": 459,
        "no_speech_prob": 0.00041083915857598186,
        "seek": 253100,
        "start": 2541,
        "temperature": 0,
        "text": " And we're going to call that folder datasets instead of data.",
        "tokens": [
          50864,
          400,
          321,
          434,
          516,
          281,
          818,
          300,
          10820,
          42856,
          2602,
          295,
          1412,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19955459594726563,
        "compression_ratio": 1.6818181818181819,
        "end": 2549,
        "id": 460,
        "no_speech_prob": 0.00041083915857598186,
        "seek": 253100,
        "start": 2546,
        "temperature": 0,
        "text": " So this is the mount command.",
        "tokens": [
          51114,
          407,
          341,
          307,
          264,
          3746,
          5622,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19955459594726563,
        "compression_ratio": 1.6818181818181819,
        "end": 2553,
        "id": 461,
        "no_speech_prob": 0.00041083915857598186,
        "seek": 253100,
        "start": 2549,
        "temperature": 0,
        "text": " We can see more information on spells documentation.",
        "tokens": [
          51264,
          492,
          393,
          536,
          544,
          1589,
          322,
          25053,
          14333,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19955459594726563,
        "compression_ratio": 1.6818181818181819,
        "end": 2558,
        "id": 462,
        "no_speech_prob": 0.00041083915857598186,
        "seek": 253100,
        "start": 2553,
        "temperature": 0,
        "text": " And then we're going to specify the machine type.",
        "tokens": [
          51464,
          400,
          550,
          321,
          434,
          516,
          281,
          16500,
          264,
          3479,
          2010,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.26817937692006427,
        "compression_ratio": 1.4148148148148147,
        "end": 2562,
        "id": 463,
        "no_speech_prob": 0.001244818209670484,
        "seek": 255800,
        "start": 2558,
        "temperature": 0,
        "text": " I used the V100 machine.",
        "tokens": [
          50364,
          286,
          1143,
          264,
          691,
          6879,
          3479,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26817937692006427,
        "compression_ratio": 1.4148148148148147,
        "end": 2571,
        "id": 464,
        "no_speech_prob": 0.001244818209670484,
        "seek": 255800,
        "start": 2562,
        "temperature": 0,
        "text": " We can check more detailed machine type here.",
        "tokens": [
          50564,
          492,
          393,
          1520,
          544,
          9942,
          3479,
          2010,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.26817937692006427,
        "compression_ratio": 1.4148148148148147,
        "end": 2582,
        "id": 465,
        "no_speech_prob": 0.001244818209670484,
        "seek": 255800,
        "start": 2571,
        "temperature": 0,
        "text": " On the spell run slash docs slash core concepts, here it talks about all those available machine types that you can use.",
        "tokens": [
          51014,
          1282,
          264,
          9827,
          1190,
          17330,
          45623,
          17330,
          4965,
          10392,
          11,
          510,
          309,
          6686,
          466,
          439,
          729,
          2435,
          3479,
          3467,
          300,
          291,
          393,
          764,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19798572439896434,
        "compression_ratio": 1.6686746987951808,
        "end": 2590,
        "id": 466,
        "no_speech_prob": 0.0005192998796701431,
        "seek": 258200,
        "start": 2582,
        "temperature": 0,
        "text": " And here there is a pricing table that lists all the machines that we can use.",
        "tokens": [
          50364,
          400,
          510,
          456,
          307,
          257,
          17621,
          3199,
          300,
          14511,
          439,
          264,
          8379,
          300,
          321,
          393,
          764,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19798572439896434,
        "compression_ratio": 1.6686746987951808,
        "end": 2596,
        "id": 467,
        "no_speech_prob": 0.0005192998796701431,
        "seek": 258200,
        "start": 2590,
        "temperature": 0,
        "text": " The one that I used yesterday is called V100.",
        "tokens": [
          50764,
          440,
          472,
          300,
          286,
          1143,
          5186,
          307,
          1219,
          691,
          6879,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19798572439896434,
        "compression_ratio": 1.6686746987951808,
        "end": 2603,
        "id": 468,
        "no_speech_prob": 0.0005192998796701431,
        "seek": 258200,
        "start": 2596,
        "temperature": 0,
        "text": " And normally it would take 12 hours to train on this K80 machine.",
        "tokens": [
          51064,
          400,
          5646,
          309,
          576,
          747,
          2272,
          2496,
          281,
          3847,
          322,
          341,
          591,
          4702,
          3479,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19798572439896434,
        "compression_ratio": 1.6686746987951808,
        "end": 2609,
        "id": 469,
        "no_speech_prob": 0.0005192998796701431,
        "seek": 258200,
        "start": 2603,
        "temperature": 0,
        "text": " And it would take four hours to train on this V100 machine.",
        "tokens": [
          51414,
          400,
          309,
          576,
          747,
          1451,
          2496,
          281,
          3847,
          322,
          341,
          691,
          6879,
          3479,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19798572439896434,
        "compression_ratio": 1.6686746987951808,
        "end": 2611,
        "id": 470,
        "no_speech_prob": 0.0005192998796701431,
        "seek": 258200,
        "start": 2609,
        "temperature": 0,
        "text": " But I tried it four times.",
        "tokens": [
          51714,
          583,
          286,
          3031,
          309,
          1451,
          1413,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21156535829816545,
        "compression_ratio": 1.4745762711864407,
        "end": 2616,
        "id": 471,
        "no_speech_prob": 0.00048029335448518395,
        "seek": 261100,
        "start": 2611,
        "temperature": 0,
        "text": " It only took me two hours to train on this V100 machine.",
        "tokens": [
          50364,
          467,
          787,
          1890,
          385,
          732,
          2496,
          281,
          3847,
          322,
          341,
          691,
          6879,
          3479,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21156535829816545,
        "compression_ratio": 1.4745762711864407,
        "end": 2620,
        "id": 472,
        "no_speech_prob": 0.00048029335448518395,
        "seek": 261100,
        "start": 2616,
        "temperature": 0,
        "text": " So this is the machine type.",
        "tokens": [
          50614,
          407,
          341,
          307,
          264,
          3479,
          2010,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21156535829816545,
        "compression_ratio": 1.4745762711864407,
        "end": 2626,
        "id": 473,
        "no_speech_prob": 0.00048029335448518395,
        "seek": 261100,
        "start": 2620,
        "temperature": 0,
        "text": " And next command we specify the framework is TensorFlow.",
        "tokens": [
          50814,
          400,
          958,
          5622,
          321,
          16500,
          264,
          8388,
          307,
          37624,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21156535829816545,
        "compression_ratio": 1.4745762711864407,
        "end": 2632,
        "id": 474,
        "no_speech_prob": 0.00048029335448518395,
        "seek": 261100,
        "start": 2626,
        "temperature": 0,
        "text": " And also we are going to get some actual package for those.",
        "tokens": [
          51114,
          400,
          611,
          321,
          366,
          516,
          281,
          483,
          512,
          3539,
          7372,
          337,
          729,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21156535829816545,
        "compression_ratio": 1.4745762711864407,
        "end": 2634,
        "id": 475,
        "no_speech_prob": 0.00048029335448518395,
        "seek": 261100,
        "start": 2632,
        "temperature": 0,
        "text": " Those are two actual packages.",
        "tokens": [
          51414,
          3950,
          366,
          732,
          3539,
          17401,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21156535829816545,
        "compression_ratio": 1.4745762711864407,
        "end": 2636,
        "id": 476,
        "no_speech_prob": 0.00048029335448518395,
        "seek": 261100,
        "start": 2634,
        "temperature": 0,
        "text": " They're for video transfer.",
        "tokens": [
          51514,
          814,
          434,
          337,
          960,
          5003,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23056564331054688,
        "compression_ratio": 1.6627218934911243,
        "end": 2642,
        "id": 477,
        "no_speech_prob": 0.06007692590355873,
        "seek": 263600,
        "start": 2637,
        "temperature": 0,
        "text": " And you can use dash dash app dash dash pip to get all those packages.",
        "tokens": [
          50414,
          400,
          291,
          393,
          764,
          8240,
          8240,
          724,
          8240,
          8240,
          8489,
          281,
          483,
          439,
          729,
          17401,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23056564331054688,
        "compression_ratio": 1.6627218934911243,
        "end": 2649,
        "id": 478,
        "no_speech_prob": 0.06007692590355873,
        "seek": 263600,
        "start": 2642,
        "temperature": 0,
        "text": " And this is the actual Python command that we are going to run.",
        "tokens": [
          50664,
          400,
          341,
          307,
          264,
          3539,
          15329,
          5622,
          300,
          321,
          366,
          516,
          281,
          1190,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23056564331054688,
        "compression_ratio": 1.6627218934911243,
        "end": 2652,
        "id": 479,
        "no_speech_prob": 0.06007692590355873,
        "seek": 263600,
        "start": 2649,
        "temperature": 0,
        "text": " We are going to run the style Python script.",
        "tokens": [
          51014,
          492,
          366,
          516,
          281,
          1190,
          264,
          3758,
          15329,
          5755,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23056564331054688,
        "compression_ratio": 1.6627218934911243,
        "end": 2662,
        "id": 480,
        "no_speech_prob": 0.06007692590355873,
        "seek": 263600,
        "start": 2652,
        "temperature": 0,
        "text": " And we are going to tell the script that we want the output to be at a folder called CKPT checkpoint.",
        "tokens": [
          51164,
          400,
          321,
          366,
          516,
          281,
          980,
          264,
          5755,
          300,
          321,
          528,
          264,
          5598,
          281,
          312,
          412,
          257,
          10820,
          1219,
          383,
          42,
          47,
          51,
          42269,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21640503163240393,
        "compression_ratio": 1.4137931034482758,
        "end": 2670,
        "id": 481,
        "no_speech_prob": 0.0007793480181135237,
        "seek": 266200,
        "start": 2663,
        "temperature": 0,
        "text": " And we are also going to tell the script that this is the path to our style image.",
        "tokens": [
          50414,
          400,
          321,
          366,
          611,
          516,
          281,
          980,
          264,
          5755,
          300,
          341,
          307,
          264,
          3100,
          281,
          527,
          3758,
          3256,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21640503163240393,
        "compression_ratio": 1.4137931034482758,
        "end": 2674,
        "id": 482,
        "no_speech_prob": 0.0007793480181135237,
        "seek": 266200,
        "start": 2670,
        "temperature": 0,
        "text": " And this is the style weight.",
        "tokens": [
          50764,
          400,
          341,
          307,
          264,
          3758,
          3364,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21640503163240393,
        "compression_ratio": 1.4137931034482758,
        "end": 2678,
        "id": 483,
        "no_speech_prob": 0.0007793480181135237,
        "seek": 266200,
        "start": 2674,
        "temperature": 0,
        "text": " This is the style loss of that model.",
        "tokens": [
          50964,
          639,
          307,
          264,
          3758,
          4470,
          295,
          300,
          2316,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21640503163240393,
        "compression_ratio": 1.4137931034482758,
        "end": 2681,
        "id": 484,
        "no_speech_prob": 0.0007793480181135237,
        "seek": 266200,
        "start": 2678,
        "temperature": 0,
        "text": " Which is 150.",
        "tokens": [
          51164,
          3013,
          307,
          8451,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.25227358803820255,
        "compression_ratio": 1.5093167701863355,
        "end": 2693,
        "id": 485,
        "no_speech_prob": 0.039632946252822876,
        "seek": 268100,
        "start": 2681,
        "temperature": 0,
        "text": " But you can read more about it at Logan's GitHub repo about the default style weight and other information.",
        "tokens": [
          50364,
          583,
          291,
          393,
          1401,
          544,
          466,
          309,
          412,
          22689,
          311,
          23331,
          49040,
          466,
          264,
          7576,
          3758,
          3364,
          293,
          661,
          1589,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25227358803820255,
        "compression_ratio": 1.5093167701863355,
        "end": 2702,
        "id": 486,
        "no_speech_prob": 0.039632946252822876,
        "seek": 268100,
        "start": 2698,
        "temperature": 0,
        "text": " And we also need to specify the train path.",
        "tokens": [
          51214,
          400,
          321,
          611,
          643,
          281,
          16500,
          264,
          3847,
          3100,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.25227358803820255,
        "compression_ratio": 1.5093167701863355,
        "end": 2705,
        "id": 487,
        "no_speech_prob": 0.039632946252822876,
        "seek": 268100,
        "start": 2702,
        "temperature": 0,
        "text": " This is the path to our Cocoa dataset.",
        "tokens": [
          51414,
          639,
          307,
          264,
          3100,
          281,
          527,
          29787,
          64,
          28872,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25227358803820255,
        "compression_ratio": 1.5093167701863355,
        "end": 2709,
        "id": 488,
        "no_speech_prob": 0.039632946252822876,
        "seek": 268100,
        "start": 2705,
        "temperature": 0,
        "text": " And this is the VGG path, the path to our VGG model.",
        "tokens": [
          51564,
          400,
          341,
          307,
          264,
          691,
          27561,
          3100,
          11,
          264,
          3100,
          281,
          527,
          691,
          27561,
          2316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2781416977508159,
        "compression_ratio": 1.541899441340782,
        "end": 2712,
        "id": 489,
        "no_speech_prob": 0.00006814282824052498,
        "seek": 270900,
        "start": 2710,
        "temperature": 0,
        "text": " And we don't need to change any of this.",
        "tokens": [
          50414,
          400,
          321,
          500,
          380,
          643,
          281,
          1319,
          604,
          295,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2781416977508159,
        "compression_ratio": 1.541899441340782,
        "end": 2717,
        "id": 490,
        "no_speech_prob": 0.00006814282824052498,
        "seek": 270900,
        "start": 2712,
        "temperature": 0,
        "text": " The only thing that we need to change is our run number.",
        "tokens": [
          50514,
          440,
          787,
          551,
          300,
          321,
          643,
          281,
          1319,
          307,
          527,
          1190,
          1230,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2781416977508159,
        "compression_ratio": 1.541899441340782,
        "end": 2724,
        "id": 491,
        "no_speech_prob": 0.00006814282824052498,
        "seek": 270900,
        "start": 2717,
        "temperature": 0,
        "text": " Which would be 13 because 13 run download all those dataset.",
        "tokens": [
          50764,
          3013,
          576,
          312,
          3705,
          570,
          3705,
          1190,
          5484,
          439,
          729,
          28872,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2781416977508159,
        "compression_ratio": 1.541899441340782,
        "end": 2733,
        "id": 492,
        "no_speech_prob": 0.00006814282824052498,
        "seek": 270900,
        "start": 2724,
        "temperature": 0,
        "text": " And we are also going to change the style image name to our own image name which is fuchuan.jpg.",
        "tokens": [
          51114,
          400,
          321,
          366,
          611,
          516,
          281,
          1319,
          264,
          3758,
          3256,
          1315,
          281,
          527,
          1065,
          3256,
          1315,
          597,
          307,
          283,
          625,
          6139,
          13,
          73,
          49861,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2781416977508159,
        "compression_ratio": 1.541899441340782,
        "end": 2738,
        "id": 493,
        "no_speech_prob": 0.00006814282824052498,
        "seek": 270900,
        "start": 2736,
        "temperature": 0,
        "text": " Okay, let's do this.",
        "tokens": [
          51714,
          1033,
          11,
          718,
          311,
          360,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.31011828860721075,
        "compression_ratio": 1.141304347826087,
        "end": 2744,
        "id": 494,
        "no_speech_prob": 0.00008480894030071795,
        "seek": 273900,
        "start": 2740,
        "temperature": 0,
        "text": " So I copy paste this command.",
        "tokens": [
          50414,
          407,
          286,
          5055,
          9163,
          341,
          5622,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.31011828860721075,
        "compression_ratio": 1.141304347826087,
        "end": 2753,
        "id": 495,
        "no_speech_prob": 0.00008480894030071795,
        "seek": 273900,
        "start": 2748,
        "temperature": 0,
        "text": " And here.",
        "tokens": [
          50814,
          400,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.31011828860721075,
        "compression_ratio": 1.141304347826087,
        "end": 2760,
        "id": 496,
        "no_speech_prob": 0.00008480894030071795,
        "seek": 273900,
        "start": 2758,
        "temperature": 0,
        "text": " I'm just going to replace.",
        "tokens": [
          51314,
          286,
          478,
          445,
          516,
          281,
          7406,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.31011828860721075,
        "compression_ratio": 1.141304347826087,
        "end": 2764,
        "id": 497,
        "no_speech_prob": 0.00008480894030071795,
        "seek": 273900,
        "start": 2760,
        "temperature": 0,
        "text": " I will just go to a code editor first.",
        "tokens": [
          51414,
          286,
          486,
          445,
          352,
          281,
          257,
          3089,
          9839,
          700,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.182262449998122,
        "compression_ratio": 1.4965034965034965,
        "end": 2776,
        "id": 498,
        "no_speech_prob": 0.00012147251254646108,
        "seek": 276400,
        "start": 2765,
        "temperature": 0,
        "text": " I'm going to replace this with my real style transfer style image which is fuchuan.jpg.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          7406,
          341,
          365,
          452,
          957,
          3758,
          5003,
          3758,
          3256,
          597,
          307,
          283,
          625,
          6139,
          13,
          73,
          49861,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.182262449998122,
        "compression_ratio": 1.4965034965034965,
        "end": 2782,
        "id": 499,
        "no_speech_prob": 0.00012147251254646108,
        "seek": 276400,
        "start": 2776,
        "temperature": 0,
        "text": " And also I'm going to replace this, the run number of my setup run to 13.",
        "tokens": [
          50964,
          400,
          611,
          286,
          478,
          516,
          281,
          7406,
          341,
          11,
          264,
          1190,
          1230,
          295,
          452,
          8657,
          1190,
          281,
          3705,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.182262449998122,
        "compression_ratio": 1.4965034965034965,
        "end": 2784,
        "id": 500,
        "no_speech_prob": 0.00012147251254646108,
        "seek": 276400,
        "start": 2782,
        "temperature": 0,
        "text": " Because that is the run that we used.",
        "tokens": [
          51264,
          1436,
          300,
          307,
          264,
          1190,
          300,
          321,
          1143,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.182262449998122,
        "compression_ratio": 1.4965034965034965,
        "end": 2786,
        "id": 501,
        "no_speech_prob": 0.00012147251254646108,
        "seek": 276400,
        "start": 2784,
        "temperature": 0,
        "text": " And that's it.",
        "tokens": [
          51364,
          400,
          300,
          311,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26414892077445984,
        "compression_ratio": 1.4248366013071896,
        "end": 2794,
        "id": 502,
        "no_speech_prob": 0.000046109675167826936,
        "seek": 278600,
        "start": 2787,
        "temperature": 0,
        "text": " So now we should be able to copy paste this command and run it in our spell.",
        "tokens": [
          50414,
          407,
          586,
          321,
          820,
          312,
          1075,
          281,
          5055,
          9163,
          341,
          5622,
          293,
          1190,
          309,
          294,
          527,
          9827,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26414892077445984,
        "compression_ratio": 1.4248366013071896,
        "end": 2798,
        "id": 503,
        "no_speech_prob": 0.000046109675167826936,
        "seek": 278600,
        "start": 2794,
        "temperature": 0,
        "text": " And by running this we are going to start a new run to train the model.",
        "tokens": [
          50764,
          400,
          538,
          2614,
          341,
          321,
          366,
          516,
          281,
          722,
          257,
          777,
          1190,
          281,
          3847,
          264,
          2316,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26414892077445984,
        "compression_ratio": 1.4248366013071896,
        "end": 2803,
        "id": 504,
        "no_speech_prob": 0.000046109675167826936,
        "seek": 278600,
        "start": 2801,
        "temperature": 0,
        "text": " Let's just do it.",
        "tokens": [
          51114,
          961,
          311,
          445,
          360,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26414892077445984,
        "compression_ratio": 1.4248366013071896,
        "end": 2808,
        "id": 505,
        "no_speech_prob": 0.000046109675167826936,
        "seek": 278600,
        "start": 2806,
        "temperature": 0,
        "text": " And it says casting spell.",
        "tokens": [
          51364,
          400,
          309,
          1619,
          17301,
          9827,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26414892077445984,
        "compression_ratio": 1.4248366013071896,
        "end": 2812,
        "id": 506,
        "no_speech_prob": 0.000046109675167826936,
        "seek": 278600,
        "start": 2809,
        "temperature": 0,
        "text": " Machine requested, done.",
        "tokens": [
          51514,
          22155,
          16436,
          11,
          1096,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2815,
        "id": 507,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2813,
        "temperature": 0,
        "text": " Run is running.",
        "tokens": [
          50414,
          8950,
          307,
          2614,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2816,
        "id": 508,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2815,
        "temperature": 0,
        "text": " Mounting is done.",
        "tokens": [
          50514,
          8426,
          278,
          307,
          1096,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2820,
        "id": 509,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2816,
        "temperature": 0,
        "text": " We mount the data folder to this run.",
        "tokens": [
          50564,
          492,
          3746,
          264,
          1412,
          10820,
          281,
          341,
          1190,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2826,
        "id": 510,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2823,
        "temperature": 0,
        "text": " And it says Tesla V100.",
        "tokens": [
          50914,
          400,
          309,
          1619,
          13666,
          691,
          6879,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2828,
        "id": 511,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2826,
        "temperature": 0,
        "text": " This is the machine type.",
        "tokens": [
          51064,
          639,
          307,
          264,
          3479,
          2010,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2832,
        "id": 512,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2829,
        "temperature": 0,
        "text": " I think it will give more information.",
        "tokens": [
          51214,
          286,
          519,
          309,
          486,
          976,
          544,
          1589,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21908600229612538,
        "compression_ratio": 1.393939393939394,
        "end": 2840,
        "id": 513,
        "no_speech_prob": 0.00004469329724088311,
        "seek": 281200,
        "start": 2832,
        "temperature": 0,
        "text": " I'm just going to do control C to let it stop logging all those logs.",
        "tokens": [
          51364,
          286,
          478,
          445,
          516,
          281,
          360,
          1969,
          383,
          281,
          718,
          309,
          1590,
          27991,
          439,
          729,
          20820,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2161644846200943,
        "compression_ratio": 1.3708609271523178,
        "end": 2847,
        "id": 514,
        "no_speech_prob": 0.0000760160619392991,
        "seek": 284200,
        "start": 2843,
        "temperature": 0,
        "text": " And we can also do spell ps to see our run.",
        "tokens": [
          50414,
          400,
          321,
          393,
          611,
          360,
          9827,
          18815,
          281,
          536,
          527,
          1190,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2161644846200943,
        "compression_ratio": 1.3708609271523178,
        "end": 2851,
        "id": 515,
        "no_speech_prob": 0.0000760160619392991,
        "seek": 284200,
        "start": 2847,
        "temperature": 0,
        "text": " So now I actually have two runs running.",
        "tokens": [
          50614,
          407,
          586,
          286,
          767,
          362,
          732,
          6676,
          2614,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2161644846200943,
        "compression_ratio": 1.3708609271523178,
        "end": 2853,
        "id": 516,
        "no_speech_prob": 0.0000760160619392991,
        "seek": 284200,
        "start": 2851,
        "temperature": 0,
        "text": " The first one is the setup.",
        "tokens": [
          50814,
          440,
          700,
          472,
          307,
          264,
          8657,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2161644846200943,
        "compression_ratio": 1.3708609271523178,
        "end": 2855,
        "id": 517,
        "no_speech_prob": 0.0000760160619392991,
        "seek": 284200,
        "start": 2853,
        "temperature": 0,
        "text": " I'm still waiting for that to finish.",
        "tokens": [
          50914,
          286,
          478,
          920,
          3806,
          337,
          300,
          281,
          2413,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2161644846200943,
        "compression_ratio": 1.3708609271523178,
        "end": 2859,
        "id": 518,
        "no_speech_prob": 0.0000760160619392991,
        "seek": 284200,
        "start": 2855,
        "temperature": 0,
        "text": " And then this is the training script.",
        "tokens": [
          51014,
          400,
          550,
          341,
          307,
          264,
          3097,
          5755,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2161644846200943,
        "compression_ratio": 1.3708609271523178,
        "end": 2862,
        "id": 519,
        "no_speech_prob": 0.0000760160619392991,
        "seek": 284200,
        "start": 2860,
        "temperature": 0,
        "text": " This V100 machine.",
        "tokens": [
          51264,
          639,
          691,
          6879,
          3479,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2789856678730733,
        "compression_ratio": 1.5363128491620113,
        "end": 2870,
        "id": 520,
        "no_speech_prob": 0.0003859464777633548,
        "seek": 286200,
        "start": 2863,
        "temperature": 0,
        "text": " Oh, and the one thing I forgot to mention is because it takes a while to finish this run,",
        "tokens": [
          50414,
          876,
          11,
          293,
          264,
          472,
          551,
          286,
          5298,
          281,
          2152,
          307,
          570,
          309,
          2516,
          257,
          1339,
          281,
          2413,
          341,
          1190,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2789856678730733,
        "compression_ratio": 1.5363128491620113,
        "end": 2875,
        "id": 521,
        "no_speech_prob": 0.0003859464777633548,
        "seek": 286200,
        "start": 2870,
        "temperature": 0,
        "text": " on spell there is a place that we can set notifications.",
        "tokens": [
          50764,
          322,
          9827,
          456,
          307,
          257,
          1081,
          300,
          321,
          393,
          992,
          13426,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2789856678730733,
        "compression_ratio": 1.5363128491620113,
        "end": 2881,
        "id": 522,
        "no_speech_prob": 0.0003859464777633548,
        "seek": 286200,
        "start": 2875,
        "temperature": 0,
        "text": " So it will send us emails when this run takes too long and will cost too much money.",
        "tokens": [
          51014,
          407,
          309,
          486,
          2845,
          505,
          12524,
          562,
          341,
          1190,
          2516,
          886,
          938,
          293,
          486,
          2063,
          886,
          709,
          1460,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2789856678730733,
        "compression_ratio": 1.5363128491620113,
        "end": 2885,
        "id": 523,
        "no_speech_prob": 0.0003859464777633548,
        "seek": 286200,
        "start": 2881,
        "temperature": 0,
        "text": " So on my spell account, if I go to setting,",
        "tokens": [
          51314,
          407,
          322,
          452,
          9827,
          2696,
          11,
          498,
          286,
          352,
          281,
          3287,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.5098321097237724,
        "compression_ratio": 1.5333333333333334,
        "end": 2897,
        "id": 524,
        "no_speech_prob": 0.0012255394831299782,
        "seek": 288500,
        "start": 2885,
        "temperature": 0,
        "text": " and notifications here, I can set some email notifications saying email me if the run exceeds $20.",
        "tokens": [
          50364,
          293,
          13426,
          510,
          11,
          286,
          393,
          992,
          512,
          3796,
          13426,
          1566,
          3796,
          385,
          498,
          264,
          1190,
          43305,
          1848,
          2009,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.5098321097237724,
        "compression_ratio": 1.5333333333333334,
        "end": 2903,
        "id": 525,
        "no_speech_prob": 0.0012255394831299782,
        "seek": 288500,
        "start": 2897,
        "temperature": 0,
        "text": " Things like this in case the run takes too long.",
        "tokens": [
          50964,
          9514,
          411,
          341,
          294,
          1389,
          264,
          1190,
          2516,
          886,
          938,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.5098321097237724,
        "compression_ratio": 1.5333333333333334,
        "end": 2906,
        "id": 526,
        "no_speech_prob": 0.0012255394831299782,
        "seek": 288500,
        "start": 2903,
        "temperature": 0,
        "text": " So we can do this.",
        "tokens": [
          51264,
          407,
          321,
          393,
          360,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.5098321097237724,
        "compression_ratio": 1.5333333333333334,
        "end": 2909,
        "id": 527,
        "no_speech_prob": 0.0012255394831299782,
        "seek": 288500,
        "start": 2906,
        "temperature": 0,
        "text": " And then we can also set a notification.",
        "tokens": [
          51414,
          400,
          550,
          321,
          393,
          611,
          992,
          257,
          11554,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2558932962088749,
        "compression_ratio": 1.4161073825503356,
        "end": 2911,
        "id": 528,
        "no_speech_prob": 0.003884389763697982,
        "seek": 290900,
        "start": 2909,
        "temperature": 0,
        "text": " The run takes too long.",
        "tokens": [
          50364,
          440,
          1190,
          2516,
          886,
          938,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2558932962088749,
        "compression_ratio": 1.4161073825503356,
        "end": 2914,
        "id": 529,
        "no_speech_prob": 0.003884389763697982,
        "seek": 290900,
        "start": 2912,
        "temperature": 0,
        "text": " So we can do this.",
        "tokens": [
          50514,
          407,
          321,
          393,
          360,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2558932962088749,
        "compression_ratio": 1.4161073825503356,
        "end": 2924,
        "id": 530,
        "no_speech_prob": 0.003884389763697982,
        "seek": 290900,
        "start": 2914,
        "temperature": 0,
        "text": " And also, if you're curious about the versions of packages and frameworks that we have in the spell environment,",
        "tokens": [
          50614,
          400,
          611,
          11,
          498,
          291,
          434,
          6369,
          466,
          264,
          9606,
          295,
          17401,
          293,
          29834,
          300,
          321,
          362,
          294,
          264,
          9827,
          2823,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2558932962088749,
        "compression_ratio": 1.4161073825503356,
        "end": 2934,
        "id": 531,
        "no_speech_prob": 0.003884389763697982,
        "seek": 290900,
        "start": 2924,
        "temperature": 0,
        "text": " one thing that we can do is to do spell run pip phrase.",
        "tokens": [
          51114,
          472,
          551,
          300,
          321,
          393,
          360,
          307,
          281,
          360,
          9827,
          1190,
          8489,
          9535,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2514602220975436,
        "compression_ratio": 1.1568627450980393,
        "end": 2940,
        "id": 532,
        "no_speech_prob": 0.0002780260401777923,
        "seek": 293400,
        "start": 2935,
        "temperature": 0,
        "text": " It will log out all those installed packages for us.",
        "tokens": [
          50414,
          467,
          486,
          3565,
          484,
          439,
          729,
          8899,
          17401,
          337,
          505,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2514602220975436,
        "compression_ratio": 1.1568627450980393,
        "end": 2943,
        "id": 533,
        "no_speech_prob": 0.0002780260401777923,
        "seek": 293400,
        "start": 2941,
        "temperature": 0,
        "text": " So this is a new run tip.",
        "tokens": [
          50714,
          407,
          341,
          307,
          257,
          777,
          1190,
          4125,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2514602220975436,
        "compression_ratio": 1.1568627450980393,
        "end": 2947,
        "id": 534,
        "no_speech_prob": 0.0002780260401777923,
        "seek": 293400,
        "start": 2944,
        "temperature": 0,
        "text": " Casting spell 17.",
        "tokens": [
          50864,
          11019,
          278,
          9827,
          3282,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2514602220975436,
        "compression_ratio": 1.1568627450980393,
        "end": 2959,
        "id": 535,
        "no_speech_prob": 0.0002780260401777923,
        "seek": 293400,
        "start": 2958,
        "temperature": 0,
        "text": " And this is finished.",
        "tokens": [
          51564,
          400,
          341,
          307,
          4335,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2961,
        "id": 536,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2959,
        "temperature": 0,
        "text": " The total run time is 10 seconds.",
        "tokens": [
          50364,
          440,
          3217,
          1190,
          565,
          307,
          1266,
          3949,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2964,
        "id": 537,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2961,
        "temperature": 0,
        "text": " And we can see all those installed packages.",
        "tokens": [
          50464,
          400,
          321,
          393,
          536,
          439,
          729,
          8899,
          17401,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2967,
        "id": 538,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2964,
        "temperature": 0,
        "text": " TensorFlow 1.10.1.",
        "tokens": [
          50614,
          37624,
          502,
          13,
          3279,
          13,
          16,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2971,
        "id": 539,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2967,
        "temperature": 0,
        "text": " Things like this if you're curious about the versions of the frameworks.",
        "tokens": [
          50764,
          9514,
          411,
          341,
          498,
          291,
          434,
          6369,
          466,
          264,
          9606,
          295,
          264,
          29834,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2981,
        "id": 540,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2976,
        "temperature": 0,
        "text": " Yeah, so let's go back to see how did our run.",
        "tokens": [
          51214,
          865,
          11,
          370,
          718,
          311,
          352,
          646,
          281,
          536,
          577,
          630,
          527,
          1190,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2984,
        "id": 541,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2983,
        "temperature": 0,
        "text": " Run's doing.",
        "tokens": [
          51564,
          8950,
          311,
          884,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23485733213878812,
        "compression_ratio": 1.415,
        "end": 2988,
        "id": 542,
        "no_speech_prob": 0.00030533780227415264,
        "seek": 295900,
        "start": 2984,
        "temperature": 0,
        "text": " So this is the run that I just started for training.",
        "tokens": [
          51614,
          407,
          341,
          307,
          264,
          1190,
          300,
          286,
          445,
          1409,
          337,
          3097,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2246682125589122,
        "compression_ratio": 1.2479338842975207,
        "end": 2991,
        "id": 543,
        "no_speech_prob": 0.00031500926706939936,
        "seek": 298800,
        "start": 2988,
        "temperature": 0,
        "text": " It has been running for three minutes.",
        "tokens": [
          50364,
          467,
          575,
          668,
          2614,
          337,
          1045,
          2077,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2246682125589122,
        "compression_ratio": 1.2479338842975207,
        "end": 2995,
        "id": 544,
        "no_speech_prob": 0.00031500926706939936,
        "seek": 298800,
        "start": 2991,
        "temperature": 0,
        "text": " And it's still running.",
        "tokens": [
          50514,
          400,
          309,
          311,
          920,
          2614,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2246682125589122,
        "compression_ratio": 1.2479338842975207,
        "end": 3007,
        "id": 545,
        "no_speech_prob": 0.00031500926706939936,
        "seek": 298800,
        "start": 3004,
        "temperature": 0,
        "text": " It will take about like two hours to finish.",
        "tokens": [
          51164,
          467,
          486,
          747,
          466,
          411,
          732,
          2496,
          281,
          2413,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2246682125589122,
        "compression_ratio": 1.2479338842975207,
        "end": 3015,
        "id": 546,
        "no_speech_prob": 0.00031500926706939936,
        "seek": 298800,
        "start": 3008,
        "temperature": 0,
        "text": " But I have a complete run, which is run 14.",
        "tokens": [
          51364,
          583,
          286,
          362,
          257,
          3566,
          1190,
          11,
          597,
          307,
          1190,
          3499,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23877612880018892,
        "compression_ratio": 1.4429530201342282,
        "end": 3021,
        "id": 547,
        "no_speech_prob": 0.00037995772436261177,
        "seek": 301500,
        "start": 3015,
        "temperature": 0,
        "text": " Run 14 also takes like two hours and six minutes to finish.",
        "tokens": [
          50364,
          8950,
          3499,
          611,
          2516,
          411,
          732,
          2496,
          293,
          2309,
          2077,
          281,
          2413,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23877612880018892,
        "compression_ratio": 1.4429530201342282,
        "end": 3027,
        "id": 548,
        "no_speech_prob": 0.00037995772436261177,
        "seek": 301500,
        "start": 3021,
        "temperature": 0,
        "text": " But here I trained another style image.",
        "tokens": [
          50664,
          583,
          510,
          286,
          8895,
          1071,
          3758,
          3256,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23877612880018892,
        "compression_ratio": 1.4429530201342282,
        "end": 3031,
        "id": 549,
        "no_speech_prob": 0.00037995772436261177,
        "seek": 301500,
        "start": 3028,
        "temperature": 0,
        "text": " See, I had this exactly same run.",
        "tokens": [
          51014,
          3008,
          11,
          286,
          632,
          341,
          2293,
          912,
          1190,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23877612880018892,
        "compression_ratio": 1.4429530201342282,
        "end": 3037,
        "id": 550,
        "no_speech_prob": 0.00037995772436261177,
        "seek": 301500,
        "start": 3033,
        "temperature": 0,
        "text": " But I trained this model on this Lotus image.",
        "tokens": [
          51264,
          583,
          286,
          8895,
          341,
          2316,
          322,
          341,
          44769,
          3256,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23877612880018892,
        "compression_ratio": 1.4429530201342282,
        "end": 3043,
        "id": 551,
        "no_speech_prob": 0.00037995772436261177,
        "seek": 301500,
        "start": 3039,
        "temperature": 0,
        "text": " And this is the output of this run.",
        "tokens": [
          51564,
          400,
          341,
          307,
          264,
          5598,
          295,
          341,
          1190,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.26547875275483,
        "compression_ratio": 1.5466666666666666,
        "end": 3049,
        "id": 552,
        "no_speech_prob": 0.00007254254160216078,
        "seek": 304300,
        "start": 3043,
        "temperature": 0,
        "text": " So when we are waiting for our run 16 to finish,",
        "tokens": [
          50364,
          407,
          562,
          321,
          366,
          3806,
          337,
          527,
          1190,
          3165,
          281,
          2413,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.26547875275483,
        "compression_ratio": 1.5466666666666666,
        "end": 3052,
        "id": 553,
        "no_speech_prob": 0.00007254254160216078,
        "seek": 304300,
        "start": 3049,
        "temperature": 0,
        "text": " we can use this run 14.",
        "tokens": [
          50664,
          321,
          393,
          764,
          341,
          1190,
          3499,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26547875275483,
        "compression_ratio": 1.5466666666666666,
        "end": 3057,
        "id": 554,
        "no_speech_prob": 0.00007254254160216078,
        "seek": 304300,
        "start": 3052,
        "temperature": 0,
        "text": " This run 14 output a new folder called ckpt checkpoint.",
        "tokens": [
          50814,
          639,
          1190,
          3499,
          5598,
          257,
          777,
          10820,
          1219,
          269,
          74,
          662,
          42269,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.26547875275483,
        "compression_ratio": 1.5466666666666666,
        "end": 3062,
        "id": 555,
        "no_speech_prob": 0.00007254254160216078,
        "seek": 304300,
        "start": 3057,
        "temperature": 0,
        "text": " And if we open this folder, we can see there are,",
        "tokens": [
          51064,
          400,
          498,
          321,
          1269,
          341,
          10820,
          11,
          321,
          393,
          536,
          456,
          366,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.26547875275483,
        "compression_ratio": 1.5466666666666666,
        "end": 3064,
        "id": 556,
        "no_speech_prob": 0.00007254254160216078,
        "seek": 304300,
        "start": 3062,
        "temperature": 0,
        "text": " let me make this bigger.",
        "tokens": [
          51314,
          718,
          385,
          652,
          341,
          3801,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26547875275483,
        "compression_ratio": 1.5466666666666666,
        "end": 3069,
        "id": 557,
        "no_speech_prob": 0.00007254254160216078,
        "seek": 304300,
        "start": 3066,
        "temperature": 0,
        "text": " If we open this ckpt folder,",
        "tokens": [
          51514,
          759,
          321,
          1269,
          341,
          269,
          74,
          662,
          10820,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.3032298977092161,
        "compression_ratio": 1.36986301369863,
        "end": 3075,
        "id": 558,
        "no_speech_prob": 0.00010391014802735299,
        "seek": 306900,
        "start": 3069,
        "temperature": 0,
        "text": " if everything goes well, we should be able to see four files in this folder.",
        "tokens": [
          50364,
          498,
          1203,
          1709,
          731,
          11,
          321,
          820,
          312,
          1075,
          281,
          536,
          1451,
          7098,
          294,
          341,
          10820,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3032298977092161,
        "compression_ratio": 1.36986301369863,
        "end": 3083,
        "id": 559,
        "no_speech_prob": 0.00010391014802735299,
        "seek": 306900,
        "start": 3075,
        "temperature": 0,
        "text": " There are checkpoint.data.index.meta.",
        "tokens": [
          50664,
          821,
          366,
          42269,
          13,
          67,
          3274,
          13,
          471,
          3121,
          13,
          5537,
          64,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3032298977092161,
        "compression_ratio": 1.36986301369863,
        "end": 3088,
        "id": 560,
        "no_speech_prob": 0.00010391014802735299,
        "seek": 306900,
        "start": 3083,
        "temperature": 0,
        "text": " This is a format of TensorFlow's saved model.",
        "tokens": [
          51064,
          639,
          307,
          257,
          7877,
          295,
          37624,
          311,
          6624,
          2316,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3032298977092161,
        "compression_ratio": 1.36986301369863,
        "end": 3094,
        "id": 561,
        "no_speech_prob": 0.00010391014802735299,
        "seek": 306900,
        "start": 3088,
        "temperature": 0,
        "text": " This.meta stores the graph information.",
        "tokens": [
          51314,
          639,
          2411,
          5537,
          64,
          9512,
          264,
          4295,
          1589,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24407266889299664,
        "compression_ratio": 1.5348837209302326,
        "end": 3100,
        "id": 562,
        "no_speech_prob": 0.0000991516062640585,
        "seek": 309400,
        "start": 3095,
        "temperature": 0,
        "text": " And this.data file here,",
        "tokens": [
          50414,
          400,
          341,
          2411,
          67,
          3274,
          3991,
          510,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.24407266889299664,
        "compression_ratio": 1.5348837209302326,
        "end": 3104,
        "id": 563,
        "no_speech_prob": 0.0000991516062640585,
        "seek": 309400,
        "start": 3100,
        "temperature": 0,
        "text": " it stores the values of each variable in that graph.",
        "tokens": [
          50664,
          309,
          9512,
          264,
          4190,
          295,
          1184,
          7006,
          294,
          300,
          4295,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24407266889299664,
        "compression_ratio": 1.5348837209302326,
        "end": 3109,
        "id": 564,
        "no_speech_prob": 0.0000991516062640585,
        "seek": 309400,
        "start": 3104,
        "temperature": 0,
        "text": " And this.index identifies the checkpoint.",
        "tokens": [
          50864,
          400,
          341,
          2411,
          471,
          3121,
          34597,
          264,
          42269,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24407266889299664,
        "compression_ratio": 1.5348837209302326,
        "end": 3115,
        "id": 565,
        "no_speech_prob": 0.0000991516062640585,
        "seek": 309400,
        "start": 3109,
        "temperature": 0,
        "text": " And this checkpoint file actually only tells us the model path.",
        "tokens": [
          51114,
          400,
          341,
          42269,
          3991,
          767,
          787,
          5112,
          505,
          264,
          2316,
          3100,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24407266889299664,
        "compression_ratio": 1.5348837209302326,
        "end": 3123,
        "id": 566,
        "no_speech_prob": 0.0000991516062640585,
        "seek": 309400,
        "start": 3115,
        "temperature": 0,
        "text": " But for next step, we're going to copy those folders back to our local computer.",
        "tokens": [
          51414,
          583,
          337,
          958,
          1823,
          11,
          321,
          434,
          516,
          281,
          5055,
          729,
          31082,
          646,
          281,
          527,
          2654,
          3820,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.3315452814102173,
        "compression_ratio": 1.2087912087912087,
        "end": 3126,
        "id": 567,
        "no_speech_prob": 0.000027535374101717025,
        "seek": 312300,
        "start": 3124,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50414,
          407,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.3315452814102173,
        "compression_ratio": 1.2087912087912087,
        "end": 3137,
        "id": 568,
        "no_speech_prob": 0.000027535374101717025,
        "seek": 312300,
        "start": 3130,
        "temperature": 0,
        "text": " We can use spell ls to list all those output for us for one run.",
        "tokens": [
          50714,
          492,
          393,
          764,
          9827,
          287,
          82,
          281,
          1329,
          439,
          729,
          5598,
          337,
          505,
          337,
          472,
          1190,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3315452814102173,
        "compression_ratio": 1.2087912087912087,
        "end": 3141,
        "id": 569,
        "no_speech_prob": 0.000027535374101717025,
        "seek": 312300,
        "start": 3137,
        "temperature": 0,
        "text": " So I'm going to do this, spell ls runs.",
        "tokens": [
          51064,
          407,
          286,
          478,
          516,
          281,
          360,
          341,
          11,
          9827,
          287,
          82,
          6676,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.40870237939151716,
        "compression_ratio": 1.5668789808917198,
        "end": 3146,
        "id": 570,
        "no_speech_prob": 0.00006814679363742471,
        "seek": 314100,
        "start": 3142,
        "temperature": 0,
        "text": " And the run number is 14.",
        "tokens": [
          50414,
          400,
          264,
          1190,
          1230,
          307,
          3499,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.40870237939151716,
        "compression_ratio": 1.5668789808917198,
        "end": 3150,
        "id": 571,
        "no_speech_prob": 0.00006814679363742471,
        "seek": 314100,
        "start": 3146,
        "temperature": 0,
        "text": " The completed training run.",
        "tokens": [
          50614,
          440,
          7365,
          3097,
          1190,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.40870237939151716,
        "compression_ratio": 1.5668789808917198,
        "end": 3157,
        "id": 572,
        "no_speech_prob": 0.00006814679363742471,
        "seek": 314100,
        "start": 3150,
        "temperature": 0,
        "text": " So if we do this, spell will tell us, oh, the output is a folder called ckpt.",
        "tokens": [
          50814,
          407,
          498,
          321,
          360,
          341,
          11,
          9827,
          486,
          980,
          505,
          11,
          1954,
          11,
          264,
          5598,
          307,
          257,
          10820,
          1219,
          269,
          74,
          662,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.40870237939151716,
        "compression_ratio": 1.5668789808917198,
        "end": 3161,
        "id": 573,
        "no_speech_prob": 0.00006814679363742471,
        "seek": 314100,
        "start": 3157,
        "temperature": 0,
        "text": " So I also want to see what is inside of ckpt.",
        "tokens": [
          51164,
          407,
          286,
          611,
          528,
          281,
          536,
          437,
          307,
          1854,
          295,
          269,
          74,
          662,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.40870237939151716,
        "compression_ratio": 1.5668789808917198,
        "end": 3164,
        "id": 574,
        "no_speech_prob": 0.00006814679363742471,
        "seek": 314100,
        "start": 3161,
        "temperature": 0,
        "text": " So I'm going to open this folder.",
        "tokens": [
          51364,
          407,
          286,
          478,
          516,
          281,
          1269,
          341,
          10820,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.40870237939151716,
        "compression_ratio": 1.5668789808917198,
        "end": 3167,
        "id": 575,
        "no_speech_prob": 0.00006814679363742471,
        "seek": 314100,
        "start": 3164,
        "temperature": 0,
        "text": " And I'm going to open this folder.",
        "tokens": [
          51514,
          400,
          286,
          478,
          516,
          281,
          1269,
          341,
          10820,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18453074664604374,
        "compression_ratio": 1.5868263473053892,
        "end": 3171,
        "id": 576,
        "no_speech_prob": 0.00010554616892477497,
        "seek": 316700,
        "start": 3167,
        "temperature": 0,
        "text": " So I also want to see what is inside of ckpt.",
        "tokens": [
          50364,
          407,
          286,
          611,
          528,
          281,
          536,
          437,
          307,
          1854,
          295,
          269,
          74,
          662,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18453074664604374,
        "compression_ratio": 1.5868263473053892,
        "end": 3176,
        "id": 577,
        "no_speech_prob": 0.00010554616892477497,
        "seek": 316700,
        "start": 3171,
        "temperature": 0,
        "text": " So I can do spell ls runs slash 14 ckpt.",
        "tokens": [
          50564,
          407,
          286,
          393,
          360,
          9827,
          287,
          82,
          6676,
          17330,
          3499,
          269,
          74,
          662,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18453074664604374,
        "compression_ratio": 1.5868263473053892,
        "end": 3184,
        "id": 578,
        "no_speech_prob": 0.00010554616892477497,
        "seek": 316700,
        "start": 3178,
        "temperature": 0,
        "text": " And then it lists all those four files that we saw on the spell website.",
        "tokens": [
          50914,
          400,
          550,
          309,
          14511,
          439,
          729,
          1451,
          7098,
          300,
          321,
          1866,
          322,
          264,
          9827,
          3144,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18453074664604374,
        "compression_ratio": 1.5868263473053892,
        "end": 3190,
        "id": 579,
        "no_speech_prob": 0.00010554616892477497,
        "seek": 316700,
        "start": 3184,
        "temperature": 0,
        "text": " And what we're going to do is we want to copy all those files back.",
        "tokens": [
          51214,
          400,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          321,
          528,
          281,
          5055,
          439,
          729,
          7098,
          646,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18453074664604374,
        "compression_ratio": 1.5868263473053892,
        "end": 3195,
        "id": 580,
        "no_speech_prob": 0.00010554616892477497,
        "seek": 316700,
        "start": 3190,
        "temperature": 0,
        "text": " So I am going to create a new folder.",
        "tokens": [
          51514,
          407,
          286,
          669,
          516,
          281,
          1884,
          257,
          777,
          10820,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2457757463642195,
        "compression_ratio": 1.3716814159292035,
        "end": 3199,
        "id": 581,
        "no_speech_prob": 0.000011125374840048607,
        "seek": 319700,
        "start": 3197,
        "temperature": 0,
        "text": " Called...",
        "tokens": [
          50364,
          45001,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2457757463642195,
        "compression_ratio": 1.3716814159292035,
        "end": 3202,
        "id": 582,
        "no_speech_prob": 0.000011125374840048607,
        "seek": 319700,
        "start": 3200,
        "temperature": 0,
        "text": " Spell model.",
        "tokens": [
          50514,
          3550,
          285,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2457757463642195,
        "compression_ratio": 1.3716814159292035,
        "end": 3208,
        "id": 583,
        "no_speech_prob": 0.000011125374840048607,
        "seek": 319700,
        "start": 3203,
        "temperature": 0,
        "text": " And then I'm going to go inside to that model.",
        "tokens": [
          50664,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          1854,
          281,
          300,
          2316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2457757463642195,
        "compression_ratio": 1.3716814159292035,
        "end": 3214,
        "id": 584,
        "no_speech_prob": 0.000011125374840048607,
        "seek": 319700,
        "start": 3209,
        "temperature": 0,
        "text": " And then here I'm going to copy all those four files.",
        "tokens": [
          50964,
          400,
          550,
          510,
          286,
          478,
          516,
          281,
          5055,
          439,
          729,
          1451,
          7098,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2457757463642195,
        "compression_ratio": 1.3716814159292035,
        "end": 3221,
        "id": 585,
        "no_speech_prob": 0.000011125374840048607,
        "seek": 319700,
        "start": 3218,
        "temperature": 0,
        "text": " And the run number again is 14.",
        "tokens": [
          51414,
          400,
          264,
          1190,
          1230,
          797,
          307,
          3499,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4583192931281196,
        "compression_ratio": 1.0555555555555556,
        "end": 3226,
        "id": 586,
        "no_speech_prob": 0.0002868195588234812,
        "seek": 322100,
        "start": 3222,
        "temperature": 0,
        "text": " So I hit enter.",
        "tokens": [
          50414,
          407,
          286,
          2045,
          3242,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4583192931281196,
        "compression_ratio": 1.0555555555555556,
        "end": 3231,
        "id": 587,
        "no_speech_prob": 0.0002868195588234812,
        "seek": 322100,
        "start": 3226,
        "temperature": 0,
        "text": " And it will say copy this file.",
        "tokens": [
          50614,
          400,
          309,
          486,
          584,
          5055,
          341,
          3991,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.4583192931281196,
        "compression_ratio": 1.0555555555555556,
        "end": 3243,
        "id": 588,
        "no_speech_prob": 0.0002868195588234812,
        "seek": 322100,
        "start": 3241,
        "temperature": 0,
        "text": " Good time.",
        "tokens": [
          51364,
          2205,
          565,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.4583192931281196,
        "compression_ratio": 1.0555555555555556,
        "end": 3245,
        "id": 589,
        "no_speech_prob": 0.0002868195588234812,
        "seek": 322100,
        "start": 3243,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51464,
          865,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4583192931281196,
        "compression_ratio": 1.0555555555555556,
        "end": 3248,
        "id": 590,
        "no_speech_prob": 0.0002868195588234812,
        "seek": 322100,
        "start": 3245,
        "temperature": 0,
        "text": " Short intermission, everybody.",
        "tokens": [
          51564,
          16881,
          728,
          29797,
          11,
          2201,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3250,
        "id": 591,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3248,
        "temperature": 0,
        "text": " Short intermission, everybody.",
        "tokens": [
          50364,
          16881,
          728,
          29797,
          11,
          2201,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3254,
        "id": 592,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3250,
        "temperature": 0,
        "text": " Now we know that two half an hour has passed.",
        "tokens": [
          50464,
          823,
          321,
          458,
          300,
          732,
          1922,
          364,
          1773,
          575,
          4678,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3256,
        "id": 593,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3254,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50664,
          2425,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3258,
        "id": 594,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3256,
        "temperature": 0,
        "text": " We're good. We're good.",
        "tokens": [
          50764,
          492,
          434,
          665,
          13,
          492,
          434,
          665,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3260,
        "id": 595,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3258,
        "temperature": 0,
        "text": " Oh, I was like...",
        "tokens": [
          50864,
          876,
          11,
          286,
          390,
          411,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3262,
        "id": 596,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3260,
        "temperature": 0,
        "text": " It's been one hour, yes.",
        "tokens": [
          50964,
          467,
          311,
          668,
          472,
          1773,
          11,
          2086,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3267,
        "id": 597,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3262,
        "temperature": 0,
        "text": " It's actually been less than an hour because the camera started a little while before we started.",
        "tokens": [
          51064,
          467,
          311,
          767,
          668,
          1570,
          813,
          364,
          1773,
          570,
          264,
          2799,
          1409,
          257,
          707,
          1339,
          949,
          321,
          1409,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3271,
        "id": 598,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3267,
        "temperature": 0,
        "text": " And if people were wondering if this really is live, yes, it's really live.",
        "tokens": [
          51314,
          400,
          498,
          561,
          645,
          6359,
          498,
          341,
          534,
          307,
          1621,
          11,
          2086,
          11,
          309,
          311,
          534,
          1621,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2877025604248047,
        "compression_ratio": 1.5921052631578947,
        "end": 3274,
        "id": 599,
        "no_speech_prob": 0.002714804606512189,
        "seek": 324800,
        "start": 3271,
        "temperature": 0,
        "text": " People in chat are like, is this live?",
        "tokens": [
          51514,
          3432,
          294,
          5081,
          366,
          411,
          11,
          307,
          341,
          1621,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.29900135211090545,
        "compression_ratio": 1.3832335329341316,
        "end": 3276,
        "id": 600,
        "no_speech_prob": 0.00012533474364317954,
        "seek": 327400,
        "start": 3275,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.29900135211090545,
        "compression_ratio": 1.3832335329341316,
        "end": 3279,
        "id": 601,
        "no_speech_prob": 0.00012533474364317954,
        "seek": 327400,
        "start": 3276,
        "temperature": 0,
        "text": " So this is finished.",
        "tokens": [
          50464,
          407,
          341,
          307,
          4335,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.29900135211090545,
        "compression_ratio": 1.3832335329341316,
        "end": 3286,
        "id": 602,
        "no_speech_prob": 0.00012533474364317954,
        "seek": 327400,
        "start": 3279,
        "temperature": 0,
        "text": " We successfully copied all those four files, which is the model, which is a TensorFlow save model,",
        "tokens": [
          50614,
          492,
          10727,
          25365,
          439,
          729,
          1451,
          7098,
          11,
          597,
          307,
          264,
          2316,
          11,
          597,
          307,
          257,
          37624,
          3155,
          2316,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.29900135211090545,
        "compression_ratio": 1.3832335329341316,
        "end": 3289,
        "id": 603,
        "no_speech_prob": 0.00012533474364317954,
        "seek": 327400,
        "start": 3286,
        "temperature": 0,
        "text": " back to our local computer.",
        "tokens": [
          50964,
          646,
          281,
          527,
          2654,
          3820,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.29900135211090545,
        "compression_ratio": 1.3832335329341316,
        "end": 3291,
        "id": 604,
        "no_speech_prob": 0.00012533474364317954,
        "seek": 327400,
        "start": 3289,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          51114,
          407,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.29900135211090545,
        "compression_ratio": 1.3832335329341316,
        "end": 3298,
        "id": 605,
        "no_speech_prob": 0.00012533474364317954,
        "seek": 327400,
        "start": 3291,
        "temperature": 0,
        "text": " Oh, I created a wrong folder inside of this GitHub repo, but it's fine.",
        "tokens": [
          51214,
          876,
          11,
          286,
          2942,
          257,
          2085,
          10820,
          1854,
          295,
          341,
          23331,
          49040,
          11,
          457,
          309,
          311,
          2489,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.28952674304737763,
        "compression_ratio": 1.535031847133758,
        "end": 3301,
        "id": 606,
        "no_speech_prob": 0.00022340886062011123,
        "seek": 329800,
        "start": 3298,
        "temperature": 0,
        "text": " So now if we...",
        "tokens": [
          50364,
          407,
          586,
          498,
          321,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.28952674304737763,
        "compression_ratio": 1.535031847133758,
        "end": 3310,
        "id": 607,
        "no_speech_prob": 0.00022340886062011123,
        "seek": 329800,
        "start": 3301,
        "temperature": 0,
        "text": " If we list out all those files, we can see all those four files are on our local machine.",
        "tokens": [
          50514,
          759,
          321,
          1329,
          484,
          439,
          729,
          7098,
          11,
          321,
          393,
          536,
          439,
          729,
          1451,
          7098,
          366,
          322,
          527,
          2654,
          3479,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.28952674304737763,
        "compression_ratio": 1.535031847133758,
        "end": 3318,
        "id": 608,
        "no_speech_prob": 0.00022340886062011123,
        "seek": 329800,
        "start": 3310,
        "temperature": 0,
        "text": " So this is how we can get the trained model back from Spell's remote machine.",
        "tokens": [
          50964,
          407,
          341,
          307,
          577,
          321,
          393,
          483,
          264,
          8895,
          2316,
          646,
          490,
          1738,
          898,
          311,
          8607,
          3479,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28952674304737763,
        "compression_ratio": 1.535031847133758,
        "end": 3325,
        "id": 609,
        "no_speech_prob": 0.00022340886062011123,
        "seek": 329800,
        "start": 3318,
        "temperature": 0,
        "text": " Actually, we can open that to see what do they look like.",
        "tokens": [
          51364,
          5135,
          11,
          321,
          393,
          1269,
          300,
          281,
          536,
          437,
          360,
          436,
          574,
          411,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2705722871373911,
        "compression_ratio": 1.4236111111111112,
        "end": 3331,
        "id": 610,
        "no_speech_prob": 0.0002868517767637968,
        "seek": 332500,
        "start": 3326,
        "temperature": 0,
        "text": " I'm going to that directory.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          300,
          21120,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2705722871373911,
        "compression_ratio": 1.4236111111111112,
        "end": 3335,
        "id": 611,
        "no_speech_prob": 0.0002868517767637968,
        "seek": 332500,
        "start": 3331,
        "temperature": 0,
        "text": " I just created this new folder called spell model.",
        "tokens": [
          50664,
          286,
          445,
          2942,
          341,
          777,
          10820,
          1219,
          9827,
          2316,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2705722871373911,
        "compression_ratio": 1.4236111111111112,
        "end": 3342,
        "id": 612,
        "no_speech_prob": 0.0002868517767637968,
        "seek": 332500,
        "start": 3335,
        "temperature": 0,
        "text": " I'm just going to drag this model out to the desktop.",
        "tokens": [
          50864,
          286,
          478,
          445,
          516,
          281,
          5286,
          341,
          2316,
          484,
          281,
          264,
          14502,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2705722871373911,
        "compression_ratio": 1.4236111111111112,
        "end": 3348,
        "id": 613,
        "no_speech_prob": 0.0002868517767637968,
        "seek": 332500,
        "start": 3342,
        "temperature": 0,
        "text": " And as we can see, we have four files.",
        "tokens": [
          51214,
          400,
          382,
          321,
          393,
          536,
          11,
          321,
          362,
          1451,
          7098,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2705722871373911,
        "compression_ratio": 1.4236111111111112,
        "end": 3351,
        "id": 614,
        "no_speech_prob": 0.0002868517767637968,
        "seek": 332500,
        "start": 3348,
        "temperature": 0,
        "text": " This is the format of the model.",
        "tokens": [
          51514,
          639,
          307,
          264,
          7877,
          295,
          264,
          2316,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24580801749716,
        "compression_ratio": 1.3515625,
        "end": 3356,
        "id": 615,
        "no_speech_prob": 0.00045120916911400855,
        "seek": 335100,
        "start": 3352,
        "temperature": 0,
        "text": " This is the format of the TensorFlow save model.",
        "tokens": [
          50414,
          639,
          307,
          264,
          7877,
          295,
          264,
          37624,
          3155,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24580801749716,
        "compression_ratio": 1.3515625,
        "end": 3367,
        "id": 616,
        "no_speech_prob": 0.00045120916911400855,
        "seek": 335100,
        "start": 3356,
        "temperature": 0,
        "text": " And if we open this checkpoint file, there's only two lines in this file.",
        "tokens": [
          50614,
          400,
          498,
          321,
          1269,
          341,
          42269,
          3991,
          11,
          456,
          311,
          787,
          732,
          3876,
          294,
          341,
          3991,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24580801749716,
        "compression_ratio": 1.3515625,
        "end": 3373,
        "id": 617,
        "no_speech_prob": 0.00045120916911400855,
        "seek": 335100,
        "start": 3367,
        "temperature": 0,
        "text": " It tells us the model checkpoint path is fns.ckpt.",
        "tokens": [
          51164,
          467,
          5112,
          505,
          264,
          2316,
          42269,
          3100,
          307,
          283,
          3695,
          13,
          547,
          662,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3029990051731919,
        "compression_ratio": 1.463276836158192,
        "end": 3381,
        "id": 618,
        "no_speech_prob": 0.004007157403975725,
        "seek": 337300,
        "start": 3373,
        "temperature": 0,
        "text": " This is important information because we're going to use this path for our next step.",
        "tokens": [
          50364,
          639,
          307,
          1021,
          1589,
          570,
          321,
          434,
          516,
          281,
          764,
          341,
          3100,
          337,
          527,
          958,
          1823,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3029990051731919,
        "compression_ratio": 1.463276836158192,
        "end": 3385,
        "id": 619,
        "no_speech_prob": 0.004007157403975725,
        "seek": 337300,
        "start": 3381,
        "temperature": 0,
        "text": " So just remember the model checkpoint path is this.",
        "tokens": [
          50764,
          407,
          445,
          1604,
          264,
          2316,
          42269,
          3100,
          307,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3029990051731919,
        "compression_ratio": 1.463276836158192,
        "end": 3388,
        "id": 620,
        "no_speech_prob": 0.004007157403975725,
        "seek": 337300,
        "start": 3385,
        "temperature": 0,
        "text": " Okay, so...",
        "tokens": [
          50964,
          1033,
          11,
          370,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.3029990051731919,
        "compression_ratio": 1.463276836158192,
        "end": 3396,
        "id": 621,
        "no_speech_prob": 0.004007157403975725,
        "seek": 337300,
        "start": 3391,
        "temperature": 0,
        "text": " So far we set up the environment, we download the dataset,",
        "tokens": [
          51264,
          407,
          1400,
          321,
          992,
          493,
          264,
          2823,
          11,
          321,
          5484,
          264,
          28872,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.3029990051731919,
        "compression_ratio": 1.463276836158192,
        "end": 3402,
        "id": 622,
        "no_speech_prob": 0.004007157403975725,
        "seek": 337300,
        "start": 3396,
        "temperature": 0,
        "text": " we trained the model with the style Python script,",
        "tokens": [
          51514,
          321,
          8895,
          264,
          2316,
          365,
          264,
          3758,
          15329,
          5755,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20395119984944662,
        "compression_ratio": 1.4939024390243902,
        "end": 3407,
        "id": 623,
        "no_speech_prob": 0.00002355231117689982,
        "seek": 340200,
        "start": 3402,
        "temperature": 0,
        "text": " we copied our trained model back to our local computer,",
        "tokens": [
          50364,
          321,
          25365,
          527,
          8895,
          2316,
          646,
          281,
          527,
          2654,
          3820,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20395119984944662,
        "compression_ratio": 1.4939024390243902,
        "end": 3416,
        "id": 624,
        "no_speech_prob": 0.00002355231117689982,
        "seek": 340200,
        "start": 3407,
        "temperature": 0,
        "text": " and the last step is to convert the model to a format that we can use in TensorFlow.js and ML5.js.",
        "tokens": [
          50614,
          293,
          264,
          1036,
          1823,
          307,
          281,
          7620,
          264,
          2316,
          281,
          257,
          7877,
          300,
          321,
          393,
          764,
          294,
          37624,
          13,
          25530,
          293,
          21601,
          20,
          13,
          25530,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20395119984944662,
        "compression_ratio": 1.4939024390243902,
        "end": 3419,
        "id": 625,
        "no_speech_prob": 0.00002355231117689982,
        "seek": 340200,
        "start": 3416,
        "temperature": 0,
        "text": " Okay, let's do this.",
        "tokens": [
          51064,
          1033,
          11,
          718,
          311,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20395119984944662,
        "compression_ratio": 1.4939024390243902,
        "end": 3428,
        "id": 626,
        "no_speech_prob": 0.00002355231117689982,
        "seek": 340200,
        "start": 3419,
        "temperature": 0,
        "text": " Oh, by the way, this is the trained model that we got on the desktop.",
        "tokens": [
          51214,
          876,
          11,
          538,
          264,
          636,
          11,
          341,
          307,
          264,
          8895,
          2316,
          300,
          321,
          658,
          322,
          264,
          14502,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3808083167442909,
        "compression_ratio": 0.9733333333333334,
        "end": 3432,
        "id": 627,
        "no_speech_prob": 0.00012533106200862676,
        "seek": 342800,
        "start": 3429,
        "temperature": 0,
        "text": " Okay, so...",
        "tokens": [
          50414,
          1033,
          11,
          370,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.3808083167442909,
        "compression_ratio": 0.9733333333333334,
        "end": 3445,
        "id": 628,
        "no_speech_prob": 0.00012533106200862676,
        "seek": 342800,
        "start": 3434,
        "temperature": 0,
        "text": " If I go back to my old directory, which is live stream, here,",
        "tokens": [
          50664,
          759,
          286,
          352,
          646,
          281,
          452,
          1331,
          21120,
          11,
          597,
          307,
          1621,
          4309,
          11,
          510,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.30256419711642796,
        "compression_ratio": 1.2429906542056075,
        "end": 3450,
        "id": 629,
        "no_speech_prob": 0.0003406227915547788,
        "seek": 344500,
        "start": 3446,
        "temperature": 0,
        "text": " we're going to use...",
        "tokens": [
          50414,
          321,
          434,
          516,
          281,
          764,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.30256419711642796,
        "compression_ratio": 1.2429906542056075,
        "end": 3462,
        "id": 630,
        "no_speech_prob": 0.0003406227915547788,
        "seek": 344500,
        "start": 3454,
        "temperature": 0,
        "text": " use the script that is from FaststyleTransfer, deeplearn.js.",
        "tokens": [
          50814,
          764,
          264,
          5755,
          300,
          307,
          490,
          15968,
          15014,
          33339,
          612,
          11,
          2452,
          306,
          1083,
          13,
          25530,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.30256419711642796,
        "compression_ratio": 1.2429906542056075,
        "end": 3467,
        "id": 631,
        "no_speech_prob": 0.0003406227915547788,
        "seek": 344500,
        "start": 3462,
        "temperature": 0,
        "text": " Deeplearn.js is the formal name for TensorFlow.js.",
        "tokens": [
          51214,
          14895,
          306,
          1083,
          13,
          25530,
          307,
          264,
          9860,
          1315,
          337,
          37624,
          13,
          25530,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23445343521406065,
        "compression_ratio": 1.2446043165467626,
        "end": 3477,
        "id": 632,
        "no_speech_prob": 0.00026529780006967485,
        "seek": 346700,
        "start": 3467,
        "temperature": 0,
        "text": " This repo is built by Richiro Nakano.",
        "tokens": [
          50364,
          639,
          49040,
          307,
          3094,
          538,
          497,
          480,
          5182,
          25779,
          3730,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23445343521406065,
        "compression_ratio": 1.2446043165467626,
        "end": 3480,
        "id": 633,
        "no_speech_prob": 0.00026529780006967485,
        "seek": 346700,
        "start": 3477,
        "temperature": 0,
        "text": " His work is amazing.",
        "tokens": [
          50864,
          2812,
          589,
          307,
          2243,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23445343521406065,
        "compression_ratio": 1.2446043165467626,
        "end": 3486,
        "id": 634,
        "no_speech_prob": 0.00026529780006967485,
        "seek": 346700,
        "start": 3480,
        "temperature": 0,
        "text": " He recently contributed a new model called SketchRN to ML5.js, too.",
        "tokens": [
          51014,
          634,
          3938,
          18434,
          257,
          777,
          2316,
          1219,
          49245,
          49,
          45,
          281,
          21601,
          20,
          13,
          25530,
          11,
          886,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23445343521406065,
        "compression_ratio": 1.2446043165467626,
        "end": 3490,
        "id": 635,
        "no_speech_prob": 0.00026529780006967485,
        "seek": 346700,
        "start": 3486,
        "temperature": 0,
        "text": " You guys should definitely check out his work.",
        "tokens": [
          51314,
          509,
          1074,
          820,
          2138,
          1520,
          484,
          702,
          589,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2221653802054269,
        "compression_ratio": 1.3359375,
        "end": 3499,
        "id": 636,
        "no_speech_prob": 0.0003799768746830523,
        "seek": 349000,
        "start": 3490,
        "temperature": 0,
        "text": " But we're going to use his script to convert the TensorFlow model into a model that we can use in ML5.js.",
        "tokens": [
          50364,
          583,
          321,
          434,
          516,
          281,
          764,
          702,
          5755,
          281,
          7620,
          264,
          37624,
          2316,
          666,
          257,
          2316,
          300,
          321,
          393,
          764,
          294,
          21601,
          20,
          13,
          25530,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2221653802054269,
        "compression_ratio": 1.3359375,
        "end": 3511,
        "id": 637,
        "no_speech_prob": 0.0003799768746830523,
        "seek": 349000,
        "start": 3500,
        "temperature": 0,
        "text": " So the way that we're going to do it is to clone his GitHub repo.",
        "tokens": [
          50864,
          407,
          264,
          636,
          300,
          321,
          434,
          516,
          281,
          360,
          309,
          307,
          281,
          26506,
          702,
          23331,
          49040,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.29901242867494243,
        "compression_ratio": 1.0898876404494382,
        "end": 3512,
        "id": 638,
        "no_speech_prob": 0.00013341712474357337,
        "seek": 351100,
        "start": 3511,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.29901242867494243,
        "compression_ratio": 1.0898876404494382,
        "end": 3517,
        "id": 639,
        "no_speech_prob": 0.00013341712474357337,
        "seek": 351100,
        "start": 3516,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50614,
          876,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.29901242867494243,
        "compression_ratio": 1.0898876404494382,
        "end": 3521,
        "id": 640,
        "no_speech_prob": 0.00013341712474357337,
        "seek": 351100,
        "start": 3518,
        "temperature": 0,
        "text": " I think there is a dot at the end.",
        "tokens": [
          50714,
          286,
          519,
          456,
          307,
          257,
          5893,
          412,
          264,
          917,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.29901242867494243,
        "compression_ratio": 1.0898876404494382,
        "end": 3522,
        "id": 641,
        "no_speech_prob": 0.00013341712474357337,
        "seek": 351100,
        "start": 3521,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.29901242867494243,
        "compression_ratio": 1.0898876404494382,
        "end": 3532,
        "id": 642,
        "no_speech_prob": 0.00013341712474357337,
        "seek": 351100,
        "start": 3528,
        "temperature": 0,
        "text": " And then we're going inside to this GitHub repo.",
        "tokens": [
          51214,
          400,
          550,
          321,
          434,
          516,
          1854,
          281,
          341,
          23331,
          49040,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.212368300982884,
        "compression_ratio": 1.3443708609271523,
        "end": 3548,
        "id": 643,
        "no_speech_prob": 0.000040694238123251125,
        "seek": 353200,
        "start": 3533,
        "temperature": 0,
        "text": " And we're going to put all those checkpoint files that we got into one of the folders inside of this GitHub repo, which is...",
        "tokens": [
          50414,
          400,
          321,
          434,
          516,
          281,
          829,
          439,
          729,
          42269,
          7098,
          300,
          321,
          658,
          666,
          472,
          295,
          264,
          31082,
          1854,
          295,
          341,
          23331,
          49040,
          11,
          597,
          307,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.212368300982884,
        "compression_ratio": 1.3443708609271523,
        "end": 3558,
        "id": 644,
        "no_speech_prob": 0.000040694238123251125,
        "seek": 353200,
        "start": 3548,
        "temperature": 0,
        "text": " So I'm just going to go to FaststyleTransfer, deeplearn.js, and go to source.",
        "tokens": [
          51164,
          407,
          286,
          478,
          445,
          516,
          281,
          352,
          281,
          15968,
          15014,
          33339,
          612,
          11,
          2452,
          306,
          1083,
          13,
          25530,
          11,
          293,
          352,
          281,
          4009,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3565,
        "id": 645,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3563,
        "temperature": 0,
        "text": " Wait, is this source?",
        "tokens": [
          50414,
          3802,
          11,
          307,
          341,
          4009,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3567,
        "id": 646,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3565,
        "temperature": 0,
        "text": " Oh, no, not source.",
        "tokens": [
          50514,
          876,
          11,
          572,
          11,
          406,
          4009,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3569,
        "id": 647,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3567,
        "temperature": 0,
        "text": " Just the root directory.",
        "tokens": [
          50614,
          1449,
          264,
          5593,
          21120,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3579,
        "id": 648,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3569,
        "temperature": 0,
        "text": " So I'm just going to copy this folder to the root directory of this GitHub repo.",
        "tokens": [
          50714,
          407,
          286,
          478,
          445,
          516,
          281,
          5055,
          341,
          10820,
          281,
          264,
          5593,
          21120,
          295,
          341,
          23331,
          49040,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3580,
        "id": 649,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3579,
        "temperature": 0,
        "text": " And I just did.",
        "tokens": [
          51214,
          400,
          286,
          445,
          630,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3581,
        "id": 650,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3580,
        "temperature": 0,
        "text": " It's here.",
        "tokens": [
          51264,
          467,
          311,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3585,
        "id": 651,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3581,
        "temperature": 0,
        "text": " And then we're going to run two Python scripts.",
        "tokens": [
          51314,
          400,
          550,
          321,
          434,
          516,
          281,
          1190,
          732,
          15329,
          23294,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20074261440319963,
        "compression_ratio": 1.5502645502645502,
        "end": 3591,
        "id": 652,
        "no_speech_prob": 0.00013134873006492853,
        "seek": 356200,
        "start": 3585,
        "temperature": 0,
        "text": " The first thing is to dump the checkpoints just to convert the format.",
        "tokens": [
          51514,
          440,
          700,
          551,
          307,
          281,
          11430,
          264,
          1520,
          20552,
          445,
          281,
          7620,
          264,
          7877,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2612731036017923,
        "compression_ratio": 1.1136363636363635,
        "end": 3594,
        "id": 653,
        "no_speech_prob": 0.00039202935295179486,
        "seek": 359100,
        "start": 3591,
        "temperature": 0,
        "text": " So what we're going to do is...",
        "tokens": [
          50364,
          407,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2612731036017923,
        "compression_ratio": 1.1136363636363635,
        "end": 3598,
        "id": 654,
        "no_speech_prob": 0.00039202935295179486,
        "seek": 359100,
        "start": 3596,
        "temperature": 0,
        "text": " Copy-paste this command.",
        "tokens": [
          50614,
          25653,
          12,
          79,
          9079,
          341,
          5622,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2612731036017923,
        "compression_ratio": 1.1136363636363635,
        "end": 3610,
        "id": 655,
        "no_speech_prob": 0.00039202935295179486,
        "seek": 359100,
        "start": 3606,
        "temperature": 0,
        "text": " Let's edit this in the code editor first.",
        "tokens": [
          51114,
          961,
          311,
          8129,
          341,
          294,
          264,
          3089,
          9839,
          700,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.26859182469985066,
        "compression_ratio": 1.542857142857143,
        "end": 3614,
        "id": 656,
        "no_speech_prob": 0.04023260250687599,
        "seek": 361000,
        "start": 3611,
        "temperature": 0,
        "text": " Python script and run this script.",
        "tokens": [
          50414,
          15329,
          5755,
          293,
          1190,
          341,
          5755,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26859182469985066,
        "compression_ratio": 1.542857142857143,
        "end": 3625,
        "id": 657,
        "no_speech_prob": 0.04023260250687599,
        "seek": 361000,
        "start": 3614,
        "temperature": 0,
        "text": " And then the output directory is source slash checkpoints slash our folder name, which will be spell model.",
        "tokens": [
          50564,
          400,
          550,
          264,
          5598,
          21120,
          307,
          4009,
          17330,
          1520,
          20552,
          17330,
          527,
          10820,
          1315,
          11,
          597,
          486,
          312,
          9827,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26859182469985066,
        "compression_ratio": 1.542857142857143,
        "end": 3632,
        "id": 658,
        "no_speech_prob": 0.04023260250687599,
        "seek": 361000,
        "start": 3626,
        "temperature": 0,
        "text": " And then the checkpoint file is in the root directory of the GitHub repo.",
        "tokens": [
          51164,
          400,
          550,
          264,
          42269,
          3991,
          307,
          294,
          264,
          5593,
          21120,
          295,
          264,
          23331,
          49040,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2045199669013589,
        "compression_ratio": 1.5284552845528456,
        "end": 3643,
        "id": 659,
        "no_speech_prob": 0.0014325071824714541,
        "seek": 363200,
        "start": 3633,
        "temperature": 0,
        "text": " So it's.slash spell model slash fns.ckpt.",
        "tokens": [
          50414,
          407,
          309,
          311,
          2411,
          10418,
          1299,
          9827,
          2316,
          17330,
          283,
          3695,
          13,
          547,
          662,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2045199669013589,
        "compression_ratio": 1.5284552845528456,
        "end": 3652,
        "id": 660,
        "no_speech_prob": 0.0014325071824714541,
        "seek": 363200,
        "start": 3643,
        "temperature": 0,
        "text": " This is the path to our model, which we saw before in this checkpoint file.",
        "tokens": [
          50914,
          639,
          307,
          264,
          3100,
          281,
          527,
          2316,
          11,
          597,
          321,
          1866,
          949,
          294,
          341,
          42269,
          3991,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2045199669013589,
        "compression_ratio": 1.5284552845528456,
        "end": 3656,
        "id": 661,
        "no_speech_prob": 0.0014325071824714541,
        "seek": 363200,
        "start": 3652,
        "temperature": 0,
        "text": " This is the path to our checkpoint.",
        "tokens": [
          51364,
          639,
          307,
          264,
          3100,
          281,
          527,
          42269,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2045199669013589,
        "compression_ratio": 1.5284552845528456,
        "end": 3660,
        "id": 662,
        "no_speech_prob": 0.0014325071824714541,
        "seek": 363200,
        "start": 3656,
        "temperature": 0,
        "text": " That's why we have this name here.",
        "tokens": [
          51564,
          663,
          311,
          983,
          321,
          362,
          341,
          1315,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18907990279021086,
        "compression_ratio": 1.3357664233576643,
        "end": 3664,
        "id": 663,
        "no_speech_prob": 0.00006709200533805415,
        "seek": 366000,
        "start": 3661,
        "temperature": 0,
        "text": " So now I'm just going to run this script.",
        "tokens": [
          50414,
          407,
          586,
          286,
          478,
          445,
          516,
          281,
          1190,
          341,
          5755,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18907990279021086,
        "compression_ratio": 1.3357664233576643,
        "end": 3674,
        "id": 664,
        "no_speech_prob": 0.00006709200533805415,
        "seek": 366000,
        "start": 3672,
        "temperature": 0,
        "text": " And then you can see it's done.",
        "tokens": [
          50964,
          400,
          550,
          291,
          393,
          536,
          309,
          311,
          1096,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18907990279021086,
        "compression_ratio": 1.3357664233576643,
        "end": 3682,
        "id": 665,
        "no_speech_prob": 0.00006709200533805415,
        "seek": 366000,
        "start": 3674,
        "temperature": 0,
        "text": " So it actually created one checkpoint file and 49 other files.",
        "tokens": [
          51064,
          407,
          309,
          767,
          2942,
          472,
          42269,
          3991,
          293,
          16513,
          661,
          7098,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18907990279021086,
        "compression_ratio": 1.3357664233576643,
        "end": 3689,
        "id": 666,
        "no_speech_prob": 0.00006709200533805415,
        "seek": 366000,
        "start": 3682,
        "temperature": 0,
        "text": " And we can go there to see what is the output.",
        "tokens": [
          51464,
          400,
          321,
          393,
          352,
          456,
          281,
          536,
          437,
          307,
          264,
          5598,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2307578227559074,
        "compression_ratio": 1.4370860927152318,
        "end": 3694,
        "id": 667,
        "no_speech_prob": 0.000009080456038645934,
        "seek": 368900,
        "start": 3689,
        "temperature": 0,
        "text": " The output lives in source checkpoint.",
        "tokens": [
          50364,
          440,
          5598,
          2909,
          294,
          4009,
          42269,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2307578227559074,
        "compression_ratio": 1.4370860927152318,
        "end": 3696,
        "id": 668,
        "no_speech_prob": 0.000009080456038645934,
        "seek": 368900,
        "start": 3694,
        "temperature": 0,
        "text": " And this is our model.",
        "tokens": [
          50614,
          400,
          341,
          307,
          527,
          2316,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2307578227559074,
        "compression_ratio": 1.4370860927152318,
        "end": 3703,
        "id": 669,
        "no_speech_prob": 0.000009080456038645934,
        "seek": 368900,
        "start": 3698,
        "temperature": 0,
        "text": " And you can see that we got the manifest.json.",
        "tokens": [
          50814,
          400,
          291,
          393,
          536,
          300,
          321,
          658,
          264,
          10067,
          13,
          73,
          3015,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2307578227559074,
        "compression_ratio": 1.4370860927152318,
        "end": 3707,
        "id": 670,
        "no_speech_prob": 0.000009080456038645934,
        "seek": 368900,
        "start": 3703,
        "temperature": 0,
        "text": " This tells us the structure of the graph.",
        "tokens": [
          51064,
          639,
          5112,
          505,
          264,
          3877,
          295,
          264,
          4295,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2307578227559074,
        "compression_ratio": 1.4370860927152318,
        "end": 3718,
        "id": 671,
        "no_speech_prob": 0.000009080456038645934,
        "seek": 368900,
        "start": 3710,
        "temperature": 0,
        "text": " And also 49 files that tells us all those variables in each layer.",
        "tokens": [
          51414,
          400,
          611,
          16513,
          7098,
          300,
          5112,
          505,
          439,
          729,
          9102,
          294,
          1184,
          4583,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19767835063319053,
        "compression_ratio": 1.3591549295774648,
        "end": 3725,
        "id": 672,
        "no_speech_prob": 0.00004908622213406488,
        "seek": 371800,
        "start": 3719,
        "temperature": 0,
        "text": " And this is the format that we can use in ml5.js and TensorFlow.js.",
        "tokens": [
          50414,
          400,
          341,
          307,
          264,
          7877,
          300,
          321,
          393,
          764,
          294,
          23271,
          20,
          13,
          25530,
          293,
          37624,
          13,
          25530,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19767835063319053,
        "compression_ratio": 1.3591549295774648,
        "end": 3734,
        "id": 673,
        "no_speech_prob": 0.00004908622213406488,
        "seek": 371800,
        "start": 3726,
        "temperature": 0,
        "text": " So now I'm just going to copy this model back to my desktop.",
        "tokens": [
          50764,
          407,
          586,
          286,
          478,
          445,
          516,
          281,
          5055,
          341,
          2316,
          646,
          281,
          452,
          14502,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19767835063319053,
        "compression_ratio": 1.3591549295774648,
        "end": 3739,
        "id": 674,
        "no_speech_prob": 0.00004908622213406488,
        "seek": 371800,
        "start": 3735,
        "temperature": 0,
        "text": " I'm going to rename it and drag it to my desktop.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          36741,
          309,
          293,
          5286,
          309,
          281,
          452,
          14502,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19767835063319053,
        "compression_ratio": 1.3591549295774648,
        "end": 3744,
        "id": 675,
        "no_speech_prob": 0.00004908622213406488,
        "seek": 371800,
        "start": 3743,
        "temperature": 0,
        "text": " Oh, it's here.",
        "tokens": [
          51614,
          876,
          11,
          309,
          311,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19749927520751953,
        "compression_ratio": 1.536231884057971,
        "end": 3757,
        "id": 676,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 374800,
        "start": 3749,
        "temperature": 0,
        "text": " Okay, so far we got two models.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          1400,
          321,
          658,
          732,
          5245,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19749927520751953,
        "compression_ratio": 1.536231884057971,
        "end": 3764,
        "id": 677,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 374800,
        "start": 3757,
        "temperature": 0,
        "text": " We have a TensorFlow saved model that can work in TensorFlow, of course.",
        "tokens": [
          50814,
          492,
          362,
          257,
          37624,
          6624,
          2316,
          300,
          393,
          589,
          294,
          37624,
          11,
          295,
          1164,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19749927520751953,
        "compression_ratio": 1.536231884057971,
        "end": 3770,
        "id": 678,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 374800,
        "start": 3764,
        "temperature": 0,
        "text": " And then we also got another model that can work in ml5.js and TensorFlow.js.",
        "tokens": [
          51164,
          400,
          550,
          321,
          611,
          658,
          1071,
          2316,
          300,
          393,
          589,
          294,
          23271,
          20,
          13,
          25530,
          293,
          37624,
          13,
          25530,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19749927520751953,
        "compression_ratio": 1.536231884057971,
        "end": 3772,
        "id": 679,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 374800,
        "start": 3770,
        "temperature": 0,
        "text": " So this is what we got today.",
        "tokens": [
          51464,
          407,
          341,
          307,
          437,
          321,
          658,
          965,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26310006896061683,
        "compression_ratio": 1.4266666666666667,
        "end": 3778,
        "id": 680,
        "no_speech_prob": 0.00020342478819657117,
        "seek": 377200,
        "start": 3773,
        "temperature": 0,
        "text": " And the next step is to run this model in ml5.js.",
        "tokens": [
          50414,
          400,
          264,
          958,
          1823,
          307,
          281,
          1190,
          341,
          2316,
          294,
          23271,
          20,
          13,
          25530,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.26310006896061683,
        "compression_ratio": 1.4266666666666667,
        "end": 3783,
        "id": 681,
        "no_speech_prob": 0.00020342478819657117,
        "seek": 377200,
        "start": 3778,
        "temperature": 0,
        "text": " Here are two demos on ml5's website.",
        "tokens": [
          50664,
          1692,
          366,
          732,
          33788,
          322,
          23271,
          20,
          311,
          3144,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.26310006896061683,
        "compression_ratio": 1.4266666666666667,
        "end": 3788,
        "id": 682,
        "no_speech_prob": 0.00020342478819657117,
        "seek": 377200,
        "start": 3783,
        "temperature": 0,
        "text": " And we also have this demo here.",
        "tokens": [
          50914,
          400,
          321,
          611,
          362,
          341,
          10723,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26310006896061683,
        "compression_ratio": 1.4266666666666667,
        "end": 3792,
        "id": 683,
        "no_speech_prob": 0.00020342478819657117,
        "seek": 377200,
        "start": 3788,
        "temperature": 0,
        "text": " That you can select different styles.",
        "tokens": [
          51164,
          663,
          291,
          393,
          3048,
          819,
          13273,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26310006896061683,
        "compression_ratio": 1.4266666666666667,
        "end": 3795,
        "id": 684,
        "no_speech_prob": 0.00020342478819657117,
        "seek": 377200,
        "start": 3792,
        "temperature": 0,
        "text": " You can upload the image.",
        "tokens": [
          51364,
          509,
          393,
          6580,
          264,
          3256,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26310006896061683,
        "compression_ratio": 1.4266666666666667,
        "end": 3798,
        "id": 685,
        "no_speech_prob": 0.00020342478819657117,
        "seek": 377200,
        "start": 3795,
        "temperature": 0,
        "text": " You can change the style here.",
        "tokens": [
          51514,
          509,
          393,
          1319,
          264,
          3758,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.45244975090026857,
        "compression_ratio": 1.3875,
        "end": 3801,
        "id": 686,
        "no_speech_prob": 0.00003944079435314052,
        "seek": 379800,
        "start": 3799,
        "temperature": 0,
        "text": " And you can upload the image.",
        "tokens": [
          50414,
          400,
          291,
          393,
          6580,
          264,
          3256,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.45244975090026857,
        "compression_ratio": 1.3875,
        "end": 3805,
        "id": 687,
        "no_speech_prob": 0.00003944079435314052,
        "seek": 379800,
        "start": 3801,
        "temperature": 0,
        "text": " I'm going to upload a photo.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          6580,
          257,
          5052,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.45244975090026857,
        "compression_ratio": 1.3875,
        "end": 3820,
        "id": 688,
        "no_speech_prob": 0.00003944079435314052,
        "seek": 379800,
        "start": 3818,
        "temperature": 0,
        "text": " A photo of a cat.",
        "tokens": [
          51364,
          316,
          5052,
          295,
          257,
          3857,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.45244975090026857,
        "compression_ratio": 1.3875,
        "end": 3823,
        "id": 689,
        "no_speech_prob": 0.00003944079435314052,
        "seek": 379800,
        "start": 3820,
        "temperature": 0,
        "text": " And I'm going to upload the image.",
        "tokens": [
          51464,
          400,
          286,
          478,
          516,
          281,
          6580,
          264,
          3256,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3827,
        "id": 690,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3824,
        "temperature": 0,
        "text": " A photo of a cat.",
        "tokens": [
          50414,
          316,
          5052,
          295,
          257,
          3857,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3830,
        "id": 691,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3827,
        "temperature": 0,
        "text": " And then click this transfer my image.",
        "tokens": [
          50564,
          400,
          550,
          2052,
          341,
          5003,
          452,
          3256,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3833,
        "id": 692,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3830,
        "temperature": 0,
        "text": " This is the transferred cat.",
        "tokens": [
          50714,
          639,
          307,
          264,
          15809,
          3857,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3837,
        "id": 693,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3833,
        "temperature": 0,
        "text": " You can also play it with different styles too.",
        "tokens": [
          50864,
          509,
          393,
          611,
          862,
          309,
          365,
          819,
          13273,
          886,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3839,
        "id": 694,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3837,
        "temperature": 0,
        "text": " Oh, I do like this one.",
        "tokens": [
          51064,
          876,
          11,
          286,
          360,
          411,
          341,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3845,
        "id": 695,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3842,
        "temperature": 0,
        "text": " And also you can use webcam.",
        "tokens": [
          51314,
          400,
          611,
          291,
          393,
          764,
          39490,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2303512914856868,
        "compression_ratio": 1.4965034965034965,
        "end": 3850,
        "id": 696,
        "no_speech_prob": 0.0005702474154531956,
        "seek": 382300,
        "start": 3847,
        "temperature": 0,
        "text": " And then click this button.",
        "tokens": [
          51564,
          400,
          550,
          2052,
          341,
          2960,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1895953147642074,
        "compression_ratio": 1.2234042553191489,
        "end": 3862,
        "id": 697,
        "no_speech_prob": 0.000014738618119736202,
        "seek": 385000,
        "start": 3851,
        "temperature": 0,
        "text": " And you can see the transferred version of the images from the webcam.",
        "tokens": [
          50414,
          400,
          291,
          393,
          536,
          264,
          15809,
          3037,
          295,
          264,
          5267,
          490,
          264,
          39490,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1895953147642074,
        "compression_ratio": 1.2234042553191489,
        "end": 3873,
        "id": 698,
        "no_speech_prob": 0.000014738618119736202,
        "seek": 385000,
        "start": 3870,
        "temperature": 0,
        "text": " So you can go there and check this demo out.",
        "tokens": [
          51364,
          407,
          291,
          393,
          352,
          456,
          293,
          1520,
          341,
          10723,
          484,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25100742067609516,
        "compression_ratio": 1.037037037037037,
        "end": 3887,
        "id": 699,
        "no_speech_prob": 0.00015597755555063486,
        "seek": 387300,
        "start": 3873,
        "temperature": 0,
        "text": " But next we're just going to run this model in our ml5 demo.",
        "tokens": [
          50364,
          583,
          958,
          321,
          434,
          445,
          516,
          281,
          1190,
          341,
          2316,
          294,
          527,
          23271,
          20,
          10723,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.25100742067609516,
        "compression_ratio": 1.037037037037037,
        "end": 3896,
        "id": 700,
        "no_speech_prob": 0.00015597755555063486,
        "seek": 387300,
        "start": 3894,
        "temperature": 0,
        "text": " We can do this quickly.",
        "tokens": [
          51414,
          492,
          393,
          360,
          341,
          2661,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3677609648023333,
        "compression_ratio": 0.8888888888888888,
        "end": 3901,
        "id": 701,
        "no_speech_prob": 0.0009847588371485472,
        "seek": 389600,
        "start": 3896,
        "temperature": 0,
        "text": " Here we're just going to clone this GitHub repo.",
        "tokens": [
          50364,
          1692,
          321,
          434,
          445,
          516,
          281,
          26506,
          341,
          23331,
          49040,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3131861125721651,
        "compression_ratio": 1.2474226804123711,
        "end": 3931,
        "id": 702,
        "no_speech_prob": 0.0002959499543067068,
        "seek": 392600,
        "start": 3927,
        "temperature": 0,
        "text": " And then go inside to that folder.",
        "tokens": [
          50414,
          400,
          550,
          352,
          1854,
          281,
          300,
          10820,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3131861125721651,
        "compression_ratio": 1.2474226804123711,
        "end": 3934,
        "id": 703,
        "no_speech_prob": 0.0002959499543067068,
        "seek": 392600,
        "start": 3931,
        "temperature": 0,
        "text": " Style transfer underscore spell.",
        "tokens": [
          50614,
          27004,
          5003,
          37556,
          9827,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3131861125721651,
        "compression_ratio": 1.2474226804123711,
        "end": 3939,
        "id": 704,
        "no_speech_prob": 0.0002959499543067068,
        "seek": 392600,
        "start": 3934,
        "temperature": 0,
        "text": " And we're going to open this folder in a code editor.",
        "tokens": [
          50764,
          400,
          321,
          434,
          516,
          281,
          1269,
          341,
          10820,
          294,
          257,
          3089,
          9839,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.5507361275809152,
        "compression_ratio": 1.6666666666666667,
        "end": 3945,
        "id": 705,
        "no_speech_prob": 0.0004044629167765379,
        "seek": 393900,
        "start": 3940,
        "temperature": 0,
        "text": " And in this models folder, there's already one models there.",
        "tokens": [
          50414,
          400,
          294,
          341,
          5245,
          10820,
          11,
          456,
          311,
          1217,
          472,
          5245,
          456,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.5507361275809152,
        "compression_ratio": 1.6666666666666667,
        "end": 3950,
        "id": 706,
        "no_speech_prob": 0.0004044629167765379,
        "seek": 393900,
        "start": 3945,
        "temperature": 0,
        "text": " We're going to add our new models inside of this folder.",
        "tokens": [
          50664,
          492,
          434,
          516,
          281,
          909,
          527,
          777,
          5245,
          1854,
          295,
          341,
          10820,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.5507361275809152,
        "compression_ratio": 1.6666666666666667,
        "end": 3957,
        "id": 707,
        "no_speech_prob": 0.0004044629167765379,
        "seek": 393900,
        "start": 3950,
        "temperature": 0,
        "text": " So what I'm going to do is to find that GitHub repo.",
        "tokens": [
          50914,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          281,
          915,
          300,
          23331,
          49040,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.5507361275809152,
        "compression_ratio": 1.6666666666666667,
        "end": 3960,
        "id": 708,
        "no_speech_prob": 0.0004044629167765379,
        "seek": 393900,
        "start": 3957,
        "temperature": 0,
        "text": " And I'm going to add it here.",
        "tokens": [
          51264,
          400,
          286,
          478,
          516,
          281,
          909,
          309,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.5507361275809152,
        "compression_ratio": 1.6666666666666667,
        "end": 3963,
        "id": 709,
        "no_speech_prob": 0.0004044629167765379,
        "seek": 393900,
        "start": 3960,
        "temperature": 0,
        "text": " And I'm going to add it here.",
        "tokens": [
          51414,
          400,
          286,
          478,
          516,
          281,
          909,
          309,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21850979846456778,
        "compression_ratio": 1.3214285714285714,
        "end": 3970,
        "id": 710,
        "no_speech_prob": 0.00012533592234831303,
        "seek": 396300,
        "start": 3963,
        "temperature": 0,
        "text": " What I'm going to do is to find that GitHub repo.",
        "tokens": [
          50364,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          281,
          915,
          300,
          23331,
          49040,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21850979846456778,
        "compression_ratio": 1.3214285714285714,
        "end": 3983,
        "id": 711,
        "no_speech_prob": 0.00012533592234831303,
        "seek": 396300,
        "start": 3977,
        "temperature": 0,
        "text": " And inside of models, I'm going to copy paste this model in.",
        "tokens": [
          51064,
          400,
          1854,
          295,
          5245,
          11,
          286,
          478,
          516,
          281,
          5055,
          9163,
          341,
          2316,
          294,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21850979846456778,
        "compression_ratio": 1.3214285714285714,
        "end": 3988,
        "id": 712,
        "no_speech_prob": 0.00012533592234831303,
        "seek": 396300,
        "start": 3983,
        "temperature": 0,
        "text": " I'm just going to rename it to Lotus.",
        "tokens": [
          51364,
          286,
          478,
          445,
          516,
          281,
          36741,
          309,
          281,
          44769,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23722456462347685,
        "compression_ratio": 1.34640522875817,
        "end": 3993,
        "id": 713,
        "no_speech_prob": 0.00014425153494812548,
        "seek": 398800,
        "start": 3988,
        "temperature": 0,
        "text": " Because the name of the art is called Lotus.",
        "tokens": [
          50364,
          1436,
          264,
          1315,
          295,
          264,
          1523,
          307,
          1219,
          44769,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23722456462347685,
        "compression_ratio": 1.34640522875817,
        "end": 3998,
        "id": 714,
        "no_speech_prob": 0.00014425153494812548,
        "seek": 398800,
        "start": 3995,
        "temperature": 0,
        "text": " So now we go back to our code editor.",
        "tokens": [
          50714,
          407,
          586,
          321,
          352,
          646,
          281,
          527,
          3089,
          9839,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23722456462347685,
        "compression_ratio": 1.34640522875817,
        "end": 4001,
        "id": 715,
        "no_speech_prob": 0.00014425153494812548,
        "seek": 398800,
        "start": 3998,
        "temperature": 0,
        "text": " We have a new model here.",
        "tokens": [
          50864,
          492,
          362,
          257,
          777,
          2316,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23722456462347685,
        "compression_ratio": 1.34640522875817,
        "end": 4007,
        "id": 716,
        "no_speech_prob": 0.00014425153494812548,
        "seek": 398800,
        "start": 4001,
        "temperature": 0,
        "text": " And we can take a look at what is inside of the index HTML.",
        "tokens": [
          51014,
          400,
          321,
          393,
          747,
          257,
          574,
          412,
          437,
          307,
          1854,
          295,
          264,
          8186,
          17995,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23722456462347685,
        "compression_ratio": 1.34640522875817,
        "end": 4014,
        "id": 717,
        "no_speech_prob": 0.00014425153494812548,
        "seek": 398800,
        "start": 4007,
        "temperature": 0,
        "text": " So to build this demo, we need p5.js.",
        "tokens": [
          51314,
          407,
          281,
          1322,
          341,
          10723,
          11,
          321,
          643,
          280,
          20,
          13,
          25530,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2010033689899209,
        "compression_ratio": 1.5193370165745856,
        "end": 4018,
        "id": 718,
        "no_speech_prob": 0.00342932459898293,
        "seek": 401400,
        "start": 4015,
        "temperature": 0,
        "text": " Mainly to get the video from the webcam.",
        "tokens": [
          50414,
          47468,
          281,
          483,
          264,
          960,
          490,
          264,
          39490,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2010033689899209,
        "compression_ratio": 1.5193370165745856,
        "end": 4026,
        "id": 719,
        "no_speech_prob": 0.00342932459898293,
        "seek": 401400,
        "start": 4018,
        "temperature": 0,
        "text": " And also we need p5 DOM library to make it easier to create DOM elements for us.",
        "tokens": [
          50564,
          400,
          611,
          321,
          643,
          280,
          20,
          35727,
          6405,
          281,
          652,
          309,
          3571,
          281,
          1884,
          35727,
          4959,
          337,
          505,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2010033689899209,
        "compression_ratio": 1.5193370165745856,
        "end": 4031,
        "id": 720,
        "no_speech_prob": 0.00342932459898293,
        "seek": 401400,
        "start": 4026,
        "temperature": 0,
        "text": " And then in the end, we need the ml5 library.",
        "tokens": [
          50964,
          400,
          550,
          294,
          264,
          917,
          11,
          321,
          643,
          264,
          23271,
          20,
          6405,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2010033689899209,
        "compression_ratio": 1.5193370165745856,
        "end": 4033,
        "id": 721,
        "no_speech_prob": 0.00342932459898293,
        "seek": 401400,
        "start": 4031,
        "temperature": 0,
        "text": " And we have some styles here.",
        "tokens": [
          51214,
          400,
          321,
          362,
          512,
          13273,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2010033689899209,
        "compression_ratio": 1.5193370165745856,
        "end": 4035,
        "id": 722,
        "no_speech_prob": 0.00342932459898293,
        "seek": 401400,
        "start": 4033,
        "temperature": 0,
        "text": " We can ignore them for now.",
        "tokens": [
          51314,
          492,
          393,
          11200,
          552,
          337,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2010033689899209,
        "compression_ratio": 1.5193370165745856,
        "end": 4039,
        "id": 723,
        "no_speech_prob": 0.00342932459898293,
        "seek": 401400,
        "start": 4035,
        "temperature": 0,
        "text": " And we're also running the Sketch.js script here.",
        "tokens": [
          51414,
          400,
          321,
          434,
          611,
          2614,
          264,
          49245,
          13,
          25530,
          5755,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20703432989902185,
        "compression_ratio": 1.4806201550387597,
        "end": 4044,
        "id": 724,
        "no_speech_prob": 0.0007208031602203846,
        "seek": 403900,
        "start": 4039,
        "temperature": 0,
        "text": " And in the body, we have header tag.",
        "tokens": [
          50364,
          400,
          294,
          264,
          1772,
          11,
          321,
          362,
          23117,
          6162,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20703432989902185,
        "compression_ratio": 1.4806201550387597,
        "end": 4047,
        "id": 725,
        "no_speech_prob": 0.0007208031602203846,
        "seek": 403900,
        "start": 4044,
        "temperature": 0,
        "text": " We have p tag.",
        "tokens": [
          50614,
          492,
          362,
          280,
          6162,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20703432989902185,
        "compression_ratio": 1.4806201550387597,
        "end": 4052,
        "id": 726,
        "no_speech_prob": 0.0007208031602203846,
        "seek": 403900,
        "start": 4047,
        "temperature": 0,
        "text": " And we are linking the source of the image.",
        "tokens": [
          50764,
          400,
          321,
          366,
          25775,
          264,
          4009,
          295,
          264,
          3256,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20703432989902185,
        "compression_ratio": 1.4806201550387597,
        "end": 4055,
        "id": 727,
        "no_speech_prob": 0.0007208031602203846,
        "seek": 403900,
        "start": 4052,
        "temperature": 0,
        "text": " The art style image.",
        "tokens": [
          51014,
          440,
          1523,
          3758,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20703432989902185,
        "compression_ratio": 1.4806201550387597,
        "end": 4059,
        "id": 728,
        "no_speech_prob": 0.0007208031602203846,
        "seek": 403900,
        "start": 4055,
        "temperature": 0,
        "text": " And also we are showing the art image.",
        "tokens": [
          51164,
          400,
          611,
          321,
          366,
          4099,
          264,
          1523,
          3256,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20703432989902185,
        "compression_ratio": 1.4806201550387597,
        "end": 4067,
        "id": 729,
        "no_speech_prob": 0.0007208031602203846,
        "seek": 403900,
        "start": 4059,
        "temperature": 0,
        "text": " But I'm going to change this image.",
        "tokens": [
          51364,
          583,
          286,
          478,
          516,
          281,
          1319,
          341,
          3256,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4071,
        "id": 730,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4069,
        "temperature": 0,
        "text": " To the Lotus image.",
        "tokens": [
          50364,
          1407,
          264,
          44769,
          3256,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4076,
        "id": 731,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4071,
        "temperature": 0,
        "text": " This is a pre-trained model.",
        "tokens": [
          50464,
          639,
          307,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4082,
        "id": 732,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4076,
        "temperature": 0,
        "text": " I'm going to add this image into this image folder.",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          909,
          341,
          3256,
          666,
          341,
          3256,
          10820,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4084,
        "id": 733,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4082,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4088,
        "id": 734,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4084,
        "temperature": 0,
        "text": " So here we can say images slash Lotus.",
        "tokens": [
          51114,
          407,
          510,
          321,
          393,
          584,
          5267,
          17330,
          44769,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4090,
        "id": 735,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4088,
        "temperature": 0,
        "text": " So we are going to show that image.",
        "tokens": [
          51314,
          407,
          321,
          366,
          516,
          281,
          855,
          300,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1889283811891234,
        "compression_ratio": 1.525,
        "end": 4096,
        "id": 736,
        "no_speech_prob": 0.00006014103564666584,
        "seek": 406900,
        "start": 4090,
        "temperature": 0,
        "text": " And in the end, we have a div container to contain our canvas.",
        "tokens": [
          51414,
          400,
          294,
          264,
          917,
          11,
          321,
          362,
          257,
          3414,
          10129,
          281,
          5304,
          527,
          16267,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22561991491983102,
        "compression_ratio": 1.5359116022099448,
        "end": 4101,
        "id": 737,
        "no_speech_prob": 0.0008426247513853014,
        "seek": 409600,
        "start": 4096,
        "temperature": 0,
        "text": " And now we can go to let's save this in the HTML.",
        "tokens": [
          50364,
          400,
          586,
          321,
          393,
          352,
          281,
          220,
          306,
          83,
          311,
          3155,
          341,
          294,
          264,
          17995,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22561991491983102,
        "compression_ratio": 1.5359116022099448,
        "end": 4104,
        "id": 738,
        "no_speech_prob": 0.0008426247513853014,
        "seek": 409600,
        "start": 4101,
        "temperature": 0,
        "text": " And then we can go to Sketch.js.",
        "tokens": [
          50614,
          400,
          550,
          321,
          393,
          352,
          281,
          49245,
          13,
          25530,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22561991491983102,
        "compression_ratio": 1.5359116022099448,
        "end": 4107,
        "id": 739,
        "no_speech_prob": 0.0008426247513853014,
        "seek": 409600,
        "start": 4104,
        "temperature": 0,
        "text": " I'm just going to delete all the code here.",
        "tokens": [
          50764,
          286,
          478,
          445,
          516,
          281,
          12097,
          439,
          264,
          3089,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22561991491983102,
        "compression_ratio": 1.5359116022099448,
        "end": 4114,
        "id": 740,
        "no_speech_prob": 0.0008426247513853014,
        "seek": 409600,
        "start": 4107,
        "temperature": 0,
        "text": " So we can do it ourselves one more time together.",
        "tokens": [
          50914,
          407,
          321,
          393,
          360,
          309,
          4175,
          472,
          544,
          565,
          1214,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22561991491983102,
        "compression_ratio": 1.5359116022099448,
        "end": 4118,
        "id": 741,
        "no_speech_prob": 0.0008426247513853014,
        "seek": 409600,
        "start": 4114,
        "temperature": 0,
        "text": " So to build this demo, we need three things.",
        "tokens": [
          51264,
          407,
          281,
          1322,
          341,
          10723,
          11,
          321,
          643,
          1045,
          721,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22561991491983102,
        "compression_ratio": 1.5359116022099448,
        "end": 4124,
        "id": 742,
        "no_speech_prob": 0.0008426247513853014,
        "seek": 409600,
        "start": 4118,
        "temperature": 0,
        "text": " We need a video that can get the images from our webcam.",
        "tokens": [
          51464,
          492,
          643,
          257,
          960,
          300,
          393,
          483,
          264,
          5267,
          490,
          527,
          39490,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.210338229864416,
        "compression_ratio": 1.5276073619631902,
        "end": 4127,
        "id": 743,
        "no_speech_prob": 0.0005357703776098788,
        "seek": 412400,
        "start": 4125,
        "temperature": 0,
        "text": " So we have video.",
        "tokens": [
          50414,
          407,
          321,
          362,
          960,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.210338229864416,
        "compression_ratio": 1.5276073619631902,
        "end": 4135,
        "id": 744,
        "no_speech_prob": 0.0005357703776098788,
        "seek": 412400,
        "start": 4127,
        "temperature": 0,
        "text": " We also need the style transfer from ml5 library to allow us to transfer images.",
        "tokens": [
          50514,
          492,
          611,
          643,
          264,
          3758,
          5003,
          490,
          23271,
          20,
          6405,
          281,
          2089,
          505,
          281,
          5003,
          5267,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.210338229864416,
        "compression_ratio": 1.5276073619631902,
        "end": 4140,
        "id": 745,
        "no_speech_prob": 0.0005357703776098788,
        "seek": 412400,
        "start": 4135,
        "temperature": 0,
        "text": " So I'm going to have another variable called style.",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          362,
          1071,
          7006,
          1219,
          3758,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.210338229864416,
        "compression_ratio": 1.5276073619631902,
        "end": 4144,
        "id": 746,
        "no_speech_prob": 0.0005357703776098788,
        "seek": 412400,
        "start": 4140,
        "temperature": 0,
        "text": " And in the end, we need a variable to hold our output image.",
        "tokens": [
          51164,
          400,
          294,
          264,
          917,
          11,
          321,
          643,
          257,
          7006,
          281,
          1797,
          527,
          5598,
          3256,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.210338229864416,
        "compression_ratio": 1.5276073619631902,
        "end": 4151,
        "id": 747,
        "no_speech_prob": 0.0005357703776098788,
        "seek": 412400,
        "start": 4144,
        "temperature": 0,
        "text": " So we're going to do let without img.",
        "tokens": [
          51364,
          407,
          321,
          434,
          516,
          281,
          360,
          718,
          1553,
          566,
          70,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15838089927298124,
        "compression_ratio": 1.4214285714285715,
        "end": 4152,
        "id": 748,
        "no_speech_prob": 0.00009761536784935743,
        "seek": 415100,
        "start": 4151,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15838089927298124,
        "compression_ratio": 1.4214285714285715,
        "end": 4156,
        "id": 749,
        "no_speech_prob": 0.00009761536784935743,
        "seek": 415100,
        "start": 4152,
        "temperature": 0,
        "text": " So this is the three things that we need.",
        "tokens": [
          50414,
          407,
          341,
          307,
          264,
          1045,
          721,
          300,
          321,
          643,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15838089927298124,
        "compression_ratio": 1.4214285714285715,
        "end": 4163,
        "id": 750,
        "no_speech_prob": 0.00009761536784935743,
        "seek": 415100,
        "start": 4156,
        "temperature": 0,
        "text": " And in p5, there is a setup function that will be called once at the beginning.",
        "tokens": [
          50614,
          400,
          294,
          280,
          20,
          11,
          456,
          307,
          257,
          8657,
          2445,
          300,
          486,
          312,
          1219,
          1564,
          412,
          264,
          2863,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15838089927298124,
        "compression_ratio": 1.4214285714285715,
        "end": 4171,
        "id": 751,
        "no_speech_prob": 0.00009761536784935743,
        "seek": 415100,
        "start": 4163,
        "temperature": 0,
        "text": " So in this setup function, we're going to use p5.js to create a canvas.",
        "tokens": [
          50964,
          407,
          294,
          341,
          8657,
          2445,
          11,
          321,
          434,
          516,
          281,
          764,
          280,
          20,
          13,
          25530,
          281,
          1884,
          257,
          16267,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24146807470987008,
        "compression_ratio": 1.2671755725190839,
        "end": 4183,
        "id": 752,
        "no_speech_prob": 0.0007793402182869613,
        "seek": 417100,
        "start": 4172,
        "temperature": 0,
        "text": " That is 320 wide and 250 as its height.",
        "tokens": [
          50414,
          663,
          307,
          42429,
          4874,
          293,
          11650,
          382,
          1080,
          6681,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24146807470987008,
        "compression_ratio": 1.2671755725190839,
        "end": 4198,
        "id": 753,
        "no_speech_prob": 0.0007793402182869613,
        "seek": 417100,
        "start": 4183,
        "temperature": 0,
        "text": " And then we're going to use this p5 DOM library to put this canvas element inside of div element whose ID is canvas container.",
        "tokens": [
          50964,
          400,
          550,
          321,
          434,
          516,
          281,
          764,
          341,
          280,
          20,
          35727,
          6405,
          281,
          829,
          341,
          16267,
          4478,
          1854,
          295,
          3414,
          4478,
          6104,
          7348,
          307,
          16267,
          10129,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4199,
        "id": 754,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4198,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4201,
        "id": 755,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4199,
        "temperature": 0,
        "text": " So we create a canvas.",
        "tokens": [
          50414,
          407,
          321,
          1884,
          257,
          16267,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4202,
        "id": 756,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4201,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50514,
          663,
          311,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4205,
        "id": 757,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4202,
        "temperature": 0,
        "text": " And then we're going to create the video.",
        "tokens": [
          50564,
          400,
          550,
          321,
          434,
          516,
          281,
          1884,
          264,
          960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4213,
        "id": 758,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4205,
        "temperature": 0,
        "text": " So p5 has this function called create capture.",
        "tokens": [
          50714,
          407,
          280,
          20,
          575,
          341,
          2445,
          1219,
          1884,
          7983,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4220,
        "id": 759,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4213,
        "temperature": 0,
        "text": " And if we pass the uppercase video in, it will try to get the video from your webcam.",
        "tokens": [
          51114,
          400,
          498,
          321,
          1320,
          264,
          11775,
          2869,
          651,
          960,
          294,
          11,
          309,
          486,
          853,
          281,
          483,
          264,
          960,
          490,
          428,
          39490,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2090056911929623,
        "compression_ratio": 1.5968586387434556,
        "end": 4225,
        "id": 760,
        "no_speech_prob": 0.000043318414100212976,
        "seek": 419800,
        "start": 4220,
        "temperature": 0,
        "text": " And we're also going to save video.height because we don't really need the original video.",
        "tokens": [
          51464,
          400,
          321,
          434,
          611,
          516,
          281,
          3155,
          960,
          13,
          71,
          36309,
          570,
          321,
          500,
          380,
          534,
          643,
          264,
          3380,
          960,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2580551249640329,
        "compression_ratio": 1.3897058823529411,
        "end": 4228,
        "id": 761,
        "no_speech_prob": 0.006192571483552456,
        "seek": 422500,
        "start": 4225,
        "temperature": 0,
        "text": " We need the transferred video.",
        "tokens": [
          50364,
          492,
          643,
          264,
          15809,
          960,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2580551249640329,
        "compression_ratio": 1.3897058823529411,
        "end": 4233,
        "id": 762,
        "no_speech_prob": 0.006192571483552456,
        "seek": 422500,
        "start": 4228,
        "temperature": 0,
        "text": " So we're also going to say video height.",
        "tokens": [
          50514,
          407,
          321,
          434,
          611,
          516,
          281,
          584,
          960,
          6681,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2580551249640329,
        "compression_ratio": 1.3897058823529411,
        "end": 4244,
        "id": 763,
        "no_speech_prob": 0.006192571483552456,
        "seek": 422500,
        "start": 4239,
        "temperature": 0,
        "text": " And we're also going to create the result image.",
        "tokens": [
          51064,
          400,
          321,
          434,
          611,
          516,
          281,
          1884,
          264,
          1874,
          3256,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2580551249640329,
        "compression_ratio": 1.3897058823529411,
        "end": 4248,
        "id": 764,
        "no_speech_prob": 0.006192571483552456,
        "seek": 422500,
        "start": 4244,
        "temperature": 0,
        "text": " p5 DOM library has this.",
        "tokens": [
          51314,
          280,
          20,
          35727,
          6405,
          575,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2580551249640329,
        "compression_ratio": 1.3897058823529411,
        "end": 4253,
        "id": 765,
        "no_speech_prob": 0.006192571483552456,
        "seek": 422500,
        "start": 4248,
        "temperature": 0,
        "text": " I just want to make it a little bit better.",
        "tokens": [
          51514,
          286,
          445,
          528,
          281,
          652,
          309,
          257,
          707,
          857,
          1101,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19640753989995913,
        "compression_ratio": 1.6348314606741574,
        "end": 4260,
        "id": 766,
        "no_speech_prob": 0.00004985940540791489,
        "seek": 425500,
        "start": 4256,
        "temperature": 0,
        "text": " We're going to create this result image.",
        "tokens": [
          50414,
          492,
          434,
          516,
          281,
          1884,
          341,
          1874,
          3256,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19640753989995913,
        "compression_ratio": 1.6348314606741574,
        "end": 4263,
        "id": 767,
        "no_speech_prob": 0.00004985940540791489,
        "seek": 425500,
        "start": 4260,
        "temperature": 0,
        "text": " Equals to create IMG.",
        "tokens": [
          50614,
          15624,
          1124,
          281,
          1884,
          21463,
          38,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19640753989995913,
        "compression_ratio": 1.6348314606741574,
        "end": 4266,
        "id": 768,
        "no_speech_prob": 0.00004985940540791489,
        "seek": 425500,
        "start": 4263,
        "temperature": 0,
        "text": " Pass the empty string there.",
        "tokens": [
          50764,
          10319,
          264,
          6707,
          6798,
          456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19640753989995913,
        "compression_ratio": 1.6348314606741574,
        "end": 4271,
        "id": 769,
        "no_speech_prob": 0.00004985940540791489,
        "seek": 425500,
        "start": 4266,
        "temperature": 0,
        "text": " And we're also going to hide this image.",
        "tokens": [
          50914,
          400,
          321,
          434,
          611,
          516,
          281,
          6479,
          341,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19640753989995913,
        "compression_ratio": 1.6348314606741574,
        "end": 4276,
        "id": 770,
        "no_speech_prob": 0.00004985940540791489,
        "seek": 425500,
        "start": 4271,
        "temperature": 0,
        "text": " We're going to draw the image on the canvas so we don't really need this image.",
        "tokens": [
          51164,
          492,
          434,
          516,
          281,
          2642,
          264,
          3256,
          322,
          264,
          16267,
          370,
          321,
          500,
          380,
          534,
          643,
          341,
          3256,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19640753989995913,
        "compression_ratio": 1.6348314606741574,
        "end": 4282,
        "id": 771,
        "no_speech_prob": 0.00004985940540791489,
        "seek": 425500,
        "start": 4276,
        "temperature": 0,
        "text": " And in the end, we're going to use ml5 to get the style transfer model, right?",
        "tokens": [
          51414,
          400,
          294,
          264,
          917,
          11,
          321,
          434,
          516,
          281,
          764,
          23271,
          20,
          281,
          483,
          264,
          3758,
          5003,
          2316,
          11,
          558,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.36937814829300863,
        "compression_ratio": 1.3505154639175259,
        "end": 4291,
        "id": 772,
        "no_speech_prob": 0.00045828413567505777,
        "seek": 428200,
        "start": 4282,
        "temperature": 0.2,
        "text": " So style equals to ml5.styleTransfer.",
        "tokens": [
          50364,
          407,
          3758,
          6915,
          281,
          23271,
          20,
          13,
          15014,
          33339,
          612,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.36937814829300863,
        "compression_ratio": 1.3505154639175259,
        "end": 4295,
        "id": 773,
        "no_speech_prob": 0.00045828413567505777,
        "seek": 428200,
        "start": 4291,
        "temperature": 0.2,
        "text": " And we are going to pass in the path to the model.",
        "tokens": [
          50814,
          400,
          321,
          366,
          516,
          281,
          1320,
          294,
          264,
          3100,
          281,
          264,
          2316,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.36937814829300863,
        "compression_ratio": 1.3505154639175259,
        "end": 4303,
        "id": 774,
        "no_speech_prob": 0.00045828413567505777,
        "seek": 428200,
        "start": 4295,
        "temperature": 0.2,
        "text": " So it's models.models.models.models.lotus.",
        "tokens": [
          51014,
          407,
          309,
          311,
          5245,
          13,
          8014,
          1625,
          13,
          8014,
          1625,
          13,
          8014,
          1625,
          13,
          43571,
          301,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4306,
        "id": 775,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4304,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4313,
        "id": 776,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4306,
        "temperature": 0,
        "text": " And then we can also tell the style transfer to look for inputs from our video.",
        "tokens": [
          50514,
          400,
          550,
          321,
          393,
          611,
          980,
          264,
          3758,
          5003,
          281,
          574,
          337,
          15743,
          490,
          527,
          960,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4315,
        "id": 777,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4313,
        "temperature": 0,
        "text": " So we're passing the video.",
        "tokens": [
          50864,
          407,
          321,
          434,
          8437,
          264,
          960,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4319,
        "id": 778,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4315,
        "temperature": 0,
        "text": " And also, we have a callback function saying,",
        "tokens": [
          50964,
          400,
          611,
          11,
          321,
          362,
          257,
          818,
          3207,
          2445,
          1566,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4322,
        "id": 779,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4319,
        "temperature": 0,
        "text": " oh, if you finish loading this model, let me know.",
        "tokens": [
          51164,
          1954,
          11,
          498,
          291,
          2413,
          15114,
          341,
          2316,
          11,
          718,
          385,
          458,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4327,
        "id": 780,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4322,
        "temperature": 0,
        "text": " So this is a callback function called model loaded.",
        "tokens": [
          51314,
          407,
          341,
          307,
          257,
          818,
          3207,
          2445,
          1219,
          2316,
          13210,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4329,
        "id": 781,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4327,
        "temperature": 0,
        "text": " We're going to define this function now.",
        "tokens": [
          51564,
          492,
          434,
          516,
          281,
          6964,
          341,
          2445,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2009282764635588,
        "compression_ratio": 1.7382198952879582,
        "end": 4331,
        "id": 782,
        "no_speech_prob": 0.00036258462932892144,
        "seek": 430300,
        "start": 4329,
        "temperature": 0,
        "text": " This is a callback function.",
        "tokens": [
          51664,
          639,
          307,
          257,
          818,
          3207,
          2445,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20276871012217962,
        "compression_ratio": 1.5617283950617284,
        "end": 4337,
        "id": 783,
        "no_speech_prob": 0.00012931543460581452,
        "seek": 433100,
        "start": 4331,
        "temperature": 0,
        "text": " So we're going to do function model loaded.",
        "tokens": [
          50364,
          407,
          321,
          434,
          516,
          281,
          360,
          2445,
          2316,
          13210,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20276871012217962,
        "compression_ratio": 1.5617283950617284,
        "end": 4344,
        "id": 784,
        "no_speech_prob": 0.00012931543460581452,
        "seek": 433100,
        "start": 4337,
        "temperature": 0,
        "text": " Once the model is loaded, we can just ask the style transfer to transfer something.",
        "tokens": [
          50664,
          3443,
          264,
          2316,
          307,
          13210,
          11,
          321,
          393,
          445,
          1029,
          264,
          3758,
          5003,
          281,
          5003,
          746,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20276871012217962,
        "compression_ratio": 1.5617283950617284,
        "end": 4350,
        "id": 785,
        "no_speech_prob": 0.00012931543460581452,
        "seek": 433100,
        "start": 4344,
        "temperature": 0,
        "text": " But at first, I want to change the text on this p tag into model loaded",
        "tokens": [
          51014,
          583,
          412,
          700,
          11,
          286,
          528,
          281,
          1319,
          264,
          2487,
          322,
          341,
          280,
          6162,
          666,
          2316,
          13210,
          51314
        ]
      },
      {
        "avg_logprob": -0.20276871012217962,
        "compression_ratio": 1.5617283950617284,
        "end": 4354,
        "id": 786,
        "no_speech_prob": 0.00012931543460581452,
        "seek": 433100,
        "start": 4350,
        "temperature": 0,
        "text": " just to let people know that the model is good to go.",
        "tokens": [
          51314,
          445,
          281,
          718,
          561,
          458,
          300,
          264,
          2316,
          307,
          665,
          281,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22547044986631812,
        "compression_ratio": 1.2429906542056075,
        "end": 4361,
        "id": 787,
        "no_speech_prob": 0.0014550420455634594,
        "seek": 435400,
        "start": 4355,
        "temperature": 0,
        "text": " So I'm going to select an element.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          3048,
          364,
          4478,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22547044986631812,
        "compression_ratio": 1.2429906542056075,
        "end": 4374,
        "id": 788,
        "no_speech_prob": 0.0014550420455634594,
        "seek": 435400,
        "start": 4365,
        "temperature": 0,
        "text": " This is a function from a p5 DOM library to select an HTML element from the DOM.",
        "tokens": [
          50914,
          639,
          307,
          257,
          2445,
          490,
          257,
          280,
          20,
          35727,
          6405,
          281,
          3048,
          364,
          17995,
          4478,
          490,
          264,
          35727,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22547044986631812,
        "compression_ratio": 1.2429906542056075,
        "end": 4377,
        "id": 789,
        "no_speech_prob": 0.0014550420455634594,
        "seek": 435400,
        "start": 4374,
        "temperature": 0,
        "text": " The ID is status.",
        "tokens": [
          51364,
          440,
          7348,
          307,
          6558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4384,
        "id": 790,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4377,
        "temperature": 0,
        "text": " And I want to change its HTML to model loaded.",
        "tokens": [
          50364,
          400,
          286,
          528,
          281,
          1319,
          1080,
          17995,
          281,
          2316,
          13210,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4385,
        "id": 791,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4384,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4390,
        "id": 792,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4385,
        "temperature": 0,
        "text": " And then once the model is loaded, I'm going to ask the style to transfer something.",
        "tokens": [
          50764,
          400,
          550,
          1564,
          264,
          2316,
          307,
          13210,
          11,
          286,
          478,
          516,
          281,
          1029,
          264,
          3758,
          281,
          5003,
          746,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4393,
        "id": 793,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4390,
        "temperature": 0,
        "text": " So I'm going to say style.transfer.",
        "tokens": [
          51014,
          407,
          286,
          478,
          516,
          281,
          584,
          3758,
          13,
          24999,
          612,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4399,
        "id": 794,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4393,
        "temperature": 0,
        "text": " And I'm going to pass in another function called result.",
        "tokens": [
          51164,
          400,
          286,
          478,
          516,
          281,
          1320,
          294,
          1071,
          2445,
          1219,
          1874,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4401,
        "id": 795,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4399,
        "temperature": 0,
        "text": " So this is a callback function.",
        "tokens": [
          51464,
          407,
          341,
          307,
          257,
          818,
          3207,
          2445,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14329403379689093,
        "compression_ratio": 1.7340425531914894,
        "end": 4406,
        "id": 796,
        "no_speech_prob": 0.000006962218321859837,
        "seek": 437700,
        "start": 4401,
        "temperature": 0,
        "text": " Once the model got anything back, this function will be called.",
        "tokens": [
          51564,
          3443,
          264,
          2316,
          658,
          1340,
          646,
          11,
          341,
          2445,
          486,
          312,
          1219,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1745811889046117,
        "compression_ratio": 1.5508982035928143,
        "end": 4409,
        "id": 797,
        "no_speech_prob": 0.000019525761672412045,
        "seek": 440600,
        "start": 4406,
        "temperature": 0,
        "text": " So let's make up this function.",
        "tokens": [
          50364,
          407,
          718,
          311,
          652,
          493,
          341,
          2445,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1745811889046117,
        "compression_ratio": 1.5508982035928143,
        "end": 4411,
        "id": 798,
        "no_speech_prob": 0.000019525761672412045,
        "seek": 440600,
        "start": 4409,
        "temperature": 0,
        "text": " Function got result.",
        "tokens": [
          50514,
          11166,
          882,
          658,
          1874,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1745811889046117,
        "compression_ratio": 1.5508982035928143,
        "end": 4413,
        "id": 799,
        "no_speech_prob": 0.000019525761672412045,
        "seek": 440600,
        "start": 4411,
        "temperature": 0,
        "text": " It will get two things.",
        "tokens": [
          50614,
          467,
          486,
          483,
          732,
          721,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1745811889046117,
        "compression_ratio": 1.5508982035928143,
        "end": 4420,
        "id": 800,
        "no_speech_prob": 0.000019525761672412045,
        "seek": 440600,
        "start": 4413,
        "temperature": 0,
        "text": " One is if there's any error during this process, it will put the error in this error variable.",
        "tokens": [
          50714,
          1485,
          307,
          498,
          456,
          311,
          604,
          6713,
          1830,
          341,
          1399,
          11,
          309,
          486,
          829,
          264,
          6713,
          294,
          341,
          6713,
          7006,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1745811889046117,
        "compression_ratio": 1.5508982035928143,
        "end": 4423,
        "id": 801,
        "no_speech_prob": 0.000019525761672412045,
        "seek": 440600,
        "start": 4420,
        "temperature": 0,
        "text": " And another thing is the output, which is an image.",
        "tokens": [
          51064,
          400,
          1071,
          551,
          307,
          264,
          5598,
          11,
          597,
          307,
          364,
          3256,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1745811889046117,
        "compression_ratio": 1.5508982035928143,
        "end": 4426,
        "id": 802,
        "no_speech_prob": 0.000019525761672412045,
        "seek": 440600,
        "start": 4423,
        "temperature": 0,
        "text": " So in this, once we got the result,",
        "tokens": [
          51214,
          407,
          294,
          341,
          11,
          1564,
          321,
          658,
          264,
          1874,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.23973915312025282,
        "compression_ratio": 1.4252873563218391,
        "end": 4439,
        "id": 803,
        "no_speech_prob": 0.020328566431999207,
        "seek": 442600,
        "start": 4426,
        "temperature": 0,
        "text": " we are going to give the result image an attribute to hold this image.source.",
        "tokens": [
          50364,
          321,
          366,
          516,
          281,
          976,
          264,
          1874,
          3256,
          364,
          19667,
          281,
          1797,
          341,
          3256,
          13,
          41676,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23973915312025282,
        "compression_ratio": 1.4252873563218391,
        "end": 4444,
        "id": 804,
        "no_speech_prob": 0.020328566431999207,
        "seek": 442600,
        "start": 4439,
        "temperature": 0,
        "text": " So we are going to say result image.attribute.",
        "tokens": [
          51014,
          407,
          321,
          366,
          516,
          281,
          584,
          1874,
          3256,
          13,
          1591,
          2024,
          1169,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2468537723316866,
        "compression_ratio": 1.6357142857142857,
        "end": 4455,
        "id": 805,
        "no_speech_prob": 0.0027575907297432423,
        "seek": 444400,
        "start": 4445,
        "temperature": 0,
        "text": " We copy the source of this image, the source, to our result image.",
        "tokens": [
          50414,
          492,
          5055,
          264,
          4009,
          295,
          341,
          3256,
          11,
          264,
          4009,
          11,
          281,
          527,
          1874,
          3256,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2468537723316866,
        "compression_ratio": 1.6357142857142857,
        "end": 4463,
        "id": 806,
        "no_speech_prob": 0.0027575907297432423,
        "seek": 444400,
        "start": 4455,
        "temperature": 0,
        "text": " And after we got the result, we want to call this style.transfer again,",
        "tokens": [
          50914,
          400,
          934,
          321,
          658,
          264,
          1874,
          11,
          321,
          528,
          281,
          818,
          341,
          3758,
          13,
          24999,
          612,
          797,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2468537723316866,
        "compression_ratio": 1.6357142857142857,
        "end": 4467,
        "id": 807,
        "no_speech_prob": 0.0027575907297432423,
        "seek": 444400,
        "start": 4463,
        "temperature": 0,
        "text": " over and over again to see more result.",
        "tokens": [
          51314,
          670,
          293,
          670,
          797,
          281,
          536,
          544,
          1874,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2468537723316866,
        "compression_ratio": 1.6357142857142857,
        "end": 4471,
        "id": 808,
        "no_speech_prob": 0.0027575907297432423,
        "seek": 444400,
        "start": 4467,
        "temperature": 0,
        "text": " So we are going to do style.transfer.result again.",
        "tokens": [
          51514,
          407,
          321,
          366,
          516,
          281,
          360,
          3758,
          13,
          24999,
          612,
          13,
          495,
          723,
          797,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2068666270081426,
        "compression_ratio": 1.5987654320987654,
        "end": 4478,
        "id": 809,
        "no_speech_prob": 0.00006108839443186298,
        "seek": 447100,
        "start": 4472,
        "temperature": 0,
        "text": " And one thing is missing because we did update the source for result image,",
        "tokens": [
          50414,
          400,
          472,
          551,
          307,
          5361,
          570,
          321,
          630,
          5623,
          264,
          4009,
          337,
          1874,
          3256,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.2068666270081426,
        "compression_ratio": 1.5987654320987654,
        "end": 4484,
        "id": 810,
        "no_speech_prob": 0.00006108839443186298,
        "seek": 447100,
        "start": 4478,
        "temperature": 0,
        "text": " but this result image is hidden, so we cannot see it.",
        "tokens": [
          50714,
          457,
          341,
          1874,
          3256,
          307,
          7633,
          11,
          370,
          321,
          2644,
          536,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2068666270081426,
        "compression_ratio": 1.5987654320987654,
        "end": 4487,
        "id": 811,
        "no_speech_prob": 0.00006108839443186298,
        "seek": 447100,
        "start": 4484,
        "temperature": 0,
        "text": " But p5 has a function called draw.",
        "tokens": [
          51014,
          583,
          280,
          20,
          575,
          257,
          2445,
          1219,
          2642,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2068666270081426,
        "compression_ratio": 1.5987654320987654,
        "end": 4491,
        "id": 812,
        "no_speech_prob": 0.00006108839443186298,
        "seek": 447100,
        "start": 4487,
        "temperature": 0,
        "text": " It will run over and over again.",
        "tokens": [
          51164,
          467,
          486,
          1190,
          670,
          293,
          670,
          797,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2068666270081426,
        "compression_ratio": 1.5987654320987654,
        "end": 4496,
        "id": 813,
        "no_speech_prob": 0.00006108839443186298,
        "seek": 447100,
        "start": 4491,
        "temperature": 0,
        "text": " In the draw function, we are going to draw this result image.",
        "tokens": [
          51364,
          682,
          264,
          2642,
          2445,
          11,
          321,
          366,
          516,
          281,
          2642,
          341,
          1874,
          3256,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23937954336909925,
        "compression_ratio": 1.2153846153846153,
        "end": 4500,
        "id": 814,
        "no_speech_prob": 0.0002868525916710496,
        "seek": 449600,
        "start": 4496,
        "temperature": 0,
        "text": " So I'm just going to say image.",
        "tokens": [
          50364,
          407,
          286,
          478,
          445,
          516,
          281,
          584,
          3256,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23937954336909925,
        "compression_ratio": 1.2153846153846153,
        "end": 4502,
        "id": 815,
        "no_speech_prob": 0.0002868525916710496,
        "seek": 449600,
        "start": 4500,
        "temperature": 0,
        "text": " It's lowercase i.",
        "tokens": [
          50564,
          467,
          311,
          3126,
          9765,
          741,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23937954336909925,
        "compression_ratio": 1.2153846153846153,
        "end": 4515,
        "id": 816,
        "no_speech_prob": 0.0002868525916710496,
        "seek": 449600,
        "start": 4502,
        "temperature": 0,
        "text": " Image result img from origin 0, 0, and the size is 320 to 240.",
        "tokens": [
          50664,
          29903,
          1874,
          566,
          70,
          490,
          4957,
          1958,
          11,
          1958,
          11,
          293,
          264,
          2744,
          307,
          42429,
          281,
          26837,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23937954336909925,
        "compression_ratio": 1.2153846153846153,
        "end": 4517,
        "id": 817,
        "no_speech_prob": 0.0002868525916710496,
        "seek": 449600,
        "start": 4515,
        "temperature": 0,
        "text": " Okay, that's it.",
        "tokens": [
          51314,
          1033,
          11,
          300,
          311,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23937954336909925,
        "compression_ratio": 1.2153846153846153,
        "end": 4523,
        "id": 818,
        "no_speech_prob": 0.0002868525916710496,
        "seek": 449600,
        "start": 4519,
        "temperature": 0,
        "text": " This is the whole Sketch.js.",
        "tokens": [
          51514,
          639,
          307,
          264,
          1379,
          49245,
          13,
          25530,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2687814749923407,
        "compression_ratio": 1.3801652892561984,
        "end": 4533,
        "id": 819,
        "no_speech_prob": 0.0001559797819936648,
        "seek": 452300,
        "start": 4523,
        "temperature": 0,
        "text": " Next, finally, we are going to run this code.",
        "tokens": [
          50364,
          3087,
          11,
          2721,
          11,
          321,
          366,
          516,
          281,
          1190,
          341,
          3089,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2687814749923407,
        "compression_ratio": 1.3801652892561984,
        "end": 4538,
        "id": 820,
        "no_speech_prob": 0.0001559797819936648,
        "seek": 452300,
        "start": 4533,
        "temperature": 0,
        "text": " We can do Python minus m simple HTTP server.",
        "tokens": [
          50864,
          492,
          393,
          360,
          15329,
          3175,
          275,
          2199,
          33283,
          7154,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2687814749923407,
        "compression_ratio": 1.3801652892561984,
        "end": 4548,
        "id": 821,
        "no_speech_prob": 0.0001559797819936648,
        "seek": 452300,
        "start": 4538,
        "temperature": 0,
        "text": " If you are using Python 3, you need to do Python minus m simple.http server.",
        "tokens": [
          51114,
          759,
          291,
          366,
          1228,
          15329,
          805,
          11,
          291,
          643,
          281,
          360,
          15329,
          3175,
          275,
          2199,
          13,
          357,
          83,
          79,
          7154,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2097921551398511,
        "compression_ratio": 1.3464566929133859,
        "end": 4553,
        "id": 822,
        "no_speech_prob": 0.001151347067207098,
        "seek": 454800,
        "start": 4548,
        "temperature": 0,
        "text": " Anyway, it started server at localhost 8000.",
        "tokens": [
          50364,
          5684,
          11,
          309,
          1409,
          7154,
          412,
          2654,
          6037,
          1649,
          1360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2097921551398511,
        "compression_ratio": 1.3464566929133859,
        "end": 4565,
        "id": 823,
        "no_speech_prob": 0.001151347067207098,
        "seek": 454800,
        "start": 4553,
        "temperature": 0,
        "text": " So now if we go to our localhost 8000, we should be able to see something.",
        "tokens": [
          50614,
          407,
          586,
          498,
          321,
          352,
          281,
          527,
          2654,
          6037,
          1649,
          1360,
          11,
          321,
          820,
          312,
          1075,
          281,
          536,
          746,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2097921551398511,
        "compression_ratio": 1.3464566929133859,
        "end": 4574,
        "id": 824,
        "no_speech_prob": 0.001151347067207098,
        "seek": 454800,
        "start": 4571,
        "temperature": 0,
        "text": " So model is loaded.",
        "tokens": [
          51514,
          407,
          2316,
          307,
          13210,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2097921551398511,
        "compression_ratio": 1.3464566929133859,
        "end": 4577,
        "id": 825,
        "no_speech_prob": 0.001151347067207098,
        "seek": 454800,
        "start": 4574,
        "temperature": 0,
        "text": " This is the wrong style source.",
        "tokens": [
          51664,
          639,
          307,
          264,
          2085,
          3758,
          4009,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21992905934651694,
        "compression_ratio": 1.3971631205673758,
        "end": 4579,
        "id": 826,
        "no_speech_prob": 0.00031999091152101755,
        "seek": 457700,
        "start": 4577,
        "temperature": 0,
        "text": " I just have to come in and try.",
        "tokens": [
          50364,
          286,
          445,
          362,
          281,
          808,
          294,
          293,
          853,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21992905934651694,
        "compression_ratio": 1.3971631205673758,
        "end": 4584,
        "id": 827,
        "no_speech_prob": 0.00031999091152101755,
        "seek": 457700,
        "start": 4582,
        "temperature": 0,
        "text": " That is so cool.",
        "tokens": [
          50614,
          663,
          307,
          370,
          1627,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21992905934651694,
        "compression_ratio": 1.3971631205673758,
        "end": 4588,
        "id": 828,
        "no_speech_prob": 0.00031999091152101755,
        "seek": 457700,
        "start": 4585,
        "temperature": 0,
        "text": " As you can see, this style has more colors,",
        "tokens": [
          50764,
          1018,
          291,
          393,
          536,
          11,
          341,
          3758,
          575,
          544,
          4577,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.21992905934651694,
        "compression_ratio": 1.3971631205673758,
        "end": 4595,
        "id": 829,
        "no_speech_prob": 0.00031999091152101755,
        "seek": 457700,
        "start": 4588,
        "temperature": 0,
        "text": " so the result is a little bit better than the previous model.",
        "tokens": [
          50914,
          370,
          264,
          1874,
          307,
          257,
          707,
          857,
          1101,
          813,
          264,
          3894,
          2316,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21992905934651694,
        "compression_ratio": 1.3971631205673758,
        "end": 4601,
        "id": 830,
        "no_speech_prob": 0.00031999091152101755,
        "seek": 457700,
        "start": 4597,
        "temperature": 0,
        "text": " Yes, this is the demo that we built today.",
        "tokens": [
          51364,
          1079,
          11,
          341,
          307,
          264,
          10723,
          300,
          321,
          3094,
          965,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2508034124606993,
        "compression_ratio": 1.489010989010989,
        "end": 4610,
        "id": 831,
        "no_speech_prob": 0.0011694654822349548,
        "seek": 460700,
        "start": 4607,
        "temperature": 0,
        "text": " This is all the resources that I used.",
        "tokens": [
          50364,
          639,
          307,
          439,
          264,
          3593,
          300,
          286,
          1143,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2508034124606993,
        "compression_ratio": 1.489010989010989,
        "end": 4615,
        "id": 832,
        "no_speech_prob": 0.0011694654822349548,
        "seek": 460700,
        "start": 4610,
        "temperature": 0,
        "text": " This is Getty's paper from 2015.",
        "tokens": [
          50514,
          639,
          307,
          460,
          38204,
          311,
          3035,
          490,
          7546,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2508034124606993,
        "compression_ratio": 1.489010989010989,
        "end": 4619,
        "id": 833,
        "no_speech_prob": 0.0011694654822349548,
        "seek": 460700,
        "start": 4615,
        "temperature": 0,
        "text": " This is Gene Cogan's What Neural Networks Sees.",
        "tokens": [
          50764,
          639,
          307,
          18083,
          383,
          21576,
          311,
          708,
          1734,
          1807,
          12640,
          82,
          1100,
          279,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2508034124606993,
        "compression_ratio": 1.489010989010989,
        "end": 4625,
        "id": 834,
        "no_speech_prob": 0.0011694654822349548,
        "seek": 460700,
        "start": 4620,
        "temperature": 0,
        "text": " This is the transfer style tutorial from Spell.",
        "tokens": [
          51014,
          639,
          307,
          264,
          5003,
          3758,
          7073,
          490,
          3550,
          285,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2508034124606993,
        "compression_ratio": 1.489010989010989,
        "end": 4630,
        "id": 835,
        "no_speech_prob": 0.0011694654822349548,
        "seek": 460700,
        "start": 4625,
        "temperature": 0,
        "text": " Also for ML5.js, it has a style transfer tutorial made by Chris.",
        "tokens": [
          51264,
          2743,
          337,
          21601,
          20,
          13,
          25530,
          11,
          309,
          575,
          257,
          3758,
          5003,
          7073,
          1027,
          538,
          6688,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2508034124606993,
        "compression_ratio": 1.489010989010989,
        "end": 4634,
        "id": 836,
        "no_speech_prob": 0.0011694654822349548,
        "seek": 460700,
        "start": 4631,
        "temperature": 0,
        "text": " I recommend you to check that out too.",
        "tokens": [
          51564,
          286,
          2748,
          291,
          281,
          1520,
          300,
          484,
          886,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2425490116727525,
        "compression_ratio": 1.4102564102564104,
        "end": 4637,
        "id": 837,
        "no_speech_prob": 0.0009253610041923821,
        "seek": 463400,
        "start": 4634,
        "temperature": 0,
        "text": " This is the link to ML5.js.",
        "tokens": [
          50364,
          639,
          307,
          264,
          2113,
          281,
          21601,
          20,
          13,
          25530,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2425490116727525,
        "compression_ratio": 1.4102564102564104,
        "end": 4641,
        "id": 838,
        "no_speech_prob": 0.0009253610041923821,
        "seek": 463400,
        "start": 4637,
        "temperature": 0,
        "text": " I also want to recommend this YouTube channel",
        "tokens": [
          50514,
          286,
          611,
          528,
          281,
          2748,
          341,
          3088,
          2269,
          50714
        ]
      },
      {
        "avg_logprob": -0.2425490116727525,
        "compression_ratio": 1.4102564102564104,
        "end": 4644,
        "id": 839,
        "no_speech_prob": 0.0009253610041923821,
        "seek": 463400,
        "start": 4641,
        "temperature": 0,
        "text": " because I learned a lot of machine learning papers from it.",
        "tokens": [
          50714,
          570,
          286,
          3264,
          257,
          688,
          295,
          3479,
          2539,
          10577,
          490,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2425490116727525,
        "compression_ratio": 1.4102564102564104,
        "end": 4652,
        "id": 840,
        "no_speech_prob": 0.0009253610041923821,
        "seek": 463400,
        "start": 4646,
        "temperature": 0,
        "text": " I want to give credit to those two project creators.",
        "tokens": [
          50964,
          286,
          528,
          281,
          976,
          5397,
          281,
          729,
          732,
          1716,
          16039,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2425490116727525,
        "compression_ratio": 1.4102564102564104,
        "end": 4659,
        "id": 841,
        "no_speech_prob": 0.0009253610041923821,
        "seek": 463400,
        "start": 4652,
        "temperature": 0,
        "text": " We used the TensorFlow implementation of the fast style transfer made by Logan Engstrom.",
        "tokens": [
          51264,
          492,
          1143,
          264,
          37624,
          11420,
          295,
          264,
          2370,
          3758,
          5003,
          1027,
          538,
          22689,
          2469,
          38673,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.25008143107096353,
        "compression_ratio": 1.439306358381503,
        "end": 4664,
        "id": 842,
        "no_speech_prob": 0.0002002667897613719,
        "seek": 465900,
        "start": 4660,
        "temperature": 0,
        "text": " We used the script to convert the TensorFlow saved model",
        "tokens": [
          50414,
          492,
          1143,
          264,
          5755,
          281,
          7620,
          264,
          37624,
          6624,
          2316,
          50614
        ]
      },
      {
        "avg_logprob": -0.25008143107096353,
        "compression_ratio": 1.439306358381503,
        "end": 4669,
        "id": 843,
        "no_speech_prob": 0.0002002667897613719,
        "seek": 465900,
        "start": 4664,
        "temperature": 0,
        "text": " to a format that we can use in TensorFlow.js and ML5.js.",
        "tokens": [
          50614,
          281,
          257,
          7877,
          300,
          321,
          393,
          764,
          294,
          37624,
          13,
          25530,
          293,
          21601,
          20,
          13,
          25530,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.25008143107096353,
        "compression_ratio": 1.439306358381503,
        "end": 4675,
        "id": 844,
        "no_speech_prob": 0.0002002667897613719,
        "seek": 465900,
        "start": 4669,
        "temperature": 0,
        "text": " It's made by Richiro Nakano.",
        "tokens": [
          50864,
          467,
          311,
          1027,
          538,
          497,
          480,
          5182,
          25779,
          3730,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25008143107096353,
        "compression_ratio": 1.439306358381503,
        "end": 4682,
        "id": 845,
        "no_speech_prob": 0.0002002667897613719,
        "seek": 465900,
        "start": 4677,
        "temperature": 0,
        "text": " To wrap up today, we trained a style transfer model with Spell.",
        "tokens": [
          51264,
          1407,
          7019,
          493,
          965,
          11,
          321,
          8895,
          257,
          3758,
          5003,
          2316,
          365,
          3550,
          285,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25008143107096353,
        "compression_ratio": 1.439306358381503,
        "end": 4687,
        "id": 846,
        "no_speech_prob": 0.0002002667897613719,
        "seek": 465900,
        "start": 4682,
        "temperature": 0,
        "text": " We ran this model with ML5 in the browser.",
        "tokens": [
          51514,
          492,
          5872,
          341,
          2316,
          365,
          21601,
          20,
          294,
          264,
          11185,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2543920250826104,
        "compression_ratio": 1.5388349514563107,
        "end": 4690,
        "id": 847,
        "no_speech_prob": 0.0003148557443637401,
        "seek": 468700,
        "start": 4687,
        "temperature": 0,
        "text": " You can check out the model here.",
        "tokens": [
          50364,
          509,
          393,
          1520,
          484,
          264,
          2316,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2543920250826104,
        "compression_ratio": 1.5388349514563107,
        "end": 4694,
        "id": 848,
        "no_speech_prob": 0.0003148557443637401,
        "seek": 468700,
        "start": 4691,
        "temperature": 0,
        "text": " That's it. I hope you guys liked the video.",
        "tokens": [
          50564,
          663,
          311,
          309,
          13,
          286,
          1454,
          291,
          1074,
          4501,
          264,
          960,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2543920250826104,
        "compression_ratio": 1.5388349514563107,
        "end": 4700,
        "id": 849,
        "no_speech_prob": 0.0003148557443637401,
        "seek": 468700,
        "start": 4694,
        "temperature": 0,
        "text": " If you run into any issues when you're training or running the model,",
        "tokens": [
          50714,
          759,
          291,
          1190,
          666,
          604,
          2663,
          562,
          291,
          434,
          3097,
          420,
          2614,
          264,
          2316,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.2543920250826104,
        "compression_ratio": 1.5388349514563107,
        "end": 4704,
        "id": 850,
        "no_speech_prob": 0.0003148557443637401,
        "seek": 468700,
        "start": 4700,
        "temperature": 0,
        "text": " you can leave the comments or open one issue on the GitHub.",
        "tokens": [
          51014,
          291,
          393,
          1856,
          264,
          3053,
          420,
          1269,
          472,
          2734,
          322,
          264,
          23331,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2543920250826104,
        "compression_ratio": 1.5388349514563107,
        "end": 4709,
        "id": 851,
        "no_speech_prob": 0.0003148557443637401,
        "seek": 468700,
        "start": 4707,
        "temperature": 0,
        "text": " Come over here. Some people asked some interesting questions.",
        "tokens": [
          51364,
          2492,
          670,
          510,
          13,
          2188,
          561,
          2351,
          512,
          1880,
          1651,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2543920250826104,
        "compression_ratio": 1.5388349514563107,
        "end": 4715,
        "id": 852,
        "no_speech_prob": 0.0003148557443637401,
        "seek": 468700,
        "start": 4709,
        "temperature": 0,
        "text": " I'm actually going to have a short Q&A session.",
        "tokens": [
          51464,
          286,
          478,
          767,
          516,
          281,
          362,
          257,
          2099,
          1249,
          5,
          32,
          5481,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4718,
        "id": 853,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4716,
        "temperature": 0,
        "text": " I'm also going to make the chat a little bit bigger",
        "tokens": [
          50414,
          286,
          478,
          611,
          516,
          281,
          652,
          264,
          5081,
          257,
          707,
          857,
          3801,
          50514
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4724,
        "id": 854,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4718,
        "temperature": 0,
        "text": " so I might be able to monitor it as we're talking a little bit.",
        "tokens": [
          50514,
          370,
          286,
          1062,
          312,
          1075,
          281,
          6002,
          309,
          382,
          321,
          434,
          1417,
          257,
          707,
          857,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4729,
        "id": 855,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4724,
        "temperature": 0,
        "text": " This is always awkward. We don't have a good interview Q&A setup here.",
        "tokens": [
          50814,
          639,
          307,
          1009,
          11411,
          13,
          492,
          500,
          380,
          362,
          257,
          665,
          4049,
          1249,
          5,
          32,
          8657,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4730,
        "id": 856,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4729,
        "temperature": 0,
        "text": " I'll just try.",
        "tokens": [
          51064,
          286,
          603,
          445,
          853,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4733,
        "id": 857,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4730,
        "temperature": 0,
        "text": " One thing that somebody asked that I thought was interesting.",
        "tokens": [
          51114,
          1485,
          551,
          300,
          2618,
          2351,
          300,
          286,
          1194,
          390,
          1880,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4735,
        "id": 858,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4733,
        "temperature": 0,
        "text": " You notice it runs slow in the browser.",
        "tokens": [
          51264,
          509,
          3449,
          309,
          6676,
          2964,
          294,
          264,
          11185,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4738,
        "id": 859,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4735,
        "temperature": 0,
        "text": " It's amazing that it runs at all.",
        "tokens": [
          51364,
          467,
          311,
          2243,
          300,
          309,
          6676,
          412,
          439,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2540272507712106,
        "compression_ratio": 1.5731225296442688,
        "end": 4744,
        "id": 860,
        "no_speech_prob": 0.017764944583177567,
        "seek": 471500,
        "start": 4739,
        "temperature": 0,
        "text": " Some people asked what performance considerations are there.",
        "tokens": [
          51564,
          2188,
          561,
          2351,
          437,
          3389,
          24070,
          366,
          456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24444868829515246,
        "compression_ratio": 1.3804347826086956,
        "end": 4747,
        "id": 861,
        "no_speech_prob": 0.000939916237257421,
        "seek": 474400,
        "start": 4744,
        "temperature": 0,
        "text": " Can this actually run on a mobile phone?",
        "tokens": [
          50364,
          1664,
          341,
          767,
          1190,
          322,
          257,
          6013,
          2593,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.24444868829515246,
        "compression_ratio": 1.3804347826086956,
        "end": 4751,
        "id": 862,
        "no_speech_prob": 0.000939916237257421,
        "seek": 474400,
        "start": 4748,
        "temperature": 0,
        "text": " How far have you pushed that or experimented with it?",
        "tokens": [
          50564,
          1012,
          1400,
          362,
          291,
          9152,
          300,
          420,
          5120,
          292,
          365,
          309,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.24444868829515246,
        "compression_ratio": 1.3804347826086956,
        "end": 4755,
        "id": 863,
        "no_speech_prob": 0.000939916237257421,
        "seek": 474400,
        "start": 4751,
        "temperature": 0,
        "text": " For now, I think it works well in Chrome.",
        "tokens": [
          50714,
          1171,
          586,
          11,
          286,
          519,
          309,
          1985,
          731,
          294,
          15327,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24444868829515246,
        "compression_ratio": 1.3804347826086956,
        "end": 4762,
        "id": 864,
        "no_speech_prob": 0.000939916237257421,
        "seek": 474400,
        "start": 4755,
        "temperature": 0,
        "text": " I know TensorFlow.js also supports iOS and other OS.",
        "tokens": [
          50914,
          286,
          458,
          37624,
          13,
          25530,
          611,
          9346,
          17430,
          293,
          661,
          12731,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24444868829515246,
        "compression_ratio": 1.3804347826086956,
        "end": 4770,
        "id": 865,
        "no_speech_prob": 0.000939916237257421,
        "seek": 474400,
        "start": 4762,
        "temperature": 0,
        "text": " It has slightly different results in different OS.",
        "tokens": [
          51264,
          467,
          575,
          4748,
          819,
          3542,
          294,
          819,
          12731,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24444868829515246,
        "compression_ratio": 1.3804347826086956,
        "end": 4773,
        "id": 866,
        "no_speech_prob": 0.000939916237257421,
        "seek": 474400,
        "start": 4770,
        "temperature": 0,
        "text": " I'm not sure.",
        "tokens": [
          51664,
          286,
          478,
          406,
          988,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4778,
        "id": 867,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4774,
        "temperature": 0,
        "text": " My experience doing this sort of stuff over the last 10 plus years,",
        "tokens": [
          50414,
          1222,
          1752,
          884,
          341,
          1333,
          295,
          1507,
          670,
          264,
          1036,
          1266,
          1804,
          924,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4782,
        "id": 868,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4778,
        "temperature": 0,
        "text": " the thing that you're doing now, in a couple of years,",
        "tokens": [
          50614,
          264,
          551,
          300,
          291,
          434,
          884,
          586,
          11,
          294,
          257,
          1916,
          295,
          924,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4784,
        "id": 869,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4782,
        "temperature": 0,
        "text": " that will work on the smaller devices.",
        "tokens": [
          50814,
          300,
          486,
          589,
          322,
          264,
          4356,
          5759,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4788,
        "id": 870,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4784,
        "temperature": 0,
        "text": " Then the newer thing will be super fast and that will work on the smaller devices.",
        "tokens": [
          50914,
          1396,
          264,
          17628,
          551,
          486,
          312,
          1687,
          2370,
          293,
          300,
          486,
          589,
          322,
          264,
          4356,
          5759,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4791,
        "id": 871,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4788,
        "temperature": 0,
        "text": " The stuff is all very cyclical.",
        "tokens": [
          51114,
          440,
          1507,
          307,
          439,
          588,
          19474,
          804,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4795,
        "id": 872,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4791,
        "temperature": 0,
        "text": " The fact that it runs in a browser just makes it so flexible.",
        "tokens": [
          51264,
          440,
          1186,
          300,
          309,
          6676,
          294,
          257,
          11185,
          445,
          1669,
          309,
          370,
          11358,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4799,
        "id": 873,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4795,
        "temperature": 0,
        "text": " Again, to be clear, the training process here",
        "tokens": [
          51464,
          3764,
          11,
          281,
          312,
          1850,
          11,
          264,
          3097,
          1399,
          510,
          51664
        ]
      },
      {
        "avg_logprob": -0.23621440755909887,
        "compression_ratio": 1.8319327731092436,
        "end": 4801,
        "id": 874,
        "no_speech_prob": 0.0018382559064775705,
        "seek": 477300,
        "start": 4799,
        "temperature": 0,
        "text": " is a thing that you can't easily do in the browser.",
        "tokens": [
          51664,
          307,
          257,
          551,
          300,
          291,
          393,
          380,
          3612,
          360,
          294,
          264,
          11185,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4803,
        "id": 875,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4801,
        "temperature": 0,
        "text": " That's the thing that takes a very long time.",
        "tokens": [
          50364,
          663,
          311,
          264,
          551,
          300,
          2516,
          257,
          588,
          938,
          565,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4805,
        "id": 876,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4803,
        "temperature": 0,
        "text": " You can certainly do it on your own computer.",
        "tokens": [
          50464,
          509,
          393,
          3297,
          360,
          309,
          322,
          428,
          1065,
          3820,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4809,
        "id": 877,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4805,
        "temperature": 0,
        "text": " You can buy a GPU, but using a cloud computing service,",
        "tokens": [
          50564,
          509,
          393,
          2256,
          257,
          18407,
          11,
          457,
          1228,
          257,
          4588,
          15866,
          2643,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4812,
        "id": 878,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4809,
        "temperature": 0,
        "text": " which Spell is one of many options,",
        "tokens": [
          50764,
          597,
          3550,
          285,
          307,
          472,
          295,
          867,
          3956,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4816,
        "id": 879,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4812,
        "temperature": 0,
        "text": " and Spell just makes it super easy because you can just do it",
        "tokens": [
          50914,
          293,
          3550,
          285,
          445,
          1669,
          309,
          1687,
          1858,
          570,
          291,
          393,
          445,
          360,
          309,
          51114
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4819,
        "id": 880,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4816,
        "temperature": 0,
        "text": " with a command line interface right from your computer.",
        "tokens": [
          51114,
          365,
          257,
          5622,
          1622,
          9226,
          558,
          490,
          428,
          3820,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4821,
        "id": 881,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4820,
        "temperature": 0,
        "text": " There was another question.",
        "tokens": [
          51314,
          821,
          390,
          1071,
          1168,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4824,
        "id": 882,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4821,
        "temperature": 0,
        "text": " I don't know if you know the answer to this because I certainly don't.",
        "tokens": [
          51364,
          286,
          500,
          380,
          458,
          498,
          291,
          458,
          264,
          1867,
          281,
          341,
          570,
          286,
          3297,
          500,
          380,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4827,
        "id": 883,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4824,
        "temperature": 0,
        "text": " People who are curious, one thing that I've talked a little bit about",
        "tokens": [
          51514,
          3432,
          567,
          366,
          6369,
          11,
          472,
          551,
          300,
          286,
          600,
          2825,
          257,
          707,
          857,
          466,
          51664
        ]
      },
      {
        "avg_logprob": -0.2234815870012556,
        "compression_ratio": 1.6774193548387097,
        "end": 4830,
        "id": 884,
        "no_speech_prob": 0.00564137427136302,
        "seek": 480100,
        "start": 4827,
        "temperature": 0,
        "text": " in more beginner level machine learning tutorials",
        "tokens": [
          51664,
          294,
          544,
          22080,
          1496,
          3479,
          2539,
          17616,
          51814
        ]
      },
      {
        "avg_logprob": -0.22981046040852865,
        "compression_ratio": 1.5777777777777777,
        "end": 4832,
        "id": 885,
        "no_speech_prob": 0.0005192822427488863,
        "seek": 483000,
        "start": 4830,
        "temperature": 0,
        "text": " is the idea of a loss function.",
        "tokens": [
          50364,
          307,
          264,
          1558,
          295,
          257,
          4470,
          2445,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22981046040852865,
        "compression_ratio": 1.5777777777777777,
        "end": 4837,
        "id": 886,
        "no_speech_prob": 0.0005192822427488863,
        "seek": 483000,
        "start": 4832,
        "temperature": 0,
        "text": " Do you know how the style transfer training process works?",
        "tokens": [
          50464,
          1144,
          291,
          458,
          577,
          264,
          3758,
          5003,
          3097,
          1399,
          1985,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.22981046040852865,
        "compression_ratio": 1.5777777777777777,
        "end": 4840,
        "id": 887,
        "no_speech_prob": 0.0005192822427488863,
        "seek": 483000,
        "start": 4837,
        "temperature": 0,
        "text": " How does it figure out how well it's doing?",
        "tokens": [
          50714,
          1012,
          775,
          309,
          2573,
          484,
          577,
          731,
          309,
          311,
          884,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.22981046040852865,
        "compression_ratio": 1.5777777777777777,
        "end": 4847,
        "id": 888,
        "no_speech_prob": 0.0005192822427488863,
        "seek": 483000,
        "start": 4840,
        "temperature": 0,
        "text": " For fast style transfer, it has an image transformation network.",
        "tokens": [
          50864,
          1171,
          2370,
          3758,
          5003,
          11,
          309,
          575,
          364,
          3256,
          9887,
          3209,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22981046040852865,
        "compression_ratio": 1.5777777777777777,
        "end": 4851,
        "id": 889,
        "no_speech_prob": 0.0005192822427488863,
        "seek": 483000,
        "start": 4847,
        "temperature": 0,
        "text": " It also has a loss calculation network.",
        "tokens": [
          51214,
          467,
          611,
          575,
          257,
          4470,
          17108,
          3209,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22981046040852865,
        "compression_ratio": 1.5777777777777777,
        "end": 4857,
        "id": 890,
        "no_speech_prob": 0.0005192822427488863,
        "seek": 483000,
        "start": 4851,
        "temperature": 0,
        "text": " I think I need to check the paper in detail,",
        "tokens": [
          51414,
          286,
          519,
          286,
          643,
          281,
          1520,
          264,
          3035,
          294,
          2607,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4864,
        "id": 891,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4857,
        "temperature": 0,
        "text": " but it calculates the loss and then goes back to trying to minimize the loss function.",
        "tokens": [
          50364,
          457,
          309,
          4322,
          1024,
          264,
          4470,
          293,
          550,
          1709,
          646,
          281,
          1382,
          281,
          17522,
          264,
          4470,
          2445,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4865,
        "id": 892,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4864,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50714,
          3769,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4867,
        "id": 893,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4865,
        "temperature": 0,
        "text": " I think we can pretty much wrap up.",
        "tokens": [
          50764,
          286,
          519,
          321,
          393,
          1238,
          709,
          7019,
          493,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4868,
        "id": 894,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4867,
        "temperature": 0,
        "text": " This is amazing.",
        "tokens": [
          50864,
          639,
          307,
          2243,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4869,
        "id": 895,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4868,
        "temperature": 0,
        "text": " This was exactly what you said.",
        "tokens": [
          50914,
          639,
          390,
          2293,
          437,
          291,
          848,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4872,
        "id": 896,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4869,
        "temperature": 0,
        "text": " Yingning said, I think about an hour and 20 minutes,",
        "tokens": [
          50964,
          28125,
          773,
          848,
          11,
          286,
          519,
          466,
          364,
          1773,
          293,
          945,
          2077,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4874,
        "id": 897,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4872,
        "temperature": 0,
        "text": " and it's exactly an hour and 20 minutes.",
        "tokens": [
          51114,
          293,
          309,
          311,
          2293,
          364,
          1773,
          293,
          945,
          2077,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4876,
        "id": 898,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4874,
        "temperature": 0,
        "text": " Here's what I want.",
        "tokens": [
          51214,
          1692,
          311,
          437,
          286,
          528,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4881,
        "id": 899,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4876,
        "temperature": 0,
        "text": " I'm really curious and excited to see how replicable this is for you.",
        "tokens": [
          51314,
          286,
          478,
          534,
          6369,
          293,
          2919,
          281,
          536,
          577,
          3248,
          43023,
          341,
          307,
          337,
          291,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22045045471191407,
        "compression_ratio": 1.6742424242424243,
        "end": 4886,
        "id": 900,
        "no_speech_prob": 0.006903546862304211,
        "seek": 485700,
        "start": 4881,
        "temperature": 0,
        "text": " If you are following this tutorial, can you sign up for your own Spell account?",
        "tokens": [
          51564,
          759,
          291,
          366,
          3480,
          341,
          7073,
          11,
          393,
          291,
          1465,
          493,
          337,
          428,
          1065,
          3550,
          285,
          2696,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4888,
        "id": 901,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4886,
        "temperature": 0,
        "text": " You can go to spell.run coding train.",
        "tokens": [
          50364,
          509,
          393,
          352,
          281,
          9827,
          13,
          12997,
          17720,
          3847,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4891,
        "id": 902,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4888,
        "temperature": 0,
        "text": " Can you clone this Python code?",
        "tokens": [
          50464,
          1664,
          291,
          26506,
          341,
          15329,
          3089,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4893,
        "id": 903,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4891,
        "temperature": 0,
        "text": " Can you pick your own style image?",
        "tokens": [
          50614,
          1664,
          291,
          1888,
          428,
          1065,
          3758,
          3256,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4899,
        "id": 904,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4893,
        "temperature": 0,
        "text": " Can you then run it with ml5 and your webcam and style your own face,",
        "tokens": [
          50714,
          1664,
          291,
          550,
          1190,
          309,
          365,
          23271,
          20,
          293,
          428,
          39490,
          293,
          3758,
          428,
          1065,
          1851,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4900,
        "id": 905,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4899,
        "temperature": 0,
        "text": " the image from the webcam?",
        "tokens": [
          51014,
          264,
          3256,
          490,
          264,
          39490,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4903,
        "id": 906,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4900,
        "temperature": 0,
        "text": " If you are able to follow this and do this, share.",
        "tokens": [
          51064,
          759,
          291,
          366,
          1075,
          281,
          1524,
          341,
          293,
          360,
          341,
          11,
          2073,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4907,
        "id": 907,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4903,
        "temperature": 0,
        "text": " This was suggested in the Coding Train Slack channel,",
        "tokens": [
          51214,
          639,
          390,
          10945,
          294,
          264,
          383,
          8616,
          28029,
          37211,
          2269,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4909,
        "id": 908,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4907,
        "temperature": 0,
        "text": " which is a Slack channel for patrons or members.",
        "tokens": [
          51414,
          597,
          307,
          257,
          37211,
          2269,
          337,
          27559,
          420,
          2679,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4913,
        "id": 909,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4909,
        "temperature": 0,
        "text": " It was suggested to use the hashtag this.style.",
        "tokens": [
          51514,
          467,
          390,
          10945,
          281,
          764,
          264,
          20379,
          341,
          13,
          15014,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22024976906656218,
        "compression_ratio": 1.7811158798283262,
        "end": 4914,
        "id": 910,
        "no_speech_prob": 0.09944095462560654,
        "seek": 488600,
        "start": 4913,
        "temperature": 0,
        "text": " This.style.",
        "tokens": [
          51714,
          639,
          13,
          15014,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4916,
        "id": 911,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4914,
        "temperature": 0,
        "text": " This dot is the joke.",
        "tokens": [
          50364,
          639,
          5893,
          307,
          264,
          7647,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4920,
        "id": 912,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4916,
        "temperature": 0,
        "text": " By the way, people were commenting that you were forgetting your semicolons,",
        "tokens": [
          50464,
          3146,
          264,
          636,
          11,
          561,
          645,
          29590,
          300,
          291,
          645,
          25428,
          428,
          27515,
          401,
          892,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4922,
        "id": 913,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4920,
        "temperature": 0,
        "text": " which you don't actually need.",
        "tokens": [
          50664,
          597,
          291,
          500,
          380,
          767,
          643,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4923,
        "id": 914,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4922,
        "temperature": 0,
        "text": " It's just funny.",
        "tokens": [
          50764,
          467,
          311,
          445,
          4074,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4926,
        "id": 915,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4923,
        "temperature": 0,
        "text": " This dot is the thing that I always forget.",
        "tokens": [
          50814,
          639,
          5893,
          307,
          264,
          551,
          300,
          286,
          1009,
          2870,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4932,
        "id": 916,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4926,
        "temperature": 0,
        "text": " Actually, I use semicolons all the time until one of my colleagues said,",
        "tokens": [
          50964,
          5135,
          11,
          286,
          764,
          27515,
          401,
          892,
          439,
          264,
          565,
          1826,
          472,
          295,
          452,
          7734,
          848,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4934,
        "id": 917,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4932,
        "temperature": 0,
        "text": " oh, you shouldn't use that.",
        "tokens": [
          51264,
          1954,
          11,
          291,
          4659,
          380,
          764,
          300,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4936,
        "id": 918,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4934,
        "temperature": 0,
        "text": " It's not clear.",
        "tokens": [
          51364,
          467,
          311,
          406,
          1850,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4940,
        "id": 919,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4936,
        "temperature": 0,
        "text": " Then I switched to not using semicolons, but I'm good with both.",
        "tokens": [
          51464,
          1396,
          286,
          16858,
          281,
          406,
          1228,
          27515,
          401,
          892,
          11,
          457,
          286,
          478,
          665,
          365,
          1293,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2185515306127353,
        "compression_ratio": 1.7431906614785992,
        "end": 4943,
        "id": 920,
        "no_speech_prob": 0.05664100497961044,
        "seek": 491400,
        "start": 4940,
        "temperature": 0,
        "text": " We could be here for the next three hours discussing whether you should use",
        "tokens": [
          51664,
          492,
          727,
          312,
          510,
          337,
          264,
          958,
          1045,
          2496,
          10850,
          1968,
          291,
          820,
          764,
          51814
        ]
      },
      {
        "avg_logprob": -0.2229436103333818,
        "compression_ratio": 1.5963302752293578,
        "end": 4945,
        "id": 921,
        "no_speech_prob": 0.049584660679101944,
        "seek": 494300,
        "start": 4943,
        "temperature": 0,
        "text": " semicolons or not.",
        "tokens": [
          50364,
          27515,
          401,
          892,
          420,
          406,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2229436103333818,
        "compression_ratio": 1.5963302752293578,
        "end": 4950,
        "id": 922,
        "no_speech_prob": 0.049584660679101944,
        "seek": 494300,
        "start": 4945,
        "temperature": 0,
        "text": " This.style, you can share things you make on Twitter with that hashtag,",
        "tokens": [
          50464,
          639,
          13,
          15014,
          11,
          291,
          393,
          2073,
          721,
          291,
          652,
          322,
          5794,
          365,
          300,
          20379,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.2229436103333818,
        "compression_ratio": 1.5963302752293578,
        "end": 4952,
        "id": 923,
        "no_speech_prob": 0.049584660679101944,
        "seek": 494300,
        "start": 4950,
        "temperature": 0,
        "text": " whatever social media you use.",
        "tokens": [
          50714,
          2035,
          2093,
          3021,
          291,
          764,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2229436103333818,
        "compression_ratio": 1.5963302752293578,
        "end": 4956,
        "id": 924,
        "no_speech_prob": 0.049584660679101944,
        "seek": 494300,
        "start": 4952,
        "temperature": 0,
        "text": " There will be a comments section here once this video is archived.",
        "tokens": [
          50814,
          821,
          486,
          312,
          257,
          3053,
          3541,
          510,
          1564,
          341,
          960,
          307,
          3912,
          3194,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2229436103333818,
        "compression_ratio": 1.5963302752293578,
        "end": 4963,
        "id": 925,
        "no_speech_prob": 0.049584660679101944,
        "seek": 494300,
        "start": 4956,
        "temperature": 0,
        "text": " Then, in addition, I will hopefully create a page on the codingtrain.com,",
        "tokens": [
          51014,
          1396,
          11,
          294,
          4500,
          11,
          286,
          486,
          4696,
          1884,
          257,
          3028,
          322,
          264,
          17720,
          83,
          7146,
          13,
          1112,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2229436103333818,
        "compression_ratio": 1.5963302752293578,
        "end": 4969,
        "id": 926,
        "no_speech_prob": 0.049584660679101944,
        "seek": 494300,
        "start": 4963,
        "temperature": 0,
        "text": " which we'll link to with all the links and everything that Yuning has shown you here.",
        "tokens": [
          51364,
          597,
          321,
          603,
          2113,
          281,
          365,
          439,
          264,
          6123,
          293,
          1203,
          300,
          18007,
          278,
          575,
          4898,
          291,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4972,
        "id": 927,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4969,
        "temperature": 0,
        "text": " All of those links, like the links of all the resources and all the artists",
        "tokens": [
          50364,
          1057,
          295,
          729,
          6123,
          11,
          411,
          264,
          6123,
          295,
          439,
          264,
          3593,
          293,
          439,
          264,
          6910,
          50514
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4977,
        "id": 928,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4972,
        "temperature": 0,
        "text": " and different things you showed, I'll update the video description for this archive,",
        "tokens": [
          50514,
          293,
          819,
          721,
          291,
          4712,
          11,
          286,
          603,
          5623,
          264,
          960,
          3855,
          337,
          341,
          23507,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4981,
        "id": 929,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4977,
        "temperature": 0,
        "text": " for the archived version of this live stream right afterwards as well.",
        "tokens": [
          50764,
          337,
          264,
          3912,
          3194,
          3037,
          295,
          341,
          1621,
          4309,
          558,
          10543,
          382,
          731,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4984,
        "id": 930,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4981,
        "temperature": 0,
        "text": " This.style, yay stream, links at the start of the stream.",
        "tokens": [
          50964,
          639,
          13,
          15014,
          11,
          23986,
          4309,
          11,
          6123,
          412,
          264,
          722,
          295,
          264,
          4309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4987,
        "id": 931,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4984,
        "temperature": 0,
        "text": " Okay, I'm just looking to see if there's any urgent burning questions.",
        "tokens": [
          51114,
          1033,
          11,
          286,
          478,
          445,
          1237,
          281,
          536,
          498,
          456,
          311,
          604,
          19022,
          9488,
          1651,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4989,
        "id": 932,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4987,
        "temperature": 0,
        "text": " I have to come back here.",
        "tokens": [
          51264,
          286,
          362,
          281,
          808,
          646,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.27300201762806287,
        "compression_ratio": 1.6811023622047243,
        "end": 4993,
        "id": 933,
        "no_speech_prob": 0.021284319460392,
        "seek": 496900,
        "start": 4989,
        "temperature": 0,
        "text": " We can wave goodbye from our This.style.",
        "tokens": [
          51364,
          492,
          393,
          5772,
          12084,
          490,
          527,
          639,
          13,
          15014,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2658524513244629,
        "compression_ratio": 1.3567251461988303,
        "end": 4999,
        "id": 934,
        "no_speech_prob": 0.03732137382030487,
        "seek": 499300,
        "start": 4993,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2658524513244629,
        "compression_ratio": 1.3567251461988303,
        "end": 5003,
        "id": 935,
        "no_speech_prob": 0.03732137382030487,
        "seek": 499300,
        "start": 4999,
        "temperature": 0,
        "text": " Then, the only way – oh, get the slides.",
        "tokens": [
          50664,
          1396,
          11,
          264,
          787,
          636,
          1662,
          1954,
          11,
          483,
          264,
          9788,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2658524513244629,
        "compression_ratio": 1.3567251461988303,
        "end": 5007,
        "id": 936,
        "no_speech_prob": 0.03732137382030487,
        "seek": 499300,
        "start": 5003,
        "temperature": 0,
        "text": " Whatever material that Yuning used that we can publish, we will certainly publish.",
        "tokens": [
          50864,
          8541,
          2527,
          300,
          18007,
          278,
          1143,
          300,
          321,
          393,
          11374,
          11,
          321,
          486,
          3297,
          11374,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2658524513244629,
        "compression_ratio": 1.3567251461988303,
        "end": 5011,
        "id": 937,
        "no_speech_prob": 0.03732137382030487,
        "seek": 499300,
        "start": 5007,
        "temperature": 0,
        "text": " We'll share the slides as well.",
        "tokens": [
          51064,
          492,
          603,
          2073,
          264,
          9788,
          382,
          731,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2658524513244629,
        "compression_ratio": 1.3567251461988303,
        "end": 5014,
        "id": 938,
        "no_speech_prob": 0.03732137382030487,
        "seek": 499300,
        "start": 5011,
        "temperature": 0,
        "text": " Also, I want to mention – is it okay if I go to your browser here?",
        "tokens": [
          51264,
          2743,
          11,
          286,
          528,
          281,
          2152,
          1662,
          307,
          309,
          1392,
          498,
          286,
          352,
          281,
          428,
          11185,
          510,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5024,
        "id": 939,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5014,
        "temperature": 0,
        "text": " If I go to YouTube slash Coding Train, and hopefully this is going to –",
        "tokens": [
          50364,
          759,
          286,
          352,
          281,
          3088,
          17330,
          383,
          8616,
          28029,
          11,
          293,
          4696,
          341,
          307,
          516,
          281,
          1662,
          50864
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5026,
        "id": 940,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5024,
        "temperature": 0,
        "text": " Oh, you can close this.",
        "tokens": [
          50864,
          876,
          11,
          291,
          393,
          1998,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5028,
        "id": 941,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5026,
        "temperature": 0,
        "text": " Oh, it's like – but I don't want to close it.",
        "tokens": [
          50964,
          876,
          11,
          309,
          311,
          411,
          1662,
          457,
          286,
          500,
          380,
          528,
          281,
          1998,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5029,
        "id": 942,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5028,
        "temperature": 0,
        "text": " It's so wonderful.",
        "tokens": [
          51064,
          467,
          311,
          370,
          3715,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5031,
        "id": 943,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5029,
        "temperature": 0,
        "text": " Okay, I'll close it.",
        "tokens": [
          51114,
          1033,
          11,
          286,
          603,
          1998,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5032,
        "id": 944,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5031,
        "temperature": 0,
        "text": " I'm going to go down here.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          352,
          760,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5040,
        "id": 945,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5032,
        "temperature": 0,
        "text": " You can see that NextUp scheduled for October 5th.",
        "tokens": [
          51264,
          509,
          393,
          536,
          300,
          3087,
          22164,
          15678,
          337,
          7617,
          1025,
          392,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5042,
        "id": 946,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5040,
        "temperature": 0,
        "text": " I think –",
        "tokens": [
          51664,
          286,
          519,
          1662,
          51764
        ]
      },
      {
        "avg_logprob": -0.2819144821166992,
        "compression_ratio": 1.4313725490196079,
        "end": 5043,
        "id": 947,
        "no_speech_prob": 0.3104386329650879,
        "seek": 501400,
        "start": 5042,
        "temperature": 0,
        "text": " I can't hear it.",
        "tokens": [
          51764,
          286,
          393,
          380,
          1568,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20361672234289424,
        "compression_ratio": 1.4655172413793103,
        "end": 5044,
        "id": 948,
        "no_speech_prob": 0.12939393520355225,
        "seek": 504300,
        "start": 5043,
        "temperature": 0,
        "text": " Oh, it's okay.",
        "tokens": [
          50364,
          876,
          11,
          309,
          311,
          1392,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20361672234289424,
        "compression_ratio": 1.4655172413793103,
        "end": 5046,
        "id": 949,
        "no_speech_prob": 0.12939393520355225,
        "seek": 504300,
        "start": 5044,
        "temperature": 0,
        "text": " I'm so used to doing this.",
        "tokens": [
          50414,
          286,
          478,
          370,
          1143,
          281,
          884,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20361672234289424,
        "compression_ratio": 1.4655172413793103,
        "end": 5055,
        "id": 950,
        "no_speech_prob": 0.12939393520355225,
        "seek": 504300,
        "start": 5046,
        "temperature": 0,
        "text": " With all the same elements, ml5, spell, and TensorFlow to train something called an LSTM,",
        "tokens": [
          50514,
          2022,
          439,
          264,
          912,
          4959,
          11,
          23271,
          20,
          11,
          9827,
          11,
          293,
          37624,
          281,
          3847,
          746,
          1219,
          364,
          441,
          6840,
          44,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20361672234289424,
        "compression_ratio": 1.4655172413793103,
        "end": 5058,
        "id": 951,
        "no_speech_prob": 0.12939393520355225,
        "seek": 504300,
        "start": 5055,
        "temperature": 0,
        "text": " which is a long, short-term memory network.",
        "tokens": [
          50964,
          597,
          307,
          257,
          938,
          11,
          2099,
          12,
          7039,
          4675,
          3209,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20361672234289424,
        "compression_ratio": 1.4655172413793103,
        "end": 5062,
        "id": 952,
        "no_speech_prob": 0.12939393520355225,
        "seek": 504300,
        "start": 5058,
        "temperature": 0,
        "text": " This is a kind of neural network that's well-suited for sequences.",
        "tokens": [
          51114,
          639,
          307,
          257,
          733,
          295,
          18161,
          3209,
          300,
          311,
          731,
          12,
          15091,
          1226,
          337,
          22978,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20361672234289424,
        "compression_ratio": 1.4655172413793103,
        "end": 5069,
        "id": 953,
        "no_speech_prob": 0.12939393520355225,
        "seek": 504300,
        "start": 5062,
        "temperature": 0,
        "text": " So if you wanted to train a model to learn about how characters appear next to each other in text",
        "tokens": [
          51314,
          407,
          498,
          291,
          1415,
          281,
          3847,
          257,
          2316,
          281,
          1466,
          466,
          577,
          4342,
          4204,
          958,
          281,
          1184,
          661,
          294,
          2487,
          51664
        ]
      },
      {
        "avg_logprob": -0.21808071311460722,
        "compression_ratio": 1.691449814126394,
        "end": 5076,
        "id": 954,
        "no_speech_prob": 0.2909196615219116,
        "seek": 506900,
        "start": 5069,
        "temperature": 0,
        "text": " or musical notes appear next to each other in a song or how strokes appear in sequence in a drawing,",
        "tokens": [
          50364,
          420,
          9165,
          5570,
          4204,
          958,
          281,
          1184,
          661,
          294,
          257,
          2153,
          420,
          577,
          24493,
          4204,
          294,
          8310,
          294,
          257,
          6316,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.21808071311460722,
        "compression_ratio": 1.691449814126394,
        "end": 5078,
        "id": 955,
        "no_speech_prob": 0.2909196615219116,
        "seek": 506900,
        "start": 5076,
        "temperature": 0,
        "text": " there's something called Sketch RNN.",
        "tokens": [
          50714,
          456,
          311,
          746,
          1219,
          49245,
          45702,
          45,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21808071311460722,
        "compression_ratio": 1.691449814126394,
        "end": 5081,
        "id": 956,
        "no_speech_prob": 0.2909196615219116,
        "seek": 506900,
        "start": 5078,
        "temperature": 0,
        "text": " There's so many possibilities, but we're going to, in that live stream,",
        "tokens": [
          50814,
          821,
          311,
          370,
          867,
          12178,
          11,
          457,
          321,
          434,
          516,
          281,
          11,
          294,
          300,
          1621,
          4309,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.21808071311460722,
        "compression_ratio": 1.691449814126394,
        "end": 5085,
        "id": 957,
        "no_speech_prob": 0.2909196615219116,
        "seek": 506900,
        "start": 5081,
        "temperature": 0,
        "text": " be able to show you how to take a text from your favorite author",
        "tokens": [
          50964,
          312,
          1075,
          281,
          855,
          291,
          577,
          281,
          747,
          257,
          2487,
          490,
          428,
          2954,
          3793,
          51164
        ]
      },
      {
        "avg_logprob": -0.21808071311460722,
        "compression_ratio": 1.691449814126394,
        "end": 5089,
        "id": 958,
        "no_speech_prob": 0.2909196615219116,
        "seek": 506900,
        "start": 5085,
        "temperature": 0,
        "text": " and train a machine learning model on spell.run cloud computing service",
        "tokens": [
          51164,
          293,
          3847,
          257,
          3479,
          2539,
          2316,
          322,
          9827,
          13,
          12997,
          4588,
          15866,
          2643,
          51364
        ]
      },
      {
        "avg_logprob": -0.21808071311460722,
        "compression_ratio": 1.691449814126394,
        "end": 5097,
        "id": 959,
        "no_speech_prob": 0.2909196615219116,
        "seek": 506900,
        "start": 5089,
        "temperature": 0,
        "text": " to download that model and then have the model generate new text in the style of that author in the browser.",
        "tokens": [
          51364,
          281,
          5484,
          300,
          2316,
          293,
          550,
          362,
          264,
          2316,
          8460,
          777,
          2487,
          294,
          264,
          3758,
          295,
          300,
          3793,
          294,
          264,
          11185,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5100,
        "id": 960,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5097,
        "temperature": 0,
        "text": " So that's coming two weeks from today at a slightly earlier time.",
        "tokens": [
          50364,
          407,
          300,
          311,
          1348,
          732,
          3259,
          490,
          965,
          412,
          257,
          4748,
          3071,
          565,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5102,
        "id": 961,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5100,
        "temperature": 0,
        "text": " And next Friday I'll be back.",
        "tokens": [
          50514,
          400,
          958,
          6984,
          286,
          603,
          312,
          646,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5105,
        "id": 962,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5102,
        "temperature": 0,
        "text": " I have this very long list of things I need to get to.",
        "tokens": [
          50614,
          286,
          362,
          341,
          588,
          938,
          1329,
          295,
          721,
          286,
          643,
          281,
          483,
          281,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5107,
        "id": 963,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5105,
        "temperature": 0,
        "text": " So I don't know what I'm going to do next Friday yet.",
        "tokens": [
          50764,
          407,
          286,
          500,
          380,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          958,
          6984,
          1939,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5110,
        "id": 964,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5107,
        "temperature": 0,
        "text": " I'm trying to schedule stuff better in advance.",
        "tokens": [
          50864,
          286,
          478,
          1382,
          281,
          7567,
          1507,
          1101,
          294,
          7295,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5112,
        "id": 965,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5110,
        "temperature": 0,
        "text": " And, yeah, so stay tuned.",
        "tokens": [
          51014,
          400,
          11,
          1338,
          11,
          370,
          1754,
          10870,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5115,
        "id": 966,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5112,
        "temperature": 0,
        "text": " Oh, I know I forgot something.",
        "tokens": [
          51114,
          876,
          11,
          286,
          458,
          286,
          5298,
          746,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5119,
        "id": 967,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5115,
        "temperature": 0,
        "text": " If certain things that you couldn't follow today, I want to mention that would be helpful to you.",
        "tokens": [
          51264,
          759,
          1629,
          721,
          300,
          291,
          2809,
          380,
          1524,
          965,
          11,
          286,
          528,
          281,
          2152,
          300,
          576,
          312,
          4961,
          281,
          291,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5124,
        "id": 968,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5119,
        "temperature": 0,
        "text": " I recently did a whole set of workflow videos, and Yingning pretty much is using the exact same stuff,",
        "tokens": [
          51464,
          286,
          3938,
          630,
          257,
          1379,
          992,
          295,
          20993,
          2145,
          11,
          293,
          28125,
          773,
          1238,
          709,
          307,
          1228,
          264,
          1900,
          912,
          1507,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.1936624413294508,
        "compression_ratio": 1.6456456456456456,
        "end": 5126,
        "id": 969,
        "no_speech_prob": 0.11915609985589981,
        "seek": 509700,
        "start": 5124,
        "temperature": 0,
        "text": " just sort of coincidentally, I guess.",
        "tokens": [
          51714,
          445,
          1333,
          295,
          13001,
          36578,
          11,
          286,
          2041,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5131,
        "id": 970,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5126,
        "temperature": 0,
        "text": " So running Git, using Visual Studio Code, running stuff from your terminal,",
        "tokens": [
          50364,
          407,
          2614,
          16939,
          11,
          1228,
          23187,
          13500,
          15549,
          11,
          2614,
          1507,
          490,
          428,
          14709,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5134,
        "id": 971,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5131,
        "temperature": 0,
        "text": " and then I also have a whole intro to spell video.",
        "tokens": [
          50614,
          293,
          550,
          286,
          611,
          362,
          257,
          1379,
          12897,
          281,
          9827,
          960,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5136,
        "id": 972,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5134,
        "temperature": 0,
        "text": " So a lot of the stuff of, like, how do I install spell again?",
        "tokens": [
          50764,
          407,
          257,
          688,
          295,
          264,
          1507,
          295,
          11,
          411,
          11,
          577,
          360,
          286,
          3625,
          9827,
          797,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5138,
        "id": 973,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5136,
        "temperature": 0,
        "text": " What does it do? Where do I sign up?",
        "tokens": [
          50864,
          708,
          775,
          309,
          360,
          30,
          2305,
          360,
          286,
          1465,
          493,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5141,
        "id": 974,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5138,
        "temperature": 0,
        "text": " You can find that in the intro to spell video as well.",
        "tokens": [
          50964,
          509,
          393,
          915,
          300,
          294,
          264,
          12897,
          281,
          9827,
          960,
          382,
          731,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5142,
        "id": 975,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5141,
        "temperature": 0,
        "text": " So I'll link to all that stuff.",
        "tokens": [
          51114,
          407,
          286,
          603,
          2113,
          281,
          439,
          300,
          1507,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5146,
        "id": 976,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5142,
        "temperature": 0,
        "text": " If there's a moderator in the chat who can link to some of those things right now, great.",
        "tokens": [
          51164,
          759,
          456,
          311,
          257,
          37778,
          294,
          264,
          5081,
          567,
          393,
          2113,
          281,
          512,
          295,
          729,
          721,
          558,
          586,
          11,
          869,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5148,
        "id": 977,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5146,
        "temperature": 0,
        "text": " But I'm going to go.",
        "tokens": [
          51364,
          583,
          286,
          478,
          516,
          281,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.217763180202908,
        "compression_ratio": 1.6714285714285715,
        "end": 5153,
        "id": 978,
        "no_speech_prob": 0.0024725792463868856,
        "seek": 512600,
        "start": 5148,
        "temperature": 0,
        "text": " This is the awkward part because I've yet...",
        "tokens": [
          51464,
          639,
          307,
          264,
          11411,
          644,
          570,
          286,
          600,
          1939,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5156,
        "id": 979,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5153,
        "temperature": 0,
        "text": " CJ, Coding Garden with CJ has another wonderful YouTube channel.",
        "tokens": [
          50364,
          42285,
          11,
          383,
          8616,
          19429,
          365,
          42285,
          575,
          1071,
          3715,
          3088,
          2269,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5161,
        "id": 980,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5156,
        "temperature": 0,
        "text": " CJ was here doing a guest spot and showed me all these things that you can do in Open Broadcast Studio.",
        "tokens": [
          50514,
          42285,
          390,
          510,
          884,
          257,
          8341,
          4008,
          293,
          4712,
          385,
          439,
          613,
          721,
          300,
          291,
          393,
          360,
          294,
          7238,
          14074,
          3734,
          13500,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5165,
        "id": 981,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5161,
        "temperature": 0,
        "text": " Like I could just press a button and then an outro video would play, but I don't have that.",
        "tokens": [
          50764,
          1743,
          286,
          727,
          445,
          1886,
          257,
          2960,
          293,
          550,
          364,
          13170,
          960,
          576,
          862,
          11,
          457,
          286,
          500,
          380,
          362,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5167,
        "id": 982,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5165,
        "temperature": 0,
        "text": " So we just have to walk awkwardly to the side.",
        "tokens": [
          50964,
          407,
          321,
          445,
          362,
          281,
          1792,
          11411,
          356,
          281,
          264,
          1252,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5169,
        "id": 983,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5167,
        "temperature": 0,
        "text": " I have to turn the stream off over here on a laptop.",
        "tokens": [
          51064,
          286,
          362,
          281,
          1261,
          264,
          4309,
          766,
          670,
          510,
          322,
          257,
          10732,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5171,
        "id": 984,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5169,
        "temperature": 0,
        "text": " Thank you for watching. Bye-bye.",
        "tokens": [
          51164,
          1044,
          291,
          337,
          1976,
          13,
          4621,
          12,
          6650,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5173,
        "id": 985,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5171,
        "temperature": 0,
        "text": " Thank you, everyone.",
        "tokens": [
          51264,
          1044,
          291,
          11,
          1518,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5178,
        "id": 986,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5173,
        "temperature": 0,
        "text": " I look forward to hearing from you in the comments and on Twitter and all the other various places.",
        "tokens": [
          51364,
          286,
          574,
          2128,
          281,
          4763,
          490,
          291,
          294,
          264,
          3053,
          293,
          322,
          5794,
          293,
          439,
          264,
          661,
          3683,
          3190,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5179,
        "id": 987,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5178,
        "temperature": 0,
        "text": " Bye. Thank you.",
        "tokens": [
          51614,
          4621,
          13,
          1044,
          291,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5180,
        "id": 988,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5179,
        "temperature": 0,
        "text": " Thank you to Spell.",
        "tokens": [
          51664,
          1044,
          291,
          281,
          3550,
          285,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19571605729468075,
        "compression_ratio": 1.69364161849711,
        "end": 5182,
        "id": 989,
        "no_speech_prob": 0.31476595997810364,
        "seek": 515300,
        "start": 5180,
        "temperature": 0,
        "text": " Thank you to White Coat Captioning.",
        "tokens": [
          51714,
          1044,
          291,
          281,
          5552,
          3066,
          267,
          9480,
          313,
          278,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.28467149204678005,
        "compression_ratio": 1.1521739130434783,
        "end": 5184,
        "id": 990,
        "no_speech_prob": 0.5483502745628357,
        "seek": 518200,
        "start": 5182,
        "temperature": 0,
        "text": " And thank you especially to Yaning.",
        "tokens": [
          50364,
          400,
          1309,
          291,
          2318,
          281,
          13633,
          278,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.28467149204678005,
        "compression_ratio": 1.1521739130434783,
        "end": 5185,
        "id": 991,
        "no_speech_prob": 0.5483502745628357,
        "seek": 518200,
        "start": 5184,
        "temperature": 0,
        "text": " Thank you, Dan.",
        "tokens": [
          50464,
          1044,
          291,
          11,
          3394,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.28467149204678005,
        "compression_ratio": 1.1521739130434783,
        "end": 5188,
        "id": 992,
        "no_speech_prob": 0.5483502745628357,
        "seek": 518200,
        "start": 5185,
        "temperature": 0,
        "text": " I can't find the page. Stop. I got it. Stop streaming.",
        "tokens": [
          50514,
          286,
          393,
          380,
          915,
          264,
          3028,
          13,
          5535,
          13,
          286,
          658,
          309,
          13,
          5535,
          11791,
          13,
          50664
        ]
      }
    ],
    "transcription": " They can hear anything you say. Which I'm going to do. Hello, we're here. The chat is very small, so I just want to see a few messages from the chat that's like, I see you, things are working, I can hear you, because half the time I set up my mic incorrectly. Welcome to the special Friday Coding Train episode. My name is Dan Shiffman. There's a lot of things that are special and different and exciting about this episode. I still don't see anybody saying anything in the chat. Oh, somebody said hi. Okay, so I'm going to take that as things are working. So today is a special episode. There's a few things about this episode that are special. Number one, we're going to do a machine learning project from start to finish. Training a model entirely in the cloud, getting that trained model back, and then implementing that model in the browser using JavaScript. So all of those pieces, that's going to happen, and the whole thing is going to take maybe an hour and a half. To present all this to you, we have a guest. Yining Shi, you might remember her from the Coding Train brick breaker tutorial that she made. I will link to Yining as an artist and a researcher. She's a core contributor to the ML5 library, which is a machine learning library that will be used as part of this tutorial. She's contributed to the P5.js library, which will also be used as part of this tutorial. She wrote the whole style transfer module of ML5, which, so basically that's what she's going to do and present here. So Yining will be here in a minute after I do my long-winded introduction. The other thing I want to mention is this video is sponsored by Spell. Spell is a cloud computing for machine learning service. I did an entire introduction to Spell, how to set it up, what it does, what are the basic commands. If you're watching this as an archive, you might want to go back and watch that first and then return. But if you're watching this live, and you haven't seen that, we'll try to help you along and get you set up with that. If you want to sign up for an account to follow along, you can get $100 in free GPU credits, which should be enough to train your style transfer model, I think. You can go to spell.run slash coding train. Spell.run slash coding train. Okay, and also, thank you to Spell. If I think, somebody tell me, turn on those closed captioning. For the first time, I am using real-time human written captions generated by a company called White Coat Captioning. So YouTube has automated captions for live streaming, which I've used before, but these are actually being typed by a professional captioner in real-time as I'm speaking, I think. This reminds me of the kids' book, The Elephant and Piggy Book by Mo Willems. It's like, you are in a book, and the characters realize they can make the reader of the book say anything they want. I can make the captioner type, blueberry, mango, watermelon, right? Those words should be appearing under me right now, I think. Okay, sorry, I'm off track. So thank you so much to Spell.run for the sponsorship. Thank you to Yining for being here. Thank you to White Coat Captioning for the captioning services and for Spell providing the funds for those. And then I'm going to be off to the side looking at the YouTube chat. So you can ask questions, I will take them down, I'll try to answer them. Other people in the chat, I'm sure, will be helpful. Mostly, we're going to save questions to the end. But if there's a sort of important key question, I might interrupt and ask that. Ah, one other thing. Yining will probably tell you about this, but I can't resist. To train a style transfer model, even in the cloud on a GPU computer, and we'll cover what that stuff means, it takes a very long time. So we're employing a cooking show-like mechanic here. We'll start the training process, but then have the pre-trained model in the oven already fully baked to bring out and show you how it works. But if you watch today, if you follow this tutorial, you will be able to train your own style transfer machine learning model in the cloud using Spell.run. And then implement that model in the browser, styling your own images. Okay. So I'm just looking at the chat. Oh, so I think that's everything. That's all my introductory stuff, yes? So I am just going to transfer it over to Yining. I'm going to mute my microphone, and then I will unmute it every once in a while if I have something really important to say. And of course, you can ask me a question if you need to. And we'll just get started. Okay? Great. Thank you so much, Dan. Thank you. Hi, everyone. My name is Yining, and I'm very excited to be here today to talk about style transfer. Thank you, Dan, for inviting me here. And I also want to thank everyone for watching this video. I hope you enjoy this video. Should we get started? Yeah, go for it. Okay. So today, we're going to talk about style transfer. We're going to do four things today. We're going to talk about what is style transfer, how does it work, and we're going to train a style transfer model with Spell. And we're also going to port the model into ML5.js to create an interactive demo. Spell and ML5.js are both tools that make machine learning more approachable for a broad range of audience. For our project today, ML5.js allows us to run our model in the browser. By the way, ML5.js is a JavaScript library based on TensorFlow.js. So our model that we got today will also work in the TensorFlow.js. And Spell provides the computing power for us to train this model faster. If I train this model on my own laptop, it might take a few days. But with the remote GPU provided by Spell, it will only take a few hours. Let me show you what we're going to build today at the end of this video. This is the demo. You can also see the demo at enington23.github.io. So this demo reads the image from our webcam and transfers the image style into this art. This painting is a Chinese ancient painting. It's called Fushi Shanjitu. The style is kind of subtle. It doesn't have too many colors. But if you train the model with a really colorful and has really obvious style, if you use those kind of style image, you will get a more obvious result. But this is the demo that we're going to build today. Okay. So before we build anything, let's talk about what is style transfer. Style transfer is the technique of free cast the content of one image in the style of another image. For example, here is a photo here. And here is artistic. This is artwork here. And this technique can extract the content from this photo and also get the style from this artwork and then combine those two together to create this new image. And here are two more examples. So how does the style transfer work? Style transfer was first introduced in the paper, A Neural Algorithm of Artistic Style by Gattis in 2015. In the paper, they proposed a system that uses convolutional neural network to separate and then recombine the content and style of arbitrary images. By the way, convolutional neural network is a deep feedforward neural network mostly used to analyze images. The idea is to, if we take this convolutional neural network here, that is trained to recognize objects on those images, then this network has already developed some internal representation of the content and the style of this image. And more importantly, this paper finds out the content representation and the style representation of an image can be separated, which means we can take the content representation of one image and the style representation from another image to generate a brand new image. The convolutional neural network that Gattis used is called VGG. It's a neural network created by Visual Geometry Group at Oxford University. This convolutional neural network is the winner of ImageNet and Object Recognition Challenge in 2014. So we will see the name of VGG again when we are training this model because we need to use this convolutional neural network to get the representation out from our images. So next, let's talk about the convolutional neural network. It works like filters on different layers of this network. There are different representations of these images. For example, if this is the input image, this photo here, this photo can be represented by all those filtered images at each level. So for content representation, which is at the bottom of this image, we can visualize the information at different layers in this network by recreating the input image from one of those filtered images. And we can see image A, B, C, D, E here. From the lower level, we can see image A, B, C. They are almost perfect. Those recreated images, they're almost perfect. But as the level gets higher and higher, all those detailed pixel information is lost. But the high level content of this image is still here. For example, for this image E here. Even though we cannot see it clearly, but we can see, oh, there is a house on this image. So this is how content representation looks like in this network. And next, we're going to talk about style representation. So on top of this convolutional neural network, Gattis, they built a brand new feature space that captured the style of the input image. The style representation computes correlation between different features in different layers of this network. For detailed implementation, we can check the paper. But basically, as the level getting higher and higher, we find the recreated style image can match the style of this artwork better and better. But the information of the global arrangement of the scene is lost. For example, for this image D and E, the style is very clear to us now, but we cannot see if there is a house on this photo anymore because the content representation is lost. And then in the end, after we got the content representation of the photo and the style representation of this artwork, we're going to synthesize a new image that can match those two at the same time. So this is basically how style transfer works. And Gene Kogan, the creator of Machine Learning for Artists, he made this amazing demo video that talks about what convolutional neural networks see on each layer. So I think you would have a better understanding about how this convolutional neural network sees images and how it can filter out this image and get the feature representation out of one image after watching his video. So I highly recommend you watch his video. And Gatti's paper opened up a brand new area of research. So there are a lot of different kinds of style transfer appeared in the last three years. We're going to quickly take a look at a few of them here, and then we're going to dive into train your style transfer model with Spell. So. In 2016, this paper came out. It's called a fast style transfer. It shows a neural network that can apply a fake style to any input image in real time. It builds on Gatti's style transfer model, but this network gives similar results, but it's a lot faster. This fast style transfer has image transformation network and a loss calculation network. To train this network, we need to pick one fixed style image, and then we use a large batch of different content image as training examples. So in their paper, they trained their network on this Microsoft Cocoa dataset, which is an object recognition dataset of 80,000 images. Today, we're going to use TensorFlow implementation of this fast style transfer. So we're also going to use this Cocoa dataset. We are going to download this dataset later. And here is an image from their paper. So this is the original photo, and this is Gatti's result, and this is the fast style transfer's result, and it works a lot faster. And. The next style transfer is for videos. This model came in 2016, too. We might think we already know how to transfer images, so for videos, we can just transfer each frame of the video one by one and then stitch all those images together to make a transferred video. That could work, but if we do that, we can see the result is not good because. The video will flicker a lot here. That's because the machine doesn't know any information about the previous image. So you can see if we just do that, the video will flicker a lot. But this model. This paper improved this frame to frame stability by adding an optical flow algorithm that tells the machine the possible motion from one frame to the next frame. It's also called temporary coherent. So this transferred. Also, this. This transfer video wouldn't be flickered too much, so we can see some results here. See, this video is not flickering at all, and they got amazing results. From their model. This is the transferred video. The result looks great. Okay. Let's go to the next model. So this is a really cool model appeared in 2017. It's called deep photo transfer. The style transfer that we saw before work really well if we're looking for some artistic painting results because they always add some like distortion of the original image. So they don't really look realistic. But this model, this deep style, deep photo transfer can produce very realistic photos. You can see this is the input image on the left. And in the middle, this is the style image. And then on the right, this is the output image. The output image look like a regular photo to me. So the result is super good. They use something called a fine transformation to make sure that the shapes are not distorted during the transformation process. And the result is just amazing. And this is the next style transfer. It's called semantic style transfer. It can produce semantically meaningful result. The machine has an understanding of the objects on the images. For example, on this image, the machine recognize that both image have nodes. So it uses this information during the transformation process. And there are a lot of applications for this model. You can convert a sketch or painting to a photo. And I think the output is pretty good. So this is semantic style transfer. The last style transfer is very special. It is called universal neural style transfer. Almost all the previous style transfer that we talked about, there are always some abstract style image that doesn't really work well. For example, if the style image is just a black line with a white background, because our model is trained on a lot of objects, images, it cannot get too much information from a line. Because it's trained on objects. But this model can solve this issue. This new model is also based on neural networks, but it doesn't need to be trained on any images. It works on any arbitrary image. It uses something called auto encoder. The encoder has two parts. It can encode something and then it can decode it. So we put our input image in and then it will encode it. And then after it decoded, it can give back the image. The idea is to use the encoder on both this style image and also this input image. And then use the decoder to decode a compressed version of those two. And in the end, you can get this result. And this is truly amazing. And I think in the future, we should port this to ML5.js so we can all play with it. So here are all those style transfer models that we talked about. Today we're going to use the TensorFlow implementation that is a combination of Getty's style transfer and the FastL transfer and the instance normalization. This TensorFlow implementation of FastL transfer is made by Logan Inkstorm. Make sure if we use this code, we can give credits to him. And finally, we're going to train our style transfer model with Spell. There are four steps. So at first, we're going to prepare our environment. We're going to download the dataset. Because we use the VGG model and the Cocoa dataset, the Cocoa dataset is large. So it might take like one hour to finish this run. And then we're going to run this style Python script to train the model. I think it will take about two hours and six minutes. And then in the end, we're going to convert this TensorFlow saved model into a format that we can use in TensorFlow.js and ML5.js. And here is a detailed instruction here. If you're curious, you can go there and read the readme there. And for step one, two, three, you can also check out the... Quick break here. There you go. And for step one, two, three, you can also check out Spell's transferring style transfer tutorial. And you can also set notifications on Spell to tell you if the run takes a long time. But I will talk about this later. And you can also set notifications on the code. The run takes a long time, but I will talk about this later. And you can also customize environment on Spell, too. But I will also talk about that later. So... I guess we're going to try to train the style transfer model on the Spell. Let me make this bigger. I'm just going to one of my empty folders here. Can you guys all see my terminal? Should I make it bigger? I think it probably should still be bigger. I would go as big as you can reasonably without it being able to still work. Like this? I think that's good, yeah. Yeah. Okay. Yes, so the first step is to set up the environment. So we're going to go to our terminal. And we can go to one of the directories. We can find a folder. On my computer, I would just go to cd dev slash live stream. And it's an empty folder. There's nothing there yet. And at first, I need to install Spell. Before I can install Spell, I need to install pip. Pip is a package management system for Python. It's kind of like NPM for JavaScript. Sorry to interrupt you, but you should move the bottom where you're typing higher up. Because the captions are actually covering where you're typing. So if you just make your terminal window go to the top. That works too, yes. It doesn't have to be that high up. How can I make this higher? You should be able to drag from the bottom right. Like drag from the bottom right of the iTerm window. Oh. Yeah, just like that. You can go two-thirds of the way down. Perfect. That's good. Okay, cool. So this is my terminal window. And before I install Spell, I need to install the pip package management for Python. It's kind of like NPM for JavaScript, the node package management. So if you don't have pip installed, we need to do that. We can do it together. But I think I already did it, so it might be faster for me. So I'm just going to switch to this page to see all those steps. So at first, to install the pip, we are going to download this get-pip. I will make this bigger, too. Oh, too big. We are going to download this get-pip Python script. So in my terminal, I'm going to... Oh. I have a dot at the end. So this will download this get-pip Python script. And now if I take a look at my folder, there is a get-pip Python script. And then I'm just going to run my script. Python get-pip.py. If you're using Python 3, you can do Python 3 get-pip.py. And I guess because I already installed pip, so it doesn't take too long. But if this is the first time that you install pip, it might take one minute, I guess. And after this is successfully installed, we are going to pip install spell. I also have done this, so it might be faster for me. So here it said, oh, requirement already satisfied because I already did it once. So now we have spell installed. So if I type in spell, I should be able to see a set of commands that I can do. I can do spell cp to copy a file. Or I can do spell run to start a new run. And I also can do spell login to log in to spell from my local computer. My spell username is yining. My password is this. And now I can say, hello, yining. So I am successfully logged into spell. And I also can do spell who am I to check who is logged into spell. And it says username yining, and this is my email created August 13th. And now we have successfully set up spell. And then we can do prepare our environment. As I mentioned before, we are going to use this TensorFlow implementation of FastL transfer made by Logan. So now I'm just going to go ahead and to clone his GitHub repository. So I'm going to do git clone. Cool. And then I'm going to go to his folder, cd fastl transfer. And now I'm here. The next step is to create some folders and then put in our style image. So at first I'm going to create a folder that is called ckpt checkpoint. And I'm going to create a git ignore file inside of ckpt folder. And I'm also going to create a folder called images here. And I'm also going to create another folder inside of the images called style. This is the folder where our style image will live in. Okay. So now if I take a look at this repo, I can see this is the new folder that we just created. And this is also the new folder that we created images. And the next step is to find a style image that we train, that can be trained on. Oh, and when we're choosing style images, we need to make sure that we could use this artwork. And also we can use that image because, and we need to give credit to all those images. Because we don't want to run into any copyright problem. I have one image here. This is an Asian Chinese painting called Fuchun Shanjitu. And I got this image from Wikipedia. So I can use this image. But if any of you guys have an artwork that I can use, you could share it with me. And I can train it with Spell and then send back the artwork to you. And then I send back the model to you if you allow me to use your artwork. But if there's no other artwork, we are just going to use this image. We're going to train it again. I already trained a model on this image. Let me check the... They're behind in real time. I think maybe you should probably move forward with that image. And I'll see if people... Because then people will do their own images following along. And then maybe we'll come up with a hashtag or something at the end. That people can share their style transfer models on Twitter or in the comments. Or whatever social media place is a good place to share. Yeah, that sounds good. Okay, so we have decided to just use this image. What I'm going to do is to put this image into images slash style. So I'm going to go to the folder. I'm going to make this bigger. I don't think I can make this window bigger. But I will just quickly put that style image into images style. I'm going to copy this image. This image is called fuchun.jpg. And I just copied this image here. So now we got our style image. The one thing that we need to do is to get at those two folders. And also commit these changes to let spell know that we made all those changes. So here I'm going to do get at images. And also add that folder checkpoint. And then I'm going to commit these changes. Cool. So now we have prepared our environment. This is done. We can move to the next step. It's to, we need to download the data set. So in order to train this model, we need some required data set for fast style transfer. We need everything is in the setup script. So we can actually open the fast style transfer GitHub repo here. So next we are going to create a new data set. So next we are going to run this script setup. As you can see in this setup, we are going to create a folder called data. And then go inside, go into that data folder. And then get this, the VGG model, convolutional neural network model back. And then make, also make a folder called bin. And then download this Cocoa data set. And then unzip this Cocoa data set. So do you remember, before we have talked about the VGG here. This is the convolutional neural network that is trained for object recognition. It can get the internal representation of the image for us. That's why we are going to use this VGG model. And also fast style transfer uses this Cocoa data set. It is trained on a large batch of images. This Cocoa data set is an object recognition data set of 80,000 images. So we also need this. Because this Cocoa data set is huge, so it might take a while. But we are just going to do it. So this is what it looks like in the setup script. And next we are just going to run this setup. I'm just adjusting the volume. I will speak up a little bit. Sorry. So next we are going to run this setup script. And we are going to use spell to run this. So in our terminal, we are going to do spell run. And this is the script that we are going to run. But here we can also specify the machine type by using this flag, dash, dash, machine type, CPU. CPU is free to use. So we are just going to run this script. And then you can see this emoji casting spell 15, number 15. This number is really important to us because later we are going to use the output of this run to do our next training run. So it's downloading this VGG model. Let me make it a little bit smaller. And I think after downloading the VGG model, it's also going to download the Cocoa data set. But here I'm just going to do control C to exit. It wouldn't stop this run. It would just stop printing all those logs. I tried to run this run on spell and it takes me one hour and 30 minutes to finish it. I can also log in to spell to see more detailed information about each run. But also in the terminal, we can do spell PS. It will list all those runs that I have done before. So I have 15 runs and the last one is running. And this is the command that I put. And this is the machine type. We are just using CPU. But we can also log into the spell website. And here I can click on this run and I can see all the information about each run. This is the run that we just did, run 15. And it will output a folder called data. And this is all the logs. And this is the CPU usage, CPU memory. So this run will take about 1.5 hours. But luckily we have another complete run. I think it's run 13. So on run 13, I run the same command setup here. And it's already completed and it outputs a folder called data. And we can click on this data to see what kind of output did we get. See we got this, let me make it bigger. We got this VGG model. We also got the Cocoa dataset. Here it's called train 2014. So next we're going to use the output from this run to train our model. Okay, so we finished this second step, downloading the dataset. And we're going to move to the next step, training with style script. And this is the whole command that we're going to run. But let's talk about this command before we actually run it. This command starts a new run. And it uses this dash dash mount flag to mount the output of our previous run, which is run 13. For run 13, the output is a folder called data. And we're going to use this mount flag to copy this data folder into the file system of our next run. And we're going to call that folder datasets instead of data. So this is the mount command. We can see more information on spells documentation. And then we're going to specify the machine type. I used the V100 machine. We can check more detailed machine type here. On the spell run slash docs slash core concepts, here it talks about all those available machine types that you can use. And here there is a pricing table that lists all the machines that we can use. The one that I used yesterday is called V100. And normally it would take 12 hours to train on this K80 machine. And it would take four hours to train on this V100 machine. But I tried it four times. It only took me two hours to train on this V100 machine. So this is the machine type. And next command we specify the framework is TensorFlow. And also we are going to get some actual package for those. Those are two actual packages. They're for video transfer. And you can use dash dash app dash dash pip to get all those packages. And this is the actual Python command that we are going to run. We are going to run the style Python script. And we are going to tell the script that we want the output to be at a folder called CKPT checkpoint. And we are also going to tell the script that this is the path to our style image. And this is the style weight. This is the style loss of that model. Which is 150. But you can read more about it at Logan's GitHub repo about the default style weight and other information. And we also need to specify the train path. This is the path to our Cocoa dataset. And this is the VGG path, the path to our VGG model. And we don't need to change any of this. The only thing that we need to change is our run number. Which would be 13 because 13 run download all those dataset. And we are also going to change the style image name to our own image name which is fuchuan.jpg. Okay, let's do this. So I copy paste this command. And here. I'm just going to replace. I will just go to a code editor first. I'm going to replace this with my real style transfer style image which is fuchuan.jpg. And also I'm going to replace this, the run number of my setup run to 13. Because that is the run that we used. And that's it. So now we should be able to copy paste this command and run it in our spell. And by running this we are going to start a new run to train the model. Let's just do it. And it says casting spell. Machine requested, done. Run is running. Mounting is done. We mount the data folder to this run. And it says Tesla V100. This is the machine type. I think it will give more information. I'm just going to do control C to let it stop logging all those logs. And we can also do spell ps to see our run. So now I actually have two runs running. The first one is the setup. I'm still waiting for that to finish. And then this is the training script. This V100 machine. Oh, and the one thing I forgot to mention is because it takes a while to finish this run, on spell there is a place that we can set notifications. So it will send us emails when this run takes too long and will cost too much money. So on my spell account, if I go to setting, and notifications here, I can set some email notifications saying email me if the run exceeds $20. Things like this in case the run takes too long. So we can do this. And then we can also set a notification. The run takes too long. So we can do this. And also, if you're curious about the versions of packages and frameworks that we have in the spell environment, one thing that we can do is to do spell run pip phrase. It will log out all those installed packages for us. So this is a new run tip. Casting spell 17. And this is finished. The total run time is 10 seconds. And we can see all those installed packages. TensorFlow 1.10.1. Things like this if you're curious about the versions of the frameworks. Yeah, so let's go back to see how did our run. Run's doing. So this is the run that I just started for training. It has been running for three minutes. And it's still running. It will take about like two hours to finish. But I have a complete run, which is run 14. Run 14 also takes like two hours and six minutes to finish. But here I trained another style image. See, I had this exactly same run. But I trained this model on this Lotus image. And this is the output of this run. So when we are waiting for our run 16 to finish, we can use this run 14. This run 14 output a new folder called ckpt checkpoint. And if we open this folder, we can see there are, let me make this bigger. If we open this ckpt folder, if everything goes well, we should be able to see four files in this folder. There are checkpoint.data.index.meta. This is a format of TensorFlow's saved model. This.meta stores the graph information. And this.data file here, it stores the values of each variable in that graph. And this.index identifies the checkpoint. And this checkpoint file actually only tells us the model path. But for next step, we're going to copy those folders back to our local computer. So... We can use spell ls to list all those output for us for one run. So I'm going to do this, spell ls runs. And the run number is 14. The completed training run. So if we do this, spell will tell us, oh, the output is a folder called ckpt. So I also want to see what is inside of ckpt. So I'm going to open this folder. And I'm going to open this folder. So I also want to see what is inside of ckpt. So I can do spell ls runs slash 14 ckpt. And then it lists all those four files that we saw on the spell website. And what we're going to do is we want to copy all those files back. So I am going to create a new folder. Called... Spell model. And then I'm going to go inside to that model. And then here I'm going to copy all those four files. And the run number again is 14. So I hit enter. And it will say copy this file. Good time. Yeah. Short intermission, everybody. Short intermission, everybody. Now we know that two half an hour has passed. Hello. We're good. We're good. Oh, I was like... It's been one hour, yes. It's actually been less than an hour because the camera started a little while before we started. And if people were wondering if this really is live, yes, it's really live. People in chat are like, is this live? Okay. So this is finished. We successfully copied all those four files, which is the model, which is a TensorFlow save model, back to our local computer. So... Oh, I created a wrong folder inside of this GitHub repo, but it's fine. So now if we... If we list out all those files, we can see all those four files are on our local machine. So this is how we can get the trained model back from Spell's remote machine. Actually, we can open that to see what do they look like. I'm going to that directory. I just created this new folder called spell model. I'm just going to drag this model out to the desktop. And as we can see, we have four files. This is the format of the model. This is the format of the TensorFlow save model. And if we open this checkpoint file, there's only two lines in this file. It tells us the model checkpoint path is fns.ckpt. This is important information because we're going to use this path for our next step. So just remember the model checkpoint path is this. Okay, so... So far we set up the environment, we download the dataset, we trained the model with the style Python script, we copied our trained model back to our local computer, and the last step is to convert the model to a format that we can use in TensorFlow.js and ML5.js. Okay, let's do this. Oh, by the way, this is the trained model that we got on the desktop. Okay, so... If I go back to my old directory, which is live stream, here, we're going to use... use the script that is from FaststyleTransfer, deeplearn.js. Deeplearn.js is the formal name for TensorFlow.js. This repo is built by Richiro Nakano. His work is amazing. He recently contributed a new model called SketchRN to ML5.js, too. You guys should definitely check out his work. But we're going to use his script to convert the TensorFlow model into a model that we can use in ML5.js. So the way that we're going to do it is to clone his GitHub repo. Oh. Oh. I think there is a dot at the end. Okay. And then we're going inside to this GitHub repo. And we're going to put all those checkpoint files that we got into one of the folders inside of this GitHub repo, which is... So I'm just going to go to FaststyleTransfer, deeplearn.js, and go to source. Wait, is this source? Oh, no, not source. Just the root directory. So I'm just going to copy this folder to the root directory of this GitHub repo. And I just did. It's here. And then we're going to run two Python scripts. The first thing is to dump the checkpoints just to convert the format. So what we're going to do is... Copy-paste this command. Let's edit this in the code editor first. Python script and run this script. And then the output directory is source slash checkpoints slash our folder name, which will be spell model. And then the checkpoint file is in the root directory of the GitHub repo. So it's.slash spell model slash fns.ckpt. This is the path to our model, which we saw before in this checkpoint file. This is the path to our checkpoint. That's why we have this name here. So now I'm just going to run this script. And then you can see it's done. So it actually created one checkpoint file and 49 other files. And we can go there to see what is the output. The output lives in source checkpoint. And this is our model. And you can see that we got the manifest.json. This tells us the structure of the graph. And also 49 files that tells us all those variables in each layer. And this is the format that we can use in ml5.js and TensorFlow.js. So now I'm just going to copy this model back to my desktop. I'm going to rename it and drag it to my desktop. Oh, it's here. Okay, so far we got two models. We have a TensorFlow saved model that can work in TensorFlow, of course. And then we also got another model that can work in ml5.js and TensorFlow.js. So this is what we got today. And the next step is to run this model in ml5.js. Here are two demos on ml5's website. And we also have this demo here. That you can select different styles. You can upload the image. You can change the style here. And you can upload the image. I'm going to upload a photo. A photo of a cat. And I'm going to upload the image. A photo of a cat. And then click this transfer my image. This is the transferred cat. You can also play it with different styles too. Oh, I do like this one. And also you can use webcam. And then click this button. And you can see the transferred version of the images from the webcam. So you can go there and check this demo out. But next we're just going to run this model in our ml5 demo. We can do this quickly. Here we're just going to clone this GitHub repo. And then go inside to that folder. Style transfer underscore spell. And we're going to open this folder in a code editor. And in this models folder, there's already one models there. We're going to add our new models inside of this folder. So what I'm going to do is to find that GitHub repo. And I'm going to add it here. And I'm going to add it here. What I'm going to do is to find that GitHub repo. And inside of models, I'm going to copy paste this model in. I'm just going to rename it to Lotus. Because the name of the art is called Lotus. So now we go back to our code editor. We have a new model here. And we can take a look at what is inside of the index HTML. So to build this demo, we need p5.js. Mainly to get the video from the webcam. And also we need p5 DOM library to make it easier to create DOM elements for us. And then in the end, we need the ml5 library. And we have some styles here. We can ignore them for now. And we're also running the Sketch.js script here. And in the body, we have header tag. We have p tag. And we are linking the source of the image. The art style image. And also we are showing the art image. But I'm going to change this image. To the Lotus image. This is a pre-trained model. I'm going to add this image into this image folder. Okay. So here we can say images slash Lotus. So we are going to show that image. And in the end, we have a div container to contain our canvas. And now we can go to let's save this in the HTML. And then we can go to Sketch.js. I'm just going to delete all the code here. So we can do it ourselves one more time together. So to build this demo, we need three things. We need a video that can get the images from our webcam. So we have video. We also need the style transfer from ml5 library to allow us to transfer images. So I'm going to have another variable called style. And in the end, we need a variable to hold our output image. So we're going to do let without img. Okay. So this is the three things that we need. And in p5, there is a setup function that will be called once at the beginning. So in this setup function, we're going to use p5.js to create a canvas. That is 320 wide and 250 as its height. And then we're going to use this p5 DOM library to put this canvas element inside of div element whose ID is canvas container. Okay. So we create a canvas. That's it. And then we're going to create the video. So p5 has this function called create capture. And if we pass the uppercase video in, it will try to get the video from your webcam. And we're also going to save video.height because we don't really need the original video. We need the transferred video. So we're also going to say video height. And we're also going to create the result image. p5 DOM library has this. I just want to make it a little bit better. We're going to create this result image. Equals to create IMG. Pass the empty string there. And we're also going to hide this image. We're going to draw the image on the canvas so we don't really need this image. And in the end, we're going to use ml5 to get the style transfer model, right? So style equals to ml5.styleTransfer. And we are going to pass in the path to the model. So it's models.models.models.models.lotus. Okay. And then we can also tell the style transfer to look for inputs from our video. So we're passing the video. And also, we have a callback function saying, oh, if you finish loading this model, let me know. So this is a callback function called model loaded. We're going to define this function now. This is a callback function. So we're going to do function model loaded. Once the model is loaded, we can just ask the style transfer to transfer something. But at first, I want to change the text on this p tag into model loaded just to let people know that the model is good to go. So I'm going to select an element. This is a function from a p5 DOM library to select an HTML element from the DOM. The ID is status. And I want to change its HTML to model loaded. Okay. And then once the model is loaded, I'm going to ask the style to transfer something. So I'm going to say style.transfer. And I'm going to pass in another function called result. So this is a callback function. Once the model got anything back, this function will be called. So let's make up this function. Function got result. It will get two things. One is if there's any error during this process, it will put the error in this error variable. And another thing is the output, which is an image. So in this, once we got the result, we are going to give the result image an attribute to hold this image.source. So we are going to say result image.attribute. We copy the source of this image, the source, to our result image. And after we got the result, we want to call this style.transfer again, over and over again to see more result. So we are going to do style.transfer.result again. And one thing is missing because we did update the source for result image, but this result image is hidden, so we cannot see it. But p5 has a function called draw. It will run over and over again. In the draw function, we are going to draw this result image. So I'm just going to say image. It's lowercase i. Image result img from origin 0, 0, and the size is 320 to 240. Okay, that's it. This is the whole Sketch.js. Next, finally, we are going to run this code. We can do Python minus m simple HTTP server. If you are using Python 3, you need to do Python minus m simple.http server. Anyway, it started server at localhost 8000. So now if we go to our localhost 8000, we should be able to see something. So model is loaded. This is the wrong style source. I just have to come in and try. That is so cool. As you can see, this style has more colors, so the result is a little bit better than the previous model. Yes, this is the demo that we built today. This is all the resources that I used. This is Getty's paper from 2015. This is Gene Cogan's What Neural Networks Sees. This is the transfer style tutorial from Spell. Also for ML5.js, it has a style transfer tutorial made by Chris. I recommend you to check that out too. This is the link to ML5.js. I also want to recommend this YouTube channel because I learned a lot of machine learning papers from it. I want to give credit to those two project creators. We used the TensorFlow implementation of the fast style transfer made by Logan Engstrom. We used the script to convert the TensorFlow saved model to a format that we can use in TensorFlow.js and ML5.js. It's made by Richiro Nakano. To wrap up today, we trained a style transfer model with Spell. We ran this model with ML5 in the browser. You can check out the model here. That's it. I hope you guys liked the video. If you run into any issues when you're training or running the model, you can leave the comments or open one issue on the GitHub. Come over here. Some people asked some interesting questions. I'm actually going to have a short Q&A session. I'm also going to make the chat a little bit bigger so I might be able to monitor it as we're talking a little bit. This is always awkward. We don't have a good interview Q&A setup here. I'll just try. One thing that somebody asked that I thought was interesting. You notice it runs slow in the browser. It's amazing that it runs at all. Some people asked what performance considerations are there. Can this actually run on a mobile phone? How far have you pushed that or experimented with it? For now, I think it works well in Chrome. I know TensorFlow.js also supports iOS and other OS. It has slightly different results in different OS. I'm not sure. My experience doing this sort of stuff over the last 10 plus years, the thing that you're doing now, in a couple of years, that will work on the smaller devices. Then the newer thing will be super fast and that will work on the smaller devices. The stuff is all very cyclical. The fact that it runs in a browser just makes it so flexible. Again, to be clear, the training process here is a thing that you can't easily do in the browser. That's the thing that takes a very long time. You can certainly do it on your own computer. You can buy a GPU, but using a cloud computing service, which Spell is one of many options, and Spell just makes it super easy because you can just do it with a command line interface right from your computer. There was another question. I don't know if you know the answer to this because I certainly don't. People who are curious, one thing that I've talked a little bit about in more beginner level machine learning tutorials is the idea of a loss function. Do you know how the style transfer training process works? How does it figure out how well it's doing? For fast style transfer, it has an image transformation network. It also has a loss calculation network. I think I need to check the paper in detail, but it calculates the loss and then goes back to trying to minimize the loss function. Great. I think we can pretty much wrap up. This is amazing. This was exactly what you said. Yingning said, I think about an hour and 20 minutes, and it's exactly an hour and 20 minutes. Here's what I want. I'm really curious and excited to see how replicable this is for you. If you are following this tutorial, can you sign up for your own Spell account? You can go to spell.run coding train. Can you clone this Python code? Can you pick your own style image? Can you then run it with ml5 and your webcam and style your own face, the image from the webcam? If you are able to follow this and do this, share. This was suggested in the Coding Train Slack channel, which is a Slack channel for patrons or members. It was suggested to use the hashtag this.style. This.style. This dot is the joke. By the way, people were commenting that you were forgetting your semicolons, which you don't actually need. It's just funny. This dot is the thing that I always forget. Actually, I use semicolons all the time until one of my colleagues said, oh, you shouldn't use that. It's not clear. Then I switched to not using semicolons, but I'm good with both. We could be here for the next three hours discussing whether you should use semicolons or not. This.style, you can share things you make on Twitter with that hashtag, whatever social media you use. There will be a comments section here once this video is archived. Then, in addition, I will hopefully create a page on the codingtrain.com, which we'll link to with all the links and everything that Yuning has shown you here. All of those links, like the links of all the resources and all the artists and different things you showed, I'll update the video description for this archive, for the archived version of this live stream right afterwards as well. This.style, yay stream, links at the start of the stream. Okay, I'm just looking to see if there's any urgent burning questions. I have to come back here. We can wave goodbye from our This.style. Okay. Then, the only way – oh, get the slides. Whatever material that Yuning used that we can publish, we will certainly publish. We'll share the slides as well. Also, I want to mention – is it okay if I go to your browser here? If I go to YouTube slash Coding Train, and hopefully this is going to – Oh, you can close this. Oh, it's like – but I don't want to close it. It's so wonderful. Okay, I'll close it. I'm going to go down here. You can see that NextUp scheduled for October 5th. I think – I can't hear it. Oh, it's okay. I'm so used to doing this. With all the same elements, ml5, spell, and TensorFlow to train something called an LSTM, which is a long, short-term memory network. This is a kind of neural network that's well-suited for sequences. So if you wanted to train a model to learn about how characters appear next to each other in text or musical notes appear next to each other in a song or how strokes appear in sequence in a drawing, there's something called Sketch RNN. There's so many possibilities, but we're going to, in that live stream, be able to show you how to take a text from your favorite author and train a machine learning model on spell.run cloud computing service to download that model and then have the model generate new text in the style of that author in the browser. So that's coming two weeks from today at a slightly earlier time. And next Friday I'll be back. I have this very long list of things I need to get to. So I don't know what I'm going to do next Friday yet. I'm trying to schedule stuff better in advance. And, yeah, so stay tuned. Oh, I know I forgot something. If certain things that you couldn't follow today, I want to mention that would be helpful to you. I recently did a whole set of workflow videos, and Yingning pretty much is using the exact same stuff, just sort of coincidentally, I guess. So running Git, using Visual Studio Code, running stuff from your terminal, and then I also have a whole intro to spell video. So a lot of the stuff of, like, how do I install spell again? What does it do? Where do I sign up? You can find that in the intro to spell video as well. So I'll link to all that stuff. If there's a moderator in the chat who can link to some of those things right now, great. But I'm going to go. This is the awkward part because I've yet... CJ, Coding Garden with CJ has another wonderful YouTube channel. CJ was here doing a guest spot and showed me all these things that you can do in Open Broadcast Studio. Like I could just press a button and then an outro video would play, but I don't have that. So we just have to walk awkwardly to the side. I have to turn the stream off over here on a laptop. Thank you for watching. Bye-bye. Thank you, everyone. I look forward to hearing from you in the comments and on Twitter and all the other various places. Bye. Thank you. Thank you to Spell. Thank you to White Coat Captioning. And thank you especially to Yaning. Thank you, Dan. I can't find the page. Stop. I got it. Stop streaming.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:59.28362Z",
  "started_at": "2023-09-26T21:26:46.71437Z",
  "completed_at": "2023-09-26T21:42:13.530091Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=gye9hSIrRWI",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 926.815721
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/sdi7zuzbxhxx2kgp7yudvceswe/cancel",
    "get": "https://api.replicate.com/v1/predictions/sdi7zuzbxhxx2kgp7yudvceswe"
  }
}