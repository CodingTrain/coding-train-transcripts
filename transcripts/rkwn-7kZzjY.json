{
  "id": "2d27kprbga3jhzeyu4ghufiktm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/rkwn-7kZzjY.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/735993 [00:00<?, ?frames/s]\n  0%|          | 2608/735993 [00:02<12:50, 951.23frames/s]\n  1%|          | 5496/735993 [00:11<26:30, 459.27frames/s]\n  1%|          | 8400/735993 [00:17<26:40, 454.73frames/s]\n  1%|▏         | 11016/735993 [00:23<27:06, 445.74frames/s]\n  2%|▏         | 13976/735993 [00:28<24:37, 488.59frames/s]\n  2%|▏         | 16440/735993 [00:35<27:32, 435.37frames/s]\n  3%|▎         | 18824/735993 [00:41<27:09, 440.00frames/s]\n  3%|▎         | 21688/735993 [00:46<26:06, 455.86frames/s]\n  3%|▎         | 24688/735993 [00:53<26:41, 444.17frames/s]\n  4%|▎         | 27312/735993 [01:00<26:55, 438.77frames/s]\n  4%|▍         | 30208/735993 [01:04<24:34, 478.66frames/s]\n  5%|▍         | 33168/735993 [01:11<24:21, 480.87frames/s]\n  5%|▍         | 36024/735993 [01:17<25:28, 457.96frames/s]\n  5%|▌         | 38784/735993 [01:23<25:20, 458.47frames/s]\n  6%|▌         | 41368/735993 [01:31<27:00, 428.64frames/s]\n  6%|▌         | 43736/735993 [01:35<26:06, 441.99frames/s]\n  6%|▋         | 46240/735993 [01:42<27:39, 415.53frames/s]\n  7%|▋         | 49240/735993 [01:47<24:31, 466.80frames/s]\n  7%|▋         | 51904/735993 [01:53<24:27, 466.06frames/s]\n  7%|▋         | 54904/735993 [02:00<25:00, 453.86frames/s]\n  8%|▊         | 57288/735993 [02:04<23:52, 473.92frames/s]\n  8%|▊         | 60040/735993 [02:09<22:48, 493.77frames/s]\n  9%|▊         | 62840/735993 [02:13<20:46, 539.91frames/s]\n  9%|▉         | 65392/735993 [02:18<20:47, 537.46frames/s]\n  9%|▉         | 68392/735993 [02:22<18:36, 597.83frames/s]\n 10%|▉         | 71264/735993 [02:30<22:46, 486.45frames/s]\n 10%|█         | 73984/735993 [02:37<23:39, 466.39frames/s]\n 10%|█         | 76984/735993 [02:44<24:01, 457.12frames/s]\n 11%|█         | 79984/735993 [02:51<24:39, 443.32frames/s]\n 11%|█▏        | 82984/735993 [02:54<19:50, 548.36frames/s]\n 12%|█▏        | 85584/735993 [02:57<18:39, 581.08frames/s]\n 12%|█▏        | 88304/735993 [03:02<18:06, 595.88frames/s]\n 12%|█▏        | 91192/735993 [03:06<17:00, 631.55frames/s]\n 13%|█▎        | 94136/735993 [03:11<17:52, 598.37frames/s]\n 13%|█▎        | 96360/735993 [03:17<20:00, 533.00frames/s]\n 13%|█▎        | 96360/735993 [03:28<20:00, 533.00frames/s]\n 14%|█▎        | 99360/735993 [03:56<59:10, 179.29frames/s]\n 14%|█▍        | 102104/735993 [04:04<49:55, 211.65frames/s]\n 14%|█▍        | 104736/735993 [04:10<42:38, 246.69frames/s]\n 15%|█▍        | 107640/735993 [04:18<37:56, 276.00frames/s]\n 15%|█▍        | 110280/735993 [04:26<36:04, 289.07frames/s]\n 15%|█▌        | 113024/735993 [04:34<34:28, 301.10frames/s]\n 16%|█▌        | 115832/735993 [04:41<31:12, 331.23frames/s]\n 16%|█▌        | 118272/735993 [04:47<30:03, 342.59frames/s]\n 16%|█▋        | 120928/735993 [04:56<30:55, 331.46frames/s]\n 17%|█▋        | 123416/735993 [05:03<30:36, 333.47frames/s]\n 17%|█▋        | 126056/735993 [05:10<29:27, 344.99frames/s]\n 18%|█▊        | 128920/735993 [05:19<29:57, 337.68frames/s]\n 18%|█▊        | 131472/735993 [05:26<28:35, 352.29frames/s]\n 18%|█▊        | 134432/735993 [05:32<26:25, 379.45frames/s]\n 19%|█▊        | 137248/735993 [05:37<23:38, 422.21frames/s]\n 19%|█▉        | 140184/735993 [05:44<22:55, 433.04frames/s]\n 19%|█▉        | 142840/735993 [05:52<24:55, 396.63frames/s]\n 20%|█▉        | 145712/735993 [05:59<25:15, 389.40frames/s]\n 20%|██        | 148616/735993 [06:07<25:32, 383.17frames/s]\n 21%|██        | 151408/735993 [06:13<23:56, 406.85frames/s]\n 21%|██        | 154376/735993 [06:21<24:38, 393.46frames/s]\n 21%|██▏       | 157216/735993 [06:29<24:44, 389.80frames/s]\n 22%|██▏       | 159752/735993 [06:35<24:16, 395.68frames/s]\n 22%|██▏       | 162640/735993 [06:43<25:16, 378.10frames/s]\n 22%|██▏       | 165440/735993 [06:52<26:48, 354.64frames/s]\n 23%|██▎       | 168400/735993 [06:58<24:25, 387.31frames/s]\n 23%|██▎       | 171344/735993 [07:06<24:39, 381.56frames/s]\n 24%|██▎       | 173864/735993 [07:12<24:11, 387.19frames/s]\n 24%|██▍       | 176512/735993 [07:18<23:17, 400.22frames/s]\n 24%|██▍       | 179488/735993 [07:25<21:59, 421.60frames/s]\n 24%|██▍       | 179488/735993 [07:38<21:59, 421.60frames/s]\n 25%|██▍       | 182256/735993 [07:45<35:29, 260.07frames/s]\n 25%|██▌       | 185160/735993 [07:53<32:14, 284.81frames/s]\n 25%|██▌       | 187632/735993 [08:01<31:16, 292.24frames/s]\n 26%|██▌       | 190152/735993 [08:09<30:39, 296.73frames/s]\n 26%|██▌       | 192832/735993 [08:15<27:14, 332.30frames/s]\n 27%|██▋       | 195632/735993 [08:24<27:21, 329.16frames/s]\n 27%|██▋       | 198616/735993 [08:30<24:32, 364.89frames/s]\n 27%|██▋       | 201448/735993 [08:38<24:55, 357.36frames/s]\n 28%|██▊       | 204112/735993 [08:45<24:05, 368.04frames/s]\n 28%|██▊       | 206880/735993 [08:53<24:54, 353.98frames/s]\n 28%|██▊       | 209376/735993 [08:59<23:03, 380.75frames/s]\n 29%|██▉       | 212144/735993 [09:05<22:28, 388.45frames/s]\n 29%|██▉       | 214824/735993 [09:12<22:24, 387.65frames/s]\n 30%|██▉       | 217744/735993 [09:20<22:19, 386.98frames/s]\n 30%|██▉       | 220744/735993 [09:26<20:35, 417.10frames/s]\n 30%|███       | 223376/735993 [09:31<19:03, 448.12frames/s]\n 31%|███       | 226232/735993 [09:37<18:50, 450.82frames/s]\n 31%|███       | 228568/735993 [09:42<18:41, 452.30frames/s]\n 31%|███▏      | 231168/735993 [09:48<18:45, 448.56frames/s]\n 32%|███▏      | 233768/735993 [09:53<17:23, 481.18frames/s]\n 32%|███▏      | 235664/735993 [09:56<16:56, 492.20frames/s]\n 32%|███▏      | 238144/735993 [10:00<15:21, 540.48frames/s]\n 33%|███▎      | 240592/735993 [10:04<15:07, 546.13frames/s]\n 33%|███▎      | 243440/735993 [10:11<16:59, 483.15frames/s]\n 33%|███▎      | 246104/735993 [10:18<17:39, 462.38frames/s]\n 34%|███▍      | 248776/735993 [10:24<18:21, 442.25frames/s]\n 34%|███▍      | 251248/735993 [10:29<17:40, 457.13frames/s]\n 34%|███▍      | 253624/735993 [10:35<17:55, 448.38frames/s]\n 35%|███▍      | 256464/735993 [10:40<17:11, 464.82frames/s]\n 35%|███▌      | 259304/735993 [10:45<16:08, 492.05frames/s]\n 36%|███▌      | 262136/735993 [10:51<15:48, 499.75frames/s]\n 36%|███▌      | 263328/735993 [10:54<16:33, 475.84frames/s]\n 36%|███▌      | 263328/735993 [11:08<16:33, 475.84frames/s]\n 36%|███▌      | 265384/735993 [11:42<1:03:27, 123.61frames/s]\n 36%|███▌      | 265384/735993 [11:58<1:03:27, 123.61frames/s]\n 36%|███▋      | 268224/735993 [12:00<57:48, 134.88frames/s]  \n 37%|███▋      | 271056/735993 [12:08<45:08, 171.63frames/s]\n 37%|███▋      | 273768/735993 [12:15<37:05, 207.67frames/s]\n 38%|███▊      | 276272/735993 [12:19<30:17, 252.99frames/s]\n 38%|███▊      | 278280/735993 [12:24<26:42, 285.58frames/s]\n 38%|███▊      | 280608/735993 [12:26<20:54, 363.00frames/s]\n 38%|███▊      | 282584/735993 [12:30<19:28, 388.11frames/s]\n 39%|███▊      | 284928/735993 [12:33<16:33, 454.23frames/s]\n 39%|███▉      | 287456/735993 [12:39<16:28, 453.84frames/s]\n 39%|███▉      | 289768/735993 [12:43<15:36, 476.36frames/s]\n 40%|███▉      | 292344/735993 [12:48<14:51, 497.57frames/s]\n 40%|████      | 295240/735993 [12:53<13:54, 528.36frames/s]\n 40%|████      | 297448/735993 [13:00<16:50, 433.97frames/s]\n 41%|████      | 300288/735993 [13:07<16:49, 431.46frames/s]\n 41%|████      | 303040/735993 [13:14<17:38, 409.06frames/s]\n 42%|████▏     | 305760/735993 [13:22<18:17, 392.11frames/s]\n 42%|████▏     | 308352/735993 [13:28<17:26, 408.77frames/s]\n 42%|████▏     | 310688/735993 [13:32<16:11, 437.76frames/s]\n 43%|████▎     | 313152/735993 [13:36<15:08, 465.66frames/s]\n 43%|████▎     | 315056/735993 [13:41<15:27, 453.76frames/s]\n 43%|████▎     | 317752/735993 [13:45<13:50, 503.49frames/s]\n 44%|████▎     | 320360/735993 [13:53<15:57, 434.15frames/s]\n 44%|████▍     | 323360/735993 [14:01<16:27, 417.82frames/s]\n 44%|████▍     | 325944/735993 [14:06<15:31, 440.33frames/s]\n 45%|████▍     | 328672/735993 [14:12<15:26, 439.84frames/s]\n 45%|████▍     | 331088/735993 [14:17<15:22, 439.06frames/s]\n 45%|████▌     | 333776/735993 [14:23<14:39, 457.13frames/s]\n 46%|████▌     | 336640/735993 [14:30<14:57, 444.99frames/s]\n 46%|████▌     | 338896/735993 [14:35<14:52, 444.83frames/s]\n 46%|████▋     | 341104/735993 [14:39<13:52, 474.33frames/s]\n 47%|████▋     | 343488/735993 [14:43<13:03, 501.06frames/s]\n 47%|████▋     | 345488/735993 [14:47<13:13, 491.94frames/s]\n 47%|████▋     | 348144/735993 [14:51<12:16, 526.31frames/s]\n 48%|████▊     | 350712/735993 [14:58<13:49, 464.40frames/s]\n 48%|████▊     | 352872/735993 [15:05<15:08, 421.69frames/s]\n 48%|████▊     | 355464/735993 [15:11<15:10, 417.79frames/s]\n 49%|████▊     | 358144/735993 [15:18<15:57, 394.68frames/s]\n 49%|████▉     | 361008/735993 [15:25<15:26, 404.69frames/s]\n 49%|████▉     | 363808/735993 [15:33<16:09, 383.77frames/s]\n 50%|████▉     | 366296/735993 [15:40<15:54, 387.41frames/s]\n 50%|█████     | 368840/735993 [15:47<16:30, 370.61frames/s]\n 51%|█████     | 371800/735993 [15:56<16:56, 358.20frames/s]\n 51%|█████     | 374080/735993 [16:03<17:35, 342.79frames/s]\n 51%|█████     | 377080/735993 [16:09<15:10, 394.22frames/s]\n 52%|█████▏    | 379756/735993 [16:15<14:43, 403.31frames/s]\n 52%|█████▏    | 382756/735993 [16:22<14:12, 414.21frames/s]\n 52%|█████▏    | 385236/735993 [16:27<13:51, 422.03frames/s]\n 53%|█████▎    | 388236/735993 [16:34<13:40, 423.63frames/s]\n 53%|█████▎    | 391108/735993 [16:41<13:25, 427.99frames/s]\n 53%|█████▎    | 393412/735993 [16:47<13:53, 410.98frames/s]\n 54%|█████▍    | 395944/735993 [16:51<12:14, 463.24frames/s]\n 54%|█████▍    | 398452/735993 [16:57<12:22, 454.64frames/s]\n 55%|█████▍    | 401120/735993 [17:05<13:39, 408.50frames/s]\n 55%|█████▍    | 403404/735993 [17:10<13:27, 412.08frames/s]\n 55%|█████▍    | 404448/735993 [17:13<13:24, 412.00frames/s]\n 55%|█████▌    | 407212/735993 [17:17<11:29, 476.60frames/s]\n 56%|█████▌    | 409568/735993 [17:24<12:43, 427.41frames/s]\n 56%|█████▌    | 412500/735993 [17:32<13:33, 397.52frames/s]\n 56%|█████▋    | 415344/735993 [17:41<14:48, 360.87frames/s]\n 57%|█████▋    | 418012/735993 [17:47<13:16, 399.39frames/s]\n 57%|█████▋    | 420920/735993 [17:53<12:37, 415.97frames/s]\n 58%|█████▊    | 423844/735993 [18:01<13:02, 398.84frames/s]\n 58%|█████▊    | 426844/735993 [18:08<12:39, 407.19frames/s]\n 58%|█████▊    | 429844/735993 [18:14<12:03, 423.19frames/s]\n 59%|█████▉    | 432844/735993 [18:20<11:09, 452.98frames/s]\n 59%|█████▉    | 435676/735993 [18:25<10:35, 472.80frames/s]\n 60%|█████▉    | 438616/735993 [18:34<11:30, 430.59frames/s]\n 60%|█████▉    | 441104/735993 [18:41<12:11, 402.96frames/s]\n 60%|██████    | 444104/735993 [18:48<11:53, 409.13frames/s]\n 61%|██████    | 447020/735993 [18:51<09:55, 485.06frames/s]\n 61%|██████    | 449900/735993 [19:00<10:58, 434.73frames/s]\n 62%|██████▏   | 452744/735993 [19:06<10:47, 437.18frames/s]\n 62%|██████▏   | 455532/735993 [19:14<11:26, 408.50frames/s]\n 62%|██████▏   | 458444/735993 [19:20<10:47, 428.77frames/s]\n 63%|██████▎   | 461284/735993 [19:30<12:08, 376.97frames/s]\n 63%|██████▎   | 464260/735993 [19:37<11:59, 377.56frames/s]\n 63%|██████▎   | 467132/735993 [19:47<12:32, 357.09frames/s]\n 64%|██████▍   | 470060/735993 [19:55<12:32, 353.42frames/s]\n 64%|██████▍   | 473036/735993 [20:01<11:19, 386.93frames/s]\n 65%|██████▍   | 475552/735993 [20:10<12:25, 349.59frames/s]\n 65%|██████▌   | 478420/735993 [20:14<10:30, 408.62frames/s]\n 65%|██████▌   | 481420/735993 [20:22<10:32, 402.36frames/s]\n 66%|██████▌   | 483840/735993 [20:27<09:52, 425.28frames/s]\n 66%|██████▌   | 486712/735993 [20:33<09:36, 432.62frames/s]\n 67%|██████▋   | 489548/735993 [20:39<09:14, 444.38frames/s]\n 67%|██████▋   | 492548/735993 [20:44<08:24, 482.87frames/s]\n 67%|██████▋   | 495548/735993 [20:53<09:07, 439.02frames/s]\n 68%|██████▊   | 498384/735993 [20:59<08:57, 442.06frames/s]\n 68%|██████▊   | 501000/735993 [21:07<09:35, 408.12frames/s]\n 68%|██████▊   | 503300/735993 [21:12<09:17, 417.60frames/s]\n 69%|██████▉   | 506300/735993 [21:18<08:57, 427.33frames/s]\n 69%|██████▉   | 509300/735993 [21:24<08:28, 446.23frames/s]\n 70%|██████▉   | 512300/735993 [21:28<07:07, 523.26frames/s]\n 70%|██████▉   | 515044/735993 [21:37<08:20, 441.53frames/s]\n 70%|███████   | 517776/735993 [21:45<08:58, 405.16frames/s]\n 71%|███████   | 520472/735993 [21:52<09:18, 386.20frames/s]\n 71%|███████   | 523472/735993 [21:58<08:24, 421.64frames/s]\n 71%|███████▏  | 525952/735993 [22:02<07:35, 461.00frames/s]\n 72%|███████▏  | 528952/735993 [22:08<07:13, 477.24frames/s]\n 72%|███████▏  | 531564/735993 [22:13<06:54, 492.75frames/s]\n 73%|███████▎  | 534564/735993 [22:19<06:55, 485.22frames/s]\n 73%|███████▎  | 537444/735993 [22:26<07:05, 466.29frames/s]\n 73%|███████▎  | 540444/735993 [22:31<06:37, 492.54frames/s]\n 74%|███████▍  | 543444/735993 [22:37<06:28, 496.07frames/s]\n 74%|███████▍  | 546156/735993 [22:46<07:26, 425.40frames/s]\n 75%|███████▍  | 549132/735993 [22:53<07:14, 430.03frames/s]\n 75%|███████▍  | 550700/735993 [22:58<07:52, 392.15frames/s]\n 75%|███████▍  | 550700/735993 [23:18<07:52, 392.15frames/s]\n 75%|███████▌  | 553624/735993 [23:49<22:45, 133.52frames/s]\n 76%|███████▌  | 556316/735993 [23:56<18:07, 165.23frames/s]\n 76%|███████▌  | 558900/735993 [24:04<15:17, 193.03frames/s]\n 76%|███████▋  | 561896/735993 [24:12<12:30, 232.11frames/s]\n 77%|███████▋  | 564896/735993 [24:18<10:20, 275.87frames/s]\n 77%|███████▋  | 567454/735993 [24:25<09:11, 305.42frames/s]\n 78%|███████▊  | 570402/735993 [24:31<08:05, 341.04frames/s]\n 78%|███████▊  | 573024/735993 [24:39<08:11, 331.35frames/s]\n 78%|███████▊  | 575904/735993 [24:49<08:19, 320.68frames/s]\n 79%|███████▊  | 578752/735993 [24:57<07:48, 335.38frames/s]\n 79%|███████▉  | 581728/735993 [25:01<06:25, 400.40frames/s]\n 79%|███████▉  | 584692/735993 [25:09<06:34, 383.73frames/s]\n 80%|███████▉  | 587676/735993 [25:16<06:04, 407.07frames/s]\n 80%|████████  | 590676/735993 [25:24<06:12, 390.56frames/s]\n 81%|████████  | 593676/735993 [25:31<05:50, 405.85frames/s]\n 81%|████████  | 596676/735993 [25:35<04:53, 474.01frames/s]\n 81%|████████▏ | 599656/735993 [25:39<04:22, 519.19frames/s]\n 82%|████████▏ | 602656/735993 [25:43<03:52, 572.98frames/s]\n 82%|████████▏ | 605656/735993 [25:51<04:19, 503.05frames/s]\n 83%|████████▎ | 608232/735993 [25:56<04:12, 505.60frames/s]\n 83%|████████▎ | 611040/735993 [25:59<03:41, 563.95frames/s]\n 83%|████████▎ | 613648/735993 [26:05<03:51, 527.82frames/s]\n 84%|████████▍ | 616648/735993 [26:11<03:51, 516.02frames/s]\n 84%|████████▍ | 619628/735993 [26:17<03:42, 522.37frames/s]\n 85%|████████▍ | 622628/735993 [26:22<03:26, 549.01frames/s]\n 85%|████████▍ | 625306/735993 [26:28<03:33, 518.91frames/s]\n 85%|████████▌ | 628306/735993 [26:32<03:11, 561.61frames/s]\n 86%|████████▌ | 630726/735993 [26:36<03:00, 582.62frames/s]\n 86%|████████▌ | 633620/735993 [26:41<02:58, 574.13frames/s]\n 86%|████████▋ | 636332/735993 [26:45<02:51, 580.81frames/s]\n 87%|████████▋ | 639332/735993 [26:51<02:53, 558.20frames/s]\n 87%|████████▋ | 642332/735993 [26:56<02:42, 574.75frames/s]\n 88%|████████▊ | 645288/735993 [27:01<02:38, 573.92frames/s]\n 88%|████████▊ | 647936/735993 [27:05<02:23, 614.26frames/s]\n 88%|████████▊ | 650936/735993 [27:08<02:03, 690.24frames/s]\n 89%|████████▉ | 653918/735993 [27:11<01:45, 776.56frames/s]\n 89%|████████▉ | 656804/735993 [27:14<01:35, 833.28frames/s]\n 90%|████████▉ | 659652/735993 [27:17<01:35, 801.67frames/s]\n 90%|████████▉ | 662064/735993 [27:24<02:00, 612.32frames/s]\n 90%|█████████ | 664904/735993 [27:28<01:50, 640.63frames/s]\n 91%|█████████ | 667764/735993 [27:33<01:49, 623.72frames/s]\n 91%|█████████ | 670564/735993 [27:37<01:44, 628.96frames/s]\n 91%|█████████▏| 673384/735993 [27:44<01:53, 551.74frames/s]\n 92%|█████████▏| 676384/735993 [27:49<01:48, 547.12frames/s]\n 92%|█████████▏| 678728/735993 [27:54<01:44, 550.30frames/s]\n 93%|█████████▎| 681728/735993 [27:58<01:34, 571.55frames/s]\n 93%|█████████▎| 684506/735993 [28:03<01:31, 564.79frames/s]\n 93%|█████████▎| 687218/735993 [28:09<01:32, 524.60frames/s]\n 94%|█████████▍| 690038/735993 [28:16<01:32, 495.94frames/s]\n 94%|█████████▍| 692910/735993 [28:21<01:25, 501.57frames/s]\n 95%|█████████▍| 695910/735993 [28:27<01:17, 517.47frames/s]\n 95%|█████████▍| 698910/735993 [28:35<01:19, 464.72frames/s]\n 95%|█████████▌| 701880/735993 [28:39<01:05, 521.86frames/s]\n 96%|█████████▌| 704572/735993 [28:44<00:58, 535.78frames/s]\n 96%|█████████▌| 707496/735993 [28:50<00:57, 495.14frames/s]\n 97%|█████████▋| 710468/735993 [28:56<00:49, 519.68frames/s]\n 97%|█████████▋| 713112/735993 [29:00<00:43, 529.96frames/s]\n 97%|█████████▋| 714660/735993 [29:13<01:04, 329.01frames/s]\n 97%|█████████▋| 717436/735993 [29:18<00:48, 380.69frames/s]\n 98%|█████████▊| 720420/735993 [29:22<00:34, 445.75frames/s]\n 98%|█████████▊| 723128/735993 [29:26<00:25, 495.55frames/s]\n 99%|█████████▊| 725824/735993 [29:30<00:19, 535.21frames/s]\n 99%|█████████▉| 728788/735993 [29:37<00:14, 484.96frames/s]\n 99%|█████████▉| 731628/735993 [29:44<00:09, 477.77frames/s]\n100%|█████████▉| 732993/735993 [29:46<00:06, 480.91frames/s]\n100%|█████████▉| 732993/735993 [29:46<00:07, 410.22frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.47307442455756954,
        "compression_ratio": 1.233644859813084,
        "end": 18.8,
        "id": 0,
        "no_speech_prob": 0.07869530469179153,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " ♪",
        "tokens": [
          50364,
          220,
          158,
          247,
          103,
          51304
        ]
      },
      {
        "avg_logprob": -0.47307442455756954,
        "compression_ratio": 1.233644859813084,
        "end": 22.64,
        "id": 1,
        "no_speech_prob": 0.07869530469179153,
        "seek": 0,
        "start": 18.8,
        "temperature": 0,
        "text": " Hello, good afternoon, good evening, good night, good morning.",
        "tokens": [
          51304,
          2425,
          11,
          665,
          6499,
          11,
          665,
          5634,
          11,
          665,
          1818,
          11,
          665,
          2446,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.47307442455756954,
        "compression_ratio": 1.233644859813084,
        "end": 26.080000000000002,
        "id": 2,
        "no_speech_prob": 0.07869530469179153,
        "seek": 0,
        "start": 22.64,
        "temperature": 0,
        "text": " There are so many time zones all over this world that we live in.",
        "tokens": [
          51496,
          821,
          366,
          370,
          867,
          565,
          16025,
          439,
          670,
          341,
          1002,
          300,
          321,
          1621,
          294,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 31.119999999999997,
        "id": 3,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 26.08,
        "temperature": 0,
        "text": " I have not started today with my mic muted, which is rare,",
        "tokens": [
          50364,
          286,
          362,
          406,
          1409,
          965,
          365,
          452,
          3123,
          32808,
          11,
          597,
          307,
          5892,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 35.44,
        "id": 4,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 31.119999999999997,
        "temperature": 0,
        "text": " because I often start my mic muted and it takes me about five minutes to realize that,",
        "tokens": [
          50616,
          570,
          286,
          2049,
          722,
          452,
          3123,
          32808,
          293,
          309,
          2516,
          385,
          466,
          1732,
          2077,
          281,
          4325,
          300,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 38.96,
        "id": 5,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 35.44,
        "temperature": 0,
        "text": " and then the first five minutes is silence, but you know, today I'm actually speaking to you.",
        "tokens": [
          50832,
          293,
          550,
          264,
          700,
          1732,
          2077,
          307,
          12239,
          11,
          457,
          291,
          458,
          11,
          965,
          286,
          478,
          767,
          4124,
          281,
          291,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 44.239999999999995,
        "id": 6,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 38.96,
        "temperature": 0,
        "text": " It's Friday, I am looking forward to this weekend.",
        "tokens": [
          51008,
          467,
          311,
          6984,
          11,
          286,
          669,
          1237,
          2128,
          281,
          341,
          6711,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 47.76,
        "id": 7,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 44.239999999999995,
        "temperature": 0,
        "text": " Yeah, I mean there's things I could say about that, but that's not what you're here for.",
        "tokens": [
          51272,
          865,
          11,
          286,
          914,
          456,
          311,
          721,
          286,
          727,
          584,
          466,
          300,
          11,
          457,
          300,
          311,
          406,
          437,
          291,
          434,
          510,
          337,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 49.44,
        "id": 8,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 47.76,
        "temperature": 0,
        "text": " It's been a long week, a little bit tired.",
        "tokens": [
          51448,
          467,
          311,
          668,
          257,
          938,
          1243,
          11,
          257,
          707,
          857,
          5868,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.29540562801223863,
        "compression_ratio": 1.707236842105263,
        "end": 54.959999999999994,
        "id": 9,
        "no_speech_prob": 0.02880910038948059,
        "seek": 2608,
        "start": 49.44,
        "temperature": 0,
        "text": " There was already a live stream today with the guest, Nabil Hussain, which I will maybe mention.",
        "tokens": [
          51532,
          821,
          390,
          1217,
          257,
          1621,
          4309,
          965,
          365,
          264,
          8341,
          11,
          426,
          5177,
          389,
          2023,
          491,
          11,
          597,
          286,
          486,
          1310,
          2152,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 65.28,
        "id": 10,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 54.96,
        "temperature": 0,
        "text": " I mean, I'm mentioning it now, but I'm back to continue the threads of last week, earlier this Monday.",
        "tokens": [
          50364,
          286,
          914,
          11,
          286,
          478,
          18315,
          309,
          586,
          11,
          457,
          286,
          478,
          646,
          281,
          2354,
          264,
          19314,
          295,
          1036,
          1243,
          11,
          3071,
          341,
          8138,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 68.08,
        "id": 11,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 65.28,
        "temperature": 0,
        "text": " Let's see, sorry, let me get the chat chicken going here.",
        "tokens": [
          50880,
          961,
          311,
          536,
          11,
          2597,
          11,
          718,
          385,
          483,
          264,
          5081,
          4662,
          516,
          510,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 70.56,
        "id": 12,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 68.08,
        "temperature": 0,
        "text": " All right, so, hi.",
        "tokens": [
          51020,
          1057,
          558,
          11,
          370,
          11,
          4879,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 73.76,
        "id": 13,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 72.08,
        "temperature": 0,
        "text": " I wasn't really ready yet.",
        "tokens": [
          51220,
          286,
          2067,
          380,
          534,
          1919,
          1939,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 76.88,
        "id": 14,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 73.76,
        "temperature": 0,
        "text": " So let me open up a web browser.",
        "tokens": [
          51304,
          407,
          718,
          385,
          1269,
          493,
          257,
          3670,
          11185,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 80.64,
        "id": 15,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 76.88,
        "temperature": 0,
        "text": " I'm completely unprepared for this, as I always am.",
        "tokens": [
          51460,
          286,
          478,
          2584,
          19237,
          45573,
          337,
          341,
          11,
          382,
          286,
          1009,
          669,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.23239034016927082,
        "compression_ratio": 1.5225225225225225,
        "end": 84,
        "id": 16,
        "no_speech_prob": 0.0023956485092639923,
        "seek": 5496,
        "start": 81.36,
        "temperature": 0,
        "text": " Like, I can't even get my web browser to open.",
        "tokens": [
          51684,
          1743,
          11,
          286,
          393,
          380,
          754,
          483,
          452,
          3670,
          11185,
          281,
          1269,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.21410024284136178,
        "compression_ratio": 1.6133333333333333,
        "end": 85.36,
        "id": 17,
        "no_speech_prob": 0.007575748488306999,
        "seek": 8400,
        "start": 84,
        "temperature": 0,
        "text": " This is how unprepared I am.",
        "tokens": [
          50364,
          639,
          307,
          577,
          19237,
          45573,
          286,
          669,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.21410024284136178,
        "compression_ratio": 1.6133333333333333,
        "end": 88.4,
        "id": 18,
        "no_speech_prob": 0.007575748488306999,
        "seek": 8400,
        "start": 86.56,
        "temperature": 0,
        "text": " So if I, let me load later.",
        "tokens": [
          50492,
          407,
          498,
          286,
          11,
          718,
          385,
          3677,
          1780,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.21410024284136178,
        "compression_ratio": 1.6133333333333333,
        "end": 90,
        "id": 19,
        "no_speech_prob": 0.007575748488306999,
        "seek": 8400,
        "start": 88.4,
        "temperature": 0,
        "text": " I don't want to try Safari, thank you.",
        "tokens": [
          50584,
          286,
          500,
          380,
          528,
          281,
          853,
          43820,
          11,
          1309,
          291,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21410024284136178,
        "compression_ratio": 1.6133333333333333,
        "end": 98.64,
        "id": 20,
        "no_speech_prob": 0.007575748488306999,
        "seek": 8400,
        "start": 91.2,
        "temperature": 0,
        "text": " If I go to this YouTube channel called The Coding Train, there's an upcoming live stream and one right now.",
        "tokens": [
          50724,
          759,
          286,
          352,
          281,
          341,
          3088,
          2269,
          1219,
          440,
          383,
          8616,
          28029,
          11,
          456,
          311,
          364,
          11500,
          1621,
          4309,
          293,
          472,
          558,
          586,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.21410024284136178,
        "compression_ratio": 1.6133333333333333,
        "end": 101.36,
        "id": 21,
        "no_speech_prob": 0.007575748488306999,
        "seek": 8400,
        "start": 98.64,
        "temperature": 0,
        "text": " That's interesting, but this is what I wanted to refer to.",
        "tokens": [
          51096,
          663,
          311,
          1880,
          11,
          457,
          341,
          307,
          437,
          286,
          1415,
          281,
          2864,
          281,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.21410024284136178,
        "compression_ratio": 1.6133333333333333,
        "end": 110.16,
        "id": 22,
        "no_speech_prob": 0.007575748488306999,
        "seek": 8400,
        "start": 102.64,
        "temperature": 0,
        "text": " So this morning, this live stream happened this morning, which was a live stream sponsored by Spell,",
        "tokens": [
          51296,
          407,
          341,
          2446,
          11,
          341,
          1621,
          4309,
          2011,
          341,
          2446,
          11,
          597,
          390,
          257,
          1621,
          4309,
          16621,
          538,
          3550,
          285,
          11,
          51672
        ]
      },
      {
        "avg_logprob": -0.21124124089512256,
        "compression_ratio": 1.6731517509727627,
        "end": 117.44,
        "id": 23,
        "no_speech_prob": 0.008710087276995182,
        "seek": 11016,
        "start": 110.16,
        "temperature": 0,
        "text": " which is a cloud computing service, and guest Nabil Hussain trained a LSTM neural network,",
        "tokens": [
          50364,
          597,
          307,
          257,
          4588,
          15866,
          2643,
          11,
          293,
          8341,
          426,
          5177,
          389,
          2023,
          491,
          8895,
          257,
          441,
          6840,
          44,
          18161,
          3209,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.21124124089512256,
        "compression_ratio": 1.6731517509727627,
        "end": 124.32,
        "id": 24,
        "no_speech_prob": 0.008710087276995182,
        "seek": 11016,
        "start": 117.44,
        "temperature": 0,
        "text": " which is a kind of neural network that's well-suited for sequences, trained a model on text.",
        "tokens": [
          50728,
          597,
          307,
          257,
          733,
          295,
          18161,
          3209,
          300,
          311,
          731,
          12,
          15091,
          1226,
          337,
          22978,
          11,
          8895,
          257,
          2316,
          322,
          2487,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.21124124089512256,
        "compression_ratio": 1.6731517509727627,
        "end": 130,
        "id": 25,
        "no_speech_prob": 0.008710087276995182,
        "seek": 11016,
        "start": 124.32,
        "temperature": 0,
        "text": " So text from an author, in this case, a rapper, was used, song lyrics were used.",
        "tokens": [
          51072,
          407,
          2487,
          490,
          364,
          3793,
          11,
          294,
          341,
          1389,
          11,
          257,
          26457,
          11,
          390,
          1143,
          11,
          2153,
          12189,
          645,
          1143,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.21124124089512256,
        "compression_ratio": 1.6731517509727627,
        "end": 136.24,
        "id": 26,
        "no_speech_prob": 0.008710087276995182,
        "seek": 11016,
        "start": 130.88,
        "temperature": 0,
        "text": " The model was trained, and then after that was completed, that model was brought into JavaScript,",
        "tokens": [
          51400,
          440,
          2316,
          390,
          8895,
          11,
          293,
          550,
          934,
          300,
          390,
          7365,
          11,
          300,
          2316,
          390,
          3038,
          666,
          15778,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.21124124089512256,
        "compression_ratio": 1.6731517509727627,
        "end": 139.76,
        "id": 27,
        "no_speech_prob": 0.008710087276995182,
        "seek": 11016,
        "start": 136.24,
        "temperature": 0,
        "text": " into the browser, and can be interacted with generating new lyrics.",
        "tokens": [
          51668,
          666,
          264,
          11185,
          11,
          293,
          393,
          312,
          49621,
          365,
          17746,
          777,
          12189,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.2484922014977321,
        "compression_ratio": 1.607773851590106,
        "end": 143.28,
        "id": 28,
        "no_speech_prob": 0.0005975911626592278,
        "seek": 13976,
        "start": 139.92,
        "temperature": 0,
        "text": " So if you're interested in that, you can check out the live stream from this morning.",
        "tokens": [
          50372,
          407,
          498,
          291,
          434,
          3102,
          294,
          300,
          11,
          291,
          393,
          1520,
          484,
          264,
          1621,
          4309,
          490,
          341,
          2446,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.2484922014977321,
        "compression_ratio": 1.607773851590106,
        "end": 147.04,
        "id": 29,
        "no_speech_prob": 0.0005975911626592278,
        "seek": 13976,
        "start": 143.84,
        "temperature": 0,
        "text": " We did have some technical difficulty a few times here and there,",
        "tokens": [
          50568,
          492,
          630,
          362,
          512,
          6191,
          10360,
          257,
          1326,
          1413,
          510,
          293,
          456,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.2484922014977321,
        "compression_ratio": 1.607773851590106,
        "end": 150.39999999999998,
        "id": 30,
        "no_speech_prob": 0.0005975911626592278,
        "seek": 13976,
        "start": 147.04,
        "temperature": 0,
        "text": " so at some point I'll probably be producing an edited version of that.",
        "tokens": [
          50728,
          370,
          412,
          512,
          935,
          286,
          603,
          1391,
          312,
          10501,
          364,
          23016,
          3037,
          295,
          300,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2484922014977321,
        "compression_ratio": 1.607773851590106,
        "end": 152.64,
        "id": 31,
        "no_speech_prob": 0.0005975911626592278,
        "seek": 13976,
        "start": 150.39999999999998,
        "temperature": 0,
        "text": " It was actually only, it was only 58 minutes.",
        "tokens": [
          50896,
          467,
          390,
          767,
          787,
          11,
          309,
          390,
          787,
          21786,
          2077,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.2484922014977321,
        "compression_ratio": 1.607773851590106,
        "end": 156.07999999999998,
        "id": 32,
        "no_speech_prob": 0.0005975911626592278,
        "seek": 13976,
        "start": 152.64,
        "temperature": 0,
        "text": " My guess is the edited version will be like 35 or 40 minutes, something like that.",
        "tokens": [
          51008,
          1222,
          2041,
          307,
          264,
          23016,
          3037,
          486,
          312,
          411,
          6976,
          420,
          3356,
          2077,
          11,
          746,
          411,
          300,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2484922014977321,
        "compression_ratio": 1.607773851590106,
        "end": 164.39999999999998,
        "id": 33,
        "no_speech_prob": 0.0005975911626592278,
        "seek": 13976,
        "start": 156.95999999999998,
        "temperature": 0,
        "text": " And Rui in the chat, ah, Rui, Rui Gamer, who was watching me, my other channel that I will not mention.",
        "tokens": [
          51224,
          400,
          497,
          3077,
          294,
          264,
          5081,
          11,
          3716,
          11,
          497,
          3077,
          11,
          497,
          3077,
          460,
          13530,
          11,
          567,
          390,
          1976,
          385,
          11,
          452,
          661,
          2269,
          300,
          286,
          486,
          406,
          2152,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 167.76000000000002,
        "id": 34,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 164.72,
        "temperature": 0,
        "text": " The secret laptop, it's not so secret, right?",
        "tokens": [
          50380,
          440,
          4054,
          10732,
          11,
          309,
          311,
          406,
          370,
          4054,
          11,
          558,
          30,
          50532
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 168.32,
        "id": 35,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 167.76000000000002,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          50532,
          1692,
          309,
          307,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 172.24,
        "id": 36,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 170.08,
        "temperature": 0,
        "text": " It's not that I want this laptop to be secret,",
        "tokens": [
          50648,
          467,
          311,
          406,
          300,
          286,
          528,
          341,
          10732,
          281,
          312,
          4054,
          11,
          50756
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 175.76,
        "id": 37,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 172.24,
        "temperature": 0,
        "text": " it's that it's just too many things blocking the way.",
        "tokens": [
          50756,
          309,
          311,
          300,
          309,
          311,
          445,
          886,
          867,
          721,
          17776,
          264,
          636,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 180.48000000000002,
        "id": 38,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 175.76,
        "temperature": 0,
        "text": " But what was I talking about?",
        "tokens": [
          50932,
          583,
          437,
          390,
          286,
          1417,
          466,
          30,
          51168
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 181.28,
        "id": 39,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 180.48000000000002,
        "temperature": 0,
        "text": " Does anybody remember?",
        "tokens": [
          51168,
          4402,
          4472,
          1604,
          30,
          51208
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 187.12,
        "id": 40,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 186.08,
        "temperature": 0,
        "text": " I'm so tired.",
        "tokens": [
          51448,
          286,
          478,
          370,
          5868,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.46745174687083174,
        "compression_ratio": 1.5093167701863355,
        "end": 188.24,
        "id": 41,
        "no_speech_prob": 0.0665387213230133,
        "seek": 16440,
        "start": 187.12,
        "temperature": 0,
        "text": " Oh, I'm so tired.",
        "tokens": [
          51500,
          876,
          11,
          286,
          478,
          370,
          5868,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.26367777774208473,
        "compression_ratio": 1.5404040404040404,
        "end": 189.28,
        "id": 42,
        "no_speech_prob": 0.003765282453969121,
        "seek": 18824,
        "start": 188.32000000000002,
        "temperature": 0,
        "text": " I'm so tired.",
        "tokens": [
          50368,
          286,
          478,
          370,
          5868,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.26367777774208473,
        "compression_ratio": 1.5404040404040404,
        "end": 190.96,
        "id": 43,
        "no_speech_prob": 0.003765282453969121,
        "seek": 18824,
        "start": 189.28,
        "temperature": 0,
        "text": " Oh, I'm so tired.",
        "tokens": [
          50416,
          876,
          11,
          286,
          478,
          370,
          5868,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.26367777774208473,
        "compression_ratio": 1.5404040404040404,
        "end": 196.88,
        "id": 44,
        "no_speech_prob": 0.003765282453969121,
        "seek": 18824,
        "start": 195.12,
        "temperature": 0,
        "text": " All right, but I'm on a mission here.",
        "tokens": [
          50708,
          1057,
          558,
          11,
          457,
          286,
          478,
          322,
          257,
          4447,
          510,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.26367777774208473,
        "compression_ratio": 1.5404040404040404,
        "end": 205.92000000000002,
        "id": 45,
        "no_speech_prob": 0.003765282453969121,
        "seek": 18824,
        "start": 197.84,
        "temperature": 0,
        "text": " None of the, last on Monday, earlier this week, here it is, Mastodon trying again.",
        "tokens": [
          50844,
          14492,
          295,
          264,
          11,
          1036,
          322,
          8138,
          11,
          3071,
          341,
          1243,
          11,
          510,
          309,
          307,
          11,
          376,
          525,
          378,
          266,
          1382,
          797,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.26367777774208473,
        "compression_ratio": 1.5404040404040404,
        "end": 212.24,
        "id": 46,
        "no_speech_prob": 0.003765282453969121,
        "seek": 18824,
        "start": 205.92000000000002,
        "temperature": 0,
        "text": " I spent two and a half hours creating a Mastodon bot, talking about what Mastodon is,",
        "tokens": [
          51248,
          286,
          4418,
          732,
          293,
          257,
          1922,
          2496,
          4084,
          257,
          376,
          525,
          378,
          266,
          10592,
          11,
          1417,
          466,
          437,
          376,
          525,
          378,
          266,
          307,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.26367777774208473,
        "compression_ratio": 1.5404040404040404,
        "end": 216.88,
        "id": 47,
        "no_speech_prob": 0.003765282453969121,
        "seek": 18824,
        "start": 212.24,
        "temperature": 0,
        "text": " which is an open source, decentralized social networking platform.",
        "tokens": [
          51564,
          597,
          307,
          364,
          1269,
          4009,
          11,
          32870,
          2093,
          17985,
          3663,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 221.68,
        "id": 48,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 217.76,
        "temperature": 0,
        "text": " I created my own instance called choochoo.space.",
        "tokens": [
          50408,
          286,
          2942,
          452,
          1065,
          5197,
          1219,
          1586,
          78,
          339,
          1986,
          13,
          24824,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 222.56,
        "id": 49,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 221.68,
        "temperature": 0,
        "text": " It's still there.",
        "tokens": [
          50604,
          467,
          311,
          920,
          456,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 228.88,
        "id": 50,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 224.07999999999998,
        "temperature": 0,
        "text": " Koji, member of choochoo.space, has posted this wonderful picture of a koala.",
        "tokens": [
          50724,
          10509,
          4013,
          11,
          4006,
          295,
          1586,
          8997,
          1986,
          13,
          24824,
          11,
          575,
          9437,
          341,
          3715,
          3036,
          295,
          257,
          8384,
          5159,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 232.07999999999998,
        "id": 51,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 230.24,
        "temperature": 0,
        "text": " Okay, we are totally using this picture.",
        "tokens": [
          51032,
          1033,
          11,
          321,
          366,
          3879,
          1228,
          341,
          3036,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 235.76,
        "id": 52,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 234.4,
        "temperature": 0,
        "text": " No, wait, how do I get this image?",
        "tokens": [
          51240,
          883,
          11,
          1699,
          11,
          577,
          360,
          286,
          483,
          341,
          3256,
          30,
          51308
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 237.12,
        "id": 53,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 235.76,
        "temperature": 0,
        "text": " Copy image address, maybe.",
        "tokens": [
          51308,
          25653,
          3256,
          2985,
          11,
          1310,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 242.32,
        "id": 54,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 237.92,
        "temperature": 0,
        "text": " Yes, okay, thank you, Koji, for somehow knowing that I could use an image of a koala.",
        "tokens": [
          51416,
          1079,
          11,
          1392,
          11,
          1309,
          291,
          11,
          10509,
          4013,
          11,
          337,
          6063,
          5276,
          300,
          286,
          727,
          764,
          364,
          3256,
          295,
          257,
          8384,
          5159,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.19595516237438235,
        "compression_ratio": 1.5905172413793103,
        "end": 244.72,
        "id": 55,
        "no_speech_prob": 0.00016092964506242424,
        "seek": 21688,
        "start": 243.04,
        "temperature": 0,
        "text": " Koala, let's put it on the desktop.",
        "tokens": [
          51672,
          10509,
          5159,
          11,
          718,
          311,
          829,
          309,
          322,
          264,
          14502,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.22491506576538087,
        "compression_ratio": 1.5223880597014925,
        "end": 251.35999999999999,
        "id": 56,
        "no_speech_prob": 0.000009080461495614145,
        "seek": 24688,
        "start": 247.84,
        "temperature": 0,
        "text": " Okay, I don't know if we're really going to use this, but I'm saving it for later.",
        "tokens": [
          50412,
          1033,
          11,
          286,
          500,
          380,
          458,
          498,
          321,
          434,
          534,
          516,
          281,
          764,
          341,
          11,
          457,
          286,
          478,
          6816,
          309,
          337,
          1780,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.22491506576538087,
        "compression_ratio": 1.5223880597014925,
        "end": 259.36,
        "id": 57,
        "no_speech_prob": 0.000009080461495614145,
        "seek": 24688,
        "start": 253.68,
        "temperature": 0,
        "text": " And Magikarp over here is talking about, nice to see Shiffman talk about Mastodon.",
        "tokens": [
          50704,
          400,
          6395,
          1035,
          6529,
          670,
          510,
          307,
          1417,
          466,
          11,
          1481,
          281,
          536,
          1160,
          3661,
          1601,
          751,
          466,
          376,
          525,
          378,
          266,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.22491506576538087,
        "compression_ratio": 1.5223880597014925,
        "end": 260.48,
        "id": 58,
        "no_speech_prob": 0.000009080461495614145,
        "seek": 24688,
        "start": 259.36,
        "temperature": 0,
        "text": " Okay, thank you.",
        "tokens": [
          50988,
          1033,
          11,
          1309,
          291,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.22491506576538087,
        "compression_ratio": 1.5223880597014925,
        "end": 268.15999999999997,
        "id": 59,
        "no_speech_prob": 0.000009080461495614145,
        "seek": 24688,
        "start": 261.52,
        "temperature": 0,
        "text": " All right, so this is Mastodon, and the instance that I'm using with my coding train bot is",
        "tokens": [
          51096,
          1057,
          558,
          11,
          370,
          341,
          307,
          376,
          525,
          378,
          266,
          11,
          293,
          264,
          5197,
          300,
          286,
          478,
          1228,
          365,
          452,
          17720,
          3847,
          10592,
          307,
          51428
        ]
      },
      {
        "avg_logprob": -0.22491506576538087,
        "compression_ratio": 1.5223880597014925,
        "end": 270.32,
        "id": 60,
        "no_speech_prob": 0.000009080461495614145,
        "seek": 24688,
        "start": 268.15999999999997,
        "temperature": 0,
        "text": " Mastodon.space.",
        "tokens": [
          51428,
          376,
          525,
          378,
          266,
          13,
          24824,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.22491506576538087,
        "compression_ratio": 1.5223880597014925,
        "end": 273.12,
        "id": 61,
        "no_speech_prob": 0.000009080461495614145,
        "seek": 24688,
        "start": 272,
        "temperature": 0,
        "text": " Bots and space.",
        "tokens": [
          51620,
          47224,
          293,
          1901,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.24129689204228388,
        "compression_ratio": 1.6021505376344085,
        "end": 277.6,
        "id": 62,
        "no_speech_prob": 0.00648803124204278,
        "seek": 27312,
        "start": 273.12,
        "temperature": 0,
        "text": " Sometimes the words keep coming out of my mouth, but my brain completely shut off.",
        "tokens": [
          50364,
          4803,
          264,
          2283,
          1066,
          1348,
          484,
          295,
          452,
          4525,
          11,
          457,
          452,
          3567,
          2584,
          5309,
          766,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.24129689204228388,
        "compression_ratio": 1.6021505376344085,
        "end": 281.2,
        "id": 63,
        "no_speech_prob": 0.00648803124204278,
        "seek": 27312,
        "start": 277.6,
        "temperature": 0,
        "text": " My brain completely shut off, and words just kept coming because I'm live streaming,",
        "tokens": [
          50588,
          1222,
          3567,
          2584,
          5309,
          766,
          11,
          293,
          2283,
          445,
          4305,
          1348,
          570,
          286,
          478,
          1621,
          11791,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.24129689204228388,
        "compression_ratio": 1.6021505376344085,
        "end": 283.6,
        "id": 64,
        "no_speech_prob": 0.00648803124204278,
        "seek": 27312,
        "start": 281.2,
        "temperature": 0,
        "text": " and I feel like if I stop talking, there'll be silence.",
        "tokens": [
          50768,
          293,
          286,
          841,
          411,
          498,
          286,
          1590,
          1417,
          11,
          456,
          603,
          312,
          12239,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.24129689204228388,
        "compression_ratio": 1.6021505376344085,
        "end": 286.56,
        "id": 65,
        "no_speech_prob": 0.00648803124204278,
        "seek": 27312,
        "start": 283.6,
        "temperature": 0,
        "text": " But what would be the worst thing about silence?",
        "tokens": [
          50888,
          583,
          437,
          576,
          312,
          264,
          5855,
          551,
          466,
          12239,
          30,
          51036
        ]
      },
      {
        "avg_logprob": -0.24129689204228388,
        "compression_ratio": 1.6021505376344085,
        "end": 302.08,
        "id": 66,
        "no_speech_prob": 0.00648803124204278,
        "seek": 27312,
        "start": 300.64,
        "temperature": 0,
        "text": " All right, that was good.",
        "tokens": [
          51740,
          1057,
          558,
          11,
          300,
          390,
          665,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 303.35999999999996,
        "id": 67,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 302.15999999999997,
        "temperature": 0,
        "text": " A little moment of silence there.",
        "tokens": [
          50368,
          316,
          707,
          1623,
          295,
          12239,
          456,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 305.52,
        "id": 68,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 304.47999999999996,
        "temperature": 0,
        "text": " I feel refreshed.",
        "tokens": [
          50484,
          286,
          841,
          46330,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 306.15999999999997,
        "id": 69,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 305.52,
        "temperature": 0,
        "text": " How do you feel?",
        "tokens": [
          50536,
          1012,
          360,
          291,
          841,
          30,
          50568
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 317.52,
        "id": 70,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 309.59999999999997,
        "temperature": 0,
        "text": " I'm trying to decide if this makes sense to be a coding challenge like Mastodon image bot,",
        "tokens": [
          50740,
          286,
          478,
          1382,
          281,
          4536,
          498,
          341,
          1669,
          2020,
          281,
          312,
          257,
          17720,
          3430,
          411,
          376,
          525,
          378,
          266,
          3256,
          10592,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 318.64,
        "id": 71,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 317.52,
        "temperature": 0,
        "text": " processing image bot.",
        "tokens": [
          51136,
          9007,
          3256,
          10592,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 323.2,
        "id": 72,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 318.64,
        "temperature": 0,
        "text": " One of the things I love about this example that I'm going to do today is it brings so",
        "tokens": [
          51192,
          1485,
          295,
          264,
          721,
          286,
          959,
          466,
          341,
          1365,
          300,
          286,
          478,
          516,
          281,
          360,
          965,
          307,
          309,
          5607,
          370,
          51420
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 324.15999999999997,
        "id": 73,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 323.2,
        "temperature": 0,
        "text": " many things together.",
        "tokens": [
          51420,
          867,
          721,
          1214,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.20579372262055018,
        "compression_ratio": 1.6160337552742616,
        "end": 331.68,
        "id": 74,
        "no_speech_prob": 0.0008295855950564146,
        "seek": 30208,
        "start": 325.03999999999996,
        "temperature": 0,
        "text": " Brings together APIs, and Node, and JavaScript, and asynchronous, and I'm going to use async",
        "tokens": [
          51512,
          1603,
          1109,
          1214,
          21445,
          11,
          293,
          38640,
          11,
          293,
          15778,
          11,
          293,
          49174,
          11,
          293,
          286,
          478,
          516,
          281,
          764,
          382,
          34015,
          51844
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 337.68,
        "id": 75,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 331.68,
        "temperature": 0,
        "text": " and await, which is like ES8 JavaScript syntax, and processing, and creating images, and shell",
        "tokens": [
          50364,
          293,
          19670,
          11,
          597,
          307,
          411,
          12564,
          23,
          15778,
          28431,
          11,
          293,
          9007,
          11,
          293,
          4084,
          5267,
          11,
          293,
          8720,
          50664
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 338.24,
        "id": 76,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 337.68,
        "temperature": 0,
        "text": " scripting.",
        "tokens": [
          50664,
          5755,
          278,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 340.64,
        "id": 77,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 338.24,
        "temperature": 0,
        "text": " Oh, so many pieces together into one project.",
        "tokens": [
          50692,
          876,
          11,
          370,
          867,
          3755,
          1214,
          666,
          472,
          1716,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 344.88,
        "id": 78,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 340.64,
        "temperature": 0,
        "text": " The project that I'm going to build is a project that starts with a processing sketch.",
        "tokens": [
          50812,
          440,
          1716,
          300,
          286,
          478,
          516,
          281,
          1322,
          307,
          257,
          1716,
          300,
          3719,
          365,
          257,
          9007,
          12325,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 347.76,
        "id": 79,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 344.88,
        "temperature": 0,
        "text": " Let's see how recent this version of processing I have is.",
        "tokens": [
          51024,
          961,
          311,
          536,
          577,
          5162,
          341,
          3037,
          295,
          9007,
          286,
          362,
          307,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 351.92,
        "id": 80,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 350.48,
        "temperature": 0,
        "text": " 3.4, that's perfect.",
        "tokens": [
          51304,
          805,
          13,
          19,
          11,
          300,
          311,
          2176,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 353.36,
        "id": 81,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 351.92,
        "temperature": 0,
        "text": " Starts with a processing sketch.",
        "tokens": [
          51376,
          6481,
          82,
          365,
          257,
          9007,
          12325,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 358.16,
        "id": 82,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 355.52,
        "temperature": 0,
        "text": " From Node, executes the processing sketch.",
        "tokens": [
          51556,
          3358,
          38640,
          11,
          4454,
          1819,
          264,
          9007,
          12325,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.18841003749681556,
        "compression_ratio": 1.7925311203319503,
        "end": 360.24,
        "id": 83,
        "no_speech_prob": 0.002631634473800659,
        "seek": 33168,
        "start": 358.16,
        "temperature": 0,
        "text": " The processing sketch saves an image.",
        "tokens": [
          51688,
          440,
          9007,
          12325,
          19155,
          364,
          3256,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.18395787477493286,
        "compression_ratio": 1.5527638190954773,
        "end": 369.84000000000003,
        "id": 84,
        "no_speech_prob": 0.006097313016653061,
        "seek": 36024,
        "start": 360.24,
        "temperature": 0,
        "text": " Node grabs the image, uploads it to Mastodon media server, then posts a toot to Mastodon",
        "tokens": [
          50364,
          38640,
          30028,
          264,
          3256,
          11,
          48611,
          309,
          281,
          376,
          525,
          378,
          266,
          3021,
          7154,
          11,
          550,
          12300,
          257,
          281,
          310,
          281,
          376,
          525,
          378,
          266,
          50844
        ]
      },
      {
        "avg_logprob": -0.18395787477493286,
        "compression_ratio": 1.5527638190954773,
        "end": 370.64,
        "id": 85,
        "no_speech_prob": 0.006097313016653061,
        "seek": 36024,
        "start": 369.84000000000003,
        "temperature": 0,
        "text": " referencing the image.",
        "tokens": [
          50844,
          40582,
          264,
          3256,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.18395787477493286,
        "compression_ratio": 1.5527638190954773,
        "end": 377.04,
        "id": 86,
        "no_speech_prob": 0.006097313016653061,
        "seek": 36024,
        "start": 370.64,
        "temperature": 0,
        "text": " So if we look at bots in space, one of my favorite, let's look at the local timeline.",
        "tokens": [
          50884,
          407,
          498,
          321,
          574,
          412,
          35410,
          294,
          1901,
          11,
          472,
          295,
          452,
          2954,
          11,
          718,
          311,
          574,
          412,
          264,
          2654,
          12933,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.18395787477493286,
        "compression_ratio": 1.5527638190954773,
        "end": 383.36,
        "id": 87,
        "no_speech_prob": 0.006097313016653061,
        "seek": 36024,
        "start": 378.08,
        "temperature": 0,
        "text": " This is nice, it's posting GIFs, but I really like the tree.",
        "tokens": [
          51256,
          639,
          307,
          1481,
          11,
          309,
          311,
          15978,
          460,
          12775,
          82,
          11,
          457,
          286,
          534,
          411,
          264,
          4230,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.18395787477493286,
        "compression_ratio": 1.5527638190954773,
        "end": 387.84000000000003,
        "id": 88,
        "no_speech_prob": 0.006097313016653061,
        "seek": 36024,
        "start": 383.36,
        "temperature": 0,
        "text": " How do I find, let's see if I search for tree bot.",
        "tokens": [
          51520,
          1012,
          360,
          286,
          915,
          11,
          718,
          311,
          536,
          498,
          286,
          3164,
          337,
          4230,
          10592,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 393.44,
        "id": 89,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 388.47999999999996,
        "temperature": 0,
        "text": " I think I can actually just go to bots in space, like if I went to kubestorm, oh, it",
        "tokens": [
          50396,
          286,
          519,
          286,
          393,
          767,
          445,
          352,
          281,
          35410,
          294,
          1901,
          11,
          411,
          498,
          286,
          1437,
          281,
          350,
          836,
          377,
          687,
          11,
          1954,
          11,
          309,
          50644
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 395.59999999999997,
        "id": 90,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 393.44,
        "temperature": 0,
        "text": " would be kubestorm.",
        "tokens": [
          50644,
          576,
          312,
          350,
          836,
          377,
          687,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 396.64,
        "id": 91,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 395.59999999999997,
        "temperature": 0,
        "text": " Oh, interesting.",
        "tokens": [
          50752,
          876,
          11,
          1880,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 400.88,
        "id": 92,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 396.64,
        "temperature": 0,
        "text": " The URL for an account is its number, so I can't simply just know the name of it.",
        "tokens": [
          50804,
          440,
          12905,
          337,
          364,
          2696,
          307,
          1080,
          1230,
          11,
          370,
          286,
          393,
          380,
          2935,
          445,
          458,
          264,
          1315,
          295,
          309,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 405.59999999999997,
        "id": 93,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 402.08,
        "temperature": 0,
        "text": " But let me say tree bot at bots in dot space.",
        "tokens": [
          51076,
          583,
          718,
          385,
          584,
          4230,
          10592,
          412,
          35410,
          294,
          5893,
          1901,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 407.28,
        "id": 94,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 405.59999999999997,
        "temperature": 0,
        "text": " Will this find it for me?",
        "tokens": [
          51252,
          3099,
          341,
          915,
          309,
          337,
          385,
          30,
          51336
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 411.59999999999997,
        "id": 95,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 408.08,
        "temperature": 0,
        "text": " Here is the, yeah, there we go.",
        "tokens": [
          51376,
          1692,
          307,
          264,
          11,
          1338,
          11,
          456,
          321,
          352,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.3926667999802974,
        "compression_ratio": 1.5044642857142858,
        "end": 413.67999999999995,
        "id": 96,
        "no_speech_prob": 0.0003199951897840947,
        "seek": 38784,
        "start": 412.32,
        "temperature": 0,
        "text": " No, I don't want to email it.",
        "tokens": [
          51588,
          883,
          11,
          286,
          500,
          380,
          528,
          281,
          3796,
          309,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 416.88,
        "id": 97,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 414.16,
        "temperature": 0,
        "text": " Don't know how this, here we go, random trees.",
        "tokens": [
          50388,
          1468,
          380,
          458,
          577,
          341,
          11,
          510,
          321,
          352,
          11,
          4974,
          5852,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 418.48,
        "id": 98,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 416.88,
        "temperature": 0,
        "text": " Oh, no, I can just do this.",
        "tokens": [
          50524,
          876,
          11,
          572,
          11,
          286,
          393,
          445,
          360,
          341,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 421.2,
        "id": 99,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 418.48,
        "temperature": 0,
        "text": " So I can do this, tree bot, there we go.",
        "tokens": [
          50604,
          407,
          286,
          393,
          360,
          341,
          11,
          4230,
          10592,
          11,
          456,
          321,
          352,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 424,
        "id": 100,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 422,
        "temperature": 0,
        "text": " No, no.",
        "tokens": [
          50780,
          883,
          11,
          572,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 434.32,
        "id": 101,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 432.72,
        "temperature": 0,
        "text": " Oh, it is random trees.",
        "tokens": [
          51316,
          876,
          11,
          309,
          307,
          4974,
          5852,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 436.32,
        "id": 102,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 434.32,
        "temperature": 0,
        "text": " It's random trees, random trees.",
        "tokens": [
          51396,
          467,
          311,
          4974,
          5852,
          11,
          4974,
          5852,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.5032004820994842,
        "compression_ratio": 1.6,
        "end": 437.36,
        "id": 103,
        "no_speech_prob": 0.009412386454641819,
        "seek": 41368,
        "start": 436.32,
        "temperature": 0,
        "text": " I'm like a lunatic.",
        "tokens": [
          51496,
          286,
          478,
          411,
          257,
          19039,
          2399,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 440.48,
        "id": 104,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 437.6,
        "temperature": 0,
        "text": " All along, oh, this is a different bot.",
        "tokens": [
          50376,
          1057,
          2051,
          11,
          1954,
          11,
          341,
          307,
          257,
          819,
          10592,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 442.48,
        "id": 105,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 441.04,
        "temperature": 0,
        "text": " This is totally a different bot.",
        "tokens": [
          50548,
          639,
          307,
          3879,
          257,
          819,
          10592,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 444.64,
        "id": 106,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 442.48,
        "temperature": 0,
        "text": " You know the one I was looking for, the fractal tree one?",
        "tokens": [
          50620,
          509,
          458,
          264,
          472,
          286,
          390,
          1237,
          337,
          11,
          264,
          17948,
          304,
          4230,
          472,
          30,
          50728
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 447.68,
        "id": 107,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 446.64,
        "temperature": 0,
        "text": " Nobody will tell me.",
        "tokens": [
          50828,
          9297,
          486,
          980,
          385,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 453.12,
        "id": 108,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 450.16,
        "temperature": 0,
        "text": " All right, yes, mastodon again, because it's not mastodon again.",
        "tokens": [
          51004,
          1057,
          558,
          11,
          2086,
          11,
          27055,
          378,
          266,
          797,
          11,
          570,
          309,
          311,
          406,
          27055,
          378,
          266,
          797,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 454.8,
        "id": 109,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 453.12,
        "temperature": 0,
        "text": " So what should this be?",
        "tokens": [
          51152,
          407,
          437,
          820,
          341,
          312,
          30,
          51236
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 460.40000000000003,
        "id": 110,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 454.8,
        "temperature": 0,
        "text": " A, oh, it's a mastodon again.",
        "tokens": [
          51236,
          316,
          11,
          1954,
          11,
          309,
          311,
          257,
          27055,
          378,
          266,
          797,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 461.44,
        "id": 111,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 460.40000000000003,
        "temperature": 0,
        "text": " It's a mastodon again.",
        "tokens": [
          51516,
          467,
          311,
          257,
          27055,
          378,
          266,
          797,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.6093006993199254,
        "compression_ratio": 1.8265895953757225,
        "end": 462.40000000000003,
        "id": 112,
        "no_speech_prob": 0.009708119556307793,
        "seek": 43736,
        "start": 461.44,
        "temperature": 0,
        "text": " It's a mastodon again.",
        "tokens": [
          51568,
          467,
          311,
          257,
          27055,
          378,
          266,
          797,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 463.44,
        "id": 113,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 462.47999999999996,
        "temperature": 0,
        "text": " What should this be?",
        "tokens": [
          50368,
          708,
          820,
          341,
          312,
          30,
          50416
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 468.08,
        "id": 114,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 467.2,
        "temperature": 0,
        "text": " It doesn't really matter.",
        "tokens": [
          50604,
          467,
          1177,
          380,
          534,
          1871,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 468.96,
        "id": 115,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 468.08,
        "temperature": 0,
        "text": " I'm making the video.",
        "tokens": [
          50648,
          286,
          478,
          1455,
          264,
          960,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 472.64,
        "id": 116,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 470.15999999999997,
        "temperature": 0,
        "text": " I think I like the idea of trying this as a coding challenge.",
        "tokens": [
          50752,
          286,
          519,
          286,
          411,
          264,
          1558,
          295,
          1382,
          341,
          382,
          257,
          17720,
          3430,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 476.79999999999995,
        "id": 117,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 474.23999999999995,
        "temperature": 0,
        "text": " Tree bot, there's a different tree bot.",
        "tokens": [
          50956,
          22291,
          10592,
          11,
          456,
          311,
          257,
          819,
          4230,
          10592,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 484.15999999999997,
        "id": 118,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 480.96,
        "temperature": 0,
        "text": " Hold on, how many bots could there be on bots in space?",
        "tokens": [
          51292,
          6962,
          322,
          11,
          577,
          867,
          35410,
          727,
          456,
          312,
          322,
          35410,
          294,
          1901,
          30,
          51452
        ]
      },
      {
        "avg_logprob": -0.24522062448354867,
        "compression_ratio": 1.4885057471264367,
        "end": 487.67999999999995,
        "id": 119,
        "no_speech_prob": 0.004331454634666443,
        "seek": 46240,
        "start": 485.2,
        "temperature": 0,
        "text": " Just humor me for a minute here.",
        "tokens": [
          51504,
          1449,
          14318,
          385,
          337,
          257,
          3456,
          510,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.24591018904500933,
        "compression_ratio": 1.3557046979865772,
        "end": 497.35999999999996,
        "id": 120,
        "no_speech_prob": 0.0015487418277189136,
        "seek": 49240,
        "start": 493.03999999999996,
        "temperature": 0,
        "text": " I feel like it posts pretty often, the one that I'm thinking of.",
        "tokens": [
          50396,
          286,
          841,
          411,
          309,
          12300,
          1238,
          2049,
          11,
          264,
          472,
          300,
          286,
          478,
          1953,
          295,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.24591018904500933,
        "compression_ratio": 1.3557046979865772,
        "end": 503.84,
        "id": 121,
        "no_speech_prob": 0.0015487418277189136,
        "seek": 49240,
        "start": 502.08,
        "temperature": 0,
        "text": " All right, I'm going to give up in a second.",
        "tokens": [
          50848,
          1057,
          558,
          11,
          286,
          478,
          516,
          281,
          976,
          493,
          294,
          257,
          1150,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.24591018904500933,
        "compression_ratio": 1.3557046979865772,
        "end": 507.44,
        "id": 122,
        "no_speech_prob": 0.0015487418277189136,
        "seek": 49240,
        "start": 505.52,
        "temperature": 0,
        "text": " Oh, I like this one, emoji DNA.",
        "tokens": [
          51020,
          876,
          11,
          286,
          411,
          341,
          472,
          11,
          31595,
          8272,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.24591018904500933,
        "compression_ratio": 1.3557046979865772,
        "end": 508.32,
        "id": 123,
        "no_speech_prob": 0.0015487418277189136,
        "seek": 49240,
        "start": 507.44,
        "temperature": 0,
        "text": " That's pretty awesome.",
        "tokens": [
          51116,
          663,
          311,
          1238,
          3476,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.24591018904500933,
        "compression_ratio": 1.3557046979865772,
        "end": 519.04,
        "id": 124,
        "no_speech_prob": 0.0015487418277189136,
        "seek": 49240,
        "start": 517.04,
        "temperature": 0,
        "text": " Mutant emoji bot, that's kind of fun.",
        "tokens": [
          51596,
          18517,
          394,
          31595,
          10592,
          11,
          300,
          311,
          733,
          295,
          1019,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 522.56,
        "id": 125,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 520,
        "temperature": 0,
        "text": " All right, so here we go.",
        "tokens": [
          50412,
          1057,
          558,
          11,
          370,
          510,
          321,
          352,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 525.8399999999999,
        "id": 126,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 523.36,
        "temperature": 0,
        "text": " Do I want to create a new bot?",
        "tokens": [
          50580,
          1144,
          286,
          528,
          281,
          1884,
          257,
          777,
          10592,
          30,
          50704
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 528.56,
        "id": 127,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 527.5999999999999,
        "temperature": 0,
        "text": " I think I'm going to use the previous.",
        "tokens": [
          50792,
          286,
          519,
          286,
          478,
          516,
          281,
          764,
          264,
          3894,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 530.4,
        "id": 128,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 528.56,
        "temperature": 0,
        "text": " So I think I'm going to do this as a coding challenge,",
        "tokens": [
          50840,
          407,
          286,
          519,
          286,
          478,
          516,
          281,
          360,
          341,
          382,
          257,
          17720,
          3430,
          11,
          50932
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 533.5999999999999,
        "id": 129,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 530.4,
        "temperature": 0,
        "text": " but I am going to get myself set up a little bit.",
        "tokens": [
          50932,
          457,
          286,
          669,
          516,
          281,
          483,
          2059,
          992,
          493,
          257,
          707,
          857,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 537.1999999999999,
        "id": 130,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 534.24,
        "temperature": 0,
        "text": " So what I need is to close these things.",
        "tokens": [
          51124,
          407,
          437,
          286,
          643,
          307,
          281,
          1998,
          613,
          721,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 539.36,
        "id": 131,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 537.76,
        "temperature": 0,
        "text": " Then I need iterm open.",
        "tokens": [
          51300,
          1396,
          286,
          643,
          309,
          966,
          1269,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.22317184285914643,
        "compression_ratio": 1.547872340425532,
        "end": 543.12,
        "id": 132,
        "no_speech_prob": 0.0002737206232268363,
        "seek": 51904,
        "start": 542.0799999999999,
        "temperature": 0,
        "text": " Let's install the update.",
        "tokens": [
          51516,
          961,
          311,
          3625,
          264,
          5623,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.3575213114420573,
        "compression_ratio": 1.3306451612903225,
        "end": 552,
        "id": 133,
        "no_speech_prob": 0.0002959462581202388,
        "seek": 54904,
        "start": 550,
        "temperature": 0,
        "text": " Okay, I've got iterm open.",
        "tokens": [
          50412,
          1033,
          11,
          286,
          600,
          658,
          309,
          966,
          1269,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.3575213114420573,
        "compression_ratio": 1.3306451612903225,
        "end": 560.7199999999999,
        "id": 134,
        "no_speech_prob": 0.0002959462581202388,
        "seek": 54904,
        "start": 554.0799999999999,
        "temperature": 0,
        "text": " We are going to go to the desktop,",
        "tokens": [
          50616,
          492,
          366,
          516,
          281,
          352,
          281,
          264,
          14502,
          11,
          50948
        ]
      },
      {
        "avg_logprob": -0.3575213114420573,
        "compression_ratio": 1.3306451612903225,
        "end": 565.76,
        "id": 135,
        "no_speech_prob": 0.0002959462581202388,
        "seek": 54904,
        "start": 562.64,
        "temperature": 0,
        "text": " mastodon, and open this.",
        "tokens": [
          51044,
          27055,
          378,
          266,
          11,
          293,
          1269,
          341,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.3575213114420573,
        "compression_ratio": 1.3306451612903225,
        "end": 571.5999999999999,
        "id": 136,
        "no_speech_prob": 0.0002959462581202388,
        "seek": 54904,
        "start": 568.16,
        "temperature": 0,
        "text": " And we're going to get mastodon bot two.",
        "tokens": [
          51320,
          400,
          321,
          434,
          516,
          281,
          483,
          27055,
          378,
          266,
          10592,
          732,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.3575213114420573,
        "compression_ratio": 1.3306451612903225,
        "end": 572.88,
        "id": 137,
        "no_speech_prob": 0.0002959462581202388,
        "seek": 54904,
        "start": 571.5999999999999,
        "temperature": 0,
        "text": " Whoa, look at all this stuff in here.",
        "tokens": [
          51492,
          7521,
          11,
          574,
          412,
          439,
          341,
          1507,
          294,
          510,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 580.88,
        "id": 138,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 572.88,
        "temperature": 0,
        "text": " Mastodon bot two, and this is going to be tree underscore bot.",
        "tokens": [
          50364,
          376,
          525,
          378,
          266,
          10592,
          732,
          11,
          293,
          341,
          307,
          516,
          281,
          312,
          4230,
          37556,
          10592,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 584.08,
        "id": 139,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 582.4,
        "temperature": 0,
        "text": " Thanks, it's tree underscore bot.",
        "tokens": [
          50840,
          2561,
          11,
          309,
          311,
          4230,
          37556,
          10592,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 586.32,
        "id": 140,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 584.08,
        "temperature": 0,
        "text": " Thank you to Alka for finding that for me.",
        "tokens": [
          50924,
          1044,
          291,
          281,
          967,
          2330,
          337,
          5006,
          300,
          337,
          385,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 592.88,
        "id": 141,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 586.32,
        "temperature": 0,
        "text": " Mastodon bot three, bots in space at tree underscore bot.",
        "tokens": [
          51036,
          376,
          525,
          378,
          266,
          10592,
          1045,
          11,
          35410,
          294,
          1901,
          412,
          4230,
          37556,
          10592,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 595.4399999999999,
        "id": 142,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 594.16,
        "temperature": 0,
        "text": " Yeah, this is what I was looking for.",
        "tokens": [
          51428,
          865,
          11,
          341,
          307,
          437,
          286,
          390,
          1237,
          337,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 598.64,
        "id": 143,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 596.64,
        "temperature": 0,
        "text": " I want to make exactly this.",
        "tokens": [
          51552,
          286,
          528,
          281,
          652,
          2293,
          341,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 599.44,
        "id": 144,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 598.64,
        "temperature": 0,
        "text": " Who created this?",
        "tokens": [
          51652,
          2102,
          2942,
          341,
          30,
          51692
        ]
      },
      {
        "avg_logprob": -0.19112338622411093,
        "compression_ratio": 1.6906077348066297,
        "end": 600.4,
        "id": 145,
        "no_speech_prob": 0.01826382428407669,
        "seek": 57288,
        "start": 599.44,
        "temperature": 0,
        "text": " Are they going to mind?",
        "tokens": [
          51692,
          2014,
          436,
          516,
          281,
          1575,
          30,
          51740
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 603.4399999999999,
        "id": 146,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 600.48,
        "temperature": 0,
        "text": " A bot generating tree is made by Alex Noviso.",
        "tokens": [
          50368,
          316,
          10592,
          17746,
          4230,
          307,
          1027,
          538,
          5202,
          883,
          4938,
          78,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 607.4399999999999,
        "id": 147,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 606,
        "temperature": 0,
        "text": " Okay, by this person.",
        "tokens": [
          50644,
          1033,
          11,
          538,
          341,
          954,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 609.6,
        "id": 148,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 608.16,
        "temperature": 0,
        "text": " All right, I'm going to recreate this.",
        "tokens": [
          50752,
          1057,
          558,
          11,
          286,
          478,
          516,
          281,
          25833,
          341,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 611.28,
        "id": 149,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 609.6,
        "temperature": 0,
        "text": " This is going to be my coding challenge.",
        "tokens": [
          50824,
          639,
          307,
          516,
          281,
          312,
          452,
          17720,
          3430,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 622.16,
        "id": 150,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 615.92,
        "temperature": 0,
        "text": " Then I close this.",
        "tokens": [
          51140,
          1396,
          286,
          1998,
          341,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 624.0799999999999,
        "id": 151,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 623.12,
        "temperature": 0,
        "text": " I'm going to be here.",
        "tokens": [
          51500,
          286,
          478,
          516,
          281,
          312,
          510,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 627.36,
        "id": 152,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 625.12,
        "temperature": 0,
        "text": " I'm going to close this.",
        "tokens": [
          51600,
          286,
          478,
          516,
          281,
          1998,
          341,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.47568516731262206,
        "compression_ratio": 1.6111111111111112,
        "end": 628.4,
        "id": 153,
        "no_speech_prob": 0.0013249785406515002,
        "seek": 60040,
        "start": 627.36,
        "temperature": 0,
        "text": " I don't need this.",
        "tokens": [
          51712,
          286,
          500,
          380,
          643,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 629.6,
        "id": 154,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 628.72,
        "temperature": 0,
        "text": " I don't need this.",
        "tokens": [
          50380,
          286,
          500,
          380,
          643,
          341,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 632.72,
        "id": 155,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 630.24,
        "temperature": 0,
        "text": " And then I need processing.",
        "tokens": [
          50456,
          400,
          550,
          286,
          643,
          9007,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 637.28,
        "id": 156,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 635.36,
        "temperature": 0,
        "text": " And I need, this is going to be long.",
        "tokens": [
          50712,
          400,
          286,
          643,
          11,
          341,
          307,
          516,
          281,
          312,
          938,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 642.24,
        "id": 157,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 641.12,
        "temperature": 0,
        "text": " I don't care.",
        "tokens": [
          51000,
          286,
          500,
          380,
          1127,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 644.16,
        "id": 158,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 642.24,
        "temperature": 0,
        "text": " I'm going to do this the way that's going to be.",
        "tokens": [
          51056,
          286,
          478,
          516,
          281,
          360,
          341,
          264,
          636,
          300,
          311,
          516,
          281,
          312,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 646.72,
        "id": 159,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 644.72,
        "temperature": 0,
        "text": " All right, and then I need code.",
        "tokens": [
          51180,
          1057,
          558,
          11,
          293,
          550,
          286,
          643,
          3089,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 647.92,
        "id": 160,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 646.72,
        "temperature": 0,
        "text": " Visual Studio code open.",
        "tokens": [
          51280,
          23187,
          13500,
          3089,
          1269,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.25600809928698415,
        "compression_ratio": 1.6204379562043796,
        "end": 653.92,
        "id": 161,
        "no_speech_prob": 0.0008830371662043035,
        "seek": 62840,
        "start": 650.3199999999999,
        "temperature": 0,
        "text": " And close these.",
        "tokens": [
          51460,
          400,
          1998,
          613,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.5056974662924713,
        "compression_ratio": 1.2894736842105263,
        "end": 656.24,
        "id": 162,
        "no_speech_prob": 0.002672931645065546,
        "seek": 65392,
        "start": 654.88,
        "temperature": 0,
        "text": " Mastodon bot three.",
        "tokens": [
          50412,
          376,
          525,
          378,
          266,
          10592,
          1045,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.5056974662924713,
        "compression_ratio": 1.2894736842105263,
        "end": 656.88,
        "id": 163,
        "no_speech_prob": 0.002672931645065546,
        "seek": 65392,
        "start": 656.24,
        "temperature": 0,
        "text": " Oh boy.",
        "tokens": [
          50480,
          876,
          3237,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.5056974662924713,
        "compression_ratio": 1.2894736842105263,
        "end": 657.38,
        "id": 164,
        "no_speech_prob": 0.002672931645065546,
        "seek": 65392,
        "start": 656.88,
        "temperature": 0,
        "text": " Oh boy.",
        "tokens": [
          50512,
          876,
          3237,
          13,
          50537
        ]
      },
      {
        "avg_logprob": -0.5056974662924713,
        "compression_ratio": 1.2894736842105263,
        "end": 663.28,
        "id": 165,
        "no_speech_prob": 0.002672931645065546,
        "seek": 65392,
        "start": 659.8399999999999,
        "temperature": 0,
        "text": " I don't need any of these files that are extra stuff.",
        "tokens": [
          50660,
          286,
          500,
          380,
          643,
          604,
          295,
          613,
          7098,
          300,
          366,
          2857,
          1507,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.5056974662924713,
        "compression_ratio": 1.2894736842105263,
        "end": 668.24,
        "id": 166,
        "no_speech_prob": 0.002672931645065546,
        "seek": 65392,
        "start": 666.4799999999999,
        "temperature": 0,
        "text": " And everything else is fine.",
        "tokens": [
          50992,
          400,
          1203,
          1646,
          307,
          2489,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.5056974662924713,
        "compression_ratio": 1.2894736842105263,
        "end": 677.4399999999999,
        "id": 167,
        "no_speech_prob": 0.002672931645065546,
        "seek": 65392,
        "start": 670.7199999999999,
        "temperature": 0,
        "text": " And then I'm going to start.",
        "tokens": [
          51204,
          400,
          550,
          286,
          478,
          516,
          281,
          722,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 685.4399999999999,
        "id": 168,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 684.16,
        "temperature": 0,
        "text": " With this much code.",
        "tokens": [
          50376,
          2022,
          341,
          709,
          3089,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 689.4399999999999,
        "id": 169,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 688.24,
        "temperature": 0,
        "text": " I'm going to start with this much code.",
        "tokens": [
          50580,
          286,
          478,
          516,
          281,
          722,
          365,
          341,
          709,
          3089,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 695.28,
        "id": 170,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 689.4399999999999,
        "temperature": 0,
        "text": " So what I'm trying to decide is should I do this?",
        "tokens": [
          50640,
          407,
          437,
          286,
          478,
          1382,
          281,
          4536,
          307,
          820,
          286,
          360,
          341,
          30,
          50932
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 698.64,
        "id": 171,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 695.28,
        "temperature": 0,
        "text": " I mean, this really doesn't matter because I want to just make this project.",
        "tokens": [
          50932,
          286,
          914,
          11,
          341,
          534,
          1177,
          380,
          1871,
          570,
          286,
          528,
          281,
          445,
          652,
          341,
          1716,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 700.3199999999999,
        "id": 172,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 699.1999999999999,
        "temperature": 0,
        "text": " Here's what I'm going to do.",
        "tokens": [
          51128,
          1692,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 701.1999999999999,
        "id": 173,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 700.3199999999999,
        "temperature": 0,
        "text": " I got an idea.",
        "tokens": [
          51184,
          286,
          658,
          364,
          1558,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 705.4399999999999,
        "id": 174,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 702.9599999999999,
        "temperature": 0,
        "text": " I'm going to act as if this is a coding challenge,",
        "tokens": [
          51316,
          286,
          478,
          516,
          281,
          605,
          382,
          498,
          341,
          307,
          257,
          17720,
          3430,
          11,
          51440
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 708.64,
        "id": 175,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 705.4399999999999,
        "temperature": 0,
        "text": " but I'm not going to say the words coding challenge.",
        "tokens": [
          51440,
          457,
          286,
          478,
          406,
          516,
          281,
          584,
          264,
          2283,
          17720,
          3430,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 710.64,
        "id": 176,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 709.1999999999999,
        "temperature": 0,
        "text": " I'm going to just do it as is.",
        "tokens": [
          51628,
          286,
          478,
          516,
          281,
          445,
          360,
          309,
          382,
          307,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.41630641558698117,
        "compression_ratio": 1.947867298578199,
        "end": 712.64,
        "id": 177,
        "no_speech_prob": 0.000006962254246900557,
        "seek": 68392,
        "start": 710.64,
        "temperature": 0,
        "text": " I'm going to say, hey, I'm going to do this.",
        "tokens": [
          51700,
          286,
          478,
          516,
          281,
          584,
          11,
          4177,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 715.4399999999999,
        "id": 178,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 712.72,
        "temperature": 0,
        "text": " I'm going to just do it as if it's a tutorial.",
        "tokens": [
          50368,
          286,
          478,
          516,
          281,
          445,
          360,
          309,
          382,
          498,
          309,
          311,
          257,
          7073,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 719.6,
        "id": 179,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 715.4399999999999,
        "temperature": 0,
        "text": " And then at the end,",
        "tokens": [
          50504,
          400,
          550,
          412,
          264,
          917,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 723.76,
        "id": 180,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 720.3199999999999,
        "temperature": 0,
        "text": " if it feels like it could actually be one video coding challenge,",
        "tokens": [
          50748,
          498,
          309,
          3417,
          411,
          309,
          727,
          767,
          312,
          472,
          960,
          17720,
          3430,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 725.6,
        "id": 181,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 723.76,
        "temperature": 0,
        "text": " it doesn't end up being multi-part tutorial,",
        "tokens": [
          50920,
          309,
          1177,
          380,
          917,
          493,
          885,
          4825,
          12,
          6971,
          7073,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 729.68,
        "id": 182,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 726.4,
        "temperature": 0,
        "text": " then I will record a brief intro calling it a coding challenge.",
        "tokens": [
          51052,
          550,
          286,
          486,
          2136,
          257,
          5353,
          12897,
          5141,
          309,
          257,
          17720,
          3430,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 730.4,
        "id": 183,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 729.68,
        "temperature": 0,
        "text": " How about that?",
        "tokens": [
          51216,
          1012,
          466,
          300,
          30,
          51252
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 731.12,
        "id": 184,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 730.4,
        "temperature": 0,
        "text": " Everybody wins.",
        "tokens": [
          51252,
          7646,
          10641,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 732.72,
        "id": 185,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 732,
        "temperature": 0,
        "text": " I mean, I win.",
        "tokens": [
          51332,
          286,
          914,
          11,
          286,
          1942,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 734.72,
        "id": 186,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 733.28,
        "temperature": 0,
        "text": " I mean, I don't know.",
        "tokens": [
          51396,
          286,
          914,
          11,
          286,
          500,
          380,
          458,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.20177957849595154,
        "compression_ratio": 1.5631067961165048,
        "end": 739.84,
        "id": 187,
        "no_speech_prob": 0.000007889248990977649,
        "seek": 71264,
        "start": 739.4399999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51704,
          1057,
          558,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 743.36,
        "id": 188,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 740.1600000000001,
        "temperature": 0,
        "text": " We're going to check out this whiteboard thing over here.",
        "tokens": [
          50380,
          492,
          434,
          516,
          281,
          1520,
          484,
          341,
          2418,
          3787,
          551,
          670,
          510,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 744.5600000000001,
        "id": 189,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 743.36,
        "temperature": 0,
        "text": " I don't think that I need.",
        "tokens": [
          50540,
          286,
          500,
          380,
          519,
          300,
          286,
          643,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 746.24,
        "id": 190,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 745.52,
        "temperature": 0,
        "text": " You know what, though?",
        "tokens": [
          50648,
          509,
          458,
          437,
          11,
          1673,
          30,
          50684
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 748.8000000000001,
        "id": 191,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 748.24,
        "temperature": 0,
        "text": " Oh, why?",
        "tokens": [
          50784,
          876,
          11,
          983,
          30,
          50812
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 750.72,
        "id": 192,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 750.24,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50884,
          7521,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 751.52,
        "id": 193,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 750.72,
        "temperature": 0,
        "text": " Oh, wrong.",
        "tokens": [
          50908,
          876,
          11,
          2085,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 752.1600000000001,
        "id": 194,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 751.52,
        "temperature": 0,
        "text": " Oh, there it is.",
        "tokens": [
          50948,
          876,
          11,
          456,
          309,
          307,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 755.44,
        "id": 195,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 753.6,
        "temperature": 0,
        "text": " I do want to erase the whiteboard, actually,",
        "tokens": [
          51052,
          286,
          360,
          528,
          281,
          23525,
          264,
          2418,
          3787,
          11,
          767,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 760.24,
        "id": 196,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 755.44,
        "temperature": 0,
        "text": " which I'm going to do very quickly with my fancy eraser mechanism.",
        "tokens": [
          51144,
          597,
          286,
          478,
          516,
          281,
          360,
          588,
          2661,
          365,
          452,
          10247,
          46018,
          7513,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 766.8000000000001,
        "id": 197,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 765.76,
        "temperature": 0,
        "text": " If I could find it.",
        "tokens": [
          51660,
          759,
          286,
          727,
          915,
          309,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 767.84,
        "id": 198,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 766.8000000000001,
        "temperature": 0,
        "text": " I can't find where.",
        "tokens": [
          51712,
          286,
          393,
          380,
          915,
          689,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4270964535799893,
        "compression_ratio": 1.5458937198067633,
        "end": 768.8000000000001,
        "id": 199,
        "no_speech_prob": 0.00035143530112691224,
        "seek": 73984,
        "start": 767.84,
        "temperature": 0,
        "text": " Did it get there?",
        "tokens": [
          51764,
          2589,
          309,
          483,
          456,
          30,
          51812
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 770.64,
        "id": 200,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 769.84,
        "temperature": 0,
        "text": " Thrown away?",
        "tokens": [
          50364,
          41645,
          648,
          1314,
          30,
          50404
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 771.52,
        "id": 201,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 770.64,
        "temperature": 0,
        "text": " My erasers?",
        "tokens": [
          50404,
          1222,
          1189,
          296,
          433,
          30,
          50448
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 772.96,
        "id": 202,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 771.52,
        "temperature": 0,
        "text": " I know you can't see me right now.",
        "tokens": [
          50448,
          286,
          458,
          291,
          393,
          380,
          536,
          385,
          558,
          586,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 774.88,
        "id": 203,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 773.52,
        "temperature": 0,
        "text": " I don't want to be seen.",
        "tokens": [
          50548,
          286,
          500,
          380,
          528,
          281,
          312,
          1612,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 778.5600000000001,
        "id": 204,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 776.5600000000001,
        "temperature": 0,
        "text": " I don't want to be seen looking for the eraser.",
        "tokens": [
          50700,
          286,
          500,
          380,
          528,
          281,
          312,
          1612,
          1237,
          337,
          264,
          46018,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 780.88,
        "id": 205,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 778.5600000000001,
        "temperature": 0,
        "text": " Am I going to have to go in the hallway and get a paper towel?",
        "tokens": [
          50800,
          2012,
          286,
          516,
          281,
          362,
          281,
          352,
          294,
          264,
          23903,
          293,
          483,
          257,
          3035,
          15755,
          30,
          50916
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 783.6800000000001,
        "id": 206,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 782,
        "temperature": 0,
        "text": " The earth will be very sad.",
        "tokens": [
          50972,
          440,
          4120,
          486,
          312,
          588,
          4227,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 786.88,
        "id": 207,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 784.8000000000001,
        "temperature": 0,
        "text": " I have a nice reusable eraser.",
        "tokens": [
          51112,
          286,
          362,
          257,
          1481,
          41807,
          46018,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 789.0400000000001,
        "id": 208,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 788.4,
        "temperature": 0,
        "text": " Doohickey.",
        "tokens": [
          51292,
          1144,
          1445,
          299,
          4119,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 791.12,
        "id": 209,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 790.24,
        "temperature": 0,
        "text": " That is completely...",
        "tokens": [
          51384,
          663,
          307,
          2584,
          485,
          51428
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 791.44,
        "id": 210,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 791.12,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51428,
          876,
          11,
          572,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 791.9200000000001,
        "id": 211,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 791.44,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          51444,
          1692,
          309,
          307,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.22861326151880726,
        "compression_ratio": 1.5388349514563107,
        "end": 792.4,
        "id": 212,
        "no_speech_prob": 0.0018968770746141672,
        "seek": 76984,
        "start": 791.9200000000001,
        "temperature": 0,
        "text": " Found it.",
        "tokens": [
          51468,
          8207,
          309,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 801.0400000000001,
        "id": 213,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 800.24,
        "temperature": 0,
        "text": " This is actually...",
        "tokens": [
          50384,
          639,
          307,
          767,
          485,
          50424
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 805.12,
        "id": 214,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 803.12,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50528,
          1033,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 814.32,
        "id": 215,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 813.84,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 815.84,
        "id": 216,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 815.2800000000001,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51136,
          821,
          321,
          352,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 818.8000000000001,
        "id": 217,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 818.5600000000001,
        "temperature": 0,
        "text": " Now.",
        "tokens": [
          51300,
          823,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 822,
        "id": 218,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 821.2,
        "temperature": 0,
        "text": " Got a marker.",
        "tokens": [
          51432,
          5803,
          257,
          15247,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.4069243481284694,
        "compression_ratio": 1.0256410256410255,
        "end": 827.0400000000001,
        "id": 219,
        "no_speech_prob": 0.0030277278274297714,
        "seek": 79984,
        "start": 825.9200000000001,
        "temperature": 0,
        "text": " I am going to...",
        "tokens": [
          51668,
          286,
          669,
          516,
          281,
          485,
          51724
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 830.58,
        "id": 220,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 830.08,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50376,
          1033,
          13,
          50401
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 839.9200000000001,
        "id": 221,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 839.12,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50828,
          1692,
          321,
          352,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 840.8000000000001,
        "id": 222,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 839.9200000000001,
        "temperature": 0,
        "text": " Everybody stretch.",
        "tokens": [
          50868,
          7646,
          5985,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 841.44,
        "id": 223,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 840.8000000000001,
        "temperature": 0,
        "text": " Stand up.",
        "tokens": [
          50912,
          9133,
          493,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 842.32,
        "id": 224,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 841.44,
        "temperature": 0,
        "text": " Stretch with me.",
        "tokens": [
          50944,
          38817,
          365,
          385,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 846.72,
        "id": 225,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 843.44,
        "temperature": 0,
        "text": " I don't know if this is maybe some correct stretching thing.",
        "tokens": [
          51044,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          1310,
          512,
          3006,
          19632,
          551,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 848.5600000000001,
        "id": 226,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 848.24,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51284,
          1057,
          558,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.29164454142252605,
        "compression_ratio": 1.2949640287769784,
        "end": 855.84,
        "id": 227,
        "no_speech_prob": 0.00010229930921923369,
        "seek": 82984,
        "start": 853.0400000000001,
        "temperature": 0,
        "text": " So other things that I need open here are...",
        "tokens": [
          51524,
          407,
          661,
          721,
          300,
          286,
          643,
          1269,
          510,
          366,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 863.9200000000001,
        "id": 228,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 856.32,
        "temperature": 0,
        "text": " I need the Mastodon API docs.",
        "tokens": [
          50388,
          286,
          643,
          264,
          376,
          525,
          378,
          266,
          9362,
          45623,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 870.08,
        "id": 229,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 866.72,
        "temperature": 0,
        "text": " And Mastodon API docs.",
        "tokens": [
          50908,
          400,
          376,
          525,
          378,
          266,
          9362,
          45623,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 872.24,
        "id": 230,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 871.6800000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51156,
          1033,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 875.36,
        "id": 231,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 872.8000000000001,
        "temperature": 0,
        "text": " So these I will definitely probably need to reference.",
        "tokens": [
          51212,
          407,
          613,
          286,
          486,
          2138,
          1391,
          643,
          281,
          6408,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 876.96,
        "id": 232,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 875.9200000000001,
        "temperature": 0,
        "text": " I've got the tree bot.",
        "tokens": [
          51368,
          286,
          600,
          658,
          264,
          4230,
          10592,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 878.4,
        "id": 233,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 876.96,
        "temperature": 0,
        "text": " I've got the coding train bot.",
        "tokens": [
          51420,
          286,
          600,
          658,
          264,
          17720,
          3847,
          10592,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.5008011986227596,
        "compression_ratio": 1.528,
        "end": 883.0400000000001,
        "id": 234,
        "no_speech_prob": 0.0010322093730792403,
        "seek": 85584,
        "start": 879.2,
        "temperature": 0,
        "text": " And I've got some code.",
        "tokens": [
          51532,
          400,
          286,
          600,
          658,
          512,
          3089,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 884.4,
        "id": 235,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 883.92,
        "temperature": 0,
        "text": " Code.",
        "tokens": [
          50408,
          15549,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 892.7199999999999,
        "id": 236,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 890.24,
        "temperature": 0,
        "text": " And let's just make sure like that does something.",
        "tokens": [
          50724,
          400,
          718,
          311,
          445,
          652,
          988,
          411,
          300,
          775,
          746,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 892.9599999999999,
        "id": 237,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 892.7199999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50848,
          1033,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 901.12,
        "id": 238,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 900.7199999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51248,
          1057,
          558,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 905.1999999999999,
        "id": 239,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 904.0799999999999,
        "temperature": 0,
        "text": " I got a notification.",
        "tokens": [
          51416,
          286,
          658,
          257,
          11554,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 908.64,
        "id": 240,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 907.28,
        "temperature": 0,
        "text": " I probably should turn those off.",
        "tokens": [
          51576,
          286,
          1391,
          820,
          1261,
          729,
          766,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 910.88,
        "id": 241,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 909.5999999999999,
        "temperature": 0,
        "text": " All these people are following me.",
        "tokens": [
          51692,
          1057,
          613,
          561,
          366,
          3480,
          385,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.2740095429501291,
        "compression_ratio": 1.2708333333333333,
        "end": 911.92,
        "id": 242,
        "no_speech_prob": 0.0019569932483136654,
        "seek": 88304,
        "start": 910.88,
        "temperature": 0,
        "text": " Look at everybody.",
        "tokens": [
          51756,
          2053,
          412,
          2201,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 914.4,
        "id": 243,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 912.24,
        "temperature": 0,
        "text": " All of a sudden, so much activity here.",
        "tokens": [
          50380,
          1057,
          295,
          257,
          3990,
          11,
          370,
          709,
          5191,
          510,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 915.28,
        "id": 244,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 914.9599999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50516,
          1033,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 923.28,
        "id": 245,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 923.04,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50920,
          1033,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 925.1999999999999,
        "id": 246,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 924.7199999999999,
        "temperature": 0,
        "text": " Let's...",
        "tokens": [
          51004,
          961,
          311,
          485,
          51028
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 926.7199999999999,
        "id": 247,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 925.1999999999999,
        "temperature": 0,
        "text": " I just want to do something here.",
        "tokens": [
          51028,
          286,
          445,
          528,
          281,
          360,
          746,
          510,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 928,
        "id": 248,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 927.28,
        "temperature": 0,
        "text": " Let's go back.",
        "tokens": [
          51132,
          961,
          311,
          352,
          646,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 928.56,
        "id": 249,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 928,
        "temperature": 0,
        "text": " Yeah, that's good.",
        "tokens": [
          51168,
          865,
          11,
          300,
          311,
          665,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 930.0799999999999,
        "id": 250,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 929.8399999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51260,
          1033,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 934.0799999999999,
        "id": 251,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 933.52,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51444,
          1057,
          558,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 937.12,
        "id": 252,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 934.9599999999999,
        "temperature": 0,
        "text": " I'm trying to figure out like if there's...",
        "tokens": [
          51516,
          286,
          478,
          1382,
          281,
          2573,
          484,
          411,
          498,
          456,
          311,
          485,
          51624
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 937.76,
        "id": 253,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 937.12,
        "temperature": 0,
        "text": " I just want to...",
        "tokens": [
          51624,
          286,
          445,
          528,
          281,
          485,
          51656
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 940.8,
        "id": 254,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 939.12,
        "temperature": 0,
        "text": " Can I just get rid of this for a little...",
        "tokens": [
          51724,
          1664,
          286,
          445,
          483,
          3973,
          295,
          341,
          337,
          257,
          707,
          485,
          51808
        ]
      },
      {
        "avg_logprob": -0.23839351384326665,
        "compression_ratio": 1.5232558139534884,
        "end": 941.36,
        "id": 255,
        "no_speech_prob": 0.0004238771216478199,
        "seek": 91192,
        "start": 940.8,
        "temperature": 0,
        "text": " Play sound.",
        "tokens": [
          51808,
          5506,
          1626,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 942.24,
        "id": 256,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 941.36,
        "temperature": 0,
        "text": " Let's get rid of this.",
        "tokens": [
          50364,
          961,
          311,
          483,
          3973,
          295,
          341,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 943.84,
        "id": 257,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 943.04,
        "temperature": 0,
        "text": " Play sound.",
        "tokens": [
          50448,
          5506,
          1626,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 944.64,
        "id": 258,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 943.84,
        "temperature": 0,
        "text": " Play sound.",
        "tokens": [
          50488,
          5506,
          1626,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 947.28,
        "id": 259,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 945.44,
        "temperature": 0,
        "text": " Actually, can I clear notifications?",
        "tokens": [
          50568,
          5135,
          11,
          393,
          286,
          1850,
          13426,
          30,
          50660
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 947.6,
        "id": 260,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 947.28,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50660,
          1079,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 950.24,
        "id": 261,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 949.92,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          50792,
          876,
          11,
          572,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 951.76,
        "id": 262,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 950.24,
        "temperature": 0,
        "text": " But can I turn them all off?",
        "tokens": [
          50808,
          583,
          393,
          286,
          1261,
          552,
          439,
          766,
          30,
          50884
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 954,
        "id": 263,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 951.76,
        "temperature": 0,
        "text": " There's no way to just like turn them all off.",
        "tokens": [
          50884,
          821,
          311,
          572,
          636,
          281,
          445,
          411,
          1261,
          552,
          439,
          766,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 954.8000000000001,
        "id": 264,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 954,
        "temperature": 0,
        "text": " How about unpin?",
        "tokens": [
          50996,
          1012,
          466,
          517,
          17836,
          30,
          51036
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 956.24,
        "id": 265,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 955.44,
        "temperature": 0,
        "text": " Yes, there we go.",
        "tokens": [
          51068,
          1079,
          11,
          456,
          321,
          352,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 958,
        "id": 266,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 957.04,
        "temperature": 0,
        "text": " I just don't want...",
        "tokens": [
          51148,
          286,
          445,
          500,
          380,
          528,
          485,
          51196
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 963.2,
        "id": 267,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 958.5600000000001,
        "temperature": 0,
        "text": " I'm afraid of random stuff appearing that other people are posting.",
        "tokens": [
          51224,
          286,
          478,
          4638,
          295,
          4974,
          1507,
          19870,
          300,
          661,
          561,
          366,
          15978,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.20921541374420452,
        "compression_ratio": 1.5123152709359606,
        "end": 963.6,
        "id": 268,
        "no_speech_prob": 0.0004582894907798618,
        "seek": 94136,
        "start": 963.2,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51456,
          1057,
          558,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 966.64,
        "id": 269,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 964.24,
        "temperature": 0.4,
        "text": " Oh, Adam in the chat.",
        "tokens": [
          50396,
          876,
          11,
          7938,
          294,
          264,
          5081,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 967.9200000000001,
        "id": 270,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 966.64,
        "temperature": 0.4,
        "text": " Apologies.",
        "tokens": [
          50516,
          8723,
          6204,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 971.9200000000001,
        "id": 271,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 967.9200000000001,
        "temperature": 0.4,
        "text": " So if you want to join choochoo.space,",
        "tokens": [
          50580,
          407,
          498,
          291,
          528,
          281,
          3917,
          1586,
          78,
          339,
          1986,
          13,
          24824,
          11,
          50780
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 978.64,
        "id": 272,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 971.9200000000001,
        "temperature": 0.4,
        "text": " I created an invite for members of the YouTube channel and patrons.",
        "tokens": [
          50780,
          286,
          2942,
          364,
          7980,
          337,
          2679,
          295,
          264,
          3088,
          417,
          282,
          6396,
          293,
          27559,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 980.88,
        "id": 273,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 979.2,
        "temperature": 0.4,
        "text": " But I'll have to get off to generate.",
        "tokens": [
          51144,
          583,
          286,
          603,
          362,
          281,
          483,
          766,
          281,
          8460,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 982.24,
        "id": 274,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 980.88,
        "temperature": 0.4,
        "text": " I didn't realize that it expired.",
        "tokens": [
          51228,
          286,
          994,
          380,
          4325,
          300,
          309,
          36587,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 984.48,
        "id": 275,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 982.24,
        "temperature": 0.4,
        "text": " I'll generate a new one after this is over.",
        "tokens": [
          51296,
          286,
          603,
          8460,
          257,
          777,
          472,
          934,
          341,
          307,
          670,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 984.72,
        "id": 276,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 984.48,
        "temperature": 0.4,
        "text": " Okay.",
        "tokens": [
          51408,
          1033,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 987.12,
        "id": 277,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 986.64,
        "temperature": 0.4,
        "text": " Hello.",
        "tokens": [
          51516,
          2425,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 988.48,
        "id": 278,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 987.9200000000001,
        "temperature": 0.4,
        "text": " Hi, Adam.",
        "tokens": [
          51580,
          220,
          17155,
          11,
          7938,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 989.12,
        "id": 279,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 988.48,
        "temperature": 0.4,
        "text": " How are you?",
        "tokens": [
          51608,
          1012,
          366,
          291,
          30,
          51640
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 989.28,
        "id": 280,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 989.12,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51640,
          286,
          478,
          869,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 989.52,
        "id": 281,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 989.28,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51648,
          286,
          478,
          869,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 989.76,
        "id": 282,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 989.52,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51660,
          286,
          478,
          869,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 990,
        "id": 283,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 989.76,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51672,
          286,
          478,
          869,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 990.08,
        "id": 284,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 990,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51684,
          286,
          478,
          869,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 990.24,
        "id": 285,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 990.08,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51688,
          286,
          478,
          869,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 990.32,
        "id": 286,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 990.24,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51696,
          286,
          478,
          869,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 990.5600000000001,
        "id": 287,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 990.32,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51700,
          286,
          478,
          869,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 990.72,
        "id": 288,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 990.5600000000001,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51712,
          286,
          478,
          869,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.0400000000001,
        "id": 289,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 990.72,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51720,
          286,
          478,
          869,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.12,
        "id": 290,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.0400000000001,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51736,
          286,
          478,
          869,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.28,
        "id": 291,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.12,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51740,
          286,
          478,
          869,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.36,
        "id": 292,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.28,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51748,
          286,
          478,
          869,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.52,
        "id": 293,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.36,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51752,
          286,
          478,
          869,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.6800000000001,
        "id": 294,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.52,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51760,
          286,
          478,
          869,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.76,
        "id": 295,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.6800000000001,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51768,
          286,
          478,
          869,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.84,
        "id": 296,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.76,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51772,
          286,
          478,
          869,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 991.9200000000001,
        "id": 297,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.84,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51776,
          286,
          478,
          869,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 992.08,
        "id": 298,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 991.9200000000001,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51780,
          286,
          478,
          869,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.48255212210753573,
        "compression_ratio": 2.3878504672897196,
        "end": 992.1600000000001,
        "id": 299,
        "no_speech_prob": 0.007232543546706438,
        "seek": 96360,
        "start": 992.08,
        "temperature": 0.4,
        "text": " I'm great.",
        "tokens": [
          51788,
          286,
          478,
          869,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 995.84,
        "id": 300,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 993.84,
        "temperature": 0,
        "text": " I'm going to make something in this video.",
        "tokens": [
          50376,
          286,
          478,
          516,
          281,
          652,
          746,
          294,
          341,
          960,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1000,
        "id": 301,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 995.84,
        "temperature": 0,
        "text": " And what I'm going to make is a tree bot.",
        "tokens": [
          50476,
          400,
          437,
          286,
          478,
          516,
          281,
          652,
          307,
          257,
          4230,
          10592,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1001.52,
        "id": 302,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1000,
        "temperature": 0,
        "text": " I love this bot.",
        "tokens": [
          50684,
          286,
          959,
          341,
          10592,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1003.0400000000001,
        "id": 303,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1001.52,
        "temperature": 0,
        "text": " It is a bot on Mastodon.",
        "tokens": [
          50760,
          467,
          307,
          257,
          10592,
          322,
          376,
          525,
          378,
          266,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1005.12,
        "id": 304,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1003.0400000000001,
        "temperature": 0,
        "text": " It is called tree underscore bot.",
        "tokens": [
          50836,
          467,
          307,
          1219,
          4230,
          37556,
          10592,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1008.4,
        "id": 305,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1005.12,
        "temperature": 0,
        "text": " It is made by Alex Novosi.",
        "tokens": [
          50940,
          467,
          307,
          1027,
          538,
          5202,
          883,
          19140,
          72,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1014.8000000000001,
        "id": 306,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1009.12,
        "temperature": 0,
        "text": " Was made for Nabo Mamo, which must be some like national bot making month.",
        "tokens": [
          51140,
          3027,
          1027,
          337,
          426,
          41265,
          376,
          10502,
          11,
          597,
          1633,
          312,
          512,
          411,
          4048,
          10592,
          1455,
          1618,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1016.16,
        "id": 307,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1014.8000000000001,
        "temperature": 0,
        "text": " Hi, national bot making month.",
        "tokens": [
          51424,
          2421,
          11,
          4048,
          10592,
          1455,
          1618,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1017.28,
        "id": 308,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1016.16,
        "temperature": 0,
        "text": " When does that happen?",
        "tokens": [
          51492,
          1133,
          775,
          300,
          1051,
          30,
          51548
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1017.84,
        "id": 309,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1017.28,
        "temperature": 0,
        "text": " Is it now?",
        "tokens": [
          51548,
          1119,
          309,
          586,
          30,
          51576
        ]
      },
      {
        "avg_logprob": -0.20707750708107056,
        "compression_ratio": 1.8055555555555556,
        "end": 1021.0400000000001,
        "id": 310,
        "no_speech_prob": 0.00970779825001955,
        "seek": 99360,
        "start": 1017.84,
        "temperature": 0,
        "text": " Because we should all make bots for national bot making month.",
        "tokens": [
          51576,
          1436,
          321,
          820,
          439,
          652,
          35410,
          337,
          4048,
          10592,
          1455,
          1618,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1024.1599999999999,
        "id": 311,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1021.36,
        "temperature": 0,
        "text": " So I am going to, I love this bot.",
        "tokens": [
          50380,
          407,
          286,
          669,
          516,
          281,
          11,
          286,
          959,
          341,
          10592,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1024.96,
        "id": 312,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1024.1599999999999,
        "temperature": 0,
        "text": " It makes a tree.",
        "tokens": [
          50520,
          467,
          1669,
          257,
          4230,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1032.6399999999999,
        "id": 313,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1030.56,
        "temperature": 0,
        "text": " This is my one start over.",
        "tokens": [
          50840,
          639,
          307,
          452,
          472,
          722,
          670,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1036.08,
        "id": 314,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1032.6399999999999,
        "temperature": 0,
        "text": " You know, my poor guests who come here to do a guest video.",
        "tokens": [
          50944,
          509,
          458,
          11,
          452,
          4716,
          9804,
          567,
          808,
          510,
          281,
          360,
          257,
          8341,
          960,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1041.12,
        "id": 315,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1036.08,
        "temperature": 0,
        "text": " I don't let them like, they don't start over like 15 times like me as if I wasn't doing this live.",
        "tokens": [
          51116,
          286,
          500,
          380,
          718,
          552,
          411,
          11,
          436,
          500,
          380,
          722,
          670,
          411,
          2119,
          1413,
          411,
          385,
          382,
          498,
          286,
          2067,
          380,
          884,
          341,
          1621,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1044.08,
        "id": 316,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1043.44,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51484,
          2425,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.24308184281136225,
        "compression_ratio": 1.6443298969072164,
        "end": 1047.36,
        "id": 317,
        "no_speech_prob": 0.0004238732799421996,
        "seek": 102104,
        "start": 1044.08,
        "temperature": 0,
        "text": " In this video, I'm going to make a bot and I'm going to make an image bot.",
        "tokens": [
          51516,
          682,
          341,
          960,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          10592,
          293,
          286,
          478,
          516,
          281,
          652,
          364,
          3256,
          10592,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1051.76,
        "id": 318,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1047.36,
        "temperature": 0,
        "text": " I'm very excited about this project because it pulls together a whole lot of different things.",
        "tokens": [
          50364,
          286,
          478,
          588,
          2919,
          466,
          341,
          1716,
          570,
          309,
          16982,
          1214,
          257,
          1379,
          688,
          295,
          819,
          721,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1055.52,
        "id": 319,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1051.76,
        "temperature": 0,
        "text": " I am going to use processing to generate an image.",
        "tokens": [
          50584,
          286,
          669,
          516,
          281,
          764,
          9007,
          281,
          8460,
          364,
          3256,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1060.08,
        "id": 320,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1055.52,
        "temperature": 0,
        "text": " I'm going to use node to call processing to generate the image.",
        "tokens": [
          50772,
          286,
          478,
          516,
          281,
          764,
          9984,
          281,
          818,
          9007,
          281,
          8460,
          264,
          3256,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1063.4399999999998,
        "id": 321,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1060.08,
        "temperature": 0,
        "text": " Then I'm going to use node to talk to an API and the API is Mastodon.",
        "tokens": [
          51000,
          1396,
          286,
          478,
          516,
          281,
          764,
          9984,
          281,
          751,
          281,
          364,
          9362,
          293,
          264,
          9362,
          307,
          376,
          525,
          378,
          266,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1069.1999999999998,
        "id": 322,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1063.4399999999998,
        "temperature": 0,
        "text": " So one thing you might want to do is I'll refer you to all of my tutorial series about",
        "tokens": [
          51168,
          407,
          472,
          551,
          291,
          1062,
          528,
          281,
          360,
          307,
          286,
          603,
          2864,
          291,
          281,
          439,
          295,
          452,
          7073,
          2638,
          466,
          51456
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1070.8799999999999,
        "id": 323,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1069.1999999999998,
        "temperature": 0,
        "text": " the basics of making a Mastodon bot.",
        "tokens": [
          51456,
          264,
          14688,
          295,
          1455,
          257,
          376,
          525,
          378,
          266,
          10592,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.1864288708635869,
        "compression_ratio": 1.7985347985347986,
        "end": 1076.3999999999999,
        "id": 324,
        "no_speech_prob": 0.048847220838069916,
        "seek": 104736,
        "start": 1070.8799999999999,
        "temperature": 0,
        "text": " I will start largely from scratch here, but I am going, I've already gotten my API keys",
        "tokens": [
          51540,
          286,
          486,
          722,
          11611,
          490,
          8459,
          510,
          11,
          457,
          286,
          669,
          516,
          11,
          286,
          600,
          1217,
          5768,
          452,
          9362,
          9317,
          51816
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1081.52,
        "id": 325,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1076.48,
        "temperature": 0,
        "text": " and I already have imported and installed this node package called Mastodon.api",
        "tokens": [
          50368,
          293,
          286,
          1217,
          362,
          25524,
          293,
          8899,
          341,
          9984,
          7372,
          1219,
          376,
          525,
          378,
          266,
          13,
          35891,
          50620
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1086.88,
        "id": 326,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1081.52,
        "temperature": 0,
        "text": " and this.env package that loads my API keys for me.",
        "tokens": [
          50620,
          293,
          341,
          2411,
          268,
          85,
          7372,
          300,
          12668,
          452,
          9362,
          9317,
          337,
          385,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1089.2,
        "id": 327,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1086.88,
        "temperature": 0,
        "text": " So that is stuff that I've done in another video.",
        "tokens": [
          50888,
          407,
          300,
          307,
          1507,
          300,
          286,
          600,
          1096,
          294,
          1071,
          960,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1091.3600000000001,
        "id": 328,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1089.2,
        "temperature": 0,
        "text": " If you want to see that, I'll link to that in the video description,",
        "tokens": [
          51004,
          759,
          291,
          528,
          281,
          536,
          300,
          11,
          286,
          603,
          2113,
          281,
          300,
          294,
          264,
          960,
          3855,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1092.72,
        "id": 329,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1091.3600000000001,
        "temperature": 0,
        "text": " but I'm just going to get started.",
        "tokens": [
          51112,
          457,
          286,
          478,
          445,
          516,
          281,
          483,
          1409,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1094.48,
        "id": 330,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1092.72,
        "temperature": 0,
        "text": " So what is the first thing that I want to do?",
        "tokens": [
          51180,
          407,
          437,
          307,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          30,
          51268
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1098.0800000000002,
        "id": 331,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1094.48,
        "temperature": 0,
        "text": " Okay, actually, let's go to, so this is my inspiration, treebot,",
        "tokens": [
          51268,
          1033,
          11,
          767,
          11,
          718,
          311,
          352,
          281,
          11,
          370,
          341,
          307,
          452,
          10249,
          11,
          4230,
          18870,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.21453990492709848,
        "compression_ratio": 1.6254545454545455,
        "end": 1102.8000000000002,
        "id": 332,
        "no_speech_prob": 0.00008349534618901089,
        "seek": 107640,
        "start": 1098.96,
        "temperature": 0,
        "text": " made by Alex Novosi for National Bot Making Month.",
        "tokens": [
          51492,
          1027,
          538,
          5202,
          883,
          19140,
          72,
          337,
          4862,
          25486,
          14595,
          24255,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1107.44,
        "id": 333,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1103.76,
        "temperature": 0,
        "text": " And I am going to try to recreate this.",
        "tokens": [
          50412,
          400,
          286,
          669,
          516,
          281,
          853,
          281,
          25833,
          341,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1108.96,
        "id": 334,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1107.44,
        "temperature": 0,
        "text": " My trees won't be nearly as nice.",
        "tokens": [
          50596,
          1222,
          5852,
          1582,
          380,
          312,
          6217,
          382,
          1481,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1111.04,
        "id": 335,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1108.96,
        "temperature": 0,
        "text": " So the first thing I want to do is I want to use processing.",
        "tokens": [
          50672,
          407,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          764,
          9007,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1115.6,
        "id": 336,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1111.04,
        "temperature": 0,
        "text": " Now, I don't have to, I could find some node package that does drawing or generates an image,",
        "tokens": [
          50776,
          823,
          11,
          286,
          500,
          380,
          362,
          281,
          11,
          286,
          727,
          915,
          512,
          9984,
          7372,
          300,
          775,
          6316,
          420,
          23815,
          364,
          3256,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1118.1599999999999,
        "id": 337,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1115.6,
        "temperature": 0,
        "text": " SVG, whatever, but I love processing.",
        "tokens": [
          51004,
          31910,
          38,
          11,
          2035,
          11,
          457,
          286,
          959,
          9007,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1122,
        "id": 338,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1118.1599999999999,
        "temperature": 0,
        "text": " It's my happy place and I'm pretty sure I can get processing to generate a tree.",
        "tokens": [
          51132,
          467,
          311,
          452,
          2055,
          1081,
          293,
          286,
          478,
          1238,
          988,
          286,
          393,
          483,
          9007,
          281,
          8460,
          257,
          4230,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1127.6,
        "id": 339,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1122,
        "temperature": 0,
        "text": " In fact, I don't even have to like write the code for this because I have before.",
        "tokens": [
          51324,
          682,
          1186,
          11,
          286,
          500,
          380,
          754,
          362,
          281,
          411,
          2464,
          264,
          3089,
          337,
          341,
          570,
          286,
          362,
          949,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.19780505145037616,
        "compression_ratio": 1.677304964539007,
        "end": 1130.24,
        "id": 340,
        "no_speech_prob": 0.0012644099770113826,
        "seek": 110280,
        "start": 1127.6,
        "temperature": 0,
        "text": " So I'm just going to go to examples, right?",
        "tokens": [
          51604,
          407,
          286,
          478,
          445,
          516,
          281,
          352,
          281,
          5110,
          11,
          558,
          30,
          51736
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1131.36,
        "id": 341,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1130.32,
        "temperature": 0,
        "text": " Isn't it in here somewhere?",
        "tokens": [
          50368,
          6998,
          380,
          309,
          294,
          510,
          4079,
          30,
          50420
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1132.72,
        "id": 342,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1131.36,
        "temperature": 0,
        "text": " Topics, simulate.",
        "tokens": [
          50420,
          8840,
          1167,
          11,
          27817,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1136,
        "id": 343,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1134.08,
        "temperature": 0,
        "text": " No, no, no.",
        "tokens": [
          50556,
          883,
          11,
          572,
          11,
          572,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1137.28,
        "id": 344,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1136,
        "temperature": 0,
        "text": " Okay, I'll be back in a second.",
        "tokens": [
          50652,
          1033,
          11,
          286,
          603,
          312,
          646,
          294,
          257,
          1150,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1143.04,
        "id": 345,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1141.2,
        "temperature": 0,
        "text": " Oh, yeah, I'm back.",
        "tokens": [
          50912,
          876,
          11,
          1338,
          11,
          286,
          478,
          646,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1146.48,
        "id": 346,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1143.04,
        "temperature": 0,
        "text": " I found it under fractals and L-systems tree.",
        "tokens": [
          51004,
          286,
          1352,
          309,
          833,
          17948,
          1124,
          293,
          441,
          12,
          28215,
          82,
          4230,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1151.76,
        "id": 347,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1146.48,
        "temperature": 0,
        "text": " Oh, look, recursive tree by Daniel Schiffman.",
        "tokens": [
          51176,
          876,
          11,
          574,
          11,
          20560,
          488,
          4230,
          538,
          8033,
          2065,
          3661,
          1601,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1155.04,
        "id": 348,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1152.72,
        "temperature": 0,
        "text": " This is my, this is a recursive tree.",
        "tokens": [
          51488,
          639,
          307,
          452,
          11,
          341,
          307,
          257,
          20560,
          488,
          4230,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.27750801813034787,
        "compression_ratio": 1.4818652849740932,
        "end": 1158.32,
        "id": 349,
        "no_speech_prob": 0.0030278137419372797,
        "seek": 113024,
        "start": 1155.04,
        "temperature": 0,
        "text": " And as I move the mouse, it changes the angle.",
        "tokens": [
          51604,
          400,
          382,
          286,
          1286,
          264,
          9719,
          11,
          309,
          2962,
          264,
          5802,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1160.1599999999999,
        "id": 350,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1158.32,
        "temperature": 0,
        "text": " So let's alter this code a little bit.",
        "tokens": [
          50364,
          407,
          718,
          311,
          11337,
          341,
          3089,
          257,
          707,
          857,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1164.8,
        "id": 351,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1161.36,
        "temperature": 0,
        "text": " Let's say that we don't care about a frame rate.",
        "tokens": [
          50516,
          961,
          311,
          584,
          300,
          321,
          500,
          380,
          1127,
          466,
          257,
          3920,
          3314,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1172.72,
        "id": 352,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1165.84,
        "temperature": 0,
        "text": " And let's not, let's have the angle be random between zero and two pi.",
        "tokens": [
          50740,
          400,
          718,
          311,
          406,
          11,
          718,
          311,
          362,
          264,
          5802,
          312,
          4974,
          1296,
          4018,
          293,
          732,
          3895,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1174.32,
        "id": 353,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1172.72,
        "temperature": 0,
        "text": " Oh, and it's converting it to radians.",
        "tokens": [
          51084,
          876,
          11,
          293,
          309,
          311,
          29942,
          309,
          281,
          2843,
          2567,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1176.1599999999999,
        "id": 354,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1174.32,
        "temperature": 0,
        "text": " So okay, between zero and 360.",
        "tokens": [
          51164,
          407,
          1392,
          11,
          1296,
          4018,
          293,
          13898,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1180.1599999999999,
        "id": 355,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1177.76,
        "temperature": 0,
        "text": " Whoa, it's doing it over and over again in draw.",
        "tokens": [
          51336,
          7521,
          11,
          309,
          311,
          884,
          309,
          670,
          293,
          670,
          797,
          294,
          2642,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1180.96,
        "id": 356,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1180.1599999999999,
        "temperature": 0,
        "text": " That's exciting.",
        "tokens": [
          51456,
          663,
          311,
          4670,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.1918249037659284,
        "compression_ratio": 1.5458937198067633,
        "end": 1182.72,
        "id": 357,
        "no_speech_prob": 0.00016865247744135559,
        "seek": 115832,
        "start": 1181.6799999999998,
        "temperature": 0,
        "text": " I'm going to say no loop.",
        "tokens": [
          51532,
          286,
          478,
          516,
          281,
          584,
          572,
          6367,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1183.44,
        "id": 358,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1182.88,
        "temperature": 0,
        "text": " So it's done.",
        "tokens": [
          50372,
          407,
          309,
          311,
          1096,
          13,
          50400
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1186.48,
        "id": 359,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1183.44,
        "temperature": 0,
        "text": " Each time I run this, I get a random tree.",
        "tokens": [
          50400,
          6947,
          565,
          286,
          1190,
          341,
          11,
          286,
          483,
          257,
          4974,
          4230,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1189.1200000000001,
        "id": 360,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1186.48,
        "temperature": 0,
        "text": " There's so much more that I could do to the design of the tree.",
        "tokens": [
          50552,
          821,
          311,
          370,
          709,
          544,
          300,
          286,
          727,
          360,
          281,
          264,
          1715,
          295,
          264,
          4230,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1191.6000000000001,
        "id": 361,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1189.1200000000001,
        "temperature": 0,
        "text": " And I'm so tempted to recode the tree.",
        "tokens": [
          50684,
          400,
          286,
          478,
          370,
          29941,
          281,
          850,
          1429,
          264,
          4230,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1193.28,
        "id": 362,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1191.6000000000001,
        "temperature": 0,
        "text": " But I'm going to just leave it as is.",
        "tokens": [
          50808,
          583,
          286,
          478,
          516,
          281,
          445,
          1856,
          309,
          382,
          307,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1197.28,
        "id": 363,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1193.28,
        "temperature": 0,
        "text": " You know, maybe I want to like not have so many large angles.",
        "tokens": [
          50892,
          509,
          458,
          11,
          1310,
          286,
          528,
          281,
          411,
          406,
          362,
          370,
          867,
          2416,
          14708,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1198.4,
        "id": 364,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1197.28,
        "temperature": 0,
        "text": " And there we go, beautiful tree.",
        "tokens": [
          51092,
          400,
          456,
          321,
          352,
          11,
          2238,
          4230,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1202.8,
        "id": 365,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1198.4,
        "temperature": 0,
        "text": " Okay, so now, now that I've done that, what do I want?",
        "tokens": [
          51148,
          1033,
          11,
          370,
          586,
          11,
          586,
          300,
          286,
          600,
          1096,
          300,
          11,
          437,
          360,
          286,
          528,
          30,
          51368
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1205.84,
        "id": 366,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1202.8,
        "temperature": 0,
        "text": " I want my processing sketch to also save.",
        "tokens": [
          51368,
          286,
          528,
          452,
          9007,
          12325,
          281,
          611,
          3155,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.26165225351457116,
        "compression_ratio": 1.6436781609195403,
        "end": 1209.28,
        "id": 367,
        "no_speech_prob": 0.00015118143346626312,
        "seek": 118272,
        "start": 1207.2,
        "temperature": 0,
        "text": " And I'm just going to call it tree.png.",
        "tokens": [
          51588,
          400,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          4230,
          13,
          79,
          872,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1211.04,
        "id": 368,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1209.28,
        "temperature": 0,
        "text": " I'm just going to call it tree.png.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          4230,
          13,
          79,
          872,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1214.08,
        "id": 369,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1211.04,
        "temperature": 0,
        "text": " So when it's done drawing, it's going to save an image.",
        "tokens": [
          50452,
          407,
          562,
          309,
          311,
          1096,
          6316,
          11,
          309,
          311,
          516,
          281,
          3155,
          364,
          3256,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1216.24,
        "id": 370,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1215.2,
        "temperature": 0,
        "text": " Okay, this is exciting.",
        "tokens": [
          50660,
          1033,
          11,
          341,
          307,
          4670,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1218.8799999999999,
        "id": 371,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1217.04,
        "temperature": 0,
        "text": " Now I need to save this somewhere.",
        "tokens": [
          50752,
          823,
          286,
          643,
          281,
          3155,
          341,
          4079,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1224.16,
        "id": 372,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1218.8799999999999,
        "temperature": 0,
        "text": " Well, where I've got my Mastodon code right here to talk to the bot.",
        "tokens": [
          50844,
          1042,
          11,
          689,
          286,
          600,
          658,
          452,
          376,
          525,
          378,
          266,
          3089,
          558,
          510,
          281,
          751,
          281,
          264,
          10592,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1227.36,
        "id": 373,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1224.16,
        "temperature": 0,
        "text": " And so what I want to do actually is I probably, to talk to the bot.",
        "tokens": [
          51108,
          400,
          370,
          437,
          286,
          528,
          281,
          360,
          767,
          307,
          286,
          1391,
          11,
          281,
          751,
          281,
          264,
          10592,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1230.56,
        "id": 374,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1229.12,
        "temperature": 0,
        "text": " I've got my Mastodon code.",
        "tokens": [
          51356,
          286,
          600,
          658,
          452,
          376,
          525,
          378,
          266,
          3089,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1232.8,
        "id": 375,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1231.44,
        "temperature": 0,
        "text": " My brain is turned off today.",
        "tokens": [
          51472,
          1222,
          3567,
          307,
          3574,
          766,
          965,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.2752382577943408,
        "compression_ratio": 1.6266666666666667,
        "end": 1234.16,
        "id": 376,
        "no_speech_prob": 0.010818339884281158,
        "seek": 120928,
        "start": 1232.8,
        "temperature": 0,
        "text": " Look, stretch break.",
        "tokens": [
          51540,
          2053,
          11,
          5985,
          1821,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1235.92,
        "id": 377,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1234.4,
        "temperature": 0,
        "text": " I'm going to have a little water over here.",
        "tokens": [
          50376,
          286,
          478,
          516,
          281,
          362,
          257,
          707,
          1281,
          670,
          510,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1241.44,
        "id": 378,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1240.64,
        "temperature": 0,
        "text": " I think we need to slow down.",
        "tokens": [
          50688,
          286,
          519,
          321,
          643,
          281,
          2964,
          760,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1245.52,
        "id": 379,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1243.28,
        "temperature": 0,
        "text": " Yeah, I made the tree in p5 also in a coding challenge.",
        "tokens": [
          50820,
          865,
          11,
          286,
          1027,
          264,
          4230,
          294,
          280,
          20,
          611,
          294,
          257,
          17720,
          3430,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1248.0800000000002,
        "id": 380,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1246.48,
        "temperature": 0,
        "text": " I've got my code here.",
        "tokens": [
          50980,
          286,
          600,
          658,
          452,
          3089,
          510,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1251.1200000000001,
        "id": 381,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1248.0800000000002,
        "temperature": 0,
        "text": " This is the code that will talk to the Mastodon service.",
        "tokens": [
          51060,
          639,
          307,
          264,
          3089,
          300,
          486,
          751,
          281,
          264,
          376,
          525,
          378,
          266,
          2643,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1254.5600000000002,
        "id": 382,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1251.1200000000001,
        "temperature": 0,
        "text": " And what I want is for this code to actually run a processing sketch.",
        "tokens": [
          51212,
          400,
          437,
          286,
          528,
          307,
          337,
          341,
          3089,
          281,
          767,
          1190,
          257,
          9007,
          12325,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1255.68,
        "id": 383,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1254.5600000000002,
        "temperature": 0,
        "text": " But this is Node.",
        "tokens": [
          51384,
          583,
          341,
          307,
          38640,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1256.64,
        "id": 384,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1255.68,
        "temperature": 0,
        "text": " This is JavaScript.",
        "tokens": [
          51440,
          639,
          307,
          15778,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.4809262459738213,
        "compression_ratio": 1.553648068669528,
        "end": 1260.5600000000002,
        "id": 385,
        "no_speech_prob": 0.0003625886747613549,
        "seek": 123416,
        "start": 1257.44,
        "temperature": 0,
        "text": " Processing is Java and it's like a T-Series.",
        "tokens": [
          51528,
          31093,
          278,
          307,
          10745,
          293,
          309,
          311,
          411,
          257,
          314,
          12,
          50,
          21659,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1261.36,
        "id": 386,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1260.56,
        "temperature": 0,
        "text": " This is JavaScript.",
        "tokens": [
          50364,
          639,
          307,
          15778,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1266.56,
        "id": 387,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1262.08,
        "temperature": 0,
        "text": " Processing is Java and it's like a desktop environment where I hit the play button.",
        "tokens": [
          50440,
          31093,
          278,
          307,
          10745,
          293,
          309,
          311,
          411,
          257,
          14502,
          2823,
          689,
          286,
          2045,
          264,
          862,
          2960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1268,
        "id": 388,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1266.56,
        "temperature": 0,
        "text": " How can I possibly do this?",
        "tokens": [
          50664,
          1012,
          393,
          286,
          6264,
          360,
          341,
          30,
          50736
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1271.52,
        "id": 389,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1268,
        "temperature": 0,
        "text": " Well, the first thing I'm going to do is actually go and save this processing sketch",
        "tokens": [
          50736,
          1042,
          11,
          264,
          700,
          551,
          286,
          478,
          516,
          281,
          360,
          307,
          767,
          352,
          293,
          3155,
          341,
          9007,
          12325,
          50912
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1274.32,
        "id": 390,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1272.3999999999999,
        "temperature": 0,
        "text": " in where my bot is.",
        "tokens": [
          50956,
          294,
          689,
          452,
          10592,
          307,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1276.8799999999999,
        "id": 391,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1274.32,
        "temperature": 0,
        "text": " And I'm actually working in this folder, Mastodon bot 3.",
        "tokens": [
          51052,
          400,
          286,
          478,
          767,
          1364,
          294,
          341,
          10820,
          11,
          376,
          525,
          378,
          266,
          10592,
          805,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1278.8799999999999,
        "id": 392,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1276.8799999999999,
        "temperature": 0,
        "text": " You can see Node modules, bot.js.",
        "tokens": [
          51180,
          509,
          393,
          536,
          38640,
          16679,
          11,
          10592,
          13,
          25530,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1280,
        "id": 393,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1278.8799999999999,
        "temperature": 0,
        "text": " So I'm going to save it there.",
        "tokens": [
          51280,
          407,
          286,
          478,
          516,
          281,
          3155,
          309,
          456,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1282.24,
        "id": 394,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1280,
        "temperature": 0,
        "text": " I'm going to call it tree gen.",
        "tokens": [
          51336,
          286,
          478,
          516,
          281,
          818,
          309,
          4230,
          1049,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1286.1599999999999,
        "id": 395,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1284.1599999999999,
        "temperature": 0,
        "text": " So I'm going to save it, tree gen.",
        "tokens": [
          51544,
          407,
          286,
          478,
          516,
          281,
          3155,
          309,
          11,
          4230,
          1049,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1287.84,
        "id": 396,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1286.1599999999999,
        "temperature": 0,
        "text": " I'm going to make sure it still runs.",
        "tokens": [
          51644,
          286,
          478,
          516,
          281,
          652,
          988,
          309,
          920,
          6676,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.19596942695411476,
        "compression_ratio": 1.8,
        "end": 1289.2,
        "id": 397,
        "no_speech_prob": 0.013636261224746704,
        "seek": 126056,
        "start": 1288.3999999999999,
        "temperature": 0,
        "text": " It still runs.",
        "tokens": [
          51756,
          467,
          920,
          6676,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1292.72,
        "id": 398,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1290.0800000000002,
        "temperature": 0,
        "text": " And now what I'm going to do, I'm going to show you a little trick.",
        "tokens": [
          50408,
          400,
          586,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          257,
          707,
          4282,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1298.56,
        "id": 399,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1292.72,
        "temperature": 0,
        "text": " Now, wouldn't it be nice if in the in terminal, I could do things like just say,",
        "tokens": [
          50540,
          823,
          11,
          2759,
          380,
          309,
          312,
          1481,
          498,
          294,
          264,
          294,
          14709,
          11,
          286,
          727,
          360,
          721,
          411,
          445,
          584,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1300.64,
        "id": 400,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1298.56,
        "temperature": 0,
        "text": " hey, run processing.",
        "tokens": [
          50832,
          4177,
          11,
          1190,
          9007,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1302.4,
        "id": 401,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1300.64,
        "temperature": 0,
        "text": " But it says processing is not found.",
        "tokens": [
          50936,
          583,
          309,
          1619,
          9007,
          307,
          406,
          1352,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1304.8,
        "id": 402,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1302.4,
        "temperature": 0,
        "text": " What if I were to say processing-java?",
        "tokens": [
          51024,
          708,
          498,
          286,
          645,
          281,
          584,
          9007,
          12,
          73,
          4061,
          30,
          51144
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1306.48,
        "id": 403,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1304.8,
        "temperature": 0,
        "text": " Permission denied.",
        "tokens": [
          51144,
          41006,
          3106,
          17774,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1307.76,
        "id": 404,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1306.48,
        "temperature": 0,
        "text": " It's different.",
        "tokens": [
          51228,
          467,
          311,
          819,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1308.8,
        "id": 405,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1307.76,
        "temperature": 0,
        "text": " How interesting.",
        "tokens": [
          51292,
          1012,
          1880,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1313.3600000000001,
        "id": 406,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1312.24,
        "temperature": 0,
        "text": " Let's start that over.",
        "tokens": [
          51516,
          961,
          311,
          722,
          300,
          670,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.24625508827075623,
        "compression_ratio": 1.6053811659192825,
        "end": 1314.72,
        "id": 407,
        "no_speech_prob": 0.00001952584534592461,
        "seek": 128920,
        "start": 1313.3600000000001,
        "temperature": 0,
        "text": " I didn't know I was going to do that.",
        "tokens": [
          51572,
          286,
          994,
          380,
          458,
          286,
          390,
          516,
          281,
          360,
          300,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.19404495514190948,
        "compression_ratio": 1.7211155378486056,
        "end": 1319.28,
        "id": 408,
        "no_speech_prob": 0.004198751412332058,
        "seek": 131472,
        "start": 1314.72,
        "temperature": 0,
        "text": " Wouldn't it be nice if I could just execute a command like processing run?",
        "tokens": [
          50364,
          26291,
          380,
          309,
          312,
          1481,
          498,
          286,
          727,
          445,
          14483,
          257,
          5622,
          411,
          9007,
          1190,
          30,
          50592
        ]
      },
      {
        "avg_logprob": -0.19404495514190948,
        "compression_ratio": 1.7211155378486056,
        "end": 1323.6000000000001,
        "id": 409,
        "no_speech_prob": 0.004198751412332058,
        "seek": 131472,
        "start": 1320.32,
        "temperature": 0,
        "text": " Of course, in terminal, in the shell, it's not going to know what that is.",
        "tokens": [
          50644,
          2720,
          1164,
          11,
          294,
          14709,
          11,
          294,
          264,
          8720,
          11,
          309,
          311,
          406,
          516,
          281,
          458,
          437,
          300,
          307,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.19404495514190948,
        "compression_ratio": 1.7211155378486056,
        "end": 1328.8,
        "id": 410,
        "no_speech_prob": 0.004198751412332058,
        "seek": 131472,
        "start": 1323.6000000000001,
        "temperature": 0,
        "text": " But a little known fact about processing, which I have done this in other videos before.",
        "tokens": [
          50808,
          583,
          257,
          707,
          2570,
          1186,
          466,
          9007,
          11,
          597,
          286,
          362,
          1096,
          341,
          294,
          661,
          2145,
          949,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.19404495514190948,
        "compression_ratio": 1.7211155378486056,
        "end": 1333.2,
        "id": 411,
        "no_speech_prob": 0.004198751412332058,
        "seek": 131472,
        "start": 1328.8,
        "temperature": 0,
        "text": " But just to start anew again, processing command line.",
        "tokens": [
          51068,
          583,
          445,
          281,
          722,
          364,
          1023,
          797,
          11,
          9007,
          5622,
          1622,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.19404495514190948,
        "compression_ratio": 1.7211155378486056,
        "end": 1339.76,
        "id": 412,
        "no_speech_prob": 0.004198751412332058,
        "seek": 131472,
        "start": 1334.56,
        "temperature": 0,
        "text": " There is actually a way to run a processing sketch command line by saying",
        "tokens": [
          51356,
          821,
          307,
          767,
          257,
          636,
          281,
          1190,
          257,
          9007,
          12325,
          5622,
          1622,
          538,
          1566,
          51616
        ]
      },
      {
        "avg_logprob": -0.19404495514190948,
        "compression_ratio": 1.7211155378486056,
        "end": 1344.32,
        "id": 413,
        "no_speech_prob": 0.004198751412332058,
        "seek": 131472,
        "start": 1339.76,
        "temperature": 0,
        "text": " processing-java, the path of the sketch, and then dash dash run.",
        "tokens": [
          51616,
          9007,
          12,
          73,
          4061,
          11,
          264,
          3100,
          295,
          264,
          12325,
          11,
          293,
          550,
          8240,
          8240,
          1190,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.20824388938375038,
        "compression_ratio": 1.8775510204081634,
        "end": 1350.08,
        "id": 414,
        "no_speech_prob": 0.000009080340532818809,
        "seek": 134432,
        "start": 1344.48,
        "temperature": 0,
        "text": " The only way you can do that is by installing first processing.java to your system.",
        "tokens": [
          50372,
          440,
          787,
          636,
          291,
          393,
          360,
          300,
          307,
          538,
          20762,
          700,
          9007,
          13,
          73,
          4061,
          281,
          428,
          1185,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.20824388938375038,
        "compression_ratio": 1.8775510204081634,
        "end": 1357.6799999999998,
        "id": 415,
        "no_speech_prob": 0.000009080340532818809,
        "seek": 134432,
        "start": 1350.08,
        "temperature": 0,
        "text": " This is installing a command line command to run a processing sketch.",
        "tokens": [
          50652,
          639,
          307,
          20762,
          257,
          5622,
          1622,
          5622,
          281,
          1190,
          257,
          9007,
          12325,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.20824388938375038,
        "compression_ratio": 1.8775510204081634,
        "end": 1359.6,
        "id": 416,
        "no_speech_prob": 0.000009080340532818809,
        "seek": 134432,
        "start": 1357.6799999999998,
        "temperature": 0,
        "text": " I'm going to do this, install processing.java.",
        "tokens": [
          51032,
          286,
          478,
          516,
          281,
          360,
          341,
          11,
          3625,
          9007,
          13,
          73,
          4061,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.20824388938375038,
        "compression_ratio": 1.8775510204081634,
        "end": 1361.12,
        "id": 417,
        "no_speech_prob": 0.000009080340532818809,
        "seek": 134432,
        "start": 1359.6,
        "temperature": 0,
        "text": " I'm going to say yes for all users.",
        "tokens": [
          51128,
          286,
          478,
          516,
          281,
          584,
          2086,
          337,
          439,
          5022,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.20824388938375038,
        "compression_ratio": 1.8775510204081634,
        "end": 1364.56,
        "id": 418,
        "no_speech_prob": 0.000009080340532818809,
        "seek": 134432,
        "start": 1362.72,
        "temperature": 0,
        "text": " It's going to want to use my password.",
        "tokens": [
          51284,
          467,
          311,
          516,
          281,
          528,
          281,
          764,
          452,
          11524,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.20824388938375038,
        "compression_ratio": 1.8775510204081634,
        "end": 1372.48,
        "id": 419,
        "no_speech_prob": 0.000009080340532818809,
        "seek": 134432,
        "start": 1367.4399999999998,
        "temperature": 0,
        "text": " I'm going to enter my password because it needs to be able to put that where it needs to go.",
        "tokens": [
          51520,
          286,
          478,
          516,
          281,
          3242,
          452,
          11524,
          570,
          309,
          2203,
          281,
          312,
          1075,
          281,
          829,
          300,
          689,
          309,
          2203,
          281,
          352,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1374.56,
        "id": 420,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1372.48,
        "temperature": 0,
        "text": " Now I can actually say processing-java.",
        "tokens": [
          50364,
          823,
          286,
          393,
          767,
          584,
          9007,
          12,
          73,
          4061,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1377.04,
        "id": 421,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1375.6,
        "temperature": 0,
        "text": " You can see I get all sorts of stuff.",
        "tokens": [
          50520,
          509,
          393,
          536,
          286,
          483,
          439,
          7527,
          295,
          1507,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1378.96,
        "id": 422,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1377.04,
        "temperature": 0,
        "text": " It doesn't know what I want to do, but watch this.",
        "tokens": [
          50592,
          467,
          1177,
          380,
          458,
          437,
          286,
          528,
          281,
          360,
          11,
          457,
          1159,
          341,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1381.84,
        "id": 423,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1379.76,
        "temperature": 0,
        "text": " I can say, let me just look in here.",
        "tokens": [
          50728,
          286,
          393,
          584,
          11,
          718,
          385,
          445,
          574,
          294,
          510,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1384.96,
        "id": 424,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1381.84,
        "temperature": 0,
        "text": " There is the tree gen processing sketch.",
        "tokens": [
          50832,
          821,
          307,
          264,
          4230,
          1049,
          9007,
          12325,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1390,
        "id": 425,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1384.96,
        "temperature": 0,
        "text": " I can say processing-java sketch equals.",
        "tokens": [
          50988,
          286,
          393,
          584,
          9007,
          12,
          73,
          4061,
          12325,
          6915,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1390.72,
        "id": 426,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1390,
        "temperature": 0,
        "text": " Is that what it was?",
        "tokens": [
          51240,
          1119,
          300,
          437,
          309,
          390,
          30,
          51276
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1393.28,
        "id": 427,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1390.72,
        "temperature": 0,
        "text": " Let's go look at the sketch equals.",
        "tokens": [
          51276,
          961,
          311,
          352,
          574,
          412,
          264,
          12325,
          6915,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1394.96,
        "id": 428,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1393.28,
        "temperature": 0,
        "text": " Now I need the full path.",
        "tokens": [
          51404,
          823,
          286,
          643,
          264,
          1577,
          3100,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1399.84,
        "id": 429,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1396.16,
        "temperature": 0,
        "text": " The full path, and I'm going to show you a way around this in a second, is this.",
        "tokens": [
          51548,
          440,
          1577,
          3100,
          11,
          293,
          286,
          478,
          516,
          281,
          855,
          291,
          257,
          636,
          926,
          341,
          294,
          257,
          1150,
          11,
          307,
          341,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2139360228581215,
        "compression_ratio": 1.7396694214876034,
        "end": 1401.84,
        "id": 430,
        "no_speech_prob": 0.0008295808802358806,
        "seek": 137248,
        "start": 1400.88,
        "temperature": 0,
        "text": " Tree gen.",
        "tokens": [
          51784,
          22291,
          1049,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1404,
        "id": 431,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1401.84,
        "temperature": 0,
        "text": " This is the full path of that processing sketch.",
        "tokens": [
          50364,
          639,
          307,
          264,
          1577,
          3100,
          295,
          300,
          9007,
          12325,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1405.4399999999998,
        "id": 432,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1404,
        "temperature": 0,
        "text": " Then I can say dash dash run.",
        "tokens": [
          50472,
          1396,
          286,
          393,
          584,
          8240,
          8240,
          1190,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1407.04,
        "id": 433,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1406.56,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50600,
          1692,
          321,
          352,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1409.84,
        "id": 434,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1408.9599999999998,
        "temperature": 0,
        "text": " Magic!",
        "tokens": [
          50720,
          16154,
          0,
          50764
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1410.56,
        "id": 435,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1409.84,
        "temperature": 0,
        "text": " It ran it!",
        "tokens": [
          50764,
          467,
          5872,
          309,
          0,
          50800
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1412,
        "id": 436,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1410.56,
        "temperature": 0,
        "text": " Look, there's the processing sketch.",
        "tokens": [
          50800,
          2053,
          11,
          456,
          311,
          264,
          9007,
          12325,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1412.8,
        "id": 437,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1412,
        "temperature": 0,
        "text": " This is really cool.",
        "tokens": [
          50872,
          639,
          307,
          534,
          1627,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1413.6,
        "id": 438,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1412.8,
        "temperature": 0,
        "text": " Now watch.",
        "tokens": [
          50912,
          823,
          1159,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1419.4399999999998,
        "id": 439,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1413.6,
        "temperature": 0,
        "text": " What's exciting about this, and it's bothering me that the background isn't 51, which is very important.",
        "tokens": [
          50952,
          708,
          311,
          4670,
          466,
          341,
          11,
          293,
          309,
          311,
          31432,
          385,
          300,
          264,
          3678,
          1943,
          380,
          18485,
          11,
          597,
          307,
          588,
          1021,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1421.4399999999998,
        "id": 440,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1419.4399999999998,
        "temperature": 0,
        "text": " I can actually quit processing completely.",
        "tokens": [
          51244,
          286,
          393,
          767,
          10366,
          9007,
          2584,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1424.48,
        "id": 441,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1422.1599999999999,
        "temperature": 0,
        "text": " I don't need to have processing open and still do this.",
        "tokens": [
          51380,
          286,
          500,
          380,
          643,
          281,
          362,
          9007,
          1269,
          293,
          920,
          360,
          341,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1426.8,
        "id": 442,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1425.84,
        "temperature": 0,
        "text": " Look at that, there it is.",
        "tokens": [
          51564,
          2053,
          412,
          300,
          11,
          456,
          309,
          307,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.22035051492544322,
        "compression_ratio": 1.6577946768060836,
        "end": 1428.3999999999999,
        "id": 443,
        "no_speech_prob": 0.0004173126071691513,
        "seek": 140184,
        "start": 1426.8,
        "temperature": 0,
        "text": " There's my tree, beautiful.",
        "tokens": [
          51612,
          821,
          311,
          452,
          4230,
          11,
          2238,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1431.92,
        "id": 444,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1428.48,
        "temperature": 0,
        "text": " But I actually do want to have processing open because I've got a little bit of a problem here.",
        "tokens": [
          50368,
          583,
          286,
          767,
          360,
          528,
          281,
          362,
          9007,
          1269,
          570,
          286,
          600,
          658,
          257,
          707,
          857,
          295,
          257,
          1154,
          510,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1435.3600000000001,
        "id": 445,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1432.5600000000002,
        "temperature": 0,
        "text": " We can see here, look, that image is there.",
        "tokens": [
          50572,
          492,
          393,
          536,
          510,
          11,
          574,
          11,
          300,
          3256,
          307,
          456,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1436.5600000000002,
        "id": 446,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1435.3600000000001,
        "temperature": 0,
        "text": " It's now saved.",
        "tokens": [
          50712,
          467,
          311,
          586,
          6624,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1440.48,
        "id": 447,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1436.5600000000002,
        "temperature": 0,
        "text": " What I want to do is go back and open this again.",
        "tokens": [
          50772,
          708,
          286,
          528,
          281,
          360,
          307,
          352,
          646,
          293,
          1269,
          341,
          797,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1443.76,
        "id": 448,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1442.0800000000002,
        "temperature": 0,
        "text": " Open, open, open, open, open.",
        "tokens": [
          51048,
          7238,
          11,
          1269,
          11,
          1269,
          11,
          1269,
          11,
          1269,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1444.8000000000002,
        "id": 449,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1443.76,
        "temperature": 0,
        "text": " I want to add one thing.",
        "tokens": [
          51132,
          286,
          528,
          281,
          909,
          472,
          551,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1447.3600000000001,
        "id": 450,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1446.48,
        "temperature": 0,
        "text": " I want it to go away.",
        "tokens": [
          51268,
          286,
          528,
          309,
          281,
          352,
          1314,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1451.1200000000001,
        "id": 451,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1448.8000000000002,
        "temperature": 0,
        "text": " I actually want to say, after I save it, exit.",
        "tokens": [
          51384,
          286,
          767,
          528,
          281,
          584,
          11,
          934,
          286,
          3155,
          309,
          11,
          11043,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1454.24,
        "id": 452,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1452.5600000000002,
        "temperature": 0,
        "text": " This is going to be helpful for me later.",
        "tokens": [
          51572,
          639,
          307,
          516,
          281,
          312,
          4961,
          337,
          385,
          1780,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.19016122448351958,
        "compression_ratio": 1.738396624472574,
        "end": 1457.1200000000001,
        "id": 453,
        "no_speech_prob": 0.0005703127826564014,
        "seek": 142840,
        "start": 1454.24,
        "temperature": 0,
        "text": " I want to say print line tree generated.",
        "tokens": [
          51656,
          286,
          528,
          281,
          584,
          4482,
          1622,
          4230,
          10833,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1459.04,
        "id": 454,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1457.12,
        "temperature": 0,
        "text": " You'll see where this comes up later.",
        "tokens": [
          50364,
          509,
          603,
          536,
          689,
          341,
          1487,
          493,
          1780,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1461.52,
        "id": 455,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1459.04,
        "temperature": 0,
        "text": " Okay, now, quit processing.",
        "tokens": [
          50460,
          1033,
          11,
          586,
          11,
          10366,
          9007,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1465.12,
        "id": 456,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1463.6,
        "temperature": 0,
        "text": " And now, I'm going to run this.",
        "tokens": [
          50688,
          400,
          586,
          11,
          286,
          478,
          516,
          281,
          1190,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1467.04,
        "id": 457,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1466.7199999999998,
        "temperature": 0,
        "text": " See it?",
        "tokens": [
          50844,
          3008,
          309,
          30,
          50860
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1467.4399999999998,
        "id": 458,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1467.04,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          50860,
          821,
          309,
          307,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1468,
        "id": 459,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1467.4399999999998,
        "temperature": 0,
        "text": " Oh, finished.",
        "tokens": [
          50880,
          876,
          11,
          4335,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1468.9599999999998,
        "id": 460,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1468,
        "temperature": 0,
        "text": " Tree generated, finished.",
        "tokens": [
          50908,
          22291,
          10833,
          11,
          4335,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1470.2399999999998,
        "id": 461,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1469.6,
        "temperature": 0,
        "text": " One more time.",
        "tokens": [
          50988,
          1485,
          544,
          565,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1473.28,
        "id": 462,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1472.2399999999998,
        "temperature": 0,
        "text": " There it is, oh, finished.",
        "tokens": [
          51120,
          821,
          309,
          307,
          11,
          1954,
          11,
          4335,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1476.32,
        "id": 463,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1473.28,
        "temperature": 0,
        "text": " Okay, this is really exciting because there's so much stuff you could do.",
        "tokens": [
          51172,
          1033,
          11,
          341,
          307,
          534,
          4670,
          570,
          456,
          311,
          370,
          709,
          1507,
          291,
          727,
          360,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1477.4399999999998,
        "id": 464,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1476.32,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          51324,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1484.6399999999999,
        "id": 465,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1477.4399999999998,
        "temperature": 0,
        "text": " I am executing this command via the shell, but I want node to execute it.",
        "tokens": [
          51380,
          286,
          669,
          32368,
          341,
          5622,
          5766,
          264,
          8720,
          11,
          457,
          286,
          528,
          9984,
          281,
          14483,
          309,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.21024680504432092,
        "compression_ratio": 1.6502057613168724,
        "end": 1486.1599999999999,
        "id": 466,
        "no_speech_prob": 0.00001750289447954856,
        "seek": 145712,
        "start": 1484.6399999999999,
        "temperature": 0,
        "text": " How can I execute it in node?",
        "tokens": [
          51740,
          1012,
          393,
          286,
          14483,
          309,
          294,
          9984,
          30,
          51816
        ]
      },
      {
        "avg_logprob": -0.22387374074835525,
        "compression_ratio": 1.6857142857142857,
        "end": 1492.48,
        "id": 467,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 148616,
        "start": 1486.24,
        "temperature": 0,
        "text": " It turns out there is a way to execute any generic shell command from node.",
        "tokens": [
          50368,
          467,
          4523,
          484,
          456,
          307,
          257,
          636,
          281,
          14483,
          604,
          19577,
          8720,
          5622,
          490,
          9984,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.22387374074835525,
        "compression_ratio": 1.6857142857142857,
        "end": 1496.24,
        "id": 468,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 148616,
        "start": 1492.48,
        "temperature": 0,
        "text": " It is with the child process package.",
        "tokens": [
          50680,
          467,
          307,
          365,
          264,
          1440,
          1399,
          7372,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.22387374074835525,
        "compression_ratio": 1.6857142857142857,
        "end": 1502.96,
        "id": 469,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 148616,
        "start": 1497.2,
        "temperature": 0,
        "text": " If I go to child process, you'll see here that there is a method called exec.",
        "tokens": [
          50916,
          759,
          286,
          352,
          281,
          1440,
          1399,
          11,
          291,
          603,
          536,
          510,
          300,
          456,
          307,
          257,
          3170,
          1219,
          4454,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.22387374074835525,
        "compression_ratio": 1.6857142857142857,
        "end": 1506,
        "id": 470,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 148616,
        "start": 1504.24,
        "temperature": 0,
        "text": " Child process dot exec.",
        "tokens": [
          51268,
          9004,
          1399,
          5893,
          4454,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.22387374074835525,
        "compression_ratio": 1.6857142857142857,
        "end": 1508.72,
        "id": 471,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 148616,
        "start": 1506,
        "temperature": 0,
        "text": " Spawns a shell and runs a command within that shell.",
        "tokens": [
          51356,
          1738,
          11251,
          82,
          257,
          8720,
          293,
          6676,
          257,
          5622,
          1951,
          300,
          8720,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.22387374074835525,
        "compression_ratio": 1.6857142857142857,
        "end": 1514.0800000000002,
        "id": 472,
        "no_speech_prob": 0.0000016797312127891928,
        "seek": 148616,
        "start": 1509.52,
        "temperature": 0,
        "text": " Truth of the matter is, it might be useful to use this exec sync because I'm going to",
        "tokens": [
          51532,
          20522,
          295,
          264,
          1871,
          307,
          11,
          309,
          1062,
          312,
          4420,
          281,
          764,
          341,
          4454,
          20271,
          570,
          286,
          478,
          516,
          281,
          51760
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1518.72,
        "id": 473,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1514.56,
        "temperature": 0,
        "text": " sync means synchronous, meaning wait until it's done to go on to the next thing.",
        "tokens": [
          50388,
          20271,
          1355,
          44743,
          11,
          3620,
          1699,
          1826,
          309,
          311,
          1096,
          281,
          352,
          322,
          281,
          264,
          958,
          551,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1520.56,
        "id": 474,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1518.72,
        "temperature": 0,
        "text": " I've got a crazy plan here.",
        "tokens": [
          50596,
          286,
          600,
          658,
          257,
          3219,
          1393,
          510,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1524.6399999999999,
        "id": 475,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1520.56,
        "temperature": 0,
        "text": " I want to do asynchronous stuff with es8, this await and async function that you may",
        "tokens": [
          50688,
          286,
          528,
          281,
          360,
          49174,
          1507,
          365,
          785,
          23,
          11,
          341,
          19670,
          293,
          382,
          34015,
          2445,
          300,
          291,
          815,
          50892
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1525.6799999999998,
        "id": 476,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1524.6399999999999,
        "temperature": 0,
        "text": " or may not have heard about.",
        "tokens": [
          50892,
          420,
          815,
          406,
          362,
          2198,
          466,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1528.48,
        "id": 477,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1525.6799999999998,
        "temperature": 0,
        "text": " So, I'm going to use this one, exec.",
        "tokens": [
          50944,
          407,
          11,
          286,
          478,
          516,
          281,
          764,
          341,
          472,
          11,
          4454,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1534.6399999999999,
        "id": 478,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1528.48,
        "temperature": 0,
        "text": " So, what I need to do is in my node code, I need to say const exec equals require.",
        "tokens": [
          51084,
          407,
          11,
          437,
          286,
          643,
          281,
          360,
          307,
          294,
          452,
          9984,
          3089,
          11,
          286,
          643,
          281,
          584,
          1817,
          4454,
          6915,
          3651,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1535.9199999999998,
        "id": 479,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1534.6399999999999,
        "temperature": 0,
        "text": " And where was this?",
        "tokens": [
          51392,
          400,
          689,
          390,
          341,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1538.56,
        "id": 480,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1535.9199999999998,
        "temperature": 0,
        "text": " It is in child process dot exec.",
        "tokens": [
          51456,
          467,
          307,
          294,
          1440,
          1399,
          5893,
          4454,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1540.32,
        "id": 481,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1538.56,
        "temperature": 0,
        "text": " Child underscore process.",
        "tokens": [
          51588,
          9004,
          37556,
          1399,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1541.6,
        "id": 482,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1541.04,
        "temperature": 0,
        "text": " No, there's no.",
        "tokens": [
          51712,
          883,
          11,
          456,
          311,
          572,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.21164231334658837,
        "compression_ratio": 1.673992673992674,
        "end": 1543.76,
        "id": 483,
        "no_speech_prob": 0.0016484707593917847,
        "seek": 151408,
        "start": 1542.56,
        "temperature": 0,
        "text": " Yeah, that's right.",
        "tokens": [
          51788,
          865,
          11,
          300,
          311,
          558,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1545.04,
        "id": 484,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1544.32,
        "temperature": 0,
        "text": " Oh, dot exec.",
        "tokens": [
          50392,
          876,
          11,
          5893,
          4454,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1546.16,
        "id": 485,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1545.04,
        "temperature": 0,
        "text": " Yes, I'm confused.",
        "tokens": [
          50428,
          1079,
          11,
          286,
          478,
          9019,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1551.52,
        "id": 486,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1546.16,
        "temperature": 0,
        "text": " So, this is me requiring the child process package and I don't have to npm install this.",
        "tokens": [
          50484,
          407,
          11,
          341,
          307,
          385,
          24165,
          264,
          1440,
          1399,
          7372,
          293,
          286,
          500,
          380,
          362,
          281,
          297,
          14395,
          3625,
          341,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1555.44,
        "id": 487,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1551.52,
        "temperature": 0,
        "text": " You'll notice that I'm on the node.js documentation page.",
        "tokens": [
          50752,
          509,
          603,
          3449,
          300,
          286,
          478,
          322,
          264,
          9984,
          13,
          25530,
          14333,
          3028,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1558.4,
        "id": 488,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1555.44,
        "temperature": 0,
        "text": " I'm not in some separate third party npm package.",
        "tokens": [
          50948,
          286,
          478,
          406,
          294,
          512,
          4994,
          2636,
          3595,
          297,
          14395,
          7372,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1561.92,
        "id": 489,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1558.4,
        "temperature": 0,
        "text": " This is built into node, but just like file system is.",
        "tokens": [
          51096,
          639,
          307,
          3094,
          666,
          9984,
          11,
          457,
          445,
          411,
          3991,
          1185,
          307,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1564,
        "id": 490,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1561.92,
        "temperature": 0,
        "text": " But I've got to say that I want to use it.",
        "tokens": [
          51272,
          583,
          286,
          600,
          658,
          281,
          584,
          300,
          286,
          528,
          281,
          764,
          309,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1567.2,
        "id": 491,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1564,
        "temperature": 0,
        "text": " So, require child process and all I want is that exec function.",
        "tokens": [
          51376,
          407,
          11,
          3651,
          1440,
          1399,
          293,
          439,
          286,
          528,
          307,
          300,
          4454,
          2445,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.16948644665704257,
        "compression_ratio": 1.6823104693140793,
        "end": 1572.16,
        "id": 492,
        "no_speech_prob": 0.00005738742765970528,
        "seek": 154376,
        "start": 1567.2,
        "temperature": 0,
        "text": " So, now there's no reason why I can't just say exec and then pass in what?",
        "tokens": [
          51536,
          407,
          11,
          586,
          456,
          311,
          572,
          1778,
          983,
          286,
          393,
          380,
          445,
          584,
          4454,
          293,
          550,
          1320,
          294,
          437,
          30,
          51784
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1574,
        "id": 493,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1573.1200000000001,
        "temperature": 0,
        "text": " Exactly this.",
        "tokens": [
          50412,
          7587,
          341,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1576.24,
        "id": 494,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1574,
        "temperature": 0,
        "text": " Oh, let me make, this is so unwieldy.",
        "tokens": [
          50456,
          876,
          11,
          718,
          385,
          652,
          11,
          341,
          307,
          370,
          14853,
          1789,
          88,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1582.88,
        "id": 495,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1576.24,
        "temperature": 0,
        "text": " So, a nice little trick that I can do is I can actually always get the current path.",
        "tokens": [
          50568,
          407,
          11,
          257,
          1481,
          707,
          4282,
          300,
          286,
          393,
          360,
          307,
          286,
          393,
          767,
          1009,
          483,
          264,
          2190,
          3100,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1588.88,
        "id": 496,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1584.0800000000002,
        "temperature": 0,
        "text": " Right, if I want to get the current path, I just type pwd, print working directory.",
        "tokens": [
          50960,
          1779,
          11,
          498,
          286,
          528,
          281,
          483,
          264,
          2190,
          3100,
          11,
          286,
          445,
          2010,
          280,
          43778,
          11,
          4482,
          1364,
          21120,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1589.6000000000001,
        "id": 497,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1588.88,
        "temperature": 0,
        "text": " Well, guess what?",
        "tokens": [
          51200,
          1042,
          11,
          2041,
          437,
          30,
          51236
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1596,
        "id": 498,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1589.6000000000001,
        "temperature": 0,
        "text": " I can actually have pwd executed within this command by using these back ticks.",
        "tokens": [
          51236,
          286,
          393,
          767,
          362,
          280,
          43778,
          17577,
          1951,
          341,
          5622,
          538,
          1228,
          613,
          646,
          42475,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.19611216953822544,
        "compression_ratio": 1.5707964601769913,
        "end": 1597.52,
        "id": 499,
        "no_speech_prob": 0.00003763638960663229,
        "seek": 157216,
        "start": 1596,
        "temperature": 0,
        "text": " I'm pretty sure this is how I do it.",
        "tokens": [
          51556,
          286,
          478,
          1238,
          988,
          341,
          307,
          577,
          286,
          360,
          309,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1603.76,
        "id": 500,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1598.08,
        "temperature": 0,
        "text": " So, now I'm saying run and I think I don't actually even need this first slash, right?",
        "tokens": [
          50392,
          407,
          11,
          586,
          286,
          478,
          1566,
          1190,
          293,
          286,
          519,
          286,
          500,
          380,
          767,
          754,
          643,
          341,
          700,
          17330,
          11,
          558,
          30,
          50676
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1608.4,
        "id": 501,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1604.32,
        "temperature": 0,
        "text": " Run sketch equals print working directory, then tree gen run.",
        "tokens": [
          50704,
          8950,
          12325,
          6915,
          4482,
          1364,
          21120,
          11,
          550,
          4230,
          1049,
          1190,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1609.28,
        "id": 502,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1608.4,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          50908,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1612,
        "id": 503,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1611.12,
        "temperature": 0,
        "text": " It is done.",
        "tokens": [
          51044,
          467,
          307,
          1096,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1615.76,
        "id": 504,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1612,
        "temperature": 0,
        "text": " Okay, so now, so great.",
        "tokens": [
          51088,
          1033,
          11,
          370,
          586,
          11,
          370,
          869,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1616.8,
        "id": 505,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1615.76,
        "temperature": 0,
        "text": " So, I can grab this.",
        "tokens": [
          51276,
          407,
          11,
          286,
          393,
          4444,
          341,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1617.76,
        "id": 506,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1616.8,
        "temperature": 0,
        "text": " This is my command.",
        "tokens": [
          51328,
          639,
          307,
          452,
          5622,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1621.44,
        "id": 507,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1619.2,
        "temperature": 0,
        "text": " We're going to get to that, the mastodon stuff in a second.",
        "tokens": [
          51448,
          492,
          434,
          516,
          281,
          483,
          281,
          300,
          11,
          264,
          27055,
          378,
          266,
          1507,
          294,
          257,
          1150,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.34207090294879416,
        "compression_ratio": 1.522633744855967,
        "end": 1626.4,
        "id": 508,
        "no_speech_prob": 0.00043732955236919224,
        "seek": 159752,
        "start": 1623.2,
        "temperature": 0,
        "text": " Constant command equals, let's just put this in a variable.",
        "tokens": [
          51648,
          37413,
          5622,
          6915,
          11,
          718,
          311,
          445,
          829,
          341,
          294,
          257,
          7006,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1628.48,
        "id": 509,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1626.48,
        "temperature": 0,
        "text": " Let's just put this in a variable like this.",
        "tokens": [
          50368,
          961,
          311,
          445,
          829,
          341,
          294,
          257,
          7006,
          411,
          341,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1633.2800000000002,
        "id": 510,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1628.48,
        "temperature": 0,
        "text": " Then I can say exec command and then that's going to have a callback.",
        "tokens": [
          50468,
          1396,
          286,
          393,
          584,
          4454,
          5622,
          293,
          550,
          300,
          311,
          516,
          281,
          362,
          257,
          818,
          3207,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1635.44,
        "id": 511,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1633.2800000000002,
        "temperature": 0,
        "text": " Oh, I don't want the, let me just run this.",
        "tokens": [
          50708,
          876,
          11,
          286,
          500,
          380,
          528,
          264,
          11,
          718,
          385,
          445,
          1190,
          341,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1636.24,
        "id": 512,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1635.44,
        "temperature": 0,
        "text": " Let's just run this.",
        "tokens": [
          50816,
          961,
          311,
          445,
          1190,
          341,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1637.0400000000002,
        "id": 513,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1636.24,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50856,
          961,
          311,
          536,
          437,
          2314,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1640.8000000000002,
        "id": 514,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1639.44,
        "temperature": 0,
        "text": " Node bot.js.",
        "tokens": [
          51016,
          38640,
          10592,
          13,
          25530,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1643.92,
        "id": 515,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1642.72,
        "temperature": 0,
        "text": " Hey, look what happened.",
        "tokens": [
          51180,
          1911,
          11,
          574,
          437,
          2011,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1644.72,
        "id": 516,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1643.92,
        "temperature": 0,
        "text": " It made it happen.",
        "tokens": [
          51240,
          467,
          1027,
          309,
          1051,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1645.44,
        "id": 517,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1644.72,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          51280,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1651.1200000000001,
        "id": 518,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1645.44,
        "temperature": 0,
        "text": " I was, the next thing I was going to do is add a callback, but I'm a new, I'm turning over a new leaf.",
        "tokens": [
          51316,
          286,
          390,
          11,
          264,
          958,
          551,
          286,
          390,
          516,
          281,
          360,
          307,
          909,
          257,
          818,
          3207,
          11,
          457,
          286,
          478,
          257,
          777,
          11,
          286,
          478,
          6246,
          670,
          257,
          777,
          10871,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.20453180207146537,
        "compression_ratio": 1.7370517928286853,
        "end": 1654.4,
        "id": 519,
        "no_speech_prob": 0.00008888074080459774,
        "seek": 162640,
        "start": 1651.1200000000001,
        "temperature": 0,
        "text": " I'm turning a new page in the book of JavaScript.",
        "tokens": [
          51600,
          286,
          478,
          6246,
          257,
          777,
          3028,
          294,
          264,
          1446,
          295,
          15778,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1657.3600000000001,
        "id": 520,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1655.2800000000002,
        "temperature": 0,
        "text": " I'm a kind of person who uses promises.",
        "tokens": [
          50408,
          286,
          478,
          257,
          733,
          295,
          954,
          567,
          4960,
          16403,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1663.92,
        "id": 521,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1658,
        "temperature": 0,
        "text": " I'm not only a kind of person who uses promises, I even use the async and await keyword to really",
        "tokens": [
          50544,
          286,
          478,
          406,
          787,
          257,
          733,
          295,
          954,
          567,
          4960,
          16403,
          11,
          286,
          754,
          764,
          264,
          382,
          34015,
          293,
          19670,
          20428,
          281,
          534,
          50840
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1668.48,
        "id": 522,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1663.92,
        "temperature": 0,
        "text": " make my life full of just ease.",
        "tokens": [
          50840,
          652,
          452,
          993,
          1577,
          295,
          445,
          12708,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1672.48,
        "id": 523,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1669.68,
        "temperature": 0,
        "text": " It's not full of ease, but I'm doing my best.",
        "tokens": [
          51128,
          467,
          311,
          406,
          1577,
          295,
          12708,
          11,
          457,
          286,
          478,
          884,
          452,
          1151,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1673.44,
        "id": 524,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1672.48,
        "temperature": 0,
        "text": " So, what does that mean?",
        "tokens": [
          51268,
          407,
          11,
          437,
          775,
          300,
          914,
          30,
          51316
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1678.48,
        "id": 525,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1673.44,
        "temperature": 0,
        "text": " The thing is, this particular node package, child process.exec, and I have a feeling if I",
        "tokens": [
          51316,
          440,
          551,
          307,
          11,
          341,
          1729,
          9984,
          7372,
          11,
          1440,
          1399,
          13,
          3121,
          3045,
          11,
          293,
          286,
          362,
          257,
          2633,
          498,
          286,
          51568
        ]
      },
      {
        "avg_logprob": -0.21103299048639113,
        "compression_ratio": 1.697211155378486,
        "end": 1684,
        "id": 526,
        "no_speech_prob": 0.000004860444278165232,
        "seek": 165440,
        "start": 1678.48,
        "temperature": 0,
        "text": " bother to look at the chat, which I'm going to open up for a second, someone's going to tell me",
        "tokens": [
          51568,
          8677,
          281,
          574,
          412,
          264,
          5081,
          11,
          597,
          286,
          478,
          516,
          281,
          1269,
          493,
          337,
          257,
          1150,
          11,
          1580,
          311,
          516,
          281,
          980,
          385,
          51844
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1687.68,
        "id": 527,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1684,
        "temperature": 0,
        "text": " I could just use something else now that natively supports promises.",
        "tokens": [
          50364,
          286,
          727,
          445,
          764,
          746,
          1646,
          586,
          300,
          8470,
          356,
          9346,
          16403,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1690.88,
        "id": 528,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1687.68,
        "temperature": 0,
        "text": " The E key does not work on this computer, which is invisible to you.",
        "tokens": [
          50548,
          440,
          462,
          2141,
          775,
          406,
          589,
          322,
          341,
          3820,
          11,
          597,
          307,
          14603,
          281,
          291,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1694.96,
        "id": 529,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1693.12,
        "temperature": 0,
        "text": " Oh, it's the wrong, I've been typing in the wrong password.",
        "tokens": [
          50820,
          876,
          11,
          309,
          311,
          264,
          2085,
          11,
          286,
          600,
          668,
          18444,
          294,
          264,
          2085,
          11524,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1695.6,
        "id": 530,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1694.96,
        "temperature": 0,
        "text": " Okay, there it is.",
        "tokens": [
          50912,
          1033,
          11,
          456,
          309,
          307,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1702.96,
        "id": 531,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1699.44,
        "temperature": 0,
        "text": " Oh, I'm being told that node.js has underscore directory name.",
        "tokens": [
          51136,
          876,
          11,
          286,
          478,
          885,
          1907,
          300,
          9984,
          13,
          25530,
          575,
          37556,
          21120,
          1315,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1706,
        "id": 532,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1702.96,
        "temperature": 0,
        "text": " So, there's other ways, people are telling me other ways I could get the directory name,",
        "tokens": [
          51312,
          407,
          11,
          456,
          311,
          661,
          2098,
          11,
          561,
          366,
          3585,
          385,
          661,
          2098,
          286,
          727,
          483,
          264,
          21120,
          1315,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1993973639703566,
        "compression_ratio": 1.696969696969697,
        "end": 1713.44,
        "id": 533,
        "no_speech_prob": 0.0003353483334649354,
        "seek": 168400,
        "start": 1706,
        "temperature": 0,
        "text": " but what I'm going to do is I'm going to promisify, which is a word apparently,",
        "tokens": [
          51464,
          457,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          2234,
          271,
          2505,
          11,
          597,
          307,
          257,
          1349,
          7970,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.2137722439236111,
        "compression_ratio": 1.5977653631284916,
        "end": 1718.96,
        "id": 534,
        "no_speech_prob": 0.00003219215795979835,
        "seek": 171344,
        "start": 1713.44,
        "temperature": 0,
        "text": " promisify, I'm going to, oh, look at this, I must have Googled this another time,",
        "tokens": [
          50364,
          2234,
          271,
          2505,
          11,
          286,
          478,
          516,
          281,
          11,
          1954,
          11,
          574,
          412,
          341,
          11,
          286,
          1633,
          362,
          45005,
          1493,
          341,
          1071,
          565,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2137722439236111,
        "compression_ratio": 1.5977653631284916,
        "end": 1725.52,
        "id": 535,
        "no_speech_prob": 0.00003219215795979835,
        "seek": 171344,
        "start": 1718.96,
        "temperature": 0,
        "text": " unless it's just very common, by using Java, not Java, sorry, the node package util.",
        "tokens": [
          50640,
          5969,
          309,
          311,
          445,
          588,
          2689,
          11,
          538,
          1228,
          10745,
          11,
          406,
          10745,
          11,
          2597,
          11,
          264,
          9984,
          7372,
          4976,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.2137722439236111,
        "compression_ratio": 1.5977653631284916,
        "end": 1733.2,
        "id": 536,
        "no_speech_prob": 0.00003219215795979835,
        "seek": 171344,
        "start": 1725.52,
        "temperature": 0,
        "text": " So, node package util, if I go look at util, and I actually just want to be here,",
        "tokens": [
          50968,
          407,
          11,
          9984,
          7372,
          4976,
          11,
          498,
          286,
          352,
          574,
          412,
          4976,
          11,
          293,
          286,
          767,
          445,
          528,
          281,
          312,
          510,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.2137722439236111,
        "compression_ratio": 1.5977653631284916,
        "end": 1738.64,
        "id": 537,
        "no_speech_prob": 0.00003219215795979835,
        "seek": 171344,
        "start": 1733.2,
        "temperature": 0,
        "text": " there is a promisify, util.promisify.",
        "tokens": [
          51352,
          456,
          307,
          257,
          2234,
          271,
          2505,
          11,
          4976,
          13,
          28722,
          271,
          2505,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.2939842309844628,
        "compression_ratio": 1.6310160427807487,
        "end": 1745.3600000000001,
        "id": 538,
        "no_speech_prob": 0.0002913681964855641,
        "seek": 173864,
        "start": 1738.88,
        "temperature": 0,
        "text": " So, what I can actually do is I can say const util equals require util,",
        "tokens": [
          50376,
          407,
          11,
          437,
          286,
          393,
          767,
          360,
          307,
          286,
          393,
          584,
          1817,
          4976,
          6915,
          3651,
          4976,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.2939842309844628,
        "compression_ratio": 1.6310160427807487,
        "end": 1751.44,
        "id": 539,
        "no_speech_prob": 0.0002913681964855641,
        "seek": 173864,
        "start": 1746.24,
        "temperature": 0,
        "text": " and then I can say util.promisify, what a weird word,",
        "tokens": [
          50744,
          293,
          550,
          286,
          393,
          584,
          4976,
          13,
          28722,
          271,
          2505,
          11,
          437,
          257,
          3657,
          1349,
          11,
          51004
        ]
      },
      {
        "avg_logprob": -0.2939842309844628,
        "compression_ratio": 1.6310160427807487,
        "end": 1756.5600000000002,
        "id": 540,
        "no_speech_prob": 0.0002913681964855641,
        "seek": 173864,
        "start": 1752.96,
        "temperature": 0,
        "text": " I don't know what happens if I promisify myself, this.",
        "tokens": [
          51080,
          286,
          500,
          380,
          458,
          437,
          2314,
          498,
          286,
          2234,
          271,
          2505,
          2059,
          11,
          341,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2939842309844628,
        "compression_ratio": 1.6310160427807487,
        "end": 1762.72,
        "id": 541,
        "no_speech_prob": 0.0002913681964855641,
        "seek": 173864,
        "start": 1756.5600000000002,
        "temperature": 0,
        "text": " So, now, this require child process exec function no longer uses a callback,",
        "tokens": [
          51260,
          407,
          11,
          586,
          11,
          341,
          3651,
          1440,
          1399,
          4454,
          2445,
          572,
          2854,
          4960,
          257,
          818,
          3207,
          11,
          51568
        ]
      },
      {
        "avg_logprob": -0.2939842309844628,
        "compression_ratio": 1.6310160427807487,
        "end": 1765.1200000000001,
        "id": 542,
        "no_speech_prob": 0.0002913681964855641,
        "seek": 173864,
        "start": 1762.72,
        "temperature": 0,
        "text": " now it uses a promise, and what does that mean?",
        "tokens": [
          51568,
          586,
          309,
          4960,
          257,
          6228,
          11,
          293,
          437,
          775,
          300,
          914,
          30,
          51688
        ]
      },
      {
        "avg_logprob": -0.346195884372877,
        "compression_ratio": 1.75,
        "end": 1774.3999999999999,
        "id": 543,
        "no_speech_prob": 0.0004172900808043778,
        "seek": 176512,
        "start": 1765.1999999999998,
        "temperature": 0,
        "text": " That means I can say.then, and whatever the response is, I can console log that response,",
        "tokens": [
          50368,
          663,
          1355,
          286,
          393,
          584,
          2411,
          19096,
          11,
          293,
          2035,
          264,
          4134,
          307,
          11,
          286,
          393,
          11076,
          3565,
          300,
          4134,
          11,
          50828
        ]
      },
      {
        "avg_logprob": -0.346195884372877,
        "compression_ratio": 1.75,
        "end": 1782.8,
        "id": 544,
        "no_speech_prob": 0.0004172900808043778,
        "seek": 176512,
        "start": 1776,
        "temperature": 0,
        "text": " and then I can also catch any error, and I can console.error that error.",
        "tokens": [
          50908,
          293,
          550,
          286,
          393,
          611,
          3745,
          604,
          6713,
          11,
          293,
          286,
          393,
          11076,
          13,
          260,
          2874,
          300,
          6713,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.346195884372877,
        "compression_ratio": 1.75,
        "end": 1788.3999999999999,
        "id": 545,
        "no_speech_prob": 0.0004172900808043778,
        "seek": 176512,
        "start": 1782.8,
        "temperature": 0,
        "text": " Now, this might be, and this, there's no semicolon there, there's a semicolon there,",
        "tokens": [
          51248,
          823,
          11,
          341,
          1062,
          312,
          11,
          293,
          341,
          11,
          456,
          311,
          572,
          27515,
          38780,
          456,
          11,
          456,
          311,
          257,
          27515,
          38780,
          456,
          11,
          51528
        ]
      },
      {
        "avg_logprob": -0.346195884372877,
        "compression_ratio": 1.75,
        "end": 1794.8799999999999,
        "id": 546,
        "no_speech_prob": 0.0004172900808043778,
        "seek": 176512,
        "start": 1788.3999999999999,
        "temperature": 0,
        "text": " this might look completely insane to you, if you haven't seen promises using a callback,",
        "tokens": [
          51528,
          341,
          1062,
          574,
          2584,
          10838,
          281,
          291,
          11,
          498,
          291,
          2378,
          380,
          1612,
          16403,
          1228,
          257,
          818,
          3207,
          11,
          51852
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1798.64,
        "id": 547,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1795.2800000000002,
        "temperature": 0.2,
        "text": " or if you haven't seen promises use before in JavaScript,",
        "tokens": [
          50384,
          420,
          498,
          291,
          2378,
          380,
          1612,
          16403,
          764,
          949,
          294,
          15778,
          11,
          50552
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1803.0400000000002,
        "id": 548,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1798.64,
        "temperature": 0.2,
        "text": " it's very similar to a callback, but instead of saying a callback,",
        "tokens": [
          50552,
          309,
          311,
          588,
          2531,
          281,
          257,
          818,
          3207,
          11,
          457,
          2602,
          295,
          1566,
          257,
          818,
          3207,
          11,
          50772
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1807.2,
        "id": 549,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1803.0400000000002,
        "temperature": 0.2,
        "text": " I basically have this callback that happens in.then, I'm also using the arrow syntax.",
        "tokens": [
          50772,
          286,
          1936,
          362,
          341,
          818,
          3207,
          300,
          2314,
          294,
          2411,
          19096,
          11,
          286,
          478,
          611,
          1228,
          264,
          11610,
          28431,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1811.2800000000002,
        "id": 550,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1807.7600000000002,
        "temperature": 0.2,
        "text": " The arrow syntax is a nice way of sort of shorthanding this,",
        "tokens": [
          51008,
          440,
          11610,
          28431,
          307,
          257,
          1481,
          636,
          295,
          1333,
          295,
          402,
          2652,
          42389,
          341,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1815.3600000000001,
        "id": 551,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1811.2800000000002,
        "temperature": 0.2,
        "text": " I'm getting the response as the argument to the callback, and I'm console logging it.",
        "tokens": [
          51184,
          286,
          478,
          1242,
          264,
          4134,
          382,
          264,
          6770,
          281,
          264,
          818,
          3207,
          11,
          293,
          286,
          478,
          11076,
          27991,
          309,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1819.5200000000002,
        "id": 552,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1815.3600000000001,
        "temperature": 0.2,
        "text": " So, if you want to know more about those things, I have a whole playlist about promises,",
        "tokens": [
          51388,
          407,
          11,
          498,
          291,
          528,
          281,
          458,
          544,
          466,
          729,
          721,
          11,
          286,
          362,
          257,
          1379,
          16788,
          466,
          16403,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.32676914356372977,
        "compression_ratio": 1.8098591549295775,
        "end": 1822.5600000000002,
        "id": 553,
        "no_speech_prob": 0.007011459209024906,
        "seek": 179488,
        "start": 1819.5200000000002,
        "temperature": 0.2,
        "text": " and a video about the arrow function that you could go and look at,",
        "tokens": [
          51596,
          293,
          257,
          960,
          466,
          264,
          11610,
          2445,
          300,
          291,
          727,
          352,
          293,
          574,
          412,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1824.56,
        "id": 554,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1822.56,
        "temperature": 0,
        "text": " and I've got a little bit of an advanced video here,",
        "tokens": [
          50364,
          293,
          286,
          600,
          658,
          257,
          707,
          857,
          295,
          364,
          7339,
          960,
          510,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1827.12,
        "id": 555,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1824.56,
        "temperature": 0,
        "text": " not advanced, but I'm using kind of modern JavaScript stuff,",
        "tokens": [
          50464,
          406,
          7339,
          11,
          457,
          286,
          478,
          1228,
          733,
          295,
          4363,
          15778,
          1507,
          11,
          50592
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1829.52,
        "id": 556,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1827.12,
        "temperature": 0,
        "text": " if you consider like three years ago modern.",
        "tokens": [
          50592,
          498,
          291,
          1949,
          411,
          1045,
          924,
          2057,
          4363,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1834.72,
        "id": 557,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1829.52,
        "temperature": 0,
        "text": " Okay, so now I've got this exec function, so let's actually run this one more time,",
        "tokens": [
          50712,
          1033,
          11,
          370,
          586,
          286,
          600,
          658,
          341,
          4454,
          2445,
          11,
          370,
          718,
          311,
          767,
          1190,
          341,
          472,
          544,
          565,
          11,
          50972
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1841.76,
        "id": 558,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1837.36,
        "temperature": 0,
        "text": " and see, it should do exactly the same thing, but look at this,",
        "tokens": [
          51104,
          293,
          536,
          11,
          309,
          820,
          360,
          2293,
          264,
          912,
          551,
          11,
          457,
          574,
          412,
          341,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1844.96,
        "id": 559,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1841.76,
        "temperature": 0,
        "text": " that response has standard out, standard error.",
        "tokens": [
          51324,
          300,
          4134,
          575,
          3832,
          484,
          11,
          3832,
          6713,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1846.6399999999999,
        "id": 560,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1844.96,
        "temperature": 0,
        "text": " So, in other words, standard out is what?",
        "tokens": [
          51484,
          407,
          11,
          294,
          661,
          2283,
          11,
          3832,
          484,
          307,
          437,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.3309528177434748,
        "compression_ratio": 1.663265306122449,
        "end": 1851.6,
        "id": 561,
        "no_speech_prob": 0.2043233960866928,
        "seek": 182256,
        "start": 1846.6399999999999,
        "temperature": 0,
        "text": " That's the thing that in, I closed my processing sketch, I guess I should have left it open,",
        "tokens": [
          51568,
          663,
          311,
          264,
          551,
          300,
          294,
          11,
          286,
          5395,
          452,
          9007,
          12325,
          11,
          286,
          2041,
          286,
          820,
          362,
          1411,
          309,
          1269,
          11,
          51816
        ]
      },
      {
        "avg_logprob": -0.2004431039094925,
        "compression_ratio": 1.7290076335877862,
        "end": 1855.12,
        "id": 562,
        "no_speech_prob": 0.00024922931334003806,
        "seek": 185160,
        "start": 1851.6,
        "temperature": 0,
        "text": " the processing sketch has a print line in it, so I can read whatever that print line is,",
        "tokens": [
          50364,
          264,
          9007,
          12325,
          575,
          257,
          4482,
          1622,
          294,
          309,
          11,
          370,
          286,
          393,
          1401,
          2035,
          300,
          4482,
          1622,
          307,
          11,
          50540
        ]
      },
      {
        "avg_logprob": -0.2004431039094925,
        "compression_ratio": 1.7290076335877862,
        "end": 1858.08,
        "id": 563,
        "no_speech_prob": 0.00024922931334003806,
        "seek": 185160,
        "start": 1855.12,
        "temperature": 0,
        "text": " so I can actually get more information from processing if I want.",
        "tokens": [
          50540,
          370,
          286,
          393,
          767,
          483,
          544,
          1589,
          490,
          9007,
          498,
          286,
          528,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.2004431039094925,
        "compression_ratio": 1.7290076335877862,
        "end": 1862.6399999999999,
        "id": 564,
        "no_speech_prob": 0.00024922931334003806,
        "seek": 185160,
        "start": 1858.08,
        "temperature": 0,
        "text": " For example, I could get the angle, actually, this is great, let's add a little feature to this,",
        "tokens": [
          50688,
          1171,
          1365,
          11,
          286,
          727,
          483,
          264,
          5802,
          11,
          767,
          11,
          341,
          307,
          869,
          11,
          718,
          311,
          909,
          257,
          707,
          4111,
          281,
          341,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.2004431039094925,
        "compression_ratio": 1.7290076335877862,
        "end": 1866.56,
        "id": 565,
        "no_speech_prob": 0.00024922931334003806,
        "seek": 185160,
        "start": 1862.6399999999999,
        "temperature": 0,
        "text": " this will be fun, because why not make this video longer than it already is?",
        "tokens": [
          50916,
          341,
          486,
          312,
          1019,
          11,
          570,
          983,
          406,
          652,
          341,
          960,
          2854,
          813,
          309,
          1217,
          307,
          30,
          51112
        ]
      },
      {
        "avg_logprob": -0.2004431039094925,
        "compression_ratio": 1.7290076335877862,
        "end": 1873.84,
        "id": 566,
        "no_speech_prob": 0.00024922931334003806,
        "seek": 185160,
        "start": 1867.6799999999998,
        "temperature": 0,
        "text": " Where am I, desktop, desktop, Mastodon, Mastodon bot 3, tree gen,",
        "tokens": [
          51168,
          2305,
          669,
          286,
          11,
          14502,
          11,
          14502,
          11,
          376,
          525,
          378,
          266,
          11,
          376,
          525,
          378,
          266,
          10592,
          805,
          11,
          4230,
          1049,
          11,
          51476
        ]
      },
      {
        "avg_logprob": -0.2004431039094925,
        "compression_ratio": 1.7290076335877862,
        "end": 1876.32,
        "id": 567,
        "no_speech_prob": 0.00024922931334003806,
        "seek": 185160,
        "start": 1873.84,
        "temperature": 0,
        "text": " so what I'm going to do here, look at this, this is great.",
        "tokens": [
          51476,
          370,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          11,
          574,
          412,
          341,
          11,
          341,
          307,
          869,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.25618487685473995,
        "compression_ratio": 1.822314049586777,
        "end": 1880.8,
        "id": 568,
        "no_speech_prob": 0.00024923053570091724,
        "seek": 187632,
        "start": 1876.8,
        "temperature": 0,
        "text": " Let's leave this open, because maybe I'm going to want to do more stuff with it,",
        "tokens": [
          50388,
          961,
          311,
          1856,
          341,
          1269,
          11,
          570,
          1310,
          286,
          478,
          516,
          281,
          528,
          281,
          360,
          544,
          1507,
          365,
          309,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.25618487685473995,
        "compression_ratio": 1.822314049586777,
        "end": 1886,
        "id": 569,
        "no_speech_prob": 0.00024923053570091724,
        "seek": 187632,
        "start": 1880.8,
        "temperature": 0,
        "text": " I am going to, let's make the angle between zero and 90, that's what it says in the comments,",
        "tokens": [
          50588,
          286,
          669,
          516,
          281,
          11,
          718,
          311,
          652,
          264,
          5802,
          1296,
          4018,
          293,
          4289,
          11,
          300,
          311,
          437,
          309,
          1619,
          294,
          264,
          3053,
          11,
          50848
        ]
      },
      {
        "avg_logprob": -0.25618487685473995,
        "compression_ratio": 1.822314049586777,
        "end": 1891.76,
        "id": 570,
        "no_speech_prob": 0.00024923053570091724,
        "seek": 187632,
        "start": 1886,
        "temperature": 0,
        "text": " and then I'm also going to say print line, and I'm just going to say angle, or is it, was it angle?",
        "tokens": [
          50848,
          293,
          550,
          286,
          478,
          611,
          516,
          281,
          584,
          4482,
          1622,
          11,
          293,
          286,
          478,
          445,
          516,
          281,
          584,
          5802,
          11,
          420,
          307,
          309,
          11,
          390,
          309,
          5802,
          30,
          51136
        ]
      },
      {
        "avg_logprob": -0.25618487685473995,
        "compression_ratio": 1.822314049586777,
        "end": 1897.36,
        "id": 571,
        "no_speech_prob": 0.00024923053570091724,
        "seek": 187632,
        "start": 1892.32,
        "temperature": 0,
        "text": " Theta, whatever, A, I'll just keep the A, and I'm going to say floor A, so just get the,",
        "tokens": [
          51164,
          334,
          7664,
          11,
          2035,
          11,
          316,
          11,
          286,
          603,
          445,
          1066,
          264,
          316,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          4123,
          316,
          11,
          370,
          445,
          483,
          264,
          11,
          51416
        ]
      },
      {
        "avg_logprob": -0.25618487685473995,
        "compression_ratio": 1.822314049586777,
        "end": 1901.52,
        "id": 572,
        "no_speech_prob": 0.00024923053570091724,
        "seek": 187632,
        "start": 1897.36,
        "temperature": 0,
        "text": " just get the, or int A, I'm just going to convert it to an integer, so watch.",
        "tokens": [
          51416,
          445,
          483,
          264,
          11,
          420,
          560,
          316,
          11,
          286,
          478,
          445,
          516,
          281,
          7620,
          309,
          281,
          364,
          24922,
          11,
          370,
          1159,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.4135781146110372,
        "compression_ratio": 1.537313432835821,
        "end": 1910.48,
        "id": 573,
        "no_speech_prob": 0.017176425084471703,
        "seek": 190152,
        "start": 1901.6,
        "temperature": 0,
        "text": " So now, when I do this in node, I'm going to say console.log response.standard out,",
        "tokens": [
          50368,
          407,
          586,
          11,
          562,
          286,
          360,
          341,
          294,
          9984,
          11,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          4134,
          13,
          1115,
          515,
          484,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.4135781146110372,
        "compression_ratio": 1.537313432835821,
        "end": 1914.48,
        "id": 574,
        "no_speech_prob": 0.017176425084471703,
        "seek": 190152,
        "start": 1910.48,
        "temperature": 0,
        "text": " so I don't need to see that whole object, I just want to see the stuff that came out of processing.",
        "tokens": [
          50812,
          370,
          286,
          500,
          380,
          643,
          281,
          536,
          300,
          1379,
          2657,
          11,
          286,
          445,
          528,
          281,
          536,
          264,
          1507,
          300,
          1361,
          484,
          295,
          9007,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.4135781146110372,
        "compression_ratio": 1.537313432835821,
        "end": 1921.84,
        "id": 575,
        "no_speech_prob": 0.017176425084471703,
        "seek": 190152,
        "start": 1916.08,
        "temperature": 0,
        "text": " Let's run it one more time, and you can see, that was the angle 42,",
        "tokens": [
          51092,
          961,
          311,
          1190,
          309,
          472,
          544,
          565,
          11,
          293,
          291,
          393,
          536,
          11,
          300,
          390,
          264,
          5802,
          14034,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.4135781146110372,
        "compression_ratio": 1.537313432835821,
        "end": 1928.32,
        "id": 576,
        "no_speech_prob": 0.017176425084471703,
        "seek": 190152,
        "start": 1921.84,
        "temperature": 0,
        "text": " ooh, spooky, spooky 42, beating of life, okay, so, great,",
        "tokens": [
          51380,
          17024,
          11,
          30510,
          11,
          30510,
          14034,
          11,
          13497,
          295,
          993,
          11,
          1392,
          11,
          370,
          11,
          869,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.3057841307728003,
        "compression_ratio": 1.828125,
        "end": 1934.56,
        "id": 577,
        "no_speech_prob": 0.0018968982622027397,
        "seek": 192832,
        "start": 1928.56,
        "temperature": 0,
        "text": " so here's the thing, I want to, once I have that image, I want to post that image to Mastodon,",
        "tokens": [
          50376,
          370,
          510,
          311,
          264,
          551,
          11,
          286,
          528,
          281,
          11,
          1564,
          286,
          362,
          300,
          3256,
          11,
          286,
          528,
          281,
          2183,
          300,
          3256,
          281,
          376,
          525,
          378,
          266,
          11,
          50676
        ]
      },
      {
        "avg_logprob": -0.3057841307728003,
        "compression_ratio": 1.828125,
        "end": 1939.4399999999998,
        "id": 578,
        "no_speech_prob": 0.0018968982622027397,
        "seek": 192832,
        "start": 1934.56,
        "temperature": 0,
        "text": " isn't this all about Mastodon, I've loaded up and connected to Mastodon through this, like, bot,",
        "tokens": [
          50676,
          1943,
          380,
          341,
          439,
          466,
          376,
          525,
          378,
          266,
          11,
          286,
          600,
          13210,
          493,
          293,
          4582,
          281,
          376,
          525,
          378,
          266,
          807,
          341,
          11,
          411,
          11,
          10592,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.3057841307728003,
        "compression_ratio": 1.828125,
        "end": 1943.52,
        "id": 579,
        "no_speech_prob": 0.0018968982622027397,
        "seek": 192832,
        "start": 1940.1599999999999,
        "temperature": 0,
        "text": " if you don't know what Mastodon is, did I say this already, I've got a whole set of videos",
        "tokens": [
          50956,
          498,
          291,
          500,
          380,
          458,
          437,
          376,
          525,
          378,
          266,
          307,
          11,
          630,
          286,
          584,
          341,
          1217,
          11,
          286,
          600,
          658,
          257,
          1379,
          992,
          295,
          2145,
          51124
        ]
      },
      {
        "avg_logprob": -0.3057841307728003,
        "compression_ratio": 1.828125,
        "end": 1949.28,
        "id": 580,
        "no_speech_prob": 0.0018968982622027397,
        "seek": 192832,
        "start": 1943.52,
        "temperature": 0,
        "text": " describing that, I mean, you can go back and look, but I want to somehow post it to this particular",
        "tokens": [
          51124,
          16141,
          300,
          11,
          286,
          914,
          11,
          291,
          393,
          352,
          646,
          293,
          574,
          11,
          457,
          286,
          528,
          281,
          6063,
          2183,
          309,
          281,
          341,
          1729,
          51412
        ]
      },
      {
        "avg_logprob": -0.3057841307728003,
        "compression_ratio": 1.828125,
        "end": 1956.32,
        "id": 581,
        "no_speech_prob": 0.0018968982622027397,
        "seek": 192832,
        "start": 1949.28,
        "temperature": 0,
        "text": " bot, the coding train bot, okay, so now, in order to do that, I need to do something,",
        "tokens": [
          51412,
          10592,
          11,
          264,
          17720,
          3847,
          10592,
          11,
          1392,
          11,
          370,
          586,
          11,
          294,
          1668,
          281,
          360,
          300,
          11,
          286,
          643,
          281,
          360,
          746,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.14357425184810862,
        "compression_ratio": 1.7411764705882353,
        "end": 1961.9199999999998,
        "id": 582,
        "no_speech_prob": 0.00002977296753670089,
        "seek": 195632,
        "start": 1956.32,
        "temperature": 0,
        "text": " so now, in order to do that, I need to look up the functions in the Mastodon API,",
        "tokens": [
          50364,
          370,
          586,
          11,
          294,
          1668,
          281,
          360,
          300,
          11,
          286,
          643,
          281,
          574,
          493,
          264,
          6828,
          294,
          264,
          376,
          525,
          378,
          266,
          9362,
          11,
          50644
        ]
      },
      {
        "avg_logprob": -0.14357425184810862,
        "compression_ratio": 1.7411764705882353,
        "end": 1970,
        "id": 583,
        "no_speech_prob": 0.00002977296753670089,
        "seek": 195632,
        "start": 1961.9199999999998,
        "temperature": 0,
        "text": " so I'm using this Mastodon API node package, and if I go here, I can look and see that it has",
        "tokens": [
          50644,
          370,
          286,
          478,
          1228,
          341,
          376,
          525,
          378,
          266,
          9362,
          9984,
          7372,
          11,
          293,
          498,
          286,
          352,
          510,
          11,
          286,
          393,
          574,
          293,
          536,
          300,
          309,
          575,
          51048
        ]
      },
      {
        "avg_logprob": -0.14357425184810862,
        "compression_ratio": 1.7411764705882353,
        "end": 1975.6799999999998,
        "id": 584,
        "no_speech_prob": 0.00002977296753670089,
        "seek": 195632,
        "start": 1971.2,
        "temperature": 0,
        "text": " Mastodon, get Mastodon post, so this is what I want, Mastodon post, here's the thing,",
        "tokens": [
          51108,
          376,
          525,
          378,
          266,
          11,
          483,
          376,
          525,
          378,
          266,
          2183,
          11,
          370,
          341,
          307,
          437,
          286,
          528,
          11,
          376,
          525,
          378,
          266,
          2183,
          11,
          510,
          311,
          264,
          551,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.14357425184810862,
        "compression_ratio": 1.7411764705882353,
        "end": 1980.08,
        "id": 585,
        "no_speech_prob": 0.00002977296753670089,
        "seek": 195632,
        "start": 1975.6799999999998,
        "temperature": 0,
        "text": " I didn't realize this when I made my other videos about Mastodon, because it says path,",
        "tokens": [
          51332,
          286,
          994,
          380,
          4325,
          341,
          562,
          286,
          1027,
          452,
          661,
          2145,
          466,
          376,
          525,
          378,
          266,
          11,
          570,
          309,
          1619,
          3100,
          11,
          51552
        ]
      },
      {
        "avg_logprob": -0.14357425184810862,
        "compression_ratio": 1.7411764705882353,
        "end": 1986.1599999999999,
        "id": 586,
        "no_speech_prob": 0.00002977296753670089,
        "seek": 195632,
        "start": 1980.08,
        "temperature": 0,
        "text": " parameters, and callback, but guess what, this supports promises, so I actually am going to do",
        "tokens": [
          51552,
          9834,
          11,
          293,
          818,
          3207,
          11,
          457,
          2041,
          437,
          11,
          341,
          9346,
          16403,
          11,
          370,
          286,
          767,
          669,
          516,
          281,
          360,
          51856
        ]
      },
      {
        "avg_logprob": -0.16448813765796264,
        "compression_ratio": 1.9665271966527196,
        "end": 1992.72,
        "id": 587,
        "no_speech_prob": 0.00016092990699689835,
        "seek": 198616,
        "start": 1986.16,
        "temperature": 0,
        "text": " this without a callback, with promises, I'm going to break this out, and didn't I say I was going",
        "tokens": [
          50364,
          341,
          1553,
          257,
          818,
          3207,
          11,
          365,
          16403,
          11,
          286,
          478,
          516,
          281,
          1821,
          341,
          484,
          11,
          293,
          994,
          380,
          286,
          584,
          286,
          390,
          516,
          50692
        ]
      },
      {
        "avg_logprob": -0.16448813765796264,
        "compression_ratio": 1.9665271966527196,
        "end": 1996.8000000000002,
        "id": 588,
        "no_speech_prob": 0.00016092990699689835,
        "seek": 198616,
        "start": 1992.72,
        "temperature": 0,
        "text": " to use async and await, I was going to write it with just that, but I think I have to start a",
        "tokens": [
          50692,
          281,
          764,
          382,
          34015,
          293,
          19670,
          11,
          286,
          390,
          516,
          281,
          2464,
          309,
          365,
          445,
          300,
          11,
          457,
          286,
          519,
          286,
          362,
          281,
          722,
          257,
          50896
        ]
      },
      {
        "avg_logprob": -0.16448813765796264,
        "compression_ratio": 1.9665271966527196,
        "end": 2001.52,
        "id": 589,
        "no_speech_prob": 0.00016092990699689835,
        "seek": 198616,
        "start": 1996.8000000000002,
        "temperature": 0,
        "text": " little bit, I have to, I'm going to go a little bit further with the full promises syntax,",
        "tokens": [
          50896,
          707,
          857,
          11,
          286,
          362,
          281,
          11,
          286,
          478,
          516,
          281,
          352,
          257,
          707,
          857,
          3052,
          365,
          264,
          1577,
          16403,
          28431,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.16448813765796264,
        "compression_ratio": 1.9665271966527196,
        "end": 2006.8000000000002,
        "id": 590,
        "no_speech_prob": 0.00016092990699689835,
        "seek": 198616,
        "start": 2001.52,
        "temperature": 0,
        "text": " then I'm going to clean it up with async and await in a second, so now, there's no semicolon there,",
        "tokens": [
          51132,
          550,
          286,
          478,
          516,
          281,
          2541,
          309,
          493,
          365,
          382,
          34015,
          293,
          19670,
          294,
          257,
          1150,
          11,
          370,
          586,
          11,
          456,
          311,
          572,
          27515,
          38780,
          456,
          11,
          51396
        ]
      },
      {
        "avg_logprob": -0.16448813765796264,
        "compression_ratio": 1.9665271966527196,
        "end": 2014.48,
        "id": 591,
        "no_speech_prob": 0.00016092990699689835,
        "seek": 198616,
        "start": 2006.8000000000002,
        "temperature": 0,
        "text": " so now what I want to do is I want to basically say this, I want to post the image, and",
        "tokens": [
          51396,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1936,
          584,
          341,
          11,
          286,
          528,
          281,
          2183,
          264,
          3256,
          11,
          293,
          51780
        ]
      },
      {
        "avg_logprob": -0.19530528840564546,
        "compression_ratio": 1.7899543378995433,
        "end": 2022.48,
        "id": 592,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 201448,
        "start": 2015.44,
        "temperature": 0,
        "text": " I want to return this, because if this returns a promise, guess what I get to do, I get to say",
        "tokens": [
          50412,
          286,
          528,
          281,
          2736,
          341,
          11,
          570,
          498,
          341,
          11247,
          257,
          6228,
          11,
          2041,
          437,
          286,
          483,
          281,
          360,
          11,
          286,
          483,
          281,
          584,
          50764
        ]
      },
      {
        "avg_logprob": -0.19530528840564546,
        "compression_ratio": 1.7899543378995433,
        "end": 2029.68,
        "id": 593,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 201448,
        "start": 2022.48,
        "temperature": 0,
        "text": " dot then response, and have another function, right, so this is the idea of chaining promises,",
        "tokens": [
          50764,
          5893,
          550,
          4134,
          11,
          293,
          362,
          1071,
          2445,
          11,
          558,
          11,
          370,
          341,
          307,
          264,
          1558,
          295,
          417,
          3686,
          16403,
          11,
          51124
        ]
      },
      {
        "avg_logprob": -0.19530528840564546,
        "compression_ratio": 1.7899543378995433,
        "end": 2035.1200000000001,
        "id": 594,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 201448,
        "start": 2029.68,
        "temperature": 0,
        "text": " and this is what, in theory, I mean, basically, the whole theory of this is to avoid callback hell,",
        "tokens": [
          51124,
          293,
          341,
          307,
          437,
          11,
          294,
          5261,
          11,
          286,
          914,
          11,
          1936,
          11,
          264,
          1379,
          5261,
          295,
          341,
          307,
          281,
          5042,
          818,
          3207,
          4921,
          11,
          51396
        ]
      },
      {
        "avg_logprob": -0.19530528840564546,
        "compression_ratio": 1.7899543378995433,
        "end": 2041.1200000000001,
        "id": 595,
        "no_speech_prob": 0.000038831010897411034,
        "seek": 201448,
        "start": 2035.1200000000001,
        "temperature": 0,
        "text": " and really, we're just in promises hell, it's all hell, but eventually, we will float into the clouds,",
        "tokens": [
          51396,
          293,
          534,
          11,
          321,
          434,
          445,
          294,
          16403,
          4921,
          11,
          309,
          311,
          439,
          4921,
          11,
          457,
          4728,
          11,
          321,
          486,
          15706,
          666,
          264,
          12193,
          11,
          51696
        ]
      },
      {
        "avg_logprob": -0.1989611851350042,
        "compression_ratio": 1.842911877394636,
        "end": 2048.24,
        "id": 596,
        "no_speech_prob": 0.002082917606458068,
        "seek": 204112,
        "start": 2041.12,
        "temperature": 0,
        "text": " and feel like we're like butterflies on wings or something, I don't know, okay, so if I return",
        "tokens": [
          50364,
          293,
          841,
          411,
          321,
          434,
          411,
          31987,
          322,
          11405,
          420,
          746,
          11,
          286,
          500,
          380,
          458,
          11,
          1392,
          11,
          370,
          498,
          286,
          2736,
          50720
        ]
      },
      {
        "avg_logprob": -0.1989611851350042,
        "compression_ratio": 1.842911877394636,
        "end": 2052.88,
        "id": 597,
        "no_speech_prob": 0.002082917606458068,
        "seek": 204112,
        "start": 2048.24,
        "temperature": 0,
        "text": " the post that I want to do when that's done, so I'm executing this command when that's done,",
        "tokens": [
          50720,
          264,
          2183,
          300,
          286,
          528,
          281,
          360,
          562,
          300,
          311,
          1096,
          11,
          370,
          286,
          478,
          32368,
          341,
          5622,
          562,
          300,
          311,
          1096,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.1989611851350042,
        "compression_ratio": 1.842911877394636,
        "end": 2059.2,
        "id": 598,
        "no_speech_prob": 0.002082917606458068,
        "seek": 204112,
        "start": 2052.88,
        "temperature": 0,
        "text": " then do this, and then when the next promise is done, then do this, all right, so what do I need",
        "tokens": [
          50952,
          550,
          360,
          341,
          11,
          293,
          550,
          562,
          264,
          958,
          6228,
          307,
          1096,
          11,
          550,
          360,
          341,
          11,
          439,
          558,
          11,
          370,
          437,
          360,
          286,
          643,
          51268
        ]
      },
      {
        "avg_logprob": -0.1989611851350042,
        "compression_ratio": 1.842911877394636,
        "end": 2063.8399999999997,
        "id": 599,
        "no_speech_prob": 0.002082917606458068,
        "seek": 204112,
        "start": 2059.2,
        "temperature": 0,
        "text": " here, the path, so the first thing I need to do, what's weird about, and actually, it might be worth",
        "tokens": [
          51268,
          510,
          11,
          264,
          3100,
          11,
          370,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          11,
          437,
          311,
          3657,
          466,
          11,
          293,
          767,
          11,
          309,
          1062,
          312,
          3163,
          51500
        ]
      },
      {
        "avg_logprob": -0.1989611851350042,
        "compression_ratio": 1.842911877394636,
        "end": 2068.7999999999997,
        "id": 600,
        "no_speech_prob": 0.002082917606458068,
        "seek": 204112,
        "start": 2063.8399999999997,
        "temperature": 0,
        "text": " just taking a minute to like write these steps out, because it'll make it more clear, I want to",
        "tokens": [
          51500,
          445,
          1940,
          257,
          3456,
          281,
          411,
          2464,
          613,
          4439,
          484,
          11,
          570,
          309,
          603,
          652,
          309,
          544,
          1850,
          11,
          286,
          528,
          281,
          51748
        ]
      },
      {
        "avg_logprob": -0.1837999297351372,
        "compression_ratio": 1.6333333333333333,
        "end": 2081.76,
        "id": 601,
        "no_speech_prob": 0.00006014137761667371,
        "seek": 206880,
        "start": 2068.8,
        "temperature": 0,
        "text": " exec processing, that's one, then two, I want to upload image, and then three, I want to toot,",
        "tokens": [
          50364,
          4454,
          9007,
          11,
          300,
          311,
          472,
          11,
          550,
          732,
          11,
          286,
          528,
          281,
          6580,
          3256,
          11,
          293,
          550,
          1045,
          11,
          286,
          528,
          281,
          281,
          310,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.1837999297351372,
        "compression_ratio": 1.6333333333333333,
        "end": 2087.84,
        "id": 602,
        "no_speech_prob": 0.00006014137761667371,
        "seek": 206880,
        "start": 2082.7200000000003,
        "temperature": 0,
        "text": " right, so what, this is the same thing for the Twitter API, it doesn't work that you just, if you",
        "tokens": [
          51060,
          558,
          11,
          370,
          437,
          11,
          341,
          307,
          264,
          912,
          551,
          337,
          264,
          5794,
          9362,
          11,
          309,
          1177,
          380,
          589,
          300,
          291,
          445,
          11,
          498,
          291,
          51316
        ]
      },
      {
        "avg_logprob": -0.1837999297351372,
        "compression_ratio": 1.6333333333333333,
        "end": 2093.76,
        "id": 603,
        "no_speech_prob": 0.00006014137761667371,
        "seek": 206880,
        "start": 2087.84,
        "temperature": 0,
        "text": " want to tweet an image, you don't just simply send your tweet along with the image, you have to first",
        "tokens": [
          51316,
          528,
          281,
          15258,
          364,
          3256,
          11,
          291,
          500,
          380,
          445,
          2935,
          2845,
          428,
          15258,
          2051,
          365,
          264,
          3256,
          11,
          291,
          362,
          281,
          700,
          51612
        ]
      },
      {
        "avg_logprob": -0.15180507990030143,
        "compression_ratio": 1.8725490196078431,
        "end": 2100.1600000000003,
        "id": 604,
        "no_speech_prob": 0.0022518252953886986,
        "seek": 209376,
        "start": 2093.76,
        "temperature": 0,
        "text": " upload the media, get that path to the media, and then you can tweet with that media reference,",
        "tokens": [
          50364,
          6580,
          264,
          3021,
          11,
          483,
          300,
          3100,
          281,
          264,
          3021,
          11,
          293,
          550,
          291,
          393,
          15258,
          365,
          300,
          3021,
          6408,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.15180507990030143,
        "compression_ratio": 1.8725490196078431,
        "end": 2106.6400000000003,
        "id": 605,
        "no_speech_prob": 0.0022518252953886986,
        "seek": 209376,
        "start": 2100.1600000000003,
        "temperature": 0,
        "text": " so this will actually return an id for the media, and then as long as I attach the id to this,",
        "tokens": [
          50684,
          370,
          341,
          486,
          767,
          2736,
          364,
          4496,
          337,
          264,
          3021,
          11,
          293,
          550,
          382,
          938,
          382,
          286,
          5085,
          264,
          4496,
          281,
          341,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.15180507990030143,
        "compression_ratio": 1.8725490196078431,
        "end": 2116.4,
        "id": 606,
        "no_speech_prob": 0.0022518252953886986,
        "seek": 209376,
        "start": 2106.6400000000003,
        "temperature": 0,
        "text": " so this creates output.png, this creates an id, and then I use that id here, and then I'm done,",
        "tokens": [
          51008,
          370,
          341,
          7829,
          5598,
          13,
          79,
          872,
          11,
          341,
          7829,
          364,
          4496,
          11,
          293,
          550,
          286,
          764,
          300,
          4496,
          510,
          11,
          293,
          550,
          286,
          478,
          1096,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.15180507990030143,
        "compression_ratio": 1.8725490196078431,
        "end": 2121.44,
        "id": 607,
        "no_speech_prob": 0.0022518252953886986,
        "seek": 209376,
        "start": 2116.4,
        "temperature": 0,
        "text": " then we're just like done, this is the three-step process, each one of these returns a promise,",
        "tokens": [
          51496,
          550,
          321,
          434,
          445,
          411,
          1096,
          11,
          341,
          307,
          264,
          1045,
          12,
          16792,
          1399,
          11,
          1184,
          472,
          295,
          613,
          11247,
          257,
          6228,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.17428396556003034,
        "compression_ratio": 1.812785388127854,
        "end": 2126.56,
        "id": 608,
        "no_speech_prob": 0.000008801088370091747,
        "seek": 212144,
        "start": 2121.44,
        "temperature": 0,
        "text": " so when, do this, then this, then that, all right, that's the process I'm working with here,",
        "tokens": [
          50364,
          370,
          562,
          11,
          360,
          341,
          11,
          550,
          341,
          11,
          550,
          300,
          11,
          439,
          558,
          11,
          300,
          311,
          264,
          1399,
          286,
          478,
          1364,
          365,
          510,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.17428396556003034,
        "compression_ratio": 1.812785388127854,
        "end": 2137.52,
        "id": 609,
        "no_speech_prob": 0.000008801088370091747,
        "seek": 212144,
        "start": 2128.16,
        "temperature": 0,
        "text": " all right, so now, so, okay, so the path, so let's go to the Mastodon API docs, and I'm actually",
        "tokens": [
          50700,
          439,
          558,
          11,
          370,
          586,
          11,
          370,
          11,
          1392,
          11,
          370,
          264,
          3100,
          11,
          370,
          718,
          311,
          352,
          281,
          264,
          376,
          525,
          378,
          266,
          9362,
          45623,
          11,
          293,
          286,
          478,
          767,
          51168
        ]
      },
      {
        "avg_logprob": -0.17428396556003034,
        "compression_ratio": 1.812785388127854,
        "end": 2143.12,
        "id": 610,
        "no_speech_prob": 0.000008801088370091747,
        "seek": 212144,
        "start": 2137.52,
        "temperature": 0,
        "text": " looking for media, so we can click here, and this is what I, this is what I want to do, I don't, media upload,",
        "tokens": [
          51168,
          1237,
          337,
          3021,
          11,
          370,
          321,
          393,
          2052,
          510,
          11,
          293,
          341,
          307,
          437,
          286,
          11,
          341,
          307,
          437,
          286,
          528,
          281,
          360,
          11,
          286,
          500,
          380,
          11,
          3021,
          6580,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.17428396556003034,
        "compression_ratio": 1.812785388127854,
        "end": 2148.2400000000002,
        "id": 611,
        "no_speech_prob": 0.000008801088370091747,
        "seek": 212144,
        "start": 2143.12,
        "temperature": 0,
        "text": " I think media upload is just this, I post to here, and then these are the things I need to send,",
        "tokens": [
          51448,
          286,
          519,
          3021,
          6580,
          307,
          445,
          341,
          11,
          286,
          2183,
          281,
          510,
          11,
          293,
          550,
          613,
          366,
          264,
          721,
          286,
          643,
          281,
          2845,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.1503015118975972,
        "compression_ratio": 1.9344262295081966,
        "end": 2154.9599999999996,
        "id": 612,
        "no_speech_prob": 0.00014653053949587047,
        "seek": 214824,
        "start": 2148.8799999999997,
        "temperature": 0,
        "text": " okay, so file description focus, let's look at that, okay, so I need to, I'm going to create",
        "tokens": [
          50396,
          1392,
          11,
          370,
          3991,
          3855,
          1879,
          11,
          718,
          311,
          574,
          412,
          300,
          11,
          1392,
          11,
          370,
          286,
          643,
          281,
          11,
          286,
          478,
          516,
          281,
          1884,
          50700
        ]
      },
      {
        "avg_logprob": -0.1503015118975972,
        "compression_ratio": 1.9344262295081966,
        "end": 2161.8399999999997,
        "id": 613,
        "no_speech_prob": 0.00014653053949587047,
        "seek": 214824,
        "start": 2154.9599999999996,
        "temperature": 0,
        "text": " some parameters, oh no, I'm up here, I'm just going to, I'm going to create some parameters,",
        "tokens": [
          50700,
          512,
          9834,
          11,
          1954,
          572,
          11,
          286,
          478,
          493,
          510,
          11,
          286,
          478,
          445,
          516,
          281,
          11,
          286,
          478,
          516,
          281,
          1884,
          512,
          9834,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.1503015118975972,
        "compression_ratio": 1.9344262295081966,
        "end": 2166.7999999999997,
        "id": 614,
        "no_speech_prob": 0.00014653053949587047,
        "seek": 214824,
        "start": 2161.8399999999997,
        "temperature": 0,
        "text": " and I need the file, which is presumably output.png, and this is not exactly right yet,",
        "tokens": [
          51044,
          293,
          286,
          643,
          264,
          3991,
          11,
          597,
          307,
          26742,
          5598,
          13,
          79,
          872,
          11,
          293,
          341,
          307,
          406,
          2293,
          558,
          1939,
          11,
          51292
        ]
      },
      {
        "avg_logprob": -0.1503015118975972,
        "compression_ratio": 1.9344262295081966,
        "end": 2172.24,
        "id": 615,
        "no_speech_prob": 0.00014653053949587047,
        "seek": 214824,
        "start": 2167.4399999999996,
        "temperature": 0,
        "text": " I can't just put the file name there, but I'll get to that in a second, then I want the description,",
        "tokens": [
          51324,
          286,
          393,
          380,
          445,
          829,
          264,
          3991,
          1315,
          456,
          11,
          457,
          286,
          603,
          483,
          281,
          300,
          294,
          257,
          1150,
          11,
          550,
          286,
          528,
          264,
          3855,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.1503015118975972,
        "compression_ratio": 1.9344262295081966,
        "end": 2177.4399999999996,
        "id": 616,
        "no_speech_prob": 0.00014653053949587047,
        "seek": 214824,
        "start": 2172.24,
        "temperature": 0,
        "text": " now the description is really important, this is not the text that is going along with the actual",
        "tokens": [
          51564,
          586,
          264,
          3855,
          307,
          534,
          1021,
          11,
          341,
          307,
          406,
          264,
          2487,
          300,
          307,
          516,
          2051,
          365,
          264,
          3539,
          51824
        ]
      },
      {
        "avg_logprob": -0.20464268974635913,
        "compression_ratio": 1.6409090909090909,
        "end": 2182.96,
        "id": 617,
        "no_speech_prob": 0.000017231541278306395,
        "seek": 217744,
        "start": 2177.44,
        "temperature": 0,
        "text": " post, what this is, is alt text, alternative text, this is for accessibility, so somebody who is",
        "tokens": [
          50364,
          2183,
          11,
          437,
          341,
          307,
          11,
          307,
          4955,
          2487,
          11,
          8535,
          2487,
          11,
          341,
          307,
          337,
          15002,
          11,
          370,
          2618,
          567,
          307,
          50640
        ]
      },
      {
        "avg_logprob": -0.20464268974635913,
        "compression_ratio": 1.6409090909090909,
        "end": 2187.76,
        "id": 618,
        "no_speech_prob": 0.000017231541278306395,
        "seek": 217744,
        "start": 2182.96,
        "temperature": 0,
        "text": " blind or with low vision, who is using a screen reader, instead of seeing this image, would actually",
        "tokens": [
          50640,
          6865,
          420,
          365,
          2295,
          5201,
          11,
          567,
          307,
          1228,
          257,
          2568,
          15149,
          11,
          2602,
          295,
          2577,
          341,
          3256,
          11,
          576,
          767,
          50880
        ]
      },
      {
        "avg_logprob": -0.20464268974635913,
        "compression_ratio": 1.6409090909090909,
        "end": 2196.16,
        "id": 619,
        "no_speech_prob": 0.000017231541278306395,
        "seek": 217744,
        "start": 2187.76,
        "temperature": 0,
        "text": " hear this description, so I would say a randomly generated fractal tree, oh, and I want to get,",
        "tokens": [
          50880,
          1568,
          341,
          3855,
          11,
          370,
          286,
          576,
          584,
          257,
          16979,
          10833,
          17948,
          304,
          4230,
          11,
          1954,
          11,
          293,
          286,
          528,
          281,
          483,
          11,
          51300
        ]
      },
      {
        "avg_logprob": -0.20464268974635913,
        "compression_ratio": 1.6409090909090909,
        "end": 2204,
        "id": 620,
        "no_speech_prob": 0.000017231541278306395,
        "seek": 217744,
        "start": 2197.76,
        "temperature": 0,
        "text": " this is, I'm going to say const angle equals response.standard out,",
        "tokens": [
          51380,
          341,
          307,
          11,
          286,
          478,
          516,
          281,
          584,
          1817,
          5802,
          6915,
          4134,
          13,
          1115,
          515,
          484,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.19461172819137573,
        "compression_ratio": 1.7740384615384615,
        "end": 2213.68,
        "id": 621,
        "no_speech_prob": 0.00002468273669364862,
        "seek": 220744,
        "start": 2207.92,
        "temperature": 0,
        "text": " with, and then, oh, and I need to use my, the new thing that I always use now, which is",
        "tokens": [
          50388,
          365,
          11,
          293,
          550,
          11,
          1954,
          11,
          293,
          286,
          643,
          281,
          764,
          452,
          11,
          264,
          777,
          551,
          300,
          286,
          1009,
          764,
          586,
          11,
          597,
          307,
          50676
        ]
      },
      {
        "avg_logprob": -0.19461172819137573,
        "compression_ratio": 1.7740384615384615,
        "end": 2222.32,
        "id": 622,
        "no_speech_prob": 0.00002468273669364862,
        "seek": 220744,
        "start": 2214.64,
        "temperature": 0,
        "text": " template literals for strings, with angle, so this would be the description, and then there's one other,",
        "tokens": [
          50724,
          12379,
          2733,
          1124,
          337,
          13985,
          11,
          365,
          5802,
          11,
          370,
          341,
          576,
          312,
          264,
          3855,
          11,
          293,
          550,
          456,
          311,
          472,
          661,
          11,
          51108
        ]
      },
      {
        "avg_logprob": -0.19461172819137573,
        "compression_ratio": 1.7740384615384615,
        "end": 2229.36,
        "id": 623,
        "no_speech_prob": 0.00002468273669364862,
        "seek": 220744,
        "start": 2225.28,
        "temperature": 0,
        "text": " so the file is required, the description, it says, is optional, but it really shouldn't be",
        "tokens": [
          51256,
          370,
          264,
          3991,
          307,
          4739,
          11,
          264,
          3855,
          11,
          309,
          1619,
          11,
          307,
          17312,
          11,
          457,
          309,
          534,
          4659,
          380,
          312,
          51460
        ]
      },
      {
        "avg_logprob": -0.19461172819137573,
        "compression_ratio": 1.7740384615384615,
        "end": 2233.76,
        "id": 624,
        "no_speech_prob": 0.00002468273669364862,
        "seek": 220744,
        "start": 2229.36,
        "temperature": 0,
        "text": " optional, you should be using alt text for accessibility, and then focus, this really",
        "tokens": [
          51460,
          17312,
          11,
          291,
          820,
          312,
          1228,
          4955,
          2487,
          337,
          15002,
          11,
          293,
          550,
          1879,
          11,
          341,
          534,
          51680
        ]
      },
      {
        "avg_logprob": -0.20795154571533203,
        "compression_ratio": 1.7575757575757576,
        "end": 2237.6800000000003,
        "id": 625,
        "no_speech_prob": 0.00433141365647316,
        "seek": 223376,
        "start": 2233.76,
        "temperature": 0,
        "text": " is optional, I'm assuming, I've actually not tried this yet, but I'm assuming this has to do with where",
        "tokens": [
          50364,
          307,
          17312,
          11,
          286,
          478,
          11926,
          11,
          286,
          600,
          767,
          406,
          3031,
          341,
          1939,
          11,
          457,
          286,
          478,
          11926,
          341,
          575,
          281,
          360,
          365,
          689,
          50560
        ]
      },
      {
        "avg_logprob": -0.20795154571533203,
        "compression_ratio": 1.7575757575757576,
        "end": 2245.6800000000003,
        "id": 626,
        "no_speech_prob": 0.00433141365647316,
        "seek": 223376,
        "start": 2237.6800000000003,
        "temperature": 0,
        "text": " the crop is, if it's showing a preview image, something like that, okay, so then, I can say, so this is",
        "tokens": [
          50560,
          264,
          9086,
          307,
          11,
          498,
          309,
          311,
          4099,
          257,
          14281,
          3256,
          11,
          746,
          411,
          300,
          11,
          1392,
          11,
          370,
          550,
          11,
          286,
          393,
          584,
          11,
          370,
          341,
          307,
          50960
        ]
      },
      {
        "avg_logprob": -0.20795154571533203,
        "compression_ratio": 1.7575757575757576,
        "end": 2253.92,
        "id": 627,
        "no_speech_prob": 0.00433141365647316,
        "seek": 223376,
        "start": 2245.6800000000003,
        "temperature": 0,
        "text": " done, and then, path, and then those parameters, I guess this could be an array, oh, path, no, but okay,",
        "tokens": [
          50960,
          1096,
          11,
          293,
          550,
          11,
          3100,
          11,
          293,
          550,
          729,
          9834,
          11,
          286,
          2041,
          341,
          727,
          312,
          364,
          10225,
          11,
          1954,
          11,
          3100,
          11,
          572,
          11,
          457,
          1392,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.20795154571533203,
        "compression_ratio": 1.7575757575757576,
        "end": 2262.32,
        "id": 628,
        "no_speech_prob": 0.00433141365647316,
        "seek": 223376,
        "start": 2255.6800000000003,
        "temperature": 0,
        "text": " path, oh yeah, the path is media, sorry, I'm posting to this path, the media path of the API,",
        "tokens": [
          51460,
          3100,
          11,
          1954,
          1338,
          11,
          264,
          3100,
          307,
          3021,
          11,
          2597,
          11,
          286,
          478,
          15978,
          281,
          341,
          3100,
          11,
          264,
          3021,
          3100,
          295,
          264,
          9362,
          11,
          51792
        ]
      },
      {
        "avg_logprob": -0.1757850072470056,
        "compression_ratio": 1.583815028901734,
        "end": 2265.92,
        "id": 629,
        "no_speech_prob": 0.00007141892274376005,
        "seek": 226232,
        "start": 2262.32,
        "temperature": 0,
        "text": " with these parameters, but this isn't right, this, I mean, let's run this, we'll get an error,",
        "tokens": [
          50364,
          365,
          613,
          9834,
          11,
          457,
          341,
          1943,
          380,
          558,
          11,
          341,
          11,
          286,
          914,
          11,
          718,
          311,
          1190,
          341,
          11,
          321,
          603,
          483,
          364,
          6713,
          11,
          50544
        ]
      },
      {
        "avg_logprob": -0.1757850072470056,
        "compression_ratio": 1.583815028901734,
        "end": 2274.0800000000004,
        "id": 630,
        "no_speech_prob": 0.00007141892274376005,
        "seek": 226232,
        "start": 2269.36,
        "temperature": 0,
        "text": " so I make the image, finished, params is not defined, so that's a different error,",
        "tokens": [
          50716,
          370,
          286,
          652,
          264,
          3256,
          11,
          4335,
          11,
          971,
          4070,
          307,
          406,
          7642,
          11,
          370,
          300,
          311,
          257,
          819,
          6713,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.1757850072470056,
        "compression_ratio": 1.583815028901734,
        "end": 2285.6800000000003,
        "id": 631,
        "no_speech_prob": 0.00007141892274376005,
        "seek": 226232,
        "start": 2275.6800000000003,
        "temperature": 0,
        "text": " params, params, whatever, one more time, run the bot, weirdly, it's like, didn't complain at me,",
        "tokens": [
          51032,
          971,
          4070,
          11,
          971,
          4070,
          11,
          2035,
          11,
          472,
          544,
          565,
          11,
          1190,
          264,
          10592,
          11,
          48931,
          11,
          309,
          311,
          411,
          11,
          994,
          380,
          11024,
          412,
          385,
          11,
          51532
        ]
      },
      {
        "avg_logprob": -0.32266210626672814,
        "compression_ratio": 1.736842105263158,
        "end": 2295.12,
        "id": 632,
        "no_speech_prob": 0.005384890362620354,
        "seek": 228568,
        "start": 2286.48,
        "temperature": 0,
        "text": " oh, but, oh, why didn't it complain, because I didn't console log this response, I don't know why I'm",
        "tokens": [
          50404,
          1954,
          11,
          457,
          11,
          1954,
          11,
          983,
          994,
          380,
          309,
          11024,
          11,
          570,
          286,
          994,
          380,
          11076,
          3565,
          341,
          4134,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          50836
        ]
      },
      {
        "avg_logprob": -0.32266210626672814,
        "compression_ratio": 1.736842105263158,
        "end": 2299.2799999999997,
        "id": 633,
        "no_speech_prob": 0.005384890362620354,
        "seek": 228568,
        "start": 2295.12,
        "temperature": 0,
        "text": " going crazy to show you this error, when I could just fix the error in the first place, all right,",
        "tokens": [
          50836,
          516,
          3219,
          281,
          855,
          291,
          341,
          6713,
          11,
          562,
          286,
          727,
          445,
          3191,
          264,
          6713,
          294,
          264,
          700,
          1081,
          11,
          439,
          558,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.32266210626672814,
        "compression_ratio": 1.736842105263158,
        "end": 2304.64,
        "id": 634,
        "no_speech_prob": 0.005384890362620354,
        "seek": 228568,
        "start": 2299.2799999999997,
        "temperature": 0,
        "text": " so all this stuff came in, and it looks like maybe this worked, because I'm getting all this stuff,",
        "tokens": [
          51044,
          370,
          439,
          341,
          1507,
          1361,
          294,
          11,
          293,
          309,
          1542,
          411,
          1310,
          341,
          2732,
          11,
          570,
          286,
          478,
          1242,
          439,
          341,
          1507,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.32266210626672814,
        "compression_ratio": 1.736842105263158,
        "end": 2311.68,
        "id": 635,
        "no_speech_prob": 0.005384890362620354,
        "seek": 228568,
        "start": 2304.64,
        "temperature": 0,
        "text": " but somewhere up here, I'm going to see like an error code, oh, so much stuff, false high water",
        "tokens": [
          51312,
          457,
          4079,
          493,
          510,
          11,
          286,
          478,
          516,
          281,
          536,
          411,
          364,
          6713,
          3089,
          11,
          1954,
          11,
          370,
          709,
          1507,
          11,
          7908,
          1090,
          1281,
          51664
        ]
      },
      {
        "avg_logprob": -0.32233474994527883,
        "compression_ratio": 1.75,
        "end": 2317.6,
        "id": 636,
        "no_speech_prob": 0.00033015228109434247,
        "seek": 231168,
        "start": 2311.7599999999998,
        "temperature": 0,
        "text": " mark, I don't know, this seemed to have worked, no, this is nonsense, this is saying this page",
        "tokens": [
          50368,
          1491,
          11,
          286,
          500,
          380,
          458,
          11,
          341,
          6576,
          281,
          362,
          2732,
          11,
          572,
          11,
          341,
          307,
          14925,
          11,
          341,
          307,
          1566,
          341,
          3028,
          50660
        ]
      },
      {
        "avg_logprob": -0.32233474994527883,
        "compression_ratio": 1.75,
        "end": 2323.3599999999997,
        "id": 637,
        "no_speech_prob": 0.00033015228109434247,
        "seek": 231168,
        "start": 2317.6,
        "temperature": 0,
        "text": " is not correct, let me go back, but this doesn't, this doesn't need, I got to edit this out, because",
        "tokens": [
          50660,
          307,
          406,
          3006,
          11,
          718,
          385,
          352,
          646,
          11,
          457,
          341,
          1177,
          380,
          11,
          341,
          1177,
          380,
          643,
          11,
          286,
          658,
          281,
          8129,
          341,
          484,
          11,
          570,
          50948
        ]
      },
      {
        "avg_logprob": -0.32233474994527883,
        "compression_ratio": 1.75,
        "end": 2337.68,
        "id": 638,
        "no_speech_prob": 0.00033015228109434247,
        "seek": 231168,
        "start": 2323.3599999999997,
        "temperature": 0,
        "text": " it's not that, let me just go back to here, so this is almost done, but there's a problem, I can't",
        "tokens": [
          50948,
          309,
          311,
          406,
          300,
          11,
          718,
          385,
          445,
          352,
          646,
          281,
          510,
          11,
          370,
          341,
          307,
          1920,
          1096,
          11,
          457,
          456,
          311,
          257,
          1154,
          11,
          286,
          393,
          380,
          51664
        ]
      },
      {
        "avg_logprob": -0.2998571526514341,
        "compression_ratio": 1.6900584795321638,
        "end": 2344,
        "id": 639,
        "no_speech_prob": 0.0010322252055630088,
        "seek": 233768,
        "start": 2337.68,
        "temperature": 0,
        "text": " just pass it the file name, this actually needs to be a readable stream, and so I need to use the",
        "tokens": [
          50364,
          445,
          1320,
          309,
          264,
          3991,
          1315,
          11,
          341,
          767,
          2203,
          281,
          312,
          257,
          49857,
          4309,
          11,
          293,
          370,
          286,
          643,
          281,
          764,
          264,
          50680
        ]
      },
      {
        "avg_logprob": -0.2998571526514341,
        "compression_ratio": 1.6900584795321638,
        "end": 2351.2,
        "id": 640,
        "no_speech_prob": 0.0010322252055630088,
        "seek": 233768,
        "start": 2344,
        "temperature": 0,
        "text": " file system package, if I go and look for node file system package, and in here, somewhere, I",
        "tokens": [
          50680,
          3991,
          1185,
          7372,
          11,
          498,
          286,
          352,
          293,
          574,
          337,
          9984,
          3991,
          1185,
          7372,
          11,
          293,
          294,
          510,
          11,
          4079,
          11,
          286,
          51040
        ]
      },
      {
        "avg_logprob": -0.2998571526514341,
        "compression_ratio": 1.6900584795321638,
        "end": 2356.64,
        "id": 641,
        "no_speech_prob": 0.0010322252055630088,
        "seek": 233768,
        "start": 2351.2,
        "temperature": 0,
        "text": " think there's like a create stream function, and actually, probably a better place for me to look",
        "tokens": [
          51040,
          519,
          456,
          311,
          411,
          257,
          1884,
          4309,
          2445,
          11,
          293,
          767,
          11,
          1391,
          257,
          1101,
          1081,
          337,
          385,
          281,
          574,
          51312
        ]
      },
      {
        "avg_logprob": -0.7741653735821064,
        "compression_ratio": 1.6020408163265305,
        "end": 2362.4,
        "id": 642,
        "no_speech_prob": 0.05580873042345047,
        "seek": 235664,
        "start": 2356.64,
        "temperature": 0,
        "text": " is just right here in, hold on, I'm going to have to do this again,",
        "tokens": [
          50364,
          307,
          445,
          558,
          510,
          294,
          11,
          1797,
          322,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          360,
          341,
          797,
          11,
          50652
        ]
      },
      {
        "avg_logprob": -0.7741653735821064,
        "compression_ratio": 1.6020408163265305,
        "end": 2381.44,
        "id": 643,
        "no_speech_prob": 0.05580873042345047,
        "seek": 235664,
        "start": 2375.12,
        "temperature": 0,
        "text": " there's some stuff going on, oh, super test, I never, I never, I never, I never, I never,",
        "tokens": [
          51288,
          456,
          311,
          512,
          1507,
          516,
          322,
          11,
          1954,
          11,
          1687,
          1500,
          11,
          286,
          1128,
          11,
          286,
          1128,
          11,
          286,
          1128,
          11,
          286,
          1128,
          11,
          286,
          1128,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.26534912802956323,
        "compression_ratio": 1.5073529411764706,
        "end": 2388,
        "id": 644,
        "no_speech_prob": 0.004905312322080135,
        "seek": 238144,
        "start": 2381.68,
        "temperature": 0,
        "text": " there's some stuff going on, oh, super test, I didn't look into that, no, sorry,",
        "tokens": [
          50376,
          456,
          311,
          512,
          1507,
          516,
          322,
          11,
          1954,
          11,
          1687,
          1500,
          11,
          286,
          994,
          380,
          574,
          666,
          300,
          11,
          572,
          11,
          2597,
          11,
          50692
        ]
      },
      {
        "avg_logprob": -0.26534912802956323,
        "compression_ratio": 1.5073529411764706,
        "end": 2394.32,
        "id": 645,
        "no_speech_prob": 0.004905312322080135,
        "seek": 238144,
        "start": 2391.68,
        "temperature": 0,
        "text": " sorry, I forgot what it is,",
        "tokens": [
          50876,
          2597,
          11,
          286,
          5298,
          437,
          309,
          307,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.26534912802956323,
        "compression_ratio": 1.5073529411764706,
        "end": 2405.92,
        "id": 646,
        "no_speech_prob": 0.004905312322080135,
        "seek": 238144,
        "start": 2401.44,
        "temperature": 0,
        "text": " create read stream, yeah, that's what I want, I think, okay, I'm pretty sure that's what I want,",
        "tokens": [
          51364,
          1884,
          1401,
          4309,
          11,
          1338,
          11,
          300,
          311,
          437,
          286,
          528,
          11,
          286,
          519,
          11,
          1392,
          11,
          286,
          478,
          1238,
          988,
          300,
          311,
          437,
          286,
          528,
          11,
          51588
        ]
      },
      {
        "avg_logprob": -0.22770569104106486,
        "compression_ratio": 1.6730769230769231,
        "end": 2409.92,
        "id": 647,
        "no_speech_prob": 0.00020662846509367228,
        "seek": 240592,
        "start": 2406.32,
        "temperature": 0,
        "text": " sorry, let me go back and do this one more time, thank you, Matzuh,",
        "tokens": [
          50384,
          2597,
          11,
          718,
          385,
          352,
          646,
          293,
          360,
          341,
          472,
          544,
          565,
          11,
          1309,
          291,
          11,
          6789,
          89,
          3232,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.22770569104106486,
        "compression_ratio": 1.6730769230769231,
        "end": 2419.92,
        "id": 648,
        "no_speech_prob": 0.00020662846509367228,
        "seek": 240592,
        "start": 2412.56,
        "temperature": 0,
        "text": " all right, so almost there, but this actually is incorrect, it doesn't work, the API is not",
        "tokens": [
          50696,
          439,
          558,
          11,
          370,
          1920,
          456,
          11,
          457,
          341,
          767,
          307,
          18424,
          11,
          309,
          1177,
          380,
          589,
          11,
          264,
          9362,
          307,
          406,
          51064
        ]
      },
      {
        "avg_logprob": -0.22770569104106486,
        "compression_ratio": 1.6730769230769231,
        "end": 2424.96,
        "id": 649,
        "no_speech_prob": 0.00020662846509367228,
        "seek": 240592,
        "start": 2419.92,
        "temperature": 0,
        "text": " going to just accept a string of the file name and figure out how to like read that file and",
        "tokens": [
          51064,
          516,
          281,
          445,
          3241,
          257,
          6798,
          295,
          264,
          3991,
          1315,
          293,
          2573,
          484,
          577,
          281,
          411,
          1401,
          300,
          3991,
          293,
          51316
        ]
      },
      {
        "avg_logprob": -0.22770569104106486,
        "compression_ratio": 1.6730769230769231,
        "end": 2429.6,
        "id": 650,
        "no_speech_prob": 0.00020662846509367228,
        "seek": 240592,
        "start": 2424.96,
        "temperature": 0,
        "text": " post all the data of that file to the server, what I actually need to do is give it a readable",
        "tokens": [
          51316,
          2183,
          439,
          264,
          1412,
          295,
          300,
          3991,
          281,
          264,
          7154,
          11,
          437,
          286,
          767,
          643,
          281,
          360,
          307,
          976,
          309,
          257,
          49857,
          51548
        ]
      },
      {
        "avg_logprob": -0.22770569104106486,
        "compression_ratio": 1.6730769230769231,
        "end": 2434.4,
        "id": 651,
        "no_speech_prob": 0.00020662846509367228,
        "seek": 240592,
        "start": 2429.6,
        "temperature": 0,
        "text": " stream, and if I, and so the code for doing that, it's part of the file system package,",
        "tokens": [
          51548,
          4309,
          11,
          293,
          498,
          286,
          11,
          293,
          370,
          264,
          3089,
          337,
          884,
          300,
          11,
          309,
          311,
          644,
          295,
          264,
          3991,
          1185,
          7372,
          11,
          51788
        ]
      },
      {
        "avg_logprob": -0.17621220179966518,
        "compression_ratio": 1.6607142857142858,
        "end": 2439.84,
        "id": 652,
        "no_speech_prob": 0.00003647845005616546,
        "seek": 243440,
        "start": 2434.4,
        "temperature": 0,
        "text": " so I need to, I need to actually also require that, and we could look up the documentation for",
        "tokens": [
          50364,
          370,
          286,
          643,
          281,
          11,
          286,
          643,
          281,
          767,
          611,
          3651,
          300,
          11,
          293,
          321,
          727,
          574,
          493,
          264,
          14333,
          337,
          50636
        ]
      },
      {
        "avg_logprob": -0.17621220179966518,
        "compression_ratio": 1.6607142857142858,
        "end": 2447.36,
        "id": 653,
        "no_speech_prob": 0.00003647845005616546,
        "seek": 243440,
        "start": 2439.84,
        "temperature": 0,
        "text": " it, but I happen to know it, I think, so I need to say, I'm going to say constant stream equals",
        "tokens": [
          50636,
          309,
          11,
          457,
          286,
          1051,
          281,
          458,
          309,
          11,
          286,
          519,
          11,
          370,
          286,
          643,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          584,
          5754,
          4309,
          6915,
          51012
        ]
      },
      {
        "avg_logprob": -0.17621220179966518,
        "compression_ratio": 1.6607142857142858,
        "end": 2454.08,
        "id": 654,
        "no_speech_prob": 0.00003647845005616546,
        "seek": 243440,
        "start": 2447.36,
        "temperature": 0,
        "text": " file system create, there it is, read stream, auto-complete, thank you, output.png, oh,",
        "tokens": [
          51012,
          3991,
          1185,
          1884,
          11,
          456,
          309,
          307,
          11,
          1401,
          4309,
          11,
          8399,
          12,
          1112,
          17220,
          11,
          1309,
          291,
          11,
          5598,
          13,
          79,
          872,
          11,
          1954,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.17621220179966518,
        "compression_ratio": 1.6607142857142858,
        "end": 2461.04,
        "id": 655,
        "no_speech_prob": 0.00003647845005616546,
        "seek": 243440,
        "start": 2455.12,
        "temperature": 0,
        "text": " and this actually isn't even right, because guess what, remember, output.png was saved in the",
        "tokens": [
          51400,
          293,
          341,
          767,
          1943,
          380,
          754,
          558,
          11,
          570,
          2041,
          437,
          11,
          1604,
          11,
          5598,
          13,
          79,
          872,
          390,
          6624,
          294,
          264,
          51696
        ]
      },
      {
        "avg_logprob": -0.190153813829609,
        "compression_ratio": 1.808411214953271,
        "end": 2468.32,
        "id": 656,
        "no_speech_prob": 0.00013982190284878016,
        "seek": 246104,
        "start": 2461.04,
        "temperature": 0,
        "text": " processing sketch, which is the folder tree gen slash output.png, so now this is the stream,",
        "tokens": [
          50364,
          9007,
          12325,
          11,
          597,
          307,
          264,
          10820,
          4230,
          1049,
          17330,
          5598,
          13,
          79,
          872,
          11,
          370,
          586,
          341,
          307,
          264,
          4309,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.190153813829609,
        "compression_ratio": 1.808411214953271,
        "end": 2474.4,
        "id": 657,
        "no_speech_prob": 0.00013982190284878016,
        "seek": 246104,
        "start": 2468.96,
        "temperature": 0,
        "text": " and this is the description that goes with it, okay, and then I want to make sure this worked,",
        "tokens": [
          50760,
          293,
          341,
          307,
          264,
          3855,
          300,
          1709,
          365,
          309,
          11,
          1392,
          11,
          293,
          550,
          286,
          528,
          281,
          652,
          988,
          341,
          2732,
          11,
          51032
        ]
      },
      {
        "avg_logprob": -0.190153813829609,
        "compression_ratio": 1.808411214953271,
        "end": 2482.16,
        "id": 658,
        "no_speech_prob": 0.00013982190284878016,
        "seek": 246104,
        "start": 2474.4,
        "temperature": 0,
        "text": " so I want to actually console log the response, so now, in theory, I have the code all the way for",
        "tokens": [
          51032,
          370,
          286,
          528,
          281,
          767,
          11076,
          3565,
          264,
          4134,
          11,
          370,
          586,
          11,
          294,
          5261,
          11,
          286,
          362,
          264,
          3089,
          439,
          264,
          636,
          337,
          51420
        ]
      },
      {
        "avg_logprob": -0.190153813829609,
        "compression_ratio": 1.808411214953271,
        "end": 2487.7599999999998,
        "id": 659,
        "no_speech_prob": 0.00013982190284878016,
        "seek": 246104,
        "start": 2482.16,
        "temperature": 0,
        "text": " executing processing, uploading the image, I need to, when I get the response, I need to get the id,",
        "tokens": [
          51420,
          32368,
          9007,
          11,
          27301,
          264,
          3256,
          11,
          286,
          643,
          281,
          11,
          562,
          286,
          483,
          264,
          4134,
          11,
          286,
          643,
          281,
          483,
          264,
          4496,
          11,
          51700
        ]
      },
      {
        "avg_logprob": -0.16982038715217687,
        "compression_ratio": 1.6241610738255035,
        "end": 2492.88,
        "id": 660,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 248776,
        "start": 2487.76,
        "temperature": 0,
        "text": " and then I go and actually just post the status, okay, here we go, let's try this,",
        "tokens": [
          50364,
          293,
          550,
          286,
          352,
          293,
          767,
          445,
          2183,
          264,
          6558,
          11,
          1392,
          11,
          510,
          321,
          352,
          11,
          718,
          311,
          853,
          341,
          11,
          50620
        ]
      },
      {
        "avg_logprob": -0.16982038715217687,
        "compression_ratio": 1.6241610738255035,
        "end": 2504.6400000000003,
        "id": 661,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 248776,
        "start": 2497.36,
        "temperature": 0,
        "text": " oh, unhandled stream error in pipe, no such foul, no such foul, no such file,",
        "tokens": [
          50844,
          1954,
          11,
          517,
          5543,
          1493,
          4309,
          6713,
          294,
          11240,
          11,
          572,
          1270,
          23491,
          11,
          572,
          1270,
          23491,
          11,
          572,
          1270,
          3991,
          11,
          51208
        ]
      },
      {
        "avg_logprob": -0.16982038715217687,
        "compression_ratio": 1.6241610738255035,
        "end": 2512.48,
        "id": 662,
        "no_speech_prob": 0.000013845985449734144,
        "seek": 248776,
        "start": 2504.6400000000003,
        "temperature": 0,
        "text": " oh, it's not called output.png, I called it tree.png, okay, let's try that again,",
        "tokens": [
          51208,
          1954,
          11,
          309,
          311,
          406,
          1219,
          5598,
          13,
          79,
          872,
          11,
          286,
          1219,
          309,
          4230,
          13,
          79,
          872,
          11,
          1392,
          11,
          718,
          311,
          853,
          300,
          797,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.1991741460397703,
        "compression_ratio": 1.7272727272727273,
        "end": 2518,
        "id": 663,
        "no_speech_prob": 0.0005033313063904643,
        "seek": 251248,
        "start": 2513.44,
        "temperature": 0,
        "text": " finished, and great, so look, this is all the stuff that I got back, now, it's kind of too much stuff",
        "tokens": [
          50412,
          4335,
          11,
          293,
          869,
          11,
          370,
          574,
          11,
          341,
          307,
          439,
          264,
          1507,
          300,
          286,
          658,
          646,
          11,
          586,
          11,
          309,
          311,
          733,
          295,
          886,
          709,
          1507,
          50640
        ]
      },
      {
        "avg_logprob": -0.1991741460397703,
        "compression_ratio": 1.7272727272727273,
        "end": 2524.48,
        "id": 664,
        "no_speech_prob": 0.0005033313063904643,
        "seek": 251248,
        "start": 2518,
        "temperature": 0,
        "text": " for me to look through, oh, what a pain, did this actually work, my goodness, craziest, but this is",
        "tokens": [
          50640,
          337,
          385,
          281,
          574,
          807,
          11,
          1954,
          11,
          437,
          257,
          1822,
          11,
          630,
          341,
          767,
          589,
          11,
          452,
          8387,
          11,
          46339,
          11,
          457,
          341,
          307,
          50964
        ]
      },
      {
        "avg_logprob": -0.1991741460397703,
        "compression_ratio": 1.7272727272727273,
        "end": 2529.84,
        "id": 665,
        "no_speech_prob": 0.0005033313063904643,
        "seek": 251248,
        "start": 2524.48,
        "temperature": 0,
        "text": " all I care about, there's more important stuff, there's more stuff, lots of tons of metadata about",
        "tokens": [
          50964,
          439,
          286,
          1127,
          466,
          11,
          456,
          311,
          544,
          1021,
          1507,
          11,
          456,
          311,
          544,
          1507,
          11,
          3195,
          295,
          9131,
          295,
          26603,
          466,
          51232
        ]
      },
      {
        "avg_logprob": -0.1991741460397703,
        "compression_ratio": 1.7272727272727273,
        "end": 2536.2400000000002,
        "id": 666,
        "no_speech_prob": 0.0005033313063904643,
        "seek": 251248,
        "start": 2529.84,
        "temperature": 0,
        "text": " the image that you just uploaded, but all I really need is data.id, so let me just go here and say",
        "tokens": [
          51232,
          264,
          3256,
          300,
          291,
          445,
          17135,
          11,
          457,
          439,
          286,
          534,
          643,
          307,
          1412,
          13,
          327,
          11,
          370,
          718,
          385,
          445,
          352,
          510,
          293,
          584,
          51552
        ]
      },
      {
        "avg_logprob": -0.2075734602666534,
        "compression_ratio": 1.6422413793103448,
        "end": 2544.9599999999996,
        "id": 667,
        "no_speech_prob": 0.008445555344223976,
        "seek": 253624,
        "start": 2536.24,
        "temperature": 0,
        "text": " console.log response.data.id, and I apologize to the bots in dot space for overloading your server,",
        "tokens": [
          50364,
          11076,
          13,
          4987,
          4134,
          13,
          67,
          3274,
          13,
          327,
          11,
          293,
          286,
          12328,
          281,
          264,
          35410,
          294,
          5893,
          1901,
          337,
          28777,
          278,
          428,
          7154,
          11,
          50800
        ]
      },
      {
        "avg_logprob": -0.2075734602666534,
        "compression_ratio": 1.6422413793103448,
        "end": 2552,
        "id": 668,
        "no_speech_prob": 0.008445555344223976,
        "seek": 253624,
        "start": 2544.9599999999996,
        "temperature": 0,
        "text": " and you can see, there's the id, okay, now, guess what, can I, should I start using, I'm going to",
        "tokens": [
          50800,
          293,
          291,
          393,
          536,
          11,
          456,
          311,
          264,
          4496,
          11,
          1392,
          11,
          586,
          11,
          2041,
          437,
          11,
          393,
          286,
          11,
          820,
          286,
          722,
          1228,
          11,
          286,
          478,
          516,
          281,
          51152
        ]
      },
      {
        "avg_logprob": -0.2075734602666534,
        "compression_ratio": 1.6422413793103448,
        "end": 2556.64,
        "id": 669,
        "no_speech_prob": 0.008445555344223976,
        "seek": 253624,
        "start": 2552,
        "temperature": 0,
        "text": " just keep going, why not go with this promise chain, this is how I would do it, probably,",
        "tokens": [
          51152,
          445,
          1066,
          516,
          11,
          983,
          406,
          352,
          365,
          341,
          6228,
          5021,
          11,
          341,
          307,
          577,
          286,
          576,
          360,
          309,
          11,
          1391,
          11,
          51384
        ]
      },
      {
        "avg_logprob": -0.2075734602666534,
        "compression_ratio": 1.6422413793103448,
        "end": 2564.64,
        "id": 670,
        "no_speech_prob": 0.008445555344223976,
        "seek": 253624,
        "start": 2557.7599999999998,
        "temperature": 0,
        "text": " then, oh, no, and then, all I need to do is return one more promise, so I'm also going to say",
        "tokens": [
          51440,
          550,
          11,
          1954,
          11,
          572,
          11,
          293,
          550,
          11,
          439,
          286,
          643,
          281,
          360,
          307,
          2736,
          472,
          544,
          6228,
          11,
          370,
          286,
          478,
          611,
          516,
          281,
          584,
          51784
        ]
      },
      {
        "avg_logprob": -0.21253298535759066,
        "compression_ratio": 1.7218543046357615,
        "end": 2573.6,
        "id": 671,
        "no_speech_prob": 0.004609511699527502,
        "seek": 256464,
        "start": 2564.64,
        "temperature": 0,
        "text": " constant parameters, now, I want to do, I need to look at the API for what, post, but just statuses,",
        "tokens": [
          50364,
          5754,
          9834,
          11,
          586,
          11,
          286,
          528,
          281,
          360,
          11,
          286,
          643,
          281,
          574,
          412,
          264,
          9362,
          337,
          437,
          11,
          2183,
          11,
          457,
          445,
          6558,
          279,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.21253298535759066,
        "compression_ratio": 1.7218543046357615,
        "end": 2579.7599999999998,
        "id": 672,
        "no_speech_prob": 0.004609511699527502,
        "seek": 256464,
        "start": 2576.24,
        "temperature": 0,
        "text": " so this is, where is I'm looking, looking, looking, looking, looking,",
        "tokens": [
          50944,
          370,
          341,
          307,
          11,
          689,
          307,
          286,
          478,
          1237,
          11,
          1237,
          11,
          1237,
          11,
          1237,
          11,
          1237,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.21253298535759066,
        "compression_ratio": 1.7218543046357615,
        "end": 2593.04,
        "id": 673,
        "no_speech_prob": 0.004609511699527502,
        "seek": 256464,
        "start": 2582.64,
        "temperature": 0,
        "text": " actually, I need to look for API v1 statuses, sorry, oh, I failed, do I, maybe I want to,",
        "tokens": [
          51264,
          767,
          11,
          286,
          643,
          281,
          574,
          337,
          9362,
          371,
          16,
          6558,
          279,
          11,
          2597,
          11,
          1954,
          11,
          286,
          7612,
          11,
          360,
          286,
          11,
          1310,
          286,
          528,
          281,
          11,
          51784
        ]
      },
      {
        "avg_logprob": -0.1871960288599918,
        "compression_ratio": 1.973856209150327,
        "end": 2598.48,
        "id": 674,
        "no_speech_prob": 0.0000013925454140917282,
        "seek": 259304,
        "start": 2593.04,
        "temperature": 0,
        "text": " maybe I should, like, actually now, rewrite this using async and await, I'm going to do that,",
        "tokens": [
          50364,
          1310,
          286,
          820,
          11,
          411,
          11,
          767,
          586,
          11,
          28132,
          341,
          1228,
          382,
          34015,
          293,
          19670,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.1871960288599918,
        "compression_ratio": 1.973856209150327,
        "end": 2604.96,
        "id": 675,
        "no_speech_prob": 0.0000013925454140917282,
        "seek": 259304,
        "start": 2598.48,
        "temperature": 0,
        "text": " I'm going to do that, I'm going to do that, I'm going to do that,",
        "tokens": [
          50636,
          286,
          478,
          516,
          281,
          360,
          300,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          11,
          50960
        ]
      },
      {
        "avg_logprob": -0.1871960288599918,
        "compression_ratio": 1.973856209150327,
        "end": 2611.2799999999997,
        "id": 676,
        "no_speech_prob": 0.0000013925454140917282,
        "seek": 259304,
        "start": 2607.92,
        "temperature": 0,
        "text": " all right, I'm going to go from where I printed this out,",
        "tokens": [
          51108,
          439,
          558,
          11,
          286,
          478,
          516,
          281,
          352,
          490,
          689,
          286,
          13567,
          341,
          484,
          11,
          51276
        ]
      },
      {
        "avg_logprob": -0.1871960288599918,
        "compression_ratio": 1.973856209150327,
        "end": 2621.36,
        "id": 677,
        "no_speech_prob": 0.0000013925454140917282,
        "seek": 259304,
        "start": 2614,
        "temperature": 0,
        "text": " now, the next step would be for, to use this id, and then, actually, in the, in the,",
        "tokens": [
          51412,
          586,
          11,
          264,
          958,
          1823,
          576,
          312,
          337,
          11,
          281,
          764,
          341,
          4496,
          11,
          293,
          550,
          11,
          767,
          11,
          294,
          264,
          11,
          294,
          264,
          11,
          51780
        ]
      },
      {
        "avg_logprob": -0.20894986010612326,
        "compression_ratio": 1.3304347826086957,
        "end": 2627.1200000000003,
        "id": 678,
        "no_speech_prob": 0.000315037090331316,
        "seek": 262136,
        "start": 2621.36,
        "temperature": 0,
        "text": " in this response, right, I exec, I execute the command, I upload the image, and then,",
        "tokens": [
          50364,
          294,
          341,
          4134,
          11,
          558,
          11,
          286,
          4454,
          11,
          286,
          14483,
          264,
          5622,
          11,
          286,
          6580,
          264,
          3256,
          11,
          293,
          550,
          11,
          50652
        ]
      },
      {
        "avg_logprob": -0.20894986010612326,
        "compression_ratio": 1.3304347826086957,
        "end": 2633.28,
        "id": 679,
        "no_speech_prob": 0.000315037090331316,
        "seek": 262136,
        "start": 2627.1200000000003,
        "temperature": 0,
        "text": " I should be saying, return m.post again, and I'm going to statuses,",
        "tokens": [
          50652,
          286,
          820,
          312,
          1566,
          11,
          2736,
          275,
          13,
          23744,
          797,
          11,
          293,
          286,
          478,
          516,
          281,
          6558,
          279,
          11,
          50960
        ]
      },
      {
        "avg_logprob": -0.8970434088456003,
        "compression_ratio": 1.6011560693641618,
        "end": 2640.1600000000003,
        "id": 680,
        "no_speech_prob": 0.005139465443789959,
        "seek": 263328,
        "start": 2633.84,
        "temperature": 1,
        "text": " I should say, return m.post, again, and I'm going to, the path I'm going to, is statuses,",
        "tokens": [
          50392,
          286,
          820,
          584,
          11,
          2736,
          275,
          13,
          30010,
          83,
          11,
          797,
          11,
          293,
          286,
          478,
          516,
          281,
          11,
          264,
          3100,
          286,
          478,
          516,
          281,
          11,
          307,
          6558,
          279,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.8970434088456003,
        "compression_ratio": 1.6011560693641618,
        "end": 2644,
        "id": 681,
        "no_speech_prob": 0.005139465443789959,
        "seek": 263328,
        "start": 2640.6400000000003,
        "temperature": 1,
        "text": " so, this, is what I should be doing, but,",
        "tokens": [
          50732,
          370,
          11,
          341,
          11,
          307,
          437,
          286,
          820,
          312,
          884,
          11,
          457,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.8970434088456003,
        "compression_ratio": 1.6011560693641618,
        "end": 2649.0400000000004,
        "id": 682,
        "no_speech_prob": 0.005139465443789959,
        "seek": 263328,
        "start": 2644.8,
        "temperature": 1,
        "text": " I can't resist, do you see how this is, I mean, it's great, it's kind of nice,",
        "tokens": [
          50940,
          286,
          393,
          380,
          4597,
          11,
          360,
          291,
          536,
          577,
          341,
          741,
          82,
          11,
          286,
          914,
          11,
          309,
          311,
          869,
          11,
          309,
          311,
          733,
          295,
          1481,
          11,
          51152
        ]
      },
      {
        "avg_logprob": -0.8970434088456003,
        "compression_ratio": 1.6011560693641618,
        "end": 2653.84,
        "id": 683,
        "no_speech_prob": 0.005139465443789959,
        "seek": 263328,
        "start": 2649.84,
        "temperature": 1,
        "text": " start the promise chain, then do this, now, it's very competitive,",
        "tokens": [
          51192,
          722,
          264,
          6228,
          5021,
          11,
          220,
          19096,
          360,
          341,
          11,
          586,
          11,
          309,
          311,
          588,
          10043,
          11,
          51392
        ]
      },
      {
        "avg_logprob": -0.28394053141276043,
        "compression_ratio": 1.6538461538461537,
        "end": 2668.96,
        "id": 684,
        "no_speech_prob": 0.0316157266497612,
        "seek": 265384,
        "start": 2654.08,
        "temperature": 0.2,
        "text": " then do this, return a new promise, and if any error happens anywhere in here, catch,",
        "tokens": [
          50376,
          550,
          360,
          341,
          11,
          2736,
          257,
          777,
          6228,
          11,
          293,
          498,
          604,
          6713,
          2314,
          4992,
          294,
          510,
          11,
          3745,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.28394053141276043,
        "compression_ratio": 1.6538461538461537,
        "end": 2675.2000000000003,
        "id": 685,
        "no_speech_prob": 0.0316157266497612,
        "seek": 265384,
        "start": 2668.96,
        "temperature": 0.2,
        "text": " so, why not, but, this is the thing, this is, now, there is a way, there is a new way,",
        "tokens": [
          51120,
          370,
          11,
          983,
          406,
          11,
          457,
          11,
          341,
          307,
          264,
          551,
          11,
          341,
          307,
          11,
          586,
          11,
          456,
          307,
          257,
          636,
          11,
          456,
          307,
          257,
          777,
          636,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.28394053141276043,
        "compression_ratio": 1.6538461538461537,
        "end": 2682.2400000000002,
        "id": 686,
        "no_speech_prob": 0.0316157266497612,
        "seek": 265384,
        "start": 2675.76,
        "temperature": 0.2,
        "text": " for me to write all of this in what feels more sequential, more synchronous, in fact,",
        "tokens": [
          51460,
          337,
          385,
          281,
          2464,
          439,
          295,
          341,
          294,
          437,
          3417,
          544,
          42881,
          11,
          544,
          44743,
          11,
          294,
          1186,
          11,
          51784
        ]
      },
      {
        "avg_logprob": -0.18135848798249898,
        "compression_ratio": 1.9473684210526316,
        "end": 2688.16,
        "id": 687,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 268224,
        "start": 2682.9599999999996,
        "temperature": 0,
        "text": " with less kind of indentation and brackets and stuff, and that is using this async and await",
        "tokens": [
          50400,
          365,
          1570,
          733,
          295,
          44494,
          399,
          293,
          26179,
          293,
          1507,
          11,
          293,
          300,
          307,
          1228,
          341,
          382,
          34015,
          293,
          19670,
          50660
        ]
      },
      {
        "avg_logprob": -0.18135848798249898,
        "compression_ratio": 1.9473684210526316,
        "end": 2691.68,
        "id": 688,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 268224,
        "start": 2688.16,
        "temperature": 0,
        "text": " syntax, so, what I'm actually going to do, is I'm going to write a function,",
        "tokens": [
          50660,
          28431,
          11,
          370,
          11,
          437,
          286,
          478,
          767,
          516,
          281,
          360,
          11,
          307,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          11,
          50836
        ]
      },
      {
        "avg_logprob": -0.18135848798249898,
        "compression_ratio": 1.9473684210526316,
        "end": 2700.24,
        "id": 689,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 268224,
        "start": 2693.04,
        "temperature": 0,
        "text": " I'm going to call it tutor, or just toot, and I'm going to modify this function with the keyword",
        "tokens": [
          50904,
          286,
          478,
          516,
          281,
          818,
          309,
          35613,
          11,
          420,
          445,
          281,
          310,
          11,
          293,
          286,
          478,
          516,
          281,
          16927,
          341,
          2445,
          365,
          264,
          20428,
          51264
        ]
      },
      {
        "avg_logprob": -0.18135848798249898,
        "compression_ratio": 1.9473684210526316,
        "end": 2705.12,
        "id": 690,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 268224,
        "start": 2700.24,
        "temperature": 0,
        "text": " async, this means this is an asynchronous function, this is indicating to JavaScript,",
        "tokens": [
          51264,
          382,
          34015,
          11,
          341,
          1355,
          341,
          307,
          364,
          49174,
          2445,
          11,
          341,
          307,
          25604,
          281,
          15778,
          11,
          51508
        ]
      },
      {
        "avg_logprob": -0.18135848798249898,
        "compression_ratio": 1.9473684210526316,
        "end": 2710.56,
        "id": 691,
        "no_speech_prob": 0.00004331898162490688,
        "seek": 268224,
        "start": 2705.12,
        "temperature": 0,
        "text": " this is a feature of ES8, a new feature of JavaScript, that's indicating that this function",
        "tokens": [
          51508,
          341,
          307,
          257,
          4111,
          295,
          12564,
          23,
          11,
          257,
          777,
          4111,
          295,
          15778,
          11,
          300,
          311,
          25604,
          300,
          341,
          2445,
          51780
        ]
      },
      {
        "avg_logprob": -0.21914144200602853,
        "compression_ratio": 1.9462809917355373,
        "end": 2716.32,
        "id": 692,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 271056,
        "start": 2710.56,
        "temperature": 0,
        "text": " will be handled asynchronously and always, always, always return a promise, and it will",
        "tokens": [
          50364,
          486,
          312,
          18033,
          42642,
          5098,
          293,
          1009,
          11,
          1009,
          11,
          1009,
          2736,
          257,
          6228,
          11,
          293,
          309,
          486,
          50652
        ]
      },
      {
        "avg_logprob": -0.21914144200602853,
        "compression_ratio": 1.9462809917355373,
        "end": 2719.92,
        "id": 693,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 271056,
        "start": 2716.32,
        "temperature": 0,
        "text": " auto-magically, it will basically automatically return that promise, so, we'll look at that later,",
        "tokens": [
          50652,
          8399,
          12,
          37941,
          984,
          11,
          309,
          486,
          1936,
          6772,
          2736,
          300,
          6228,
          11,
          370,
          11,
          321,
          603,
          574,
          412,
          300,
          1780,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.21914144200602853,
        "compression_ratio": 1.9462809917355373,
        "end": 2724.7999999999997,
        "id": 694,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 271056,
        "start": 2719.92,
        "temperature": 0,
        "text": " how it does that, so, in other words, but this, I want to do the same thing, like, what I want to",
        "tokens": [
          50832,
          577,
          309,
          775,
          300,
          11,
          370,
          11,
          294,
          661,
          2283,
          11,
          457,
          341,
          11,
          286,
          528,
          281,
          360,
          264,
          912,
          551,
          11,
          411,
          11,
          437,
          286,
          528,
          281,
          51076
        ]
      },
      {
        "avg_logprob": -0.21914144200602853,
        "compression_ratio": 1.9462809917355373,
        "end": 2729.7599999999998,
        "id": 695,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 271056,
        "start": 2724.7999999999997,
        "temperature": 0,
        "text": " do here, is I want to say exec, execute the command, right, these are the steps, and then I",
        "tokens": [
          51076,
          360,
          510,
          11,
          307,
          286,
          528,
          281,
          584,
          4454,
          11,
          14483,
          264,
          5622,
          11,
          558,
          11,
          613,
          366,
          264,
          4439,
          11,
          293,
          550,
          286,
          51324
        ]
      },
      {
        "avg_logprob": -0.21914144200602853,
        "compression_ratio": 1.9462809917355373,
        "end": 2737.68,
        "id": 696,
        "no_speech_prob": 0.00002078514444292523,
        "seek": 271056,
        "start": 2729.7599999999998,
        "temperature": 0,
        "text": " want to say post the media, post the media, the nice thing about using this syntax, is I don't",
        "tokens": [
          51324,
          528,
          281,
          584,
          2183,
          264,
          3021,
          11,
          2183,
          264,
          3021,
          11,
          264,
          1481,
          551,
          466,
          1228,
          341,
          28431,
          11,
          307,
          286,
          500,
          380,
          51720
        ]
      },
      {
        "avg_logprob": -0.20666925112406412,
        "compression_ratio": 1.8215962441314555,
        "end": 2744.56,
        "id": 697,
        "no_speech_prob": 0.00022693352366331965,
        "seek": 273768,
        "start": 2737.68,
        "temperature": 0,
        "text": " have to separate it out with these, chaining these dot thens, I can actually just use the await",
        "tokens": [
          50364,
          362,
          281,
          4994,
          309,
          484,
          365,
          613,
          11,
          417,
          3686,
          613,
          5893,
          550,
          82,
          11,
          286,
          393,
          767,
          445,
          764,
          264,
          19670,
          50708
        ]
      },
      {
        "avg_logprob": -0.20666925112406412,
        "compression_ratio": 1.8215962441314555,
        "end": 2752.56,
        "id": 698,
        "no_speech_prob": 0.00022693352366331965,
        "seek": 273768,
        "start": 2744.56,
        "temperature": 0,
        "text": " keyword, what the await keyword means, is don't go to the next line of code, await the end of this",
        "tokens": [
          50708,
          20428,
          11,
          437,
          264,
          19670,
          20428,
          1355,
          11,
          307,
          500,
          380,
          352,
          281,
          264,
          958,
          1622,
          295,
          3089,
          11,
          19670,
          264,
          917,
          295,
          341,
          51108
        ]
      },
      {
        "avg_logprob": -0.20666925112406412,
        "compression_ratio": 1.8215962441314555,
        "end": 2757.44,
        "id": 699,
        "no_speech_prob": 0.00022693352366331965,
        "seek": 273768,
        "start": 2752.56,
        "temperature": 0,
        "text": " function, so, if I have a bunch of asynchronous things, if I package them all together in an",
        "tokens": [
          51108,
          2445,
          11,
          370,
          11,
          498,
          286,
          362,
          257,
          3840,
          295,
          49174,
          721,
          11,
          498,
          286,
          7372,
          552,
          439,
          1214,
          294,
          364,
          51352
        ]
      },
      {
        "avg_logprob": -0.20666925112406412,
        "compression_ratio": 1.8215962441314555,
        "end": 2762.72,
        "id": 700,
        "no_speech_prob": 0.00022693352366331965,
        "seek": 273768,
        "start": 2757.44,
        "temperature": 0,
        "text": " asynchronous function, I can write them sequentially as line after line after line, and essentially,",
        "tokens": [
          51352,
          49174,
          2445,
          11,
          286,
          393,
          2464,
          552,
          5123,
          3137,
          382,
          1622,
          934,
          1622,
          934,
          1622,
          11,
          293,
          4476,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.21243448035661563,
        "compression_ratio": 1.6153846153846154,
        "end": 2772.08,
        "id": 701,
        "no_speech_prob": 0.00009170163684757426,
        "seek": 276272,
        "start": 2762.72,
        "temperature": 0,
        "text": " and, you know, I'm going to have some other params here, so, this is, basically, I get to write it",
        "tokens": [
          50364,
          293,
          11,
          291,
          458,
          11,
          286,
          478,
          516,
          281,
          362,
          512,
          661,
          971,
          4070,
          510,
          11,
          370,
          11,
          341,
          307,
          11,
          1936,
          11,
          286,
          483,
          281,
          2464,
          309,
          50832
        ]
      },
      {
        "avg_logprob": -0.21243448035661563,
        "compression_ratio": 1.6153846153846154,
        "end": 2776.64,
        "id": 702,
        "no_speech_prob": 0.00009170163684757426,
        "seek": 276272,
        "start": 2772.08,
        "temperature": 0,
        "text": " like this, now, I need to do stuff in between, that's the thing, like, for example, this returns",
        "tokens": [
          50832,
          411,
          341,
          11,
          586,
          11,
          286,
          643,
          281,
          360,
          1507,
          294,
          1296,
          11,
          300,
          311,
          264,
          551,
          11,
          411,
          11,
          337,
          1365,
          11,
          341,
          11247,
          51060
        ]
      },
      {
        "avg_logprob": -0.21243448035661563,
        "compression_ratio": 1.6153846153846154,
        "end": 2782.7999999999997,
        "id": 703,
        "no_speech_prob": 0.00009170163684757426,
        "seek": 276272,
        "start": 2776.64,
        "temperature": 0,
        "text": " a response, and then what I want to do is get the angle and create the stream, so, this goes here,",
        "tokens": [
          51060,
          257,
          4134,
          11,
          293,
          550,
          437,
          286,
          528,
          281,
          360,
          307,
          483,
          264,
          5802,
          293,
          1884,
          264,
          4309,
          11,
          370,
          11,
          341,
          1709,
          510,
          11,
          51368
        ]
      },
      {
        "avg_logprob": -0.34872369068424874,
        "compression_ratio": 1.3473684210526315,
        "end": 2786.0800000000004,
        "id": 704,
        "no_speech_prob": 0.0013250132324174047,
        "seek": 278280,
        "start": 2783.1200000000003,
        "temperature": 0,
        "text": " so, this is my step one,",
        "tokens": [
          50380,
          370,
          11,
          341,
          307,
          452,
          1823,
          472,
          11,
          50528
        ]
      },
      {
        "avg_logprob": -0.34872369068424874,
        "compression_ratio": 1.3473684210526315,
        "end": 2806.0800000000004,
        "id": 705,
        "no_speech_prob": 0.0013250132324174047,
        "seek": 278280,
        "start": 2798.0800000000004,
        "temperature": 0,
        "text": " this is my step one, right, execute processing, look at it, it's just exactly like this, now, I have my",
        "tokens": [
          51128,
          341,
          307,
          452,
          1823,
          472,
          11,
          558,
          11,
          14483,
          9007,
          11,
          574,
          412,
          309,
          11,
          309,
          311,
          445,
          2293,
          411,
          341,
          11,
          586,
          11,
          286,
          362,
          452,
          51528
        ]
      },
      {
        "avg_logprob": -0.2588090784409467,
        "compression_ratio": 1.5778894472361809,
        "end": 2813.92,
        "id": 706,
        "no_speech_prob": 0.006192880216985941,
        "seek": 280608,
        "start": 2806.08,
        "temperature": 0,
        "text": " step two, where I need to create these parameters that are getting passed in, and, by the way, I don't",
        "tokens": [
          50364,
          1823,
          732,
          11,
          689,
          286,
          643,
          281,
          1884,
          613,
          9834,
          300,
          366,
          1242,
          4678,
          294,
          11,
          293,
          11,
          538,
          264,
          636,
          11,
          286,
          500,
          380,
          50756
        ]
      },
      {
        "avg_logprob": -0.2588090784409467,
        "compression_ratio": 1.5778894472361809,
        "end": 2818.64,
        "id": 707,
        "no_speech_prob": 0.006192880216985941,
        "seek": 280608,
        "start": 2813.92,
        "temperature": 0,
        "text": " have to make a separate variable, it could be embedded right in here, but it's just sort of like, a little bit,",
        "tokens": [
          50756,
          362,
          281,
          652,
          257,
          4994,
          7006,
          11,
          309,
          727,
          312,
          16741,
          558,
          294,
          510,
          11,
          457,
          309,
          311,
          445,
          1333,
          295,
          411,
          11,
          257,
          707,
          857,
          11,
          50992
        ]
      },
      {
        "avg_logprob": -0.2588090784409467,
        "compression_ratio": 1.5778894472361809,
        "end": 2825.84,
        "id": 708,
        "no_speech_prob": 0.006192880216985941,
        "seek": 280608,
        "start": 2818.64,
        "temperature": 0,
        "text": " for legibility, I'm making it something separate, and so, I'm now going to say, basically, step two",
        "tokens": [
          50992,
          337,
          1676,
          2841,
          11,
          286,
          478,
          1455,
          309,
          746,
          4994,
          11,
          293,
          370,
          11,
          286,
          478,
          586,
          516,
          281,
          584,
          11,
          1936,
          11,
          1823,
          732,
          51352
        ]
      },
      {
        "avg_logprob": -0.3038451165863962,
        "compression_ratio": 1.5923076923076922,
        "end": 2838.48,
        "id": 709,
        "no_speech_prob": 0.06371276080608368,
        "seek": 282584,
        "start": 2826.8,
        "temperature": 0,
        "text": " is upload, upload, upload, ha, media, and that's going to have a response, and then, what do I need?",
        "tokens": [
          50412,
          307,
          6580,
          11,
          6580,
          11,
          6580,
          11,
          324,
          11,
          3021,
          11,
          293,
          300,
          311,
          516,
          281,
          362,
          257,
          4134,
          11,
          293,
          550,
          11,
          437,
          360,
          286,
          643,
          30,
          50996
        ]
      },
      {
        "avg_logprob": -0.3038451165863962,
        "compression_ratio": 1.5923076923076922,
        "end": 2849.28,
        "id": 710,
        "no_speech_prob": 0.06371276080608368,
        "seek": 282584,
        "start": 2838.48,
        "temperature": 0,
        "text": " I need to get the ID out of that, and then, I am now going to say, step three, and, by the way, I suppose,",
        "tokens": [
          50996,
          286,
          643,
          281,
          483,
          264,
          7348,
          484,
          295,
          300,
          11,
          293,
          550,
          11,
          286,
          669,
          586,
          516,
          281,
          584,
          11,
          1823,
          1045,
          11,
          293,
          11,
          538,
          264,
          636,
          11,
          286,
          7297,
          11,
          51536
        ]
      },
      {
        "avg_logprob": -0.2518792386914863,
        "compression_ratio": 1.84,
        "end": 2856.6400000000003,
        "id": 711,
        "no_speech_prob": 0.03514423221349716,
        "seek": 284928,
        "start": 2849.28,
        "temperature": 0,
        "text": " if I'm being accurate about this, this is all, I suppose, this is part of step two, I don't know,",
        "tokens": [
          50364,
          498,
          286,
          478,
          885,
          8559,
          466,
          341,
          11,
          341,
          307,
          439,
          11,
          286,
          7297,
          11,
          341,
          307,
          644,
          295,
          1823,
          732,
          11,
          286,
          500,
          380,
          458,
          11,
          50732
        ]
      },
      {
        "avg_logprob": -0.2518792386914863,
        "compression_ratio": 1.84,
        "end": 2860.7200000000003,
        "id": 712,
        "no_speech_prob": 0.03514423221349716,
        "seek": 284928,
        "start": 2856.6400000000003,
        "temperature": 0,
        "text": " it doesn't really, this is a little bit silly, what I'm getting myself worked up about, but, which line of",
        "tokens": [
          50732,
          309,
          1177,
          380,
          534,
          11,
          341,
          307,
          257,
          707,
          857,
          11774,
          11,
          437,
          286,
          478,
          1242,
          2059,
          2732,
          493,
          466,
          11,
          457,
          11,
          597,
          1622,
          295,
          50936
        ]
      },
      {
        "avg_logprob": -0.2518792386914863,
        "compression_ratio": 1.84,
        "end": 2867.44,
        "id": 713,
        "no_speech_prob": 0.03514423221349716,
        "seek": 284928,
        "start": 2860.7200000000003,
        "temperature": 0,
        "text": " code is part of which step, I don't know, but, step three, and, maybe, I'll name this params one, just to be,",
        "tokens": [
          50936,
          3089,
          307,
          644,
          295,
          597,
          1823,
          11,
          286,
          500,
          380,
          458,
          11,
          457,
          11,
          1823,
          1045,
          11,
          293,
          11,
          1310,
          11,
          286,
          603,
          1315,
          341,
          971,
          4070,
          472,
          11,
          445,
          281,
          312,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.2518792386914863,
        "compression_ratio": 1.84,
        "end": 2874.5600000000004,
        "id": 714,
        "no_speech_prob": 0.03514423221349716,
        "seek": 284928,
        "start": 2867.44,
        "temperature": 0,
        "text": " just for, I don't know, why, why not, to have them have different variable names, then, step three,",
        "tokens": [
          51272,
          445,
          337,
          11,
          286,
          500,
          380,
          458,
          11,
          983,
          11,
          983,
          406,
          11,
          281,
          362,
          552,
          362,
          819,
          7006,
          5288,
          11,
          550,
          11,
          1823,
          1045,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.27032798528671265,
        "compression_ratio": 1.4758620689655173,
        "end": 2885.7599999999998,
        "id": 715,
        "no_speech_prob": 0.007011557929217815,
        "seek": 287456,
        "start": 2875.52,
        "temperature": 0,
        "text": " which is params two, I want the status to be, and this is, you know, I'd have to, I think I know what it's",
        "tokens": [
          50412,
          597,
          307,
          971,
          4070,
          732,
          11,
          286,
          528,
          264,
          6558,
          281,
          312,
          11,
          293,
          341,
          307,
          11,
          291,
          458,
          11,
          286,
          1116,
          362,
          281,
          11,
          286,
          519,
          286,
          458,
          437,
          309,
          311,
          50924
        ]
      },
      {
        "avg_logprob": -0.27032798528671265,
        "compression_ratio": 1.4758620689655173,
        "end": 2897.68,
        "id": 716,
        "no_speech_prob": 0.007011557929217815,
        "seek": 287456,
        "start": 2885.7599999999998,
        "temperature": 0,
        "text": " supposed to be, but, behold, my beautiful tree, with angle, and then, I should use the string, the template",
        "tokens": [
          50924,
          3442,
          281,
          312,
          11,
          457,
          11,
          27234,
          11,
          452,
          2238,
          4230,
          11,
          365,
          5802,
          11,
          293,
          550,
          11,
          286,
          820,
          764,
          264,
          6798,
          11,
          264,
          12379,
          51520
        ]
      },
      {
        "avg_logprob": -0.2721891403198242,
        "compression_ratio": 1.4195804195804196,
        "end": 2912.16,
        "id": 717,
        "no_speech_prob": 0.06559785455465317,
        "seek": 289768,
        "start": 2897.68,
        "temperature": 0,
        "text": " literals again, degrees, and then, I need, ah, so, now, so, this, okay, let me look this up in the, in the",
        "tokens": [
          50364,
          2733,
          1124,
          797,
          11,
          5310,
          11,
          293,
          550,
          11,
          286,
          643,
          11,
          3716,
          11,
          370,
          11,
          586,
          11,
          370,
          11,
          341,
          11,
          1392,
          11,
          718,
          385,
          574,
          341,
          493,
          294,
          264,
          11,
          294,
          264,
          51088
        ]
      },
      {
        "avg_logprob": -0.2721891403198242,
        "compression_ratio": 1.4195804195804196,
        "end": 2923.44,
        "id": 718,
        "no_speech_prob": 0.06559785455465317,
        "seek": 289768,
        "start": 2912.16,
        "temperature": 0,
        "text": " Mastodon API docs, give me a second to find this, let's edit out me looking for it, API, V1, V1,",
        "tokens": [
          51088,
          376,
          525,
          378,
          266,
          9362,
          45623,
          11,
          976,
          385,
          257,
          1150,
          281,
          915,
          341,
          11,
          718,
          311,
          8129,
          484,
          385,
          1237,
          337,
          309,
          11,
          9362,
          11,
          691,
          16,
          11,
          691,
          16,
          11,
          51652
        ]
      },
      {
        "avg_logprob": -0.21392409006754556,
        "compression_ratio": 1.562043795620438,
        "end": 2926.64,
        "id": 719,
        "no_speech_prob": 0.00017400526849087328,
        "seek": 292344,
        "start": 2923.52,
        "temperature": 0,
        "text": " statuses, statuses,",
        "tokens": [
          50368,
          6558,
          279,
          11,
          6558,
          279,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.21392409006754556,
        "compression_ratio": 1.562043795620438,
        "end": 2932.4,
        "id": 720,
        "no_speech_prob": 0.00017400526849087328,
        "seek": 292344,
        "start": 2931.04,
        "temperature": 0,
        "text": " geez louise,",
        "tokens": [
          50744,
          46108,
          15185,
          908,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.21392409006754556,
        "compression_ratio": 1.562043795620438,
        "end": 2939.28,
        "id": 721,
        "no_speech_prob": 0.00017400526849087328,
        "seek": 292344,
        "start": 2935.28,
        "temperature": 0,
        "text": " there's got to be a better way to search on this, oh, it was all the way at the end,",
        "tokens": [
          50956,
          456,
          311,
          658,
          281,
          312,
          257,
          1101,
          636,
          281,
          3164,
          322,
          341,
          11,
          1954,
          11,
          309,
          390,
          439,
          264,
          636,
          412,
          264,
          917,
          11,
          51156
        ]
      },
      {
        "avg_logprob": -0.21392409006754556,
        "compression_ratio": 1.562043795620438,
        "end": 2952.4,
        "id": 722,
        "no_speech_prob": 0.00017400526849087328,
        "seek": 292344,
        "start": 2942.64,
        "temperature": 0,
        "text": " here it is, okay, I found it, this is the API, this is the path, statuses, for posting a status,",
        "tokens": [
          51324,
          510,
          309,
          307,
          11,
          1392,
          11,
          286,
          1352,
          309,
          11,
          341,
          307,
          264,
          9362,
          11,
          341,
          307,
          264,
          3100,
          11,
          6558,
          279,
          11,
          337,
          15978,
          257,
          6558,
          11,
          51812
        ]
      },
      {
        "avg_logprob": -0.2595291801120924,
        "compression_ratio": 1.7959183673469388,
        "end": 2957.2000000000003,
        "id": 723,
        "no_speech_prob": 0.006192742381244898,
        "seek": 295240,
        "start": 2952.4,
        "temperature": 0,
        "text": " and I, this is the text of the status, there are other things you could do here that I've talked about in previous",
        "tokens": [
          50364,
          293,
          286,
          11,
          341,
          307,
          264,
          2487,
          295,
          264,
          6558,
          11,
          456,
          366,
          661,
          721,
          291,
          727,
          360,
          510,
          300,
          286,
          600,
          2825,
          466,
          294,
          3894,
          50604
        ]
      },
      {
        "avg_logprob": -0.2595291801120924,
        "compression_ratio": 1.7959183673469388,
        "end": 2964.2400000000002,
        "id": 724,
        "no_speech_prob": 0.006192742381244898,
        "seek": 295240,
        "start": 2957.2000000000003,
        "temperature": 0,
        "text": " videos, but this is what I want, media IDs, now, notice this is an array, it's an array of media IDs, because a",
        "tokens": [
          50604,
          2145,
          11,
          457,
          341,
          307,
          437,
          286,
          528,
          11,
          3021,
          48212,
          11,
          586,
          11,
          3449,
          341,
          307,
          364,
          10225,
          11,
          309,
          311,
          364,
          10225,
          295,
          3021,
          48212,
          11,
          570,
          257,
          50956
        ]
      },
      {
        "avg_logprob": -0.2595291801120924,
        "compression_ratio": 1.7959183673469388,
        "end": 2969.2000000000003,
        "id": 725,
        "no_speech_prob": 0.006192742381244898,
        "seek": 295240,
        "start": 2964.2400000000002,
        "temperature": 0,
        "text": " particular status could have, and it says here, maximum four, more than one image associated with it, so, you",
        "tokens": [
          50956,
          1729,
          6558,
          727,
          362,
          11,
          293,
          309,
          1619,
          510,
          11,
          6674,
          1451,
          11,
          544,
          813,
          472,
          3256,
          6615,
          365,
          309,
          11,
          370,
          11,
          291,
          51204
        ]
      },
      {
        "avg_logprob": -0.2595291801120924,
        "compression_ratio": 1.7959183673469388,
        "end": 2974.48,
        "id": 726,
        "no_speech_prob": 0.006192742381244898,
        "seek": 295240,
        "start": 2969.2000000000003,
        "temperature": 0,
        "text": " can upload more than one image, so, that might be an exercise that you try to do after this video, but,",
        "tokens": [
          51204,
          393,
          6580,
          544,
          813,
          472,
          3256,
          11,
          370,
          11,
          300,
          1062,
          312,
          364,
          5380,
          300,
          291,
          853,
          281,
          360,
          934,
          341,
          960,
          11,
          457,
          11,
          51468
        ]
      },
      {
        "avg_logprob": -0.25372765280983667,
        "compression_ratio": 1.7172774869109948,
        "end": 2983.92,
        "id": 727,
        "no_speech_prob": 0.10520616918802261,
        "seek": 297448,
        "start": 2974.48,
        "temperature": 0,
        "text": " basically, now, I can say, comma, media underscore IDs, and I just have that one ID, so, I just put, I can",
        "tokens": [
          50364,
          1936,
          11,
          586,
          11,
          286,
          393,
          584,
          11,
          22117,
          11,
          3021,
          37556,
          48212,
          11,
          293,
          286,
          445,
          362,
          300,
          472,
          7348,
          11,
          370,
          11,
          286,
          445,
          829,
          11,
          286,
          393,
          50836
        ]
      },
      {
        "avg_logprob": -0.25372765280983667,
        "compression_ratio": 1.7172774869109948,
        "end": 2992.4,
        "id": 728,
        "no_speech_prob": 0.10520616918802261,
        "seek": 297448,
        "start": 2983.92,
        "temperature": 0,
        "text": " make an array and put it there, and then, this has to be statuses, params, and then, what I can do, is I can, and",
        "tokens": [
          50836,
          652,
          364,
          10225,
          293,
          829,
          309,
          456,
          11,
          293,
          550,
          11,
          341,
          575,
          281,
          312,
          6558,
          279,
          11,
          971,
          4070,
          11,
          293,
          550,
          11,
          437,
          286,
          393,
          360,
          11,
          307,
          286,
          393,
          11,
          293,
          51260
        ]
      },
      {
        "avg_logprob": -0.25372765280983667,
        "compression_ratio": 1.7172774869109948,
        "end": 3002.88,
        "id": 729,
        "no_speech_prob": 0.10520616918802261,
        "seek": 297448,
        "start": 2992.4,
        "temperature": 0,
        "text": " this is the response, and I can just now say, return response, so, if we could look at this all together, I",
        "tokens": [
          51260,
          341,
          307,
          264,
          4134,
          11,
          293,
          286,
          393,
          445,
          586,
          584,
          11,
          2736,
          4134,
          11,
          370,
          11,
          498,
          321,
          727,
          574,
          412,
          341,
          439,
          1214,
          11,
          286,
          51784
        ]
      },
      {
        "avg_logprob": -0.2887665598016036,
        "compression_ratio": 1.757936507936508,
        "end": 3009.2000000000003,
        "id": 730,
        "no_speech_prob": 0.08269302546977997,
        "seek": 300288,
        "start": 3002.96,
        "temperature": 0,
        "text": " think I have to make this, like, a tiny bit smaller for you to see it, can I fit it all in one nice place, look at",
        "tokens": [
          50368,
          519,
          286,
          362,
          281,
          652,
          341,
          11,
          411,
          11,
          257,
          5870,
          857,
          4356,
          337,
          291,
          281,
          536,
          309,
          11,
          393,
          286,
          3318,
          309,
          439,
          294,
          472,
          1481,
          1081,
          11,
          574,
          412,
          50680
        ]
      },
      {
        "avg_logprob": -0.2887665598016036,
        "compression_ratio": 1.757936507936508,
        "end": 3016.1600000000003,
        "id": 731,
        "no_speech_prob": 0.08269302546977997,
        "seek": 300288,
        "start": 3009.2000000000003,
        "temperature": 0,
        "text": " this, look how beautiful this is, it's almost like I've written this code in a language like Java or C that's, like,",
        "tokens": [
          50680,
          341,
          11,
          574,
          577,
          2238,
          341,
          307,
          11,
          309,
          311,
          1920,
          411,
          286,
          600,
          3720,
          341,
          3089,
          294,
          257,
          2856,
          411,
          10745,
          420,
          383,
          300,
          311,
          11,
          411,
          11,
          51028
        ]
      },
      {
        "avg_logprob": -0.2887665598016036,
        "compression_ratio": 1.757936507936508,
        "end": 3022.4,
        "id": 732,
        "no_speech_prob": 0.08269302546977997,
        "seek": 300288,
        "start": 3016.1600000000003,
        "temperature": 0,
        "text": " perfectly synchronous and linear and procedural, because what I'm saying is, await executing this command,",
        "tokens": [
          51028,
          6239,
          44743,
          293,
          8213,
          293,
          43951,
          11,
          570,
          437,
          286,
          478,
          1566,
          307,
          11,
          19670,
          32368,
          341,
          5622,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.2887665598016036,
        "compression_ratio": 1.757936507936508,
        "end": 3030.4,
        "id": 733,
        "no_speech_prob": 0.08269302546977997,
        "seek": 300288,
        "start": 3022.4,
        "temperature": 0,
        "text": " then, do some stuff, then, await uploading the media, then, do some other stuff, then, await posting the",
        "tokens": [
          51340,
          550,
          11,
          360,
          512,
          1507,
          11,
          550,
          11,
          19670,
          27301,
          264,
          3021,
          11,
          550,
          11,
          360,
          512,
          661,
          1507,
          11,
          550,
          11,
          19670,
          15978,
          264,
          51740
        ]
      },
      {
        "avg_logprob": -0.25901621631068045,
        "compression_ratio": 1.7540322580645162,
        "end": 3036.64,
        "id": 734,
        "no_speech_prob": 0.005139514338225126,
        "seek": 303040,
        "start": 3030.48,
        "temperature": 0,
        "text": " actual status, and when you're done, return, and guess what, if I now say, let me make this bigger again, whoops,",
        "tokens": [
          50368,
          3539,
          6558,
          11,
          293,
          562,
          291,
          434,
          1096,
          11,
          2736,
          11,
          293,
          2041,
          437,
          11,
          498,
          286,
          586,
          584,
          11,
          718,
          385,
          652,
          341,
          3801,
          797,
          11,
          567,
          3370,
          11,
          50676
        ]
      },
      {
        "avg_logprob": -0.25901621631068045,
        "compression_ratio": 1.7540322580645162,
        "end": 3044.88,
        "id": 735,
        "no_speech_prob": 0.005139514338225126,
        "seek": 303040,
        "start": 3036.64,
        "temperature": 0,
        "text": " if I say, toot, guess what, this toot function that I've written, remember when I said it natively returns a",
        "tokens": [
          50676,
          498,
          286,
          584,
          11,
          281,
          310,
          11,
          2041,
          437,
          11,
          341,
          281,
          310,
          2445,
          300,
          286,
          600,
          3720,
          11,
          1604,
          562,
          286,
          848,
          309,
          8470,
          356,
          11247,
          257,
          51088
        ]
      },
      {
        "avg_logprob": -0.25901621631068045,
        "compression_ratio": 1.7540322580645162,
        "end": 3051.84,
        "id": 736,
        "no_speech_prob": 0.005139514338225126,
        "seek": 303040,
        "start": 3044.88,
        "temperature": 0,
        "text": " promise, well, by the way, I said return right down here, so, this thing right there is the promise it's",
        "tokens": [
          51088,
          6228,
          11,
          731,
          11,
          538,
          264,
          636,
          11,
          286,
          848,
          2736,
          558,
          760,
          510,
          11,
          370,
          11,
          341,
          551,
          558,
          456,
          307,
          264,
          6228,
          309,
          311,
          51436
        ]
      },
      {
        "avg_logprob": -0.25901621631068045,
        "compression_ratio": 1.7540322580645162,
        "end": 3057.6,
        "id": 737,
        "no_speech_prob": 0.005139514338225126,
        "seek": 303040,
        "start": 3051.84,
        "temperature": 0,
        "text": " returning, and I actually might, I could configure my own object, which could be kind of interesting, like,",
        "tokens": [
          51436,
          12678,
          11,
          293,
          286,
          767,
          1062,
          11,
          286,
          727,
          22162,
          452,
          1065,
          2657,
          11,
          597,
          727,
          312,
          733,
          295,
          1880,
          11,
          411,
          11,
          51724
        ]
      },
      {
        "avg_logprob": -0.275527510532113,
        "compression_ratio": 1.85,
        "end": 3073.12,
        "id": 738,
        "no_speech_prob": 0.0016229598550125957,
        "seek": 305760,
        "start": 3057.68,
        "temperature": 0,
        "text": " what if I said, return, I could just say something like, success, true, and status, behold my beautiful tree,",
        "tokens": [
          50368,
          437,
          498,
          286,
          848,
          11,
          2736,
          11,
          286,
          727,
          445,
          584,
          746,
          411,
          11,
          2245,
          11,
          2074,
          11,
          293,
          6558,
          11,
          27234,
          452,
          2238,
          4230,
          11,
          51140
        ]
      },
      {
        "avg_logprob": -0.275527510532113,
        "compression_ratio": 1.85,
        "end": 3078.16,
        "id": 739,
        "no_speech_prob": 0.0016229598550125957,
        "seek": 305760,
        "start": 3073.12,
        "temperature": 0,
        "text": " whatever, and I could just say angle, whatever, I could put, like, angle, and then that angle there, so I could",
        "tokens": [
          51140,
          2035,
          11,
          293,
          286,
          727,
          445,
          584,
          5802,
          11,
          2035,
          11,
          286,
          727,
          829,
          11,
          411,
          11,
          5802,
          11,
          293,
          550,
          300,
          5802,
          456,
          11,
          370,
          286,
          727,
          51392
        ]
      },
      {
        "avg_logprob": -0.275527510532113,
        "compression_ratio": 1.85,
        "end": 3083.52,
        "id": 740,
        "no_speech_prob": 0.0016229598550125957,
        "seek": 305760,
        "start": 3078.16,
        "temperature": 0,
        "text": " actually configure an object, and I could pull stuff out of the response there, I could return that, and then I",
        "tokens": [
          51392,
          767,
          22162,
          364,
          2657,
          11,
          293,
          286,
          727,
          2235,
          1507,
          484,
          295,
          264,
          4134,
          456,
          11,
          286,
          727,
          2736,
          300,
          11,
          293,
          550,
          286,
          51660
        ]
      },
      {
        "avg_logprob": -0.27157673239707947,
        "compression_ratio": 1.5955882352941178,
        "end": 3094.72,
        "id": 741,
        "no_speech_prob": 0.12591856718063354,
        "seek": 308352,
        "start": 3083.6,
        "temperature": 0,
        "text": " would say, then, then response, I can't spell today, I mean, I can never spell, console.log, that response,",
        "tokens": [
          50368,
          576,
          584,
          11,
          550,
          11,
          550,
          4134,
          11,
          286,
          393,
          380,
          9827,
          965,
          11,
          286,
          914,
          11,
          286,
          393,
          1128,
          9827,
          11,
          11076,
          13,
          4987,
          11,
          300,
          4134,
          11,
          50924
        ]
      },
      {
        "avg_logprob": -0.27157673239707947,
        "compression_ratio": 1.5955882352941178,
        "end": 3106.88,
        "id": 742,
        "no_speech_prob": 0.12591856718063354,
        "seek": 308352,
        "start": 3094.72,
        "temperature": 0,
        "text": " catch, any error, console.error, error, and this needs a period here, and I need to hit save, and something's",
        "tokens": [
          50924,
          3745,
          11,
          604,
          6713,
          11,
          11076,
          13,
          260,
          2874,
          11,
          6713,
          11,
          293,
          341,
          2203,
          257,
          2896,
          510,
          11,
          293,
          286,
          643,
          281,
          2045,
          3155,
          11,
          293,
          746,
          311,
          51532
        ]
      },
      {
        "avg_logprob": -0.34190852400185406,
        "compression_ratio": 1.744,
        "end": 3120.4,
        "id": 743,
        "no_speech_prob": 0.5888427495956421,
        "seek": 310688,
        "start": 3106.96,
        "temperature": 0,
        "text": " wrong, too many, not enough, too many dots, toot.then response, why can't I see this, oh, there's too many dots,",
        "tokens": [
          50368,
          2085,
          11,
          886,
          867,
          11,
          406,
          1547,
          11,
          886,
          867,
          15026,
          11,
          281,
          310,
          13,
          19096,
          4134,
          11,
          983,
          393,
          380,
          286,
          536,
          341,
          11,
          1954,
          11,
          456,
          311,
          886,
          867,
          15026,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.34190852400185406,
        "compression_ratio": 1.744,
        "end": 3131.52,
        "id": 744,
        "no_speech_prob": 0.5888427495956421,
        "seek": 310688,
        "start": 3120.4,
        "temperature": 0,
        "text": " too many dots, Mozart, too many dots, still too many dots, toot, then, oh my god, what's happening to me,",
        "tokens": [
          51040,
          886,
          867,
          15026,
          11,
          42653,
          11,
          886,
          867,
          15026,
          11,
          920,
          886,
          867,
          15026,
          11,
          281,
          310,
          11,
          550,
          11,
          1954,
          452,
          3044,
          11,
          437,
          311,
          2737,
          281,
          385,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.292576298569188,
        "compression_ratio": 1.6964285714285714,
        "end": 3139.04,
        "id": 745,
        "no_speech_prob": 0.23090918362140656,
        "seek": 313152,
        "start": 3132.48,
        "temperature": 0,
        "text": " toot, then, response, console.log, response, is it just not auto-formatting it?",
        "tokens": [
          50412,
          281,
          310,
          11,
          550,
          11,
          4134,
          11,
          11076,
          13,
          4987,
          11,
          4134,
          11,
          307,
          309,
          445,
          406,
          8399,
          12,
          837,
          267,
          783,
          309,
          30,
          50740
        ]
      },
      {
        "avg_logprob": -0.292576298569188,
        "compression_ratio": 1.6964285714285714,
        "end": 3150.56,
        "id": 746,
        "no_speech_prob": 0.23090918362140656,
        "seek": 313152,
        "start": 3142.4,
        "temperature": 0,
        "text": " No, it's auto-formatting, toot, then, response, console.log, response, dot, catch, oh, may I need a semicolon?",
        "tokens": [
          50908,
          883,
          11,
          309,
          311,
          8399,
          12,
          837,
          267,
          783,
          11,
          281,
          310,
          11,
          550,
          11,
          4134,
          11,
          11076,
          13,
          4987,
          11,
          4134,
          11,
          5893,
          11,
          3745,
          11,
          1954,
          11,
          815,
          286,
          643,
          257,
          27515,
          38780,
          30,
          51316
        ]
      },
      {
        "avg_logprob": -0.25431395310621996,
        "compression_ratio": 1.4285714285714286,
        "end": 3158.64,
        "id": 747,
        "no_speech_prob": 0.06008470803499222,
        "seek": 315056,
        "start": 3150.64,
        "temperature": 0,
        "text": " No, then, catch, I have to look at the chat, yeah, I know I should wrap things in a,",
        "tokens": [
          50368,
          883,
          11,
          550,
          11,
          3745,
          11,
          286,
          362,
          281,
          574,
          412,
          264,
          5081,
          11,
          1338,
          11,
          286,
          458,
          286,
          820,
          7019,
          721,
          294,
          257,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.25431395310621996,
        "compression_ratio": 1.4285714285714286,
        "end": 3169.92,
        "id": 748,
        "no_speech_prob": 0.06008470803499222,
        "seek": 315056,
        "start": 3167.04,
        "temperature": 0,
        "text": " I can't get the password on this computer to work,",
        "tokens": [
          51188,
          286,
          393,
          380,
          483,
          264,
          11524,
          322,
          341,
          3820,
          281,
          589,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.25431395310621996,
        "compression_ratio": 1.4285714285714286,
        "end": 3177.52,
        "id": 749,
        "no_speech_prob": 0.06008470803499222,
        "seek": 315056,
        "start": 3172.7999999999997,
        "temperature": 0,
        "text": " the dot goes on the next line, oh, that's what it is, oops, yes.",
        "tokens": [
          51476,
          264,
          5893,
          1709,
          322,
          264,
          958,
          1622,
          11,
          1954,
          11,
          300,
          311,
          437,
          309,
          307,
          11,
          34166,
          11,
          2086,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2595478375752767,
        "compression_ratio": 1.7103174603174602,
        "end": 3186.32,
        "id": 750,
        "no_speech_prob": 0.0006166229140944779,
        "seek": 317752,
        "start": 3177.92,
        "temperature": 0,
        "text": " Okay, it's not too many, it was too many dots, but I fixed that, the issue is the dot goes on the next line,",
        "tokens": [
          50384,
          1033,
          11,
          309,
          311,
          406,
          886,
          867,
          11,
          309,
          390,
          886,
          867,
          15026,
          11,
          457,
          286,
          6806,
          300,
          11,
          264,
          2734,
          307,
          264,
          5893,
          1709,
          322,
          264,
          958,
          1622,
          11,
          50804
        ]
      },
      {
        "avg_logprob": -0.2595478375752767,
        "compression_ratio": 1.7103174603174602,
        "end": 3190.72,
        "id": 751,
        "no_speech_prob": 0.0006166229140944779,
        "seek": 317752,
        "start": 3186.32,
        "temperature": 0,
        "text": " that's the convention, that's what it's looking for, there, now it's formatted the way I want it to be.",
        "tokens": [
          50804,
          300,
          311,
          264,
          10286,
          11,
          300,
          311,
          437,
          309,
          311,
          1237,
          337,
          11,
          456,
          11,
          586,
          309,
          311,
          1254,
          32509,
          264,
          636,
          286,
          528,
          309,
          281,
          312,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2595478375752767,
        "compression_ratio": 1.7103174603174602,
        "end": 3198.8,
        "id": 752,
        "no_speech_prob": 0.0006166229140944779,
        "seek": 317752,
        "start": 3190.72,
        "temperature": 0,
        "text": " So, I still have to engage, oh, boy, with this idea of a promise, but I can basically wrap that all into this",
        "tokens": [
          51024,
          407,
          11,
          286,
          920,
          362,
          281,
          4683,
          11,
          1954,
          11,
          3237,
          11,
          365,
          341,
          1558,
          295,
          257,
          6228,
          11,
          457,
          286,
          393,
          1936,
          7019,
          300,
          439,
          666,
          341,
          51428
        ]
      },
      {
        "avg_logprob": -0.2595478375752767,
        "compression_ratio": 1.7103174603174602,
        "end": 3203.6,
        "id": 753,
        "no_speech_prob": 0.0006166229140944779,
        "seek": 317752,
        "start": 3198.8,
        "temperature": 0,
        "text": " one asynchronous function, and people in the chat are telling me I can actually, I don't need to do the then",
        "tokens": [
          51428,
          472,
          49174,
          2445,
          11,
          293,
          561,
          294,
          264,
          5081,
          366,
          3585,
          385,
          286,
          393,
          767,
          11,
          286,
          500,
          380,
          643,
          281,
          360,
          264,
          550,
          51668
        ]
      },
      {
        "avg_logprob": -0.2564814616057832,
        "compression_ratio": 1.8078602620087336,
        "end": 3209.2799999999997,
        "id": 754,
        "no_speech_prob": 0.006488158833235502,
        "seek": 320360,
        "start": 3203.68,
        "temperature": 0,
        "text": " catch in this way, because I could actually put a try and catch inside of here, but, eh, one step at a time,",
        "tokens": [
          50368,
          3745,
          294,
          341,
          636,
          11,
          570,
          286,
          727,
          767,
          829,
          257,
          853,
          293,
          3745,
          1854,
          295,
          510,
          11,
          457,
          11,
          7670,
          11,
          472,
          1823,
          412,
          257,
          565,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.2564814616057832,
        "compression_ratio": 1.8078602620087336,
        "end": 3218.08,
        "id": 755,
        "no_speech_prob": 0.006488158833235502,
        "seek": 320360,
        "start": 3209.2799999999997,
        "temperature": 0,
        "text": " I think I might be done, all right, let's see, let's see what happens, okay, no, response,",
        "tokens": [
          50648,
          286,
          519,
          286,
          1062,
          312,
          1096,
          11,
          439,
          558,
          11,
          718,
          311,
          536,
          11,
          718,
          311,
          536,
          437,
          2314,
          11,
          1392,
          11,
          572,
          11,
          4134,
          11,
          51088
        ]
      },
      {
        "avg_logprob": -0.2564814616057832,
        "compression_ratio": 1.8078602620087336,
        "end": 3226.56,
        "id": 756,
        "no_speech_prob": 0.006488158833235502,
        "seek": 320360,
        "start": 3218.7999999999997,
        "temperature": 0,
        "text": " oh, wait, oh, so, I have also reused, so, I should call this response one, response two, maybe there's a",
        "tokens": [
          51124,
          1954,
          11,
          1699,
          11,
          1954,
          11,
          370,
          11,
          286,
          362,
          611,
          319,
          4717,
          11,
          370,
          11,
          286,
          820,
          818,
          341,
          4134,
          472,
          11,
          4134,
          732,
          11,
          1310,
          456,
          311,
          257,
          51512
        ]
      },
      {
        "avg_logprob": -0.2564814616057832,
        "compression_ratio": 1.8078602620087336,
        "end": 3232.16,
        "id": 757,
        "no_speech_prob": 0.006488158833235502,
        "seek": 320360,
        "start": 3226.56,
        "temperature": 0,
        "text": " more thoughtful way of doing this, response three, I mean, I didn't actually use the response, but, whatever,",
        "tokens": [
          51512,
          544,
          21566,
          636,
          295,
          884,
          341,
          11,
          4134,
          1045,
          11,
          286,
          914,
          11,
          286,
          994,
          380,
          767,
          764,
          264,
          4134,
          11,
          457,
          11,
          2035,
          11,
          51792
        ]
      },
      {
        "avg_logprob": -0.2627490445187217,
        "compression_ratio": 1.6266666666666667,
        "end": 3240.88,
        "id": 758,
        "no_speech_prob": 0.00008614608668722212,
        "seek": 323360,
        "start": 3234.56,
        "temperature": 0,
        "text": " and there we go, start the bot, make the image, the angle's 72, finished, params is not defined,",
        "tokens": [
          50412,
          293,
          456,
          321,
          352,
          11,
          722,
          264,
          10592,
          11,
          652,
          264,
          3256,
          11,
          264,
          5802,
          311,
          18731,
          11,
          4335,
          11,
          971,
          4070,
          307,
          406,
          7642,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.2627490445187217,
        "compression_ratio": 1.6266666666666667,
        "end": 3251.52,
        "id": 759,
        "no_speech_prob": 0.00008614608668722212,
        "seek": 323360,
        "start": 3240.88,
        "temperature": 0,
        "text": " oh, I was so close, I was so close, params one, params two, params two here, and I think params one there, all right,",
        "tokens": [
          50728,
          1954,
          11,
          286,
          390,
          370,
          1998,
          11,
          286,
          390,
          370,
          1998,
          11,
          971,
          4070,
          472,
          11,
          971,
          4070,
          732,
          11,
          971,
          4070,
          732,
          510,
          11,
          293,
          286,
          519,
          971,
          4070,
          472,
          456,
          11,
          439,
          558,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.2627490445187217,
        "compression_ratio": 1.6266666666666667,
        "end": 3259.44,
        "id": 760,
        "no_speech_prob": 0.00008614608668722212,
        "seek": 323360,
        "start": 3258.08,
        "temperature": 0,
        "text": " I'm feeling pretty confident,",
        "tokens": [
          51588,
          286,
          478,
          2633,
          1238,
          6679,
          11,
          51656
        ]
      },
      {
        "avg_logprob": -0.43702902542917355,
        "compression_ratio": 1.6796116504854368,
        "end": 3263.76,
        "id": 761,
        "no_speech_prob": 0.0009547204826958477,
        "seek": 325944,
        "start": 3259.76,
        "temperature": 0,
        "text": " ah, success, angle is 56, flash finished,",
        "tokens": [
          50380,
          3716,
          11,
          2245,
          11,
          5802,
          307,
          19687,
          11,
          7319,
          4335,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.43702902542917355,
        "compression_ratio": 1.6796116504854368,
        "end": 3274.16,
        "id": 762,
        "no_speech_prob": 0.0009547204826958477,
        "seek": 325944,
        "start": 3267.12,
        "temperature": 0,
        "text": " that's a little weird, but, let's see here, let's go to the bot, look, behold my beautiful tree with angle 56",
        "tokens": [
          50748,
          300,
          311,
          257,
          707,
          3657,
          11,
          457,
          11,
          718,
          311,
          536,
          510,
          11,
          718,
          311,
          352,
          281,
          264,
          10592,
          11,
          574,
          11,
          27234,
          452,
          2238,
          4230,
          365,
          5802,
          19687,
          51100
        ]
      },
      {
        "avg_logprob": -0.43702902542917355,
        "compression_ratio": 1.6796116504854368,
        "end": 3280.4,
        "id": 763,
        "no_speech_prob": 0.0009547204826958477,
        "seek": 325944,
        "start": 3274.16,
        "temperature": 0,
        "text": " finished degrees, okay, so, there's a little bit of awkwardness there, in that the standard out is just",
        "tokens": [
          51100,
          4335,
          5310,
          11,
          1392,
          11,
          370,
          11,
          456,
          311,
          257,
          707,
          857,
          295,
          11411,
          1287,
          456,
          11,
          294,
          300,
          264,
          3832,
          484,
          307,
          445,
          51412
        ]
      },
      {
        "avg_logprob": -0.43702902542917355,
        "compression_ratio": 1.6796116504854368,
        "end": 3286.7200000000003,
        "id": 764,
        "no_speech_prob": 0.0009547204826958477,
        "seek": 325944,
        "start": 3280.4,
        "temperature": 0,
        "text": " always giving me the word finished, so, because I would like this to be a little bit more,",
        "tokens": [
          51412,
          1009,
          2902,
          385,
          264,
          1349,
          4335,
          11,
          370,
          11,
          570,
          286,
          576,
          411,
          341,
          281,
          312,
          257,
          707,
          857,
          544,
          11,
          51728
        ]
      },
      {
        "avg_logprob": -0.21780625308852597,
        "compression_ratio": 1.6296296296296295,
        "end": 3293.8399999999997,
        "id": 765,
        "no_speech_prob": 0.000008939676263253205,
        "seek": 328672,
        "start": 3286.72,
        "temperature": 0,
        "text": " so, because I would like this to work without that, I think I've guessed what I'm going to have to do is,",
        "tokens": [
          50364,
          370,
          11,
          570,
          286,
          576,
          411,
          341,
          281,
          589,
          1553,
          300,
          11,
          286,
          519,
          286,
          600,
          21852,
          437,
          286,
          478,
          516,
          281,
          362,
          281,
          360,
          307,
          11,
          50720
        ]
      },
      {
        "avg_logprob": -0.21780625308852597,
        "compression_ratio": 1.6296296296296295,
        "end": 3302.8799999999997,
        "id": 766,
        "no_speech_prob": 0.000008939676263253205,
        "seek": 328672,
        "start": 3293.8399999999997,
        "temperature": 0,
        "text": " is that just something that happens, like, with processing Java, because I didn't write finished",
        "tokens": [
          50720,
          307,
          300,
          445,
          746,
          300,
          2314,
          11,
          411,
          11,
          365,
          9007,
          10745,
          11,
          570,
          286,
          994,
          380,
          2464,
          4335,
          51172
        ]
      },
      {
        "avg_logprob": -0.21780625308852597,
        "compression_ratio": 1.6296296296296295,
        "end": 3310.8799999999997,
        "id": 767,
        "no_speech_prob": 0.000008939676263253205,
        "seek": 328672,
        "start": 3302.8799999999997,
        "temperature": 0,
        "text": " anywhere in here, right, that's not a print line I put in here, so, I think what I could do is, when that",
        "tokens": [
          51172,
          4992,
          294,
          510,
          11,
          558,
          11,
          300,
          311,
          406,
          257,
          4482,
          1622,
          286,
          829,
          294,
          510,
          11,
          370,
          11,
          286,
          519,
          437,
          286,
          727,
          360,
          307,
          11,
          562,
          300,
          51572
        ]
      },
      {
        "avg_logprob": -0.20561686857247058,
        "compression_ratio": 1.8493975903614457,
        "end": 3320.1600000000003,
        "id": 768,
        "no_speech_prob": 0.004007276147603989,
        "seek": 331088,
        "start": 3310.88,
        "temperature": 0,
        "text": " comes, the standard out comes, I could say, response, I mean, I could just do a substring, I could do a regular",
        "tokens": [
          50364,
          1487,
          11,
          264,
          3832,
          484,
          1487,
          11,
          286,
          727,
          584,
          11,
          4134,
          11,
          286,
          914,
          11,
          286,
          727,
          445,
          360,
          257,
          4594,
          2937,
          11,
          286,
          727,
          360,
          257,
          3890,
          50828
        ]
      },
      {
        "avg_logprob": -0.20561686857247058,
        "compression_ratio": 1.8493975903614457,
        "end": 3329.76,
        "id": 769,
        "no_speech_prob": 0.004007276147603989,
        "seek": 331088,
        "start": 3320.1600000000003,
        "temperature": 0,
        "text": " expression, so many things, so many things I could do, why don't I split it, out equals response,",
        "tokens": [
          50828,
          6114,
          11,
          370,
          867,
          721,
          11,
          370,
          867,
          721,
          286,
          727,
          360,
          11,
          983,
          500,
          380,
          286,
          7472,
          309,
          11,
          484,
          6915,
          4134,
          11,
          51308
        ]
      },
      {
        "avg_logprob": -0.20561686857247058,
        "compression_ratio": 1.8493975903614457,
        "end": 3337.76,
        "id": 770,
        "no_speech_prob": 0.004007276147603989,
        "seek": 331088,
        "start": 3330.8,
        "temperature": 0,
        "text": " response standard out split, and I could just split it by the line break, right, because finished",
        "tokens": [
          51360,
          4134,
          3832,
          484,
          7472,
          11,
          293,
          286,
          727,
          445,
          7472,
          309,
          538,
          264,
          1622,
          1821,
          11,
          558,
          11,
          570,
          4335,
          51708
        ]
      },
      {
        "avg_logprob": -0.24313393345585577,
        "compression_ratio": 1.7641921397379912,
        "end": 3345.28,
        "id": 771,
        "no_speech_prob": 0.0013044781517237425,
        "seek": 333776,
        "start": 3337.76,
        "temperature": 0,
        "text": " comes after the line break, and then, and then I could just take the first one, so, this split is a",
        "tokens": [
          50364,
          1487,
          934,
          264,
          1622,
          1821,
          11,
          293,
          550,
          11,
          293,
          550,
          286,
          727,
          445,
          747,
          264,
          700,
          472,
          11,
          370,
          11,
          341,
          7472,
          307,
          257,
          50740
        ]
      },
      {
        "avg_logprob": -0.24313393345585577,
        "compression_ratio": 1.7641921397379912,
        "end": 3349.5200000000004,
        "id": 772,
        "no_speech_prob": 0.0013044781517237425,
        "seek": 333776,
        "start": 3345.28,
        "temperature": 0,
        "text": " function that takes a string and splits it up into chunks based on a delimiter, and you can get really",
        "tokens": [
          50740,
          2445,
          300,
          2516,
          257,
          6798,
          293,
          37741,
          309,
          493,
          666,
          24004,
          2361,
          322,
          257,
          1103,
          332,
          1681,
          11,
          293,
          291,
          393,
          483,
          534,
          50952
        ]
      },
      {
        "avg_logprob": -0.24313393345585577,
        "compression_ratio": 1.7641921397379912,
        "end": 3356.8,
        "id": 773,
        "no_speech_prob": 0.0013044781517237425,
        "seek": 333776,
        "start": 3349.5200000000004,
        "temperature": 0,
        "text": " fancy with that, but I think, and then this should just be out, without the cap locked, I mean, I should",
        "tokens": [
          50952,
          10247,
          365,
          300,
          11,
          457,
          286,
          519,
          11,
          293,
          550,
          341,
          820,
          445,
          312,
          484,
          11,
          1553,
          264,
          1410,
          9376,
          11,
          286,
          914,
          11,
          286,
          820,
          51316
        ]
      },
      {
        "avg_logprob": -0.24313393345585577,
        "compression_ratio": 1.7641921397379912,
        "end": 3366.4,
        "id": 774,
        "no_speech_prob": 0.0013044781517237425,
        "seek": 333776,
        "start": 3356.8,
        "temperature": 0,
        "text": " really test this, so, let's look, is that visible on the stream, that little bit of spittle just",
        "tokens": [
          51316,
          534,
          1500,
          341,
          11,
          370,
          11,
          718,
          311,
          574,
          11,
          307,
          300,
          8974,
          322,
          264,
          4309,
          11,
          300,
          707,
          857,
          295,
          637,
          703,
          445,
          51796
        ]
      },
      {
        "avg_logprob": -0.22158145904541016,
        "compression_ratio": 1.58,
        "end": 3375.6800000000003,
        "id": 775,
        "no_speech_prob": 0.0008693645941093564,
        "seek": 336640,
        "start": 3366.4,
        "temperature": 0,
        "text": " projected out of my mouth, I think I over excited, we'll edit that part out, perhaps, I mean, I really should",
        "tokens": [
          50364,
          26231,
          484,
          295,
          452,
          4525,
          11,
          286,
          519,
          286,
          670,
          2919,
          11,
          321,
          603,
          8129,
          300,
          644,
          484,
          11,
          4317,
          11,
          286,
          914,
          11,
          286,
          534,
          820,
          50828
        ]
      },
      {
        "avg_logprob": -0.22158145904541016,
        "compression_ratio": 1.58,
        "end": 3380.96,
        "id": 776,
        "no_speech_prob": 0.0008693645941093564,
        "seek": 336640,
        "start": 3375.6800000000003,
        "temperature": 0,
        "text": " probably test this, but I'm going to have to just rely on the fact that I think I wrote that code correctly,",
        "tokens": [
          50828,
          1391,
          1500,
          341,
          11,
          457,
          286,
          478,
          516,
          281,
          362,
          281,
          445,
          10687,
          322,
          264,
          1186,
          300,
          286,
          519,
          286,
          4114,
          300,
          3089,
          8944,
          11,
          51092
        ]
      },
      {
        "avg_logprob": -0.22158145904541016,
        "compression_ratio": 1.58,
        "end": 3388.96,
        "id": 777,
        "no_speech_prob": 0.0008693645941093564,
        "seek": 336640,
        "start": 3380.96,
        "temperature": 0,
        "text": " that's my way of testing it, let's run this one more time, undefined, true, angle 55, what's that",
        "tokens": [
          51092,
          300,
          311,
          452,
          636,
          295,
          4997,
          309,
          11,
          718,
          311,
          1190,
          341,
          472,
          544,
          565,
          11,
          674,
          5666,
          2001,
          11,
          2074,
          11,
          5802,
          12330,
          11,
          437,
          311,
          300,
          51492
        ]
      },
      {
        "avg_logprob": -0.24954374486749822,
        "compression_ratio": 1.5037593984962405,
        "end": 3401.04,
        "id": 778,
        "no_speech_prob": 0.048136305063962936,
        "seek": 338896,
        "start": 3389.04,
        "temperature": 0,
        "text": " undefined there, I like seeing that, oh, there we go, behold my beautiful tree with angle 55 degrees,",
        "tokens": [
          50368,
          674,
          5666,
          2001,
          456,
          11,
          286,
          411,
          2577,
          300,
          11,
          1954,
          11,
          456,
          321,
          352,
          11,
          27234,
          452,
          2238,
          4230,
          365,
          5802,
          12330,
          5310,
          11,
          50968
        ]
      },
      {
        "avg_logprob": -0.24954374486749822,
        "compression_ratio": 1.5037593984962405,
        "end": 3411.04,
        "id": 779,
        "no_speech_prob": 0.048136305063962936,
        "seek": 338896,
        "start": 3403.12,
        "temperature": 0,
        "text": " what was undefined, what did I console log in an undefined way, console log response standard out,",
        "tokens": [
          51072,
          437,
          390,
          674,
          5666,
          2001,
          11,
          437,
          630,
          286,
          11076,
          3565,
          294,
          364,
          674,
          5666,
          2001,
          636,
          11,
          11076,
          3565,
          4134,
          3832,
          484,
          11,
          51468
        ]
      },
      {
        "avg_logprob": -0.29055974181269256,
        "compression_ratio": 1.4620689655172414,
        "end": 3422.56,
        "id": 780,
        "no_speech_prob": 0.014503241516649723,
        "seek": 341104,
        "start": 3412,
        "temperature": 0,
        "text": " is that it, no, no, that's 10 finished, wait, if it was 10, why did this become 55, I'm so confused,",
        "tokens": [
          50412,
          307,
          300,
          309,
          11,
          572,
          11,
          572,
          11,
          300,
          311,
          1266,
          4335,
          11,
          1699,
          11,
          498,
          309,
          390,
          1266,
          11,
          983,
          630,
          341,
          1813,
          12330,
          11,
          286,
          478,
          370,
          9019,
          11,
          50940
        ]
      },
      {
        "avg_logprob": -0.29055974181269256,
        "compression_ratio": 1.4620689655172414,
        "end": 3434.88,
        "id": 781,
        "no_speech_prob": 0.014503241516649723,
        "seek": 341104,
        "start": 3422.56,
        "temperature": 0,
        "text": " let's be a little more methodical here, oh, because, oh, what am I looking at, oh, I did, ah, it does it twice,",
        "tokens": [
          50940,
          718,
          311,
          312,
          257,
          707,
          544,
          3170,
          804,
          510,
          11,
          1954,
          11,
          570,
          11,
          1954,
          11,
          437,
          669,
          286,
          1237,
          412,
          11,
          1954,
          11,
          286,
          630,
          11,
          3716,
          11,
          309,
          775,
          309,
          6091,
          11,
          51556
        ]
      },
      {
        "avg_logprob": -0.2994888917899426,
        "compression_ratio": 1.6538461538461537,
        "end": 3441.6,
        "id": 782,
        "no_speech_prob": 0.05665015056729317,
        "seek": 343488,
        "start": 3434.96,
        "temperature": 0,
        "text": " I think I have it happening twice, let's take that out, apologies, everybody, this thing is happening twice",
        "tokens": [
          50368,
          286,
          519,
          286,
          362,
          309,
          2737,
          6091,
          11,
          718,
          311,
          747,
          300,
          484,
          11,
          34929,
          11,
          2201,
          11,
          341,
          551,
          307,
          2737,
          6091,
          50700
        ]
      },
      {
        "avg_logprob": -0.2994888917899426,
        "compression_ratio": 1.6538461538461537,
        "end": 3446.6400000000003,
        "id": 783,
        "no_speech_prob": 0.05665015056729317,
        "seek": 343488,
        "start": 3441.6,
        "temperature": 0,
        "text": " because I had the old code in there, I mean, I'm just going to delete that, throw caution to the wind,",
        "tokens": [
          50700,
          570,
          286,
          632,
          264,
          1331,
          3089,
          294,
          456,
          11,
          286,
          914,
          11,
          286,
          478,
          445,
          516,
          281,
          12097,
          300,
          11,
          3507,
          23585,
          281,
          264,
          2468,
          11,
          50952
        ]
      },
      {
        "avg_logprob": -0.2994888917899426,
        "compression_ratio": 1.6538461538461537,
        "end": 3454.88,
        "id": 784,
        "no_speech_prob": 0.05665015056729317,
        "seek": 343488,
        "start": 3446.6400000000003,
        "temperature": 0,
        "text": " what a little mess here, okay, that's weird that it did that twice, I'm so confused, okay,",
        "tokens": [
          50952,
          437,
          257,
          707,
          2082,
          510,
          11,
          1392,
          11,
          300,
          311,
          3657,
          300,
          309,
          630,
          300,
          6091,
          11,
          286,
          478,
          370,
          9019,
          11,
          1392,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.3098963152977728,
        "compression_ratio": 1.6,
        "end": 3471.52,
        "id": 785,
        "no_speech_prob": 0.00036258858744986355,
        "seek": 345488,
        "start": 3455.6,
        "temperature": 0,
        "text": " angle 74, it just did it once, there we go, okay, one more thing that I need to do, just so this becomes a true bot",
        "tokens": [
          50400,
          5802,
          28868,
          11,
          309,
          445,
          630,
          309,
          1564,
          11,
          456,
          321,
          352,
          11,
          1392,
          11,
          472,
          544,
          551,
          300,
          286,
          643,
          281,
          360,
          11,
          445,
          370,
          341,
          3643,
          257,
          2074,
          10592,
          51196
        ]
      },
      {
        "avg_logprob": -0.3098963152977728,
        "compression_ratio": 1.6,
        "end": 3481.44,
        "id": 786,
        "no_speech_prob": 0.00036258858744986355,
        "seek": 345488,
        "start": 3471.52,
        "temperature": 0,
        "text": " is what I want to do is I want to say set interval and have it do this thing that it just did there,",
        "tokens": [
          51196,
          307,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          992,
          15035,
          293,
          362,
          309,
          360,
          341,
          551,
          300,
          309,
          445,
          630,
          456,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.24258585726277213,
        "compression_ratio": 1.65625,
        "end": 3489.76,
        "id": 787,
        "no_speech_prob": 0.006903744302690029,
        "seek": 348144,
        "start": 3482.4,
        "temperature": 0,
        "text": " every, well, let's have it do it every 10 seconds right now, I don't want it to do it every 10 seconds,",
        "tokens": [
          50412,
          633,
          11,
          731,
          11,
          718,
          311,
          362,
          309,
          360,
          309,
          633,
          1266,
          3949,
          558,
          586,
          11,
          286,
          500,
          380,
          528,
          309,
          281,
          360,
          309,
          633,
          1266,
          3949,
          11,
          50780
        ]
      },
      {
        "avg_logprob": -0.24258585726277213,
        "compression_ratio": 1.65625,
        "end": 3498.8,
        "id": 788,
        "no_speech_prob": 0.006903744302690029,
        "seek": 348144,
        "start": 3489.76,
        "temperature": 0,
        "text": " but just to, boy, I guess there's another, oh, another parentheses there, there we go, no, this is so hard,",
        "tokens": [
          50780,
          457,
          445,
          281,
          11,
          3237,
          11,
          286,
          2041,
          456,
          311,
          1071,
          11,
          1954,
          11,
          1071,
          34153,
          456,
          11,
          456,
          321,
          352,
          11,
          572,
          11,
          341,
          307,
          370,
          1152,
          11,
          51232
        ]
      },
      {
        "avg_logprob": -0.24258585726277213,
        "compression_ratio": 1.65625,
        "end": 3507.12,
        "id": 789,
        "no_speech_prob": 0.006903744302690029,
        "seek": 348144,
        "start": 3498.8,
        "temperature": 0,
        "text": " maybe I should just write a separate function, okay, set interval, then I put the function, which is this,",
        "tokens": [
          51232,
          1310,
          286,
          820,
          445,
          2464,
          257,
          4994,
          2445,
          11,
          1392,
          11,
          992,
          15035,
          11,
          550,
          286,
          829,
          264,
          2445,
          11,
          597,
          307,
          341,
          11,
          51648
        ]
      },
      {
        "avg_logprob": -0.26189664352771846,
        "compression_ratio": 1.632183908045977,
        "end": 3516.08,
        "id": 790,
        "no_speech_prob": 0.0769592821598053,
        "seek": 350712,
        "start": 3507.12,
        "temperature": 0,
        "text": " which calls toot, which is this, which does this, every 10,000 seconds, this is not right, oh, look at this,",
        "tokens": [
          50364,
          597,
          5498,
          281,
          310,
          11,
          597,
          307,
          341,
          11,
          597,
          775,
          341,
          11,
          633,
          1266,
          11,
          1360,
          3949,
          11,
          341,
          307,
          406,
          558,
          11,
          1954,
          11,
          574,
          412,
          341,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.26189664352771846,
        "compression_ratio": 1.632183908045977,
        "end": 3521.68,
        "id": 791,
        "no_speech_prob": 0.0769592821598053,
        "seek": 350712,
        "start": 3516.08,
        "temperature": 0,
        "text": " what a mess, I mean, if I was doing it without the arrow syntax, it would look like this, right?",
        "tokens": [
          50812,
          437,
          257,
          2082,
          11,
          286,
          914,
          11,
          498,
          286,
          390,
          884,
          309,
          1553,
          264,
          11610,
          28431,
          11,
          309,
          576,
          574,
          411,
          341,
          11,
          558,
          30,
          51092
        ]
      },
      {
        "avg_logprob": -0.26189664352771846,
        "compression_ratio": 1.632183908045977,
        "end": 3528.72,
        "id": 792,
        "no_speech_prob": 0.0769592821598053,
        "seek": 350712,
        "start": 3522.96,
        "temperature": 0,
        "text": " And then this would go here, no, no, no, that goes first, right, that's close.",
        "tokens": [
          51156,
          400,
          550,
          341,
          576,
          352,
          510,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          300,
          1709,
          700,
          11,
          558,
          11,
          300,
          311,
          1998,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.24595866157013235,
        "compression_ratio": 1.8324324324324324,
        "end": 3540.3199999999997,
        "id": 793,
        "no_speech_prob": 0.04885651916265488,
        "seek": 352872,
        "start": 3528.72,
        "temperature": 0,
        "text": " Then this, what's wrong here? This is opening the function, that's closing it, no, there's no parentheses there,",
        "tokens": [
          50364,
          1396,
          341,
          11,
          437,
          311,
          2085,
          510,
          30,
          639,
          307,
          5193,
          264,
          2445,
          11,
          300,
          311,
          10377,
          309,
          11,
          572,
          11,
          456,
          311,
          572,
          34153,
          456,
          11,
          50944
        ]
      },
      {
        "avg_logprob": -0.24595866157013235,
        "compression_ratio": 1.8324324324324324,
        "end": 3548.24,
        "id": 794,
        "no_speech_prob": 0.04885651916265488,
        "seek": 352872,
        "start": 3540.3199999999997,
        "temperature": 0,
        "text": " that's the end of the function, then this, then this, we're good, we're good, this is it, oh, but look how weird,",
        "tokens": [
          50944,
          300,
          311,
          264,
          917,
          295,
          264,
          2445,
          11,
          550,
          341,
          11,
          550,
          341,
          11,
          321,
          434,
          665,
          11,
          321,
          434,
          665,
          11,
          341,
          307,
          309,
          11,
          1954,
          11,
          457,
          574,
          577,
          3657,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.24595866157013235,
        "compression_ratio": 1.8324324324324324,
        "end": 3554.64,
        "id": 795,
        "no_speech_prob": 0.04885651916265488,
        "seek": 352872,
        "start": 3548.24,
        "temperature": 0,
        "text": " I don't like this at all, this is making me crazy, I'm going to do, I'm going to do this, I mean, it's so silly,",
        "tokens": [
          51340,
          286,
          500,
          380,
          411,
          341,
          412,
          439,
          11,
          341,
          307,
          1455,
          385,
          3219,
          11,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          11,
          286,
          914,
          11,
          309,
          311,
          370,
          11774,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.23039071390947957,
        "compression_ratio": 1.991111111111111,
        "end": 3561.3599999999997,
        "id": 796,
        "no_speech_prob": 0.0023596470709890127,
        "seek": 355464,
        "start": 3554.72,
        "temperature": 0,
        "text": " function tooter, and then I'm going to put, this is like, I'm a ridiculous person, I'm going to put this in,",
        "tokens": [
          50368,
          2445,
          281,
          310,
          260,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          829,
          11,
          341,
          307,
          411,
          11,
          286,
          478,
          257,
          11083,
          954,
          11,
          286,
          478,
          516,
          281,
          829,
          341,
          294,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.23039071390947957,
        "compression_ratio": 1.991111111111111,
        "end": 3569.12,
        "id": 797,
        "no_speech_prob": 0.0023596470709890127,
        "seek": 355464,
        "start": 3561.3599999999997,
        "temperature": 0,
        "text": " oh, no, ah, oh, help me, help, help, I'm going to get this, I'm going to put this, and then I'm just going to name my function,",
        "tokens": [
          50700,
          1954,
          11,
          572,
          11,
          3716,
          11,
          1954,
          11,
          854,
          385,
          11,
          854,
          11,
          854,
          11,
          286,
          478,
          516,
          281,
          483,
          341,
          11,
          286,
          478,
          516,
          281,
          829,
          341,
          11,
          293,
          550,
          286,
          478,
          445,
          516,
          281,
          1315,
          452,
          2445,
          11,
          51088
        ]
      },
      {
        "avg_logprob": -0.23039071390947957,
        "compression_ratio": 1.991111111111111,
        "end": 3577.68,
        "id": 798,
        "no_speech_prob": 0.0023596470709890127,
        "seek": 355464,
        "start": 3569.12,
        "temperature": 0,
        "text": " forget about this anonymous stuff, this is what I want, right? I have a separate function, which calls my asynchronous function,",
        "tokens": [
          51088,
          2870,
          466,
          341,
          24932,
          1507,
          11,
          341,
          307,
          437,
          286,
          528,
          11,
          558,
          30,
          286,
          362,
          257,
          4994,
          2445,
          11,
          597,
          5498,
          452,
          49174,
          2445,
          11,
          51516
        ]
      },
      {
        "avg_logprob": -0.23039071390947957,
        "compression_ratio": 1.991111111111111,
        "end": 3581.44,
        "id": 799,
        "no_speech_prob": 0.0023596470709890127,
        "seek": 355464,
        "start": 3577.68,
        "temperature": 0,
        "text": " does the then, the catch, and then I'm going to have that happen every 10 seconds.",
        "tokens": [
          51516,
          775,
          264,
          550,
          11,
          264,
          3745,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          362,
          300,
          1051,
          633,
          1266,
          3949,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.2976498697318283,
        "compression_ratio": 1.5244444444444445,
        "end": 3591.2000000000003,
        "id": 800,
        "no_speech_prob": 0.00023050550953485072,
        "seek": 358144,
        "start": 3582.4,
        "temperature": 0,
        "text": " Okay, by the way, someone in the chat, K1ng Julian is asking, would it be possible to ask the bot to create a tree with a specified angle?",
        "tokens": [
          50412,
          1033,
          11,
          538,
          264,
          636,
          11,
          1580,
          294,
          264,
          5081,
          11,
          591,
          16,
          872,
          25151,
          307,
          3365,
          11,
          576,
          309,
          312,
          1944,
          281,
          1029,
          264,
          10592,
          281,
          1884,
          257,
          4230,
          365,
          257,
          22206,
          5802,
          30,
          50852
        ]
      },
      {
        "avg_logprob": -0.2976498697318283,
        "compression_ratio": 1.5244444444444445,
        "end": 3596.8,
        "id": 801,
        "no_speech_prob": 0.00023050550953485072,
        "seek": 358144,
        "start": 3591.2000000000003,
        "temperature": 0,
        "text": " Yes, and that is what I'm going to do in a follow-up tutorial, you'll see that in the next one, okay, here we go.",
        "tokens": [
          50852,
          1079,
          11,
          293,
          300,
          307,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          257,
          1524,
          12,
          1010,
          7073,
          11,
          291,
          603,
          536,
          300,
          294,
          264,
          958,
          472,
          11,
          1392,
          11,
          510,
          321,
          352,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2976498697318283,
        "compression_ratio": 1.5244444444444445,
        "end": 3610.08,
        "id": 802,
        "no_speech_prob": 0.00023050550953485072,
        "seek": 358144,
        "start": 3603.2000000000003,
        "temperature": 0,
        "text": " And we have a tree, oh, no, I forgot, it's going to wait, so one thing about set interval,",
        "tokens": [
          51452,
          400,
          321,
          362,
          257,
          4230,
          11,
          1954,
          11,
          572,
          11,
          286,
          5298,
          11,
          309,
          311,
          516,
          281,
          1699,
          11,
          370,
          472,
          551,
          466,
          992,
          15035,
          11,
          51796
        ]
      },
      {
        "avg_logprob": -0.28573450446128845,
        "compression_ratio": 1.7158273381294964,
        "end": 3619.04,
        "id": 803,
        "no_speech_prob": 0.0017821334768086672,
        "seek": 361008,
        "start": 3611.04,
        "temperature": 0,
        "text": " which is, I mean, it works, okay, I'll just keep going now, set interval will not execute that function immediately,",
        "tokens": [
          50412,
          597,
          307,
          11,
          286,
          914,
          11,
          309,
          1985,
          11,
          1392,
          11,
          286,
          603,
          445,
          1066,
          516,
          586,
          11,
          992,
          15035,
          486,
          406,
          14483,
          300,
          2445,
          4258,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.28573450446128845,
        "compression_ratio": 1.7158273381294964,
        "end": 3625.6,
        "id": 804,
        "no_speech_prob": 0.0017821334768086672,
        "seek": 361008,
        "start": 3619.04,
        "temperature": 0,
        "text": " it will wait the amount of time before doing it the first time, but now, we did it twice, every 10 seconds,",
        "tokens": [
          50812,
          309,
          486,
          1699,
          264,
          2372,
          295,
          565,
          949,
          884,
          309,
          264,
          700,
          565,
          11,
          457,
          586,
          11,
          321,
          630,
          309,
          6091,
          11,
          633,
          1266,
          3949,
          11,
          51140
        ]
      },
      {
        "avg_logprob": -0.28573450446128845,
        "compression_ratio": 1.7158273381294964,
        "end": 3632.64,
        "id": 805,
        "no_speech_prob": 0.0017821334768086672,
        "seek": 361008,
        "start": 3625.6,
        "temperature": 0,
        "text": " the first one was angle 44, and the second one was angle 28, let's, we can wait 10, you can watch this video for 10 more seconds,",
        "tokens": [
          51140,
          264,
          700,
          472,
          390,
          5802,
          16408,
          11,
          293,
          264,
          1150,
          472,
          390,
          5802,
          7562,
          11,
          718,
          311,
          11,
          321,
          393,
          1699,
          1266,
          11,
          291,
          393,
          1159,
          341,
          960,
          337,
          1266,
          544,
          3949,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.28573450446128845,
        "compression_ratio": 1.7158273381294964,
        "end": 3638.08,
        "id": 806,
        "no_speech_prob": 0.0017821334768086672,
        "seek": 361008,
        "start": 3632.64,
        "temperature": 0,
        "text": " we can also speed this up now, let it happen like four or five times, but I think that's good, so let's just go and check,",
        "tokens": [
          51492,
          321,
          393,
          611,
          3073,
          341,
          493,
          586,
          11,
          718,
          309,
          1051,
          411,
          1451,
          420,
          1732,
          1413,
          11,
          457,
          286,
          519,
          300,
          311,
          665,
          11,
          370,
          718,
          311,
          445,
          352,
          293,
          1520,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.218633542742048,
        "compression_ratio": 1.5924170616113744,
        "end": 3650.4,
        "id": 807,
        "no_speech_prob": 0.00034062410122714937,
        "seek": 363808,
        "start": 3639.04,
        "temperature": 0,
        "text": " here, and we can see 83 degrees, 28, 44, there we go, and 44, 28, 83, 44, 28, 83, wonderful, okay, so this is working,",
        "tokens": [
          50412,
          510,
          11,
          293,
          321,
          393,
          536,
          30997,
          5310,
          11,
          7562,
          11,
          16408,
          11,
          456,
          321,
          352,
          11,
          293,
          16408,
          11,
          7562,
          11,
          30997,
          11,
          16408,
          11,
          7562,
          11,
          30997,
          11,
          3715,
          11,
          1392,
          11,
          370,
          341,
          307,
          1364,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.218633542742048,
        "compression_ratio": 1.5924170616113744,
        "end": 3657.84,
        "id": 808,
        "no_speech_prob": 0.00034062410122714937,
        "seek": 363808,
        "start": 3650.4,
        "temperature": 0,
        "text": " you know, now, of course, I don't want to leave it like this, right, having a bot post every 10 seconds,",
        "tokens": [
          50980,
          291,
          458,
          11,
          586,
          11,
          295,
          1164,
          11,
          286,
          500,
          380,
          528,
          281,
          1856,
          309,
          411,
          341,
          11,
          558,
          11,
          1419,
          257,
          10592,
          2183,
          633,
          1266,
          3949,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.218633542742048,
        "compression_ratio": 1.5924170616113744,
        "end": 3662.96,
        "id": 809,
        "no_speech_prob": 0.00034062410122714937,
        "seek": 363808,
        "start": 3657.84,
        "temperature": 0,
        "text": " no one wants to follow a bot that posts every 10 seconds, maybe I want it to just, once a day, it's going to do,",
        "tokens": [
          51352,
          572,
          472,
          2738,
          281,
          1524,
          257,
          10592,
          300,
          12300,
          633,
          1266,
          3949,
          11,
          1310,
          286,
          528,
          309,
          281,
          445,
          11,
          1564,
          257,
          786,
          11,
          309,
          311,
          516,
          281,
          360,
          11,
          51608
        ]
      },
      {
        "avg_logprob": -0.1966412916021832,
        "compression_ratio": 1.8138528138528138,
        "end": 3668.16,
        "id": 810,
        "no_speech_prob": 0.03567710891366005,
        "seek": 366296,
        "start": 3662.96,
        "temperature": 0,
        "text": " maybe once an hour might be the maximum, the most I would do, but let's just, if I want to do it once a day,",
        "tokens": [
          50364,
          1310,
          1564,
          364,
          1773,
          1062,
          312,
          264,
          6674,
          11,
          264,
          881,
          286,
          576,
          360,
          11,
          457,
          718,
          311,
          445,
          11,
          498,
          286,
          528,
          281,
          360,
          309,
          1564,
          257,
          786,
          11,
          50624
        ]
      },
      {
        "avg_logprob": -0.1966412916021832,
        "compression_ratio": 1.8138528138528138,
        "end": 3677.84,
        "id": 811,
        "no_speech_prob": 0.03567710891366005,
        "seek": 366296,
        "start": 3668.16,
        "temperature": 0,
        "text": " it would be 24 hours times 60 minutes, there's 60 seconds in a minute, and a thousand milliseconds in a second,",
        "tokens": [
          50624,
          309,
          576,
          312,
          4022,
          2496,
          1413,
          4060,
          2077,
          11,
          456,
          311,
          4060,
          3949,
          294,
          257,
          3456,
          11,
          293,
          257,
          4714,
          34184,
          294,
          257,
          1150,
          11,
          51108
        ]
      },
      {
        "avg_logprob": -0.1966412916021832,
        "compression_ratio": 1.8138528138528138,
        "end": 3684.32,
        "id": 812,
        "no_speech_prob": 0.03567710891366005,
        "seek": 366296,
        "start": 3677.84,
        "temperature": 0,
        "text": " so this would now be, but I wouldn't want it to wait a whole day, so I probably want to call it once,",
        "tokens": [
          51108,
          370,
          341,
          576,
          586,
          312,
          11,
          457,
          286,
          2759,
          380,
          528,
          309,
          281,
          1699,
          257,
          1379,
          786,
          11,
          370,
          286,
          1391,
          528,
          281,
          818,
          309,
          1564,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.1966412916021832,
        "compression_ratio": 1.8138528138528138,
        "end": 3688.4,
        "id": 813,
        "no_speech_prob": 0.03567710891366005,
        "seek": 366296,
        "start": 3684.32,
        "temperature": 0,
        "text": " so I'll call it once, then set the interval, and I'm sure there's a more elegant way to do that,",
        "tokens": [
          51432,
          370,
          286,
          603,
          818,
          309,
          1564,
          11,
          550,
          992,
          264,
          15035,
          11,
          293,
          286,
          478,
          988,
          456,
          311,
          257,
          544,
          21117,
          636,
          281,
          360,
          300,
          11,
          51636
        ]
      },
      {
        "avg_logprob": -0.26680090072307183,
        "compression_ratio": 1.9036144578313252,
        "end": 3699.04,
        "id": 814,
        "no_speech_prob": 0.24214355647563934,
        "seek": 368840,
        "start": 3688.4,
        "temperature": 0,
        "text": " that all of you will someday, will write in the comments, and here we go, and, node, bot, bot.js, here we go,",
        "tokens": [
          50364,
          300,
          439,
          295,
          291,
          486,
          19412,
          11,
          486,
          2464,
          294,
          264,
          3053,
          11,
          293,
          510,
          321,
          352,
          11,
          293,
          11,
          9984,
          11,
          10592,
          11,
          10592,
          13,
          25530,
          11,
          510,
          321,
          352,
          11,
          50896
        ]
      },
      {
        "avg_logprob": -0.26680090072307183,
        "compression_ratio": 1.9036144578313252,
        "end": 3705.84,
        "id": 815,
        "no_speech_prob": 0.24214355647563934,
        "seek": 368840,
        "start": 3699.04,
        "temperature": 0,
        "text": " it does the first one, and then, now, we're going to wait, 24, we're going to wait 24 hours, I'll wait, yes, we'll wait,",
        "tokens": [
          50896,
          309,
          775,
          264,
          700,
          472,
          11,
          293,
          550,
          11,
          586,
          11,
          321,
          434,
          516,
          281,
          1699,
          11,
          4022,
          11,
          321,
          434,
          516,
          281,
          1699,
          4022,
          2496,
          11,
          286,
          603,
          1699,
          11,
          2086,
          11,
          321,
          603,
          1699,
          11,
          51236
        ]
      },
      {
        "avg_logprob": -0.26680090072307183,
        "compression_ratio": 1.9036144578313252,
        "end": 3713.52,
        "id": 816,
        "no_speech_prob": 0.24214355647563934,
        "seek": 368840,
        "start": 3705.84,
        "temperature": 0,
        "text": " and then, in 24 hours, I'll still be standing here, I can tell you to go home, have dinner, go to sleep, come back,",
        "tokens": [
          51236,
          293,
          550,
          11,
          294,
          4022,
          2496,
          11,
          286,
          603,
          920,
          312,
          4877,
          510,
          11,
          286,
          393,
          980,
          291,
          281,
          352,
          1280,
          11,
          362,
          6148,
          11,
          352,
          281,
          2817,
          11,
          808,
          646,
          11,
          51620
        ]
      },
      {
        "avg_logprob": -0.26680090072307183,
        "compression_ratio": 1.9036144578313252,
        "end": 3718,
        "id": 817,
        "no_speech_prob": 0.24214355647563934,
        "seek": 368840,
        "start": 3713.52,
        "temperature": 0,
        "text": " this laptop would still be here, and it would do the next one, we're just going to have to believe that that's going to happen,",
        "tokens": [
          51620,
          341,
          10732,
          576,
          920,
          312,
          510,
          11,
          293,
          309,
          576,
          360,
          264,
          958,
          472,
          11,
          321,
          434,
          445,
          516,
          281,
          362,
          281,
          1697,
          300,
          300,
          311,
          516,
          281,
          1051,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.2351082960764567,
        "compression_ratio": 1.7220216606498195,
        "end": 3723.52,
        "id": 818,
        "no_speech_prob": 0.00010229722101939842,
        "seek": 371800,
        "start": 3718.32,
        "temperature": 0,
        "text": " again, there is a question of, well, where would I actually want to deploy this, I've got to talk about that in a separate video,",
        "tokens": [
          50380,
          797,
          11,
          456,
          307,
          257,
          1168,
          295,
          11,
          731,
          11,
          689,
          576,
          286,
          767,
          528,
          281,
          7274,
          341,
          11,
          286,
          600,
          658,
          281,
          751,
          466,
          300,
          294,
          257,
          4994,
          960,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2351082960764567,
        "compression_ratio": 1.7220216606498195,
        "end": 3730,
        "id": 819,
        "no_speech_prob": 0.00010229722101939842,
        "seek": 371800,
        "start": 3723.52,
        "temperature": 0,
        "text": " but just the quick answer is, you're going to want to find a server, maybe you have one through a hosting company,",
        "tokens": [
          50640,
          457,
          445,
          264,
          1702,
          1867,
          307,
          11,
          291,
          434,
          516,
          281,
          528,
          281,
          915,
          257,
          7154,
          11,
          1310,
          291,
          362,
          472,
          807,
          257,
          16058,
          2237,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.2351082960764567,
        "compression_ratio": 1.7220216606498195,
        "end": 3734.48,
        "id": 820,
        "no_speech_prob": 0.00010229722101939842,
        "seek": 371800,
        "start": 3730,
        "temperature": 0,
        "text": " maybe you happen to have a computer that's always on in your home, a Raspberry Pi that can act as a server,",
        "tokens": [
          50964,
          1310,
          291,
          1051,
          281,
          362,
          257,
          3820,
          300,
          311,
          1009,
          322,
          294,
          428,
          1280,
          11,
          257,
          41154,
          17741,
          300,
          393,
          605,
          382,
          257,
          7154,
          11,
          51188
        ]
      },
      {
        "avg_logprob": -0.2351082960764567,
        "compression_ratio": 1.7220216606498195,
        "end": 3740.8,
        "id": 821,
        "no_speech_prob": 0.00010229722101939842,
        "seek": 371800,
        "start": 3734.48,
        "temperature": 0,
        "text": " but you need somewhere where you can just let it run over and over again, forever, okay, so, thanks for watching this video,",
        "tokens": [
          51188,
          457,
          291,
          643,
          4079,
          689,
          291,
          393,
          445,
          718,
          309,
          1190,
          670,
          293,
          670,
          797,
          11,
          5680,
          11,
          1392,
          11,
          370,
          11,
          3231,
          337,
          1976,
          341,
          960,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.23942271868387857,
        "compression_ratio": 1.645,
        "end": 3747.52,
        "id": 822,
        "no_speech_prob": 0.16663511097431183,
        "seek": 374080,
        "start": 3740.88,
        "temperature": 0,
        "text": " making a Mastodon image bot, and what I'm going to do, I want to do one more tutorial, because,",
        "tokens": [
          50368,
          1455,
          257,
          376,
          525,
          378,
          266,
          3256,
          10592,
          11,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          286,
          528,
          281,
          360,
          472,
          544,
          7073,
          11,
          570,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.23942271868387857,
        "compression_ratio": 1.645,
        "end": 3755.36,
        "id": 823,
        "no_speech_prob": 0.16663511097431183,
        "seek": 374080,
        "start": 3748.2400000000002,
        "temperature": 0,
        "text": " how would you do it so that if someone at mentions the bot, let's say, with an angle, then the bot",
        "tokens": [
          50736,
          577,
          576,
          291,
          360,
          309,
          370,
          300,
          498,
          1580,
          412,
          23844,
          264,
          10592,
          11,
          718,
          311,
          584,
          11,
          365,
          364,
          5802,
          11,
          550,
          264,
          10592,
          51092
        ]
      },
      {
        "avg_logprob": -0.23942271868387857,
        "compression_ratio": 1.645,
        "end": 3760.0800000000004,
        "id": 824,
        "no_speech_prob": 0.16663511097431183,
        "seek": 374080,
        "start": 3755.36,
        "temperature": 0,
        "text": " replies back with a tree with that angle, let's see if we can make that work, that's going to be fun,",
        "tokens": [
          51092,
          42289,
          646,
          365,
          257,
          4230,
          365,
          300,
          5802,
          11,
          718,
          311,
          536,
          498,
          321,
          393,
          652,
          300,
          589,
          11,
          300,
          311,
          516,
          281,
          312,
          1019,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.23942271868387857,
        "compression_ratio": 1.645,
        "end": 3761.36,
        "id": 825,
        "no_speech_prob": 0.16663511097431183,
        "seek": 374080,
        "start": 3760.0800000000004,
        "temperature": 0,
        "text": " okay, see you in the next video.",
        "tokens": [
          51328,
          1392,
          11,
          536,
          291,
          294,
          264,
          958,
          960,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2730828857421875,
        "compression_ratio": 1.5942622950819672,
        "end": 3773.76,
        "id": 826,
        "no_speech_prob": 0.010487822815775871,
        "seek": 377080,
        "start": 3771.76,
        "temperature": 0,
        "text": " Okay, um,",
        "tokens": [
          50412,
          1033,
          11,
          1105,
          11,
          50512
        ]
      },
      {
        "avg_logprob": -0.2730828857421875,
        "compression_ratio": 1.5942622950819672,
        "end": 3780.0800000000004,
        "id": 827,
        "no_speech_prob": 0.010487822815775871,
        "seek": 377080,
        "start": 3774.48,
        "temperature": 0,
        "text": " okay, so Nathan asks a really good question about deploying, wouldn't processing starting as a desktop app",
        "tokens": [
          50548,
          1392,
          11,
          370,
          20634,
          8962,
          257,
          534,
          665,
          1168,
          466,
          34198,
          11,
          2759,
          380,
          9007,
          2891,
          382,
          257,
          14502,
          724,
          50828
        ]
      },
      {
        "avg_logprob": -0.2730828857421875,
        "compression_ratio": 1.5942622950819672,
        "end": 3786.0800000000004,
        "id": 828,
        "no_speech_prob": 0.010487822815775871,
        "seek": 377080,
        "start": 3780.4,
        "temperature": 0,
        "text": " prevent the bot from working, so I've actually covered this in my previous Twitter bot series,",
        "tokens": [
          50844,
          4871,
          264,
          10592,
          490,
          1364,
          11,
          370,
          286,
          600,
          767,
          5343,
          341,
          294,
          452,
          3894,
          5794,
          10592,
          2638,
          11,
          51128
        ]
      },
      {
        "avg_logprob": -0.2730828857421875,
        "compression_ratio": 1.5942622950819672,
        "end": 3792.2400000000002,
        "id": 829,
        "no_speech_prob": 0.010487822815775871,
        "seek": 377080,
        "start": 3787.2400000000002,
        "temperature": 0,
        "text": " yes, but no, so it needs a windowing environment for processing to run,",
        "tokens": [
          51186,
          2086,
          11,
          457,
          572,
          11,
          370,
          309,
          2203,
          257,
          4910,
          278,
          2823,
          337,
          9007,
          281,
          1190,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.2730828857421875,
        "compression_ratio": 1.5942622950819672,
        "end": 3797.5600000000004,
        "id": 830,
        "no_speech_prob": 0.010487822815775871,
        "seek": 377080,
        "start": 3792.6800000000003,
        "temperature": 0,
        "text": " so that's going to work on this laptop, on a Raspberry Pi, if you have a headless server, like, you know,",
        "tokens": [
          51458,
          370,
          300,
          311,
          516,
          281,
          589,
          322,
          341,
          10732,
          11,
          322,
          257,
          41154,
          17741,
          11,
          498,
          291,
          362,
          257,
          1378,
          1832,
          7154,
          11,
          411,
          11,
          291,
          458,
          11,
          51702
        ]
      },
      {
        "avg_logprob": -0.31751824951171875,
        "compression_ratio": 1.6958174904942966,
        "end": 3804.6,
        "id": 831,
        "no_speech_prob": 0.003222377272322774,
        "seek": 379756,
        "start": 3797.6,
        "temperature": 0,
        "text": " I'm running this instance off DigitalOcean, so I could deploy the bot there, I would have to run a bunch of commands,",
        "tokens": [
          50366,
          286,
          478,
          2614,
          341,
          5197,
          766,
          15522,
          46,
          6428,
          11,
          370,
          286,
          727,
          7274,
          264,
          10592,
          456,
          11,
          286,
          576,
          362,
          281,
          1190,
          257,
          3840,
          295,
          16901,
          11,
          50716
        ]
      },
      {
        "avg_logprob": -0.31751824951171875,
        "compression_ratio": 1.6958174904942966,
        "end": 3809.12,
        "id": 832,
        "no_speech_prob": 0.003222377272322774,
        "seek": 379756,
        "start": 3804.6,
        "temperature": 0,
        "text": " to, not to trick it, I was going to say, but to, and I have this documented,",
        "tokens": [
          50716,
          281,
          11,
          406,
          281,
          4282,
          309,
          11,
          286,
          390,
          516,
          281,
          584,
          11,
          457,
          281,
          11,
          293,
          286,
          362,
          341,
          23007,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.31751824951171875,
        "compression_ratio": 1.6958174904942966,
        "end": 3815.24,
        "id": 833,
        "no_speech_prob": 0.003222377272322774,
        "seek": 379756,
        "start": 3810.84,
        "temperature": 0,
        "text": " for Twitter bots, and I want to rewrite all, anyone wants to help me rewrite all these pages,",
        "tokens": [
          51028,
          337,
          5794,
          35410,
          11,
          293,
          286,
          528,
          281,
          28132,
          439,
          11,
          2878,
          2738,
          281,
          854,
          385,
          28132,
          439,
          613,
          7183,
          11,
          51248
        ]
      },
      {
        "avg_logprob": -0.31751824951171875,
        "compression_ratio": 1.6958174904942966,
        "end": 3820.2799999999997,
        "id": 834,
        "no_speech_prob": 0.003222377272322774,
        "seek": 379756,
        "start": 3815.24,
        "temperature": 0,
        "text": " or basically do, I intend to make an entire new version of this page,",
        "tokens": [
          51248,
          420,
          1936,
          360,
          11,
          286,
          19759,
          281,
          652,
          364,
          2302,
          777,
          3037,
          295,
          341,
          3028,
          11,
          51500
        ]
      },
      {
        "avg_logprob": -0.31751824951171875,
        "compression_ratio": 1.6958174904942966,
        "end": 3825.08,
        "id": 835,
        "no_speech_prob": 0.003222377272322774,
        "seek": 379756,
        "start": 3820.2799999999997,
        "temperature": 0,
        "text": " with Mastodon, but I just, I don't have the time to write this up, but I think in here,",
        "tokens": [
          51500,
          365,
          376,
          525,
          378,
          266,
          11,
          457,
          286,
          445,
          11,
          286,
          500,
          380,
          362,
          264,
          565,
          281,
          2464,
          341,
          493,
          11,
          457,
          286,
          519,
          294,
          510,
          11,
          51740
        ]
      },
      {
        "avg_logprob": -0.2873062010734312,
        "compression_ratio": 1.6199095022624435,
        "end": 3833.24,
        "id": 836,
        "no_speech_prob": 0.00012730895832646638,
        "seek": 382756,
        "start": 3828.56,
        "temperature": 0,
        "text": " deploy bot to Amazon EC2, which is actually, admittedly, probably one of the hardest ways to deploy it,",
        "tokens": [
          50414,
          7274,
          10592,
          281,
          6795,
          19081,
          17,
          11,
          597,
          307,
          767,
          11,
          14920,
          356,
          11,
          1391,
          472,
          295,
          264,
          13158,
          2098,
          281,
          7274,
          309,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.2873062010734312,
        "compression_ratio": 1.6199095022624435,
        "end": 3837.68,
        "id": 837,
        "no_speech_prob": 0.00012730895832646638,
        "seek": 382756,
        "start": 3833.7599999999998,
        "temperature": 0,
        "text": " so, but here, somewhere in here, I have the instructions for,",
        "tokens": [
          50674,
          370,
          11,
          457,
          510,
          11,
          4079,
          294,
          510,
          11,
          286,
          362,
          264,
          9415,
          337,
          11,
          50870
        ]
      },
      {
        "avg_logprob": -0.2873062010734312,
        "compression_ratio": 1.6199095022624435,
        "end": 3845.84,
        "id": 838,
        "no_speech_prob": 0.00012730895832646638,
        "seek": 382756,
        "start": 3838.72,
        "temperature": 0,
        "text": " yeah, so this, you need to make sure that the server has Java, and you can install Java that way,",
        "tokens": [
          50922,
          1338,
          11,
          370,
          341,
          11,
          291,
          643,
          281,
          652,
          988,
          300,
          264,
          7154,
          575,
          10745,
          11,
          293,
          291,
          393,
          3625,
          10745,
          300,
          636,
          11,
          51278
        ]
      },
      {
        "avg_logprob": -0.2873062010734312,
        "compression_ratio": 1.6199095022624435,
        "end": 3852.36,
        "id": 839,
        "no_speech_prob": 0.00012730895832646638,
        "seek": 382756,
        "start": 3846.2,
        "temperature": 0,
        "text": " then you need to do this weird stuff, that creates a fake display for processing to render on,",
        "tokens": [
          51296,
          550,
          291,
          643,
          281,
          360,
          341,
          3657,
          1507,
          11,
          300,
          7829,
          257,
          7592,
          4674,
          337,
          9007,
          281,
          15529,
          322,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.3018879699707031,
        "compression_ratio": 1.6370967741935485,
        "end": 3858.44,
        "id": 840,
        "no_speech_prob": 0.00026529672322794795,
        "seek": 385236,
        "start": 3852.76,
        "temperature": 0,
        "text": " and then you need to also, like, always run that display in the background, and once you've done this, it works.",
        "tokens": [
          50384,
          293,
          550,
          291,
          643,
          281,
          611,
          11,
          411,
          11,
          1009,
          1190,
          300,
          4674,
          294,
          264,
          3678,
          11,
          293,
          1564,
          291,
          600,
          1096,
          341,
          11,
          309,
          1985,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.3018879699707031,
        "compression_ratio": 1.6370967741935485,
        "end": 3861.6400000000003,
        "id": 841,
        "no_speech_prob": 0.00026529672322794795,
        "seek": 385236,
        "start": 3858.6800000000003,
        "temperature": 0,
        "text": " So I have tested this, not in a year, but it does work.",
        "tokens": [
          50680,
          407,
          286,
          362,
          8246,
          341,
          11,
          406,
          294,
          257,
          1064,
          11,
          457,
          309,
          775,
          589,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.3018879699707031,
        "compression_ratio": 1.6370967741935485,
        "end": 3866.96,
        "id": 842,
        "no_speech_prob": 0.00026529672322794795,
        "seek": 385236,
        "start": 3863.8,
        "temperature": 0,
        "text": " Yeah, so I'm going to, the stream is not over, it is 5.10,",
        "tokens": [
          50936,
          865,
          11,
          370,
          286,
          478,
          516,
          281,
          11,
          264,
          4309,
          307,
          406,
          670,
          11,
          309,
          307,
          1025,
          13,
          3279,
          11,
          51094
        ]
      },
      {
        "avg_logprob": -0.3018879699707031,
        "compression_ratio": 1.6370967741935485,
        "end": 3873.08,
        "id": 843,
        "no_speech_prob": 0.00026529672322794795,
        "seek": 385236,
        "start": 3866.96,
        "temperature": 0,
        "text": " ooh, I'm kind of going to go, but I'm, I definitely want to, this is going to be the end of the Mastodon bot stuff,",
        "tokens": [
          51094,
          17024,
          11,
          286,
          478,
          733,
          295,
          516,
          281,
          352,
          11,
          457,
          286,
          478,
          11,
          286,
          2138,
          528,
          281,
          11,
          341,
          307,
          516,
          281,
          312,
          264,
          917,
          295,
          264,
          376,
          525,
          378,
          266,
          10592,
          1507,
          11,
          51400
        ]
      },
      {
        "avg_logprob": -0.3018879699707031,
        "compression_ratio": 1.6370967741935485,
        "end": 3877.08,
        "id": 844,
        "no_speech_prob": 0.00026529672322794795,
        "seek": 385236,
        "start": 3873.08,
        "temperature": 0,
        "text": " I'm just coming over here to look, I have a bunch of messages,",
        "tokens": [
          51400,
          286,
          478,
          445,
          1348,
          670,
          510,
          281,
          574,
          11,
          286,
          362,
          257,
          3840,
          295,
          7897,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3886.28,
        "id": 845,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3883.2400000000002,
        "temperature": 0,
        "text": " okay, oh, and apparently I got a new member,",
        "tokens": [
          50408,
          1392,
          11,
          1954,
          11,
          293,
          7970,
          286,
          658,
          257,
          777,
          4006,
          11,
          50560
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3890.84,
        "id": 846,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3886.7200000000003,
        "temperature": 0,
        "text": " thank you to, it's sort of gone from the chat, it happened in the middle of me,",
        "tokens": [
          50582,
          1309,
          291,
          281,
          11,
          309,
          311,
          1333,
          295,
          2780,
          490,
          264,
          5081,
          11,
          309,
          2011,
          294,
          264,
          2808,
          295,
          385,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3894.56,
        "id": 847,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3890.84,
        "temperature": 0,
        "text": " thank you to, I think, Joel, Joel, who joined as a member, appreciate it,",
        "tokens": [
          50788,
          1309,
          291,
          281,
          11,
          286,
          519,
          11,
          21522,
          11,
          21522,
          11,
          567,
          6869,
          382,
          257,
          4006,
          11,
          4449,
          309,
          11,
          50974
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3898.52,
        "id": 848,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3894.84,
        "temperature": 0,
        "text": " Joel, if you, oh, Joel, you can see, Joel has the this.icon,",
        "tokens": [
          50988,
          21522,
          11,
          498,
          291,
          11,
          1954,
          11,
          21522,
          11,
          291,
          393,
          536,
          11,
          21522,
          575,
          264,
          341,
          13,
          11911,
          11,
          51172
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3902.92,
        "id": 849,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3898.88,
        "temperature": 0,
        "text": " the this.icon is for if you've been a member for, that's the first icon you get,",
        "tokens": [
          51190,
          264,
          341,
          13,
          11911,
          307,
          337,
          498,
          291,
          600,
          668,
          257,
          4006,
          337,
          11,
          300,
          311,
          264,
          700,
          6528,
          291,
          483,
          11,
          51392
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3908.6,
        "id": 850,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3903.2400000000002,
        "temperature": 0,
        "text": " and then I think if you're a member later, you get,",
        "tokens": [
          51408,
          293,
          550,
          286,
          519,
          498,
          291,
          434,
          257,
          4006,
          1780,
          11,
          291,
          483,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.3181406469906078,
        "compression_ratio": 1.9377777777777778,
        "end": 3911.08,
        "id": 851,
        "no_speech_prob": 0.0007096537738107145,
        "seek": 388236,
        "start": 3908.96,
        "temperature": 0,
        "text": " so the question is, so now the question is,",
        "tokens": [
          51694,
          370,
          264,
          1168,
          307,
          11,
          370,
          586,
          264,
          1168,
          307,
          11,
          51800
        ]
      },
      {
        "avg_logprob": -0.37460729127289144,
        "compression_ratio": 1.7538461538461538,
        "end": 3915.72,
        "id": 852,
        "no_speech_prob": 0.000003844929324259283,
        "seek": 391108,
        "start": 3912.08,
        "temperature": 0,
        "text": " if you're, sorry, I should finish my sentences, I have a problem not finishing my sentences,",
        "tokens": [
          50414,
          498,
          291,
          434,
          11,
          2597,
          11,
          286,
          820,
          2413,
          452,
          16579,
          11,
          286,
          362,
          257,
          1154,
          406,
          12693,
          452,
          16579,
          11,
          50596
        ]
      },
      {
        "avg_logprob": -0.37460729127289144,
        "compression_ratio": 1.7538461538461538,
        "end": 3919.88,
        "id": 853,
        "no_speech_prob": 0.000003844929324259283,
        "seek": 391108,
        "start": 3916.04,
        "temperature": 0,
        "text": " if you're a member for more than a month, you get a different one, and two months, I don't remember what those are,",
        "tokens": [
          50612,
          498,
          291,
          434,
          257,
          4006,
          337,
          544,
          813,
          257,
          1618,
          11,
          291,
          483,
          257,
          819,
          472,
          11,
          293,
          732,
          2493,
          11,
          286,
          500,
          380,
          1604,
          437,
          729,
          366,
          11,
          50804
        ]
      },
      {
        "avg_logprob": -0.37460729127289144,
        "compression_ratio": 1.7538461538461538,
        "end": 3924,
        "id": 854,
        "no_speech_prob": 0.000003844929324259283,
        "seek": 391108,
        "start": 3920.36,
        "temperature": 0,
        "text": " let's see what those are, whatever, okay,",
        "tokens": [
          50828,
          718,
          311,
          536,
          437,
          729,
          366,
          11,
          2035,
          11,
          1392,
          11,
          51010
        ]
      },
      {
        "avg_logprob": -0.37460729127289144,
        "compression_ratio": 1.7538461538461538,
        "end": 3934.12,
        "id": 855,
        "no_speech_prob": 0.000003844929324259283,
        "seek": 391108,
        "start": 3925.56,
        "temperature": 0,
        "text": " because that's, so, the question is now, should that be, should that be a coding challenge,",
        "tokens": [
          51088,
          570,
          300,
          311,
          11,
          370,
          11,
          264,
          1168,
          307,
          586,
          11,
          820,
          300,
          312,
          11,
          820,
          300,
          312,
          257,
          17720,
          3430,
          11,
          51516
        ]
      },
      {
        "avg_logprob": -0.4696794289809007,
        "compression_ratio": 1.3603603603603605,
        "end": 3941.48,
        "id": 856,
        "no_speech_prob": 0.03409319743514061,
        "seek": 393412,
        "start": 3935,
        "temperature": 0,
        "text": " and, or should it just, it probably should just be in the Mastodon tutorials,",
        "tokens": [
          50408,
          293,
          11,
          420,
          820,
          309,
          445,
          11,
          309,
          1391,
          820,
          445,
          312,
          294,
          264,
          376,
          525,
          378,
          266,
          17616,
          11,
          50732
        ]
      },
      {
        "avg_logprob": -0.4696794289809007,
        "compression_ratio": 1.3603603603603605,
        "end": 3947.7999999999997,
        "id": 857,
        "no_speech_prob": 0.03409319743514061,
        "seek": 393412,
        "start": 3945.08,
        "temperature": 0,
        "text": " I don't know, I never know these things,",
        "tokens": [
          50912,
          286,
          500,
          380,
          458,
          11,
          286,
          1128,
          458,
          613,
          721,
          11,
          51048
        ]
      },
      {
        "avg_logprob": -0.4696794289809007,
        "compression_ratio": 1.3603603603603605,
        "end": 3955.72,
        "id": 858,
        "no_speech_prob": 0.03409319743514061,
        "seek": 393412,
        "start": 3952.7999999999997,
        "temperature": 0,
        "text": " I don't know, alright, so,",
        "tokens": [
          51298,
          286,
          500,
          380,
          458,
          11,
          5845,
          11,
          370,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.4696794289809007,
        "compression_ratio": 1.3603603603603605,
        "end": 3959.44,
        "id": 859,
        "no_speech_prob": 0.03409319743514061,
        "seek": 393412,
        "start": 3958.92,
        "temperature": 0,
        "text": " okay,",
        "tokens": [
          51604,
          1392,
          11,
          51630
        ]
      },
      {
        "avg_logprob": -0.36410136705034235,
        "compression_ratio": 1.5893719806763285,
        "end": 3965.04,
        "id": 860,
        "no_speech_prob": 0.0008166851475834846,
        "seek": 395944,
        "start": 3959.96,
        "temperature": 0,
        "text": " alright, but I'm going to do part two, and then I'll think about it.",
        "tokens": [
          50390,
          5845,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          644,
          732,
          11,
          293,
          550,
          286,
          603,
          519,
          466,
          309,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.36410136705034235,
        "compression_ratio": 1.5893719806763285,
        "end": 3970.44,
        "id": 861,
        "no_speech_prob": 0.0008166851475834846,
        "seek": 395944,
        "start": 3966.7200000000003,
        "temperature": 0,
        "text": " Exporting the sketch as a Java app wouldn't make a difference,",
        "tokens": [
          50728,
          50130,
          278,
          264,
          12325,
          382,
          257,
          10745,
          724,
          2759,
          380,
          652,
          257,
          2649,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.36410136705034235,
        "compression_ratio": 1.5893719806763285,
        "end": 3979.12,
        "id": 862,
        "no_speech_prob": 0.0008166851475834846,
        "seek": 395944,
        "start": 3970.96,
        "temperature": 0,
        "text": " it still needs processing, the app still needs, that, you can also do that, but you still need a windowing environment,",
        "tokens": [
          50940,
          309,
          920,
          2203,
          9007,
          11,
          264,
          724,
          920,
          2203,
          11,
          300,
          11,
          291,
          393,
          611,
          360,
          300,
          11,
          457,
          291,
          920,
          643,
          257,
          4910,
          278,
          2823,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.36410136705034235,
        "compression_ratio": 1.5893719806763285,
        "end": 3984.52,
        "id": 863,
        "no_speech_prob": 0.0008166851475834846,
        "seek": 395944,
        "start": 3979.84,
        "temperature": 0,
        "text": " I don't believe that would remove the need for X11, Nathan asked in the chat,",
        "tokens": [
          51384,
          286,
          500,
          380,
          1697,
          300,
          576,
          4159,
          264,
          643,
          337,
          1783,
          5348,
          11,
          20634,
          2351,
          294,
          264,
          5081,
          11,
          51618
        ]
      },
      {
        "avg_logprob": -0.29364495849609373,
        "compression_ratio": 1.828125,
        "end": 3993,
        "id": 864,
        "no_speech_prob": 0.000029773027563351206,
        "seek": 398452,
        "start": 3985.12,
        "temperature": 0,
        "text": " but I could be wrong about that, but I'm pretty sure, like, it's not actually, the processing IDE never opens,",
        "tokens": [
          50394,
          457,
          286,
          727,
          312,
          2085,
          466,
          300,
          11,
          457,
          286,
          478,
          1238,
          988,
          11,
          411,
          11,
          309,
          311,
          406,
          767,
          11,
          264,
          9007,
          40930,
          1128,
          9870,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.29364495849609373,
        "compression_ratio": 1.828125,
        "end": 3998.96,
        "id": 865,
        "no_speech_prob": 0.000029773027563351206,
        "seek": 398452,
        "start": 3993.72,
        "temperature": 0,
        "text": " it's, processing is just like, it's just running, it's just compiling the processing code and executing it as an app,",
        "tokens": [
          50824,
          309,
          311,
          11,
          9007,
          307,
          445,
          411,
          11,
          309,
          311,
          445,
          2614,
          11,
          309,
          311,
          445,
          715,
          4883,
          264,
          9007,
          3089,
          293,
          32368,
          309,
          382,
          364,
          724,
          11,
          51086
        ]
      },
      {
        "avg_logprob": -0.29364495849609373,
        "compression_ratio": 1.828125,
        "end": 4000.72,
        "id": 866,
        "no_speech_prob": 0.000029773027563351206,
        "seek": 398452,
        "start": 3999.16,
        "temperature": 0,
        "text": " it's basically doing that for you,",
        "tokens": [
          51096,
          309,
          311,
          1936,
          884,
          300,
          337,
          291,
          11,
          51174
        ]
      },
      {
        "avg_logprob": -0.29364495849609373,
        "compression_ratio": 1.828125,
        "end": 4006.36,
        "id": 867,
        "no_speech_prob": 0.000029773027563351206,
        "seek": 398452,
        "start": 4002.44,
        "temperature": 0,
        "text": " so I'm pretty sure you need a windowing environment, maybe there's some other way you could do it,",
        "tokens": [
          51260,
          370,
          286,
          478,
          1238,
          988,
          291,
          643,
          257,
          4910,
          278,
          2823,
          11,
          1310,
          456,
          311,
          512,
          661,
          636,
          291,
          727,
          360,
          309,
          11,
          51456
        ]
      },
      {
        "avg_logprob": -0.29364495849609373,
        "compression_ratio": 1.828125,
        "end": 4011.2,
        "id": 868,
        "no_speech_prob": 0.000029773027563351206,
        "seek": 398452,
        "start": 4006.36,
        "temperature": 0,
        "text": " and by the way, you don't have to use processing, you know, this is just, I think, really useful because,",
        "tokens": [
          51456,
          293,
          538,
          264,
          636,
          11,
          291,
          500,
          380,
          362,
          281,
          764,
          9007,
          11,
          291,
          458,
          11,
          341,
          307,
          445,
          11,
          286,
          519,
          11,
          534,
          4420,
          570,
          11,
          51698
        ]
      },
      {
        "avg_logprob": -0.3445907739492563,
        "compression_ratio": 1.516304347826087,
        "end": 4015.3199999999997,
        "id": 869,
        "no_speech_prob": 0.00002627451431180816,
        "seek": 401120,
        "start": 4011.56,
        "temperature": 0,
        "text": " you know, it's sort of, it's very, I love the fact that it's sort of gluing these different things together.",
        "tokens": [
          50382,
          291,
          458,
          11,
          309,
          311,
          1333,
          295,
          11,
          309,
          311,
          588,
          11,
          286,
          959,
          264,
          1186,
          300,
          309,
          311,
          1333,
          295,
          1563,
          9635,
          613,
          819,
          721,
          1214,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.3445907739492563,
        "compression_ratio": 1.516304347826087,
        "end": 4016.64,
        "id": 870,
        "no_speech_prob": 0.00002627451431180816,
        "seek": 401120,
        "start": 4016.12,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50610,
          1033,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.3445907739492563,
        "compression_ratio": 1.516304347826087,
        "end": 4022.3599999999997,
        "id": 871,
        "no_speech_prob": 0.00002627451431180816,
        "seek": 401120,
        "start": 4020.3999999999996,
        "temperature": 0,
        "text": " I'll just drink a little water out of sight.",
        "tokens": [
          50824,
          286,
          603,
          445,
          2822,
          257,
          707,
          1281,
          484,
          295,
          7860,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.3445907739492563,
        "compression_ratio": 1.516304347826087,
        "end": 4034.04,
        "id": 872,
        "no_speech_prob": 0.00002627451431180816,
        "seek": 401120,
        "start": 4025,
        "temperature": 0,
        "text": " Water hasn't paid their sponsorship recently, so I'm not going to drink water in how you, visually, in an apparent way.",
        "tokens": [
          51054,
          8772,
          6132,
          380,
          4835,
          641,
          42922,
          3938,
          11,
          370,
          286,
          478,
          406,
          516,
          281,
          2822,
          1281,
          294,
          577,
          291,
          11,
          19622,
          11,
          294,
          364,
          18335,
          636,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.5270851359647863,
        "compression_ratio": 1.1237113402061856,
        "end": 4034.56,
        "id": 873,
        "no_speech_prob": 0.0015247388510033488,
        "seek": 403404,
        "start": 4034.04,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50390
        ]
      },
      {
        "avg_logprob": -0.5270851359647863,
        "compression_ratio": 1.1237113402061856,
        "end": 4043.96,
        "id": 874,
        "no_speech_prob": 0.0015247388510033488,
        "seek": 403404,
        "start": 4038.4,
        "temperature": 0,
        "text": " Sometimes the words don't form in my brain and exit out of my mouth in a way that makes sense.",
        "tokens": [
          50582,
          4803,
          264,
          2283,
          500,
          380,
          1254,
          294,
          452,
          3567,
          293,
          11043,
          484,
          295,
          452,
          4525,
          294,
          257,
          636,
          300,
          1669,
          2020,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.5270851359647863,
        "compression_ratio": 1.1237113402061856,
        "end": 4044.48,
        "id": 875,
        "no_speech_prob": 0.0015247388510033488,
        "seek": 403404,
        "start": 4043.96,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50860,
          2798,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.3738187051588489,
        "compression_ratio": 1.5182926829268293,
        "end": 4064.32,
        "id": 876,
        "no_speech_prob": 0.07920075207948685,
        "seek": 404448,
        "start": 4044.48,
        "temperature": 0,
        "text": " Hello, so previously, I made a bot that picked a random number between 0 and 90, generated this fractal tree using that angle,",
        "tokens": [
          50364,
          2425,
          11,
          370,
          8046,
          11,
          286,
          1027,
          257,
          10592,
          300,
          6183,
          257,
          4974,
          1230,
          1296,
          1958,
          293,
          4289,
          11,
          10833,
          341,
          17948,
          304,
          4230,
          1228,
          300,
          5802,
          11,
          51356
        ]
      },
      {
        "avg_logprob": -0.3738187051588489,
        "compression_ratio": 1.5182926829268293,
        "end": 4072.12,
        "id": 877,
        "no_speech_prob": 0.07920075207948685,
        "seek": 404448,
        "start": 4064.32,
        "temperature": 0,
        "text": " using processing, made the image, and then posted that image to Mastodon using this coding train bot at bots in space dot,",
        "tokens": [
          51356,
          1228,
          9007,
          11,
          1027,
          264,
          3256,
          11,
          293,
          550,
          9437,
          300,
          3256,
          281,
          376,
          525,
          378,
          266,
          1228,
          341,
          17720,
          3847,
          10592,
          412,
          35410,
          294,
          1901,
          5893,
          11,
          51746
        ]
      },
      {
        "avg_logprob": -0.30532507294590033,
        "compression_ratio": 1.634703196347032,
        "end": 4075.8399999999997,
        "id": 878,
        "no_speech_prob": 0.0006771920016035438,
        "seek": 407212,
        "start": 4072.24,
        "temperature": 0,
        "text": " bots in dot space, whatever, bots in space dot instance.",
        "tokens": [
          50370,
          35410,
          294,
          5893,
          1901,
          11,
          2035,
          11,
          35410,
          294,
          1901,
          5893,
          5197,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.30532507294590033,
        "compression_ratio": 1.634703196347032,
        "end": 4082.88,
        "id": 879,
        "no_speech_prob": 0.0006771920016035438,
        "seek": 407212,
        "start": 4076.16,
        "temperature": 0,
        "text": " So you can see a bunch of these here, and so now what I want to do is, instead of, and the bot, if we look at the code,",
        "tokens": [
          50566,
          407,
          291,
          393,
          536,
          257,
          3840,
          295,
          613,
          510,
          11,
          293,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          2602,
          295,
          11,
          293,
          264,
          10592,
          11,
          498,
          321,
          574,
          412,
          264,
          3089,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.30532507294590033,
        "compression_ratio": 1.634703196347032,
        "end": 4089.24,
        "id": 880,
        "no_speech_prob": 0.0006771920016035438,
        "seek": 407212,
        "start": 4082.88,
        "temperature": 0,
        "text": " is just executing all of this stuff to generate the image and post it once a day.",
        "tokens": [
          50902,
          307,
          445,
          32368,
          439,
          295,
          341,
          1507,
          281,
          8460,
          264,
          3256,
          293,
          2183,
          309,
          1564,
          257,
          786,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.30532507294590033,
        "compression_ratio": 1.634703196347032,
        "end": 4095.68,
        "id": 881,
        "no_speech_prob": 0.0006771920016035438,
        "seek": 407212,
        "start": 4089.8399999999997,
        "temperature": 0,
        "text": " So what I would like to do now, in this video, is change it, no, I'm not going to use set interval,",
        "tokens": [
          51250,
          407,
          437,
          286,
          576,
          411,
          281,
          360,
          586,
          11,
          294,
          341,
          960,
          11,
          307,
          1319,
          309,
          11,
          572,
          11,
          286,
          478,
          406,
          516,
          281,
          764,
          992,
          15035,
          11,
          51542
        ]
      },
      {
        "avg_logprob": -0.2810522247763241,
        "compression_ratio": 1.821561338289963,
        "end": 4101.4,
        "id": 882,
        "no_speech_prob": 0.0032224387396126986,
        "seek": 409568,
        "start": 4096.5199999999995,
        "temperature": 0,
        "text": " in fact, I'm not ever going to post an image.",
        "tokens": [
          50406,
          294,
          1186,
          11,
          286,
          478,
          406,
          1562,
          516,
          281,
          2183,
          364,
          3256,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.2810522247763241,
        "compression_ratio": 1.821561338289963,
        "end": 4107.76,
        "id": 883,
        "no_speech_prob": 0.0032224387396126986,
        "seek": 409568,
        "start": 4101.639999999999,
        "temperature": 0,
        "text": " I am only going to post an image as a reply to somebody else, and I'm going to look in their reply,",
        "tokens": [
          50662,
          286,
          669,
          787,
          516,
          281,
          2183,
          364,
          3256,
          382,
          257,
          16972,
          281,
          2618,
          1646,
          11,
          293,
          286,
          478,
          516,
          281,
          574,
          294,
          641,
          16972,
          11,
          50968
        ]
      },
      {
        "avg_logprob": -0.2810522247763241,
        "compression_ratio": 1.821561338289963,
        "end": 4112.16,
        "id": 884,
        "no_speech_prob": 0.0032224387396126986,
        "seek": 409568,
        "start": 4108.2,
        "temperature": 0,
        "text": " find the angle that they've specified, and send them back a tree with that angle.",
        "tokens": [
          50990,
          915,
          264,
          5802,
          300,
          436,
          600,
          22206,
          11,
          293,
          2845,
          552,
          646,
          257,
          4230,
          365,
          300,
          5802,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2810522247763241,
        "compression_ratio": 1.821561338289963,
        "end": 4115.28,
        "id": 885,
        "no_speech_prob": 0.0032224387396126986,
        "seek": 409568,
        "start": 4112.44,
        "temperature": 0,
        "text": " And you can just imagine the possibilities of things you can do.",
        "tokens": [
          51202,
          400,
          291,
          393,
          445,
          3811,
          264,
          12178,
          295,
          721,
          291,
          393,
          360,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2810522247763241,
        "compression_ratio": 1.821561338289963,
        "end": 4120,
        "id": 886,
        "no_speech_prob": 0.0032224387396126986,
        "seek": 409568,
        "start": 4115.28,
        "temperature": 0,
        "text": " I mean, one of my favorite, this is a Twitter bot, but one of my favorite bots is lowpolybot,",
        "tokens": [
          51344,
          286,
          914,
          11,
          472,
          295,
          452,
          2954,
          11,
          341,
          307,
          257,
          5794,
          10592,
          11,
          457,
          472,
          295,
          452,
          2954,
          35410,
          307,
          2295,
          2259,
          356,
          18870,
          11,
          51580
        ]
      },
      {
        "avg_logprob": -0.2810522247763241,
        "compression_ratio": 1.821561338289963,
        "end": 4125,
        "id": 887,
        "no_speech_prob": 0.0032224387396126986,
        "seek": 409568,
        "start": 4120.72,
        "temperature": 0,
        "text": " and what lowpolybot does is it's still running, is the question, because most of these bots, you can't,",
        "tokens": [
          51616,
          293,
          437,
          2295,
          2259,
          356,
          18870,
          775,
          307,
          309,
          311,
          920,
          2614,
          11,
          307,
          264,
          1168,
          11,
          570,
          881,
          295,
          613,
          35410,
          11,
          291,
          393,
          380,
          11,
          51830
        ]
      },
      {
        "avg_logprob": -0.2821298612581266,
        "compression_ratio": 1.8210526315789475,
        "end": 4127.72,
        "id": 888,
        "no_speech_prob": 0.00010720654972828925,
        "seek": 412500,
        "start": 4125.04,
        "temperature": 0,
        "text": " the reason why I'm using mastodon, one of the reasons why I'm using mastodon,",
        "tokens": [
          50366,
          264,
          1778,
          983,
          286,
          478,
          1228,
          27055,
          378,
          266,
          11,
          472,
          295,
          264,
          4112,
          983,
          286,
          478,
          1228,
          27055,
          378,
          266,
          11,
          50500
        ]
      },
      {
        "avg_logprob": -0.2821298612581266,
        "compression_ratio": 1.8210526315789475,
        "end": 4134.4,
        "id": 889,
        "no_speech_prob": 0.00010720654972828925,
        "seek": 412500,
        "start": 4128.04,
        "temperature": 0,
        "text": " is that these don't, I don't think, you can't really run these anymore on Twitter, they've changed the API specifications too much.",
        "tokens": [
          50516,
          307,
          300,
          613,
          500,
          380,
          11,
          286,
          500,
          380,
          519,
          11,
          291,
          393,
          380,
          534,
          1190,
          613,
          3602,
          322,
          5794,
          11,
          436,
          600,
          3105,
          264,
          9362,
          29448,
          886,
          709,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2821298612581266,
        "compression_ratio": 1.8210526315789475,
        "end": 4139.32,
        "id": 890,
        "no_speech_prob": 0.00010720654972828925,
        "seek": 412500,
        "start": 4134.56,
        "temperature": 0,
        "text": " So the idea is that you send in an image, and an image processes it for you and sends it back.",
        "tokens": [
          50842,
          407,
          264,
          1558,
          307,
          300,
          291,
          2845,
          294,
          364,
          3256,
          11,
          293,
          364,
          3256,
          7555,
          309,
          337,
          291,
          293,
          14790,
          309,
          646,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2821298612581266,
        "compression_ratio": 1.8210526315789475,
        "end": 4142.64,
        "id": 891,
        "no_speech_prob": 0.00010720654972828925,
        "seek": 412500,
        "start": 4139.32,
        "temperature": 0,
        "text": " Okay, so now, let's do this.",
        "tokens": [
          51080,
          1033,
          11,
          370,
          586,
          11,
          718,
          311,
          360,
          341,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.2821298612581266,
        "compression_ratio": 1.8210526315789475,
        "end": 4147,
        "id": 892,
        "no_speech_prob": 0.00010720654972828925,
        "seek": 412500,
        "start": 4142.84,
        "temperature": 0,
        "text": " So the thing that I need to do is I need to connect to a stream.",
        "tokens": [
          51256,
          407,
          264,
          551,
          300,
          286,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          1745,
          281,
          257,
          4309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2821298612581266,
        "compression_ratio": 1.8210526315789475,
        "end": 4153.44,
        "id": 893,
        "no_speech_prob": 0.00010720654972828925,
        "seek": 412500,
        "start": 4147.2,
        "temperature": 0,
        "text": " I've talked about this in previous videos, where I made a bot that just replied, I need to connect to the streaming API.",
        "tokens": [
          51474,
          286,
          600,
          2825,
          466,
          341,
          294,
          3894,
          2145,
          11,
          689,
          286,
          1027,
          257,
          10592,
          300,
          445,
          20345,
          11,
          286,
          643,
          281,
          1745,
          281,
          264,
          11791,
          9362,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.25541556371401436,
        "compression_ratio": 1.5031847133757963,
        "end": 4159.04,
        "id": 894,
        "no_speech_prob": 0.00011959746916545555,
        "seek": 415344,
        "start": 4153.759999999999,
        "temperature": 0,
        "text": " And so the way that I do that is here, m.stream.",
        "tokens": [
          50380,
          400,
          370,
          264,
          636,
          300,
          286,
          360,
          300,
          307,
          510,
          11,
          275,
          13,
          9291,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.25541556371401436,
        "compression_ratio": 1.5031847133757963,
        "end": 4167.759999999999,
        "id": 895,
        "no_speech_prob": 0.00011959746916545555,
        "seek": 415344,
        "start": 4159.48,
        "temperature": 0,
        "text": " So I'm going to say m.stream, and then I want to connect to the user stream.",
        "tokens": [
          50666,
          407,
          286,
          478,
          516,
          281,
          584,
          275,
          13,
          9291,
          11,
          293,
          550,
          286,
          528,
          281,
          1745,
          281,
          264,
          4195,
          4309,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.25541556371401436,
        "compression_ratio": 1.5031847133757963,
        "end": 4171.759999999999,
        "id": 896,
        "no_speech_prob": 0.00011959746916545555,
        "seek": 415344,
        "start": 4169.2,
        "temperature": 0,
        "text": " And doing that, I should get a promise.",
        "tokens": [
          51152,
          400,
          884,
          300,
          11,
          286,
          820,
          483,
          257,
          6228,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.25541556371401436,
        "compression_ratio": 1.5031847133757963,
        "end": 4180.12,
        "id": 897,
        "no_speech_prob": 0.00011959746916545555,
        "seek": 415344,
        "start": 4174.44,
        "temperature": 0,
        "text": " Then response, console.log response, can you see what I'm typing here?",
        "tokens": [
          51414,
          1396,
          4134,
          11,
          11076,
          13,
          4987,
          4134,
          11,
          393,
          291,
          536,
          437,
          286,
          478,
          18444,
          510,
          30,
          51698
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4183.68,
        "id": 898,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4180.32,
        "temperature": 0,
        "text": " And then, wow, autofill has gone crazy.",
        "tokens": [
          50374,
          400,
          550,
          11,
          6076,
          11,
          1476,
          2670,
          373,
          575,
          2780,
          3219,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4189.4,
        "id": 899,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4183.84,
        "temperature": 0,
        "text": " Catch any error, console.error, error.",
        "tokens": [
          50550,
          23869,
          604,
          6713,
          11,
          11076,
          13,
          260,
          2874,
          11,
          6713,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4197.28,
        "id": 900,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4191.5199999999995,
        "temperature": 0,
        "text": " And I put too many dots, too many dots, too many dots, the dots go there, where did the dots go? I've lost the dot.",
        "tokens": [
          50934,
          400,
          286,
          829,
          886,
          867,
          15026,
          11,
          886,
          867,
          15026,
          11,
          886,
          867,
          15026,
          11,
          264,
          15026,
          352,
          456,
          11,
          689,
          630,
          264,
          15026,
          352,
          30,
          286,
          600,
          2731,
          264,
          5893,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4200.08,
        "id": 901,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4197.28,
        "temperature": 0,
        "text": " I really have a problem with dots, apparently.",
        "tokens": [
          51222,
          286,
          534,
          362,
          257,
          1154,
          365,
          15026,
          11,
          7970,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4200.88,
        "id": 902,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4200.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51376,
          1033,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4203,
        "id": 903,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4202.48,
        "temperature": 0,
        "text": " Now.",
        "tokens": [
          51482,
          823,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.4096788348573627,
        "compression_ratio": 1.625668449197861,
        "end": 4209.2,
        "id": 904,
        "no_speech_prob": 0.0005357780028134584,
        "seek": 418012,
        "start": 4204.68,
        "temperature": 0,
        "text": " So the idea is now, any time there is a user event,",
        "tokens": [
          51592,
          407,
          264,
          1558,
          307,
          586,
          11,
          604,
          565,
          456,
          307,
          257,
          4195,
          2280,
          11,
          51818
        ]
      },
      {
        "avg_logprob": -0.2859868851919023,
        "compression_ratio": 1.696629213483146,
        "end": 4212.8,
        "id": 905,
        "no_speech_prob": 0.00014883698895573616,
        "seek": 420920,
        "start": 4209.92,
        "temperature": 0,
        "text": " any time there is a user event, I'm going to look at that event.",
        "tokens": [
          50400,
          604,
          565,
          456,
          307,
          257,
          4195,
          2280,
          11,
          286,
          478,
          516,
          281,
          574,
          412,
          300,
          2280,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.2859868851919023,
        "compression_ratio": 1.696629213483146,
        "end": 4214.28,
        "id": 906,
        "no_speech_prob": 0.00014883698895573616,
        "seek": 420920,
        "start": 4212.8,
        "temperature": 0,
        "text": " Now, I've done this before.",
        "tokens": [
          50544,
          823,
          11,
          286,
          600,
          1096,
          341,
          949,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.2859868851919023,
        "compression_ratio": 1.696629213483146,
        "end": 4221.48,
        "id": 907,
        "no_speech_prob": 0.00014883698895573616,
        "seek": 420920,
        "start": 4214.5199999999995,
        "temperature": 0,
        "text": " Isn't it okay for me, since I just did this in a previous tutorial, I think it's okay for me to look up what I did in that instead of figuring it out again.",
        "tokens": [
          50630,
          6998,
          380,
          309,
          1392,
          337,
          385,
          11,
          1670,
          286,
          445,
          630,
          341,
          294,
          257,
          3894,
          7073,
          11,
          286,
          519,
          309,
          311,
          1392,
          337,
          385,
          281,
          574,
          493,
          437,
          286,
          630,
          294,
          300,
          2602,
          295,
          15213,
          309,
          484,
          797,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.2859868851919023,
        "compression_ratio": 1.696629213483146,
        "end": 4227.4,
        "id": 908,
        "no_speech_prob": 0.00014883698895573616,
        "seek": 420920,
        "start": 4221.72,
        "temperature": 0,
        "text": " So a mastodon bot underscore two right now is where I had some code from a previous video.",
        "tokens": [
          50990,
          407,
          257,
          27055,
          378,
          266,
          10592,
          37556,
          732,
          558,
          586,
          307,
          689,
          286,
          632,
          512,
          3089,
          490,
          257,
          3894,
          960,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.2859868851919023,
        "compression_ratio": 1.696629213483146,
        "end": 4238.44,
        "id": 909,
        "no_speech_prob": 0.00014883698895573616,
        "seek": 420920,
        "start": 4228.2,
        "temperature": 0,
        "text": " And I can look at the bot code, and I can see what I actually did is if I said, if the event was a notification,",
        "tokens": [
          51314,
          400,
          286,
          393,
          574,
          412,
          264,
          10592,
          3089,
          11,
          293,
          286,
          393,
          536,
          437,
          286,
          767,
          630,
          307,
          498,
          286,
          848,
          11,
          498,
          264,
          2280,
          390,
          257,
          11554,
          11,
          51826
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4240.44,
        "id": 910,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4238.44,
        "temperature": 0,
        "text": " whoa, oh, look at this.",
        "tokens": [
          50364,
          13310,
          11,
          1954,
          11,
          574,
          412,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4242.08,
        "id": 911,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4241.08,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          50496,
          876,
          11,
          574,
          412,
          341,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4243.48,
        "id": 912,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4242.08,
        "temperature": 0,
        "text": " Ah, you know what?",
        "tokens": [
          50546,
          2438,
          11,
          291,
          458,
          437,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4246.96,
        "id": 913,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4244.48,
        "temperature": 0,
        "text": " I've written this code incorrectly.",
        "tokens": [
          50666,
          286,
          600,
          3720,
          341,
          3089,
          42892,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4252.759999999999,
        "id": 914,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4247.48,
        "temperature": 0,
        "text": " You have to configure, when you're using the streaming API, it doesn't work like the get or the post API.",
        "tokens": [
          50816,
          509,
          362,
          281,
          22162,
          11,
          562,
          291,
          434,
          1228,
          264,
          11791,
          9362,
          11,
          309,
          1177,
          380,
          589,
          411,
          264,
          483,
          420,
          264,
          2183,
          9362,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4258.12,
        "id": 915,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4253.44,
        "temperature": 0,
        "text": " You actually have to call this on function to specify an event.",
        "tokens": [
          51114,
          509,
          767,
          362,
          281,
          818,
          341,
          322,
          2445,
          281,
          16500,
          364,
          2280,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4259.5199999999995,
        "id": 916,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4258.12,
        "temperature": 0,
        "text": " So apologies for that.",
        "tokens": [
          51348,
          407,
          34929,
          337,
          300,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4260.759999999999,
        "id": 917,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4259.679999999999,
        "temperature": 0,
        "text": " Good thing I looked.",
        "tokens": [
          51426,
          2205,
          551,
          286,
          2956,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.35768137568921116,
        "compression_ratio": 1.6721991701244814,
        "end": 4268.4,
        "id": 918,
        "no_speech_prob": 0.0014550465857610106,
        "seek": 423844,
        "start": 4262.36,
        "temperature": 0,
        "text": " The way this should actually be written is const listener, like I want to create a listener.",
        "tokens": [
          51560,
          440,
          636,
          341,
          820,
          767,
          312,
          3720,
          307,
          1817,
          31569,
          11,
          411,
          286,
          528,
          281,
          1884,
          257,
          31569,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4271.12,
        "id": 919,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4269.2,
        "temperature": 0,
        "text": " That's connected to that user stream, right?",
        "tokens": [
          50402,
          663,
          311,
          4582,
          281,
          300,
          4195,
          4309,
          11,
          558,
          30,
          50498
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4272.32,
        "id": 920,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4271.12,
        "temperature": 0,
        "text": " Whoops, where's the other code?",
        "tokens": [
          50498,
          45263,
          11,
          689,
          311,
          264,
          661,
          3089,
          30,
          50558
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4272.919999999999,
        "id": 921,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4272.599999999999,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50572,
          1779,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4274.5199999999995,
        "id": 922,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4273.04,
        "temperature": 0,
        "text": " Streaming slash user.",
        "tokens": [
          50594,
          24904,
          278,
          17330,
          4195,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4275.44,
        "id": 923,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4274.5599999999995,
        "temperature": 0,
        "text": " Yeah, I knew that.",
        "tokens": [
          50670,
          865,
          11,
          286,
          2586,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4277.5199999999995,
        "id": 924,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4275.48,
        "temperature": 0,
        "text": " Streaming slash user.",
        "tokens": [
          50716,
          24904,
          278,
          17330,
          4195,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4284.639999999999,
        "id": 925,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4277.879999999999,
        "temperature": 0,
        "text": " And then I want to say listener.on notification.",
        "tokens": [
          50836,
          400,
          550,
          286,
          528,
          281,
          584,
          31569,
          13,
          266,
          11554,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4291.44,
        "id": 926,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4284.799999999999,
        "temperature": 0,
        "text": " So if I get a notification, and now I'm going to guess that this returns a promise.",
        "tokens": [
          51182,
          407,
          498,
          286,
          483,
          257,
          11554,
          11,
          293,
          586,
          286,
          478,
          516,
          281,
          2041,
          300,
          341,
          11247,
          257,
          6228,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4293.4,
        "id": 927,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4292.719999999999,
        "temperature": 0,
        "text": " But it won't.",
        "tokens": [
          51578,
          583,
          309,
          1582,
          380,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4295.32,
        "id": 928,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4293.759999999999,
        "temperature": 0,
        "text": " I'm so sad.",
        "tokens": [
          51630,
          286,
          478,
          370,
          4227,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.3220277332124256,
        "compression_ratio": 1.575609756097561,
        "end": 4296.5599999999995,
        "id": 929,
        "no_speech_prob": 0.0001660347916185856,
        "seek": 426844,
        "start": 4295.879999999999,
        "temperature": 0,
        "text": " Why doesn't this?",
        "tokens": [
          51736,
          1545,
          1177,
          380,
          341,
          30,
          51770
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4299.5599999999995,
        "id": 930,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4298.839999999999,
        "temperature": 0,
        "text": " I give up.",
        "tokens": [
          50384,
          286,
          976,
          493,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4300.44,
        "id": 931,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4300,
        "temperature": 0,
        "text": " I give up.",
        "tokens": [
          50442,
          286,
          976,
          493,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4301.16,
        "id": 932,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4300.44,
        "temperature": 0,
        "text": " I quit.",
        "tokens": [
          50464,
          286,
          10366,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4303.759999999999,
        "id": 933,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4301.799999999999,
        "temperature": 0,
        "text": " I can't do this kind of syntax.",
        "tokens": [
          50532,
          286,
          393,
          380,
          360,
          341,
          733,
          295,
          28431,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4306.36,
        "id": 934,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4304.679999999999,
        "temperature": 0,
        "text": " I did it with a callback before.",
        "tokens": [
          50676,
          286,
          630,
          309,
          365,
          257,
          818,
          3207,
          949,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4309.16,
        "id": 935,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4306.4,
        "temperature": 0,
        "text": " Return to stream listener instance.",
        "tokens": [
          50762,
          24350,
          281,
          4309,
          31569,
          5197,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4310.839999999999,
        "id": 936,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4309.16,
        "temperature": 0,
        "text": " See examples on how to use it.",
        "tokens": [
          50900,
          3008,
          5110,
          322,
          577,
          281,
          764,
          309,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4317.48,
        "id": 937,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4316.44,
        "temperature": 0,
        "text": " Give me a second here.",
        "tokens": [
          51264,
          5303,
          385,
          257,
          1150,
          510,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4323.879999999999,
        "id": 938,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4321.639999999999,
        "temperature": 0,
        "text": " I can't type the password over here.",
        "tokens": [
          51524,
          286,
          393,
          380,
          2010,
          264,
          11524,
          670,
          510,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2983280708049906,
        "compression_ratio": 1.4772727272727273,
        "end": 4327.36,
        "id": 939,
        "no_speech_prob": 0.0010484609520062804,
        "seek": 429844,
        "start": 4324.639999999999,
        "temperature": 0,
        "text": " Event emitters do not return promises.",
        "tokens": [
          51674,
          13222,
          32084,
          1559,
          360,
          406,
          2736,
          16403,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4331,
        "id": 940,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4329.44,
        "temperature": 0,
        "text": " Let's start over.",
        "tokens": [
          50414,
          961,
          311,
          722,
          670,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4332.04,
        "id": 941,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4331.24,
        "temperature": 0,
        "text": " Let's go back.",
        "tokens": [
          50504,
          961,
          311,
          352,
          646,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4341.839999999999,
        "id": 942,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4339.599999999999,
        "temperature": 0,
        "text": " So that won't give me a promise.",
        "tokens": [
          50922,
          407,
          300,
          1582,
          380,
          976,
          385,
          257,
          6228,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4342.48,
        "id": 943,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4341.839999999999,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51034,
          663,
          311,
          2489,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4343.639999999999,
        "id": 944,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4343.16,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51100,
          663,
          311,
          2489,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4344.799999999999,
        "id": 945,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4343.639999999999,
        "temperature": 0,
        "text": " I'm okay with that.",
        "tokens": [
          51124,
          286,
          478,
          1392,
          365,
          300,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4347.4,
        "id": 946,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4346.919999999999,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51288,
          467,
          311,
          2489,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4349.799999999999,
        "id": 947,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4349.04,
        "temperature": 0,
        "text": " Where was I?",
        "tokens": [
          51394,
          2305,
          390,
          286,
          30,
          51432
        ]
      },
      {
        "avg_logprob": -0.4158617184485918,
        "compression_ratio": 1.5602836879432624,
        "end": 4356.759999999999,
        "id": 948,
        "no_speech_prob": 0.0001823540951590985,
        "seek": 432844,
        "start": 4351.96,
        "temperature": 0,
        "text": " So I want to connect to the streaming API, and I want to connect to the user stream.",
        "tokens": [
          51540,
          407,
          286,
          528,
          281,
          1745,
          281,
          264,
          11791,
          9362,
          11,
          293,
          286,
          528,
          281,
          1745,
          281,
          264,
          4195,
          4309,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4362.68,
        "id": 949,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4356.84,
        "temperature": 0,
        "text": " Meaning any time I get any sort of notification, somebody favorites something, mentions me, reblogs me.",
        "tokens": [
          50368,
          19948,
          604,
          565,
          286,
          483,
          604,
          1333,
          295,
          11554,
          11,
          2618,
          16907,
          746,
          11,
          23844,
          385,
          11,
          12970,
          4987,
          82,
          385,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4365.52,
        "id": 950,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4363.360000000001,
        "temperature": 0,
        "text": " If I post something, I think I get an event.",
        "tokens": [
          50694,
          759,
          286,
          2183,
          746,
          11,
          286,
          519,
          286,
          483,
          364,
          2280,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4369.16,
        "id": 951,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4365.72,
        "temperature": 0,
        "text": " So the way that I do that is by saying m.stream.",
        "tokens": [
          50812,
          407,
          264,
          636,
          300,
          286,
          360,
          300,
          307,
          538,
          1566,
          275,
          13,
          9291,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4374.68,
        "id": 952,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4369.16,
        "temperature": 0,
        "text": " I have to go look it up here in this API.",
        "tokens": [
          50984,
          286,
          362,
          281,
          352,
          574,
          309,
          493,
          510,
          294,
          341,
          9362,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4377.56,
        "id": 953,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4374.92,
        "temperature": 0,
        "text": " m.stream path and parameters.",
        "tokens": [
          51272,
          275,
          13,
          9291,
          3100,
          293,
          9834,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4379.56,
        "id": 954,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4378.12,
        "temperature": 0,
        "text": " Return to stream listener instance.",
        "tokens": [
          51432,
          24350,
          281,
          4309,
          31569,
          5197,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4380.92,
        "id": 955,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4379.56,
        "temperature": 0,
        "text": " See examples on how to use it.",
        "tokens": [
          51504,
          3008,
          5110,
          322,
          577,
          281,
          764,
          309,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4382.16,
        "id": 956,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4381.360000000001,
        "temperature": 0,
        "text": " Okay, why not?",
        "tokens": [
          51594,
          1033,
          11,
          983,
          406,
          30,
          51634
        ]
      },
      {
        "avg_logprob": -0.29663800048828126,
        "compression_ratio": 1.6240601503759398,
        "end": 4386.16,
        "id": 957,
        "no_speech_prob": 0.0021489050704985857,
        "seek": 435676,
        "start": 4382.24,
        "temperature": 0,
        "text": " I've done this already in a previous video, so I could look at my previous code.",
        "tokens": [
          51638,
          286,
          600,
          1096,
          341,
          1217,
          294,
          257,
          3894,
          960,
          11,
          370,
          286,
          727,
          574,
          412,
          452,
          3894,
          3089,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4391.599999999999,
        "id": 958,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4386.44,
        "temperature": 0,
        "text": " But let's actually, sorry, let's just go to examples, streaming.js.",
        "tokens": [
          50378,
          583,
          718,
          311,
          767,
          11,
          2597,
          11,
          718,
          311,
          445,
          352,
          281,
          5110,
          11,
          11791,
          13,
          25530,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4392.5199999999995,
        "id": 959,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4391.599999999999,
        "temperature": 0,
        "text": " Oh, we can see that here.",
        "tokens": [
          50636,
          876,
          11,
          321,
          393,
          536,
          300,
          510,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4393.639999999999,
        "id": 960,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4392.76,
        "temperature": 0,
        "text": " So this is what I want to do.",
        "tokens": [
          50694,
          407,
          341,
          307,
          437,
          286,
          528,
          281,
          360,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4395.68,
        "id": 961,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4393.639999999999,
        "temperature": 0,
        "text": " I want to connect to the stream.",
        "tokens": [
          50738,
          286,
          528,
          281,
          1745,
          281,
          264,
          4309,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4398.5599999999995,
        "id": 962,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4396.76,
        "temperature": 0,
        "text": " Create a stream instance.",
        "tokens": [
          50894,
          20248,
          257,
          4309,
          5197,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4401.24,
        "id": 963,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4399.08,
        "temperature": 0,
        "text": " Right, connecting to streaming slash user.",
        "tokens": [
          51010,
          1779,
          11,
          11015,
          281,
          11791,
          17330,
          4195,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4406.12,
        "id": 964,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4401.48,
        "temperature": 0,
        "text": " And then on a particular event, like a notification.",
        "tokens": [
          51130,
          400,
          550,
          322,
          257,
          1729,
          2280,
          11,
          411,
          257,
          11554,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4407.16,
        "id": 965,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4406.4,
        "temperature": 0,
        "text": " Was that what it was?",
        "tokens": [
          51376,
          3027,
          300,
          437,
          309,
          390,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4408.599999999999,
        "id": 966,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4407.5599999999995,
        "temperature": 0,
        "text": " Oh no, just a message.",
        "tokens": [
          51434,
          876,
          572,
          11,
          445,
          257,
          3636,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.36095848083496096,
        "compression_ratio": 1.6289592760180995,
        "end": 4411.04,
        "id": 967,
        "no_speech_prob": 0.0015487397322431207,
        "seek": 438616,
        "start": 4408.88,
        "temperature": 0,
        "text": " So the event here is called message.",
        "tokens": [
          51500,
          407,
          264,
          2280,
          510,
          307,
          1219,
          3636,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2993454403347439,
        "compression_ratio": 1.6818181818181819,
        "end": 4417.76,
        "id": 968,
        "no_speech_prob": 0.0016484702937304974,
        "seek": 441104,
        "start": 4411.92,
        "temperature": 0,
        "text": " And then on a message, and this by the way, I've just been told from the chat,",
        "tokens": [
          50408,
          400,
          550,
          322,
          257,
          3636,
          11,
          293,
          341,
          538,
          264,
          636,
          11,
          286,
          600,
          445,
          668,
          1907,
          490,
          264,
          5081,
          11,
          50700
        ]
      },
      {
        "avg_logprob": -0.2993454403347439,
        "compression_ratio": 1.6818181818181819,
        "end": 4422.76,
        "id": 969,
        "no_speech_prob": 0.0016484702937304974,
        "seek": 441104,
        "start": 4417.76,
        "temperature": 0,
        "text": " thank you to Alka in the chat, that the streaming API doesn't support promises.",
        "tokens": [
          50700,
          1309,
          291,
          281,
          967,
          2330,
          294,
          264,
          5081,
          11,
          300,
          264,
          11791,
          9362,
          1177,
          380,
          1406,
          16403,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2993454403347439,
        "compression_ratio": 1.6818181818181819,
        "end": 4428.2,
        "id": 970,
        "no_speech_prob": 0.0016484702937304974,
        "seek": 441104,
        "start": 4422.96,
        "temperature": 0,
        "text": " So in this case, I do have to use a callback and I can say response.",
        "tokens": [
          50960,
          407,
          294,
          341,
          1389,
          11,
          286,
          360,
          362,
          281,
          764,
          257,
          818,
          3207,
          293,
          286,
          393,
          584,
          4134,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.2993454403347439,
        "compression_ratio": 1.6818181818181819,
        "end": 4431.64,
        "id": 971,
        "no_speech_prob": 0.0016484702937304974,
        "seek": 441104,
        "start": 4428.4,
        "temperature": 0,
        "text": " I like to use the word response like this.",
        "tokens": [
          51232,
          286,
          411,
          281,
          764,
          264,
          1349,
          4134,
          411,
          341,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.2993454403347439,
        "compression_ratio": 1.6818181818181819,
        "end": 4437.48,
        "id": 972,
        "no_speech_prob": 0.0016484702937304974,
        "seek": 441104,
        "start": 4432,
        "temperature": 0,
        "text": " So now here, anytime I get a response, I'm sorry, anytime there is a message,",
        "tokens": [
          51412,
          407,
          586,
          510,
          11,
          13038,
          286,
          483,
          257,
          4134,
          11,
          286,
          478,
          2597,
          11,
          13038,
          456,
          307,
          257,
          3636,
          11,
          51686
        ]
      },
      {
        "avg_logprob": -0.2993454403347439,
        "compression_ratio": 1.6818181818181819,
        "end": 4438.36,
        "id": 973,
        "no_speech_prob": 0.0016484702937304974,
        "seek": 441104,
        "start": 4437.6,
        "temperature": 0,
        "text": " what do I want to do?",
        "tokens": [
          51692,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51730
        ]
      },
      {
        "avg_logprob": -0.3884653854370117,
        "compression_ratio": 1.3383458646616542,
        "end": 4456.8,
        "id": 974,
        "no_speech_prob": 0.0001511808659415692,
        "seek": 444104,
        "start": 4441.04,
        "temperature": 0,
        "text": " You need a callback, not a promise.",
        "tokens": [
          50364,
          509,
          643,
          257,
          818,
          3207,
          11,
          406,
          257,
          6228,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.3884653854370117,
        "compression_ratio": 1.3383458646616542,
        "end": 4459.8,
        "id": 975,
        "no_speech_prob": 0.0001511808659415692,
        "seek": 444104,
        "start": 4456.92,
        "temperature": 0,
        "text": " Also, please stop separating dots with keywords.",
        "tokens": [
          51158,
          2743,
          11,
          1767,
          1590,
          29279,
          15026,
          365,
          21009,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.3884653854370117,
        "compression_ratio": 1.3383458646616542,
        "end": 4462.2,
        "id": 976,
        "no_speech_prob": 0.0001511808659415692,
        "seek": 444104,
        "start": 4461.24,
        "temperature": 0,
        "text": " I don't know what that means.",
        "tokens": [
          51374,
          286,
          500,
          380,
          458,
          437,
          300,
          1355,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.3884653854370117,
        "compression_ratio": 1.3383458646616542,
        "end": 4470.2,
        "id": 977,
        "no_speech_prob": 0.0001511808659415692,
        "seek": 444104,
        "start": 4467.16,
        "temperature": 0,
        "text": " Why the heck do you keep separating the dots from the keywords?",
        "tokens": [
          51670,
          1545,
          264,
          12872,
          360,
          291,
          1066,
          29279,
          264,
          15026,
          490,
          264,
          21009,
          30,
          51822
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4473.28,
        "id": 978,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4470.28,
        "temperature": 0,
        "text": " Oh yeah, that's when I put the dot, because I'm not used to this.",
        "tokens": [
          50368,
          876,
          1338,
          11,
          300,
          311,
          562,
          286,
          829,
          264,
          5893,
          11,
          570,
          286,
          478,
          406,
          1143,
          281,
          341,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4479.84,
        "id": 979,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4474.32,
        "temperature": 0,
        "text": " I programmed in like for like 15 years with all this JavaScript promises nonsense.",
        "tokens": [
          50570,
          286,
          31092,
          294,
          411,
          337,
          411,
          2119,
          924,
          365,
          439,
          341,
          15778,
          16403,
          14925,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4481,
        "id": 980,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4479.84,
        "temperature": 0,
        "text": " I'm learning, I'm learning.",
        "tokens": [
          50846,
          286,
          478,
          2539,
          11,
          286,
          478,
          2539,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4482.32,
        "id": 981,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4481,
        "temperature": 0,
        "text": " Give me a break here.",
        "tokens": [
          50904,
          5303,
          385,
          257,
          1821,
          510,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4483.48,
        "id": 982,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4482.32,
        "temperature": 0,
        "text": " I could be going home.",
        "tokens": [
          50970,
          286,
          727,
          312,
          516,
          1280,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4488.24,
        "id": 983,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4483.5199999999995,
        "temperature": 0,
        "text": " There's a baseball game starting in two hours that I intend to watch.",
        "tokens": [
          51030,
          821,
          311,
          257,
          14323,
          1216,
          2891,
          294,
          732,
          2496,
          300,
          286,
          19759,
          281,
          1159,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4489,
        "id": 984,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4488.639999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51286,
          1033,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4491.96,
        "id": 985,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4491.679999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51438,
          1057,
          558,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4496.04,
        "id": 986,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4491.96,
        "temperature": 0,
        "text": " So now I do want to look up my previous code because I need to figure out what I",
        "tokens": [
          51452,
          407,
          586,
          286,
          360,
          528,
          281,
          574,
          493,
          452,
          3894,
          3089,
          570,
          286,
          643,
          281,
          2573,
          484,
          437,
          286,
          51656
        ]
      },
      {
        "avg_logprob": -0.295386547178734,
        "compression_ratio": 1.6159420289855073,
        "end": 4499,
        "id": 987,
        "no_speech_prob": 0.000055621465435251594,
        "seek": 447020,
        "start": 4496.04,
        "temperature": 0,
        "text": " need to determine what I'm looking for in that response.",
        "tokens": [
          51656,
          643,
          281,
          6997,
          437,
          286,
          478,
          1237,
          337,
          294,
          300,
          4134,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.23619462986185094,
        "compression_ratio": 1.826086956521739,
        "end": 4503.72,
        "id": 988,
        "no_speech_prob": 0.00004832541890209541,
        "seek": 449900,
        "start": 4499,
        "temperature": 0,
        "text": " So I have that open here and you can see that what I'm doing here is if the event",
        "tokens": [
          50364,
          407,
          286,
          362,
          300,
          1269,
          510,
          293,
          291,
          393,
          536,
          300,
          437,
          286,
          478,
          884,
          510,
          307,
          498,
          264,
          2280,
          50600
        ]
      },
      {
        "avg_logprob": -0.23619462986185094,
        "compression_ratio": 1.826086956521739,
        "end": 4507.96,
        "id": 989,
        "no_speech_prob": 0.00004832541890209541,
        "seek": 449900,
        "start": 4504.12,
        "temperature": 0,
        "text": " is a notification and if it's a mention, that's what I'm looking for.",
        "tokens": [
          50620,
          307,
          257,
          11554,
          293,
          498,
          309,
          311,
          257,
          2152,
          11,
          300,
          311,
          437,
          286,
          478,
          1237,
          337,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.23619462986185094,
        "compression_ratio": 1.826086956521739,
        "end": 4509.32,
        "id": 990,
        "no_speech_prob": 0.00004832541890209541,
        "seek": 449900,
        "start": 4508.2,
        "temperature": 0,
        "text": " I'm looking for a mention.",
        "tokens": [
          50824,
          286,
          478,
          1237,
          337,
          257,
          2152,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.23619462986185094,
        "compression_ratio": 1.826086956521739,
        "end": 4519,
        "id": 991,
        "no_speech_prob": 0.00004832541890209541,
        "seek": 449900,
        "start": 4509.6,
        "temperature": 0,
        "text": " So I'm going to say if response.event equals notification, I'm just only going to do",
        "tokens": [
          50894,
          407,
          286,
          478,
          516,
          281,
          584,
          498,
          4134,
          13,
          68,
          2475,
          6915,
          11554,
          11,
          286,
          478,
          445,
          787,
          516,
          281,
          360,
          51364
        ]
      },
      {
        "avg_logprob": -0.23619462986185094,
        "compression_ratio": 1.826086956521739,
        "end": 4525.24,
        "id": 992,
        "no_speech_prob": 0.00004832541890209541,
        "seek": 449900,
        "start": 4519,
        "temperature": 0,
        "text": " mentions and response.data.type, I think, equals mention.",
        "tokens": [
          51364,
          23844,
          293,
          4134,
          13,
          67,
          3274,
          13,
          20467,
          11,
          286,
          519,
          11,
          6915,
          2152,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.23619462986185094,
        "compression_ratio": 1.826086956521739,
        "end": 4527.44,
        "id": 993,
        "no_speech_prob": 0.00004832541890209541,
        "seek": 449900,
        "start": 4526.76,
        "temperature": 0,
        "text": " Is that right?",
        "tokens": [
          51752,
          1119,
          300,
          558,
          30,
          51786
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4529.24,
        "id": 994,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4527.5199999999995,
        "temperature": 0,
        "text": " This would be just looking at my previous code.",
        "tokens": [
          50368,
          639,
          576,
          312,
          445,
          1237,
          412,
          452,
          3894,
          3089,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4530,
        "id": 995,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4529.48,
        "temperature": 0,
        "text": " Response.",
        "tokens": [
          50466,
          43937,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4531.36,
        "id": 996,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4530,
        "temperature": 0,
        "text": " Message.data.type.",
        "tokens": [
          50492,
          45947,
          13,
          67,
          3274,
          13,
          20467,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4533.44,
        "id": 997,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4532.36,
        "temperature": 0,
        "text": " Message.event.",
        "tokens": [
          50610,
          45947,
          13,
          68,
          2475,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4537.2,
        "id": 998,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4533.639999999999,
        "temperature": 0,
        "text": " So where is the mention in this one that I did?",
        "tokens": [
          50674,
          407,
          689,
          307,
          264,
          2152,
          294,
          341,
          472,
          300,
          286,
          630,
          30,
          50852
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4541.28,
        "id": 999,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4540.879999999999,
        "temperature": 0,
        "text": " Mention.",
        "tokens": [
          51036,
          376,
          1251,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4542.36,
        "id": 1000,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4541.28,
        "temperature": 0,
        "text": " Ah, message.data.",
        "tokens": [
          51056,
          2438,
          11,
          3636,
          13,
          67,
          3274,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4543.08,
        "id": 1001,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4542.36,
        "temperature": 0,
        "text": " It's right there.",
        "tokens": [
          51110,
          467,
          311,
          558,
          456,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4544.4,
        "id": 1002,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4543.24,
        "temperature": 0,
        "text": " Message.data.type.",
        "tokens": [
          51154,
          45947,
          13,
          67,
          3274,
          13,
          20467,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4546.36,
        "id": 1003,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4544.4,
        "temperature": 0,
        "text": " So I'm using different variable names, which is fine.",
        "tokens": [
          51212,
          407,
          286,
          478,
          1228,
          819,
          7006,
          5288,
          11,
          597,
          307,
          2489,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4553.679999999999,
        "id": 1004,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4546.599999999999,
        "temperature": 0,
        "text": " But if the event is a notification and the type of the event is a mention, then now I'm",
        "tokens": [
          51322,
          583,
          498,
          264,
          2280,
          307,
          257,
          11554,
          293,
          264,
          2010,
          295,
          264,
          2280,
          307,
          257,
          2152,
          11,
          550,
          586,
          286,
          478,
          51676
        ]
      },
      {
        "avg_logprob": -0.31638858032226563,
        "compression_ratio": 1.6814159292035398,
        "end": 4555.32,
        "id": 1005,
        "no_speech_prob": 0.0018102012109011412,
        "seek": 452744,
        "start": 4553.679999999999,
        "temperature": 0,
        "text": " ready to basically do this, right?",
        "tokens": [
          51676,
          1919,
          281,
          1936,
          360,
          341,
          11,
          558,
          30,
          51758
        ]
      },
      {
        "avg_logprob": -0.27109332706617273,
        "compression_ratio": 1.618279569892473,
        "end": 4558.759999999999,
        "id": 1006,
        "no_speech_prob": 0.00006922171451151371,
        "seek": 455532,
        "start": 4555.32,
        "temperature": 0,
        "text": " The idea is if I mentioned, go ahead and do this.",
        "tokens": [
          50364,
          440,
          1558,
          307,
          498,
          286,
          2835,
          11,
          352,
          2286,
          293,
          360,
          341,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.27109332706617273,
        "compression_ratio": 1.618279569892473,
        "end": 4561.92,
        "id": 1007,
        "no_speech_prob": 0.00006922171451151371,
        "seek": 455532,
        "start": 4558.759999999999,
        "temperature": 0,
        "text": " But, and I don't need a separate function for this.",
        "tokens": [
          50536,
          583,
          11,
          293,
          286,
          500,
          380,
          643,
          257,
          4994,
          2445,
          337,
          341,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.27109332706617273,
        "compression_ratio": 1.618279569892473,
        "end": 4566.759999999999,
        "id": 1008,
        "no_speech_prob": 0.00006922171451151371,
        "seek": 455532,
        "start": 4566.04,
        "temperature": 0,
        "text": " I can't use this.",
        "tokens": [
          50900,
          286,
          393,
          380,
          764,
          341,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.27109332706617273,
        "compression_ratio": 1.618279569892473,
        "end": 4570.08,
        "id": 1009,
        "no_speech_prob": 0.00006922171451151371,
        "seek": 455532,
        "start": 4568.5199999999995,
        "temperature": 0,
        "text": " So I'm just going to take this here.",
        "tokens": [
          51024,
          407,
          286,
          478,
          445,
          516,
          281,
          747,
          341,
          510,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.27109332706617273,
        "compression_ratio": 1.618279569892473,
        "end": 4575.759999999999,
        "id": 1010,
        "no_speech_prob": 0.00006922171451151371,
        "seek": 455532,
        "start": 4570.36,
        "temperature": 0,
        "text": " But what I want to do is I need to add some stuff to this.",
        "tokens": [
          51116,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          643,
          281,
          909,
          512,
          1507,
          281,
          341,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.27109332706617273,
        "compression_ratio": 1.618279569892473,
        "end": 4584.44,
        "id": 1011,
        "no_speech_prob": 0.00006922171451151371,
        "seek": 455532,
        "start": 4576.12,
        "temperature": 0,
        "text": " So, for example, I probably want to mention a user account and I want to have a reply",
        "tokens": [
          51404,
          407,
          11,
          337,
          1365,
          11,
          286,
          1391,
          528,
          281,
          2152,
          257,
          4195,
          2696,
          293,
          286,
          528,
          281,
          362,
          257,
          16972,
          51820
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4586.839999999999,
        "id": 1012,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4584.44,
        "temperature": 0,
        "text": " ID and also that angle.",
        "tokens": [
          50364,
          7348,
          293,
          611,
          300,
          5802,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4591.719999999999,
        "id": 1013,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4587,
        "temperature": 0,
        "text": " So I need to, if I'm going to reply, I want to at mention them.",
        "tokens": [
          50492,
          407,
          286,
          643,
          281,
          11,
          498,
          286,
          478,
          516,
          281,
          16972,
          11,
          286,
          528,
          281,
          412,
          2152,
          552,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4593.759999999999,
        "id": 1014,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4591.719999999999,
        "temperature": 0,
        "text": " So I need their account to reference.",
        "tokens": [
          50728,
          407,
          286,
          643,
          641,
          2696,
          281,
          6408,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4599.799999999999,
        "id": 1015,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4594.12,
        "temperature": 0,
        "text": " I also, if I want it to be threaded, I need the ID of that post so I can include that",
        "tokens": [
          50848,
          286,
          611,
          11,
          498,
          286,
          528,
          309,
          281,
          312,
          47493,
          11,
          286,
          643,
          264,
          7348,
          295,
          300,
          2183,
          370,
          286,
          393,
          4090,
          300,
          51132
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4601.2,
        "id": 1016,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4600,
        "temperature": 0,
        "text": " and then the angle I want.",
        "tokens": [
          51142,
          293,
          550,
          264,
          5802,
          286,
          528,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4603.32,
        "id": 1017,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4601.24,
        "temperature": 0,
        "text": " So now the angle shouldn't come.",
        "tokens": [
          51204,
          407,
          586,
          264,
          5802,
          4659,
          380,
          808,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4605.799999999999,
        "id": 1018,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4603.36,
        "temperature": 0,
        "text": " Oh, I've got to send the angle into processing.",
        "tokens": [
          51310,
          876,
          11,
          286,
          600,
          658,
          281,
          2845,
          264,
          5802,
          666,
          9007,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4606.44,
        "id": 1019,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4606.16,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51450,
          1057,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4608.16,
        "id": 1020,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4606.44,
        "temperature": 0,
        "text": " That's going to be something we have to figure out.",
        "tokens": [
          51464,
          663,
          311,
          516,
          281,
          312,
          746,
          321,
          362,
          281,
          2573,
          484,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4608.639999999999,
        "id": 1021,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4608.44,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4610.24,
        "id": 1022,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4608.799999999999,
        "temperature": 0,
        "text": " I'm going to get to that in a second.",
        "tokens": [
          51582,
          286,
          478,
          516,
          281,
          483,
          281,
          300,
          294,
          257,
          1150,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.2284364064534505,
        "compression_ratio": 1.7969924812030076,
        "end": 4612.839999999999,
        "id": 1023,
        "no_speech_prob": 0.0010987211717292666,
        "seek": 458444,
        "start": 4610.28,
        "temperature": 0,
        "text": " So let's try to get the whole flow of this working.",
        "tokens": [
          51656,
          407,
          718,
          311,
          853,
          281,
          483,
          264,
          1379,
          3095,
          295,
          341,
          1364,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4616.2,
        "id": 1024,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4613.52,
        "temperature": 0,
        "text": " This is an interesting problem that I completely forgot that I had to figure out.",
        "tokens": [
          50398,
          639,
          307,
          364,
          1880,
          1154,
          300,
          286,
          2584,
          5298,
          300,
          286,
          632,
          281,
          2573,
          484,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4622.88,
        "id": 1025,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4616.4400000000005,
        "temperature": 0,
        "text": " So first, let me get the ID is, and I did this before.",
        "tokens": [
          50544,
          407,
          700,
          11,
          718,
          385,
          483,
          264,
          7348,
          307,
          11,
          293,
          286,
          630,
          341,
          949,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4626,
        "id": 1026,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4622.88,
        "temperature": 0,
        "text": " So I'm just going to, we can see the ID is this.",
        "tokens": [
          50866,
          407,
          286,
          478,
          445,
          516,
          281,
          11,
          321,
          393,
          536,
          264,
          7348,
          307,
          341,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4629.84,
        "id": 1027,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4627.96,
        "temperature": 0,
        "text": " This is pulling the ID out of them.",
        "tokens": [
          51120,
          639,
          307,
          8407,
          264,
          7348,
          484,
          295,
          552,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4632.76,
        "id": 1028,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4629.88,
        "temperature": 0,
        "text": " And I said response instead of message, which is fine.",
        "tokens": [
          51216,
          400,
          286,
          848,
          4134,
          2602,
          295,
          3636,
          11,
          597,
          307,
          2489,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4635.68,
        "id": 1029,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4633.400000000001,
        "temperature": 0,
        "text": " And then the account name is right here.",
        "tokens": [
          51392,
          400,
          550,
          264,
          2696,
          1315,
          307,
          558,
          510,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4639.92,
        "id": 1030,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4636.400000000001,
        "temperature": 0,
        "text": " So I want to also get the account, which is also a response.",
        "tokens": [
          51542,
          407,
          286,
          528,
          281,
          611,
          483,
          264,
          2696,
          11,
          597,
          307,
          611,
          257,
          4134,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.253473328005883,
        "compression_ratio": 1.8025210084033614,
        "end": 4642.6,
        "id": 1031,
        "no_speech_prob": 0.00003321406984468922,
        "seek": 461284,
        "start": 4640.12,
        "temperature": 0,
        "text": " So I can then pass in the account, pass in the ID.",
        "tokens": [
          51728,
          407,
          286,
          393,
          550,
          1320,
          294,
          264,
          2696,
          11,
          1320,
          294,
          264,
          7348,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4644.400000000001,
        "id": 1032,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4642.6,
        "temperature": 0,
        "text": " Now the angle is a tricky one.",
        "tokens": [
          50364,
          823,
          264,
          5802,
          307,
          257,
          12414,
          472,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4647.160000000001,
        "id": 1033,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4645.04,
        "temperature": 0,
        "text": " So what am I expecting the person to say?",
        "tokens": [
          50486,
          407,
          437,
          669,
          286,
          9650,
          264,
          954,
          281,
          584,
          30,
          50592
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4651,
        "id": 1034,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4647.160000000001,
        "temperature": 0,
        "text": " I guess I'm expecting somewhere in their post that there's a number.",
        "tokens": [
          50592,
          286,
          2041,
          286,
          478,
          9650,
          4079,
          294,
          641,
          2183,
          300,
          456,
          311,
          257,
          1230,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4656.120000000001,
        "id": 1035,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4651.96,
        "temperature": 0,
        "text": " And they could put multiple numbers.",
        "tokens": [
          50832,
          400,
          436,
          727,
          829,
          3866,
          3547,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4657.6,
        "id": 1036,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4656.120000000001,
        "temperature": 0,
        "text": " I'm just going to pick the first number.",
        "tokens": [
          51040,
          286,
          478,
          445,
          516,
          281,
          1888,
          264,
          700,
          1230,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4661,
        "id": 1037,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4657.8,
        "temperature": 0,
        "text": " So what I'm going to do, whoops, this is by the way, my inspiration, the tree bot.",
        "tokens": [
          51124,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          567,
          3370,
          11,
          341,
          307,
          538,
          264,
          636,
          11,
          452,
          10249,
          11,
          264,
          4230,
          10592,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4662.04,
        "id": 1038,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4661.240000000001,
        "temperature": 0,
        "text": " But where am I?",
        "tokens": [
          51296,
          583,
          689,
          669,
          286,
          30,
          51336
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4663.08,
        "id": 1039,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4662.04,
        "temperature": 0,
        "text": " I'm looking at my code.",
        "tokens": [
          51336,
          286,
          478,
          1237,
          412,
          452,
          3089,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4665.88,
        "id": 1040,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4663.84,
        "temperature": 0,
        "text": " I need to get the content of what they've sent me.",
        "tokens": [
          51426,
          286,
          643,
          281,
          483,
          264,
          2701,
          295,
          437,
          436,
          600,
          2279,
          385,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4667.320000000001,
        "id": 1041,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4665.88,
        "temperature": 0,
        "text": " This is their message content.",
        "tokens": [
          51528,
          639,
          307,
          641,
          3636,
          2701,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.22638960763917748,
        "compression_ratio": 1.7173913043478262,
        "end": 4671.320000000001,
        "id": 1042,
        "no_speech_prob": 0.00000276939772447804,
        "seek": 464260,
        "start": 4668.84,
        "temperature": 0,
        "text": " So what I want to do is use a regular expression.",
        "tokens": [
          51676,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          764,
          257,
          3890,
          6114,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4676.08,
        "id": 1043,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4671.92,
        "temperature": 0,
        "text": " So my regular expression is going to be, I need to find a number.",
        "tokens": [
          50394,
          407,
          452,
          3890,
          6114,
          307,
          516,
          281,
          312,
          11,
          286,
          643,
          281,
          915,
          257,
          1230,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4679.679999999999,
        "id": 1044,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4676.36,
        "temperature": 0,
        "text": " The number that I want is between two and three digits.",
        "tokens": [
          50616,
          440,
          1230,
          300,
          286,
          528,
          307,
          1296,
          732,
          293,
          1045,
          27011,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4684.599999999999,
        "id": 1045,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4680.36,
        "temperature": 0,
        "text": " So I guess I'm going to allow, I mean, do I allow an angle greater than 90?",
        "tokens": [
          50816,
          407,
          286,
          2041,
          286,
          478,
          516,
          281,
          2089,
          11,
          286,
          914,
          11,
          360,
          286,
          2089,
          364,
          5802,
          5044,
          813,
          4289,
          30,
          51028
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4685.639999999999,
        "id": 1046,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4684.679999999999,
        "temperature": 0,
        "text": " I mean, sure.",
        "tokens": [
          51032,
          286,
          914,
          11,
          988,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4687.759999999999,
        "id": 1047,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4685.639999999999,
        "temperature": 0,
        "text": " I could actually, it could be any number.",
        "tokens": [
          51080,
          286,
          727,
          767,
          11,
          309,
          727,
          312,
          604,
          1230,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4688.84,
        "id": 1048,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4688.36,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51216,
          1779,
          30,
          51240
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4691.32,
        "id": 1049,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4689,
        "temperature": 0,
        "text": " I could really just say any number, doesn't matter how big.",
        "tokens": [
          51248,
          286,
          727,
          534,
          445,
          584,
          604,
          1230,
          11,
          1177,
          380,
          1871,
          577,
          955,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4693.759999999999,
        "id": 1050,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4692.16,
        "temperature": 0,
        "text": " So I want to match this.",
        "tokens": [
          51406,
          407,
          286,
          528,
          281,
          2995,
          341,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.26624195969949555,
        "compression_ratio": 1.7427385892116183,
        "end": 4700.599999999999,
        "id": 1051,
        "no_speech_prob": 0.000022125581381260417,
        "seek": 467132,
        "start": 4693.799999999999,
        "temperature": 0,
        "text": " And so if I say regular, oh, so if I say content.match regular expression,",
        "tokens": [
          51488,
          400,
          370,
          498,
          286,
          584,
          3890,
          11,
          1954,
          11,
          370,
          498,
          286,
          584,
          2701,
          13,
          76,
          852,
          3890,
          6114,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.24946547569112576,
        "compression_ratio": 1.6119402985074627,
        "end": 4704.4400000000005,
        "id": 1052,
        "no_speech_prob": 0.00007141885726014152,
        "seek": 470060,
        "start": 4700.84,
        "temperature": 0,
        "text": " is this, now I've forgotten how regular expressions work.",
        "tokens": [
          50376,
          307,
          341,
          11,
          586,
          286,
          600,
          11832,
          577,
          3890,
          15277,
          589,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.24946547569112576,
        "compression_ratio": 1.6119402985074627,
        "end": 4709.200000000001,
        "id": 1053,
        "no_speech_prob": 0.00007141885726014152,
        "seek": 470060,
        "start": 4704.76,
        "temperature": 0,
        "text": " So let's just go to the browser for a second and let's noodle around here.",
        "tokens": [
          50572,
          407,
          718,
          311,
          445,
          352,
          281,
          264,
          11185,
          337,
          257,
          1150,
          293,
          718,
          311,
          21873,
          926,
          510,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.24946547569112576,
        "compression_ratio": 1.6119402985074627,
        "end": 4714.68,
        "id": 1054,
        "no_speech_prob": 0.00007141885726014152,
        "seek": 470060,
        "start": 4709.360000000001,
        "temperature": 0,
        "text": " So let's say if I make a regular expression and I make it equal to this,",
        "tokens": [
          50802,
          407,
          718,
          311,
          584,
          498,
          286,
          652,
          257,
          3890,
          6114,
          293,
          286,
          652,
          309,
          2681,
          281,
          341,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.24946547569112576,
        "compression_ratio": 1.6119402985074627,
        "end": 4721.84,
        "id": 1055,
        "no_speech_prob": 0.00007141885726014152,
        "seek": 470060,
        "start": 4715.76,
        "temperature": 0,
        "text": " and then I have a string like, hello 42 goodbye.",
        "tokens": [
          51122,
          293,
          550,
          286,
          362,
          257,
          6798,
          411,
          11,
          7751,
          14034,
          12084,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.24946547569112576,
        "compression_ratio": 1.6119402985074627,
        "end": 4728.120000000001,
        "id": 1056,
        "no_speech_prob": 0.00007141885726014152,
        "seek": 470060,
        "start": 4723.240000000001,
        "temperature": 0,
        "text": " If I say s.match that regular expression, what do I get?",
        "tokens": [
          51496,
          759,
          286,
          584,
          262,
          13,
          76,
          852,
          300,
          3890,
          6114,
          11,
          437,
          360,
          286,
          483,
          30,
          51740
        ]
      },
      {
        "avg_logprob": -0.24946547569112576,
        "compression_ratio": 1.6119402985074627,
        "end": 4730.360000000001,
        "id": 1057,
        "no_speech_prob": 0.00007141885726014152,
        "seek": 470060,
        "start": 4729.08,
        "temperature": 0,
        "text": " Ah, perfect.",
        "tokens": [
          51788,
          2438,
          11,
          2176,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4733.599999999999,
        "id": 1058,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4730.5599999999995,
        "temperature": 0,
        "text": " I get what it matched, the index and some more information.",
        "tokens": [
          50374,
          286,
          483,
          437,
          309,
          21447,
          11,
          264,
          8186,
          293,
          512,
          544,
          1589,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4735.2,
        "id": 1059,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4733.639999999999,
        "temperature": 0,
        "text": " All it cares about is what it matched.",
        "tokens": [
          50528,
          1057,
          309,
          12310,
          466,
          307,
          437,
          309,
          21447,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4736.599999999999,
        "id": 1060,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4735.44,
        "temperature": 0,
        "text": " And I don't need it to be global.",
        "tokens": [
          50618,
          400,
          286,
          500,
          380,
          643,
          309,
          281,
          312,
          4338,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4737.88,
        "id": 1061,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4736.599999999999,
        "temperature": 0,
        "text": " I don't need to get all the numbers.",
        "tokens": [
          50676,
          286,
          500,
          380,
          643,
          281,
          483,
          439,
          264,
          3547,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4740.599999999999,
        "id": 1062,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4737.88,
        "temperature": 0,
        "text": " Like I could get all the numbers and average them or something, but I'm just",
        "tokens": [
          50740,
          1743,
          286,
          727,
          483,
          439,
          264,
          3547,
          293,
          4274,
          552,
          420,
          746,
          11,
          457,
          286,
          478,
          445,
          50876
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4741.36,
        "id": 1063,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4740.599999999999,
        "temperature": 0,
        "text": " going to get the first one.",
        "tokens": [
          50876,
          516,
          281,
          483,
          264,
          700,
          472,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4742.28,
        "id": 1064,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4741.4,
        "temperature": 0,
        "text": " So this is fine.",
        "tokens": [
          50916,
          407,
          341,
          307,
          2489,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4747.04,
        "id": 1065,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4742.599999999999,
        "temperature": 0,
        "text": " So then I'm going to, and I do have to deal with the fact, what if it doesn't",
        "tokens": [
          50976,
          407,
          550,
          286,
          478,
          516,
          281,
          11,
          293,
          286,
          360,
          362,
          281,
          2028,
          365,
          264,
          1186,
          11,
          437,
          498,
          309,
          1177,
          380,
          51198
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4747.639999999999,
        "id": 1066,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4747.04,
        "temperature": 0,
        "text": " match anything?",
        "tokens": [
          51198,
          2995,
          1340,
          30,
          51228
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4749.759999999999,
        "id": 1067,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4747.679999999999,
        "temperature": 0,
        "text": " So let's see what it gives me if it doesn't match.",
        "tokens": [
          51230,
          407,
          718,
          311,
          536,
          437,
          309,
          2709,
          385,
          498,
          309,
          1177,
          380,
          2995,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4754.48,
        "id": 1068,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4749.92,
        "temperature": 0,
        "text": " So let's say s equals this, and I'm going to say s match regular expression.",
        "tokens": [
          51342,
          407,
          718,
          311,
          584,
          262,
          6915,
          341,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          262,
          2995,
          3890,
          6114,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4754.799999999999,
        "id": 1069,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4754.5199999999995,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51572,
          883,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.22001738664580556,
        "compression_ratio": 1.924187725631769,
        "end": 4755.5199999999995,
        "id": 1070,
        "no_speech_prob": 0.00003219218706362881,
        "seek": 473036,
        "start": 4754.839999999999,
        "temperature": 0,
        "text": " So that's fine.",
        "tokens": [
          51588,
          407,
          300,
          311,
          2489,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.34012838091169084,
        "compression_ratio": 1.644736842105263,
        "end": 4763.84,
        "id": 1071,
        "no_speech_prob": 0.00032503437250852585,
        "seek": 475552,
        "start": 4755.88,
        "temperature": 0,
        "text": " So now I'm going to say results equals content match regular expression and the",
        "tokens": [
          50382,
          407,
          586,
          286,
          478,
          516,
          281,
          584,
          3542,
          6915,
          2701,
          2995,
          3890,
          6114,
          293,
          264,
          50780
        ]
      },
      {
        "avg_logprob": -0.34012838091169084,
        "compression_ratio": 1.644736842105263,
        "end": 4764.8,
        "id": 1072,
        "no_speech_prob": 0.00032503437250852585,
        "seek": 475552,
        "start": 4763.88,
        "temperature": 0,
        "text": " angle.",
        "tokens": [
          50782,
          5802,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.34012838091169084,
        "compression_ratio": 1.644736842105263,
        "end": 4769.72,
        "id": 1073,
        "no_speech_prob": 0.00032503437250852585,
        "seek": 475552,
        "start": 4765.040000000001,
        "temperature": 0,
        "text": " So I'm going to say if results, or I could, if results, I could probably use",
        "tokens": [
          50840,
          407,
          286,
          478,
          516,
          281,
          584,
          498,
          3542,
          11,
          420,
          286,
          727,
          11,
          498,
          3542,
          11,
          286,
          727,
          1391,
          764,
          51074
        ]
      },
      {
        "avg_logprob": -0.34012838091169084,
        "compression_ratio": 1.644736842105263,
        "end": 4770.8,
        "id": 1074,
        "no_speech_prob": 0.00032503437250852585,
        "seek": 475552,
        "start": 4769.72,
        "temperature": 0,
        "text": " that ternary thing.",
        "tokens": [
          51074,
          300,
          256,
          1248,
          822,
          551,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.34012838091169084,
        "compression_ratio": 1.644736842105263,
        "end": 4778.400000000001,
        "id": 1075,
        "no_speech_prob": 0.00032503437250852585,
        "seek": 475552,
        "start": 4771,
        "temperature": 0,
        "text": " Then the angle equals results index zero.",
        "tokens": [
          51138,
          1396,
          264,
          5802,
          6915,
          3542,
          8186,
          4018,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.34012838091169084,
        "compression_ratio": 1.644736842105263,
        "end": 4784.200000000001,
        "id": 1076,
        "no_speech_prob": 0.00032503437250852585,
        "seek": 475552,
        "start": 4779.4400000000005,
        "temperature": 0,
        "text": " Otherwise, angle equals.",
        "tokens": [
          51560,
          10328,
          11,
          5802,
          6915,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4786.04,
        "id": 1077,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4784.36,
        "temperature": 0,
        "text": " Oh, otherwise I'm going to say there's no angle.",
        "tokens": [
          50372,
          876,
          11,
          5911,
          286,
          478,
          516,
          281,
          584,
          456,
          311,
          572,
          5802,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4789.08,
        "id": 1078,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4786.08,
        "temperature": 0,
        "text": " I could reply and say you need to, you need to, you need to mention me with a",
        "tokens": [
          50458,
          286,
          727,
          16972,
          293,
          584,
          291,
          643,
          281,
          11,
          291,
          643,
          281,
          11,
          291,
          643,
          281,
          2152,
          385,
          365,
          257,
          50608
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4789.48,
        "id": 1079,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4789.08,
        "temperature": 0,
        "text": " number.",
        "tokens": [
          50608,
          1230,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4797.5599999999995,
        "id": 1080,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4789.5199999999995,
        "temperature": 0,
        "text": " So I'll, so I'm actually going to just say, yeah, angle equals negative one.",
        "tokens": [
          50630,
          407,
          286,
          603,
          11,
          370,
          286,
          478,
          767,
          516,
          281,
          445,
          584,
          11,
          1338,
          11,
          5802,
          6915,
          3671,
          472,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4804.5199999999995,
        "id": 1081,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4799.4,
        "temperature": 0,
        "text": " So I'm going to use negative one as like a, and I can actually just do this.",
        "tokens": [
          51124,
          407,
          286,
          478,
          516,
          281,
          764,
          3671,
          472,
          382,
          411,
          257,
          11,
          293,
          286,
          393,
          767,
          445,
          360,
          341,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4808.76,
        "id": 1082,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4807.679999999999,
        "temperature": 0,
        "text": " And then do this.",
        "tokens": [
          51538,
          400,
          550,
          360,
          341,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4809.36,
        "id": 1083,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4808.8,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          51594,
          1033,
          11,
          869,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4809.48,
        "id": 1084,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4809.36,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51622,
          3769,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4809.639999999999,
        "id": 1085,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4809.48,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51628,
          3769,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4809.88,
        "id": 1086,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4809.639999999999,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          51636,
          3769,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2857524629623171,
        "compression_ratio": 1.813953488372093,
        "end": 4813.679999999999,
        "id": 1087,
        "no_speech_prob": 0.000005594327376456931,
        "seek": 478420,
        "start": 4810.5199999999995,
        "temperature": 0,
        "text": " So now in theory, now I can pass that angle here.",
        "tokens": [
          51680,
          407,
          586,
          294,
          5261,
          11,
          586,
          286,
          393,
          1320,
          300,
          5802,
          510,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.27568800184461806,
        "compression_ratio": 1.5875706214689265,
        "end": 4818.2,
        "id": 1088,
        "no_speech_prob": 0.000010451541129441466,
        "seek": 481420,
        "start": 4815.2,
        "temperature": 0,
        "text": " So, all right, now one thing I can do, let's just do this.",
        "tokens": [
          50414,
          407,
          11,
          439,
          558,
          11,
          586,
          472,
          551,
          286,
          393,
          360,
          11,
          718,
          311,
          445,
          360,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.27568800184461806,
        "compression_ratio": 1.5875706214689265,
        "end": 4824.92,
        "id": 1089,
        "no_speech_prob": 0.000010451541129441466,
        "seek": 481420,
        "start": 4819.679999999999,
        "temperature": 0,
        "text": " So if the first thing I want to do is just say, if angle equals negative one,",
        "tokens": [
          50638,
          407,
          498,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          307,
          445,
          584,
          11,
          498,
          5802,
          6915,
          3671,
          472,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.27568800184461806,
        "compression_ratio": 1.5875706214689265,
        "end": 4825.96,
        "id": 1090,
        "no_speech_prob": 0.000010451541129441466,
        "seek": 481420,
        "start": 4825.5599999999995,
        "temperature": 0,
        "text": " right?",
        "tokens": [
          50932,
          558,
          30,
          50952
        ]
      },
      {
        "avg_logprob": -0.27568800184461806,
        "compression_ratio": 1.5875706214689265,
        "end": 4833.4,
        "id": 1091,
        "no_speech_prob": 0.000010451541129441466,
        "seek": 481420,
        "start": 4826.2,
        "temperature": 0,
        "text": " If I've gotten a negative one angle, I want to actually just be done.",
        "tokens": [
          50964,
          759,
          286,
          600,
          5768,
          257,
          3671,
          472,
          5802,
          11,
          286,
          528,
          281,
          767,
          445,
          312,
          1096,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.27568800184461806,
        "compression_ratio": 1.5875706214689265,
        "end": 4838.12,
        "id": 1092,
        "no_speech_prob": 0.000010451541129441466,
        "seek": 481420,
        "start": 4834.5199999999995,
        "temperature": 0,
        "text": " Like I want to say, um, oh, but I have to mention the person.",
        "tokens": [
          51380,
          1743,
          286,
          528,
          281,
          584,
          11,
          1105,
          11,
          1954,
          11,
          457,
          286,
          362,
          281,
          2152,
          264,
          954,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.27568800184461806,
        "compression_ratio": 1.5875706214689265,
        "end": 4838.4,
        "id": 1093,
        "no_speech_prob": 0.000010451541129441466,
        "seek": 481420,
        "start": 4838.16,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51562,
          1033,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4844.5199999999995,
        "id": 1094,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4838.5199999999995,
        "temperature": 0,
        "text": " So I have to say, uh, if in a status post, can I find that here?",
        "tokens": [
          50370,
          407,
          286,
          362,
          281,
          584,
          11,
          2232,
          11,
          498,
          294,
          257,
          6558,
          2183,
          11,
          393,
          286,
          915,
          300,
          510,
          30,
          50670
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4845.719999999999,
        "id": 1095,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4845.32,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50710,
          1057,
          558,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4850.16,
        "id": 1096,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4845.799999999999,
        "temperature": 0,
        "text": " So the text of the status, you can see this text of status in reply to ID.",
        "tokens": [
          50734,
          407,
          264,
          2487,
          295,
          264,
          6558,
          11,
          291,
          393,
          536,
          341,
          2487,
          295,
          6558,
          294,
          16972,
          281,
          7348,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4851.24,
        "id": 1097,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4850.48,
        "temperature": 0,
        "text": " So this is important.",
        "tokens": [
          50968,
          407,
          341,
          307,
          1021,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4864.759999999999,
        "id": 1098,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4851.24,
        "temperature": 0,
        "text": " So I'm going to say, um, uh, please specify an angle in degrees using digits.",
        "tokens": [
          51006,
          407,
          286,
          478,
          516,
          281,
          584,
          11,
          1105,
          11,
          2232,
          11,
          1767,
          16500,
          364,
          5802,
          294,
          5310,
          1228,
          27011,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4865.759999999999,
        "id": 1099,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4865.16,
        "temperature": 0,
        "text": " Cause it won't work.",
        "tokens": [
          51702,
          10865,
          309,
          1582,
          380,
          589,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.30273788853695516,
        "compression_ratio": 1.4974358974358974,
        "end": 4867.12,
        "id": 1100,
        "no_speech_prob": 0.0008693645359016955,
        "seek": 483840,
        "start": 4865.759999999999,
        "temperature": 0,
        "text": " You say the word 90.",
        "tokens": [
          51732,
          509,
          584,
          264,
          1349,
          4289,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.24997445578887084,
        "compression_ratio": 1.776536312849162,
        "end": 4877.28,
        "id": 1101,
        "no_speech_prob": 0.0000023320646960200975,
        "seek": 486712,
        "start": 4867.4,
        "temperature": 0,
        "text": " Then I need to say, uh, uh, in reply, what is it in reply to ID in reply to ID is",
        "tokens": [
          50378,
          1396,
          286,
          643,
          281,
          584,
          11,
          2232,
          11,
          2232,
          11,
          294,
          16972,
          11,
          437,
          307,
          309,
          294,
          16972,
          281,
          7348,
          294,
          16972,
          281,
          7348,
          307,
          50872
        ]
      },
      {
        "avg_logprob": -0.24997445578887084,
        "compression_ratio": 1.776536312849162,
        "end": 4878.64,
        "id": 1102,
        "no_speech_prob": 0.0000023320646960200975,
        "seek": 486712,
        "start": 4877.28,
        "temperature": 0,
        "text": " that reply ID.",
        "tokens": [
          50872,
          300,
          16972,
          7348,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.24997445578887084,
        "compression_ratio": 1.776536312849162,
        "end": 4884.44,
        "id": 1103,
        "no_speech_prob": 0.0000023320646960200975,
        "seek": 486712,
        "start": 4879.68,
        "temperature": 0,
        "text": " And then also, um, I, I want to use their, the account.",
        "tokens": [
          50992,
          400,
          550,
          611,
          11,
          1105,
          11,
          286,
          11,
          286,
          528,
          281,
          764,
          641,
          11,
          264,
          2696,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.24997445578887084,
        "compression_ratio": 1.776536312849162,
        "end": 4888.8,
        "id": 1104,
        "no_speech_prob": 0.0000023320646960200975,
        "seek": 486712,
        "start": 4884.44,
        "temperature": 0,
        "text": " So I'm going to, uh, I want to start with the account, uh, account.",
        "tokens": [
          51230,
          407,
          286,
          478,
          516,
          281,
          11,
          2232,
          11,
          286,
          528,
          281,
          722,
          365,
          264,
          2696,
          11,
          2232,
          11,
          2696,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.24997445578887084,
        "compression_ratio": 1.776536312849162,
        "end": 4894.44,
        "id": 1105,
        "no_speech_prob": 0.0000023320646960200975,
        "seek": 486712,
        "start": 4888.92,
        "temperature": 0,
        "text": " Uh, and do I say at, I think I have to say at the account, uh, please specify",
        "tokens": [
          51454,
          4019,
          11,
          293,
          360,
          286,
          584,
          412,
          11,
          286,
          519,
          286,
          362,
          281,
          584,
          412,
          264,
          2696,
          11,
          2232,
          11,
          1767,
          16500,
          51730
        ]
      },
      {
        "avg_logprob": -0.24997445578887084,
        "compression_ratio": 1.776536312849162,
        "end": 4895.48,
        "id": 1106,
        "no_speech_prob": 0.0000023320646960200975,
        "seek": 486712,
        "start": 4894.44,
        "temperature": 0,
        "text": " an angle in digits.",
        "tokens": [
          51730,
          364,
          5802,
          294,
          27011,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4897.5199999999995,
        "id": 1107,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4896.48,
        "temperature": 0,
        "text": " Then in reply to ID.",
        "tokens": [
          50414,
          1396,
          294,
          16972,
          281,
          7348,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4897.879999999999,
        "id": 1108,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4897.5599999999995,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50468,
          1033,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4904.12,
        "id": 1109,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4898.24,
        "temperature": 0,
        "text": " So this is good and I'll call this, uh, and then I'm going to say, uh, uh,",
        "tokens": [
          50502,
          407,
          341,
          307,
          665,
          293,
          286,
          603,
          818,
          341,
          11,
          2232,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          2232,
          11,
          2232,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4911.16,
        "id": 1110,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4904.12,
        "temperature": 0,
        "text": " response, um, let's say params and response and, uh, success angle negative",
        "tokens": [
          50796,
          4134,
          11,
          1105,
          11,
          718,
          311,
          584,
          971,
          4070,
          293,
          4134,
          293,
          11,
          2232,
          11,
          2245,
          5802,
          3671,
          51148
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4911.4,
        "id": 1111,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4911.16,
        "temperature": 0,
        "text": " one.",
        "tokens": [
          51148,
          472,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4911.959999999999,
        "id": 1112,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4911.679999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51174,
          1033,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4919.599999999999,
        "id": 1113,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4912.4,
        "temperature": 0,
        "text": " So this now should, if I run this and you, and then I'm going to put an else",
        "tokens": [
          51210,
          407,
          341,
          586,
          820,
          11,
          498,
          286,
          1190,
          341,
          293,
          291,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          829,
          364,
          1646,
          51570
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4920.04,
        "id": 1114,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4919.599999999999,
        "temperature": 0,
        "text": " here.",
        "tokens": [
          51570,
          510,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.2909124429943492,
        "compression_ratio": 1.6296296296296295,
        "end": 4924.4,
        "id": 1115,
        "no_speech_prob": 0.000027969204893452115,
        "seek": 489548,
        "start": 4922.44,
        "temperature": 0,
        "text": " This function has gotten quite long.",
        "tokens": [
          51712,
          639,
          2445,
          575,
          5768,
          1596,
          938,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4930.28,
        "id": 1116,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4926.08,
        "temperature": 0,
        "text": " But basically what I'm doing is first I'm checking if there was a legitimate",
        "tokens": [
          50394,
          583,
          1936,
          437,
          286,
          478,
          884,
          307,
          700,
          286,
          478,
          8568,
          498,
          456,
          390,
          257,
          17956,
          50604
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4930.719999999999,
        "id": 1117,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4930.28,
        "temperature": 0,
        "text": " angle.",
        "tokens": [
          50604,
          5802,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4934.4,
        "id": 1118,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4930.959999999999,
        "temperature": 0,
        "text": " And if there wasn't, I'm replying back to say, please specify an angle in",
        "tokens": [
          50638,
          400,
          498,
          456,
          2067,
          380,
          11,
          286,
          478,
          1085,
          7310,
          646,
          281,
          584,
          11,
          1767,
          16500,
          364,
          5802,
          294,
          50810
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4935.04,
        "id": 1119,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4934.4,
        "temperature": 0,
        "text": " degrees.",
        "tokens": [
          50810,
          5310,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4937.5199999999995,
        "id": 1120,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4935.5199999999995,
        "temperature": 0,
        "text": " And then, uh, let's see how that goes.",
        "tokens": [
          50866,
          400,
          550,
          11,
          2232,
          11,
          718,
          311,
          536,
          577,
          300,
          1709,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4939.28,
        "id": 1121,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4937.5199999999995,
        "temperature": 0,
        "text": " So right now, if I run this bot.",
        "tokens": [
          50966,
          407,
          558,
          586,
          11,
          498,
          286,
          1190,
          341,
          10592,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4942.5599999999995,
        "id": 1122,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4941.12,
        "temperature": 0,
        "text": " Oh, I forgot to make a new one.",
        "tokens": [
          51146,
          876,
          11,
          286,
          5298,
          281,
          652,
          257,
          777,
          472,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4943,
        "id": 1123,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4942.5599999999995,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51218,
          663,
          311,
          2489,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4947.4,
        "id": 1124,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4943,
        "temperature": 0,
        "text": " I'll have to, if I run this bot, somebody should feel free to at mention me",
        "tokens": [
          51240,
          286,
          603,
          362,
          281,
          11,
          498,
          286,
          1190,
          341,
          10592,
          11,
          2618,
          820,
          841,
          1737,
          281,
          412,
          2152,
          385,
          51460
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4949.48,
        "id": 1125,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4948.24,
        "temperature": 0,
        "text": " without a digit.",
        "tokens": [
          51502,
          1553,
          257,
          14293,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.32566379937599965,
        "compression_ratio": 1.6071428571428572,
        "end": 4951.36,
        "id": 1126,
        "no_speech_prob": 0.000012606919881363865,
        "seek": 492548,
        "start": 4950.04,
        "temperature": 0,
        "text": " Can somebody do that please?",
        "tokens": [
          51592,
          1664,
          2618,
          360,
          300,
          1767,
          30,
          51658
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4963.28,
        "id": 1127,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4955.48,
        "temperature": 0,
        "text": " I'm looking at the chat.",
        "tokens": [
          50364,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4964.679999999999,
        "id": 1128,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4963.28,
        "temperature": 0,
        "text": " I'm taking a break for a second.",
        "tokens": [
          50754,
          286,
          478,
          1940,
          257,
          1821,
          337,
          257,
          1150,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4965.799999999999,
        "id": 1129,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4964.719999999999,
        "temperature": 0,
        "text": " This will get edited out.",
        "tokens": [
          50826,
          639,
          486,
          483,
          23016,
          484,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4969.719999999999,
        "id": 1130,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4969.44,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51062,
          1033,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4970.4,
        "id": 1131,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4969.719999999999,
        "temperature": 0,
        "text": " I got an error.",
        "tokens": [
          51076,
          286,
          658,
          364,
          6713,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4971.44,
        "id": 1132,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4970.879999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51134,
          1033,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4974,
        "id": 1133,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4973.679999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51274,
          1057,
          558,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4975.4,
        "id": 1134,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4974,
        "temperature": 0,
        "text": " Somebody at messaged me.",
        "tokens": [
          51290,
          13463,
          412,
          2082,
          2980,
          385,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4977.919999999999,
        "id": 1135,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4975.4,
        "temperature": 0,
        "text": " Thank you for helping me debug this.",
        "tokens": [
          51360,
          1044,
          291,
          337,
          4315,
          385,
          24083,
          341,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4981.44,
        "id": 1136,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4978.12,
        "temperature": 0,
        "text": " And I got an error in bot.js line 25.",
        "tokens": [
          51496,
          400,
          286,
          658,
          364,
          6713,
          294,
          10592,
          13,
          25530,
          1622,
          3552,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.34323707156711153,
        "compression_ratio": 1.460122699386503,
        "end": 4983.839999999999,
        "id": 1137,
        "no_speech_prob": 0.00023781378695275635,
        "seek": 495548,
        "start": 4981.759999999999,
        "temperature": 0,
        "text": " Bot.js line 25.",
        "tokens": [
          51678,
          25486,
          13,
          25530,
          1622,
          3552,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4987.6,
        "id": 1138,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4984.28,
        "temperature": 0,
        "text": " Ah, response, response, response.",
        "tokens": [
          50386,
          2438,
          11,
          4134,
          11,
          4134,
          11,
          4134,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4988.68,
        "id": 1139,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4987.64,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50554,
          4919,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4990.400000000001,
        "id": 1140,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4988.92,
        "temperature": 0,
        "text": " Response, response.",
        "tokens": [
          50618,
          43937,
          11,
          4134,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4990.6,
        "id": 1141,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4990.4400000000005,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50694,
          1057,
          558,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4991.4800000000005,
        "id": 1142,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4990.6,
        "temperature": 0,
        "text": " Let's try this again.",
        "tokens": [
          50702,
          961,
          311,
          853,
          341,
          797,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4992.68,
        "id": 1143,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4991.72,
        "temperature": 0,
        "text": " Be prepared.",
        "tokens": [
          50758,
          879,
          4927,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4994.64,
        "id": 1144,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4994.4400000000005,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50894,
          1057,
          558,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4996.64,
        "id": 1145,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4994.64,
        "temperature": 0,
        "text": " At mention me with no number, please.",
        "tokens": [
          50904,
          1711,
          2152,
          385,
          365,
          572,
          1230,
          11,
          1767,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4999.2,
        "id": 1146,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4996.72,
        "temperature": 0,
        "text": " You can put a number in it, but it won't work if you put a number in it.",
        "tokens": [
          51008,
          509,
          393,
          829,
          257,
          1230,
          294,
          309,
          11,
          457,
          309,
          1582,
          380,
          589,
          498,
          291,
          829,
          257,
          1230,
          294,
          309,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 4999.76,
        "id": 1147,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 4999.400000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51142,
          1057,
          558,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5001.08,
        "id": 1148,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5000.56,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51200,
          7951,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5002.64,
        "id": 1149,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5001.92,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51268,
          14711,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5004.04,
        "id": 1150,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5003.32,
        "temperature": 0,
        "text": " Someone please.",
        "tokens": [
          51338,
          8734,
          1767,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5004.68,
        "id": 1151,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5004.12,
        "temperature": 0,
        "text": " Oh, there we go.",
        "tokens": [
          51378,
          876,
          11,
          456,
          321,
          352,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5005.12,
        "id": 1152,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5004.72,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51408,
          1033,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5006.28,
        "id": 1153,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5005.400000000001,
        "temperature": 0,
        "text": " So let's take a look.",
        "tokens": [
          51442,
          407,
          718,
          311,
          747,
          257,
          574,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5008.12,
        "id": 1154,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5006.52,
        "temperature": 0,
        "text": " So someone mentioned me with a number.",
        "tokens": [
          51498,
          407,
          1580,
          2835,
          385,
          365,
          257,
          1230,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.3279237950101812,
        "compression_ratio": 1.811659192825112,
        "end": 5010,
        "id": 1155,
        "no_speech_prob": 0.0004172910994384438,
        "seek": 498384,
        "start": 5008.12,
        "temperature": 0,
        "text": " That's great that we had both of those tested.",
        "tokens": [
          51578,
          663,
          311,
          869,
          300,
          321,
          632,
          1293,
          295,
          729,
          8246,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.22717267274856567,
        "compression_ratio": 1.6391752577319587,
        "end": 5016.12,
        "id": 1156,
        "no_speech_prob": 0.0022518218029290438,
        "seek": 501000,
        "start": 5010.48,
        "temperature": 0,
        "text": " Um, and we can see this one, uh, said, please specify an angle in degrees and digits.",
        "tokens": [
          50388,
          3301,
          11,
          293,
          321,
          393,
          536,
          341,
          472,
          11,
          2232,
          11,
          848,
          11,
          1767,
          16500,
          364,
          5802,
          294,
          5310,
          293,
          27011,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.22717267274856567,
        "compression_ratio": 1.6391752577319587,
        "end": 5016.76,
        "id": 1157,
        "no_speech_prob": 0.0022518218029290438,
        "seek": 501000,
        "start": 5016.12,
        "temperature": 0,
        "text": " That's right.",
        "tokens": [
          50670,
          663,
          311,
          558,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.22717267274856567,
        "compression_ratio": 1.6391752577319587,
        "end": 5020.6,
        "id": 1158,
        "no_speech_prob": 0.0022518218029290438,
        "seek": 501000,
        "start": 5017,
        "temperature": 0,
        "text": " And then this one, uh, just said, behold my beautiful tree.",
        "tokens": [
          50714,
          400,
          550,
          341,
          472,
          11,
          2232,
          11,
          445,
          848,
          11,
          27234,
          452,
          2238,
          4230,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.22717267274856567,
        "compression_ratio": 1.6391752577319587,
        "end": 5023.08,
        "id": 1159,
        "no_speech_prob": 0.0022518218029290438,
        "seek": 501000,
        "start": 5020.64,
        "temperature": 0,
        "text": " So I haven't done the thing where I actually get the angle.",
        "tokens": [
          50896,
          407,
          286,
          2378,
          380,
          1096,
          264,
          551,
          689,
          286,
          767,
          483,
          264,
          5802,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.22717267274856567,
        "compression_ratio": 1.6391752577319587,
        "end": 5033,
        "id": 1160,
        "no_speech_prob": 0.0022518218029290438,
        "seek": 501000,
        "start": 5023.4,
        "temperature": 0,
        "text": " So let's, let's first, let's just first, if I really do get an angle, let's do all the same steps.",
        "tokens": [
          51034,
          407,
          718,
          311,
          11,
          718,
          311,
          700,
          11,
          718,
          311,
          445,
          700,
          11,
          498,
          286,
          534,
          360,
          483,
          364,
          5802,
          11,
          718,
          311,
          360,
          439,
          264,
          912,
          4439,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5040.4,
        "id": 1161,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5033.48,
        "temperature": 0,
        "text": " But right now I'm going to also add, uh, at account.",
        "tokens": [
          50388,
          583,
          558,
          586,
          286,
          478,
          516,
          281,
          611,
          909,
          11,
          2232,
          11,
          412,
          2696,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5051.04,
        "id": 1162,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5040.44,
        "temperature": 0,
        "text": " So I'm going to mention that account, uh, with angle, and then I'm going to use, uh, the angle that they asked for.",
        "tokens": [
          50736,
          407,
          286,
          478,
          516,
          281,
          2152,
          300,
          2696,
          11,
          2232,
          11,
          365,
          5802,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          764,
          11,
          2232,
          11,
          264,
          5802,
          300,
          436,
          2351,
          337,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5056.96,
        "id": 1163,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5052.52,
        "temperature": 0,
        "text": " And then, so this, and I need in reply ID in, what was it?",
        "tokens": [
          51340,
          400,
          550,
          11,
          370,
          341,
          11,
          293,
          286,
          643,
          294,
          16972,
          7348,
          294,
          11,
          437,
          390,
          309,
          30,
          51562
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5060.2,
        "id": 1164,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5056.96,
        "temperature": 0,
        "text": " In reply, same thing in reply to ID.",
        "tokens": [
          51562,
          682,
          16972,
          11,
          912,
          551,
          294,
          16972,
          281,
          7348,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5061.88,
        "id": 1165,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5061.44,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51786,
          2305,
          307,
          300,
          30,
          51808
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5062.32,
        "id": 1166,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5061.88,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51808,
          2305,
          307,
          300,
          30,
          51830
        ]
      },
      {
        "avg_logprob": -0.26030631112580255,
        "compression_ratio": 1.7965116279069768,
        "end": 5062.84,
        "id": 1167,
        "no_speech_prob": 0.02556423470377922,
        "seek": 503300,
        "start": 5062.32,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51830,
          2305,
          307,
          300,
          30,
          51856
        ]
      },
      {
        "avg_logprob": -0.25773107244613325,
        "compression_ratio": 1.6313131313131313,
        "end": 5063.68,
        "id": 1168,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 506300,
        "start": 5063.16,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50372,
          1692,
          321,
          352,
          13,
          50398
        ]
      },
      {
        "avg_logprob": -0.25773107244613325,
        "compression_ratio": 1.6313131313131313,
        "end": 5065.48,
        "id": 1169,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 506300,
        "start": 5064.16,
        "temperature": 0,
        "text": " In reply to ID.",
        "tokens": [
          50422,
          682,
          16972,
          281,
          7348,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.25773107244613325,
        "compression_ratio": 1.6313131313131313,
        "end": 5066.6,
        "id": 1170,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 506300,
        "start": 5066.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50532,
          1033,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.25773107244613325,
        "compression_ratio": 1.6313131313131313,
        "end": 5081.52,
        "id": 1171,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 506300,
        "start": 5066.92,
        "temperature": 0,
        "text": " So now if I run this one more time, you can now at mention me with an angle and you'll get a tree back, or you can at mention me with no angle and you will get a message back saying you need an angle.",
        "tokens": [
          50560,
          407,
          586,
          498,
          286,
          1190,
          341,
          472,
          544,
          565,
          11,
          291,
          393,
          586,
          412,
          2152,
          385,
          365,
          364,
          5802,
          293,
          291,
          603,
          483,
          257,
          4230,
          646,
          11,
          420,
          291,
          393,
          412,
          2152,
          385,
          365,
          572,
          5802,
          293,
          291,
          486,
          483,
          257,
          3636,
          646,
          1566,
          291,
          643,
          364,
          5802,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.25773107244613325,
        "compression_ratio": 1.6313131313131313,
        "end": 5086.4,
        "id": 1172,
        "no_speech_prob": 0.000019833207261399366,
        "seek": 506300,
        "start": 5081.56,
        "temperature": 0,
        "text": " But I won't be using the angle you asked for just yet, but let's just see if this works.",
        "tokens": [
          51292,
          583,
          286,
          1582,
          380,
          312,
          1228,
          264,
          5802,
          291,
          2351,
          337,
          445,
          1939,
          11,
          457,
          718,
          311,
          445,
          536,
          498,
          341,
          1985,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.43558542545025164,
        "compression_ratio": 1.4196428571428572,
        "end": 5096.76,
        "id": 1173,
        "no_speech_prob": 0.004331432282924652,
        "seek": 509300,
        "start": 5093,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.43558542545025164,
        "compression_ratio": 1.4196428571428572,
        "end": 5102.16,
        "id": 1174,
        "no_speech_prob": 0.004331432282924652,
        "seek": 509300,
        "start": 5097.68,
        "temperature": 0,
        "text": " Somebody, somebody still mentioned me please with no angle, with no, no digits.",
        "tokens": [
          50598,
          13463,
          11,
          2618,
          920,
          2835,
          385,
          1767,
          365,
          572,
          5802,
          11,
          365,
          572,
          11,
          572,
          27011,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.43558542545025164,
        "compression_ratio": 1.4196428571428572,
        "end": 5114.56,
        "id": 1175,
        "no_speech_prob": 0.004331432282924652,
        "seek": 509300,
        "start": 5114,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51414,
          663,
          311,
          3657,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.43558542545025164,
        "compression_ratio": 1.4196428571428572,
        "end": 5117.8,
        "id": 1176,
        "no_speech_prob": 0.004331432282924652,
        "seek": 509300,
        "start": 5116.28,
        "temperature": 0,
        "text": " Come on, somebody, no digits, please.",
        "tokens": [
          51528,
          2492,
          322,
          11,
          2618,
          11,
          572,
          27011,
          11,
          1767,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.43558542545025164,
        "compression_ratio": 1.4196428571428572,
        "end": 5118.68,
        "id": 1177,
        "no_speech_prob": 0.004331432282924652,
        "seek": 509300,
        "start": 5117.8,
        "temperature": 0,
        "text": " No digits.",
        "tokens": [
          51604,
          883,
          27011,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.43558542545025164,
        "compression_ratio": 1.4196428571428572,
        "end": 5121.88,
        "id": 1178,
        "no_speech_prob": 0.004331432282924652,
        "seek": 509300,
        "start": 5121.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51788,
          1033,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5123.92,
        "id": 1179,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5123.24,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          50376,
          1033,
          11,
          869,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5129.52,
        "id": 1180,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5123.96,
        "temperature": 0,
        "text": " So we can see that we got one, two, three, four, five mentions, one of which had a negative one.",
        "tokens": [
          50412,
          407,
          321,
          393,
          536,
          300,
          321,
          658,
          472,
          11,
          732,
          11,
          1045,
          11,
          1451,
          11,
          1732,
          23844,
          11,
          472,
          295,
          597,
          632,
          257,
          3671,
          472,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5131.12,
        "id": 1181,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5129.84,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          50706,
          407,
          718,
          311,
          536,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5136.64,
        "id": 1182,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5131.16,
        "temperature": 0,
        "text": " Uh, let's just check our bot now and we can see 60, 38, 56.",
        "tokens": [
          50772,
          4019,
          11,
          718,
          311,
          445,
          1520,
          527,
          10592,
          586,
          293,
          321,
          393,
          536,
          4060,
          11,
          12843,
          11,
          19687,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5137.24,
        "id": 1183,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5136.68,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          51048,
          823,
          510,
          311,
          264,
          551,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5138.88,
        "id": 1184,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5137.24,
        "temperature": 0,
        "text": " I'm not actually using the angle.",
        "tokens": [
          51076,
          286,
          478,
          406,
          767,
          1228,
          264,
          5802,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5140.8,
        "id": 1185,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5138.88,
        "temperature": 0,
        "text": " It's still just a random angle.",
        "tokens": [
          51158,
          467,
          311,
          920,
          445,
          257,
          4974,
          5802,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5148.88,
        "id": 1186,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5142.12,
        "temperature": 0,
        "text": " So, um, what I need to do is, oh, and I forgot that I was pulling it out of here.",
        "tokens": [
          51320,
          407,
          11,
          1105,
          11,
          437,
          286,
          643,
          281,
          360,
          307,
          11,
          1954,
          11,
          293,
          286,
          5298,
          300,
          286,
          390,
          8407,
          309,
          484,
          295,
          510,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5150.04,
        "id": 1187,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5148.88,
        "temperature": 0,
        "text": " So it's actually not let, hold on.",
        "tokens": [
          51658,
          407,
          309,
          311,
          767,
          406,
          718,
          11,
          1797,
          322,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.22427080659305348,
        "compression_ratio": 1.58,
        "end": 5150.44,
        "id": 1188,
        "no_speech_prob": 0.000330145878251642,
        "seek": 512300,
        "start": 5150.04,
        "temperature": 0,
        "text": " Let's.",
        "tokens": [
          51716,
          961,
          311,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5156.2,
        "id": 1189,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5151.44,
        "temperature": 0,
        "text": " So we see Alka asked for 56 and I made a tree with 52.",
        "tokens": [
          50414,
          407,
          321,
          536,
          967,
          2330,
          2351,
          337,
          19687,
          293,
          286,
          1027,
          257,
          4230,
          365,
          18079,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5159.839999999999,
        "id": 1190,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5156.24,
        "temperature": 0,
        "text": " So now let's take this out, right?",
        "tokens": [
          50654,
          407,
          586,
          718,
          311,
          747,
          341,
          484,
          11,
          558,
          30,
          50834
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5161.48,
        "id": 1191,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5159.879999999999,
        "temperature": 0,
        "text": " And actually try to use that angle.",
        "tokens": [
          50836,
          400,
          767,
          853,
          281,
          764,
          300,
          5802,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5162.2,
        "id": 1192,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5161.48,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          50916,
          823,
          510,
          311,
          264,
          551,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5164.719999999999,
        "id": 1193,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5162.36,
        "temperature": 0,
        "text": " I can't just, how do I do this?",
        "tokens": [
          50960,
          286,
          393,
          380,
          445,
          11,
          577,
          360,
          286,
          360,
          341,
          30,
          51078
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5171.16,
        "id": 1194,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5165.44,
        "temperature": 0,
        "text": " So what I'm actually going to do, this is interesting, is I need to go back to that exec command.",
        "tokens": [
          51114,
          407,
          437,
          286,
          478,
          767,
          516,
          281,
          360,
          11,
          341,
          307,
          1880,
          11,
          307,
          286,
          643,
          281,
          352,
          646,
          281,
          300,
          4454,
          5622,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5172.5599999999995,
        "id": 1195,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5171.48,
        "temperature": 0,
        "text": " Where did I have that?",
        "tokens": [
          51416,
          2305,
          630,
          286,
          362,
          300,
          30,
          51470
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5173.759999999999,
        "id": 1196,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5173.2,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51502,
          2305,
          307,
          300,
          30,
          51530
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5174.5199999999995,
        "id": 1197,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5173.799999999999,
        "temperature": 0,
        "text": " Oh, command.",
        "tokens": [
          51532,
          876,
          11,
          5622,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2866589103158065,
        "compression_ratio": 1.5798319327731092,
        "end": 5177.759999999999,
        "id": 1198,
        "no_speech_prob": 0.00014653051039204001,
        "seek": 515044,
        "start": 5175.48,
        "temperature": 0,
        "text": " So that's, whoa, it's all the way, way up here.",
        "tokens": [
          51616,
          407,
          300,
          311,
          11,
          13310,
          11,
          309,
          311,
          439,
          264,
          636,
          11,
          636,
          493,
          510,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5182.12,
        "id": 1199,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5178.6,
        "temperature": 0,
        "text": " So what I actually need to do is I need to add another argument to this.",
        "tokens": [
          50406,
          407,
          437,
          286,
          767,
          643,
          281,
          360,
          307,
          286,
          643,
          281,
          909,
          1071,
          6770,
          281,
          341,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5188.360000000001,
        "id": 1200,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5183.12,
        "temperature": 0,
        "text": " And so what I'm going to do, and I think, where do I, I haven't done this in a while.",
        "tokens": [
          50632,
          400,
          370,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          293,
          286,
          519,
          11,
          689,
          360,
          286,
          11,
          286,
          2378,
          380,
          1096,
          341,
          294,
          257,
          1339,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5190.360000000001,
        "id": 1201,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5188.360000000001,
        "temperature": 0,
        "text": " Let's, all right, let's, let's do it this way.",
        "tokens": [
          50894,
          961,
          311,
          11,
          439,
          558,
          11,
          718,
          311,
          11,
          718,
          311,
          360,
          309,
          341,
          636,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5190.76,
        "id": 1202,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5190.360000000001,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50994,
          4919,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5193.24,
        "id": 1203,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5191.64,
        "temperature": 0,
        "text": " Let me grab this command.",
        "tokens": [
          51058,
          961,
          385,
          4444,
          341,
          5622,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5195.56,
        "id": 1204,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5194.2,
        "temperature": 0,
        "text": " We're going to figure this out together.",
        "tokens": [
          51186,
          492,
          434,
          516,
          281,
          2573,
          341,
          484,
          1214,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5200.92,
        "id": 1205,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5197.6,
        "temperature": 0,
        "text": " And we go back to here and I'm going to run that command.",
        "tokens": [
          51356,
          400,
          321,
          352,
          646,
          281,
          510,
          293,
          286,
          478,
          516,
          281,
          1190,
          300,
          5622,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.21268886135470483,
        "compression_ratio": 1.7612612612612613,
        "end": 5204.72,
        "id": 1206,
        "no_speech_prob": 0.00000323776043842372,
        "seek": 517776,
        "start": 5201.320000000001,
        "temperature": 0,
        "text": " So this runs and I get the, that spits out the angle.",
        "tokens": [
          51542,
          407,
          341,
          6676,
          293,
          286,
          483,
          264,
          11,
          300,
          637,
          1208,
          484,
          264,
          5802,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5211.76,
        "id": 1207,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5204.72,
        "temperature": 0,
        "text": " Now there should be a way in processing for me to get the arguments.",
        "tokens": [
          50364,
          823,
          456,
          820,
          312,
          257,
          636,
          294,
          9007,
          337,
          385,
          281,
          483,
          264,
          12869,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5215.320000000001,
        "id": 1208,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5212.400000000001,
        "temperature": 0,
        "text": " How do you get the arguments in Java?",
        "tokens": [
          50748,
          1012,
          360,
          291,
          483,
          264,
          12869,
          294,
          10745,
          30,
          50894
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5220.12,
        "id": 1209,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5218.4800000000005,
        "temperature": 0,
        "text": " The command line arguments.",
        "tokens": [
          51052,
          440,
          5622,
          1622,
          12869,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5221.64,
        "id": 1210,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5220.360000000001,
        "temperature": 0,
        "text": " Somebody must know this.",
        "tokens": [
          51146,
          13463,
          1633,
          458,
          341,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5224.72,
        "id": 1211,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5222.68,
        "temperature": 0,
        "text": " It's like system.args.",
        "tokens": [
          51262,
          467,
          311,
          411,
          1185,
          13,
          289,
          21559,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5230.64,
        "id": 1212,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5226.4800000000005,
        "temperature": 0,
        "text": " This is like the most, this is like the core string args.",
        "tokens": [
          51452,
          639,
          307,
          411,
          264,
          881,
          11,
          341,
          307,
          411,
          264,
          4965,
          6798,
          3882,
          82,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5233.76,
        "id": 1213,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5230.88,
        "temperature": 0,
        "text": " Is it just there in a global variable somewhere in processing?",
        "tokens": [
          51672,
          1119,
          309,
          445,
          456,
          294,
          257,
          4338,
          7006,
          4079,
          294,
          9007,
          30,
          51816
        ]
      },
      {
        "avg_logprob": -0.29225915342896847,
        "compression_ratio": 1.7180851063829787,
        "end": 5234.68,
        "id": 1214,
        "no_speech_prob": 0.0005792902666144073,
        "seek": 520472,
        "start": 5233.76,
        "temperature": 0,
        "text": " I should know this.",
        "tokens": [
          51816,
          286,
          820,
          458,
          341,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.40136104159884983,
        "compression_ratio": 1.3863636363636365,
        "end": 5236.4400000000005,
        "id": 1215,
        "no_speech_prob": 0.00002627457979542669,
        "seek": 523472,
        "start": 5234.92,
        "temperature": 0,
        "text": " I did this like a year ago.",
        "tokens": [
          50374,
          286,
          630,
          341,
          411,
          257,
          1064,
          2057,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.40136104159884983,
        "compression_ratio": 1.3863636363636365,
        "end": 5241.4800000000005,
        "id": 1216,
        "no_speech_prob": 0.00002627457979542669,
        "seek": 523472,
        "start": 5238.68,
        "temperature": 0,
        "text": " Print line system.args.",
        "tokens": [
          50562,
          34439,
          1622,
          1185,
          13,
          289,
          21559,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.40136104159884983,
        "compression_ratio": 1.3863636363636365,
        "end": 5244.56,
        "id": 1217,
        "no_speech_prob": 0.00002627457979542669,
        "seek": 523472,
        "start": 5242.64,
        "temperature": 0,
        "text": " What's the chance like that that's like a thing?",
        "tokens": [
          50760,
          708,
          311,
          264,
          2931,
          411,
          300,
          300,
          311,
          411,
          257,
          551,
          30,
          50856
        ]
      },
      {
        "avg_logprob": -0.40136104159884983,
        "compression_ratio": 1.3863636363636365,
        "end": 5245.08,
        "id": 1218,
        "no_speech_prob": 0.00002627457979542669,
        "seek": 523472,
        "start": 5244.56,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50856,
          883,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.40136104159884983,
        "compression_ratio": 1.3863636363636365,
        "end": 5248.6,
        "id": 1219,
        "no_speech_prob": 0.00002627457979542669,
        "seek": 523472,
        "start": 5247.280000000001,
        "temperature": 0,
        "text": " I know, I'm going to look this up.",
        "tokens": [
          50992,
          286,
          458,
          11,
          286,
          478,
          516,
          281,
          574,
          341,
          493,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.40136104159884983,
        "compression_ratio": 1.3863636363636365,
        "end": 5259.52,
        "id": 1220,
        "no_speech_prob": 0.00002627457979542669,
        "seek": 523472,
        "start": 5258,
        "temperature": 0,
        "text": " Why does this computer keep going to sleep?",
        "tokens": [
          51528,
          1545,
          775,
          341,
          3820,
          1066,
          516,
          281,
          2817,
          30,
          51604
        ]
      },
      {
        "avg_logprob": -0.3769452115322681,
        "compression_ratio": 1.6512820512820512,
        "end": 5264.68,
        "id": 1221,
        "no_speech_prob": 0.000024682865841896273,
        "seek": 525952,
        "start": 5260.52,
        "temperature": 0,
        "text": " By the way, Adam asked in the chat, does it only reply to local or any account in the federation?",
        "tokens": [
          50414,
          3146,
          264,
          636,
          11,
          7938,
          2351,
          294,
          264,
          5081,
          11,
          775,
          309,
          787,
          16972,
          281,
          2654,
          420,
          604,
          2696,
          294,
          264,
          4636,
          5053,
          30,
          50622
        ]
      },
      {
        "avg_logprob": -0.3769452115322681,
        "compression_ratio": 1.6512820512820512,
        "end": 5266.4400000000005,
        "id": 1222,
        "no_speech_prob": 0.000024682865841896273,
        "seek": 525952,
        "start": 5264.68,
        "temperature": 0,
        "text": " It'll apply to any account in the federation.",
        "tokens": [
          50622,
          467,
          603,
          3079,
          281,
          604,
          2696,
          294,
          264,
          4636,
          5053,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.3769452115322681,
        "compression_ratio": 1.6512820512820512,
        "end": 5269.4800000000005,
        "id": 1223,
        "no_speech_prob": 0.000024682865841896273,
        "seek": 525952,
        "start": 5266.4400000000005,
        "temperature": 0,
        "text": " I could set it up to only reply to local, but that's not what it does by default.",
        "tokens": [
          50710,
          286,
          727,
          992,
          309,
          493,
          281,
          787,
          16972,
          281,
          2654,
          11,
          457,
          300,
          311,
          406,
          437,
          309,
          775,
          538,
          7576,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.3769452115322681,
        "compression_ratio": 1.6512820512820512,
        "end": 5278.56,
        "id": 1224,
        "no_speech_prob": 0.000024682865841896273,
        "seek": 525952,
        "start": 5275.400000000001,
        "temperature": 0,
        "text": " So I did this like a year ago with my Twitter image replier.",
        "tokens": [
          51158,
          407,
          286,
          630,
          341,
          411,
          257,
          1064,
          2057,
          365,
          452,
          5794,
          3256,
          3248,
          811,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.3769452115322681,
        "compression_ratio": 1.6512820512820512,
        "end": 5286.96,
        "id": 1225,
        "no_speech_prob": 0.000024682865841896273,
        "seek": 525952,
        "start": 5281.120000000001,
        "temperature": 0,
        "text": " Oh, but, oh, this was even crazier.",
        "tokens": [
          51444,
          876,
          11,
          457,
          11,
          1954,
          11,
          341,
          390,
          754,
          2094,
          33352,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5292.72,
        "id": 1226,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5289.56,
        "temperature": 0,
        "text": " Because I downloaded image that somebody else posts.",
        "tokens": [
          50366,
          1436,
          286,
          21748,
          3256,
          300,
          2618,
          1646,
          12300,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5297.240000000001,
        "id": 1227,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5295.56,
        "temperature": 0,
        "text": " I'm pretty sure, yeah, oh, args.",
        "tokens": [
          50666,
          286,
          478,
          1238,
          988,
          11,
          1338,
          11,
          1954,
          11,
          3882,
          82,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5298.360000000001,
        "id": 1228,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5297.240000000001,
        "temperature": 0,
        "text": " It's just in args.",
        "tokens": [
          50750,
          467,
          311,
          445,
          294,
          3882,
          82,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5302.040000000001,
        "id": 1229,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5300.72,
        "temperature": 0,
        "text": " It's just in args.",
        "tokens": [
          50924,
          467,
          311,
          445,
          294,
          3882,
          82,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5304.400000000001,
        "id": 1230,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5303.56,
        "temperature": 0,
        "text": " Silly me.",
        "tokens": [
          51066,
          318,
          6917,
          385,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5309.4800000000005,
        "id": 1231,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5308.400000000001,
        "temperature": 0,
        "text": " Silly me.",
        "tokens": [
          51308,
          318,
          6917,
          385,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5314,
        "id": 1232,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5313.080000000001,
        "temperature": 0,
        "text": " Okay, I looked it up.",
        "tokens": [
          51542,
          1033,
          11,
          286,
          2956,
          309,
          493,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.3968682540090461,
        "compression_ratio": 1.4306569343065694,
        "end": 5315.64,
        "id": 1233,
        "no_speech_prob": 0.000010783302059280686,
        "seek": 528952,
        "start": 5314,
        "temperature": 0,
        "text": " I can't believe I forgot this.",
        "tokens": [
          51588,
          286,
          393,
          380,
          1697,
          286,
          5298,
          341,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5322.68,
        "id": 1234,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5316.04,
        "temperature": 0,
        "text": " But processing actually just has built in variable, built in variable called args,",
        "tokens": [
          50384,
          583,
          9007,
          767,
          445,
          575,
          3094,
          294,
          7006,
          11,
          3094,
          294,
          7006,
          1219,
          3882,
          82,
          11,
          50716
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5324.360000000001,
        "id": 1235,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5322.68,
        "temperature": 0,
        "text": " which has those command line arguments.",
        "tokens": [
          50716,
          597,
          575,
          729,
          5622,
          1622,
          12869,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5326.92,
        "id": 1236,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5324.360000000001,
        "temperature": 0,
        "text": " So I'm going to put print array args.",
        "tokens": [
          50800,
          407,
          286,
          478,
          516,
          281,
          829,
          4482,
          10225,
          3882,
          82,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5328.160000000001,
        "id": 1237,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5326.92,
        "temperature": 0,
        "text": " And now I'm going to do this.",
        "tokens": [
          50928,
          400,
          586,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5330.68,
        "id": 1238,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5329.56,
        "temperature": 0,
        "text": " We should see.",
        "tokens": [
          51060,
          492,
          820,
          536,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5334.88,
        "id": 1239,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5331.76,
        "temperature": 0,
        "text": " Whoa, oh, it's null because there were none.",
        "tokens": [
          51170,
          7521,
          11,
          1954,
          11,
          309,
          311,
          18184,
          570,
          456,
          645,
          6022,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5335.52,
        "id": 1240,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5334.88,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51326,
          663,
          311,
          3657,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5339,
        "id": 1241,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5336.8,
        "temperature": 0,
        "text": " Because where do those go?",
        "tokens": [
          51422,
          1436,
          689,
          360,
          729,
          352,
          30,
          51532
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5342.400000000001,
        "id": 1242,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5340.88,
        "temperature": 0,
        "text": " They're not here.",
        "tokens": [
          51626,
          814,
          434,
          406,
          510,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5343.72,
        "id": 1243,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5342.400000000001,
        "temperature": 0,
        "text": " Where, how do I pass arguments?",
        "tokens": [
          51702,
          2305,
          11,
          577,
          360,
          286,
          1320,
          12869,
          30,
          51768
        ]
      },
      {
        "avg_logprob": -0.3545358557450144,
        "compression_ratio": 1.6282051282051282,
        "end": 5345.4400000000005,
        "id": 1244,
        "no_speech_prob": 0.000053910494898445904,
        "seek": 531564,
        "start": 5343.72,
        "temperature": 0,
        "text": " If I just add something else like here.",
        "tokens": [
          51768,
          759,
          286,
          445,
          909,
          746,
          1646,
          411,
          510,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5348.360000000001,
        "id": 1245,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5346.64,
        "temperature": 0,
        "text": " Oh, yeah, there we go.",
        "tokens": [
          50414,
          876,
          11,
          1338,
          11,
          456,
          321,
          352,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5350.88,
        "id": 1246,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5348.360000000001,
        "temperature": 0,
        "text": " Okay, so if I just add, the args come at the end.",
        "tokens": [
          50500,
          1033,
          11,
          370,
          498,
          286,
          445,
          909,
          11,
          264,
          3882,
          82,
          808,
          412,
          264,
          917,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5353.56,
        "id": 1247,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5350.88,
        "temperature": 0,
        "text": " I thought some of these might be args, but of course there's none.",
        "tokens": [
          50626,
          286,
          1194,
          512,
          295,
          613,
          1062,
          312,
          3882,
          82,
          11,
          457,
          295,
          1164,
          456,
          311,
          6022,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5359,
        "id": 1248,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5353.56,
        "temperature": 0,
        "text": " So we can see here, if I just execute it with an argument like with the angle 40,",
        "tokens": [
          50760,
          407,
          321,
          393,
          536,
          510,
          11,
          498,
          286,
          445,
          14483,
          309,
          365,
          364,
          6770,
          411,
          365,
          264,
          5802,
          3356,
          11,
          51032
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5366.56,
        "id": 1249,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5360.280000000001,
        "temperature": 0,
        "text": " then, blah, blah, 40, because I have some, I had a bl in there, blah, 40.",
        "tokens": [
          51096,
          550,
          11,
          12288,
          11,
          12288,
          11,
          3356,
          11,
          570,
          286,
          362,
          512,
          11,
          286,
          632,
          257,
          888,
          294,
          456,
          11,
          12288,
          11,
          3356,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5368.72,
        "id": 1250,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5366.56,
        "temperature": 0,
        "text": " Okay, perfect, this is much easier than I thought.",
        "tokens": [
          51410,
          1033,
          11,
          2176,
          11,
          341,
          307,
          709,
          3571,
          813,
          286,
          1194,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5372.88,
        "id": 1251,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5369.6,
        "temperature": 0,
        "text": " All I need to do is now say command.",
        "tokens": [
          51562,
          1057,
          286,
          643,
          281,
          360,
          307,
          586,
          584,
          5622,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.32253840475371387,
        "compression_ratio": 1.6979591836734693,
        "end": 5374.4400000000005,
        "id": 1252,
        "no_speech_prob": 0.00000826786708785221,
        "seek": 534564,
        "start": 5372.88,
        "temperature": 0,
        "text": " Where do I execute that command?",
        "tokens": [
          51726,
          2305,
          360,
          286,
          14483,
          300,
          5622,
          30,
          51804
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5376.04,
        "id": 1253,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5375.4,
        "temperature": 0,
        "text": " Right here.",
        "tokens": [
          50412,
          1779,
          510,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5384.96,
        "id": 1254,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5377,
        "temperature": 0,
        "text": " Execute command plus space angle, right?",
        "tokens": [
          50492,
          17662,
          1169,
          5622,
          1804,
          1901,
          5802,
          11,
          558,
          30,
          50890
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5386.759999999999,
        "id": 1255,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5384.96,
        "temperature": 0,
        "text": " I guess I could use a template literal there.",
        "tokens": [
          50890,
          286,
          2041,
          286,
          727,
          764,
          257,
          12379,
          20411,
          456,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5388.96,
        "id": 1256,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5386.759999999999,
        "temperature": 0,
        "text": " So I just need to add that angle there.",
        "tokens": [
          50980,
          407,
          286,
          445,
          643,
          281,
          909,
          300,
          5802,
          456,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5393.48,
        "id": 1257,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5388.96,
        "temperature": 0,
        "text": " And I probably want to double check to make sure there are any args.",
        "tokens": [
          51090,
          400,
          286,
          1391,
          528,
          281,
          3834,
          1520,
          281,
          652,
          988,
          456,
          366,
          604,
          3882,
          82,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5397.639999999999,
        "id": 1258,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5393.48,
        "temperature": 0,
        "text": " But if args is not equal to null,",
        "tokens": [
          51316,
          583,
          498,
          3882,
          82,
          307,
          406,
          2681,
          281,
          18184,
          11,
          51524
        ]
      },
      {
        "avg_logprob": -0.3266507495533336,
        "compression_ratio": 1.5,
        "end": 5404.04,
        "id": 1259,
        "no_speech_prob": 0.000041986069845734164,
        "seek": 537444,
        "start": 5399,
        "temperature": 0,
        "text": " then I'm going to make this a global variable, a equals zero.",
        "tokens": [
          51592,
          550,
          286,
          478,
          516,
          281,
          652,
          341,
          257,
          4338,
          7006,
          11,
          257,
          6915,
          4018,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5408.639999999999,
        "id": 1260,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5405.24,
        "temperature": 0,
        "text": " And then I'm going to say a equals args index zero.",
        "tokens": [
          50404,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          257,
          6915,
          3882,
          82,
          8186,
          4018,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5410.799999999999,
        "id": 1261,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5408.639999999999,
        "temperature": 0,
        "text": " I guess that's going to be a string, right?",
        "tokens": [
          50574,
          286,
          2041,
          300,
          311,
          516,
          281,
          312,
          257,
          6798,
          11,
          558,
          30,
          50682
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5414.08,
        "id": 1262,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5410.799999999999,
        "temperature": 0,
        "text": " So I need to convert that to an integer or a float maybe.",
        "tokens": [
          50682,
          407,
          286,
          643,
          281,
          7620,
          300,
          281,
          364,
          24922,
          420,
          257,
          15706,
          1310,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5416.919999999999,
        "id": 1263,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5415.639999999999,
        "temperature": 0,
        "text": " And then I don't need it here.",
        "tokens": [
          50924,
          400,
          550,
          286,
          500,
          380,
          643,
          309,
          510,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5419.4,
        "id": 1264,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5417.839999999999,
        "temperature": 0,
        "text": " And now, here we go.",
        "tokens": [
          51034,
          400,
          586,
          11,
          510,
          321,
          352,
          13,
          51112
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5424.799999999999,
        "id": 1265,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5419.4,
        "temperature": 0,
        "text": " So now, if, let's take out the exit just so we see.",
        "tokens": [
          51112,
          407,
          586,
          11,
          498,
          11,
          718,
          311,
          747,
          484,
          264,
          11043,
          445,
          370,
          321,
          536,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5429.28,
        "id": 1266,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5427.08,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51496,
          961,
          311,
          360,
          341,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.29573660630446214,
        "compression_ratio": 1.5072463768115942,
        "end": 5432.24,
        "id": 1267,
        "no_speech_prob": 0.000009223448614648078,
        "seek": 540444,
        "start": 5429.28,
        "temperature": 0,
        "text": " Processing Java, run with the angle 10.",
        "tokens": [
          51606,
          31093,
          278,
          10745,
          11,
          1190,
          365,
          264,
          5802,
          1266,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5436.28,
        "id": 1268,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5434.5199999999995,
        "temperature": 0,
        "text": " That looks like the angle 10, right?",
        "tokens": [
          50368,
          663,
          1542,
          411,
          264,
          5802,
          1266,
          11,
          558,
          30,
          50456
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5439.32,
        "id": 1269,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5436.28,
        "temperature": 0,
        "text": " Now, let's run with an angle of 90.",
        "tokens": [
          50456,
          823,
          11,
          718,
          311,
          1190,
          365,
          364,
          5802,
          295,
          4289,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5443.4,
        "id": 1270,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5441.5599999999995,
        "temperature": 0,
        "text": " And that looks like the angle 90, perfect.",
        "tokens": [
          50720,
          400,
          300,
          1542,
          411,
          264,
          5802,
          4289,
          11,
          2176,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5445.24,
        "id": 1271,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5443.4,
        "temperature": 0,
        "text": " I've passed in the angle.",
        "tokens": [
          50812,
          286,
          600,
          4678,
          294,
          264,
          5802,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5447.96,
        "id": 1272,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5445.24,
        "temperature": 0,
        "text": " And so now, I should be able to, I mean, right,",
        "tokens": [
          50904,
          400,
          370,
          586,
          11,
          286,
          820,
          312,
          1075,
          281,
          11,
          286,
          914,
          11,
          558,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5449.639999999999,
        "id": 1273,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5447.96,
        "temperature": 0,
        "text": " is there anything left to do?",
        "tokens": [
          51040,
          307,
          456,
          1340,
          1411,
          281,
          360,
          30,
          51124
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5451.639999999999,
        "id": 1274,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5449.639999999999,
        "temperature": 0,
        "text": " I think this works.",
        "tokens": [
          51124,
          286,
          519,
          341,
          1985,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5453.36,
        "id": 1275,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5451.639999999999,
        "temperature": 0,
        "text": " Because I got the angle, I've got the angle,",
        "tokens": [
          51224,
          1436,
          286,
          658,
          264,
          5802,
          11,
          286,
          600,
          658,
          264,
          5802,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5456.36,
        "id": 1276,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5453.36,
        "temperature": 0,
        "text": " I'm going to give it the angle.",
        "tokens": [
          51310,
          286,
          478,
          516,
          281,
          976,
          309,
          264,
          5802,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5457.28,
        "id": 1277,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5456.36,
        "temperature": 0,
        "text": " Yeah, all right.",
        "tokens": [
          51460,
          865,
          11,
          439,
          558,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5459.679999999999,
        "id": 1278,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5458.759999999999,
        "temperature": 0,
        "text": " What the hey ho?",
        "tokens": [
          51580,
          708,
          264,
          4177,
          1106,
          30,
          51626
        ]
      },
      {
        "avg_logprob": -0.25747611030699713,
        "compression_ratio": 1.7023255813953488,
        "end": 5461.5599999999995,
        "id": 1279,
        "no_speech_prob": 0.00003071813625865616,
        "seek": 543444,
        "start": 5460.599999999999,
        "temperature": 0,
        "text": " Let's run this.",
        "tokens": [
          51672,
          961,
          311,
          1190,
          341,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5463.400000000001,
        "id": 1280,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5462.56,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50414,
          2438,
          0,
          50456
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5468.96,
        "id": 1281,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5465.88,
        "temperature": 0,
        "text": " Node bot.js, Mastodon bot starting.",
        "tokens": [
          50580,
          38640,
          10592,
          13,
          25530,
          11,
          376,
          525,
          378,
          266,
          10592,
          2891,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5471.4400000000005,
        "id": 1282,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5468.96,
        "temperature": 0,
        "text": " And now, I'll just wait for a little bit.",
        "tokens": [
          50734,
          400,
          586,
          11,
          286,
          603,
          445,
          1699,
          337,
          257,
          707,
          857,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5476.56,
        "id": 1283,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5474.4800000000005,
        "temperature": 0,
        "text": " Try test anything you can imagine.",
        "tokens": [
          51010,
          6526,
          1500,
          1340,
          291,
          393,
          3811,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5479.200000000001,
        "id": 1284,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5476.56,
        "temperature": 0,
        "text": " Oh, whoops, sorry, stop, stop.",
        "tokens": [
          51114,
          876,
          11,
          567,
          3370,
          11,
          2597,
          11,
          1590,
          11,
          1590,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5482.4400000000005,
        "id": 1285,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5480.88,
        "temperature": 0,
        "text": " It's funny, like, actually, this is fine.",
        "tokens": [
          51330,
          467,
          311,
          4074,
          11,
          411,
          11,
          767,
          11,
          341,
          307,
          2489,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5483.92,
        "id": 1286,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5482.4400000000005,
        "temperature": 0,
        "text": " I forgot the exit thing.",
        "tokens": [
          51408,
          286,
          5298,
          264,
          11043,
          551,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.30436312357584633,
        "compression_ratio": 1.4709302325581395,
        "end": 5491.320000000001,
        "id": 1287,
        "no_speech_prob": 0.000021112424292368814,
        "seek": 546156,
        "start": 5489.04,
        "temperature": 0,
        "text": " So amusingly, I forgot the exit thing.",
        "tokens": [
          51738,
          407,
          47809,
          356,
          11,
          286,
          5298,
          264,
          11043,
          551,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.3017939214837061,
        "compression_ratio": 1.490566037735849,
        "end": 5493.679999999999,
        "id": 1288,
        "no_speech_prob": 0.000021782416297355667,
        "seek": 549132,
        "start": 5492.08,
        "temperature": 0,
        "text": " So it's opening up Processing, but it's never finishing.",
        "tokens": [
          50402,
          407,
          309,
          311,
          5193,
          493,
          31093,
          278,
          11,
          457,
          309,
          311,
          1128,
          12693,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.3017939214837061,
        "compression_ratio": 1.490566037735849,
        "end": 5497.08,
        "id": 1289,
        "no_speech_prob": 0.000021782416297355667,
        "seek": 549132,
        "start": 5493.679999999999,
        "temperature": 0,
        "text": " So it's actually, that exit thing is very important",
        "tokens": [
          50482,
          407,
          309,
          311,
          767,
          11,
          300,
          11043,
          551,
          307,
          588,
          1021,
          50652
        ]
      },
      {
        "avg_logprob": -0.3017939214837061,
        "compression_ratio": 1.490566037735849,
        "end": 5500.12,
        "id": 1290,
        "no_speech_prob": 0.000021782416297355667,
        "seek": 549132,
        "start": 5497.08,
        "temperature": 0,
        "text": " because I forgot that I had that in there.",
        "tokens": [
          50652,
          570,
          286,
          5298,
          300,
          286,
          632,
          300,
          294,
          456,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.3017939214837061,
        "compression_ratio": 1.490566037735849,
        "end": 5501.92,
        "id": 1291,
        "no_speech_prob": 0.000021782416297355667,
        "seek": 549132,
        "start": 5500.12,
        "temperature": 0,
        "text": " I've got to put that back in there.",
        "tokens": [
          50804,
          286,
          600,
          658,
          281,
          829,
          300,
          646,
          294,
          456,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.3017939214837061,
        "compression_ratio": 1.490566037735849,
        "end": 5505.799999999999,
        "id": 1292,
        "no_speech_prob": 0.000021782416297355667,
        "seek": 549132,
        "start": 5502.96,
        "temperature": 0,
        "text": " And let's try this one more time.",
        "tokens": [
          50946,
          400,
          718,
          311,
          853,
          341,
          472,
          544,
          565,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.3017939214837061,
        "compression_ratio": 1.490566037735849,
        "end": 5507,
        "id": 1293,
        "no_speech_prob": 0.000021782416297355667,
        "seek": 549132,
        "start": 5505.799999999999,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          51088,
          400,
          510,
          321,
          352,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5538.32,
        "id": 1294,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5537.48,
        "temperature": 0.4,
        "text": " All right, thank you, everybody.",
        "tokens": [
          50388,
          1057,
          558,
          11,
          1309,
          291,
          11,
          2201,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5539.72,
        "id": 1295,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5538.32,
        "temperature": 0.4,
        "text": " This looks like some good testing.",
        "tokens": [
          50430,
          639,
          1542,
          411,
          512,
          665,
          4997,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5541.48,
        "id": 1296,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5539.72,
        "temperature": 0.4,
        "text": " I hope that no one is like,",
        "tokens": [
          50500,
          286,
          1454,
          300,
          572,
          472,
          307,
          411,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5543.56,
        "id": 1297,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5541.48,
        "temperature": 0.4,
        "text": " and so let's take a look now.",
        "tokens": [
          50588,
          293,
          370,
          718,
          311,
          747,
          257,
          574,
          586,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5544.4,
        "id": 1298,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5543.56,
        "temperature": 0.4,
        "text": " Wait.",
        "tokens": [
          50692,
          3802,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5549.28,
        "id": 1299,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5548,
        "temperature": 0.4,
        "text": " All right, thank you, everybody.",
        "tokens": [
          50914,
          1057,
          558,
          11,
          1309,
          291,
          11,
          2201,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5551.24,
        "id": 1300,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5549.28,
        "temperature": 0.4,
        "text": " This looks like some good amount of testing.",
        "tokens": [
          50978,
          639,
          1542,
          411,
          512,
          665,
          2372,
          295,
          4997,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5555,
        "id": 1301,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5551.24,
        "temperature": 0.4,
        "text": " Let's go now to bots in space and take a look.",
        "tokens": [
          51076,
          961,
          311,
          352,
          586,
          281,
          35410,
          294,
          1901,
          293,
          747,
          257,
          574,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5560,
        "id": 1302,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5555,
        "temperature": 0.4,
        "text": " Here is a beholder, and let's see what we get.",
        "tokens": [
          51264,
          1692,
          307,
          257,
          1540,
          2641,
          260,
          11,
          293,
          718,
          311,
          536,
          437,
          321,
          483,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5561.68,
        "id": 1303,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5560.36,
        "temperature": 0.4,
        "text": " This is a beholder.",
        "tokens": [
          51532,
          220,
          5723,
          307,
          257,
          312,
          20480,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5562.6,
        "id": 1304,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5561.68,
        "temperature": 0.4,
        "text": " This is a bot.",
        "tokens": [
          51598,
          639,
          307,
          257,
          10592,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5564.44,
        "id": 1305,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5562.6,
        "temperature": 0.4,
        "text": " So this is a bot.",
        "tokens": [
          51644,
          407,
          341,
          307,
          257,
          10592,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.8590439753745919,
        "compression_ratio": 1.9795918367346939,
        "end": 5566.24,
        "id": 1306,
        "no_speech_prob": 0.0015729556325823069,
        "seek": 553700,
        "start": 5564.44,
        "temperature": 0.4,
        "text": " So let's go ahead and run this.",
        "tokens": [
          51736,
          407,
          718,
          311,
          352,
          2286,
          293,
          1190,
          341,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5569.44,
        "id": 1307,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5566.679999999999,
        "temperature": 0,
        "text": " Behold my tree with an angle of 90.",
        "tokens": [
          50386,
          879,
          4104,
          452,
          4230,
          365,
          364,
          5802,
          295,
          4289,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5571.719999999999,
        "id": 1308,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5569.44,
        "temperature": 0,
        "text": " Please specify an angle so we can see here.",
        "tokens": [
          50524,
          2555,
          16500,
          364,
          5802,
          370,
          321,
          393,
          536,
          510,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5573.44,
        "id": 1309,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5571.719999999999,
        "temperature": 0,
        "text": " Nope, right, that worked.",
        "tokens": [
          50638,
          12172,
          11,
          558,
          11,
          300,
          2732,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5576,
        "id": 1310,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5573.44,
        "temperature": 0,
        "text": " Here, a right triangle has an angle of 90 degrees.",
        "tokens": [
          50724,
          1692,
          11,
          257,
          558,
          13369,
          575,
          364,
          5802,
          295,
          4289,
          5310,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5576.96,
        "id": 1311,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5576,
        "temperature": 0,
        "text": " I love right triangles.",
        "tokens": [
          50852,
          286,
          959,
          558,
          29896,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5577.84,
        "id": 1312,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5576.96,
        "temperature": 0,
        "text": " There we go, perfect.",
        "tokens": [
          50900,
          821,
          321,
          352,
          11,
          2176,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5582.84,
        "id": 1313,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5577.84,
        "temperature": 0,
        "text": " So 89, and there we go, 128 degrees.",
        "tokens": [
          50944,
          407,
          31877,
          11,
          293,
          456,
          321,
          352,
          11,
          29810,
          5310,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5585.84,
        "id": 1314,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5583.719999999999,
        "temperature": 0,
        "text": " 128, this is working, yay!",
        "tokens": [
          51238,
          29810,
          11,
          341,
          307,
          1364,
          11,
          23986,
          0,
          51344
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5587.92,
        "id": 1315,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5587.08,
        "temperature": 0,
        "text": " This is done.",
        "tokens": [
          51406,
          639,
          307,
          1096,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5589.719999999999,
        "id": 1316,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5587.92,
        "temperature": 0,
        "text": " So I hope now you have enjoyed,",
        "tokens": [
          51448,
          407,
          286,
          1454,
          586,
          291,
          362,
          4626,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5591.04,
        "id": 1317,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5589.719999999999,
        "temperature": 0,
        "text": " you can imagine sort of,",
        "tokens": [
          51538,
          291,
          393,
          3811,
          1333,
          295,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.22860737297478623,
        "compression_ratio": 1.6652542372881356,
        "end": 5593.16,
        "id": 1318,
        "no_speech_prob": 0.00038596164085902274,
        "seek": 556624,
        "start": 5591.04,
        "temperature": 0,
        "text": " I mean, there is another piece to this that I could do,",
        "tokens": [
          51604,
          286,
          914,
          11,
          456,
          307,
          1071,
          2522,
          281,
          341,
          300,
          286,
          727,
          360,
          11,
          51710
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5596.44,
        "id": 1319,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5593.16,
        "temperature": 0,
        "text": " which is what if the person sends me an image",
        "tokens": [
          50364,
          597,
          307,
          437,
          498,
          264,
          954,
          14790,
          385,
          364,
          3256,
          50528
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5598.48,
        "id": 1320,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5596.44,
        "temperature": 0,
        "text": " and I do send the image and send it back?",
        "tokens": [
          50528,
          293,
          286,
          360,
          2845,
          264,
          3256,
          293,
          2845,
          309,
          646,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5601.36,
        "id": 1321,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5598.48,
        "temperature": 0,
        "text": " I guess I'll have to come back another day and do that one.",
        "tokens": [
          50630,
          286,
          2041,
          286,
          603,
          362,
          281,
          808,
          646,
          1071,
          786,
          293,
          360,
          300,
          472,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5603.66,
        "id": 1322,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5601.36,
        "temperature": 0,
        "text": " But now you can see the full process",
        "tokens": [
          50774,
          583,
          586,
          291,
          393,
          536,
          264,
          1577,
          1399,
          50889
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5606.84,
        "id": 1323,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5603.66,
        "temperature": 0,
        "text": " that you can have another user at mention you",
        "tokens": [
          50889,
          300,
          291,
          393,
          362,
          1071,
          4195,
          412,
          2152,
          291,
          51048
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5609.44,
        "id": 1324,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5606.84,
        "temperature": 0,
        "text": " with some data, text data,",
        "tokens": [
          51048,
          365,
          512,
          1412,
          11,
          2487,
          1412,
          11,
          51178
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5612.4,
        "id": 1325,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5609.44,
        "temperature": 0,
        "text": " use that text data to generate an image and send it back.",
        "tokens": [
          51178,
          764,
          300,
          2487,
          1412,
          281,
          8460,
          364,
          3256,
          293,
          2845,
          309,
          646,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5613.9,
        "id": 1326,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5612.4,
        "temperature": 0,
        "text": " So I hope you enjoyed this tutorial.",
        "tokens": [
          51326,
          407,
          286,
          1454,
          291,
          4626,
          341,
          7073,
          13,
          51401
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5617.16,
        "id": 1327,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5613.9,
        "temperature": 0,
        "text": " I hope you make some wonderful bots at bots in space,",
        "tokens": [
          51401,
          286,
          1454,
          291,
          652,
          512,
          3715,
          35410,
          412,
          35410,
          294,
          1901,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.24356077575683593,
        "compression_ratio": 1.7975708502024292,
        "end": 5619,
        "id": 1328,
        "no_speech_prob": 0.0005274753202684224,
        "seek": 559316,
        "start": 5617.16,
        "temperature": 0,
        "text": " and I will see you in a future video.",
        "tokens": [
          51564,
          293,
          286,
          486,
          536,
          291,
          294,
          257,
          2027,
          960,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5619.84,
        "id": 1329,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5619,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5623.76,
        "id": 1330,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5622.92,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50560,
          1033,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5628.84,
        "id": 1331,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5626.04,
        "temperature": 0,
        "text": " Don't be snide, asks, is he okay?",
        "tokens": [
          50716,
          1468,
          380,
          312,
          2406,
          482,
          11,
          8962,
          11,
          307,
          415,
          1392,
          30,
          50856
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5630.04,
        "id": 1332,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5628.84,
        "temperature": 0,
        "text": " Definitely not.",
        "tokens": [
          50856,
          12151,
          406,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5631.9,
        "id": 1333,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5631.08,
        "temperature": 0,
        "text": " I don't think I've ever been okay.",
        "tokens": [
          50968,
          286,
          500,
          380,
          519,
          286,
          600,
          1562,
          668,
          1392,
          13,
          51009
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5633.4,
        "id": 1334,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5631.9,
        "temperature": 0,
        "text": " Look, and I'm also going bald.",
        "tokens": [
          51009,
          2053,
          11,
          293,
          286,
          478,
          611,
          516,
          21096,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5636.36,
        "id": 1335,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5634.28,
        "temperature": 0,
        "text": " Hey, Coding Garden with CJ is here.",
        "tokens": [
          51128,
          1911,
          11,
          383,
          8616,
          19429,
          365,
          42285,
          307,
          510,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5638.6,
        "id": 1336,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5636.36,
        "temperature": 0,
        "text": " Hello, hello, hello, hello.",
        "tokens": [
          51232,
          2425,
          11,
          7751,
          11,
          7751,
          11,
          7751,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5641.68,
        "id": 1337,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5640.06,
        "temperature": 0,
        "text": " All right, I think I'm done for today.",
        "tokens": [
          51417,
          1057,
          558,
          11,
          286,
          519,
          286,
          478,
          1096,
          337,
          965,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5643.18,
        "id": 1338,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5641.68,
        "temperature": 0,
        "text": " It is 5.40.",
        "tokens": [
          51498,
          467,
          307,
          1025,
          13,
          5254,
          13,
          51573
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5646.48,
        "id": 1339,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5644.16,
        "temperature": 0,
        "text": " I have got to go.",
        "tokens": [
          51622,
          286,
          362,
          658,
          281,
          352,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.3473388671875,
        "compression_ratio": 1.4832535885167464,
        "end": 5648.96,
        "id": 1340,
        "no_speech_prob": 0.0005442021647468209,
        "seek": 561900,
        "start": 5646.48,
        "temperature": 0,
        "text": " Does anybody have any questions they want to ask?",
        "tokens": [
          51738,
          4402,
          4472,
          362,
          604,
          1651,
          436,
          528,
          281,
          1029,
          30,
          51862
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5651.76,
        "id": 1341,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5649.8,
        "temperature": 0,
        "text": " I can't believe this doesn't crash anymore.",
        "tokens": [
          50406,
          286,
          393,
          380,
          1697,
          341,
          1177,
          380,
          8252,
          3602,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5653.96,
        "id": 1342,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5652.84,
        "temperature": 0,
        "text": " I think I'm done.",
        "tokens": [
          50558,
          286,
          519,
          286,
          478,
          1096,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5657.4800000000005,
        "id": 1343,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5655.76,
        "temperature": 0,
        "text": " Oh, the question is,",
        "tokens": [
          50704,
          876,
          11,
          264,
          1168,
          307,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5659.28,
        "id": 1344,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5657.4800000000005,
        "temperature": 0,
        "text": " should that have been a coding challenge?",
        "tokens": [
          50790,
          820,
          300,
          362,
          668,
          257,
          17720,
          3430,
          30,
          50880
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5662.04,
        "id": 1345,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5659.28,
        "temperature": 0,
        "text": " I think maybe it should just be two more tutorials.",
        "tokens": [
          50880,
          286,
          519,
          1310,
          309,
          820,
          445,
          312,
          732,
          544,
          17616,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5664.2,
        "id": 1346,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5662.04,
        "temperature": 0,
        "text": " Should have realized that from the beginning though.",
        "tokens": [
          51018,
          6454,
          362,
          5334,
          300,
          490,
          264,
          2863,
          1673,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5665.04,
        "id": 1347,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5664.2,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51126,
          286,
          500,
          380,
          458,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5669.08,
        "id": 1348,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5666.08,
        "temperature": 0,
        "text": " Anybody have any, I guess I'm going to, like, I'll pretend.",
        "tokens": [
          51220,
          19082,
          362,
          604,
          11,
          286,
          2041,
          286,
          478,
          516,
          281,
          11,
          411,
          11,
          286,
          603,
          11865,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.32692733764648435,
        "compression_ratio": 1.5837320574162679,
        "end": 5678.36,
        "id": 1349,
        "no_speech_prob": 0.00007967256533447653,
        "seek": 564896,
        "start": 5676.4,
        "temperature": 0,
        "text": " I'm going to do two intros.",
        "tokens": [
          51736,
          286,
          478,
          516,
          281,
          360,
          732,
          560,
          2635,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5681.84,
        "id": 1350,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5679.8,
        "temperature": 0,
        "text": " Just in case.",
        "tokens": [
          50406,
          1449,
          294,
          1389,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5682.68,
        "id": 1351,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5681.84,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50508,
          286,
          500,
          380,
          458,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5691.24,
        "id": 1352,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5689.4,
        "temperature": 0,
        "text": " This is, for people who haven't watched before,",
        "tokens": [
          50886,
          639,
          307,
          11,
          337,
          561,
          567,
          2378,
          380,
          6337,
          949,
          11,
          50978
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5692.32,
        "id": 1353,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5691.24,
        "temperature": 0,
        "text": " this is the weird thing that I do,",
        "tokens": [
          50978,
          341,
          307,
          264,
          3657,
          551,
          300,
          286,
          360,
          11,
          51032
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5695.52,
        "id": 1354,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5692.32,
        "temperature": 0,
        "text": " that this all gets edited later into shorter",
        "tokens": [
          51032,
          300,
          341,
          439,
          2170,
          23016,
          1780,
          666,
          11639,
          51192
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5697.8,
        "id": 1355,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5695.52,
        "temperature": 0,
        "text": " standalone videos that go in playlists.",
        "tokens": [
          51192,
          37454,
          2145,
          300,
          352,
          294,
          862,
          36693,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5699.88,
        "id": 1356,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5697.8,
        "temperature": 0,
        "text": " So I often, like, after I finish something,",
        "tokens": [
          51306,
          407,
          286,
          2049,
          11,
          411,
          11,
          934,
          286,
          2413,
          746,
          11,
          51410
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5701.12,
        "id": 1357,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5699.88,
        "temperature": 0,
        "text": " will do an intro.",
        "tokens": [
          51410,
          486,
          360,
          364,
          12897,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.27833398183186847,
        "compression_ratio": 1.5051020408163265,
        "end": 5704.54,
        "id": 1358,
        "no_speech_prob": 0.00006502743053715676,
        "seek": 567896,
        "start": 5702.12,
        "temperature": 0,
        "text": " So Daniel writes, make it a tutorial.",
        "tokens": [
          51522,
          407,
          8033,
          13657,
          11,
          652,
          309,
          257,
          7073,
          13,
          51643
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5710.0199999999995,
        "id": 1359,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5705.0199999999995,
        "temperature": 0,
        "text": " Joel asks, are there limitations to the shell commands",
        "tokens": [
          50388,
          21522,
          8962,
          11,
          366,
          456,
          15705,
          281,
          264,
          8720,
          16901,
          50638
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5713.06,
        "id": 1360,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5710.0199999999995,
        "temperature": 0,
        "text": " executable by node?",
        "tokens": [
          50638,
          7568,
          712,
          538,
          9984,
          30,
          50790
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5714.1,
        "id": 1361,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5713.06,
        "temperature": 0,
        "text": " Not really.",
        "tokens": [
          50790,
          1726,
          534,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5716.66,
        "id": 1362,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5714.1,
        "temperature": 0,
        "text": " I mean, the limitations are what you can execute",
        "tokens": [
          50842,
          286,
          914,
          11,
          264,
          15705,
          366,
          437,
          291,
          393,
          14483,
          50970
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5717.62,
        "id": 1363,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5716.66,
        "temperature": 0,
        "text": " as a shell command.",
        "tokens": [
          50970,
          382,
          257,
          8720,
          5622,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5721.54,
        "id": 1364,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5718.9,
        "temperature": 0,
        "text": " There's no difference between calling the exec function",
        "tokens": [
          51082,
          821,
          311,
          572,
          2649,
          1296,
          5141,
          264,
          4454,
          2445,
          51214
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5724.7,
        "id": 1365,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5721.54,
        "temperature": 0,
        "text": " in node and just typing the thing into the shell.",
        "tokens": [
          51214,
          294,
          9984,
          293,
          445,
          18444,
          264,
          551,
          666,
          264,
          8720,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5727.88,
        "id": 1366,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5724.7,
        "temperature": 0,
        "text": " There is this limitation though that if the shell command",
        "tokens": [
          51372,
          821,
          307,
          341,
          27432,
          1673,
          300,
          498,
          264,
          8720,
          5622,
          51531
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5731.3,
        "id": 1367,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5727.88,
        "temperature": 0,
        "text": " opens a window or operates like, you know,",
        "tokens": [
          51531,
          9870,
          257,
          4910,
          420,
          22577,
          411,
          11,
          291,
          458,
          11,
          51702
        ]
      },
      {
        "avg_logprob": -0.31369181512628946,
        "compression_ratio": 1.748917748917749,
        "end": 5734.0199999999995,
        "id": 1368,
        "no_speech_prob": 0.000007296368039533263,
        "seek": 570454,
        "start": 5731.3,
        "temperature": 0,
        "text": " some application that's on a Mac computer",
        "tokens": [
          51702,
          512,
          3861,
          300,
          311,
          322,
          257,
          5707,
          3820,
          51838
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5736.14,
        "id": 1369,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5734.540000000001,
        "temperature": 0,
        "text": " and you happen to deploy this to a server",
        "tokens": [
          50390,
          293,
          291,
          1051,
          281,
          7274,
          341,
          281,
          257,
          7154,
          50470
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5738.14,
        "id": 1370,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5736.14,
        "temperature": 0,
        "text": " that's a Linux server, it's not going to work.",
        "tokens": [
          50470,
          300,
          311,
          257,
          18734,
          7154,
          11,
          309,
          311,
          406,
          516,
          281,
          589,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5741.240000000001,
        "id": 1371,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5738.14,
        "temperature": 0,
        "text": " But as long as the system you're using supports",
        "tokens": [
          50570,
          583,
          382,
          938,
          382,
          264,
          1185,
          291,
          434,
          1228,
          9346,
          50725
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5743.040000000001,
        "id": 1372,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5741.240000000001,
        "temperature": 0,
        "text": " that shell command, you can execute it from node.",
        "tokens": [
          50725,
          300,
          8720,
          5622,
          11,
          291,
          393,
          14483,
          309,
          490,
          9984,
          13,
          50815
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5744.3,
        "id": 1373,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5743.040000000001,
        "temperature": 0,
        "text": " And it supports node.",
        "tokens": [
          50815,
          400,
          309,
          9346,
          9984,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5745.14,
        "id": 1374,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5744.3,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50878,
          1033,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5750.84,
        "id": 1375,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5748.14,
        "temperature": 0,
        "text": " Hello, welcome to a coding challenge.",
        "tokens": [
          51070,
          2425,
          11,
          2928,
          281,
          257,
          17720,
          3430,
          13,
          51205
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5753.06,
        "id": 1376,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5750.84,
        "temperature": 0,
        "text": " This one's a little bit weird because it's more like",
        "tokens": [
          51205,
          639,
          472,
          311,
          257,
          707,
          857,
          3657,
          570,
          309,
          311,
          544,
          411,
          51316
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5755.02,
        "id": 1377,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5753.06,
        "temperature": 0,
        "text": " an extension of a tutorial series that I'm doing,",
        "tokens": [
          51316,
          364,
          10320,
          295,
          257,
          7073,
          2638,
          300,
          286,
          478,
          884,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5757.02,
        "id": 1378,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5755.02,
        "temperature": 0,
        "text": " but I did it all in one video.",
        "tokens": [
          51414,
          457,
          286,
          630,
          309,
          439,
          294,
          472,
          960,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5759.18,
        "id": 1379,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5757.02,
        "temperature": 0,
        "text": " So I think maybe it can be a coding challenge.",
        "tokens": [
          51514,
          407,
          286,
          519,
          1310,
          309,
          393,
          312,
          257,
          17720,
          3430,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.2511255977717975,
        "compression_ratio": 1.650735294117647,
        "end": 5760.240000000001,
        "id": 1380,
        "no_speech_prob": 0.0005357774789445102,
        "seek": 573402,
        "start": 5759.18,
        "temperature": 0,
        "text": " I completed it.",
        "tokens": [
          51622,
          286,
          7365,
          309,
          13,
          51675
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5764.4,
        "id": 1381,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5760.24,
        "temperature": 0,
        "text": " I made a bot for Mastodon that picks a random number,",
        "tokens": [
          50364,
          286,
          1027,
          257,
          10592,
          337,
          376,
          525,
          378,
          266,
          300,
          16137,
          257,
          4974,
          1230,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5767.679999999999,
        "id": 1382,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5764.4,
        "temperature": 0,
        "text": " generates a little fractal tree using that angle,",
        "tokens": [
          50572,
          23815,
          257,
          707,
          17948,
          304,
          4230,
          1228,
          300,
          5802,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5769.36,
        "id": 1383,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5767.679999999999,
        "temperature": 0,
        "text": " and then posts that image.",
        "tokens": [
          50736,
          293,
          550,
          12300,
          300,
          3256,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5771.92,
        "id": 1384,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5769.36,
        "temperature": 0,
        "text": " This is inspired by the tree bot,",
        "tokens": [
          50820,
          639,
          307,
          7547,
          538,
          264,
          4230,
          10592,
          11,
          50948
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5773.96,
        "id": 1385,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5771.92,
        "temperature": 0,
        "text": " which I'm going to reference again in a second",
        "tokens": [
          50948,
          597,
          286,
          478,
          516,
          281,
          6408,
          797,
          294,
          257,
          1150,
          51050
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5775.4,
        "id": 1386,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5773.96,
        "temperature": 0,
        "text": " because I already did before.",
        "tokens": [
          51050,
          570,
          286,
          1217,
          630,
          949,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5778.5,
        "id": 1387,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5777.28,
        "temperature": 0,
        "text": " So if you're about to watch this,",
        "tokens": [
          51216,
          407,
          498,
          291,
          434,
          466,
          281,
          1159,
          341,
          11,
          51277
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5780.0199999999995,
        "id": 1388,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5778.5,
        "temperature": 0,
        "text": " enjoy the coding challenge.",
        "tokens": [
          51277,
          2103,
          264,
          17720,
          3430,
          13,
          51353
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5781.4,
        "id": 1389,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5780.0199999999995,
        "temperature": 0,
        "text": " I will publish the code for this.",
        "tokens": [
          51353,
          286,
          486,
          11374,
          264,
          3089,
          337,
          341,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5783.2,
        "id": 1390,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5781.4,
        "temperature": 0,
        "text": " Make your own Mastodon bot.",
        "tokens": [
          51422,
          4387,
          428,
          1065,
          376,
          525,
          378,
          266,
          10592,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5785.36,
        "id": 1391,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5783.2,
        "temperature": 0,
        "text": " If you want to know more about what is Mastodon",
        "tokens": [
          51512,
          759,
          291,
          528,
          281,
          458,
          544,
          466,
          437,
          307,
          376,
          525,
          378,
          266,
          51620
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5787.44,
        "id": 1392,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5785.36,
        "temperature": 0,
        "text": " and how do you sign up to get an API key",
        "tokens": [
          51620,
          293,
          577,
          360,
          291,
          1465,
          493,
          281,
          483,
          364,
          9362,
          2141,
          51724
        ]
      },
      {
        "avg_logprob": -0.21922273893614072,
        "compression_ratio": 1.6870748299319729,
        "end": 5789.04,
        "id": 1393,
        "no_speech_prob": 0.004468302708119154,
        "seek": 576024,
        "start": 5787.44,
        "temperature": 0,
        "text": " and all that stuff, then I will refer you",
        "tokens": [
          51724,
          293,
          439,
          300,
          1507,
          11,
          550,
          286,
          486,
          2864,
          291,
          51804
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5791.16,
        "id": 1394,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5789.04,
        "temperature": 0,
        "text": " to the tutorial series of which this video",
        "tokens": [
          50364,
          281,
          264,
          7073,
          2638,
          295,
          597,
          341,
          960,
          50470
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5792.6,
        "id": 1395,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5791.16,
        "temperature": 0,
        "text": " is also in the playlist.",
        "tokens": [
          50470,
          307,
          611,
          294,
          264,
          16788,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5794.08,
        "id": 1396,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5792.6,
        "temperature": 0,
        "text": " I don't know, does this make sense?",
        "tokens": [
          50542,
          286,
          500,
          380,
          458,
          11,
          775,
          341,
          652,
          2020,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5795,
        "id": 1397,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5794.08,
        "temperature": 0,
        "text": " Whatever.",
        "tokens": [
          50616,
          8541,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5796.56,
        "id": 1398,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5795,
        "temperature": 0,
        "text": " Watch the video, I do the whole project,",
        "tokens": [
          50662,
          7277,
          264,
          960,
          11,
          286,
          360,
          264,
          1379,
          1716,
          11,
          50740
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5797.6,
        "id": 1399,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5796.56,
        "temperature": 0,
        "text": " and then I finish it.",
        "tokens": [
          50740,
          293,
          550,
          286,
          2413,
          309,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5804.72,
        "id": 1400,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5803.28,
        "temperature": 0,
        "text": " What if I send a very big number,",
        "tokens": [
          51076,
          708,
          498,
          286,
          2845,
          257,
          588,
          955,
          1230,
          11,
          51148
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5806.24,
        "id": 1401,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5804.72,
        "temperature": 0,
        "text": " way more than 360?",
        "tokens": [
          51148,
          636,
          544,
          813,
          13898,
          30,
          51224
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5807.18,
        "id": 1402,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5806.24,
        "temperature": 0,
        "text": " Should work.",
        "tokens": [
          51224,
          6454,
          589,
          13,
          51271
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5814.48,
        "id": 1403,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5810.44,
        "temperature": 0,
        "text": " The rotation, once you get, if you do 365,",
        "tokens": [
          51434,
          440,
          12447,
          11,
          1564,
          291,
          483,
          11,
          498,
          291,
          360,
          22046,
          11,
          51636
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5816.24,
        "id": 1404,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5814.48,
        "temperature": 0,
        "text": " it's going to be the same as five degrees.",
        "tokens": [
          51636,
          309,
          311,
          516,
          281,
          312,
          264,
          912,
          382,
          1732,
          5310,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.298617724714608,
        "compression_ratio": 1.5126050420168067,
        "end": 5817.5199999999995,
        "id": 1405,
        "no_speech_prob": 0.00014425911649595946,
        "seek": 578904,
        "start": 5816.24,
        "temperature": 0,
        "text": " So I think it would still work.",
        "tokens": [
          51724,
          407,
          286,
          519,
          309,
          576,
          920,
          589,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2627506861611018,
        "compression_ratio": 1.5874125874125875,
        "end": 5820.22,
        "id": 1406,
        "no_speech_prob": 0.00002318743099749554,
        "seek": 581752,
        "start": 5817.52,
        "temperature": 0,
        "text": " I could constrain it if I wanted to within the code.",
        "tokens": [
          50364,
          286,
          727,
          1817,
          7146,
          309,
          498,
          286,
          1415,
          281,
          1951,
          264,
          3089,
          13,
          50499
        ]
      },
      {
        "avg_logprob": -0.2627506861611018,
        "compression_ratio": 1.5874125874125875,
        "end": 5823.92,
        "id": 1407,
        "no_speech_prob": 0.00002318743099749554,
        "seek": 581752,
        "start": 5823.080000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50642,
          1033,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2627506861611018,
        "compression_ratio": 1.5874125874125875,
        "end": 5838.580000000001,
        "id": 1408,
        "no_speech_prob": 0.00002318743099749554,
        "seek": 581752,
        "start": 5835.400000000001,
        "temperature": 0,
        "text": " Okay, part two of this coding challenge.",
        "tokens": [
          51258,
          1033,
          11,
          644,
          732,
          295,
          341,
          17720,
          3430,
          13,
          51417
        ]
      },
      {
        "avg_logprob": -0.2627506861611018,
        "compression_ratio": 1.5874125874125875,
        "end": 5839.96,
        "id": 1409,
        "no_speech_prob": 0.00002318743099749554,
        "seek": 581752,
        "start": 5838.580000000001,
        "temperature": 0,
        "text": " In part two of this coding challenge,",
        "tokens": [
          51417,
          682,
          644,
          732,
          295,
          341,
          17720,
          3430,
          11,
          51486
        ]
      },
      {
        "avg_logprob": -0.2627506861611018,
        "compression_ratio": 1.5874125874125875,
        "end": 5842.280000000001,
        "id": 1410,
        "no_speech_prob": 0.00002318743099749554,
        "seek": 581752,
        "start": 5839.96,
        "temperature": 0,
        "text": " I actually change it from just being a bot",
        "tokens": [
          51486,
          286,
          767,
          1319,
          309,
          490,
          445,
          885,
          257,
          10592,
          51602
        ]
      },
      {
        "avg_logprob": -0.2627506861611018,
        "compression_ratio": 1.5874125874125875,
        "end": 5847.280000000001,
        "id": 1411,
        "no_speech_prob": 0.00002318743099749554,
        "seek": 581752,
        "start": 5842.280000000001,
        "temperature": 0,
        "text": " that automatically posts a tree every so often",
        "tokens": [
          51602,
          300,
          6772,
          12300,
          257,
          4230,
          633,
          370,
          2049,
          51852
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5851.4,
        "id": 1412,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5847.44,
        "temperature": 0,
        "text": " to a bot that receives a post, a toot.",
        "tokens": [
          50372,
          281,
          257,
          10592,
          300,
          20717,
          257,
          2183,
          11,
          257,
          281,
          310,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5852.24,
        "id": 1413,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5851.4,
        "temperature": 0,
        "text": " They're called toots.",
        "tokens": [
          50570,
          814,
          434,
          1219,
          281,
          1971,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5853.679999999999,
        "id": 1414,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5852.24,
        "temperature": 0,
        "text": " I just got used to saying tweet,",
        "tokens": [
          50612,
          286,
          445,
          658,
          1143,
          281,
          1566,
          15258,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5854.759999999999,
        "id": 1415,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5853.679999999999,
        "temperature": 0,
        "text": " and now I got to say toot.",
        "tokens": [
          50684,
          293,
          586,
          286,
          658,
          281,
          584,
          281,
          310,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5855.66,
        "id": 1416,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5854.759999999999,
        "temperature": 0,
        "text": " This is very hard.",
        "tokens": [
          50738,
          639,
          307,
          588,
          1152,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5860.28,
        "id": 1417,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5857.36,
        "temperature": 0,
        "text": " It receives a toot mention from another account.",
        "tokens": [
          50868,
          467,
          20717,
          257,
          281,
          310,
          2152,
          490,
          1071,
          2696,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5864.759999999999,
        "id": 1418,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5860.28,
        "temperature": 0,
        "text": " Nathan, thank you to Nathan Growl for helping me test this.",
        "tokens": [
          51014,
          20634,
          11,
          1309,
          291,
          281,
          20634,
          18476,
          75,
          337,
          4315,
          385,
          1500,
          341,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5867.84,
        "id": 1419,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5864.759999999999,
        "temperature": 0,
        "text": " And it says, give me an 89 degree angle tree, please.",
        "tokens": [
          51238,
          400,
          309,
          1619,
          11,
          976,
          385,
          364,
          31877,
          4314,
          5802,
          4230,
          11,
          1767,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5870.04,
        "id": 1420,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5867.84,
        "temperature": 0,
        "text": " And then I, the coding trained bot,",
        "tokens": [
          51392,
          400,
          550,
          286,
          11,
          264,
          17720,
          8895,
          10592,
          11,
          51502
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5871.759999999999,
        "id": 1421,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5870.04,
        "temperature": 0,
        "text": " replies, generates that tree image,",
        "tokens": [
          51502,
          42289,
          11,
          23815,
          300,
          4230,
          3256,
          11,
          51588
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5872.759999999999,
        "id": 1422,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5871.759999999999,
        "temperature": 0,
        "text": " and replies back with it.",
        "tokens": [
          51588,
          293,
          42289,
          646,
          365,
          309,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5875.96,
        "id": 1423,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5872.759999999999,
        "temperature": 0,
        "text": " So I complete this aspect of it.",
        "tokens": [
          51638,
          407,
          286,
          3566,
          341,
          4171,
          295,
          309,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2671840985616048,
        "compression_ratio": 1.6357142857142857,
        "end": 5876.92,
        "id": 1424,
        "no_speech_prob": 0.00006709193985443562,
        "seek": 584728,
        "start": 5875.96,
        "temperature": 0,
        "text": " It's kind of convoluted.",
        "tokens": [
          51798,
          467,
          311,
          733,
          295,
          3754,
          2308,
          292,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5879.4800000000005,
        "id": 1425,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5877.56,
        "temperature": 0,
        "text": " I could probably refactor that code a little bit.",
        "tokens": [
          50396,
          286,
          727,
          1391,
          1895,
          15104,
          300,
          3089,
          257,
          707,
          857,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5880.88,
        "id": 1426,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5879.4800000000005,
        "temperature": 0,
        "text": " But, and I hope you enjoy watching",
        "tokens": [
          50492,
          583,
          11,
          293,
          286,
          1454,
          291,
          2103,
          1976,
          50562
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5882.88,
        "id": 1427,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5880.88,
        "temperature": 0,
        "text": " this second part of the coding challenge.",
        "tokens": [
          50562,
          341,
          1150,
          644,
          295,
          264,
          17720,
          3430,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5890.12,
        "id": 1428,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5888,
        "temperature": 0,
        "text": " Yeah, a float would just get the integer part",
        "tokens": [
          50918,
          865,
          11,
          257,
          15706,
          576,
          445,
          483,
          264,
          24922,
          644,
          51024
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5891.96,
        "id": 1429,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5890.12,
        "temperature": 0,
        "text": " because of the regular expression that I'm using.",
        "tokens": [
          51024,
          570,
          295,
          264,
          3890,
          6114,
          300,
          286,
          478,
          1228,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5893.82,
        "id": 1430,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5891.96,
        "temperature": 0,
        "text": " I could have made my regular expression.",
        "tokens": [
          51116,
          286,
          727,
          362,
          1027,
          452,
          3890,
          6114,
          13,
          51209
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5896.28,
        "id": 1431,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5893.82,
        "temperature": 0,
        "text": " So sorry, the question is from Adam.",
        "tokens": [
          51209,
          407,
          2597,
          11,
          264,
          1168,
          307,
          490,
          7938,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5898.6,
        "id": 1432,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5896.28,
        "temperature": 0,
        "text": " I wonder, how would it handle a float",
        "tokens": [
          51332,
          286,
          2441,
          11,
          577,
          576,
          309,
          4813,
          257,
          15706,
          51448
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5901,
        "id": 1433,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5898.6,
        "temperature": 0,
        "text": " or a number greater than 360?",
        "tokens": [
          51448,
          420,
          257,
          1230,
          5044,
          813,
          13898,
          30,
          51568
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5903.4800000000005,
        "id": 1434,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5901.84,
        "temperature": 0,
        "text": " Floats would probably be okay.",
        "tokens": [
          51610,
          15153,
          1720,
          576,
          1391,
          312,
          1392,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2611993421025637,
        "compression_ratio": 1.6917293233082706,
        "end": 5906.76,
        "id": 1435,
        "no_speech_prob": 0.000527476251590997,
        "seek": 587692,
        "start": 5903.4800000000005,
        "temperature": 0,
        "text": " So I could definitely change my regular expression",
        "tokens": [
          51692,
          407,
          286,
          727,
          2138,
          1319,
          452,
          3890,
          6114,
          51856
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5909.280000000001,
        "id": 1436,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5907.72,
        "temperature": 0,
        "text": " to account for that.",
        "tokens": [
          50412,
          281,
          2696,
          337,
          300,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5911.4800000000005,
        "id": 1437,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5909.280000000001,
        "temperature": 0,
        "text": " I forgot where I have it.",
        "tokens": [
          50490,
          286,
          5298,
          689,
          286,
          362,
          309,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5914.56,
        "id": 1438,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5911.4800000000005,
        "temperature": 0,
        "text": " So I could say like, optionally,",
        "tokens": [
          50600,
          407,
          286,
          727,
          584,
          411,
          11,
          3614,
          379,
          11,
          50754
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5916.64,
        "id": 1439,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5914.56,
        "temperature": 0,
        "text": " something like optionally a dot,",
        "tokens": [
          50754,
          746,
          411,
          3614,
          379,
          257,
          5893,
          11,
          50858
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5918.52,
        "id": 1440,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5916.64,
        "temperature": 0,
        "text": " but I'd have to do this, right?",
        "tokens": [
          50858,
          457,
          286,
          1116,
          362,
          281,
          360,
          341,
          11,
          558,
          30,
          50952
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5920.360000000001,
        "id": 1441,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5918.52,
        "temperature": 0,
        "text": " Because I want a literal dot optionally,",
        "tokens": [
          50952,
          1436,
          286,
          528,
          257,
          20411,
          5893,
          3614,
          379,
          11,
          51044
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5923.64,
        "id": 1442,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5920.360000000001,
        "temperature": 0,
        "text": " and then some more digits optionally, whatever.",
        "tokens": [
          51044,
          293,
          550,
          512,
          544,
          27011,
          3614,
          379,
          11,
          2035,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5925.42,
        "id": 1443,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5923.64,
        "temperature": 0,
        "text": " Something like that I could do.",
        "tokens": [
          51208,
          6595,
          411,
          300,
          286,
          727,
          360,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5928.860000000001,
        "id": 1444,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5926.42,
        "temperature": 0,
        "text": " But I'm not, can I leave it running for a while?",
        "tokens": [
          51347,
          583,
          286,
          478,
          406,
          11,
          393,
          286,
          1856,
          309,
          2614,
          337,
          257,
          1339,
          30,
          51469
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5930.06,
        "id": 1445,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5928.860000000001,
        "temperature": 0,
        "text": " I want some trees.",
        "tokens": [
          51469,
          286,
          528,
          512,
          5852,
          13,
          51529
        ]
      },
      {
        "avg_logprob": -0.25413069260858856,
        "compression_ratio": 1.6886792452830188,
        "end": 5932.84,
        "id": 1446,
        "no_speech_prob": 0.00004198623719275929,
        "seek": 590676,
        "start": 5931.24,
        "temperature": 0,
        "text": " Why don't I deploy this?",
        "tokens": [
          51588,
          1545,
          500,
          380,
          286,
          7274,
          341,
          30,
          51668
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5941.24,
        "id": 1447,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5936.92,
        "temperature": 0,
        "text": " I kind of need, I kind of want to make a,",
        "tokens": [
          50372,
          286,
          733,
          295,
          643,
          11,
          286,
          733,
          295,
          528,
          281,
          652,
          257,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5944,
        "id": 1448,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5941.24,
        "temperature": 0,
        "text": " I probably should make the bot that does all the things",
        "tokens": [
          50588,
          286,
          1391,
          820,
          652,
          264,
          10592,
          300,
          775,
          439,
          264,
          721,
          50726
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5945.68,
        "id": 1449,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5944,
        "temperature": 0,
        "text": " in all the videos that I've shown so far,",
        "tokens": [
          50726,
          294,
          439,
          264,
          2145,
          300,
          286,
          600,
          4898,
          370,
          1400,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5947.280000000001,
        "id": 1450,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5945.68,
        "temperature": 0,
        "text": " and then deploy it.",
        "tokens": [
          50810,
          293,
          550,
          7274,
          309,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5948.88,
        "id": 1451,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5947.280000000001,
        "temperature": 0,
        "text": " Anybody wants to help with that?",
        "tokens": [
          50890,
          19082,
          2738,
          281,
          854,
          365,
          300,
          30,
          50970
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5949.72,
        "id": 1452,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5948.88,
        "temperature": 0,
        "text": " Ha ha ha.",
        "tokens": [
          50970,
          4064,
          324,
          324,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5953.96,
        "id": 1453,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5951.320000000001,
        "temperature": 0,
        "text": " So, anybody wants to help with that?",
        "tokens": [
          51092,
          407,
          11,
          4472,
          2738,
          281,
          854,
          365,
          300,
          30,
          51224
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5957.68,
        "id": 1454,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5956.400000000001,
        "temperature": 0,
        "text": " Let me do this.",
        "tokens": [
          51346,
          961,
          385,
          360,
          341,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.2913900740603183,
        "compression_ratio": 1.6368715083798884,
        "end": 5964.52,
        "id": 1455,
        "no_speech_prob": 0.0000027694040909409523,
        "seek": 593676,
        "start": 5962.4400000000005,
        "temperature": 0,
        "text": " Let's do this real quick before I go.",
        "tokens": [
          51648,
          961,
          311,
          360,
          341,
          957,
          1702,
          949,
          286,
          352,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5968.92,
        "id": 1456,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5967.24,
        "temperature": 0,
        "text": " Let's create a new repo.",
        "tokens": [
          50388,
          961,
          311,
          1884,
          257,
          777,
          49040,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5974.08,
        "id": 1457,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5971.24,
        "temperature": 0,
        "text": " Coding train bot.",
        "tokens": [
          50588,
          383,
          8616,
          3847,
          10592,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5976.4400000000005,
        "id": 1458,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5974.08,
        "temperature": 0,
        "text": " No, no, stop.",
        "tokens": [
          50730,
          883,
          11,
          572,
          11,
          1590,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5977.66,
        "id": 1459,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5976.4400000000005,
        "temperature": 0,
        "text": " Coding train bot.",
        "tokens": [
          50848,
          383,
          8616,
          3847,
          10592,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5980.4800000000005,
        "id": 1460,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5979.64,
        "temperature": 0,
        "text": " Stop!",
        "tokens": [
          51008,
          5535,
          0,
          51050
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5985.12,
        "id": 1461,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5984.280000000001,
        "temperature": 0,
        "text": " Bot.",
        "tokens": [
          51240,
          25486,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5989.360000000001,
        "id": 1462,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5986.8,
        "temperature": 0,
        "text": " Bot code for coding train.",
        "tokens": [
          51366,
          25486,
          3089,
          337,
          17720,
          3847,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5993.400000000001,
        "id": 1463,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5992,
        "temperature": 0,
        "text": " Sure, whatever.",
        "tokens": [
          51626,
          4894,
          11,
          2035,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.4178451669627222,
        "compression_ratio": 1.33,
        "end": 5996.08,
        "id": 1464,
        "no_speech_prob": 0.00004539782094070688,
        "seek": 596676,
        "start": 5995.24,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          51788,
          7010,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6001.06,
        "id": 1465,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 5997.6,
        "temperature": 0,
        "text": " Okay, then I am going to,",
        "tokens": [
          50406,
          1033,
          11,
          550,
          286,
          669,
          516,
          281,
          11,
          50579
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6006.04,
        "id": 1466,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6004.320000000001,
        "temperature": 0,
        "text": " let me create a new file.",
        "tokens": [
          50742,
          718,
          385,
          1884,
          257,
          777,
          3991,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6011.360000000001,
        "id": 1467,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6007.88,
        "temperature": 0,
        "text": " Dot, dot git ignore.",
        "tokens": [
          50920,
          38753,
          11,
          5893,
          18331,
          11200,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6015.08,
        "id": 1468,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6012.64,
        "temperature": 0,
        "text": " And I want to ignore node modules.",
        "tokens": [
          51158,
          400,
          286,
          528,
          281,
          11200,
          9984,
          16679,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6017,
        "id": 1469,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6015.08,
        "temperature": 0,
        "text": " Sorry that you can't see this.",
        "tokens": [
          51280,
          4919,
          300,
          291,
          393,
          380,
          536,
          341,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6018.9400000000005,
        "id": 1470,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6017,
        "temperature": 0,
        "text": " And I want to ignore, what did I have in,",
        "tokens": [
          51376,
          400,
          286,
          528,
          281,
          11200,
          11,
          437,
          630,
          286,
          362,
          294,
          11,
          51473
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6020.88,
        "id": 1471,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6018.9400000000005,
        "temperature": 0,
        "text": " what am I ignoring in all my things?",
        "tokens": [
          51473,
          437,
          669,
          286,
          26258,
          294,
          439,
          452,
          721,
          30,
          51570
        ]
      },
      {
        "avg_logprob": -0.3228232292901902,
        "compression_ratio": 1.51875,
        "end": 6026.56,
        "id": 1472,
        "no_speech_prob": 0.0000453977299912367,
        "seek": 599676,
        "start": 6024.16,
        "temperature": 0,
        "text": " I don't want dot vs code.",
        "tokens": [
          51734,
          286,
          500,
          380,
          528,
          5893,
          12041,
          3089,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6029.64,
        "id": 1473,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6027.360000000001,
        "temperature": 0,
        "text": " I think, because who knows what's in that.",
        "tokens": [
          50404,
          286,
          519,
          11,
          570,
          567,
          3255,
          437,
          311,
          294,
          300,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6031.120000000001,
        "id": 1474,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6029.64,
        "temperature": 0,
        "text": " And I don't want dot env.",
        "tokens": [
          50518,
          400,
          286,
          500,
          380,
          528,
          5893,
          2267,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6033.96,
        "id": 1475,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6033.120000000001,
        "temperature": 0,
        "text": " So, whoops.",
        "tokens": [
          50692,
          407,
          11,
          567,
          3370,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6036.04,
        "id": 1476,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6033.96,
        "temperature": 0,
        "text": " So, this is git ignore.",
        "tokens": [
          50734,
          407,
          11,
          341,
          307,
          18331,
          11200,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6041.96,
        "id": 1477,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6039.92,
        "temperature": 0,
        "text": " Come on, you can do it.",
        "tokens": [
          51032,
          2492,
          322,
          11,
          291,
          393,
          360,
          309,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6043.88,
        "id": 1478,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6041.96,
        "temperature": 0,
        "text": " You can commit this new file.",
        "tokens": [
          51134,
          509,
          393,
          5599,
          341,
          777,
          3991,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6044.72,
        "id": 1479,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6043.88,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51230,
          821,
          321,
          352,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.3514667459436365,
        "compression_ratio": 1.3448275862068966,
        "end": 6048.4400000000005,
        "id": 1480,
        "no_speech_prob": 0.00006709120498271659,
        "seek": 602656,
        "start": 6045.56,
        "temperature": 0,
        "text": " Let's try cloning this.",
        "tokens": [
          51314,
          961,
          311,
          853,
          596,
          16638,
          341,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6061.280000000001,
        "id": 1481,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6056.56,
        "temperature": 0,
        "text": " Git clone, whoops.",
        "tokens": [
          50364,
          16939,
          26506,
          11,
          567,
          3370,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6063.96,
        "id": 1482,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6061.280000000001,
        "temperature": 0,
        "text": " Git clone this.",
        "tokens": [
          50600,
          16939,
          26506,
          341,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6066.320000000001,
        "id": 1483,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6065.04,
        "temperature": 0,
        "text": " Open.",
        "tokens": [
          50788,
          7238,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6068.4400000000005,
        "id": 1484,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6066.320000000001,
        "temperature": 0,
        "text": " So, what I'm going to do is,",
        "tokens": [
          50852,
          407,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6070.8,
        "id": 1485,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6069.96,
        "temperature": 0,
        "text": " where is that?",
        "tokens": [
          51034,
          689,
          307,
          300,
          30,
          51076
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6072.6,
        "id": 1486,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6070.8,
        "temperature": 0,
        "text": " Coding train mastodon bot, mastodon.",
        "tokens": [
          51076,
          383,
          8616,
          3847,
          27055,
          378,
          266,
          10592,
          11,
          27055,
          378,
          266,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6076.200000000001,
        "id": 1487,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6072.6,
        "temperature": 0,
        "text": " I'm going to put, so here's what I would love.",
        "tokens": [
          51166,
          286,
          478,
          516,
          281,
          829,
          11,
          370,
          510,
          311,
          437,
          286,
          576,
          959,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6077.400000000001,
        "id": 1488,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6076.200000000001,
        "temperature": 0,
        "text": " Oh boy.",
        "tokens": [
          51346,
          876,
          3237,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6080.1,
        "id": 1489,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6077.400000000001,
        "temperature": 0,
        "text": " I would love you forever if you can help me with this.",
        "tokens": [
          51406,
          286,
          576,
          959,
          291,
          5680,
          498,
          291,
          393,
          854,
          385,
          365,
          341,
          13,
          51541
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6083.080000000001,
        "id": 1490,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6081,
        "temperature": 0,
        "text": " So, and I'll file the issues.",
        "tokens": [
          51586,
          407,
          11,
          293,
          286,
          603,
          3991,
          264,
          2663,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.29127151901657516,
        "compression_ratio": 1.6,
        "end": 6085.9800000000005,
        "id": 1491,
        "no_speech_prob": 0.00016346407937817276,
        "seek": 605656,
        "start": 6083.080000000001,
        "temperature": 0,
        "text": " So, let me, give me a second here.",
        "tokens": [
          51690,
          407,
          11,
          718,
          385,
          11,
          976,
          385,
          257,
          1150,
          510,
          13,
          51835
        ]
      },
      {
        "avg_logprob": -0.3985632089468149,
        "compression_ratio": 1.6111111111111112,
        "end": 6087.400000000001,
        "id": 1492,
        "no_speech_prob": 0.000127307532238774,
        "seek": 608656,
        "start": 6086.56,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.3985632089468149,
        "compression_ratio": 1.6111111111111112,
        "end": 6100.280000000001,
        "id": 1493,
        "no_speech_prob": 0.000127307532238774,
        "seek": 608656,
        "start": 6095.280000000001,
        "temperature": 0,
        "text": " So, what I want to get rid of,",
        "tokens": [
          50800,
          407,
          11,
          437,
          286,
          528,
          281,
          483,
          3973,
          295,
          11,
          51050
        ]
      },
      {
        "avg_logprob": -0.3985632089468149,
        "compression_ratio": 1.6111111111111112,
        "end": 6102.400000000001,
        "id": 1494,
        "no_speech_prob": 0.000127307532238774,
        "seek": 608656,
        "start": 6100.96,
        "temperature": 0,
        "text": " I don't need this git ignore.",
        "tokens": [
          51084,
          286,
          500,
          380,
          643,
          341,
          18331,
          11200,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.3985632089468149,
        "compression_ratio": 1.6111111111111112,
        "end": 6107.04,
        "id": 1495,
        "no_speech_prob": 0.000127307532238774,
        "seek": 608656,
        "start": 6104.4400000000005,
        "temperature": 0,
        "text": " Like this is, I don't need that git ignore.",
        "tokens": [
          51258,
          1743,
          341,
          307,
          11,
          286,
          500,
          380,
          643,
          300,
          18331,
          11200,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.3985632089468149,
        "compression_ratio": 1.6111111111111112,
        "end": 6109.4800000000005,
        "id": 1496,
        "no_speech_prob": 0.000127307532238774,
        "seek": 608656,
        "start": 6107.04,
        "temperature": 0,
        "text": " I don't need that git ignore, okay.",
        "tokens": [
          51388,
          286,
          500,
          380,
          643,
          300,
          18331,
          11200,
          11,
          1392,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.3985632089468149,
        "compression_ratio": 1.6111111111111112,
        "end": 6112.320000000001,
        "id": 1497,
        "no_speech_prob": 0.000127307532238774,
        "seek": 608656,
        "start": 6109.4800000000005,
        "temperature": 0,
        "text": " So, now git status, whoops.",
        "tokens": [
          51510,
          407,
          11,
          586,
          18331,
          6558,
          11,
          567,
          3370,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.43094087080522014,
        "compression_ratio": 1.3157894736842106,
        "end": 6113.16,
        "id": 1498,
        "no_speech_prob": 0.00007254308002302423,
        "seek": 611232,
        "start": 6112.32,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.43094087080522014,
        "compression_ratio": 1.3157894736842106,
        "end": 6125.639999999999,
        "id": 1499,
        "no_speech_prob": 0.00007254308002302423,
        "seek": 611232,
        "start": 6122.4,
        "temperature": 0,
        "text": " I'm going to be very confident I did git ignore correctly",
        "tokens": [
          50868,
          286,
          478,
          516,
          281,
          312,
          588,
          6679,
          286,
          630,
          18331,
          11200,
          8944,
          51030
        ]
      },
      {
        "avg_logprob": -0.43094087080522014,
        "compression_ratio": 1.3157894736842106,
        "end": 6128.36,
        "id": 1500,
        "no_speech_prob": 0.00007254308002302423,
        "seek": 611232,
        "start": 6125.639999999999,
        "temperature": 0,
        "text": " and I'm going to git add, git commit.",
        "tokens": [
          51030,
          293,
          286,
          478,
          516,
          281,
          18331,
          909,
          11,
          18331,
          5599,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.43094087080522014,
        "compression_ratio": 1.3157894736842106,
        "end": 6134.96,
        "id": 1501,
        "no_speech_prob": 0.00007254308002302423,
        "seek": 611232,
        "start": 6130.38,
        "temperature": 0,
        "text": " And I'm going to say, upload, whoops.",
        "tokens": [
          51267,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          6580,
          11,
          567,
          3370,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.43094087080522014,
        "compression_ratio": 1.3157894736842106,
        "end": 6138.16,
        "id": 1502,
        "no_speech_prob": 0.00007254308002302423,
        "seek": 611232,
        "start": 6137.32,
        "temperature": 0,
        "text": " Shoot.",
        "tokens": [
          51614,
          19760,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.43094087080522014,
        "compression_ratio": 1.3157894736842106,
        "end": 6140.4,
        "id": 1503,
        "no_speech_prob": 0.00007254308002302423,
        "seek": 611232,
        "start": 6139.5599999999995,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51726,
          2438,
          0,
          51768
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6144.96,
        "id": 1504,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6141.4,
        "temperature": 0,
        "text": " How do I associate editor with git?",
        "tokens": [
          50414,
          1012,
          360,
          286,
          14644,
          9839,
          365,
          18331,
          30,
          50592
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6146.12,
        "id": 1505,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6144.96,
        "temperature": 0,
        "text": " I can't use VI.",
        "tokens": [
          50592,
          286,
          393,
          380,
          764,
          27619,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6147.759999999999,
        "id": 1506,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6146.12,
        "temperature": 0,
        "text": " I'm incapable of using VI.",
        "tokens": [
          50650,
          286,
          478,
          44174,
          295,
          1228,
          27619,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6152.36,
        "id": 1507,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6149.44,
        "temperature": 0,
        "text": " So, I'm going to, and I could just do dash M,",
        "tokens": [
          50816,
          407,
          11,
          286,
          478,
          516,
          281,
          11,
          293,
          286,
          727,
          445,
          360,
          8240,
          376,
          11,
          50962
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6154.96,
        "id": 1508,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6152.36,
        "temperature": 0,
        "text": " but I'm trying to be a good citizen.",
        "tokens": [
          50962,
          457,
          286,
          478,
          1382,
          281,
          312,
          257,
          665,
          13326,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6160.799999999999,
        "id": 1509,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6158.639999999999,
        "temperature": 0,
        "text": " And you guys are really spamming this bot.",
        "tokens": [
          51276,
          400,
          291,
          1074,
          366,
          534,
          24028,
          2810,
          341,
          10592,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6164.599999999999,
        "id": 1510,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6162.5199999999995,
        "temperature": 0,
        "text": " Oh shoot, all those files.",
        "tokens": [
          51470,
          876,
          3076,
          11,
          439,
          729,
          7098,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.30411548828810786,
        "compression_ratio": 1.3915343915343916,
        "end": 6166.48,
        "id": 1511,
        "no_speech_prob": 0.000006048915565770585,
        "seek": 614040,
        "start": 6164.599999999999,
        "temperature": 0,
        "text": " Thank you, I forgot about that.",
        "tokens": [
          51574,
          1044,
          291,
          11,
          286,
          5298,
          466,
          300,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6170.759999999999,
        "id": 1512,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6166.679999999999,
        "temperature": 0,
        "text": " Oh, good, but I haven't done that yet.",
        "tokens": [
          50374,
          876,
          11,
          665,
          11,
          457,
          286,
          2378,
          380,
          1096,
          300,
          1939,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6172.08,
        "id": 1513,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6170.759999999999,
        "temperature": 0,
        "text": " Can I remove those?",
        "tokens": [
          50578,
          1664,
          286,
          4159,
          729,
          30,
          50644
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6173.12,
        "id": 1514,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6172.08,
        "temperature": 0,
        "text": " Is it too late?",
        "tokens": [
          50644,
          1119,
          309,
          886,
          3469,
          30,
          50696
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6179.04,
        "id": 1515,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6177.94,
        "temperature": 0,
        "text": " Can I unstage?",
        "tokens": [
          50937,
          1664,
          286,
          18799,
          609,
          30,
          50992
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6180.62,
        "id": 1516,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6179.04,
        "temperature": 0,
        "text": " How do I unstage files?",
        "tokens": [
          50992,
          1012,
          360,
          286,
          18799,
          609,
          7098,
          30,
          51071
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6184.28,
        "id": 1517,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6180.62,
        "temperature": 0,
        "text": " So, I don't want to add these data.json files.",
        "tokens": [
          51071,
          407,
          11,
          286,
          500,
          380,
          528,
          281,
          909,
          613,
          1412,
          13,
          73,
          3015,
          7098,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6187.16,
        "id": 1518,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6184.28,
        "temperature": 0,
        "text": " How do I unstage files?",
        "tokens": [
          51254,
          1012,
          360,
          286,
          18799,
          609,
          7098,
          30,
          51398
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6190.04,
        "id": 1519,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6188.5599999999995,
        "temperature": 0,
        "text": " Can I just do remove?",
        "tokens": [
          51468,
          1664,
          286,
          445,
          360,
          4159,
          30,
          51542
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6191.5,
        "id": 1520,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6190.04,
        "temperature": 0,
        "text": " Git unstage.",
        "tokens": [
          51542,
          16939,
          18799,
          609,
          13,
          51615
        ]
      },
      {
        "avg_logprob": -0.2822992905326512,
        "compression_ratio": 1.5838926174496644,
        "end": 6196.12,
        "id": 1521,
        "no_speech_prob": 0.0000573875404370483,
        "seek": 616648,
        "start": 6194.2,
        "temperature": 0,
        "text": " Unstaging files.",
        "tokens": [
          51750,
          1156,
          372,
          3568,
          7098,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6198.32,
        "id": 1522,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6197.48,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50414,
          2438,
          0,
          50456
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6203.879999999999,
        "id": 1523,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6202.799999999999,
        "temperature": 0,
        "text": " Git reset.",
        "tokens": [
          50680,
          16939,
          14322,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6206.679999999999,
        "id": 1524,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6205,
        "temperature": 0,
        "text": " Oh, great, let's do that.",
        "tokens": [
          50790,
          876,
          11,
          869,
          11,
          718,
          311,
          360,
          300,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6208.2,
        "id": 1525,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6206.679999999999,
        "temperature": 0,
        "text": " Git reset.",
        "tokens": [
          50874,
          16939,
          14322,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6209.5,
        "id": 1526,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6208.2,
        "temperature": 0,
        "text": " I'm going to git status.",
        "tokens": [
          50950,
          286,
          478,
          516,
          281,
          18331,
          6558,
          13,
          51015
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6213.959999999999,
        "id": 1527,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6211.32,
        "temperature": 0,
        "text": " Perfect, thank you, that was easy.",
        "tokens": [
          51106,
          10246,
          11,
          1309,
          291,
          11,
          300,
          390,
          1858,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6215.959999999999,
        "id": 1528,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6213.959999999999,
        "temperature": 0,
        "text": " Git reset.",
        "tokens": [
          51238,
          16939,
          14322,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6218.08,
        "id": 1529,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6215.959999999999,
        "temperature": 0,
        "text": " So here, I don't want any of these.",
        "tokens": [
          51338,
          407,
          510,
          11,
          286,
          500,
          380,
          528,
          604,
          295,
          613,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6221.599999999999,
        "id": 1530,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6219.2,
        "temperature": 0,
        "text": " And here, so it's just in that one.",
        "tokens": [
          51500,
          400,
          510,
          11,
          370,
          309,
          311,
          445,
          294,
          300,
          472,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.35346887225196477,
        "compression_ratio": 1.4513888888888888,
        "end": 6226.28,
        "id": 1531,
        "no_speech_prob": 0.00002627457433845848,
        "seek": 619648,
        "start": 6223.24,
        "temperature": 0,
        "text": " And in theory,",
        "tokens": [
          51702,
          400,
          294,
          5261,
          11,
          51854
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6229.16,
        "id": 1532,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6227.12,
        "temperature": 0,
        "text": " I think I really have to shut off the bots,",
        "tokens": [
          50406,
          286,
          519,
          286,
          534,
          362,
          281,
          5309,
          766,
          264,
          35410,
          11,
          50508
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6230.96,
        "id": 1533,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6229.16,
        "temperature": 0,
        "text": " making me crazy.",
        "tokens": [
          50508,
          1455,
          385,
          3219,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6233.5599999999995,
        "id": 1534,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6230.96,
        "temperature": 0,
        "text": " Git status, wait, oops.",
        "tokens": [
          50598,
          16939,
          6558,
          11,
          1699,
          11,
          34166,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6234.7,
        "id": 1535,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6233.5599999999995,
        "temperature": 0,
        "text": " Git status.",
        "tokens": [
          50728,
          16939,
          6558,
          13,
          50785
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6238.5,
        "id": 1536,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6235.719999999999,
        "temperature": 0,
        "text": " Now let me get my editor working here.",
        "tokens": [
          50836,
          823,
          718,
          385,
          483,
          452,
          9839,
          1364,
          510,
          13,
          50975
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6245.12,
        "id": 1537,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6243.08,
        "temperature": 0,
        "text": " Why did that, oh, the camera went off.",
        "tokens": [
          51204,
          1545,
          630,
          300,
          11,
          1954,
          11,
          264,
          2799,
          1437,
          766,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.3830489052666558,
        "compression_ratio": 1.4367088607594938,
        "end": 6254.9,
        "id": 1538,
        "no_speech_prob": 0.00005649787271977402,
        "seek": 622628,
        "start": 6251.599999999999,
        "temperature": 0,
        "text": " Here we go, git config dash dash global core editor.",
        "tokens": [
          51630,
          1692,
          321,
          352,
          11,
          18331,
          6662,
          8240,
          8240,
          4338,
          4965,
          9839,
          13,
          51795
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6261.08,
        "id": 1539,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6256.679999999999,
        "temperature": 0,
        "text": " Git config dash dash global core dot editor.",
        "tokens": [
          50384,
          16939,
          6662,
          8240,
          8240,
          4338,
          4965,
          5893,
          9839,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6265.16,
        "id": 1540,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6262.2,
        "temperature": 0,
        "text": " Code dash dash wait, I think.",
        "tokens": [
          50660,
          15549,
          8240,
          8240,
          1699,
          11,
          286,
          519,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6266.32,
        "id": 1541,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6265.16,
        "temperature": 0,
        "text": " That right?",
        "tokens": [
          50808,
          663,
          558,
          30,
          50866
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6267.16,
        "id": 1542,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6266.32,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50866,
          865,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6271.639999999999,
        "id": 1543,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6267.16,
        "temperature": 0,
        "text": " And now, all right, so now I'm going to add those,",
        "tokens": [
          50908,
          400,
          586,
          11,
          439,
          558,
          11,
          370,
          586,
          286,
          478,
          516,
          281,
          909,
          729,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6273.0599999999995,
        "id": 1544,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6271.639999999999,
        "temperature": 0,
        "text": " stage those files.",
        "tokens": [
          51132,
          3233,
          729,
          7098,
          13,
          51203
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6277.04,
        "id": 1545,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6274.639999999999,
        "temperature": 0,
        "text": " Go wait for that to draw that tree.",
        "tokens": [
          51282,
          1037,
          1699,
          337,
          300,
          281,
          2642,
          300,
          4230,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6277.88,
        "id": 1546,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6277.04,
        "temperature": 0,
        "text": " Say git config.",
        "tokens": [
          51402,
          6463,
          18331,
          6662,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6280.679999999999,
        "id": 1547,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6279.16,
        "temperature": 0,
        "text": " Okay, I have to shut it off.",
        "tokens": [
          51508,
          1033,
          11,
          286,
          362,
          281,
          5309,
          309,
          766,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.3555105559679927,
        "compression_ratio": 1.4795918367346939,
        "end": 6283.0599999999995,
        "id": 1548,
        "no_speech_prob": 0.0000725433710613288,
        "seek": 625628,
        "start": 6280.679999999999,
        "temperature": 0,
        "text": " I'm sorry, everybody, I can't take it anymore.",
        "tokens": [
          51584,
          286,
          478,
          2597,
          11,
          2201,
          11,
          286,
          393,
          380,
          747,
          309,
          3602,
          13,
          51703
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6284.860000000001,
        "id": 1549,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6284.02,
        "temperature": 0,
        "text": " Ha ha ha.",
        "tokens": [
          50412,
          4064,
          324,
          324,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6288.06,
        "id": 1550,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6286.06,
        "temperature": 0,
        "text": " I can't take it anymore, okay.",
        "tokens": [
          50514,
          286,
          393,
          380,
          747,
          309,
          3602,
          11,
          1392,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6291,
        "id": 1551,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6289.660000000001,
        "temperature": 0,
        "text": " Git commit.",
        "tokens": [
          50694,
          16939,
          5599,
          13,
          50761
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6294.820000000001,
        "id": 1552,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6291,
        "temperature": 0,
        "text": " All right, so now I am adding",
        "tokens": [
          50761,
          1057,
          558,
          11,
          370,
          586,
          286,
          669,
          5127,
          50952
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6301.14,
        "id": 1553,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6296.14,
        "temperature": 0,
        "text": " code from all Mastodon tutorials.",
        "tokens": [
          51018,
          3089,
          490,
          439,
          376,
          525,
          378,
          266,
          17616,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6307.88,
        "id": 1554,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6305.06,
        "temperature": 0,
        "text": " This needs some work.",
        "tokens": [
          51464,
          639,
          2203,
          512,
          589,
          13,
          51605
        ]
      },
      {
        "avg_logprob": -0.3552317399245042,
        "compression_ratio": 1.2867132867132867,
        "end": 6312.88,
        "id": 1555,
        "no_speech_prob": 0.00044421094935387373,
        "seek": 628306,
        "start": 6307.88,
        "temperature": 0,
        "text": " I'll open issues, but it's missing the image.",
        "tokens": [
          51605,
          286,
          603,
          1269,
          2663,
          11,
          457,
          309,
          311,
          5361,
          264,
          3256,
          13,
          51855
        ]
      },
      {
        "avg_logprob": -0.34339318452058015,
        "compression_ratio": 1.330827067669173,
        "end": 6316.46,
        "id": 1556,
        "no_speech_prob": 0.0007793576223775744,
        "seek": 631306,
        "start": 6313.18,
        "temperature": 0,
        "text": " Uploader bot without replying.",
        "tokens": [
          50370,
          624,
          21132,
          8312,
          10592,
          1553,
          1085,
          7310,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.34339318452058015,
        "compression_ratio": 1.330827067669173,
        "end": 6321.46,
        "id": 1557,
        "no_speech_prob": 0.0007793576223775744,
        "seek": 631306,
        "start": 6316.46,
        "temperature": 0,
        "text": " And I also intend to put all of this together",
        "tokens": [
          50534,
          400,
          286,
          611,
          19759,
          281,
          829,
          439,
          295,
          341,
          1214,
          50784
        ]
      },
      {
        "avg_logprob": -0.34339318452058015,
        "compression_ratio": 1.330827067669173,
        "end": 6325.5,
        "id": 1558,
        "no_speech_prob": 0.0007793576223775744,
        "seek": 631306,
        "start": 6321.740000000001,
        "temperature": 0,
        "text": " in a single bot and deploy it.",
        "tokens": [
          50798,
          294,
          257,
          2167,
          10592,
          293,
          7274,
          309,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.34339318452058015,
        "compression_ratio": 1.330827067669173,
        "end": 6329.22,
        "id": 1559,
        "no_speech_prob": 0.0007793576223775744,
        "seek": 631306,
        "start": 6327.72,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51097,
          1033,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.34339318452058015,
        "compression_ratio": 1.330827067669173,
        "end": 6330.900000000001,
        "id": 1560,
        "no_speech_prob": 0.0007793576223775744,
        "seek": 631306,
        "start": 6329.22,
        "temperature": 0,
        "text": " So this will be a",
        "tokens": [
          51172,
          407,
          341,
          486,
          312,
          257,
          51256
        ]
      },
      {
        "avg_logprob": -0.34339318452058015,
        "compression_ratio": 1.330827067669173,
        "end": 6337.26,
        "id": 1561,
        "no_speech_prob": 0.0007793576223775744,
        "seek": 631306,
        "start": 6333.1,
        "temperature": 0,
        "text": " pull requests and community features welcome.",
        "tokens": [
          51366,
          2235,
          12475,
          293,
          1768,
          4122,
          2928,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6340.54,
        "id": 1562,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6338.26,
        "temperature": 0,
        "text": " Okay, let me do that.",
        "tokens": [
          50414,
          1033,
          11,
          718,
          385,
          360,
          300,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6343.8,
        "id": 1563,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6340.54,
        "temperature": 0,
        "text": " And then git push origin master.",
        "tokens": [
          50528,
          400,
          550,
          18331,
          2944,
          4957,
          4505,
          13,
          50691
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6345.9400000000005,
        "id": 1564,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6345.1,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50756,
          1033,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6348.56,
        "id": 1565,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6347.54,
        "temperature": 0,
        "text": " So,",
        "tokens": [
          50878,
          407,
          11,
          50929
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6354.1,
        "id": 1566,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6351.38,
        "temperature": 0,
        "text": " so what I need now, anybody wants to help?",
        "tokens": [
          51070,
          370,
          437,
          286,
          643,
          586,
          11,
          4472,
          2738,
          281,
          854,
          30,
          51206
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6355.54,
        "id": 1567,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6354.1,
        "temperature": 0,
        "text": " Oh, and I forgot to put this.",
        "tokens": [
          51206,
          876,
          11,
          293,
          286,
          5298,
          281,
          829,
          341,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6359.900000000001,
        "id": 1568,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6357.820000000001,
        "temperature": 0,
        "text": " I'll need to transfer this repo.",
        "tokens": [
          51392,
          286,
          603,
          643,
          281,
          5003,
          341,
          49040,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6362.46,
        "id": 1569,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6361.1,
        "temperature": 0,
        "text": " Transfer repo.",
        "tokens": [
          51556,
          35025,
          49040,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.45338927643208565,
        "compression_ratio": 1.4516129032258065,
        "end": 6366.2,
        "id": 1570,
        "no_speech_prob": 0.00031015509739518166,
        "seek": 633726,
        "start": 6363.3,
        "temperature": 0,
        "text": " Transfer, what is the name of the repo?",
        "tokens": [
          51666,
          35025,
          11,
          437,
          307,
          264,
          1315,
          295,
          264,
          49040,
          30,
          51811
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6370.179999999999,
        "id": 1571,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6366.2,
        "temperature": 0,
        "text": " Coding train bot Mastodon.",
        "tokens": [
          50364,
          383,
          8616,
          3847,
          10592,
          376,
          525,
          378,
          266,
          13,
          50563
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6372.88,
        "id": 1572,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6370.179999999999,
        "temperature": 0,
        "text": " And the new owners should be Coding Train.",
        "tokens": [
          50563,
          400,
          264,
          777,
          7710,
          820,
          312,
          383,
          8616,
          28029,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6375.9,
        "id": 1573,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6374.32,
        "temperature": 0,
        "text": " Transfer the repository.",
        "tokens": [
          50770,
          35025,
          264,
          25841,
          13,
          50849
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6379.48,
        "id": 1574,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6378.2,
        "temperature": 0,
        "text": " Do my password.",
        "tokens": [
          50964,
          1144,
          452,
          11524,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6382,
        "id": 1575,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6381.16,
        "temperature": 0,
        "text": " Sure.",
        "tokens": [
          51112,
          4894,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6391.36,
        "id": 1576,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6386.72,
        "temperature": 0,
        "text": " Now I want to go to Coding Train organization.",
        "tokens": [
          51390,
          823,
          286,
          528,
          281,
          352,
          281,
          383,
          8616,
          28029,
          4475,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.34622828165690106,
        "compression_ratio": 1.4923076923076923,
        "end": 6393.32,
        "id": 1577,
        "no_speech_prob": 0.0006666932022199035,
        "seek": 636620,
        "start": 6391.36,
        "temperature": 0,
        "text": " And Coding Train bot Mastodon.",
        "tokens": [
          51622,
          400,
          383,
          8616,
          28029,
          10592,
          376,
          525,
          378,
          266,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6396.639999999999,
        "id": 1578,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6393.32,
        "temperature": 0,
        "text": " And by the way, now, because it's in the Coding Train,",
        "tokens": [
          50364,
          400,
          538,
          264,
          636,
          11,
          586,
          11,
          570,
          309,
          311,
          294,
          264,
          383,
          8616,
          28029,
          11,
          50530
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6402.599999999999,
        "id": 1579,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6400.2,
        "temperature": 0,
        "text": " there's no reason I can just call it Mastodon bot.",
        "tokens": [
          50708,
          456,
          311,
          572,
          1778,
          286,
          393,
          445,
          818,
          309,
          376,
          525,
          378,
          266,
          10592,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6403.44,
        "id": 1580,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6402.599999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50828,
          1033,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6409.44,
        "id": 1581,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6405.799999999999,
        "temperature": 0,
        "text": " So now let's go to, did it not change that?",
        "tokens": [
          50988,
          407,
          586,
          718,
          311,
          352,
          281,
          11,
          630,
          309,
          406,
          1319,
          300,
          30,
          51170
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6410.36,
        "id": 1582,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6409.44,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          51170,
          2492,
          322,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6413.46,
        "id": 1583,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6411.32,
        "temperature": 0,
        "text": " Settings, settings.",
        "tokens": [
          51264,
          27286,
          11,
          6257,
          13,
          51371
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6420.08,
        "id": 1584,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6416.08,
        "temperature": 0,
        "text": " Mastodon bot.",
        "tokens": [
          51502,
          376,
          525,
          378,
          266,
          10592,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6421.44,
        "id": 1585,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6420.08,
        "temperature": 0,
        "text": " Rename.",
        "tokens": [
          51702,
          12883,
          529,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.317751895422223,
        "compression_ratio": 1.4240506329113924,
        "end": 6422.58,
        "id": 1586,
        "no_speech_prob": 0.00006605183443753049,
        "seek": 639332,
        "start": 6421.44,
        "temperature": 0,
        "text": " There we go, okay.",
        "tokens": [
          51770,
          821,
          321,
          352,
          11,
          1392,
          13,
          51827
        ]
      },
      {
        "avg_logprob": -0.2791933408925231,
        "compression_ratio": 1.6214285714285714,
        "end": 6428.32,
        "id": 1587,
        "no_speech_prob": 0.00003120171095361002,
        "seek": 642332,
        "start": 6423.32,
        "temperature": 0,
        "text": " So, okay, so now I need to file some issues.",
        "tokens": [
          50364,
          407,
          11,
          1392,
          11,
          370,
          586,
          286,
          643,
          281,
          3991,
          512,
          2663,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2791933408925231,
        "compression_ratio": 1.6214285714285714,
        "end": 6436.92,
        "id": 1588,
        "no_speech_prob": 0.00003120171095361002,
        "seek": 642332,
        "start": 6431.92,
        "temperature": 0,
        "text": " Missing image uploader bot.",
        "tokens": [
          50794,
          5275,
          278,
          3256,
          6580,
          260,
          10592,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.2791933408925231,
        "compression_ratio": 1.6214285714285714,
        "end": 6442.32,
        "id": 1589,
        "no_speech_prob": 0.00003120171095361002,
        "seek": 642332,
        "start": 6437.32,
        "temperature": 0,
        "text": " When I went on to code the example bot that,",
        "tokens": [
          51064,
          1133,
          286,
          1437,
          322,
          281,
          3089,
          264,
          1365,
          10592,
          300,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2791933408925231,
        "compression_ratio": 1.6214285714285714,
        "end": 6445,
        "id": 1590,
        "no_speech_prob": 0.00003120171095361002,
        "seek": 642332,
        "start": 6443.16,
        "temperature": 0,
        "text": " when I went on to code the example bot",
        "tokens": [
          51356,
          562,
          286,
          1437,
          322,
          281,
          3089,
          264,
          1365,
          10592,
          51448
        ]
      },
      {
        "avg_logprob": -0.2791933408925231,
        "compression_ratio": 1.6214285714285714,
        "end": 6447.82,
        "id": 1591,
        "no_speech_prob": 0.00003120171095361002,
        "seek": 642332,
        "start": 6445,
        "temperature": 0,
        "text": " that replies with an image,",
        "tokens": [
          51448,
          300,
          42289,
          365,
          364,
          3256,
          11,
          51589
        ]
      },
      {
        "avg_logprob": -0.2791933408925231,
        "compression_ratio": 1.6214285714285714,
        "end": 6452.82,
        "id": 1592,
        "no_speech_prob": 0.00003120171095361002,
        "seek": 642332,
        "start": 6447.82,
        "temperature": 0,
        "text": " I wrote over the bot.js file that was the,",
        "tokens": [
          51589,
          286,
          4114,
          670,
          264,
          10592,
          13,
          25530,
          3991,
          300,
          390,
          264,
          11,
          51839
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6458.44,
        "id": 1593,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6453.44,
        "temperature": 0,
        "text": " that posted a tree every 24 hours.",
        "tokens": [
          50370,
          300,
          9437,
          257,
          4230,
          633,
          4022,
          2496,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6463.179999999999,
        "id": 1594,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6460,
        "temperature": 0,
        "text": " I would like to revive that.",
        "tokens": [
          50698,
          286,
          576,
          411,
          281,
          36292,
          300,
          13,
          50857
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6468.34,
        "id": 1595,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6464.08,
        "temperature": 0,
        "text": " If anyone was, I'd like to revive that.",
        "tokens": [
          50902,
          759,
          2878,
          390,
          11,
          286,
          1116,
          411,
          281,
          36292,
          300,
          13,
          51115
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6475.48,
        "id": 1596,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6472.799999999999,
        "temperature": 0,
        "text": " So, and so what do I have here?",
        "tokens": [
          51338,
          407,
          11,
          293,
          370,
          437,
          360,
          286,
          362,
          510,
          30,
          51472
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6477.719999999999,
        "id": 1597,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6475.48,
        "temperature": 0,
        "text": " There's Mastodon bot one,",
        "tokens": [
          51472,
          821,
          311,
          376,
          525,
          378,
          266,
          10592,
          472,
          11,
          51584
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6481.179999999999,
        "id": 1598,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6477.719999999999,
        "temperature": 0,
        "text": " which is just the one that does a random number.",
        "tokens": [
          51584,
          597,
          307,
          445,
          264,
          472,
          300,
          775,
          257,
          4974,
          1230,
          13,
          51757
        ]
      },
      {
        "avg_logprob": -0.2168409698887875,
        "compression_ratio": 1.4387096774193548,
        "end": 6482.88,
        "id": 1599,
        "no_speech_prob": 0.000030717965273652226,
        "seek": 645332,
        "start": 6481.179999999999,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51757,
          663,
          311,
          2489,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.3264451113614169,
        "compression_ratio": 1.3650793650793651,
        "end": 6488.32,
        "id": 1600,
        "no_speech_prob": 0.000038830985431559384,
        "seek": 648288,
        "start": 6483.32,
        "temperature": 0,
        "text": " Mastodon bot two is the one that replies favorites.",
        "tokens": [
          50386,
          376,
          525,
          378,
          266,
          10592,
          732,
          307,
          264,
          472,
          300,
          42289,
          16907,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.3264451113614169,
        "compression_ratio": 1.3650793650793651,
        "end": 6494.6,
        "id": 1601,
        "no_speech_prob": 0.000038830985431559384,
        "seek": 648288,
        "start": 6492.96,
        "temperature": 0,
        "text": " So that's fine.",
        "tokens": [
          50868,
          407,
          300,
          311,
          2489,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.3264451113614169,
        "compression_ratio": 1.3650793650793651,
        "end": 6499.08,
        "id": 1602,
        "no_speech_prob": 0.000038830985431559384,
        "seek": 648288,
        "start": 6494.6,
        "temperature": 0,
        "text": " So then also issues, a new issue,",
        "tokens": [
          50950,
          407,
          550,
          611,
          2663,
          11,
          257,
          777,
          2734,
          11,
          51174
        ]
      },
      {
        "avg_logprob": -0.3264451113614169,
        "compression_ratio": 1.3650793650793651,
        "end": 6504.36,
        "id": 1603,
        "no_speech_prob": 0.000038830985431559384,
        "seek": 648288,
        "start": 6501,
        "temperature": 0,
        "text": " one bot to rule them all.",
        "tokens": [
          51270,
          472,
          10592,
          281,
          4978,
          552,
          439,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.3264451113614169,
        "compression_ratio": 1.3650793650793651,
        "end": 6509.36,
        "id": 1604,
        "no_speech_prob": 0.000038830985431559384,
        "seek": 648288,
        "start": 6504.36,
        "temperature": 0,
        "text": " I would like, ultimately, these are examples",
        "tokens": [
          51438,
          286,
          576,
          411,
          11,
          6284,
          11,
          613,
          366,
          5110,
          51688
        ]
      },
      {
        "avg_logprob": -0.34829957144601004,
        "compression_ratio": 1.5454545454545454,
        "end": 6511.44,
        "id": 1605,
        "no_speech_prob": 0.00005475759826367721,
        "seek": 650936,
        "start": 6509.48,
        "temperature": 0,
        "text": " that will live in,",
        "tokens": [
          50370,
          300,
          486,
          1621,
          294,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.34829957144601004,
        "compression_ratio": 1.5454545454545454,
        "end": 6519.299999999999,
        "id": 1606,
        "no_speech_prob": 0.00005475759826367721,
        "seek": 650936,
        "start": 6515.7,
        "temperature": 0,
        "text": " but here I'd like to combine them all.",
        "tokens": [
          50681,
          457,
          510,
          286,
          1116,
          411,
          281,
          10432,
          552,
          439,
          13,
          50861
        ]
      },
      {
        "avg_logprob": -0.34829957144601004,
        "compression_ratio": 1.5454545454545454,
        "end": 6522.82,
        "id": 1607,
        "no_speech_prob": 0.00005475759826367721,
        "seek": 650936,
        "start": 6520.219999999999,
        "temperature": 0,
        "text": " I'd like to combine them all as one bot",
        "tokens": [
          50907,
          286,
          1116,
          411,
          281,
          10432,
          552,
          439,
          382,
          472,
          10592,
          51037
        ]
      },
      {
        "avg_logprob": -0.34829957144601004,
        "compression_ratio": 1.5454545454545454,
        "end": 6525.86,
        "id": 1608,
        "no_speech_prob": 0.00005475759826367721,
        "seek": 650936,
        "start": 6522.82,
        "temperature": 0,
        "text": " that I can deploy, deploy,",
        "tokens": [
          51037,
          300,
          286,
          393,
          7274,
          11,
          7274,
          11,
          51189
        ]
      },
      {
        "avg_logprob": -0.34829957144601004,
        "compression_ratio": 1.5454545454545454,
        "end": 6531.82,
        "id": 1609,
        "no_speech_prob": 0.00005475759826367721,
        "seek": 650936,
        "start": 6526.82,
        "temperature": 0,
        "text": " and leave running for testing and fun times.",
        "tokens": [
          51237,
          293,
          1856,
          2614,
          337,
          4997,
          293,
          1019,
          1413,
          13,
          51487
        ]
      },
      {
        "avg_logprob": -0.34829957144601004,
        "compression_ratio": 1.5454545454545454,
        "end": 6538.88,
        "id": 1610,
        "no_speech_prob": 0.00005475759826367721,
        "seek": 650936,
        "start": 6536.679999999999,
        "temperature": 0,
        "text": " And then I'm going to submit this.",
        "tokens": [
          51730,
          400,
          550,
          286,
          478,
          516,
          281,
          10315,
          341,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6542.259999999999,
        "id": 1611,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6539.7,
        "temperature": 0,
        "text": " Labels help wanted.",
        "tokens": [
          50381,
          10137,
          1625,
          854,
          1415,
          13,
          50509
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6545.44,
        "id": 1612,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6543.339999999999,
        "temperature": 0,
        "text": " And issues,",
        "tokens": [
          50563,
          400,
          2663,
          11,
          50668
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6552.38,
        "id": 1613,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6548.44,
        "temperature": 0,
        "text": " labels help wanted.",
        "tokens": [
          50818,
          16949,
          854,
          1415,
          13,
          51015
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6553.9,
        "id": 1614,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6552.38,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51015,
          1033,
          13,
          51091
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6555.48,
        "id": 1615,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6553.9,
        "temperature": 0,
        "text": " Also probably,",
        "tokens": [
          51091,
          2743,
          1391,
          11,
          51170
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6560.0599999999995,
        "id": 1616,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6558.0199999999995,
        "temperature": 0,
        "text": " redo with promises.",
        "tokens": [
          51297,
          29956,
          365,
          16403,
          13,
          51399
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6566.339999999999,
        "id": 1617,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6561.339999999999,
        "temperature": 0,
        "text": " Should I redo the earlier bot examples with promises?",
        "tokens": [
          51463,
          6454,
          286,
          29956,
          264,
          3071,
          10592,
          5110,
          365,
          16403,
          30,
          51713
        ]
      },
      {
        "avg_logprob": -0.3981380815859194,
        "compression_ratio": 1.3675213675213675,
        "end": 6569.179999999999,
        "id": 1618,
        "no_speech_prob": 0.00006709203444188461,
        "seek": 653936,
        "start": 6568.339999999999,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51813,
          286,
          500,
          380,
          458,
          13,
          51855
        ]
      },
      {
        "avg_logprob": -0.3759678431919643,
        "compression_ratio": 1.348148148148148,
        "end": 6570.700000000001,
        "id": 1619,
        "no_speech_prob": 0.00029595615342259407,
        "seek": 656918,
        "start": 6569.88,
        "temperature": 0,
        "text": " Question.",
        "tokens": [
          50399,
          14464,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.3759678431919643,
        "compression_ratio": 1.348148148148148,
        "end": 6579.4800000000005,
        "id": 1620,
        "no_speech_prob": 0.00029595615342259407,
        "seek": 656918,
        "start": 6574.4800000000005,
        "temperature": 0,
        "text": " It's tricky because I'd like that to be available,",
        "tokens": [
          50629,
          467,
          311,
          12414,
          570,
          286,
          1116,
          411,
          300,
          281,
          312,
          2435,
          11,
          50879
        ]
      },
      {
        "avg_logprob": -0.3759678431919643,
        "compression_ratio": 1.348148148148148,
        "end": 6585.76,
        "id": 1621,
        "no_speech_prob": 0.00029595615342259407,
        "seek": 656918,
        "start": 6582.72,
        "temperature": 0,
        "text": " but I used callbacks in the videos,",
        "tokens": [
          51041,
          457,
          286,
          1143,
          818,
          17758,
          294,
          264,
          2145,
          11,
          51193
        ]
      },
      {
        "avg_logprob": -0.3759678431919643,
        "compression_ratio": 1.348148148148148,
        "end": 6589.96,
        "id": 1622,
        "no_speech_prob": 0.00029595615342259407,
        "seek": 656918,
        "start": 6585.76,
        "temperature": 0,
        "text": " so would make it hard to follow along.",
        "tokens": [
          51193,
          370,
          576,
          652,
          309,
          1152,
          281,
          1524,
          2051,
          13,
          51403
        ]
      },
      {
        "avg_logprob": -0.3759678431919643,
        "compression_ratio": 1.348148148148148,
        "end": 6595.9400000000005,
        "id": 1623,
        "no_speech_prob": 0.00029595615342259407,
        "seek": 656918,
        "start": 6591,
        "temperature": 0,
        "text": " Maybe I should make both available.",
        "tokens": [
          51455,
          2704,
          286,
          820,
          652,
          1293,
          2435,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.3759678431919643,
        "compression_ratio": 1.348148148148148,
        "end": 6598.04,
        "id": 1624,
        "no_speech_prob": 0.00029595615342259407,
        "seek": 656918,
        "start": 6597.200000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51765,
          1057,
          558,
          13,
          51807
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6600.68,
        "id": 1625,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6598.04,
        "temperature": 0,
        "text": " So now everybody has their work cut out",
        "tokens": [
          50364,
          407,
          586,
          2201,
          575,
          641,
          589,
          1723,
          484,
          50496
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6602.5199999999995,
        "id": 1626,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6600.68,
        "temperature": 0,
        "text": " for them this weekend.",
        "tokens": [
          50496,
          337,
          552,
          341,
          6711,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6605.12,
        "id": 1627,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6602.5199999999995,
        "temperature": 0,
        "text": " I'm accepting pull requests from here.",
        "tokens": [
          50588,
          286,
          478,
          17391,
          2235,
          12475,
          490,
          510,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6610.8,
        "id": 1628,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6608.32,
        "temperature": 0,
        "text": " And if I could somehow revive this laptop,",
        "tokens": [
          50878,
          400,
          498,
          286,
          727,
          6063,
          36292,
          341,
          10732,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6612.2,
        "id": 1629,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6610.8,
        "temperature": 0,
        "text": " I can look at the chat.",
        "tokens": [
          51002,
          286,
          393,
          574,
          412,
          264,
          5081,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6623.48,
        "id": 1630,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6620.76,
        "temperature": 0,
        "text": " All right, so, oh, Hacktoberfest.",
        "tokens": [
          51500,
          1057,
          558,
          11,
          370,
          11,
          1954,
          11,
          35170,
          44715,
          32348,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6624.32,
        "id": 1631,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6623.48,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51636,
          286,
          500,
          380,
          458,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.2810247444812162,
        "compression_ratio": 1.4825581395348837,
        "end": 6626.5199999999995,
        "id": 1632,
        "no_speech_prob": 0.0003982105408795178,
        "seek": 659804,
        "start": 6624.32,
        "temperature": 0,
        "text": " I don't know about this Hacktoberfest.",
        "tokens": [
          51678,
          286,
          500,
          380,
          458,
          466,
          341,
          35170,
          44715,
          32348,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6628.360000000001,
        "id": 1633,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6626.52,
        "temperature": 0,
        "text": " I don't know how to make that happen.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          577,
          281,
          652,
          300,
          1051,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6630.92,
        "id": 1634,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6629.360000000001,
        "temperature": 0,
        "text": " What, there's no pull requests yet?",
        "tokens": [
          50506,
          708,
          11,
          456,
          311,
          572,
          2235,
          12475,
          1939,
          30,
          50584
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6632.4800000000005,
        "id": 1635,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6630.92,
        "temperature": 0,
        "text": " It's still been two minutes.",
        "tokens": [
          50584,
          467,
          311,
          920,
          668,
          732,
          2077,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6633.320000000001,
        "id": 1636,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6632.4800000000005,
        "temperature": 0,
        "text": " I have to go.",
        "tokens": [
          50662,
          286,
          362,
          281,
          352,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6634.92,
        "id": 1637,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6633.320000000001,
        "temperature": 0,
        "text": " It's six o'clock.",
        "tokens": [
          50704,
          467,
          311,
          2309,
          277,
          6,
          9023,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6637.56,
        "id": 1638,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6634.92,
        "temperature": 0,
        "text": " American League East Division Series.",
        "tokens": [
          50784,
          2665,
          11199,
          6747,
          17183,
          13934,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6638.68,
        "id": 1639,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6637.56,
        "temperature": 0,
        "text": " Yankees versus Red Sox.",
        "tokens": [
          50916,
          13633,
          330,
          279,
          5717,
          4477,
          407,
          87,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6641.88,
        "id": 1640,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6638.68,
        "temperature": 0,
        "text": " You can all try to guess who I'll be rooting for.",
        "tokens": [
          50972,
          509,
          393,
          439,
          853,
          281,
          2041,
          567,
          286,
          603,
          312,
          41572,
          337,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6643.360000000001,
        "id": 1641,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6641.88,
        "temperature": 0,
        "text": " Go Orioles.",
        "tokens": [
          51132,
          1037,
          23621,
          7456,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6644.4400000000005,
        "id": 1642,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6643.360000000001,
        "temperature": 0,
        "text": " Next year's going to be the year.",
        "tokens": [
          51206,
          3087,
          1064,
          311,
          516,
          281,
          312,
          264,
          1064,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6645.8,
        "id": 1643,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6644.4400000000005,
        "temperature": 0,
        "text": " Orioles, go Orioles.",
        "tokens": [
          51260,
          23621,
          7456,
          11,
          352,
          23621,
          7456,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6646.84,
        "id": 1644,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6645.8,
        "temperature": 0,
        "text": " I don't know if I should have brought",
        "tokens": [
          51328,
          286,
          500,
          380,
          458,
          498,
          286,
          820,
          362,
          3038,
          51380
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6648.88,
        "id": 1645,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6646.84,
        "temperature": 0,
        "text": " my Orioles baseball hat.",
        "tokens": [
          51380,
          452,
          23621,
          7456,
          14323,
          2385,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.24768173862511003,
        "compression_ratio": 1.569811320754717,
        "end": 6650.64,
        "id": 1646,
        "no_speech_prob": 0.00011774396989494562,
        "seek": 662652,
        "start": 6648.88,
        "temperature": 0,
        "text": " But oh well, I don't have that with me.",
        "tokens": [
          51482,
          583,
          1954,
          731,
          11,
          286,
          500,
          380,
          362,
          300,
          365,
          385,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6656.64,
        "id": 1647,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6651.64,
        "temperature": 0,
        "text": " All right, so I am happy to take a couple questions",
        "tokens": [
          50414,
          1057,
          558,
          11,
          370,
          286,
          669,
          2055,
          281,
          747,
          257,
          1916,
          1651,
          50664
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6659.400000000001,
        "id": 1648,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6657.08,
        "temperature": 0,
        "text": " while I kind of figure out if there's anything else",
        "tokens": [
          50686,
          1339,
          286,
          733,
          295,
          2573,
          484,
          498,
          456,
          311,
          1340,
          1646,
          50802
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6660.400000000001,
        "id": 1649,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6659.400000000001,
        "temperature": 0,
        "text": " that I need to do.",
        "tokens": [
          50802,
          300,
          286,
          643,
          281,
          360,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6663.200000000001,
        "id": 1650,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6661.5,
        "temperature": 0,
        "text": " I will put on my,",
        "tokens": [
          50907,
          286,
          486,
          829,
          322,
          452,
          11,
          50992
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6666.4400000000005,
        "id": 1651,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6665.6,
        "temperature": 0,
        "text": " this song.",
        "tokens": [
          51112,
          341,
          2153,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6674.6,
        "id": 1652,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6672.780000000001,
        "temperature": 0,
        "text": " Oh, you don't have to do anything to allow users",
        "tokens": [
          51471,
          876,
          11,
          291,
          500,
          380,
          362,
          281,
          360,
          1340,
          281,
          2089,
          5022,
          51562
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6676.84,
        "id": 1653,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6674.6,
        "temperature": 0,
        "text": " to participate in Hacktober necessarily,",
        "tokens": [
          51562,
          281,
          8197,
          294,
          35170,
          44715,
          4725,
          11,
          51674
        ]
      },
      {
        "avg_logprob": -0.34561929470155295,
        "compression_ratio": 1.4450261780104712,
        "end": 6679.04,
        "id": 1654,
        "no_speech_prob": 0.0000326990702887997,
        "seek": 665064,
        "start": 6676.84,
        "temperature": 0,
        "text": " just for visibility on their site.",
        "tokens": [
          51674,
          445,
          337,
          19883,
          322,
          641,
          3621,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6682.92,
        "id": 1655,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6680.04,
        "temperature": 0,
        "text": " Oh, so wait, is there a way,",
        "tokens": [
          50414,
          876,
          11,
          370,
          1699,
          11,
          307,
          456,
          257,
          636,
          11,
          50558
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6689.56,
        "id": 1656,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6687.32,
        "temperature": 0,
        "text": " oh, there's a good question here.",
        "tokens": [
          50778,
          1954,
          11,
          456,
          311,
          257,
          665,
          1168,
          510,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6691.36,
        "id": 1657,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6689.56,
        "temperature": 0,
        "text": " Joel in the chat writes, also do you need",
        "tokens": [
          50890,
          21522,
          294,
          264,
          5081,
          13657,
          11,
          611,
          360,
          291,
          643,
          50980
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6694.2,
        "id": 1658,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6691.36,
        "temperature": 0,
        "text": " to auto delete the images to prevent buildup, Dan?",
        "tokens": [
          50980,
          281,
          8399,
          12097,
          264,
          5267,
          281,
          4871,
          1322,
          1010,
          11,
          3394,
          30,
          51122
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6696.64,
        "id": 1659,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6694.2,
        "temperature": 0,
        "text": " Or are they not stored by processing?",
        "tokens": [
          51122,
          1610,
          366,
          436,
          406,
          12187,
          538,
          9007,
          30,
          51244
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6698.8,
        "id": 1660,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6696.64,
        "temperature": 0,
        "text": " Okay, so this is a great question.",
        "tokens": [
          51244,
          1033,
          11,
          370,
          341,
          307,
          257,
          869,
          1168,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6700.08,
        "id": 1661,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6698.8,
        "temperature": 0,
        "text": " So to be clear,",
        "tokens": [
          51352,
          407,
          281,
          312,
          1850,
          11,
          51416
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6704.96,
        "id": 1662,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6702.04,
        "temperature": 0,
        "text": " the, if I run, if the bot runs,",
        "tokens": [
          51514,
          264,
          11,
          498,
          286,
          1190,
          11,
          498,
          264,
          10592,
          6676,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.301030277070545,
        "compression_ratio": 1.4927536231884058,
        "end": 6707.64,
        "id": 1663,
        "no_speech_prob": 0.00010554664913797751,
        "seek": 667904,
        "start": 6704.96,
        "temperature": 0,
        "text": " where, let's find, I don't know.",
        "tokens": [
          51660,
          689,
          11,
          718,
          311,
          915,
          11,
          286,
          500,
          380,
          458,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6709,
        "id": 1664,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6707.64,
        "temperature": 0,
        "text": " I guess I deleted the image.",
        "tokens": [
          50364,
          286,
          2041,
          286,
          22981,
          264,
          3256,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6710.04,
        "id": 1665,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6709,
        "temperature": 0,
        "text": " Let me run it again.",
        "tokens": [
          50432,
          961,
          385,
          1190,
          309,
          797,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6714,
        "id": 1666,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6713.160000000001,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50640,
          286,
          500,
          380,
          458,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6723.160000000001,
        "id": 1667,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6722,
        "temperature": 0,
        "text": " So I'm running this bot.",
        "tokens": [
          51082,
          407,
          286,
          478,
          2614,
          341,
          10592,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6727.04,
        "id": 1668,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6723.160000000001,
        "temperature": 0,
        "text": " To be clear, if this makes an image of a tree,",
        "tokens": [
          51140,
          1407,
          312,
          1850,
          11,
          498,
          341,
          1669,
          364,
          3256,
          295,
          257,
          4230,
          11,
          51334
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6730.34,
        "id": 1669,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6727.04,
        "temperature": 0,
        "text": " it's going to save it as tree.png on the computer.",
        "tokens": [
          51334,
          309,
          311,
          516,
          281,
          3155,
          309,
          382,
          4230,
          13,
          79,
          872,
          322,
          264,
          3820,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6733.4400000000005,
        "id": 1670,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6730.34,
        "temperature": 0,
        "text": " So there is a png on this computer.",
        "tokens": [
          51499,
          407,
          456,
          307,
          257,
          280,
          872,
          322,
          341,
          3820,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.18621282992155655,
        "compression_ratio": 1.6011904761904763,
        "end": 6735.64,
        "id": 1671,
        "no_speech_prob": 0.000009818320904741995,
        "seek": 670764,
        "start": 6733.4400000000005,
        "temperature": 0,
        "text": " Then it's going to upload that as a media file",
        "tokens": [
          51654,
          1396,
          309,
          311,
          516,
          281,
          6580,
          300,
          382,
          257,
          3021,
          3991,
          51764
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6739.12,
        "id": 1672,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6735.64,
        "temperature": 0,
        "text": " to Mastodon, where it will be stored permanently",
        "tokens": [
          50364,
          281,
          376,
          525,
          378,
          266,
          11,
          689,
          309,
          486,
          312,
          12187,
          24042,
          50538
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6741.92,
        "id": 1673,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6739.12,
        "temperature": 0,
        "text": " on the bot's in-space server.",
        "tokens": [
          50538,
          322,
          264,
          10592,
          311,
          294,
          12,
          24824,
          7154,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6742.96,
        "id": 1674,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6741.92,
        "temperature": 0,
        "text": " And then,",
        "tokens": [
          50678,
          400,
          550,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6745.12,
        "id": 1675,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6743.96,
        "temperature": 0,
        "text": " and then,",
        "tokens": [
          50780,
          293,
          550,
          11,
          50838
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6748.8,
        "id": 1676,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6746.56,
        "temperature": 0,
        "text": " it's, and that's, those are the two places where it is.",
        "tokens": [
          50910,
          309,
          311,
          11,
          293,
          300,
          311,
          11,
          729,
          366,
          264,
          732,
          3190,
          689,
          309,
          307,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6751.96,
        "id": 1677,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6748.8,
        "temperature": 0,
        "text": " Now, if it does it again, it's going to overwrite",
        "tokens": [
          51022,
          823,
          11,
          498,
          309,
          775,
          309,
          797,
          11,
          309,
          311,
          516,
          281,
          670,
          21561,
          51180
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6754.8,
        "id": 1678,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6751.96,
        "temperature": 0,
        "text": " the image on this laptop, because my processing code,",
        "tokens": [
          51180,
          264,
          3256,
          322,
          341,
          10732,
          11,
          570,
          452,
          9007,
          3089,
          11,
          51322
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6758.400000000001,
        "id": 1679,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6754.8,
        "temperature": 0,
        "text": " which I've now closed, just says save tree.png.",
        "tokens": [
          51322,
          597,
          286,
          600,
          586,
          5395,
          11,
          445,
          1619,
          3155,
          4230,
          13,
          79,
          872,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6759.84,
        "id": 1680,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6758.400000000001,
        "temperature": 0,
        "text": " So I'm not numbering them, I'm not saving,",
        "tokens": [
          51502,
          407,
          286,
          478,
          406,
          1230,
          278,
          552,
          11,
          286,
          478,
          406,
          6816,
          11,
          51574
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6761.04,
        "id": 1681,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6759.84,
        "temperature": 0,
        "text": " it's always overwriting it.",
        "tokens": [
          51574,
          309,
          311,
          1009,
          670,
          19868,
          309,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.2276993068397468,
        "compression_ratio": 1.686046511627907,
        "end": 6763.84,
        "id": 1682,
        "no_speech_prob": 0.000015206825992208906,
        "seek": 673564,
        "start": 6761.04,
        "temperature": 0,
        "text": " But then, when that gets posted, that's a new media file.",
        "tokens": [
          51634,
          583,
          550,
          11,
          562,
          300,
          2170,
          9437,
          11,
          300,
          311,
          257,
          777,
          3021,
          3991,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6766.64,
        "id": 1683,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6763.84,
        "temperature": 0,
        "text": " So what I'm doing is I am building up a lot",
        "tokens": [
          50364,
          407,
          437,
          286,
          478,
          884,
          307,
          286,
          669,
          2390,
          493,
          257,
          688,
          50504
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6769.68,
        "id": 1684,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6766.64,
        "temperature": 0,
        "text": " on the bot's in-dot-space server, presumably.",
        "tokens": [
          50504,
          322,
          264,
          10592,
          311,
          294,
          12,
          43494,
          12,
          24824,
          7154,
          11,
          26742,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6772.400000000001,
        "id": 1685,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6769.68,
        "temperature": 0,
        "text": " But at the moment, the server, I guess,",
        "tokens": [
          50656,
          583,
          412,
          264,
          1623,
          11,
          264,
          7154,
          11,
          286,
          2041,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6774.56,
        "id": 1686,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6772.400000000001,
        "temperature": 0,
        "text": " can sustain a bunch of image bots.",
        "tokens": [
          50792,
          393,
          6769,
          257,
          3840,
          295,
          3256,
          35410,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6777.96,
        "id": 1687,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6774.56,
        "temperature": 0,
        "text": " I don't, I want to cautiously not go crazy with this.",
        "tokens": [
          50900,
          286,
          500,
          380,
          11,
          286,
          528,
          281,
          21130,
          8994,
          406,
          352,
          3219,
          365,
          341,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6779.2,
        "id": 1688,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6777.96,
        "temperature": 0,
        "text": " I'm going to turn this off.",
        "tokens": [
          51070,
          286,
          478,
          516,
          281,
          1261,
          341,
          766,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6781.900000000001,
        "id": 1689,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6779.2,
        "temperature": 0,
        "text": " But you'll see here, even though it made three images,",
        "tokens": [
          51132,
          583,
          291,
          603,
          536,
          510,
          11,
          754,
          1673,
          309,
          1027,
          1045,
          5267,
          11,
          51267
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6788.92,
        "id": 1690,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6784.92,
        "temperature": 0,
        "text": " in this folder, only the last one is there.",
        "tokens": [
          51418,
          294,
          341,
          10820,
          11,
          787,
          264,
          1036,
          472,
          307,
          456,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6791.8,
        "id": 1691,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6788.92,
        "temperature": 0,
        "text": " The zero angle tree.",
        "tokens": [
          51618,
          440,
          4018,
          5802,
          4230,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.23367082277933757,
        "compression_ratio": 1.5614754098360655,
        "end": 6792.64,
        "id": 1692,
        "no_speech_prob": 5.989272153783531e-7,
        "seek": 676384,
        "start": 6791.8,
        "temperature": 0,
        "text": " Good question.",
        "tokens": [
          51762,
          2205,
          1168,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6795.56,
        "id": 1693,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6794.72,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50408,
          876,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6798.6,
        "id": 1694,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6796.96,
        "temperature": 0,
        "text": " Oh, maintaining a repo.",
        "tokens": [
          50520,
          876,
          11,
          14916,
          257,
          49040,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6801.24,
        "id": 1695,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6798.6,
        "temperature": 0,
        "text": " Create issues labeled or label existing ones,",
        "tokens": [
          50602,
          20248,
          2663,
          21335,
          420,
          7645,
          6741,
          2306,
          11,
          50734
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6804.08,
        "id": 1696,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6801.24,
        "temperature": 0,
        "text": " Hacktoberfest, on your GitHub projects",
        "tokens": [
          50734,
          35170,
          44715,
          32348,
          11,
          322,
          428,
          23331,
          4455,
          50876
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6806.18,
        "id": 1697,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6804.08,
        "temperature": 0,
        "text": " to help contributors know what to work on.",
        "tokens": [
          50876,
          281,
          854,
          45627,
          458,
          437,
          281,
          589,
          322,
          13,
          50981
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6807.02,
        "id": 1698,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6806.18,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50981,
          876,
          13,
          51023
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6812,
        "id": 1699,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6809.360000000001,
        "temperature": 0,
        "text": " Tag any spam or irrelevant pull requests",
        "tokens": [
          51140,
          11204,
          604,
          24028,
          420,
          28682,
          2235,
          12475,
          51272
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6814.54,
        "id": 1700,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6812,
        "temperature": 0,
        "text": " with the invalid label to disqualify them.",
        "tokens": [
          51272,
          365,
          264,
          34702,
          7645,
          281,
          717,
          22345,
          2505,
          552,
          13,
          51399
        ]
      },
      {
        "avg_logprob": -0.3775475445915671,
        "compression_ratio": 1.3880597014925373,
        "end": 6817.28,
        "id": 1701,
        "no_speech_prob": 0.00024923068122006953,
        "seek": 679384,
        "start": 6814.54,
        "temperature": 0,
        "text": " So, okay, let's, I guess this is a,",
        "tokens": [
          51399,
          407,
          11,
          1392,
          11,
          718,
          311,
          11,
          286,
          2041,
          341,
          307,
          257,
          11,
          51536
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6818.099999999999,
        "id": 1702,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6817.28,
        "temperature": 0,
        "text": " uh,",
        "tokens": [
          50364,
          2232,
          11,
          50405
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6824,
        "id": 1703,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6820.639999999999,
        "temperature": 0,
        "text": " Hacktoberfest, I guess, is a Digital Ocean sponsored thing.",
        "tokens": [
          50532,
          35170,
          44715,
          32348,
          11,
          286,
          2041,
          11,
          307,
          257,
          15522,
          18101,
          16621,
          551,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6825.719999999999,
        "id": 1704,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6824,
        "temperature": 0,
        "text": " And if you do a certain amount of pull requests,",
        "tokens": [
          50700,
          400,
          498,
          291,
          360,
          257,
          1629,
          2372,
          295,
          2235,
          12475,
          11,
          50786
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6826.84,
        "id": 1705,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6825.719999999999,
        "temperature": 0,
        "text": " you get like a t-shirt.",
        "tokens": [
          50786,
          291,
          483,
          411,
          257,
          256,
          12,
          15313,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6827.92,
        "id": 1706,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6826.84,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50842,
          1033,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6829.719999999999,
        "id": 1707,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6827.92,
        "temperature": 0,
        "text": " Oh boy, I got a lot of,",
        "tokens": [
          50896,
          876,
          3237,
          11,
          286,
          658,
          257,
          688,
          295,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6834,
        "id": 1708,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6831.12,
        "temperature": 0,
        "text": " so let's just do that right now real quick",
        "tokens": [
          51056,
          370,
          718,
          311,
          445,
          360,
          300,
          558,
          586,
          957,
          1702,
          51200
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6836.38,
        "id": 1709,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6835.12,
        "temperature": 0,
        "text": " for these issues.",
        "tokens": [
          51256,
          337,
          613,
          2663,
          13,
          51319
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6840.92,
        "id": 1710,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6837.719999999999,
        "temperature": 0,
        "text": " So, labels, I probably have to make one.",
        "tokens": [
          51386,
          407,
          11,
          16949,
          11,
          286,
          1391,
          362,
          281,
          652,
          472,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6842.08,
        "id": 1711,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6840.92,
        "temperature": 0,
        "text": " New label,",
        "tokens": [
          51546,
          1873,
          7645,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.356147312881923,
        "compression_ratio": 1.4341463414634146,
        "end": 6845.5599999999995,
        "id": 1712,
        "no_speech_prob": 0.000049086433136835694,
        "seek": 681728,
        "start": 6844.04,
        "temperature": 0,
        "text": " Hacktoberfest.",
        "tokens": [
          51702,
          35170,
          44715,
          32348,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6850.36,
        "id": 1713,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6848.08,
        "temperature": 0,
        "text": " Hacktoberfest.",
        "tokens": [
          50404,
          35170,
          44715,
          32348,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6851.759999999999,
        "id": 1714,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6850.36,
        "temperature": 0,
        "text": " This should be like orange.",
        "tokens": [
          50518,
          639,
          820,
          312,
          411,
          7671,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6853.84,
        "id": 1715,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6852.679999999999,
        "temperature": 0,
        "text": " I'm just going to keep, instead of trying",
        "tokens": [
          50634,
          286,
          478,
          445,
          516,
          281,
          1066,
          11,
          2602,
          295,
          1382,
          50692
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6856.48,
        "id": 1716,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6853.84,
        "temperature": 0,
        "text": " to figure out orange, oh, it's pretty orange!",
        "tokens": [
          50692,
          281,
          2573,
          484,
          7671,
          11,
          1954,
          11,
          309,
          311,
          1238,
          7671,
          0,
          50824
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6860.08,
        "id": 1717,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6858.84,
        "temperature": 0,
        "text": " Ah, ah, good enough.",
        "tokens": [
          50942,
          2438,
          11,
          3716,
          11,
          665,
          1547,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6861.4,
        "id": 1718,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6860.08,
        "temperature": 0,
        "text": " Okay, create label.",
        "tokens": [
          51004,
          1033,
          11,
          1884,
          7645,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6863.36,
        "id": 1719,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6862.32,
        "temperature": 0,
        "text": " Issues.",
        "tokens": [
          51116,
          38195,
          1247,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6867.28,
        "id": 1720,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6865.78,
        "temperature": 0,
        "text": " Labels.",
        "tokens": [
          51289,
          10137,
          1625,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6868.2,
        "id": 1721,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6867.28,
        "temperature": 0,
        "text": " Hacktoberfest.",
        "tokens": [
          51364,
          35170,
          44715,
          32348,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6869.94,
        "id": 1722,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6868.2,
        "temperature": 0,
        "text": " Oh boy.",
        "tokens": [
          51410,
          876,
          3237,
          13,
          51497
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6870.94,
        "id": 1723,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6869.94,
        "temperature": 0,
        "text": " Anybody wants to help me?",
        "tokens": [
          51497,
          19082,
          2738,
          281,
          854,
          385,
          30,
          51547
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6874.219999999999,
        "id": 1724,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6870.94,
        "temperature": 0,
        "text": " Here's a, I have so many open source projects",
        "tokens": [
          51547,
          1692,
          311,
          257,
          11,
          286,
          362,
          370,
          867,
          1269,
          4009,
          4455,
          51711
        ]
      },
      {
        "avg_logprob": -0.3090140024820964,
        "compression_ratio": 1.4736842105263157,
        "end": 6875.0599999999995,
        "id": 1725,
        "no_speech_prob": 0.0006263296818360686,
        "seek": 684728,
        "start": 6874.219999999999,
        "temperature": 0,
        "text": " that I should go through.",
        "tokens": [
          51711,
          300,
          286,
          820,
          352,
          807,
          13,
          51753
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6877.02,
        "id": 1726,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6875.06,
        "temperature": 0,
        "text": " I'll do this on some other things too.",
        "tokens": [
          50364,
          286,
          603,
          360,
          341,
          322,
          512,
          661,
          721,
          886,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6879.660000000001,
        "id": 1727,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6877.02,
        "temperature": 0,
        "text": " Other Coding Train repos maybe,",
        "tokens": [
          50462,
          5358,
          383,
          8616,
          28029,
          1085,
          329,
          1310,
          11,
          50594
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6881.42,
        "id": 1728,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6879.660000000001,
        "temperature": 0,
        "text": " but that's a place to get started.",
        "tokens": [
          50594,
          457,
          300,
          311,
          257,
          1081,
          281,
          483,
          1409,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6882.38,
        "id": 1729,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6881.42,
        "temperature": 0,
        "text": " Okay, that's great.",
        "tokens": [
          50682,
          1033,
          11,
          300,
          311,
          869,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6883.860000000001,
        "id": 1730,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6882.38,
        "temperature": 0,
        "text": " Thank you for letting me know that.",
        "tokens": [
          50730,
          1044,
          291,
          337,
          8295,
          385,
          458,
          300,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6888.860000000001,
        "id": 1731,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6883.860000000001,
        "temperature": 0,
        "text": " Ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah.",
        "tokens": [
          50804,
          220,
          10844,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          11,
          3716,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6892.46,
        "id": 1732,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6890.900000000001,
        "temperature": 0,
        "text": " Getting a phone call, weird.",
        "tokens": [
          51156,
          13674,
          257,
          2593,
          818,
          11,
          3657,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6897.700000000001,
        "id": 1733,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6895.780000000001,
        "temperature": 0,
        "text": " Ah, I also wanted to, I should have done this",
        "tokens": [
          51400,
          2438,
          11,
          286,
          611,
          1415,
          281,
          11,
          286,
          820,
          362,
          1096,
          341,
          51496
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6899.02,
        "id": 1734,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6897.700000000001,
        "temperature": 0,
        "text": " at the beginning, I forgot,",
        "tokens": [
          51496,
          412,
          264,
          2863,
          11,
          286,
          5298,
          11,
          51562
        ]
      },
      {
        "avg_logprob": -0.32903786592705303,
        "compression_ratio": 1.7264150943396226,
        "end": 6902.18,
        "id": 1735,
        "no_speech_prob": 0.0003353486827109009,
        "seek": 687506,
        "start": 6899.02,
        "temperature": 0,
        "text": " but I wanted to mention Processing India.",
        "tokens": [
          51562,
          457,
          286,
          1415,
          281,
          2152,
          31093,
          278,
          5282,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6905.22,
        "id": 1736,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6902.18,
        "temperature": 0,
        "text": " I think it's Processing Community Day in India.",
        "tokens": [
          50364,
          286,
          519,
          309,
          311,
          31093,
          278,
          10421,
          5226,
          294,
          5282,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6908.240000000001,
        "id": 1737,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6905.22,
        "temperature": 0,
        "text": " There are actually four Processing Community Days",
        "tokens": [
          50516,
          821,
          366,
          767,
          1451,
          31093,
          278,
          10421,
          26007,
          50667
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6910.76,
        "id": 1738,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6908.240000000001,
        "temperature": 0,
        "text": " in India in these four different cities.",
        "tokens": [
          50667,
          294,
          5282,
          294,
          613,
          1451,
          819,
          6486,
          13,
          50793
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6913.58,
        "id": 1739,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6910.76,
        "temperature": 0,
        "text": " The one in Bangalore is being organized",
        "tokens": [
          50793,
          440,
          472,
          294,
          11538,
          304,
          418,
          307,
          885,
          9983,
          50934
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6918.58,
        "id": 1740,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6913.58,
        "temperature": 0,
        "text": " by two alumni of the ITP program where I teach.",
        "tokens": [
          50934,
          538,
          732,
          16347,
          295,
          264,
          6783,
          47,
          1461,
          689,
          286,
          2924,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6922.3,
        "id": 1741,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6919.3,
        "temperature": 0,
        "text": " So I encourage you to, if you're interested",
        "tokens": [
          51220,
          407,
          286,
          5373,
          291,
          281,
          11,
          498,
          291,
          434,
          3102,
          51370
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6923.58,
        "id": 1742,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6922.3,
        "temperature": 0,
        "text": " in getting involved with any of these,",
        "tokens": [
          51370,
          294,
          1242,
          3288,
          365,
          604,
          295,
          613,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6924.42,
        "id": 1743,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6923.58,
        "temperature": 0,
        "text": " to check them out.",
        "tokens": [
          51434,
          281,
          1520,
          552,
          484,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6926.16,
        "id": 1744,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6924.42,
        "temperature": 0,
        "text": " Matura had emailed me and said to mention it",
        "tokens": [
          51476,
          6789,
          2991,
          632,
          45460,
          385,
          293,
          848,
          281,
          2152,
          309,
          51563
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6928.1,
        "id": 1745,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6926.16,
        "temperature": 0,
        "text": " on a live stream, so I'm doing that now.",
        "tokens": [
          51563,
          322,
          257,
          1621,
          4309,
          11,
          370,
          286,
          478,
          884,
          300,
          586,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6929.38,
        "id": 1746,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6928.1,
        "temperature": 0,
        "text": " I'll try to remember maybe at the beginning",
        "tokens": [
          51660,
          286,
          603,
          853,
          281,
          1604,
          1310,
          412,
          264,
          2863,
          51724
        ]
      },
      {
        "avg_logprob": -0.2144188179689295,
        "compression_ratio": 1.663265306122449,
        "end": 6930.38,
        "id": 1747,
        "no_speech_prob": 0.00009460982983000576,
        "seek": 690218,
        "start": 6929.38,
        "temperature": 0,
        "text": " of the next one to mention it,",
        "tokens": [
          51724,
          295,
          264,
          958,
          472,
          281,
          2152,
          309,
          11,
          51774
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6932.82,
        "id": 1748,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6930.38,
        "temperature": 0,
        "text": " because who knows, who's still watching this now?",
        "tokens": [
          50364,
          570,
          567,
          3255,
          11,
          567,
          311,
          920,
          1976,
          341,
          586,
          30,
          50486
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6934.54,
        "id": 1749,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6933.7,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50530,
          1033,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6940.16,
        "id": 1750,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6938.1,
        "temperature": 0,
        "text": " Oh, Alka asked, which folder would you want",
        "tokens": [
          50750,
          876,
          11,
          967,
          2330,
          2351,
          11,
          597,
          10820,
          576,
          291,
          528,
          50853
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6942.1,
        "id": 1751,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6940.16,
        "temperature": 0,
        "text": " the combine bot called?",
        "tokens": [
          50853,
          264,
          10432,
          10592,
          1219,
          30,
          50950
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6943.88,
        "id": 1752,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6942.1,
        "temperature": 0,
        "text": " Mastodon bot combined.",
        "tokens": [
          50950,
          376,
          525,
          378,
          266,
          10592,
          9354,
          13,
          51039
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6948.88,
        "id": 1753,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6943.88,
        "temperature": 0,
        "text": " So I'm open to any way of reorganizing the repo.",
        "tokens": [
          51039,
          407,
          286,
          478,
          1269,
          281,
          604,
          636,
          295,
          41203,
          3319,
          264,
          49040,
          13,
          51289
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6951.34,
        "id": 1754,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6948.96,
        "temperature": 0,
        "text": " Maybe actually just have a folder called bot,",
        "tokens": [
          51293,
          2704,
          767,
          445,
          362,
          257,
          10820,
          1219,
          10592,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6952.52,
        "id": 1755,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6951.34,
        "temperature": 0,
        "text": " and that's the combined one,",
        "tokens": [
          51412,
          293,
          300,
          311,
          264,
          9354,
          472,
          11,
          51471
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6954.14,
        "id": 1756,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6952.52,
        "temperature": 0,
        "text": " and then the other ones are like,",
        "tokens": [
          51471,
          293,
          550,
          264,
          661,
          2306,
          366,
          411,
          11,
          51552
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6956.86,
        "id": 1757,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6954.14,
        "temperature": 0,
        "text": " maybe a folder called bot and a folder called examples.",
        "tokens": [
          51552,
          1310,
          257,
          10820,
          1219,
          10592,
          293,
          257,
          10820,
          1219,
          5110,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.3342778502392168,
        "compression_ratio": 1.705128205128205,
        "end": 6959.1,
        "id": 1758,
        "no_speech_prob": 0.0008969014161266387,
        "seek": 693038,
        "start": 6956.86,
        "temperature": 0,
        "text": " So bot is the one, or it could just be",
        "tokens": [
          51688,
          407,
          10592,
          307,
          264,
          472,
          11,
          420,
          309,
          727,
          445,
          312,
          51800
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6962.1,
        "id": 1759,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6959.1,
        "temperature": 0,
        "text": " in the root directory, could be the actual bot,",
        "tokens": [
          50364,
          294,
          264,
          5593,
          21120,
          11,
          727,
          312,
          264,
          3539,
          10592,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6963.02,
        "id": 1760,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6962.1,
        "temperature": 0,
        "text": " and then there's sub-examples,",
        "tokens": [
          50514,
          293,
          550,
          456,
          311,
          1422,
          12,
          3121,
          335,
          2622,
          11,
          50560
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6964.3,
        "id": 1761,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6963.02,
        "temperature": 0,
        "text": " but that's probably confusing.",
        "tokens": [
          50560,
          457,
          300,
          311,
          1391,
          13181,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6965.700000000001,
        "id": 1762,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6964.3,
        "temperature": 0,
        "text": " So, but something like that.",
        "tokens": [
          50624,
          407,
          11,
          457,
          746,
          411,
          300,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6967.4800000000005,
        "id": 1763,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6965.700000000001,
        "temperature": 0,
        "text": " I'm open to suggestion.",
        "tokens": [
          50694,
          286,
          478,
          1269,
          281,
          16541,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6975.3,
        "id": 1764,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6972.3,
        "temperature": 0,
        "text": " Ah, this is such a great question.",
        "tokens": [
          51024,
          2438,
          11,
          341,
          307,
          1270,
          257,
          869,
          1168,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6978.92,
        "id": 1765,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6975.3,
        "temperature": 0,
        "text": " Awalvi asks, open source is daunting for beginners.",
        "tokens": [
          51174,
          6381,
          304,
          4917,
          8962,
          11,
          1269,
          4009,
          307,
          37657,
          337,
          26992,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6980.9400000000005,
        "id": 1766,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6978.92,
        "temperature": 0,
        "text": " How should I start?",
        "tokens": [
          51355,
          1012,
          820,
          286,
          722,
          30,
          51456
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6983.54,
        "id": 1767,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6980.9400000000005,
        "temperature": 0,
        "text": " This is such a good question, and a really,",
        "tokens": [
          51456,
          639,
          307,
          1270,
          257,
          665,
          1168,
          11,
          293,
          257,
          534,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6985.06,
        "id": 1768,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6983.54,
        "temperature": 0,
        "text": " my phone just keeps ringing.",
        "tokens": [
          51586,
          452,
          2593,
          445,
          5965,
          18423,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.33443603515625,
        "compression_ratio": 1.5982905982905984,
        "end": 6987.1,
        "id": 1769,
        "no_speech_prob": 0.00017130712512880564,
        "seek": 695910,
        "start": 6985.06,
        "temperature": 0,
        "text": " Hold on, just hold on a second.",
        "tokens": [
          51662,
          6962,
          322,
          11,
          445,
          1797,
          322,
          257,
          1150,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -2.081776573544457,
        "compression_ratio": 0.9347826086956522,
        "end": 6993.14,
        "id": 1770,
        "no_speech_prob": 0.0006764893769286573,
        "seek": 698910,
        "start": 6990.1,
        "temperature": 1,
        "text": " Hello?",
        "tokens": [
          50414,
          2425,
          30,
          50566
        ]
      },
      {
        "avg_logprob": -2.081776573544457,
        "compression_ratio": 0.9347826086956522,
        "end": 6994.400000000001,
        "id": 1771,
        "no_speech_prob": 0.0006764893769286573,
        "seek": 698910,
        "start": 6993.14,
        "temperature": 1,
        "text": " Hello?",
        "tokens": [
          50566,
          2425,
          30,
          50629
        ]
      },
      {
        "avg_logprob": -2.081776573544457,
        "compression_ratio": 0.9347826086956522,
        "end": 6996.280000000001,
        "id": 1772,
        "no_speech_prob": 0.0006764893769286573,
        "seek": 698910,
        "start": 6994.400000000001,
        "temperature": 1,
        "text": " Can you put another one?",
        "tokens": [
          50629,
          1664,
          291,
          829,
          1071,
          472,
          30,
          50723
        ]
      },
      {
        "avg_logprob": -2.081776573544457,
        "compression_ratio": 0.9347826086956522,
        "end": 6997.120000000001,
        "id": 1773,
        "no_speech_prob": 0.0006764893769286573,
        "seek": 698910,
        "start": 6996.280000000001,
        "temperature": 1,
        "text": " Yes.",
        "tokens": [
          50723,
          1079,
          13,
          50765
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7023.6,
        "id": 1774,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7019.1,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50589
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7024.72,
        "id": 1775,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7023.6,
        "temperature": 0,
        "text": " Sorry, that was important.",
        "tokens": [
          50589,
          4919,
          11,
          300,
          390,
          1021,
          13,
          50645
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7030.120000000001,
        "id": 1776,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7024.72,
        "temperature": 0,
        "text": " I had to just answer that.",
        "tokens": [
          50645,
          286,
          632,
          281,
          445,
          1867,
          300,
          13,
          50915
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7031.84,
        "id": 1777,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7030.120000000001,
        "temperature": 0,
        "text": " Let me just send a message here.",
        "tokens": [
          50915,
          961,
          385,
          445,
          2845,
          257,
          3636,
          510,
          13,
          51001
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7032.6,
        "id": 1778,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7031.84,
        "temperature": 0,
        "text": " No, it's fine.",
        "tokens": [
          51001,
          883,
          11,
          309,
          311,
          2489,
          13,
          51039
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7033.1,
        "id": 1779,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7032.6,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51039,
          2264,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7041.92,
        "id": 1780,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7040,
        "temperature": 0,
        "text": " OK, what was I saying?",
        "tokens": [
          51409,
          2264,
          11,
          437,
          390,
          286,
          1566,
          30,
          51505
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7044.320000000001,
        "id": 1781,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7041.92,
        "temperature": 0,
        "text": " Oh, yeah, contributing to open source.",
        "tokens": [
          51505,
          876,
          11,
          1338,
          11,
          19270,
          281,
          1269,
          4009,
          13,
          51625
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7045.64,
        "id": 1782,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7044.320000000001,
        "temperature": 0,
        "text": " This is a really tough problem.",
        "tokens": [
          51625,
          639,
          307,
          257,
          534,
          4930,
          1154,
          13,
          51691
        ]
      },
      {
        "avg_logprob": -0.3954959196202895,
        "compression_ratio": 1.4124293785310735,
        "end": 7048.8,
        "id": 1783,
        "no_speech_prob": 0.11748947948217392,
        "seek": 701910,
        "start": 7045.64,
        "temperature": 0,
        "text": " I actually am teaching a course this semester,",
        "tokens": [
          51691,
          286,
          767,
          669,
          4571,
          257,
          1164,
          341,
          11894,
          11,
          51849
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7052.12,
        "id": 1784,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7048.8,
        "temperature": 0,
        "text": " Open Source Studio at ITP.",
        "tokens": [
          50364,
          7238,
          29629,
          13500,
          412,
          6783,
          47,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7055.12,
        "id": 1785,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7052.12,
        "temperature": 0,
        "text": " Let's see if I Google that if it comes up.",
        "tokens": [
          50530,
          961,
          311,
          536,
          498,
          286,
          3329,
          300,
          498,
          309,
          1487,
          493,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7058.84,
        "id": 1786,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7055.12,
        "temperature": 0,
        "text": " And so this is a course that I'm teaching.",
        "tokens": [
          50680,
          400,
          370,
          341,
          307,
          257,
          1164,
          300,
          286,
          478,
          4571,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7063.4800000000005,
        "id": 1787,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7058.84,
        "temperature": 0,
        "text": " And in here under Resources, this",
        "tokens": [
          50866,
          400,
          294,
          510,
          833,
          29706,
          11,
          341,
          51098
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7068.2,
        "id": 1788,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7063.4800000000005,
        "temperature": 0,
        "text": " is some nice guides and open source projects for beginners.",
        "tokens": [
          51098,
          307,
          512,
          1481,
          17007,
          293,
          1269,
          4009,
          4455,
          337,
          26992,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7070.04,
        "id": 1789,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7068.2,
        "temperature": 0,
        "text": " There's a bunch of readings that I",
        "tokens": [
          51334,
          821,
          311,
          257,
          3840,
          295,
          27319,
          300,
          286,
          51426
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7073.4400000000005,
        "id": 1790,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7070.04,
        "temperature": 0,
        "text": " would suggest that are here on the syllabus for this course.",
        "tokens": [
          51426,
          576,
          3402,
          300,
          366,
          510,
          322,
          264,
          48077,
          337,
          341,
          1164,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.25204508232347894,
        "compression_ratio": 1.577092511013216,
        "end": 7075.72,
        "id": 1791,
        "no_speech_prob": 0.0005272339913062751,
        "seek": 704880,
        "start": 7073.4400000000005,
        "temperature": 0,
        "text": " You can read a lot of the students' posts and response.",
        "tokens": [
          51596,
          509,
          393,
          1401,
          257,
          688,
          295,
          264,
          1731,
          6,
          12300,
          293,
          4134,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7078.280000000001,
        "id": 1792,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7076.08,
        "temperature": 0,
        "text": " This course is about contributing",
        "tokens": [
          50382,
          639,
          1164,
          307,
          466,
          19270,
          50492
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7079.68,
        "id": 1793,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7078.280000000001,
        "temperature": 0,
        "text": " to open source projects.",
        "tokens": [
          50492,
          281,
          1269,
          4009,
          4455,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7081.64,
        "id": 1794,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7079.68,
        "temperature": 0,
        "text": " So there might be some places here",
        "tokens": [
          50562,
          407,
          456,
          1062,
          312,
          512,
          3190,
          510,
          50660
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7082.92,
        "id": 1795,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7081.64,
        "temperature": 0,
        "text": " that will help you get started.",
        "tokens": [
          50660,
          300,
          486,
          854,
          291,
          483,
          1409,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7084.8,
        "id": 1796,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7082.92,
        "temperature": 0,
        "text": " But my recommendation is this.",
        "tokens": [
          50724,
          583,
          452,
          11879,
          307,
          341,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7086.76,
        "id": 1797,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7084.8,
        "temperature": 0,
        "text": " And I realize that not everybody can do this.",
        "tokens": [
          50818,
          400,
          286,
          4325,
          300,
          406,
          2201,
          393,
          360,
          341,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7089.8,
        "id": 1798,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7086.76,
        "temperature": 0,
        "text": " But if you can find a local meetup where an open source",
        "tokens": [
          50916,
          583,
          498,
          291,
          393,
          915,
          257,
          2654,
          1677,
          1010,
          689,
          364,
          1269,
          4009,
          51068
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7093.9400000000005,
        "id": 1799,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7089.8,
        "temperature": 0,
        "text": " project is hosting an event to encourage people to contribute,",
        "tokens": [
          51068,
          1716,
          307,
          16058,
          364,
          2280,
          281,
          5373,
          561,
          281,
          10586,
          11,
          51275
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7095.860000000001,
        "id": 1800,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7093.9400000000005,
        "temperature": 0,
        "text": " it's really great to be with a group of people",
        "tokens": [
          51275,
          309,
          311,
          534,
          869,
          281,
          312,
          365,
          257,
          1594,
          295,
          561,
          51371
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7097.360000000001,
        "id": 1801,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7095.860000000001,
        "temperature": 0,
        "text": " who are learning and figuring it out.",
        "tokens": [
          51371,
          567,
          366,
          2539,
          293,
          15213,
          309,
          484,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7099.2,
        "id": 1802,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7097.360000000001,
        "temperature": 0,
        "text": " That's a really wonderful way to do it.",
        "tokens": [
          51446,
          663,
          311,
          257,
          534,
          3715,
          636,
          281,
          360,
          309,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7101.2,
        "id": 1803,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7099.2,
        "temperature": 0,
        "text": " P5.js, we try to have these.",
        "tokens": [
          51538,
          430,
          20,
          13,
          25530,
          11,
          321,
          853,
          281,
          362,
          613,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7103.16,
        "id": 1804,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7101.2,
        "temperature": 0,
        "text": " And Processing Foundation, we try to have things",
        "tokens": [
          51638,
          400,
          31093,
          278,
          10335,
          11,
          321,
          853,
          281,
          362,
          721,
          51736
        ]
      },
      {
        "avg_logprob": -0.2604818664141149,
        "compression_ratio": 1.7373417721518987,
        "end": 7104.96,
        "id": 1805,
        "no_speech_prob": 0.025950275361537933,
        "seek": 707572,
        "start": 7103.16,
        "temperature": 0,
        "text": " like that when possible.",
        "tokens": [
          51736,
          411,
          300,
          562,
          1944,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7109.6,
        "id": 1806,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7104.96,
        "temperature": 0,
        "text": " I know that Dev.to in New York is having a Hacktoberfest event.",
        "tokens": [
          50364,
          286,
          458,
          300,
          9096,
          13,
          1353,
          294,
          1873,
          3609,
          307,
          1419,
          257,
          35170,
          44715,
          32348,
          2280,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7121.16,
        "id": 1807,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7114.24,
        "temperature": 0,
        "text": " So this is you can sign up and some stuff here.",
        "tokens": [
          50828,
          407,
          341,
          307,
          291,
          393,
          1465,
          493,
          293,
          512,
          1507,
          510,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7123,
        "id": 1808,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7121.16,
        "temperature": 0,
        "text": " I think they're having a meetup for this.",
        "tokens": [
          51174,
          286,
          519,
          436,
          434,
          1419,
          257,
          1677,
          1010,
          337,
          341,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7125.2,
        "id": 1809,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7123,
        "temperature": 0,
        "text": " So this is just about Hacktoberfest.",
        "tokens": [
          51266,
          407,
          341,
          307,
          445,
          466,
          35170,
          44715,
          32348,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7127.88,
        "id": 1810,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7125.2,
        "temperature": 0,
        "text": " But there is also, I think on October 10,",
        "tokens": [
          51376,
          583,
          456,
          307,
          611,
          11,
          286,
          519,
          322,
          7617,
          1266,
          11,
          51510
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7130.84,
        "id": 1811,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7127.88,
        "temperature": 0,
        "text": " they're having a Hacktoberfest meetup.",
        "tokens": [
          51510,
          436,
          434,
          1419,
          257,
          35170,
          44715,
          32348,
          1677,
          1010,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7132.4800000000005,
        "id": 1812,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7130.84,
        "temperature": 0,
        "text": " So that's just one example.",
        "tokens": [
          51658,
          407,
          300,
          311,
          445,
          472,
          1365,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7133.6,
        "id": 1813,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7132.4800000000005,
        "temperature": 0,
        "text": " So that would be my advice.",
        "tokens": [
          51740,
          407,
          300,
          576,
          312,
          452,
          5192,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.28145669359679615,
        "compression_ratio": 1.6829268292682926,
        "end": 7134.68,
        "id": 1814,
        "no_speech_prob": 0.000024682532966835424,
        "seek": 710496,
        "start": 7133.6,
        "temperature": 0,
        "text": " It's really hard.",
        "tokens": [
          51796,
          467,
          311,
          534,
          1152,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7137.76,
        "id": 1815,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7135.64,
        "temperature": 0,
        "text": " What's really nice about here is I really",
        "tokens": [
          50412,
          708,
          311,
          534,
          1481,
          466,
          510,
          307,
          286,
          534,
          50518
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7141.64,
        "id": 1816,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7137.76,
        "temperature": 0,
        "text": " recommend looking at these great for new contributors,",
        "tokens": [
          50518,
          2748,
          1237,
          412,
          613,
          869,
          337,
          777,
          45627,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7145.320000000001,
        "id": 1817,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7141.64,
        "temperature": 0,
        "text": " awesome for beginners, and first timers only links.",
        "tokens": [
          50712,
          3476,
          337,
          26992,
          11,
          293,
          700,
          524,
          433,
          787,
          6123,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7147.8,
        "id": 1818,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7145.320000000001,
        "temperature": 0,
        "text": " Because you want to find an open source project that's",
        "tokens": [
          50896,
          1436,
          291,
          528,
          281,
          915,
          364,
          1269,
          4009,
          1716,
          300,
          311,
          51020
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7149.72,
        "id": 1819,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7147.8,
        "temperature": 0,
        "text": " going to have a welcoming atmosphere",
        "tokens": [
          51020,
          516,
          281,
          362,
          257,
          17378,
          8018,
          51116
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7153.8,
        "id": 1820,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7149.72,
        "temperature": 0,
        "text": " and that are looking to help bring beginners",
        "tokens": [
          51116,
          293,
          300,
          366,
          1237,
          281,
          854,
          1565,
          26992,
          51320
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7154.84,
        "id": 1821,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7153.8,
        "temperature": 0,
        "text": " into the community.",
        "tokens": [
          51320,
          666,
          264,
          1768,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7158.52,
        "id": 1822,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7154.84,
        "temperature": 0,
        "text": " And I hope that's certainly our goal with Processing and P5.js",
        "tokens": [
          51372,
          400,
          286,
          1454,
          300,
          311,
          3297,
          527,
          3387,
          365,
          31093,
          278,
          293,
          430,
          20,
          13,
          25530,
          51556
        ]
      },
      {
        "avg_logprob": -0.31659006118774413,
        "compression_ratio": 1.6352459016393444,
        "end": 7161.12,
        "id": 1823,
        "no_speech_prob": 0.0001442276843590662,
        "seek": 713468,
        "start": 7158.52,
        "temperature": 0,
        "text": " and the Processing Foundation.",
        "tokens": [
          51556,
          293,
          264,
          31093,
          278,
          10335,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.7846038216038754,
        "compression_ratio": 1.0833333333333333,
        "end": 7161.62,
        "id": 1824,
        "no_speech_prob": 0.0035376509185880423,
        "seek": 716112,
        "start": 7161.12,
        "temperature": 0.2,
        "text": " Yeah.",
        "tokens": [
          50364,
          865,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.7846038216038754,
        "compression_ratio": 1.0833333333333333,
        "end": 7171.48,
        "id": 1825,
        "no_speech_prob": 0.0035376509185880423,
        "seek": 716112,
        "start": 7170.84,
        "temperature": 0.2,
        "text": " Ciao.",
        "tokens": [
          50850,
          28473,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.7846038216038754,
        "compression_ratio": 1.0833333333333333,
        "end": 7173.24,
        "id": 1826,
        "no_speech_prob": 0.0035376509185880423,
        "seek": 716112,
        "start": 7171.48,
        "temperature": 0.2,
        "text": " Shabar.",
        "tokens": [
          50882,
          1160,
          455,
          289,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.7846038216038754,
        "compression_ratio": 1.0833333333333333,
        "end": 7174.5599999999995,
        "id": 1827,
        "no_speech_prob": 0.0035376509185880423,
        "seek": 716112,
        "start": 7173.24,
        "temperature": 0.2,
        "text": " Shabrar.",
        "tokens": [
          50970,
          1160,
          455,
          5352,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.7846038216038754,
        "compression_ratio": 1.0833333333333333,
        "end": 7175.08,
        "id": 1828,
        "no_speech_prob": 0.0035376509185880423,
        "seek": 716112,
        "start": 7174.5599999999995,
        "temperature": 0.2,
        "text": " Good night.",
        "tokens": [
          51036,
          2205,
          1818,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.7846038216038754,
        "compression_ratio": 1.0833333333333333,
        "end": 7176.599999999999,
        "id": 1829,
        "no_speech_prob": 0.0035376509185880423,
        "seek": 716112,
        "start": 7175.08,
        "temperature": 0.2,
        "text": " How do you say good night in Italian?",
        "tokens": [
          51062,
          1012,
          360,
          291,
          584,
          665,
          1818,
          294,
          10003,
          30,
          51138
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7177.1,
        "id": 1830,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7176.6,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50364,
          2438,
          13,
          50389
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7188.400000000001,
        "id": 1831,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7187.04,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50886,
          865,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7191.52,
        "id": 1832,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7188.400000000001,
        "temperature": 0,
        "text": " I need to learn about modules and imports and exports.",
        "tokens": [
          50954,
          286,
          643,
          281,
          1466,
          466,
          16679,
          293,
          41596,
          293,
          31428,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7193.4400000000005,
        "id": 1833,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7191.52,
        "temperature": 0,
        "text": " That's like an ES6 or an ES8 thing, right?",
        "tokens": [
          51110,
          663,
          311,
          411,
          364,
          12564,
          21,
          420,
          364,
          12564,
          23,
          551,
          11,
          558,
          30,
          51206
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7195.4800000000005,
        "id": 1834,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7193.4400000000005,
        "temperature": 0,
        "text": " That's a thing that I'm not using yet that I need",
        "tokens": [
          51206,
          663,
          311,
          257,
          551,
          300,
          286,
          478,
          406,
          1228,
          1939,
          300,
          286,
          643,
          51308
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7196.120000000001,
        "id": 1835,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7195.4800000000005,
        "temperature": 0,
        "text": " to learn about.",
        "tokens": [
          51308,
          281,
          1466,
          466,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7198.72,
        "id": 1836,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7196.120000000001,
        "temperature": 0,
        "text": " Instead of using require or instead of just",
        "tokens": [
          51340,
          7156,
          295,
          1228,
          3651,
          420,
          2602,
          295,
          445,
          51470
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7201.240000000001,
        "id": 1837,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7198.72,
        "temperature": 0,
        "text": " importing a library in the index.html,",
        "tokens": [
          51470,
          43866,
          257,
          6405,
          294,
          264,
          8186,
          13,
          357,
          15480,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7203.160000000001,
        "id": 1838,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7201.240000000001,
        "temperature": 0,
        "text": " maybe that's a thing that I need to learn about",
        "tokens": [
          51596,
          1310,
          300,
          311,
          257,
          551,
          300,
          286,
          643,
          281,
          1466,
          466,
          51692
        ]
      },
      {
        "avg_logprob": -0.3044486925439927,
        "compression_ratio": 1.7446808510638299,
        "end": 7204.360000000001,
        "id": 1839,
        "no_speech_prob": 0.0006986272637732327,
        "seek": 717660,
        "start": 7203.160000000001,
        "temperature": 0,
        "text": " and do some stuff with.",
        "tokens": [
          51692,
          293,
          360,
          512,
          1507,
          365,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7207.2,
        "id": 1840,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7204.36,
        "temperature": 0,
        "text": " Somebody in the Slack channel, please let me know.",
        "tokens": [
          50364,
          13463,
          294,
          264,
          37211,
          2269,
          11,
          1767,
          718,
          385,
          458,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7218.5199999999995,
        "id": 1841,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7214.96,
        "temperature": 0,
        "text": " So Joel says I should post that answer as a video.",
        "tokens": [
          50894,
          407,
          21522,
          1619,
          286,
          820,
          2183,
          300,
          1867,
          382,
          257,
          960,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7221.48,
        "id": 1842,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7218.5199999999995,
        "temperature": 0,
        "text": " I mean, maybe that's, I would like",
        "tokens": [
          51072,
          286,
          914,
          11,
          1310,
          300,
          311,
          11,
          286,
          576,
          411,
          51220
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7224.88,
        "id": 1843,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7221.48,
        "temperature": 0,
        "text": " to do some specific videos about contributing to open source.",
        "tokens": [
          51220,
          281,
          360,
          512,
          2685,
          2145,
          466,
          19270,
          281,
          1269,
          4009,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7229.799999999999,
        "id": 1844,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7224.88,
        "temperature": 0,
        "text": " Certainly, I do have a GitHub for poets.",
        "tokens": [
          51390,
          16628,
          11,
          286,
          360,
          362,
          257,
          23331,
          337,
          38364,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7232.16,
        "id": 1845,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7229.799999999999,
        "temperature": 0,
        "text": " If you Google that, you'll find my,",
        "tokens": [
          51636,
          759,
          291,
          3329,
          300,
          11,
          291,
          603,
          915,
          452,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.2867555094289256,
        "compression_ratio": 1.4654377880184333,
        "end": 7234.2,
        "id": 1846,
        "no_speech_prob": 0.0046089147217571735,
        "seek": 720436,
        "start": 7232.16,
        "temperature": 0,
        "text": " this is, these are made quite a while ago.",
        "tokens": [
          51754,
          341,
          307,
          11,
          613,
          366,
          1027,
          1596,
          257,
          1339,
          2057,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7237.04,
        "id": 1847,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7235.04,
        "temperature": 0,
        "text": " I think they're still mostly up to date.",
        "tokens": [
          50406,
          286,
          519,
          436,
          434,
          920,
          5240,
          493,
          281,
          4002,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7238.44,
        "id": 1848,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7237.04,
        "temperature": 0,
        "text": " I think some things have changed.",
        "tokens": [
          50506,
          286,
          519,
          512,
          721,
          362,
          3105,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7242.16,
        "id": 1849,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7238.44,
        "temperature": 0,
        "text": " These are 2016, so almost three years ago,",
        "tokens": [
          50576,
          1981,
          366,
          6549,
          11,
          370,
          1920,
          1045,
          924,
          2057,
          11,
          50762
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7243.16,
        "id": 1850,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7242.16,
        "temperature": 0,
        "text": " two and a half years ago.",
        "tokens": [
          50762,
          732,
          293,
          257,
          1922,
          924,
          2057,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7244.92,
        "id": 1851,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7243.16,
        "temperature": 0,
        "text": " But this will certainly help you at least",
        "tokens": [
          50812,
          583,
          341,
          486,
          3297,
          854,
          291,
          412,
          1935,
          50900
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7247.5599999999995,
        "id": 1852,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7244.92,
        "temperature": 0,
        "text": " with some of the technical aspects of using Git and GitHub.",
        "tokens": [
          50900,
          365,
          512,
          295,
          264,
          6191,
          7270,
          295,
          1228,
          16939,
          293,
          23331,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.4166372368134648,
        "compression_ratio": 1.4504950495049505,
        "end": 7261.28,
        "id": 1853,
        "no_speech_prob": 0.003164575668051839,
        "seek": 723420,
        "start": 7257.08,
        "temperature": 0,
        "text": " Importing p5.js to ES6, interesting suggestion.",
        "tokens": [
          51508,
          26391,
          278,
          280,
          20,
          13,
          25530,
          281,
          12564,
          21,
          11,
          1880,
          16541,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7266.679999999999,
        "id": 1854,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7261.32,
        "temperature": 0,
        "text": " I think there's a roadmap related to that",
        "tokens": [
          50366,
          286,
          519,
          456,
          311,
          257,
          35738,
          4077,
          281,
          300,
          50634
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7267.5599999999995,
        "id": 1855,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7266.679999999999,
        "temperature": 0,
        "text": " that you could find.",
        "tokens": [
          50634,
          300,
          291,
          727,
          915,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7275.88,
        "id": 1856,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7272.12,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          50906,
          1057,
          558,
          11,
          2201,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7277.8,
        "id": 1857,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7275.88,
        "temperature": 0,
        "text": " Thank you so much for watching this episode",
        "tokens": [
          51094,
          1044,
          291,
          370,
          709,
          337,
          1976,
          341,
          3500,
          51190
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7278.639999999999,
        "id": 1858,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7277.8,
        "temperature": 0,
        "text": " of The Coding Train.",
        "tokens": [
          51190,
          295,
          440,
          383,
          8616,
          28029,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7282.8,
        "id": 1859,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7278.639999999999,
        "temperature": 0,
        "text": " I will be back next Friday.",
        "tokens": [
          51232,
          286,
          486,
          312,
          646,
          958,
          6984,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7284.88,
        "id": 1860,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7282.8,
        "temperature": 0,
        "text": " Not before next Friday, next Friday.",
        "tokens": [
          51440,
          1726,
          949,
          958,
          6984,
          11,
          958,
          6984,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7285.719999999999,
        "id": 1861,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7284.88,
        "temperature": 0,
        "text": " Stay tuned.",
        "tokens": [
          51544,
          8691,
          10870,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.3419879050481887,
        "compression_ratio": 1.4973262032085561,
        "end": 7288.24,
        "id": 1862,
        "no_speech_prob": 0.000188140053069219,
        "seek": 726128,
        "start": 7285.719999999999,
        "temperature": 0,
        "text": " All of the edited versions of the Mastodon bot videos",
        "tokens": [
          51586,
          1057,
          295,
          264,
          23016,
          9606,
          295,
          264,
          376,
          525,
          378,
          266,
          10592,
          2145,
          51712
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7289.679999999999,
        "id": 1863,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7288.24,
        "temperature": 0,
        "text": " are coming out.",
        "tokens": [
          50364,
          366,
          1348,
          484,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7292.92,
        "id": 1864,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7289.679999999999,
        "temperature": 0,
        "text": " An edited version of Nabil's live stream this morning.",
        "tokens": [
          50436,
          1107,
          23016,
          3037,
          295,
          426,
          5177,
          311,
          1621,
          4309,
          341,
          2446,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7296.12,
        "id": 1865,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7292.92,
        "temperature": 0,
        "text": " If you use the spell.run platform,",
        "tokens": [
          50598,
          759,
          291,
          764,
          264,
          9827,
          13,
          12997,
          3663,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7299.28,
        "id": 1866,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7296.12,
        "temperature": 0,
        "text": " you can sign up at spell.run slash coding train.",
        "tokens": [
          50758,
          291,
          393,
          1465,
          493,
          412,
          9827,
          13,
          12997,
          17330,
          17720,
          3847,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7302.92,
        "id": 1867,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7299.28,
        "temperature": 0,
        "text": " If you use it, please send me a tweet, a Mastodon toot,",
        "tokens": [
          50916,
          759,
          291,
          764,
          309,
          11,
          1767,
          2845,
          385,
          257,
          15258,
          11,
          257,
          376,
          525,
          378,
          266,
          281,
          310,
          11,
          51098
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7304.719999999999,
        "id": 1868,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7302.92,
        "temperature": 0,
        "text": " a comment on YouTube, something like that.",
        "tokens": [
          51098,
          257,
          2871,
          322,
          3088,
          11,
          746,
          411,
          300,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7305.8,
        "id": 1869,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7304.719999999999,
        "temperature": 0,
        "text": " I'd love to hear about it and hear what",
        "tokens": [
          51188,
          286,
          1116,
          959,
          281,
          1568,
          466,
          309,
          293,
          1568,
          437,
          51242
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7307.36,
        "id": 1870,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7305.8,
        "temperature": 0,
        "text": " your experience was like, okay?",
        "tokens": [
          51242,
          428,
          1752,
          390,
          411,
          11,
          1392,
          30,
          51320
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7309.719999999999,
        "id": 1871,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7307.36,
        "temperature": 0,
        "text": " What am I going to do next time?",
        "tokens": [
          51320,
          708,
          669,
          286,
          516,
          281,
          360,
          958,
          565,
          30,
          51438
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7310.88,
        "id": 1872,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7309.719999999999,
        "temperature": 0,
        "text": " Bonne nuit.",
        "tokens": [
          51438,
          7368,
          716,
          38467,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7312.2,
        "id": 1873,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7310.88,
        "temperature": 0,
        "text": " What am I going to do next time?",
        "tokens": [
          51496,
          708,
          669,
          286,
          516,
          281,
          360,
          958,
          565,
          30,
          51562
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7313.2,
        "id": 1874,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7312.2,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51562,
          286,
          500,
          380,
          458,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7315.679999999999,
        "id": 1875,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7313.2,
        "temperature": 0,
        "text": " But, Word2Vec is coming up.",
        "tokens": [
          51612,
          583,
          11,
          8725,
          17,
          53,
          3045,
          307,
          1348,
          493,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.2369875431060791,
        "compression_ratio": 1.6655290102389078,
        "end": 7317.88,
        "id": 1876,
        "no_speech_prob": 0.028867751359939575,
        "seek": 728824,
        "start": 7315.679999999999,
        "temperature": 0,
        "text": " So actually, the things that I need to do,",
        "tokens": [
          51736,
          407,
          767,
          11,
          264,
          721,
          300,
          286,
          643,
          281,
          360,
          11,
          51846
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7319.64,
        "id": 1877,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7318.52,
        "temperature": 0,
        "text": " if I look at my other course that I'm teaching",
        "tokens": [
          50396,
          498,
          286,
          574,
          412,
          452,
          661,
          1164,
          300,
          286,
          478,
          4571,
          50452
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7323.400000000001,
        "id": 1878,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7319.64,
        "temperature": 0,
        "text": " this semester, A to Z F18,",
        "tokens": [
          50452,
          341,
          11894,
          11,
          316,
          281,
          1176,
          479,
          6494,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7325.86,
        "id": 1879,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7323.400000000001,
        "temperature": 0,
        "text": " this will really tell me what I need to do.",
        "tokens": [
          50640,
          341,
          486,
          534,
          980,
          385,
          437,
          286,
          643,
          281,
          360,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7331.6,
        "id": 1880,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7328.12,
        "temperature": 0,
        "text": " I think I would like to do Bayesian classification.",
        "tokens": [
          50876,
          286,
          519,
          286,
          576,
          411,
          281,
          360,
          7840,
          42434,
          21538,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7334.04,
        "id": 1881,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7331.6,
        "temperature": 0,
        "text": " That's something I would like to do.",
        "tokens": [
          51050,
          663,
          311,
          746,
          286,
          576,
          411,
          281,
          360,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7336.54,
        "id": 1882,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7334.04,
        "temperature": 0,
        "text": " I did videos on this last year.",
        "tokens": [
          51172,
          286,
          630,
          2145,
          322,
          341,
          1036,
          1064,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7339.28,
        "id": 1883,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7337.6,
        "temperature": 0,
        "text": " Word2Vec.",
        "tokens": [
          51350,
          8725,
          17,
          53,
          3045,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7342.28,
        "id": 1884,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7339.28,
        "temperature": 0,
        "text": " The LSTM thing I think I can probably just leave.",
        "tokens": [
          51434,
          440,
          441,
          6840,
          44,
          551,
          286,
          519,
          286,
          393,
          1391,
          445,
          1856,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7343.4800000000005,
        "id": 1885,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7342.28,
        "temperature": 0,
        "text": " I don't need to, I'm not going to,",
        "tokens": [
          51584,
          286,
          500,
          380,
          643,
          281,
          11,
          286,
          478,
          406,
          516,
          281,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7344.84,
        "id": 1886,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7343.4800000000005,
        "temperature": 0,
        "text": " I mean I would like to make videos on that,",
        "tokens": [
          51644,
          286,
          914,
          286,
          576,
          411,
          281,
          652,
          2145,
          322,
          300,
          11,
          51712
        ]
      },
      {
        "avg_logprob": -0.2532527980519764,
        "compression_ratio": 1.6245059288537549,
        "end": 7346.28,
        "id": 1887,
        "no_speech_prob": 0.000018630998965818435,
        "seek": 731788,
        "start": 7344.84,
        "temperature": 0,
        "text": " but I have Nabil's guest one now,",
        "tokens": [
          51712,
          457,
          286,
          362,
          426,
          5177,
          311,
          8341,
          472,
          586,
          11,
          51784
        ]
      },
      {
        "avg_logprob": -0.265199378684715,
        "compression_ratio": 1.2372881355932204,
        "end": 7348.639999999999,
        "id": 1888,
        "no_speech_prob": 0.000025466049919486977,
        "seek": 734628,
        "start": 7346.32,
        "temperature": 0,
        "text": " so I think that's going to be fine.",
        "tokens": [
          50366,
          370,
          286,
          519,
          300,
          311,
          516,
          281,
          312,
          2489,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.265199378684715,
        "compression_ratio": 1.2372881355932204,
        "end": 7349.88,
        "id": 1889,
        "no_speech_prob": 0.000025466049919486977,
        "seek": 734628,
        "start": 7348.639999999999,
        "temperature": 0,
        "text": " And then, Word2Vec.",
        "tokens": [
          50482,
          400,
          550,
          11,
          8725,
          17,
          53,
          3045,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.265199378684715,
        "compression_ratio": 1.2372881355932204,
        "end": 7352.5599999999995,
        "id": 1890,
        "no_speech_prob": 0.000025466049919486977,
        "seek": 734628,
        "start": 7349.88,
        "temperature": 0,
        "text": " So that's what's coming up next, Word2Vec.",
        "tokens": [
          50544,
          407,
          300,
          311,
          437,
          311,
          1348,
          493,
          958,
          11,
          8725,
          17,
          53,
          3045,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.265199378684715,
        "compression_ratio": 1.2372881355932204,
        "end": 7354.759999999999,
        "id": 1891,
        "no_speech_prob": 0.000025466049919486977,
        "seek": 734628,
        "start": 7352.5599999999995,
        "temperature": 0,
        "text": " All right, bye everybody.",
        "tokens": [
          50678,
          1057,
          558,
          11,
          6543,
          2201,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.265199378684715,
        "compression_ratio": 1.2372881355932204,
        "end": 7359.84,
        "id": 1892,
        "no_speech_prob": 0.000025466049919486977,
        "seek": 734628,
        "start": 7358.8,
        "temperature": 0,
        "text": " Have a great weekend.",
        "tokens": [
          50990,
          3560,
          257,
          869,
          6711,
          13,
          51042
        ]
      }
    ],
    "transcription": " ♪ Hello, good afternoon, good evening, good night, good morning. There are so many time zones all over this world that we live in. I have not started today with my mic muted, which is rare, because I often start my mic muted and it takes me about five minutes to realize that, and then the first five minutes is silence, but you know, today I'm actually speaking to you. It's Friday, I am looking forward to this weekend. Yeah, I mean there's things I could say about that, but that's not what you're here for. It's been a long week, a little bit tired. There was already a live stream today with the guest, Nabil Hussain, which I will maybe mention. I mean, I'm mentioning it now, but I'm back to continue the threads of last week, earlier this Monday. Let's see, sorry, let me get the chat chicken going here. All right, so, hi. I wasn't really ready yet. So let me open up a web browser. I'm completely unprepared for this, as I always am. Like, I can't even get my web browser to open. This is how unprepared I am. So if I, let me load later. I don't want to try Safari, thank you. If I go to this YouTube channel called The Coding Train, there's an upcoming live stream and one right now. That's interesting, but this is what I wanted to refer to. So this morning, this live stream happened this morning, which was a live stream sponsored by Spell, which is a cloud computing service, and guest Nabil Hussain trained a LSTM neural network, which is a kind of neural network that's well-suited for sequences, trained a model on text. So text from an author, in this case, a rapper, was used, song lyrics were used. The model was trained, and then after that was completed, that model was brought into JavaScript, into the browser, and can be interacted with generating new lyrics. So if you're interested in that, you can check out the live stream from this morning. We did have some technical difficulty a few times here and there, so at some point I'll probably be producing an edited version of that. It was actually only, it was only 58 minutes. My guess is the edited version will be like 35 or 40 minutes, something like that. And Rui in the chat, ah, Rui, Rui Gamer, who was watching me, my other channel that I will not mention. The secret laptop, it's not so secret, right? Here it is. It's not that I want this laptop to be secret, it's that it's just too many things blocking the way. But what was I talking about? Does anybody remember? I'm so tired. Oh, I'm so tired. I'm so tired. Oh, I'm so tired. All right, but I'm on a mission here. None of the, last on Monday, earlier this week, here it is, Mastodon trying again. I spent two and a half hours creating a Mastodon bot, talking about what Mastodon is, which is an open source, decentralized social networking platform. I created my own instance called choochoo.space. It's still there. Koji, member of choochoo.space, has posted this wonderful picture of a koala. Okay, we are totally using this picture. No, wait, how do I get this image? Copy image address, maybe. Yes, okay, thank you, Koji, for somehow knowing that I could use an image of a koala. Koala, let's put it on the desktop. Okay, I don't know if we're really going to use this, but I'm saving it for later. And Magikarp over here is talking about, nice to see Shiffman talk about Mastodon. Okay, thank you. All right, so this is Mastodon, and the instance that I'm using with my coding train bot is Mastodon.space. Bots and space. Sometimes the words keep coming out of my mouth, but my brain completely shut off. My brain completely shut off, and words just kept coming because I'm live streaming, and I feel like if I stop talking, there'll be silence. But what would be the worst thing about silence? All right, that was good. A little moment of silence there. I feel refreshed. How do you feel? I'm trying to decide if this makes sense to be a coding challenge like Mastodon image bot, processing image bot. One of the things I love about this example that I'm going to do today is it brings so many things together. Brings together APIs, and Node, and JavaScript, and asynchronous, and I'm going to use async and await, which is like ES8 JavaScript syntax, and processing, and creating images, and shell scripting. Oh, so many pieces together into one project. The project that I'm going to build is a project that starts with a processing sketch. Let's see how recent this version of processing I have is. 3.4, that's perfect. Starts with a processing sketch. From Node, executes the processing sketch. The processing sketch saves an image. Node grabs the image, uploads it to Mastodon media server, then posts a toot to Mastodon referencing the image. So if we look at bots in space, one of my favorite, let's look at the local timeline. This is nice, it's posting GIFs, but I really like the tree. How do I find, let's see if I search for tree bot. I think I can actually just go to bots in space, like if I went to kubestorm, oh, it would be kubestorm. Oh, interesting. The URL for an account is its number, so I can't simply just know the name of it. But let me say tree bot at bots in dot space. Will this find it for me? Here is the, yeah, there we go. No, I don't want to email it. Don't know how this, here we go, random trees. Oh, no, I can just do this. So I can do this, tree bot, there we go. No, no. Oh, it is random trees. It's random trees, random trees. I'm like a lunatic. All along, oh, this is a different bot. This is totally a different bot. You know the one I was looking for, the fractal tree one? Nobody will tell me. All right, yes, mastodon again, because it's not mastodon again. So what should this be? A, oh, it's a mastodon again. It's a mastodon again. It's a mastodon again. What should this be? It doesn't really matter. I'm making the video. I think I like the idea of trying this as a coding challenge. Tree bot, there's a different tree bot. Hold on, how many bots could there be on bots in space? Just humor me for a minute here. I feel like it posts pretty often, the one that I'm thinking of. All right, I'm going to give up in a second. Oh, I like this one, emoji DNA. That's pretty awesome. Mutant emoji bot, that's kind of fun. All right, so here we go. Do I want to create a new bot? I think I'm going to use the previous. So I think I'm going to do this as a coding challenge, but I am going to get myself set up a little bit. So what I need is to close these things. Then I need iterm open. Let's install the update. Okay, I've got iterm open. We are going to go to the desktop, mastodon, and open this. And we're going to get mastodon bot two. Whoa, look at all this stuff in here. Mastodon bot two, and this is going to be tree underscore bot. Thanks, it's tree underscore bot. Thank you to Alka for finding that for me. Mastodon bot three, bots in space at tree underscore bot. Yeah, this is what I was looking for. I want to make exactly this. Who created this? Are they going to mind? A bot generating tree is made by Alex Noviso. Okay, by this person. All right, I'm going to recreate this. This is going to be my coding challenge. Then I close this. I'm going to be here. I'm going to close this. I don't need this. I don't need this. And then I need processing. And I need, this is going to be long. I don't care. I'm going to do this the way that's going to be. All right, and then I need code. Visual Studio code open. And close these. Mastodon bot three. Oh boy. Oh boy. I don't need any of these files that are extra stuff. And everything else is fine. And then I'm going to start. With this much code. I'm going to start with this much code. So what I'm trying to decide is should I do this? I mean, this really doesn't matter because I want to just make this project. Here's what I'm going to do. I got an idea. I'm going to act as if this is a coding challenge, but I'm not going to say the words coding challenge. I'm going to just do it as is. I'm going to say, hey, I'm going to do this. I'm going to just do it as if it's a tutorial. And then at the end, if it feels like it could actually be one video coding challenge, it doesn't end up being multi-part tutorial, then I will record a brief intro calling it a coding challenge. How about that? Everybody wins. I mean, I win. I mean, I don't know. All right. We're going to check out this whiteboard thing over here. I don't think that I need. You know what, though? Oh, why? Whoa. Oh, wrong. Oh, there it is. I do want to erase the whiteboard, actually, which I'm going to do very quickly with my fancy eraser mechanism. If I could find it. I can't find where. Did it get there? Thrown away? My erasers? I know you can't see me right now. I don't want to be seen. I don't want to be seen looking for the eraser. Am I going to have to go in the hallway and get a paper towel? The earth will be very sad. I have a nice reusable eraser. Doohickey. That is completely... Oh, no. Here it is. Found it. This is actually... Okay. Okay. There we go. Now. Got a marker. I am going to... Okay. Here we go. Everybody stretch. Stand up. Stretch with me. I don't know if this is maybe some correct stretching thing. All right. So other things that I need open here are... I need the Mastodon API docs. And Mastodon API docs. Okay. So these I will definitely probably need to reference. I've got the tree bot. I've got the coding train bot. And I've got some code. Code. And let's just make sure like that does something. Okay. All right. I got a notification. I probably should turn those off. All these people are following me. Look at everybody. All of a sudden, so much activity here. Okay. Okay. Let's... I just want to do something here. Let's go back. Yeah, that's good. Okay. All right. I'm trying to figure out like if there's... I just want to... Can I just get rid of this for a little... Play sound. Let's get rid of this. Play sound. Play sound. Actually, can I clear notifications? Yes. Oh, no. But can I turn them all off? There's no way to just like turn them all off. How about unpin? Yes, there we go. I just don't want... I'm afraid of random stuff appearing that other people are posting. All right. Oh, Adam in the chat. Apologies. So if you want to join choochoo.space, I created an invite for members of the YouTube channel and patrons. But I'll have to get off to generate. I didn't realize that it expired. I'll generate a new one after this is over. Okay. Hello. Hi, Adam. How are you? I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm great. I'm going to make something in this video. And what I'm going to make is a tree bot. I love this bot. It is a bot on Mastodon. It is called tree underscore bot. It is made by Alex Novosi. Was made for Nabo Mamo, which must be some like national bot making month. Hi, national bot making month. When does that happen? Is it now? Because we should all make bots for national bot making month. So I am going to, I love this bot. It makes a tree. This is my one start over. You know, my poor guests who come here to do a guest video. I don't let them like, they don't start over like 15 times like me as if I wasn't doing this live. Hello. In this video, I'm going to make a bot and I'm going to make an image bot. I'm very excited about this project because it pulls together a whole lot of different things. I am going to use processing to generate an image. I'm going to use node to call processing to generate the image. Then I'm going to use node to talk to an API and the API is Mastodon. So one thing you might want to do is I'll refer you to all of my tutorial series about the basics of making a Mastodon bot. I will start largely from scratch here, but I am going, I've already gotten my API keys and I already have imported and installed this node package called Mastodon.api and this.env package that loads my API keys for me. So that is stuff that I've done in another video. If you want to see that, I'll link to that in the video description, but I'm just going to get started. So what is the first thing that I want to do? Okay, actually, let's go to, so this is my inspiration, treebot, made by Alex Novosi for National Bot Making Month. And I am going to try to recreate this. My trees won't be nearly as nice. So the first thing I want to do is I want to use processing. Now, I don't have to, I could find some node package that does drawing or generates an image, SVG, whatever, but I love processing. It's my happy place and I'm pretty sure I can get processing to generate a tree. In fact, I don't even have to like write the code for this because I have before. So I'm just going to go to examples, right? Isn't it in here somewhere? Topics, simulate. No, no, no. Okay, I'll be back in a second. Oh, yeah, I'm back. I found it under fractals and L-systems tree. Oh, look, recursive tree by Daniel Schiffman. This is my, this is a recursive tree. And as I move the mouse, it changes the angle. So let's alter this code a little bit. Let's say that we don't care about a frame rate. And let's not, let's have the angle be random between zero and two pi. Oh, and it's converting it to radians. So okay, between zero and 360. Whoa, it's doing it over and over again in draw. That's exciting. I'm going to say no loop. So it's done. Each time I run this, I get a random tree. There's so much more that I could do to the design of the tree. And I'm so tempted to recode the tree. But I'm going to just leave it as is. You know, maybe I want to like not have so many large angles. And there we go, beautiful tree. Okay, so now, now that I've done that, what do I want? I want my processing sketch to also save. And I'm just going to call it tree.png. I'm just going to call it tree.png. So when it's done drawing, it's going to save an image. Okay, this is exciting. Now I need to save this somewhere. Well, where I've got my Mastodon code right here to talk to the bot. And so what I want to do actually is I probably, to talk to the bot. I've got my Mastodon code. My brain is turned off today. Look, stretch break. I'm going to have a little water over here. I think we need to slow down. Yeah, I made the tree in p5 also in a coding challenge. I've got my code here. This is the code that will talk to the Mastodon service. And what I want is for this code to actually run a processing sketch. But this is Node. This is JavaScript. Processing is Java and it's like a T-Series. This is JavaScript. Processing is Java and it's like a desktop environment where I hit the play button. How can I possibly do this? Well, the first thing I'm going to do is actually go and save this processing sketch in where my bot is. And I'm actually working in this folder, Mastodon bot 3. You can see Node modules, bot.js. So I'm going to save it there. I'm going to call it tree gen. So I'm going to save it, tree gen. I'm going to make sure it still runs. It still runs. And now what I'm going to do, I'm going to show you a little trick. Now, wouldn't it be nice if in the in terminal, I could do things like just say, hey, run processing. But it says processing is not found. What if I were to say processing-java? Permission denied. It's different. How interesting. Let's start that over. I didn't know I was going to do that. Wouldn't it be nice if I could just execute a command like processing run? Of course, in terminal, in the shell, it's not going to know what that is. But a little known fact about processing, which I have done this in other videos before. But just to start anew again, processing command line. There is actually a way to run a processing sketch command line by saying processing-java, the path of the sketch, and then dash dash run. The only way you can do that is by installing first processing.java to your system. This is installing a command line command to run a processing sketch. I'm going to do this, install processing.java. I'm going to say yes for all users. It's going to want to use my password. I'm going to enter my password because it needs to be able to put that where it needs to go. Now I can actually say processing-java. You can see I get all sorts of stuff. It doesn't know what I want to do, but watch this. I can say, let me just look in here. There is the tree gen processing sketch. I can say processing-java sketch equals. Is that what it was? Let's go look at the sketch equals. Now I need the full path. The full path, and I'm going to show you a way around this in a second, is this. Tree gen. This is the full path of that processing sketch. Then I can say dash dash run. Here we go. Magic! It ran it! Look, there's the processing sketch. This is really cool. Now watch. What's exciting about this, and it's bothering me that the background isn't 51, which is very important. I can actually quit processing completely. I don't need to have processing open and still do this. Look at that, there it is. There's my tree, beautiful. But I actually do want to have processing open because I've got a little bit of a problem here. We can see here, look, that image is there. It's now saved. What I want to do is go back and open this again. Open, open, open, open, open. I want to add one thing. I want it to go away. I actually want to say, after I save it, exit. This is going to be helpful for me later. I want to say print line tree generated. You'll see where this comes up later. Okay, now, quit processing. And now, I'm going to run this. See it? There it is. Oh, finished. Tree generated, finished. One more time. There it is, oh, finished. Okay, this is really exciting because there's so much stuff you could do. Now, here's the thing. I am executing this command via the shell, but I want node to execute it. How can I execute it in node? It turns out there is a way to execute any generic shell command from node. It is with the child process package. If I go to child process, you'll see here that there is a method called exec. Child process dot exec. Spawns a shell and runs a command within that shell. Truth of the matter is, it might be useful to use this exec sync because I'm going to sync means synchronous, meaning wait until it's done to go on to the next thing. I've got a crazy plan here. I want to do asynchronous stuff with es8, this await and async function that you may or may not have heard about. So, I'm going to use this one, exec. So, what I need to do is in my node code, I need to say const exec equals require. And where was this? It is in child process dot exec. Child underscore process. No, there's no. Yeah, that's right. Oh, dot exec. Yes, I'm confused. So, this is me requiring the child process package and I don't have to npm install this. You'll notice that I'm on the node.js documentation page. I'm not in some separate third party npm package. This is built into node, but just like file system is. But I've got to say that I want to use it. So, require child process and all I want is that exec function. So, now there's no reason why I can't just say exec and then pass in what? Exactly this. Oh, let me make, this is so unwieldy. So, a nice little trick that I can do is I can actually always get the current path. Right, if I want to get the current path, I just type pwd, print working directory. Well, guess what? I can actually have pwd executed within this command by using these back ticks. I'm pretty sure this is how I do it. So, now I'm saying run and I think I don't actually even need this first slash, right? Run sketch equals print working directory, then tree gen run. Let's see if this works. It is done. Okay, so now, so great. So, I can grab this. This is my command. We're going to get to that, the mastodon stuff in a second. Constant command equals, let's just put this in a variable. Let's just put this in a variable like this. Then I can say exec command and then that's going to have a callback. Oh, I don't want the, let me just run this. Let's just run this. Let's see what happens. Node bot.js. Hey, look what happened. It made it happen. Now, here's the thing. I was, the next thing I was going to do is add a callback, but I'm a new, I'm turning over a new leaf. I'm turning a new page in the book of JavaScript. I'm a kind of person who uses promises. I'm not only a kind of person who uses promises, I even use the async and await keyword to really make my life full of just ease. It's not full of ease, but I'm doing my best. So, what does that mean? The thing is, this particular node package, child process.exec, and I have a feeling if I bother to look at the chat, which I'm going to open up for a second, someone's going to tell me I could just use something else now that natively supports promises. The E key does not work on this computer, which is invisible to you. Oh, it's the wrong, I've been typing in the wrong password. Okay, there it is. Oh, I'm being told that node.js has underscore directory name. So, there's other ways, people are telling me other ways I could get the directory name, but what I'm going to do is I'm going to promisify, which is a word apparently, promisify, I'm going to, oh, look at this, I must have Googled this another time, unless it's just very common, by using Java, not Java, sorry, the node package util. So, node package util, if I go look at util, and I actually just want to be here, there is a promisify, util.promisify. So, what I can actually do is I can say const util equals require util, and then I can say util.promisify, what a weird word, I don't know what happens if I promisify myself, this. So, now, this require child process exec function no longer uses a callback, now it uses a promise, and what does that mean? That means I can say.then, and whatever the response is, I can console log that response, and then I can also catch any error, and I can console.error that error. Now, this might be, and this, there's no semicolon there, there's a semicolon there, this might look completely insane to you, if you haven't seen promises using a callback, or if you haven't seen promises use before in JavaScript, it's very similar to a callback, but instead of saying a callback, I basically have this callback that happens in.then, I'm also using the arrow syntax. The arrow syntax is a nice way of sort of shorthanding this, I'm getting the response as the argument to the callback, and I'm console logging it. So, if you want to know more about those things, I have a whole playlist about promises, and a video about the arrow function that you could go and look at, and I've got a little bit of an advanced video here, not advanced, but I'm using kind of modern JavaScript stuff, if you consider like three years ago modern. Okay, so now I've got this exec function, so let's actually run this one more time, and see, it should do exactly the same thing, but look at this, that response has standard out, standard error. So, in other words, standard out is what? That's the thing that in, I closed my processing sketch, I guess I should have left it open, the processing sketch has a print line in it, so I can read whatever that print line is, so I can actually get more information from processing if I want. For example, I could get the angle, actually, this is great, let's add a little feature to this, this will be fun, because why not make this video longer than it already is? Where am I, desktop, desktop, Mastodon, Mastodon bot 3, tree gen, so what I'm going to do here, look at this, this is great. Let's leave this open, because maybe I'm going to want to do more stuff with it, I am going to, let's make the angle between zero and 90, that's what it says in the comments, and then I'm also going to say print line, and I'm just going to say angle, or is it, was it angle? Theta, whatever, A, I'll just keep the A, and I'm going to say floor A, so just get the, just get the, or int A, I'm just going to convert it to an integer, so watch. So now, when I do this in node, I'm going to say console.log response.standard out, so I don't need to see that whole object, I just want to see the stuff that came out of processing. Let's run it one more time, and you can see, that was the angle 42, ooh, spooky, spooky 42, beating of life, okay, so, great, so here's the thing, I want to, once I have that image, I want to post that image to Mastodon, isn't this all about Mastodon, I've loaded up and connected to Mastodon through this, like, bot, if you don't know what Mastodon is, did I say this already, I've got a whole set of videos describing that, I mean, you can go back and look, but I want to somehow post it to this particular bot, the coding train bot, okay, so now, in order to do that, I need to do something, so now, in order to do that, I need to look up the functions in the Mastodon API, so I'm using this Mastodon API node package, and if I go here, I can look and see that it has Mastodon, get Mastodon post, so this is what I want, Mastodon post, here's the thing, I didn't realize this when I made my other videos about Mastodon, because it says path, parameters, and callback, but guess what, this supports promises, so I actually am going to do this without a callback, with promises, I'm going to break this out, and didn't I say I was going to use async and await, I was going to write it with just that, but I think I have to start a little bit, I have to, I'm going to go a little bit further with the full promises syntax, then I'm going to clean it up with async and await in a second, so now, there's no semicolon there, so now what I want to do is I want to basically say this, I want to post the image, and I want to return this, because if this returns a promise, guess what I get to do, I get to say dot then response, and have another function, right, so this is the idea of chaining promises, and this is what, in theory, I mean, basically, the whole theory of this is to avoid callback hell, and really, we're just in promises hell, it's all hell, but eventually, we will float into the clouds, and feel like we're like butterflies on wings or something, I don't know, okay, so if I return the post that I want to do when that's done, so I'm executing this command when that's done, then do this, and then when the next promise is done, then do this, all right, so what do I need here, the path, so the first thing I need to do, what's weird about, and actually, it might be worth just taking a minute to like write these steps out, because it'll make it more clear, I want to exec processing, that's one, then two, I want to upload image, and then three, I want to toot, right, so what, this is the same thing for the Twitter API, it doesn't work that you just, if you want to tweet an image, you don't just simply send your tweet along with the image, you have to first upload the media, get that path to the media, and then you can tweet with that media reference, so this will actually return an id for the media, and then as long as I attach the id to this, so this creates output.png, this creates an id, and then I use that id here, and then I'm done, then we're just like done, this is the three-step process, each one of these returns a promise, so when, do this, then this, then that, all right, that's the process I'm working with here, all right, so now, so, okay, so the path, so let's go to the Mastodon API docs, and I'm actually looking for media, so we can click here, and this is what I, this is what I want to do, I don't, media upload, I think media upload is just this, I post to here, and then these are the things I need to send, okay, so file description focus, let's look at that, okay, so I need to, I'm going to create some parameters, oh no, I'm up here, I'm just going to, I'm going to create some parameters, and I need the file, which is presumably output.png, and this is not exactly right yet, I can't just put the file name there, but I'll get to that in a second, then I want the description, now the description is really important, this is not the text that is going along with the actual post, what this is, is alt text, alternative text, this is for accessibility, so somebody who is blind or with low vision, who is using a screen reader, instead of seeing this image, would actually hear this description, so I would say a randomly generated fractal tree, oh, and I want to get, this is, I'm going to say const angle equals response.standard out, with, and then, oh, and I need to use my, the new thing that I always use now, which is template literals for strings, with angle, so this would be the description, and then there's one other, so the file is required, the description, it says, is optional, but it really shouldn't be optional, you should be using alt text for accessibility, and then focus, this really is optional, I'm assuming, I've actually not tried this yet, but I'm assuming this has to do with where the crop is, if it's showing a preview image, something like that, okay, so then, I can say, so this is done, and then, path, and then those parameters, I guess this could be an array, oh, path, no, but okay, path, oh yeah, the path is media, sorry, I'm posting to this path, the media path of the API, with these parameters, but this isn't right, this, I mean, let's run this, we'll get an error, so I make the image, finished, params is not defined, so that's a different error, params, params, whatever, one more time, run the bot, weirdly, it's like, didn't complain at me, oh, but, oh, why didn't it complain, because I didn't console log this response, I don't know why I'm going crazy to show you this error, when I could just fix the error in the first place, all right, so all this stuff came in, and it looks like maybe this worked, because I'm getting all this stuff, but somewhere up here, I'm going to see like an error code, oh, so much stuff, false high water mark, I don't know, this seemed to have worked, no, this is nonsense, this is saying this page is not correct, let me go back, but this doesn't, this doesn't need, I got to edit this out, because it's not that, let me just go back to here, so this is almost done, but there's a problem, I can't just pass it the file name, this actually needs to be a readable stream, and so I need to use the file system package, if I go and look for node file system package, and in here, somewhere, I think there's like a create stream function, and actually, probably a better place for me to look is just right here in, hold on, I'm going to have to do this again, there's some stuff going on, oh, super test, I never, I never, I never, I never, I never, there's some stuff going on, oh, super test, I didn't look into that, no, sorry, sorry, I forgot what it is, create read stream, yeah, that's what I want, I think, okay, I'm pretty sure that's what I want, sorry, let me go back and do this one more time, thank you, Matzuh, all right, so almost there, but this actually is incorrect, it doesn't work, the API is not going to just accept a string of the file name and figure out how to like read that file and post all the data of that file to the server, what I actually need to do is give it a readable stream, and if I, and so the code for doing that, it's part of the file system package, so I need to, I need to actually also require that, and we could look up the documentation for it, but I happen to know it, I think, so I need to say, I'm going to say constant stream equals file system create, there it is, read stream, auto-complete, thank you, output.png, oh, and this actually isn't even right, because guess what, remember, output.png was saved in the processing sketch, which is the folder tree gen slash output.png, so now this is the stream, and this is the description that goes with it, okay, and then I want to make sure this worked, so I want to actually console log the response, so now, in theory, I have the code all the way for executing processing, uploading the image, I need to, when I get the response, I need to get the id, and then I go and actually just post the status, okay, here we go, let's try this, oh, unhandled stream error in pipe, no such foul, no such foul, no such file, oh, it's not called output.png, I called it tree.png, okay, let's try that again, finished, and great, so look, this is all the stuff that I got back, now, it's kind of too much stuff for me to look through, oh, what a pain, did this actually work, my goodness, craziest, but this is all I care about, there's more important stuff, there's more stuff, lots of tons of metadata about the image that you just uploaded, but all I really need is data.id, so let me just go here and say console.log response.data.id, and I apologize to the bots in dot space for overloading your server, and you can see, there's the id, okay, now, guess what, can I, should I start using, I'm going to just keep going, why not go with this promise chain, this is how I would do it, probably, then, oh, no, and then, all I need to do is return one more promise, so I'm also going to say constant parameters, now, I want to do, I need to look at the API for what, post, but just statuses, so this is, where is I'm looking, looking, looking, looking, looking, actually, I need to look for API v1 statuses, sorry, oh, I failed, do I, maybe I want to, maybe I should, like, actually now, rewrite this using async and await, I'm going to do that, I'm going to do that, I'm going to do that, I'm going to do that, all right, I'm going to go from where I printed this out, now, the next step would be for, to use this id, and then, actually, in the, in the, in this response, right, I exec, I execute the command, I upload the image, and then, I should be saying, return m.post again, and I'm going to statuses, I should say, return m.post, again, and I'm going to, the path I'm going to, is statuses, so, this, is what I should be doing, but, I can't resist, do you see how this is, I mean, it's great, it's kind of nice, start the promise chain, then do this, now, it's very competitive, then do this, return a new promise, and if any error happens anywhere in here, catch, so, why not, but, this is the thing, this is, now, there is a way, there is a new way, for me to write all of this in what feels more sequential, more synchronous, in fact, with less kind of indentation and brackets and stuff, and that is using this async and await syntax, so, what I'm actually going to do, is I'm going to write a function, I'm going to call it tutor, or just toot, and I'm going to modify this function with the keyword async, this means this is an asynchronous function, this is indicating to JavaScript, this is a feature of ES8, a new feature of JavaScript, that's indicating that this function will be handled asynchronously and always, always, always return a promise, and it will auto-magically, it will basically automatically return that promise, so, we'll look at that later, how it does that, so, in other words, but this, I want to do the same thing, like, what I want to do here, is I want to say exec, execute the command, right, these are the steps, and then I want to say post the media, post the media, the nice thing about using this syntax, is I don't have to separate it out with these, chaining these dot thens, I can actually just use the await keyword, what the await keyword means, is don't go to the next line of code, await the end of this function, so, if I have a bunch of asynchronous things, if I package them all together in an asynchronous function, I can write them sequentially as line after line after line, and essentially, and, you know, I'm going to have some other params here, so, this is, basically, I get to write it like this, now, I need to do stuff in between, that's the thing, like, for example, this returns a response, and then what I want to do is get the angle and create the stream, so, this goes here, so, this is my step one, this is my step one, right, execute processing, look at it, it's just exactly like this, now, I have my step two, where I need to create these parameters that are getting passed in, and, by the way, I don't have to make a separate variable, it could be embedded right in here, but it's just sort of like, a little bit, for legibility, I'm making it something separate, and so, I'm now going to say, basically, step two is upload, upload, upload, ha, media, and that's going to have a response, and then, what do I need? I need to get the ID out of that, and then, I am now going to say, step three, and, by the way, I suppose, if I'm being accurate about this, this is all, I suppose, this is part of step two, I don't know, it doesn't really, this is a little bit silly, what I'm getting myself worked up about, but, which line of code is part of which step, I don't know, but, step three, and, maybe, I'll name this params one, just to be, just for, I don't know, why, why not, to have them have different variable names, then, step three, which is params two, I want the status to be, and this is, you know, I'd have to, I think I know what it's supposed to be, but, behold, my beautiful tree, with angle, and then, I should use the string, the template literals again, degrees, and then, I need, ah, so, now, so, this, okay, let me look this up in the, in the Mastodon API docs, give me a second to find this, let's edit out me looking for it, API, V1, V1, statuses, statuses, geez louise, there's got to be a better way to search on this, oh, it was all the way at the end, here it is, okay, I found it, this is the API, this is the path, statuses, for posting a status, and I, this is the text of the status, there are other things you could do here that I've talked about in previous videos, but this is what I want, media IDs, now, notice this is an array, it's an array of media IDs, because a particular status could have, and it says here, maximum four, more than one image associated with it, so, you can upload more than one image, so, that might be an exercise that you try to do after this video, but, basically, now, I can say, comma, media underscore IDs, and I just have that one ID, so, I just put, I can make an array and put it there, and then, this has to be statuses, params, and then, what I can do, is I can, and this is the response, and I can just now say, return response, so, if we could look at this all together, I think I have to make this, like, a tiny bit smaller for you to see it, can I fit it all in one nice place, look at this, look how beautiful this is, it's almost like I've written this code in a language like Java or C that's, like, perfectly synchronous and linear and procedural, because what I'm saying is, await executing this command, then, do some stuff, then, await uploading the media, then, do some other stuff, then, await posting the actual status, and when you're done, return, and guess what, if I now say, let me make this bigger again, whoops, if I say, toot, guess what, this toot function that I've written, remember when I said it natively returns a promise, well, by the way, I said return right down here, so, this thing right there is the promise it's returning, and I actually might, I could configure my own object, which could be kind of interesting, like, what if I said, return, I could just say something like, success, true, and status, behold my beautiful tree, whatever, and I could just say angle, whatever, I could put, like, angle, and then that angle there, so I could actually configure an object, and I could pull stuff out of the response there, I could return that, and then I would say, then, then response, I can't spell today, I mean, I can never spell, console.log, that response, catch, any error, console.error, error, and this needs a period here, and I need to hit save, and something's wrong, too many, not enough, too many dots, toot.then response, why can't I see this, oh, there's too many dots, too many dots, Mozart, too many dots, still too many dots, toot, then, oh my god, what's happening to me, toot, then, response, console.log, response, is it just not auto-formatting it? No, it's auto-formatting, toot, then, response, console.log, response, dot, catch, oh, may I need a semicolon? No, then, catch, I have to look at the chat, yeah, I know I should wrap things in a, I can't get the password on this computer to work, the dot goes on the next line, oh, that's what it is, oops, yes. Okay, it's not too many, it was too many dots, but I fixed that, the issue is the dot goes on the next line, that's the convention, that's what it's looking for, there, now it's formatted the way I want it to be. So, I still have to engage, oh, boy, with this idea of a promise, but I can basically wrap that all into this one asynchronous function, and people in the chat are telling me I can actually, I don't need to do the then catch in this way, because I could actually put a try and catch inside of here, but, eh, one step at a time, I think I might be done, all right, let's see, let's see what happens, okay, no, response, oh, wait, oh, so, I have also reused, so, I should call this response one, response two, maybe there's a more thoughtful way of doing this, response three, I mean, I didn't actually use the response, but, whatever, and there we go, start the bot, make the image, the angle's 72, finished, params is not defined, oh, I was so close, I was so close, params one, params two, params two here, and I think params one there, all right, I'm feeling pretty confident, ah, success, angle is 56, flash finished, that's a little weird, but, let's see here, let's go to the bot, look, behold my beautiful tree with angle 56 finished degrees, okay, so, there's a little bit of awkwardness there, in that the standard out is just always giving me the word finished, so, because I would like this to be a little bit more, so, because I would like this to work without that, I think I've guessed what I'm going to have to do is, is that just something that happens, like, with processing Java, because I didn't write finished anywhere in here, right, that's not a print line I put in here, so, I think what I could do is, when that comes, the standard out comes, I could say, response, I mean, I could just do a substring, I could do a regular expression, so many things, so many things I could do, why don't I split it, out equals response, response standard out split, and I could just split it by the line break, right, because finished comes after the line break, and then, and then I could just take the first one, so, this split is a function that takes a string and splits it up into chunks based on a delimiter, and you can get really fancy with that, but I think, and then this should just be out, without the cap locked, I mean, I should really test this, so, let's look, is that visible on the stream, that little bit of spittle just projected out of my mouth, I think I over excited, we'll edit that part out, perhaps, I mean, I really should probably test this, but I'm going to have to just rely on the fact that I think I wrote that code correctly, that's my way of testing it, let's run this one more time, undefined, true, angle 55, what's that undefined there, I like seeing that, oh, there we go, behold my beautiful tree with angle 55 degrees, what was undefined, what did I console log in an undefined way, console log response standard out, is that it, no, no, that's 10 finished, wait, if it was 10, why did this become 55, I'm so confused, let's be a little more methodical here, oh, because, oh, what am I looking at, oh, I did, ah, it does it twice, I think I have it happening twice, let's take that out, apologies, everybody, this thing is happening twice because I had the old code in there, I mean, I'm just going to delete that, throw caution to the wind, what a little mess here, okay, that's weird that it did that twice, I'm so confused, okay, angle 74, it just did it once, there we go, okay, one more thing that I need to do, just so this becomes a true bot is what I want to do is I want to say set interval and have it do this thing that it just did there, every, well, let's have it do it every 10 seconds right now, I don't want it to do it every 10 seconds, but just to, boy, I guess there's another, oh, another parentheses there, there we go, no, this is so hard, maybe I should just write a separate function, okay, set interval, then I put the function, which is this, which calls toot, which is this, which does this, every 10,000 seconds, this is not right, oh, look at this, what a mess, I mean, if I was doing it without the arrow syntax, it would look like this, right? And then this would go here, no, no, no, that goes first, right, that's close. Then this, what's wrong here? This is opening the function, that's closing it, no, there's no parentheses there, that's the end of the function, then this, then this, we're good, we're good, this is it, oh, but look how weird, I don't like this at all, this is making me crazy, I'm going to do, I'm going to do this, I mean, it's so silly, function tooter, and then I'm going to put, this is like, I'm a ridiculous person, I'm going to put this in, oh, no, ah, oh, help me, help, help, I'm going to get this, I'm going to put this, and then I'm just going to name my function, forget about this anonymous stuff, this is what I want, right? I have a separate function, which calls my asynchronous function, does the then, the catch, and then I'm going to have that happen every 10 seconds. Okay, by the way, someone in the chat, K1ng Julian is asking, would it be possible to ask the bot to create a tree with a specified angle? Yes, and that is what I'm going to do in a follow-up tutorial, you'll see that in the next one, okay, here we go. And we have a tree, oh, no, I forgot, it's going to wait, so one thing about set interval, which is, I mean, it works, okay, I'll just keep going now, set interval will not execute that function immediately, it will wait the amount of time before doing it the first time, but now, we did it twice, every 10 seconds, the first one was angle 44, and the second one was angle 28, let's, we can wait 10, you can watch this video for 10 more seconds, we can also speed this up now, let it happen like four or five times, but I think that's good, so let's just go and check, here, and we can see 83 degrees, 28, 44, there we go, and 44, 28, 83, 44, 28, 83, wonderful, okay, so this is working, you know, now, of course, I don't want to leave it like this, right, having a bot post every 10 seconds, no one wants to follow a bot that posts every 10 seconds, maybe I want it to just, once a day, it's going to do, maybe once an hour might be the maximum, the most I would do, but let's just, if I want to do it once a day, it would be 24 hours times 60 minutes, there's 60 seconds in a minute, and a thousand milliseconds in a second, so this would now be, but I wouldn't want it to wait a whole day, so I probably want to call it once, so I'll call it once, then set the interval, and I'm sure there's a more elegant way to do that, that all of you will someday, will write in the comments, and here we go, and, node, bot, bot.js, here we go, it does the first one, and then, now, we're going to wait, 24, we're going to wait 24 hours, I'll wait, yes, we'll wait, and then, in 24 hours, I'll still be standing here, I can tell you to go home, have dinner, go to sleep, come back, this laptop would still be here, and it would do the next one, we're just going to have to believe that that's going to happen, again, there is a question of, well, where would I actually want to deploy this, I've got to talk about that in a separate video, but just the quick answer is, you're going to want to find a server, maybe you have one through a hosting company, maybe you happen to have a computer that's always on in your home, a Raspberry Pi that can act as a server, but you need somewhere where you can just let it run over and over again, forever, okay, so, thanks for watching this video, making a Mastodon image bot, and what I'm going to do, I want to do one more tutorial, because, how would you do it so that if someone at mentions the bot, let's say, with an angle, then the bot replies back with a tree with that angle, let's see if we can make that work, that's going to be fun, okay, see you in the next video. Okay, um, okay, so Nathan asks a really good question about deploying, wouldn't processing starting as a desktop app prevent the bot from working, so I've actually covered this in my previous Twitter bot series, yes, but no, so it needs a windowing environment for processing to run, so that's going to work on this laptop, on a Raspberry Pi, if you have a headless server, like, you know, I'm running this instance off DigitalOcean, so I could deploy the bot there, I would have to run a bunch of commands, to, not to trick it, I was going to say, but to, and I have this documented, for Twitter bots, and I want to rewrite all, anyone wants to help me rewrite all these pages, or basically do, I intend to make an entire new version of this page, with Mastodon, but I just, I don't have the time to write this up, but I think in here, deploy bot to Amazon EC2, which is actually, admittedly, probably one of the hardest ways to deploy it, so, but here, somewhere in here, I have the instructions for, yeah, so this, you need to make sure that the server has Java, and you can install Java that way, then you need to do this weird stuff, that creates a fake display for processing to render on, and then you need to also, like, always run that display in the background, and once you've done this, it works. So I have tested this, not in a year, but it does work. Yeah, so I'm going to, the stream is not over, it is 5.10, ooh, I'm kind of going to go, but I'm, I definitely want to, this is going to be the end of the Mastodon bot stuff, I'm just coming over here to look, I have a bunch of messages, okay, oh, and apparently I got a new member, thank you to, it's sort of gone from the chat, it happened in the middle of me, thank you to, I think, Joel, Joel, who joined as a member, appreciate it, Joel, if you, oh, Joel, you can see, Joel has the this.icon, the this.icon is for if you've been a member for, that's the first icon you get, and then I think if you're a member later, you get, so the question is, so now the question is, if you're, sorry, I should finish my sentences, I have a problem not finishing my sentences, if you're a member for more than a month, you get a different one, and two months, I don't remember what those are, let's see what those are, whatever, okay, because that's, so, the question is now, should that be, should that be a coding challenge, and, or should it just, it probably should just be in the Mastodon tutorials, I don't know, I never know these things, I don't know, alright, so, okay, alright, but I'm going to do part two, and then I'll think about it. Exporting the sketch as a Java app wouldn't make a difference, it still needs processing, the app still needs, that, you can also do that, but you still need a windowing environment, I don't believe that would remove the need for X11, Nathan asked in the chat, but I could be wrong about that, but I'm pretty sure, like, it's not actually, the processing IDE never opens, it's, processing is just like, it's just running, it's just compiling the processing code and executing it as an app, it's basically doing that for you, so I'm pretty sure you need a windowing environment, maybe there's some other way you could do it, and by the way, you don't have to use processing, you know, this is just, I think, really useful because, you know, it's sort of, it's very, I love the fact that it's sort of gluing these different things together. Okay. I'll just drink a little water out of sight. Water hasn't paid their sponsorship recently, so I'm not going to drink water in how you, visually, in an apparent way. Okay. Sometimes the words don't form in my brain and exit out of my mouth in a way that makes sense. Alright. Hello, so previously, I made a bot that picked a random number between 0 and 90, generated this fractal tree using that angle, using processing, made the image, and then posted that image to Mastodon using this coding train bot at bots in space dot, bots in dot space, whatever, bots in space dot instance. So you can see a bunch of these here, and so now what I want to do is, instead of, and the bot, if we look at the code, is just executing all of this stuff to generate the image and post it once a day. So what I would like to do now, in this video, is change it, no, I'm not going to use set interval, in fact, I'm not ever going to post an image. I am only going to post an image as a reply to somebody else, and I'm going to look in their reply, find the angle that they've specified, and send them back a tree with that angle. And you can just imagine the possibilities of things you can do. I mean, one of my favorite, this is a Twitter bot, but one of my favorite bots is lowpolybot, and what lowpolybot does is it's still running, is the question, because most of these bots, you can't, the reason why I'm using mastodon, one of the reasons why I'm using mastodon, is that these don't, I don't think, you can't really run these anymore on Twitter, they've changed the API specifications too much. So the idea is that you send in an image, and an image processes it for you and sends it back. Okay, so now, let's do this. So the thing that I need to do is I need to connect to a stream. I've talked about this in previous videos, where I made a bot that just replied, I need to connect to the streaming API. And so the way that I do that is here, m.stream. So I'm going to say m.stream, and then I want to connect to the user stream. And doing that, I should get a promise. Then response, console.log response, can you see what I'm typing here? And then, wow, autofill has gone crazy. Catch any error, console.error, error. And I put too many dots, too many dots, too many dots, the dots go there, where did the dots go? I've lost the dot. I really have a problem with dots, apparently. Okay. Now. So the idea is now, any time there is a user event, any time there is a user event, I'm going to look at that event. Now, I've done this before. Isn't it okay for me, since I just did this in a previous tutorial, I think it's okay for me to look up what I did in that instead of figuring it out again. So a mastodon bot underscore two right now is where I had some code from a previous video. And I can look at the bot code, and I can see what I actually did is if I said, if the event was a notification, whoa, oh, look at this. Oh, look at this. Ah, you know what? I've written this code incorrectly. You have to configure, when you're using the streaming API, it doesn't work like the get or the post API. You actually have to call this on function to specify an event. So apologies for that. Good thing I looked. The way this should actually be written is const listener, like I want to create a listener. That's connected to that user stream, right? Whoops, where's the other code? Right? Streaming slash user. Yeah, I knew that. Streaming slash user. And then I want to say listener.on notification. So if I get a notification, and now I'm going to guess that this returns a promise. But it won't. I'm so sad. Why doesn't this? I give up. I give up. I quit. I can't do this kind of syntax. I did it with a callback before. Return to stream listener instance. See examples on how to use it. Give me a second here. I can't type the password over here. Event emitters do not return promises. Let's start over. Let's go back. So that won't give me a promise. That's fine. That's fine. I'm okay with that. It's fine. Where was I? So I want to connect to the streaming API, and I want to connect to the user stream. Meaning any time I get any sort of notification, somebody favorites something, mentions me, reblogs me. If I post something, I think I get an event. So the way that I do that is by saying m.stream. I have to go look it up here in this API. m.stream path and parameters. Return to stream listener instance. See examples on how to use it. Okay, why not? I've done this already in a previous video, so I could look at my previous code. But let's actually, sorry, let's just go to examples, streaming.js. Oh, we can see that here. So this is what I want to do. I want to connect to the stream. Create a stream instance. Right, connecting to streaming slash user. And then on a particular event, like a notification. Was that what it was? Oh no, just a message. So the event here is called message. And then on a message, and this by the way, I've just been told from the chat, thank you to Alka in the chat, that the streaming API doesn't support promises. So in this case, I do have to use a callback and I can say response. I like to use the word response like this. So now here, anytime I get a response, I'm sorry, anytime there is a message, what do I want to do? You need a callback, not a promise. Also, please stop separating dots with keywords. I don't know what that means. Why the heck do you keep separating the dots from the keywords? Oh yeah, that's when I put the dot, because I'm not used to this. I programmed in like for like 15 years with all this JavaScript promises nonsense. I'm learning, I'm learning. Give me a break here. I could be going home. There's a baseball game starting in two hours that I intend to watch. Okay. All right. So now I do want to look up my previous code because I need to figure out what I need to determine what I'm looking for in that response. So I have that open here and you can see that what I'm doing here is if the event is a notification and if it's a mention, that's what I'm looking for. I'm looking for a mention. So I'm going to say if response.event equals notification, I'm just only going to do mentions and response.data.type, I think, equals mention. Is that right? This would be just looking at my previous code. Response. Message.data.type. Message.event. So where is the mention in this one that I did? Mention. Ah, message.data. It's right there. Message.data.type. So I'm using different variable names, which is fine. But if the event is a notification and the type of the event is a mention, then now I'm ready to basically do this, right? The idea is if I mentioned, go ahead and do this. But, and I don't need a separate function for this. I can't use this. So I'm just going to take this here. But what I want to do is I need to add some stuff to this. So, for example, I probably want to mention a user account and I want to have a reply ID and also that angle. So I need to, if I'm going to reply, I want to at mention them. So I need their account to reference. I also, if I want it to be threaded, I need the ID of that post so I can include that and then the angle I want. So now the angle shouldn't come. Oh, I've got to send the angle into processing. All right. That's going to be something we have to figure out. Okay. I'm going to get to that in a second. So let's try to get the whole flow of this working. This is an interesting problem that I completely forgot that I had to figure out. So first, let me get the ID is, and I did this before. So I'm just going to, we can see the ID is this. This is pulling the ID out of them. And I said response instead of message, which is fine. And then the account name is right here. So I want to also get the account, which is also a response. So I can then pass in the account, pass in the ID. Now the angle is a tricky one. So what am I expecting the person to say? I guess I'm expecting somewhere in their post that there's a number. And they could put multiple numbers. I'm just going to pick the first number. So what I'm going to do, whoops, this is by the way, my inspiration, the tree bot. But where am I? I'm looking at my code. I need to get the content of what they've sent me. This is their message content. So what I want to do is use a regular expression. So my regular expression is going to be, I need to find a number. The number that I want is between two and three digits. So I guess I'm going to allow, I mean, do I allow an angle greater than 90? I mean, sure. I could actually, it could be any number. Right? I could really just say any number, doesn't matter how big. So I want to match this. And so if I say regular, oh, so if I say content.match regular expression, is this, now I've forgotten how regular expressions work. So let's just go to the browser for a second and let's noodle around here. So let's say if I make a regular expression and I make it equal to this, and then I have a string like, hello 42 goodbye. If I say s.match that regular expression, what do I get? Ah, perfect. I get what it matched, the index and some more information. All it cares about is what it matched. And I don't need it to be global. I don't need to get all the numbers. Like I could get all the numbers and average them or something, but I'm just going to get the first one. So this is fine. So then I'm going to, and I do have to deal with the fact, what if it doesn't match anything? So let's see what it gives me if it doesn't match. So let's say s equals this, and I'm going to say s match regular expression. No. So that's fine. So now I'm going to say results equals content match regular expression and the angle. So I'm going to say if results, or I could, if results, I could probably use that ternary thing. Then the angle equals results index zero. Otherwise, angle equals. Oh, otherwise I'm going to say there's no angle. I could reply and say you need to, you need to, you need to mention me with a number. So I'll, so I'm actually going to just say, yeah, angle equals negative one. So I'm going to use negative one as like a, and I can actually just do this. And then do this. Okay, great. Great. Great. Great. So now in theory, now I can pass that angle here. So, all right, now one thing I can do, let's just do this. So if the first thing I want to do is just say, if angle equals negative one, right? If I've gotten a negative one angle, I want to actually just be done. Like I want to say, um, oh, but I have to mention the person. Okay. So I have to say, uh, if in a status post, can I find that here? All right. So the text of the status, you can see this text of status in reply to ID. So this is important. So I'm going to say, um, uh, please specify an angle in degrees using digits. Cause it won't work. You say the word 90. Then I need to say, uh, uh, in reply, what is it in reply to ID in reply to ID is that reply ID. And then also, um, I, I want to use their, the account. So I'm going to, uh, I want to start with the account, uh, account. Uh, and do I say at, I think I have to say at the account, uh, please specify an angle in digits. Then in reply to ID. Okay. So this is good and I'll call this, uh, and then I'm going to say, uh, uh, response, um, let's say params and response and, uh, success angle negative one. Okay. So this now should, if I run this and you, and then I'm going to put an else here. This function has gotten quite long. But basically what I'm doing is first I'm checking if there was a legitimate angle. And if there wasn't, I'm replying back to say, please specify an angle in degrees. And then, uh, let's see how that goes. So right now, if I run this bot. Oh, I forgot to make a new one. That's fine. I'll have to, if I run this bot, somebody should feel free to at mention me without a digit. Can somebody do that please? I'm looking at the chat. I'm taking a break for a second. This will get edited out. Okay. I got an error. Okay. All right. Somebody at messaged me. Thank you for helping me debug this. And I got an error in bot.js line 25. Bot.js line 25. Ah, response, response, response. Sorry. Response, response. All right. Let's try this again. Be prepared. All right. At mention me with no number, please. You can put a number in it, but it won't work if you put a number in it. All right. Ooh. Interesting. Someone please. Oh, there we go. Okay. So let's take a look. So someone mentioned me with a number. That's great that we had both of those tested. Um, and we can see this one, uh, said, please specify an angle in degrees and digits. That's right. And then this one, uh, just said, behold my beautiful tree. So I haven't done the thing where I actually get the angle. So let's, let's first, let's just first, if I really do get an angle, let's do all the same steps. But right now I'm going to also add, uh, at account. So I'm going to mention that account, uh, with angle, and then I'm going to use, uh, the angle that they asked for. And then, so this, and I need in reply ID in, what was it? In reply, same thing in reply to ID. Where is that? Where is that? Where is that? Here we go. In reply to ID. Okay. So now if I run this one more time, you can now at mention me with an angle and you'll get a tree back, or you can at mention me with no angle and you will get a message back saying you need an angle. But I won't be using the angle you asked for just yet, but let's just see if this works. All right. Somebody, somebody still mentioned me please with no angle, with no, no digits. That's weird. Come on, somebody, no digits, please. No digits. Okay. Okay, great. So we can see that we got one, two, three, four, five mentions, one of which had a negative one. So let's see. Uh, let's just check our bot now and we can see 60, 38, 56. Now here's the thing. I'm not actually using the angle. It's still just a random angle. So, um, what I need to do is, oh, and I forgot that I was pulling it out of here. So it's actually not let, hold on. Let's. So we see Alka asked for 56 and I made a tree with 52. So now let's take this out, right? And actually try to use that angle. Now here's the thing. I can't just, how do I do this? So what I'm actually going to do, this is interesting, is I need to go back to that exec command. Where did I have that? Where is that? Oh, command. So that's, whoa, it's all the way, way up here. So what I actually need to do is I need to add another argument to this. And so what I'm going to do, and I think, where do I, I haven't done this in a while. Let's, all right, let's, let's do it this way. Sorry. Let me grab this command. We're going to figure this out together. And we go back to here and I'm going to run that command. So this runs and I get the, that spits out the angle. Now there should be a way in processing for me to get the arguments. How do you get the arguments in Java? The command line arguments. Somebody must know this. It's like system.args. This is like the most, this is like the core string args. Is it just there in a global variable somewhere in processing? I should know this. I did this like a year ago. Print line system.args. What's the chance like that that's like a thing? No. I know, I'm going to look this up. Why does this computer keep going to sleep? By the way, Adam asked in the chat, does it only reply to local or any account in the federation? It'll apply to any account in the federation. I could set it up to only reply to local, but that's not what it does by default. So I did this like a year ago with my Twitter image replier. Oh, but, oh, this was even crazier. Because I downloaded image that somebody else posts. I'm pretty sure, yeah, oh, args. It's just in args. It's just in args. Silly me. Silly me. Okay, I looked it up. I can't believe I forgot this. But processing actually just has built in variable, built in variable called args, which has those command line arguments. So I'm going to put print array args. And now I'm going to do this. We should see. Whoa, oh, it's null because there were none. That's weird. Because where do those go? They're not here. Where, how do I pass arguments? If I just add something else like here. Oh, yeah, there we go. Okay, so if I just add, the args come at the end. I thought some of these might be args, but of course there's none. So we can see here, if I just execute it with an argument like with the angle 40, then, blah, blah, 40, because I have some, I had a bl in there, blah, 40. Okay, perfect, this is much easier than I thought. All I need to do is now say command. Where do I execute that command? Right here. Execute command plus space angle, right? I guess I could use a template literal there. So I just need to add that angle there. And I probably want to double check to make sure there are any args. But if args is not equal to null, then I'm going to make this a global variable, a equals zero. And then I'm going to say a equals args index zero. I guess that's going to be a string, right? So I need to convert that to an integer or a float maybe. And then I don't need it here. And now, here we go. So now, if, let's take out the exit just so we see. Let's do this. Processing Java, run with the angle 10. That looks like the angle 10, right? Now, let's run with an angle of 90. And that looks like the angle 90, perfect. I've passed in the angle. And so now, I should be able to, I mean, right, is there anything left to do? I think this works. Because I got the angle, I've got the angle, I'm going to give it the angle. Yeah, all right. What the hey ho? Let's run this. Ah! Node bot.js, Mastodon bot starting. And now, I'll just wait for a little bit. Try test anything you can imagine. Oh, whoops, sorry, stop, stop. It's funny, like, actually, this is fine. I forgot the exit thing. So amusingly, I forgot the exit thing. So it's opening up Processing, but it's never finishing. So it's actually, that exit thing is very important because I forgot that I had that in there. I've got to put that back in there. And let's try this one more time. And here we go. All right, thank you, everybody. This looks like some good testing. I hope that no one is like, and so let's take a look now. Wait. All right, thank you, everybody. This looks like some good amount of testing. Let's go now to bots in space and take a look. Here is a beholder, and let's see what we get. This is a beholder. This is a bot. So this is a bot. So let's go ahead and run this. Behold my tree with an angle of 90. Please specify an angle so we can see here. Nope, right, that worked. Here, a right triangle has an angle of 90 degrees. I love right triangles. There we go, perfect. So 89, and there we go, 128 degrees. 128, this is working, yay! This is done. So I hope now you have enjoyed, you can imagine sort of, I mean, there is another piece to this that I could do, which is what if the person sends me an image and I do send the image and send it back? I guess I'll have to come back another day and do that one. But now you can see the full process that you can have another user at mention you with some data, text data, use that text data to generate an image and send it back. So I hope you enjoyed this tutorial. I hope you make some wonderful bots at bots in space, and I will see you in a future video. Okay. Okay. Don't be snide, asks, is he okay? Definitely not. I don't think I've ever been okay. Look, and I'm also going bald. Hey, Coding Garden with CJ is here. Hello, hello, hello, hello. All right, I think I'm done for today. It is 5.40. I have got to go. Does anybody have any questions they want to ask? I can't believe this doesn't crash anymore. I think I'm done. Oh, the question is, should that have been a coding challenge? I think maybe it should just be two more tutorials. Should have realized that from the beginning though. I don't know. Anybody have any, I guess I'm going to, like, I'll pretend. I'm going to do two intros. Just in case. I don't know. This is, for people who haven't watched before, this is the weird thing that I do, that this all gets edited later into shorter standalone videos that go in playlists. So I often, like, after I finish something, will do an intro. So Daniel writes, make it a tutorial. Joel asks, are there limitations to the shell commands executable by node? Not really. I mean, the limitations are what you can execute as a shell command. There's no difference between calling the exec function in node and just typing the thing into the shell. There is this limitation though that if the shell command opens a window or operates like, you know, some application that's on a Mac computer and you happen to deploy this to a server that's a Linux server, it's not going to work. But as long as the system you're using supports that shell command, you can execute it from node. And it supports node. Okay. Hello, welcome to a coding challenge. This one's a little bit weird because it's more like an extension of a tutorial series that I'm doing, but I did it all in one video. So I think maybe it can be a coding challenge. I completed it. I made a bot for Mastodon that picks a random number, generates a little fractal tree using that angle, and then posts that image. This is inspired by the tree bot, which I'm going to reference again in a second because I already did before. So if you're about to watch this, enjoy the coding challenge. I will publish the code for this. Make your own Mastodon bot. If you want to know more about what is Mastodon and how do you sign up to get an API key and all that stuff, then I will refer you to the tutorial series of which this video is also in the playlist. I don't know, does this make sense? Whatever. Watch the video, I do the whole project, and then I finish it. What if I send a very big number, way more than 360? Should work. The rotation, once you get, if you do 365, it's going to be the same as five degrees. So I think it would still work. I could constrain it if I wanted to within the code. Okay. Okay, part two of this coding challenge. In part two of this coding challenge, I actually change it from just being a bot that automatically posts a tree every so often to a bot that receives a post, a toot. They're called toots. I just got used to saying tweet, and now I got to say toot. This is very hard. It receives a toot mention from another account. Nathan, thank you to Nathan Growl for helping me test this. And it says, give me an 89 degree angle tree, please. And then I, the coding trained bot, replies, generates that tree image, and replies back with it. So I complete this aspect of it. It's kind of convoluted. I could probably refactor that code a little bit. But, and I hope you enjoy watching this second part of the coding challenge. Yeah, a float would just get the integer part because of the regular expression that I'm using. I could have made my regular expression. So sorry, the question is from Adam. I wonder, how would it handle a float or a number greater than 360? Floats would probably be okay. So I could definitely change my regular expression to account for that. I forgot where I have it. So I could say like, optionally, something like optionally a dot, but I'd have to do this, right? Because I want a literal dot optionally, and then some more digits optionally, whatever. Something like that I could do. But I'm not, can I leave it running for a while? I want some trees. Why don't I deploy this? I kind of need, I kind of want to make a, I probably should make the bot that does all the things in all the videos that I've shown so far, and then deploy it. Anybody wants to help with that? Ha ha ha. So, anybody wants to help with that? Let me do this. Let's do this real quick before I go. Let's create a new repo. Coding train bot. No, no, stop. Coding train bot. Stop! Bot. Bot code for coding train. Sure, whatever. Yep. Okay, then I am going to, let me create a new file. Dot, dot git ignore. And I want to ignore node modules. Sorry that you can't see this. And I want to ignore, what did I have in, what am I ignoring in all my things? I don't want dot vs code. I think, because who knows what's in that. And I don't want dot env. So, whoops. So, this is git ignore. Come on, you can do it. You can commit this new file. There we go. Let's try cloning this. Git clone, whoops. Git clone this. Open. So, what I'm going to do is, where is that? Coding train mastodon bot, mastodon. I'm going to put, so here's what I would love. Oh boy. I would love you forever if you can help me with this. So, and I'll file the issues. So, let me, give me a second here. Okay. So, what I want to get rid of, I don't need this git ignore. Like this is, I don't need that git ignore. I don't need that git ignore, okay. So, now git status, whoops. Okay. I'm going to be very confident I did git ignore correctly and I'm going to git add, git commit. And I'm going to say, upload, whoops. Shoot. Ah! How do I associate editor with git? I can't use VI. I'm incapable of using VI. So, I'm going to, and I could just do dash M, but I'm trying to be a good citizen. And you guys are really spamming this bot. Oh shoot, all those files. Thank you, I forgot about that. Oh, good, but I haven't done that yet. Can I remove those? Is it too late? Can I unstage? How do I unstage files? So, I don't want to add these data.json files. How do I unstage files? Can I just do remove? Git unstage. Unstaging files. Ah! Git reset. Oh, great, let's do that. Git reset. I'm going to git status. Perfect, thank you, that was easy. Git reset. So here, I don't want any of these. And here, so it's just in that one. And in theory, I think I really have to shut off the bots, making me crazy. Git status, wait, oops. Git status. Now let me get my editor working here. Why did that, oh, the camera went off. Here we go, git config dash dash global core editor. Git config dash dash global core dot editor. Code dash dash wait, I think. That right? Yeah. And now, all right, so now I'm going to add those, stage those files. Go wait for that to draw that tree. Say git config. Okay, I have to shut it off. I'm sorry, everybody, I can't take it anymore. Ha ha ha. I can't take it anymore, okay. Git commit. All right, so now I am adding code from all Mastodon tutorials. This needs some work. I'll open issues, but it's missing the image. Uploader bot without replying. And I also intend to put all of this together in a single bot and deploy it. Okay. So this will be a pull requests and community features welcome. Okay, let me do that. And then git push origin master. Okay. So, so what I need now, anybody wants to help? Oh, and I forgot to put this. I'll need to transfer this repo. Transfer repo. Transfer, what is the name of the repo? Coding train bot Mastodon. And the new owners should be Coding Train. Transfer the repository. Do my password. Sure. Now I want to go to Coding Train organization. And Coding Train bot Mastodon. And by the way, now, because it's in the Coding Train, there's no reason I can just call it Mastodon bot. Okay. So now let's go to, did it not change that? Come on. Settings, settings. Mastodon bot. Rename. There we go, okay. So, okay, so now I need to file some issues. Missing image uploader bot. When I went on to code the example bot that, when I went on to code the example bot that replies with an image, I wrote over the bot.js file that was the, that posted a tree every 24 hours. I would like to revive that. If anyone was, I'd like to revive that. So, and so what do I have here? There's Mastodon bot one, which is just the one that does a random number. That's fine. Mastodon bot two is the one that replies favorites. So that's fine. So then also issues, a new issue, one bot to rule them all. I would like, ultimately, these are examples that will live in, but here I'd like to combine them all. I'd like to combine them all as one bot that I can deploy, deploy, and leave running for testing and fun times. And then I'm going to submit this. Labels help wanted. And issues, labels help wanted. Okay. Also probably, redo with promises. Should I redo the earlier bot examples with promises? I don't know. Question. It's tricky because I'd like that to be available, but I used callbacks in the videos, so would make it hard to follow along. Maybe I should make both available. All right. So now everybody has their work cut out for them this weekend. I'm accepting pull requests from here. And if I could somehow revive this laptop, I can look at the chat. All right, so, oh, Hacktoberfest. I don't know. I don't know about this Hacktoberfest. I don't know how to make that happen. What, there's no pull requests yet? It's still been two minutes. I have to go. It's six o'clock. American League East Division Series. Yankees versus Red Sox. You can all try to guess who I'll be rooting for. Go Orioles. Next year's going to be the year. Orioles, go Orioles. I don't know if I should have brought my Orioles baseball hat. But oh well, I don't have that with me. All right, so I am happy to take a couple questions while I kind of figure out if there's anything else that I need to do. I will put on my, this song. Oh, you don't have to do anything to allow users to participate in Hacktober necessarily, just for visibility on their site. Oh, so wait, is there a way, oh, there's a good question here. Joel in the chat writes, also do you need to auto delete the images to prevent buildup, Dan? Or are they not stored by processing? Okay, so this is a great question. So to be clear, the, if I run, if the bot runs, where, let's find, I don't know. I guess I deleted the image. Let me run it again. I don't know. So I'm running this bot. To be clear, if this makes an image of a tree, it's going to save it as tree.png on the computer. So there is a png on this computer. Then it's going to upload that as a media file to Mastodon, where it will be stored permanently on the bot's in-space server. And then, and then, it's, and that's, those are the two places where it is. Now, if it does it again, it's going to overwrite the image on this laptop, because my processing code, which I've now closed, just says save tree.png. So I'm not numbering them, I'm not saving, it's always overwriting it. But then, when that gets posted, that's a new media file. So what I'm doing is I am building up a lot on the bot's in-dot-space server, presumably. But at the moment, the server, I guess, can sustain a bunch of image bots. I don't, I want to cautiously not go crazy with this. I'm going to turn this off. But you'll see here, even though it made three images, in this folder, only the last one is there. The zero angle tree. Good question. Oh. Oh, maintaining a repo. Create issues labeled or label existing ones, Hacktoberfest, on your GitHub projects to help contributors know what to work on. Oh. Tag any spam or irrelevant pull requests with the invalid label to disqualify them. So, okay, let's, I guess this is a, uh, Hacktoberfest, I guess, is a Digital Ocean sponsored thing. And if you do a certain amount of pull requests, you get like a t-shirt. Okay. Oh boy, I got a lot of, so let's just do that right now real quick for these issues. So, labels, I probably have to make one. New label, Hacktoberfest. Hacktoberfest. This should be like orange. I'm just going to keep, instead of trying to figure out orange, oh, it's pretty orange! Ah, ah, good enough. Okay, create label. Issues. Labels. Hacktoberfest. Oh boy. Anybody wants to help me? Here's a, I have so many open source projects that I should go through. I'll do this on some other things too. Other Coding Train repos maybe, but that's a place to get started. Okay, that's great. Thank you for letting me know that. Ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah, ah. Getting a phone call, weird. Ah, I also wanted to, I should have done this at the beginning, I forgot, but I wanted to mention Processing India. I think it's Processing Community Day in India. There are actually four Processing Community Days in India in these four different cities. The one in Bangalore is being organized by two alumni of the ITP program where I teach. So I encourage you to, if you're interested in getting involved with any of these, to check them out. Matura had emailed me and said to mention it on a live stream, so I'm doing that now. I'll try to remember maybe at the beginning of the next one to mention it, because who knows, who's still watching this now? Okay. Oh, Alka asked, which folder would you want the combine bot called? Mastodon bot combined. So I'm open to any way of reorganizing the repo. Maybe actually just have a folder called bot, and that's the combined one, and then the other ones are like, maybe a folder called bot and a folder called examples. So bot is the one, or it could just be in the root directory, could be the actual bot, and then there's sub-examples, but that's probably confusing. So, but something like that. I'm open to suggestion. Ah, this is such a great question. Awalvi asks, open source is daunting for beginners. How should I start? This is such a good question, and a really, my phone just keeps ringing. Hold on, just hold on a second. Hello? Hello? Can you put another one? Yes. OK. Sorry, that was important. I had to just answer that. Let me just send a message here. No, it's fine. OK. OK, what was I saying? Oh, yeah, contributing to open source. This is a really tough problem. I actually am teaching a course this semester, Open Source Studio at ITP. Let's see if I Google that if it comes up. And so this is a course that I'm teaching. And in here under Resources, this is some nice guides and open source projects for beginners. There's a bunch of readings that I would suggest that are here on the syllabus for this course. You can read a lot of the students' posts and response. This course is about contributing to open source projects. So there might be some places here that will help you get started. But my recommendation is this. And I realize that not everybody can do this. But if you can find a local meetup where an open source project is hosting an event to encourage people to contribute, it's really great to be with a group of people who are learning and figuring it out. That's a really wonderful way to do it. P5.js, we try to have these. And Processing Foundation, we try to have things like that when possible. I know that Dev.to in New York is having a Hacktoberfest event. So this is you can sign up and some stuff here. I think they're having a meetup for this. So this is just about Hacktoberfest. But there is also, I think on October 10, they're having a Hacktoberfest meetup. So that's just one example. So that would be my advice. It's really hard. What's really nice about here is I really recommend looking at these great for new contributors, awesome for beginners, and first timers only links. Because you want to find an open source project that's going to have a welcoming atmosphere and that are looking to help bring beginners into the community. And I hope that's certainly our goal with Processing and P5.js and the Processing Foundation. Yeah. Ciao. Shabar. Shabrar. Good night. How do you say good night in Italian? Ah. Yeah. I need to learn about modules and imports and exports. That's like an ES6 or an ES8 thing, right? That's a thing that I'm not using yet that I need to learn about. Instead of using require or instead of just importing a library in the index.html, maybe that's a thing that I need to learn about and do some stuff with. Somebody in the Slack channel, please let me know. So Joel says I should post that answer as a video. I mean, maybe that's, I would like to do some specific videos about contributing to open source. Certainly, I do have a GitHub for poets. If you Google that, you'll find my, this is, these are made quite a while ago. I think they're still mostly up to date. I think some things have changed. These are 2016, so almost three years ago, two and a half years ago. But this will certainly help you at least with some of the technical aspects of using Git and GitHub. Importing p5.js to ES6, interesting suggestion. I think there's a roadmap related to that that you could find. All right, everybody. Thank you so much for watching this episode of The Coding Train. I will be back next Friday. Not before next Friday, next Friday. Stay tuned. All of the edited versions of the Mastodon bot videos are coming out. An edited version of Nabil's live stream this morning. If you use the spell.run platform, you can sign up at spell.run slash coding train. If you use it, please send me a tweet, a Mastodon toot, a comment on YouTube, something like that. I'd love to hear about it and hear what your experience was like, okay? What am I going to do next time? Bonne nuit. What am I going to do next time? I don't know. But, Word2Vec is coming up. So actually, the things that I need to do, if I look at my other course that I'm teaching this semester, A to Z F18, this will really tell me what I need to do. I think I would like to do Bayesian classification. That's something I would like to do. I did videos on this last year. Word2Vec. The LSTM thing I think I can probably just leave. I don't need to, I'm not going to, I mean I would like to make videos on that, but I have Nabil's guest one now, so I think that's going to be fine. And then, Word2Vec. So that's what's coming up next, Word2Vec. All right, bye everybody. Have a great weekend.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:58.051683Z",
  "started_at": "2023-09-26T21:25:07.009364Z",
  "completed_at": "2023-09-26T21:55:14.108203Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=rkwn-7kZzjY",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1807.098839
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/2d27kprbga3jhzeyu4ghufiktm/cancel",
    "get": "https://api.replicate.com/v1/predictions/2d27kprbga3jhzeyu4ghufiktm"
  }
}