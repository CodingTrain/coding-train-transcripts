{
  "id": "wi24y5bb4fhb5ubkj2besigf2a",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/SyEZ5Yo2ec8.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/81311 [00:00<?, ?frames/s]\n  3%|▎         | 2612/81311 [00:07<03:35, 365.94frames/s]\n  7%|▋         | 5480/81311 [00:16<03:47, 333.11frames/s]\n 10%|█         | 8328/81311 [00:28<04:28, 271.85frames/s]\n 14%|█▎        | 11072/81311 [00:35<03:46, 309.65frames/s]\n 17%|█▋        | 13600/81311 [00:41<03:15, 347.11frames/s]\n 20%|██        | 16520/81311 [00:47<02:47, 386.65frames/s]\n 24%|██▍       | 19388/81311 [00:55<02:41, 382.46frames/s]\n 27%|██▋       | 22254/81311 [01:04<02:49, 347.56frames/s]\n 31%|███       | 25224/81311 [01:12<02:33, 365.47frames/s]\n 34%|███▍      | 28024/81311 [01:22<02:39, 333.09frames/s]\n 38%|███▊      | 30952/81311 [01:33<02:41, 311.34frames/s]\n 42%|████▏     | 33864/81311 [01:40<02:24, 328.33frames/s]\n 45%|████▍     | 36528/81311 [01:49<02:19, 321.85frames/s]\n 49%|████▊     | 39468/81311 [01:57<02:04, 335.39frames/s]\n 52%|█████▏    | 42448/81311 [02:06<01:56, 332.29frames/s]\n 56%|█████▌    | 45136/81311 [02:14<01:48, 331.99frames/s]\n 59%|█████▉    | 47978/81311 [02:23<01:40, 331.39frames/s]\n 62%|██████▏   | 50790/81311 [02:31<01:30, 339.09frames/s]\n 66%|██████▌   | 53626/81311 [02:40<01:23, 333.30frames/s]\n 70%|██████▉   | 56566/81311 [02:50<01:19, 311.21frames/s]\n 73%|███████▎  | 59538/81311 [03:02<01:14, 290.87frames/s]\n 77%|███████▋  | 62378/81311 [03:12<01:04, 293.52frames/s]\n 80%|████████  | 65110/81311 [03:22<00:56, 285.86frames/s]\n 83%|████████▎ | 67866/81311 [03:31<00:46, 287.15frames/s]\n 87%|████████▋ | 70474/81311 [03:40<00:37, 289.84frames/s]\n 90%|█████████ | 73474/81311 [03:51<00:27, 286.75frames/s]\n 90%|█████████ | 73474/81311 [04:03<00:27, 286.75frames/s]\n 94%|█████████▍| 76428/81311 [04:15<00:24, 200.13frames/s]\n 97%|█████████▋| 79264/81311 [04:23<00:08, 235.23frames/s]\n 97%|█████████▋| 79264/81311 [04:33<00:08, 235.23frames/s]\n 99%|█████████▉| 80364/81311 [05:04<00:08, 111.13frames/s]\n99%|█████████▉| 80364/81311 [05:09<00:03, 260.07frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 5,
        "id": 0,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " It's time, it's time to fit our model.",
        "tokens": [
          50364,
          467,
          311,
          565,
          11,
          309,
          311,
          565,
          281,
          3318,
          527,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 8.120000000000001,
        "id": 1,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 5.76,
        "temperature": 0,
        "text": " Here we go, so, so far, you know,",
        "tokens": [
          50652,
          1692,
          321,
          352,
          11,
          370,
          11,
          370,
          1400,
          11,
          291,
          458,
          11,
          50770
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 10.040000000000001,
        "id": 2,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 8.120000000000001,
        "temperature": 0,
        "text": " hopefully you've watched all the previous parts",
        "tokens": [
          50770,
          4696,
          291,
          600,
          6337,
          439,
          264,
          3894,
          3166,
          50866
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 11.92,
        "id": 3,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 10.040000000000001,
        "temperature": 0,
        "text": " of this series, if you haven't, that's fine too,",
        "tokens": [
          50866,
          295,
          341,
          2638,
          11,
          498,
          291,
          2378,
          380,
          11,
          300,
          311,
          2489,
          886,
          11,
          50960
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 15.8,
        "id": 4,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 11.92,
        "temperature": 0,
        "text": " but what I have so far is I prepared my data set,",
        "tokens": [
          50960,
          457,
          437,
          286,
          362,
          370,
          1400,
          307,
          286,
          4927,
          452,
          1412,
          992,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 18.52,
        "id": 5,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 15.8,
        "temperature": 0,
        "text": " loaded it from a JSON file, I've turned everything",
        "tokens": [
          51154,
          13210,
          309,
          490,
          257,
          31828,
          3991,
          11,
          286,
          600,
          3574,
          1203,
          51290
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 22.400000000000002,
        "id": 6,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 18.52,
        "temperature": 0,
        "text": " into tensors, and then I created a model,",
        "tokens": [
          51290,
          666,
          10688,
          830,
          11,
          293,
          550,
          286,
          2942,
          257,
          2316,
          11,
          51484
        ]
      },
      {
        "avg_logprob": -0.27555869990943843,
        "compression_ratio": 1.5254237288135593,
        "end": 26.12,
        "id": 7,
        "no_speech_prob": 0.002757266629487276,
        "seek": 0,
        "start": 22.400000000000002,
        "temperature": 0,
        "text": " tf, using TensorFlow.js, a tf.sequential.model,",
        "tokens": [
          51484,
          256,
          69,
          11,
          1228,
          37624,
          13,
          25530,
          11,
          257,
          256,
          69,
          13,
          11834,
          2549,
          13,
          8014,
          338,
          11,
          51670
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 30.520000000000003,
        "id": 8,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 26.12,
        "temperature": 0,
        "text": " which is designed to receive RGB inputs",
        "tokens": [
          50364,
          597,
          307,
          4761,
          281,
          4774,
          31231,
          15743,
          50584
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 35,
        "id": 9,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 30.520000000000003,
        "temperature": 0,
        "text": " and output a probability distribution for color labels.",
        "tokens": [
          50584,
          293,
          5598,
          257,
          8482,
          7316,
          337,
          2017,
          16949,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 37.64,
        "id": 10,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 35,
        "temperature": 0,
        "text": " And, you know, again, this is somewhat of a trivial scenario",
        "tokens": [
          50808,
          400,
          11,
          291,
          458,
          11,
          797,
          11,
          341,
          307,
          8344,
          295,
          257,
          26703,
          9005,
          50940
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 40.56,
        "id": 11,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 37.64,
        "temperature": 0,
        "text": " but I'm classifying data, simple data",
        "tokens": [
          50940,
          457,
          286,
          478,
          1508,
          5489,
          1412,
          11,
          2199,
          1412,
          51086
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 42.760000000000005,
        "id": 12,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 40.56,
        "temperature": 0,
        "text": " with just three values all between zero, one,",
        "tokens": [
          51086,
          365,
          445,
          1045,
          4190,
          439,
          1296,
          4018,
          11,
          472,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 45.84,
        "id": 13,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 42.760000000000005,
        "temperature": 0,
        "text": " and nine possible categories or labels.",
        "tokens": [
          51196,
          293,
          4949,
          1944,
          10479,
          420,
          16949,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 49.52,
        "id": 14,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 45.84,
        "temperature": 0,
        "text": " Okay, so, that's what I've done so far,",
        "tokens": [
          51350,
          1033,
          11,
          370,
          11,
          300,
          311,
          437,
          286,
          600,
          1096,
          370,
          1400,
          11,
          51534
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 51.68000000000001,
        "id": 15,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 49.52,
        "temperature": 0,
        "text": " so now that I have this, this is actually like,",
        "tokens": [
          51534,
          370,
          586,
          300,
          286,
          362,
          341,
          11,
          341,
          307,
          767,
          411,
          11,
          51642
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 52.92,
        "id": 16,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 51.68000000000001,
        "temperature": 0,
        "text": " in some ways this video's going to be over",
        "tokens": [
          51642,
          294,
          512,
          2098,
          341,
          960,
          311,
          516,
          281,
          312,
          670,
          51704
        ]
      },
      {
        "avg_logprob": -0.2375177430712487,
        "compression_ratio": 1.568904593639576,
        "end": 54.8,
        "id": 17,
        "no_speech_prob": 0.0000037853171761526028,
        "seek": 2612,
        "start": 52.92,
        "temperature": 0,
        "text": " in like two seconds, not really,",
        "tokens": [
          51704,
          294,
          411,
          732,
          3949,
          11,
          406,
          534,
          11,
          51798
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 57.879999999999995,
        "id": 18,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 54.8,
        "temperature": 0,
        "text": " all I need to do is call model.fit.",
        "tokens": [
          50364,
          439,
          286,
          643,
          281,
          360,
          307,
          818,
          2316,
          13,
          6845,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 61.519999999999996,
        "id": 19,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 57.879999999999995,
        "temperature": 0,
        "text": " So model.fit, now what do I need to pass to model.fit?",
        "tokens": [
          50518,
          407,
          2316,
          13,
          6845,
          11,
          586,
          437,
          360,
          286,
          643,
          281,
          1320,
          281,
          2316,
          13,
          6845,
          30,
          50700
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 64,
        "id": 20,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 61.519999999999996,
        "temperature": 0,
        "text": " Well, the idea of model.fit is that I'm saying,",
        "tokens": [
          50700,
          1042,
          11,
          264,
          1558,
          295,
          2316,
          13,
          6845,
          307,
          300,
          286,
          478,
          1566,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 67.39999999999999,
        "id": 21,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 64,
        "temperature": 0,
        "text": " hey, here's the training data, here are all the inputs",
        "tokens": [
          50824,
          4177,
          11,
          510,
          311,
          264,
          3097,
          1412,
          11,
          510,
          366,
          439,
          264,
          15743,
          50994
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 69.75999999999999,
        "id": 22,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 67.39999999999999,
        "temperature": 0,
        "text": " and their associated target outputs,",
        "tokens": [
          50994,
          293,
          641,
          6615,
          3779,
          23930,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 72.2,
        "id": 23,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 69.75999999999999,
        "temperature": 0,
        "text": " which I have called x's and y's.",
        "tokens": [
          51112,
          597,
          286,
          362,
          1219,
          2031,
          311,
          293,
          288,
          311,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 74.1,
        "id": 24,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 72.2,
        "temperature": 0,
        "text": " Now, I think I'm going to get an error right now.",
        "tokens": [
          51234,
          823,
          11,
          286,
          519,
          286,
          478,
          516,
          281,
          483,
          364,
          6713,
          558,
          586,
          13,
          51329
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 77.44,
        "id": 25,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 74.1,
        "temperature": 0,
        "text": " Let me just actually run this, and I'm going to,",
        "tokens": [
          51329,
          961,
          385,
          445,
          767,
          1190,
          341,
          11,
          293,
          286,
          478,
          516,
          281,
          11,
          51496
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 79.4,
        "id": 26,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 77.44,
        "temperature": 0,
        "text": " whoops, let me run this and see if I get the error",
        "tokens": [
          51496,
          567,
          3370,
          11,
          718,
          385,
          1190,
          341,
          293,
          536,
          498,
          286,
          483,
          264,
          6713,
          51594
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 81.75999999999999,
        "id": 27,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 79.4,
        "temperature": 0,
        "text": " that I'm expecting, yeah, so look at this,",
        "tokens": [
          51594,
          300,
          286,
          478,
          9650,
          11,
          1338,
          11,
          370,
          574,
          412,
          341,
          11,
          51712
        ]
      },
      {
        "avg_logprob": -0.21320168076047472,
        "compression_ratio": 1.786764705882353,
        "end": 83.28,
        "id": 28,
        "no_speech_prob": 0.0000017330511354884948,
        "seek": 5480,
        "start": 81.75999999999999,
        "temperature": 0,
        "text": " oh, okay, so a couple things.",
        "tokens": [
          51712,
          1954,
          11,
          1392,
          11,
          370,
          257,
          1916,
          721,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 89.12,
        "id": 29,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 84.12,
        "temperature": 0,
        "text": " Ah, welcome to your life, doing machine learning,",
        "tokens": [
          50406,
          2438,
          11,
          2928,
          281,
          428,
          993,
          11,
          884,
          3479,
          2539,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 91.64,
        "id": 30,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 89.24,
        "temperature": 0,
        "text": " shape mismatching, I didn't even expect this error,",
        "tokens": [
          50662,
          3909,
          23220,
          29569,
          11,
          286,
          994,
          380,
          754,
          2066,
          341,
          6713,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 92.96000000000001,
        "id": 31,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 91.64,
        "temperature": 0,
        "text": " so I have to think about this one.",
        "tokens": [
          50782,
          370,
          286,
          362,
          281,
          519,
          466,
          341,
          472,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 96.26,
        "id": 32,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 92.96000000000001,
        "temperature": 0,
        "text": " Error when checking input, expected dense input",
        "tokens": [
          50848,
          3300,
          2874,
          562,
          8568,
          4846,
          11,
          5176,
          18011,
          4846,
          51013
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 101.26,
        "id": 33,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 96.26,
        "temperature": 0,
        "text": " to have shape three, but got array with shape 5,643.3,",
        "tokens": [
          51013,
          281,
          362,
          3909,
          1045,
          11,
          457,
          658,
          10225,
          365,
          3909,
          1025,
          11,
          21,
          17201,
          13,
          18,
          11,
          51263
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 106.84,
        "id": 34,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 102.2,
        "temperature": 0,
        "text": " so I guess, right, I'm sending in not just three inputs,",
        "tokens": [
          51310,
          370,
          286,
          2041,
          11,
          558,
          11,
          286,
          478,
          7750,
          294,
          406,
          445,
          1045,
          15743,
          11,
          51542
        ]
      },
      {
        "avg_logprob": -0.2837880911286344,
        "compression_ratio": 1.5922330097087378,
        "end": 110.72,
        "id": 35,
        "no_speech_prob": 0.00001952588172571268,
        "seek": 8328,
        "start": 106.84,
        "temperature": 0,
        "text": " the shape of my inputs is many,",
        "tokens": [
          51542,
          264,
          3909,
          295,
          452,
          15743,
          307,
          867,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 114.72,
        "id": 36,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 111.72,
        "temperature": 0,
        "text": " so I think if I just do, ah-ha,",
        "tokens": [
          50414,
          370,
          286,
          519,
          498,
          286,
          445,
          360,
          11,
          3716,
          12,
          1641,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 120.8,
        "id": 37,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 117.2,
        "temperature": 0,
        "text": " so I made a mistake and I used input dimensions,",
        "tokens": [
          50688,
          370,
          286,
          1027,
          257,
          6146,
          293,
          286,
          1143,
          4846,
          12819,
          11,
          50868
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 123.7,
        "id": 38,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 120.8,
        "temperature": 0,
        "text": " where what I really meant was input shape.",
        "tokens": [
          50868,
          689,
          437,
          286,
          534,
          4140,
          390,
          4846,
          3909,
          13,
          51013
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 127.03999999999999,
        "id": 39,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 123.7,
        "temperature": 0,
        "text": " All right, let's go look at the documentation",
        "tokens": [
          51013,
          1057,
          558,
          11,
          718,
          311,
          352,
          574,
          412,
          264,
          14333,
          51180
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 129.07999999999998,
        "id": 40,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 127.03999999999999,
        "temperature": 0,
        "text": " and see what it says there,",
        "tokens": [
          51180,
          293,
          536,
          437,
          309,
          1619,
          456,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 131.38,
        "id": 41,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 129.07999999999998,
        "temperature": 0,
        "text": " and I actually, I've got it pulled up already.",
        "tokens": [
          51282,
          293,
          286,
          767,
          11,
          286,
          600,
          658,
          309,
          7373,
          493,
          1217,
          13,
          51397
        ]
      },
      {
        "avg_logprob": -0.24736573961046007,
        "compression_ratio": 1.5670103092783505,
        "end": 136,
        "id": 42,
        "no_speech_prob": 0.000003187564743711846,
        "seek": 11072,
        "start": 132.38,
        "temperature": 0,
        "text": " Okay, so you can see what I specified was input dimensions.",
        "tokens": [
          51447,
          1033,
          11,
          370,
          291,
          393,
          536,
          437,
          286,
          22206,
          390,
          4846,
          12819,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 140.12,
        "id": 43,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 136.92,
        "temperature": 0,
        "text": " If specified defines input shape",
        "tokens": [
          50410,
          759,
          22206,
          23122,
          4846,
          3909,
          50570
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 144.96,
        "id": 44,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 140.12,
        "temperature": 0,
        "text": " as bracket input dimensions, oh, so actually,",
        "tokens": [
          50570,
          382,
          16904,
          4846,
          12819,
          11,
          1954,
          11,
          370,
          767,
          11,
          50812
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 149.96,
        "id": 45,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 144.96,
        "temperature": 0,
        "text": " I don't even need those array brackets there,",
        "tokens": [
          50812,
          286,
          500,
          380,
          754,
          643,
          729,
          10225,
          26179,
          456,
          11,
          51062
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 153.12,
        "id": 46,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 150.4,
        "temperature": 0,
        "text": " and that should fix it, there we go,",
        "tokens": [
          51084,
          293,
          300,
          820,
          3191,
          309,
          11,
          456,
          321,
          352,
          11,
          51220
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 155.58,
        "id": 47,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 153.12,
        "temperature": 0,
        "text": " but if I wanted to use those array brackets",
        "tokens": [
          51220,
          457,
          498,
          286,
          1415,
          281,
          764,
          729,
          10225,
          26179,
          51343
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 157.24,
        "id": 48,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 155.58,
        "temperature": 0,
        "text": " because I'm sending in many data points,",
        "tokens": [
          51343,
          570,
          286,
          478,
          7750,
          294,
          867,
          1412,
          2793,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 160.52,
        "id": 49,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 157.24,
        "temperature": 0,
        "text": " I could actually just specify the input shape directly,",
        "tokens": [
          51426,
          286,
          727,
          767,
          445,
          16500,
          264,
          4846,
          3909,
          3838,
          11,
          51590
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 163.12,
        "id": 50,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 160.52,
        "temperature": 0,
        "text": " and this would then have the array brackets around it,",
        "tokens": [
          51590,
          293,
          341,
          576,
          550,
          362,
          264,
          10225,
          26179,
          926,
          309,
          11,
          51720
        ]
      },
      {
        "avg_logprob": -0.22867642770899405,
        "compression_ratio": 1.775229357798165,
        "end": 165.2,
        "id": 51,
        "no_speech_prob": 0.000013631344700115733,
        "seek": 13600,
        "start": 163.12,
        "temperature": 0,
        "text": " so it's a subtle distinction,",
        "tokens": [
          51720,
          370,
          309,
          311,
          257,
          13743,
          16844,
          11,
          51824
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 169.07999999999998,
        "id": 52,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 165.2,
        "temperature": 0,
        "text": " I think because only input dimensions is documented,",
        "tokens": [
          50364,
          286,
          519,
          570,
          787,
          4846,
          12819,
          307,
          23007,
          11,
          50558
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 171.44,
        "id": 53,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 169.07999999999998,
        "temperature": 0,
        "text": " let's use that one and let's put a three here.",
        "tokens": [
          50558,
          718,
          311,
          764,
          300,
          472,
          293,
          718,
          311,
          829,
          257,
          1045,
          510,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 175.51999999999998,
        "id": 54,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 171.44,
        "temperature": 0,
        "text": " Okay, so now we've got the, I wonder why that didn't,",
        "tokens": [
          50676,
          1033,
          11,
          370,
          586,
          321,
          600,
          658,
          264,
          11,
          286,
          2441,
          983,
          300,
          994,
          380,
          11,
          50880
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 176.95999999999998,
        "id": 55,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 175.51999999999998,
        "temperature": 0,
        "text": " oh, because I didn't call fit before.",
        "tokens": [
          50880,
          1954,
          11,
          570,
          286,
          994,
          380,
          818,
          3318,
          949,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 178.79999999999998,
        "id": 56,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 176.95999999999998,
        "temperature": 0,
        "text": " Okay, so now I'm fitting the model.",
        "tokens": [
          50952,
          1033,
          11,
          370,
          586,
          286,
          478,
          15669,
          264,
          2316,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 182.35999999999999,
        "id": 57,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 178.79999999999998,
        "temperature": 0,
        "text": " Hmm, I don't see an error, I expected an error.",
        "tokens": [
          51044,
          8239,
          11,
          286,
          500,
          380,
          536,
          364,
          6713,
          11,
          286,
          5176,
          364,
          6713,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 185.28,
        "id": 58,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 182.35999999999999,
        "temperature": 0,
        "text": " Let's, so what happens when I fit the model?",
        "tokens": [
          51222,
          961,
          311,
          11,
          370,
          437,
          2314,
          562,
          286,
          3318,
          264,
          2316,
          30,
          51368
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 188.67999999999998,
        "id": 59,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 185.28,
        "temperature": 0,
        "text": " Well, it returns a promise, model.fit returns a promise.",
        "tokens": [
          51368,
          1042,
          11,
          309,
          11247,
          257,
          6228,
          11,
          2316,
          13,
          6845,
          11247,
          257,
          6228,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 191.04,
        "id": 60,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 188.67999999999998,
        "temperature": 0,
        "text": " If you don't know what a promise is, guess what?",
        "tokens": [
          51538,
          759,
          291,
          500,
          380,
          458,
          437,
          257,
          6228,
          307,
          11,
          2041,
          437,
          30,
          51656
        ]
      },
      {
        "avg_logprob": -0.18982853301583905,
        "compression_ratio": 1.8181818181818181,
        "end": 193.88,
        "id": 61,
        "no_speech_prob": 0.000004029453975817887,
        "seek": 16520,
        "start": 191.04,
        "temperature": 0,
        "text": " I have a whole set of videos about what a promise is,",
        "tokens": [
          51656,
          286,
          362,
          257,
          1379,
          992,
          295,
          2145,
          466,
          437,
          257,
          6228,
          307,
          11,
          51798
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 196.4,
        "id": 62,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 193.88,
        "temperature": 0,
        "text": " and I'm also going to be using eventually await and async,",
        "tokens": [
          50364,
          293,
          286,
          478,
          611,
          516,
          281,
          312,
          1228,
          4728,
          19670,
          293,
          382,
          34015,
          11,
          50490
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 197.6,
        "id": 63,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 196.4,
        "temperature": 0,
        "text": " which I also have videos about,",
        "tokens": [
          50490,
          597,
          286,
          611,
          362,
          2145,
          466,
          11,
          50550
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 201.35999999999999,
        "id": 64,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 197.6,
        "temperature": 0,
        "text": " but right now I can just write the dot then,",
        "tokens": [
          50550,
          457,
          558,
          586,
          286,
          393,
          445,
          2464,
          264,
          5893,
          550,
          11,
          50738
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 203.92,
        "id": 65,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 201.35999999999999,
        "temperature": 0,
        "text": " a prompt, fit returns a promise,",
        "tokens": [
          50738,
          257,
          12391,
          11,
          3318,
          11247,
          257,
          6228,
          11,
          50866
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 206.64,
        "id": 66,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 203.92,
        "temperature": 0,
        "text": " which I can then call a function called then",
        "tokens": [
          50866,
          597,
          286,
          393,
          550,
          818,
          257,
          2445,
          1219,
          550,
          51002
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 209.32,
        "id": 67,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 206.64,
        "temperature": 0,
        "text": " to where the results will be passed in,",
        "tokens": [
          51002,
          281,
          689,
          264,
          3542,
          486,
          312,
          4678,
          294,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 212.32,
        "id": 68,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 210.6,
        "temperature": 0,
        "text": " and I'm just going to say,",
        "tokens": [
          51200,
          293,
          286,
          478,
          445,
          516,
          281,
          584,
          11,
          51286
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 214.12,
        "id": 69,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 212.32,
        "temperature": 0,
        "text": " and I'm going to use this arrow syntax,",
        "tokens": [
          51286,
          293,
          286,
          478,
          516,
          281,
          764,
          341,
          11610,
          28431,
          11,
          51376
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 218.28,
        "id": 70,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 214.12,
        "temperature": 0,
        "text": " this ES6 arrow syntax, console.log results,",
        "tokens": [
          51376,
          341,
          12564,
          21,
          11610,
          28431,
          11,
          11076,
          13,
          4987,
          3542,
          11,
          51584
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 220.2,
        "id": 71,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 218.28,
        "temperature": 0,
        "text": " and eventually I might want to do more with this,",
        "tokens": [
          51584,
          293,
          4728,
          286,
          1062,
          528,
          281,
          360,
          544,
          365,
          341,
          11,
          51680
        ]
      },
      {
        "avg_logprob": -0.20509069357345353,
        "compression_ratio": 1.8125,
        "end": 222.54,
        "id": 72,
        "no_speech_prob": 0.0000034465736007405212,
        "seek": 19388,
        "start": 220.2,
        "temperature": 0,
        "text": " so I'm actually going to make it a full function,",
        "tokens": [
          51680,
          370,
          286,
          478,
          767,
          516,
          281,
          652,
          309,
          257,
          1577,
          2445,
          11,
          51797
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 223.72,
        "id": 73,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 222.54,
        "temperature": 0,
        "text": " so this is what I'm saying is,",
        "tokens": [
          50364,
          370,
          341,
          307,
          437,
          286,
          478,
          1566,
          307,
          11,
          50423
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 228.26,
        "id": 74,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 223.72,
        "temperature": 0,
        "text": " once you fit the model, then log the results.",
        "tokens": [
          50423,
          1564,
          291,
          3318,
          264,
          2316,
          11,
          550,
          3565,
          264,
          3542,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 230.76,
        "id": 75,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 229.4,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50707,
          961,
          311,
          536,
          437,
          2314,
          13,
          50775
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 237.07999999999998,
        "id": 76,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 233.7,
        "temperature": 0,
        "text": " Waiting, waiting, ah, okay, great, look at this.",
        "tokens": [
          50922,
          37291,
          11,
          3806,
          11,
          3716,
          11,
          1392,
          11,
          869,
          11,
          574,
          412,
          341,
          13,
          51091
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 239.89999999999998,
        "id": 77,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 237.07999999999998,
        "temperature": 0,
        "text": " History, loss, and there's my loss.",
        "tokens": [
          51091,
          12486,
          11,
          4470,
          11,
          293,
          456,
          311,
          452,
          4470,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 244.89999999999998,
        "id": 78,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 239.89999999999998,
        "temperature": 0,
        "text": " So it fit that model, it did one epoch,",
        "tokens": [
          51232,
          407,
          309,
          3318,
          300,
          2316,
          11,
          309,
          630,
          472,
          30992,
          339,
          11,
          51482
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 248.5,
        "id": 79,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 246.26,
        "temperature": 0,
        "text": " and gave me a loss, great.",
        "tokens": [
          51550,
          293,
          2729,
          385,
          257,
          4470,
          11,
          869,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.24849262804088026,
        "compression_ratio": 1.5989304812834224,
        "end": 252.23999999999998,
        "id": 80,
        "no_speech_prob": 3.0590192068302713e-7,
        "seek": 22254,
        "start": 248.5,
        "temperature": 0,
        "text": " So, done, trained the model, here's the thing.",
        "tokens": [
          51662,
          407,
          11,
          1096,
          11,
          8895,
          264,
          2316,
          11,
          510,
          311,
          264,
          551,
          13,
          51849
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 254.24,
        "id": 81,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 252.84,
        "temperature": 0,
        "text": " What I want to do ultimately,",
        "tokens": [
          50394,
          708,
          286,
          528,
          281,
          360,
          6284,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 255.8,
        "id": 82,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 254.24,
        "temperature": 0,
        "text": " so this is actually in a way done,",
        "tokens": [
          50464,
          370,
          341,
          307,
          767,
          294,
          257,
          636,
          1096,
          11,
          50542
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 256.96000000000004,
        "id": 83,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 255.8,
        "temperature": 0,
        "text": " what I want to do is, first of all,",
        "tokens": [
          50542,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          700,
          295,
          439,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 259.98,
        "id": 84,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 256.96000000000004,
        "temperature": 0,
        "text": " I want to train the model for more than just one epoch,",
        "tokens": [
          50600,
          286,
          528,
          281,
          3847,
          264,
          2316,
          337,
          544,
          813,
          445,
          472,
          30992,
          339,
          11,
          50751
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 262.76,
        "id": 85,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 259.98,
        "temperature": 0,
        "text": " so one thing that I need to do here",
        "tokens": [
          50751,
          370,
          472,
          551,
          300,
          286,
          643,
          281,
          360,
          510,
          50890
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 265.12,
        "id": 86,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 262.76,
        "temperature": 0,
        "text": " is pass in some options.",
        "tokens": [
          50890,
          307,
          1320,
          294,
          512,
          3956,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 267.90000000000003,
        "id": 87,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 265.12,
        "temperature": 0,
        "text": " So I'm going to create a variable called options,",
        "tokens": [
          51008,
          407,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          1219,
          3956,
          11,
          51147
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 272.40000000000003,
        "id": 88,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 269.36,
        "temperature": 0,
        "text": " and one thing I can specify is epochs,",
        "tokens": [
          51220,
          293,
          472,
          551,
          286,
          393,
          16500,
          307,
          30992,
          28346,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 274.8,
        "id": 89,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 272.40000000000003,
        "temperature": 0,
        "text": " I'm going to say do it for 10,",
        "tokens": [
          51372,
          286,
          478,
          516,
          281,
          584,
          360,
          309,
          337,
          1266,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 275.64,
        "id": 90,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 274.8,
        "temperature": 0,
        "text": " and then I'm going to say,",
        "tokens": [
          51492,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          51534
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 279.08,
        "id": 91,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 275.64,
        "temperature": 0,
        "text": " and let's actually, let's just say two right now,",
        "tokens": [
          51534,
          293,
          718,
          311,
          767,
          11,
          718,
          311,
          445,
          584,
          732,
          558,
          586,
          11,
          51706
        ]
      },
      {
        "avg_logprob": -0.21974292835155568,
        "compression_ratio": 1.8442622950819672,
        "end": 280.24,
        "id": 92,
        "no_speech_prob": 6.577927820217155e-7,
        "seek": 25224,
        "start": 279.08,
        "temperature": 0,
        "text": " because it's going to take a while.",
        "tokens": [
          51706,
          570,
          309,
          311,
          516,
          281,
          747,
          257,
          1339,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 283.72,
        "id": 93,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 280.24,
        "temperature": 0,
        "text": " So the third argument to model.fit is options,",
        "tokens": [
          50364,
          407,
          264,
          2636,
          6770,
          281,
          2316,
          13,
          6845,
          307,
          3956,
          11,
          50538
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 285.84000000000003,
        "id": 94,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 283.72,
        "temperature": 0,
        "text": " and if I go into TensorFlow.js,",
        "tokens": [
          50538,
          293,
          498,
          286,
          352,
          666,
          37624,
          13,
          25530,
          11,
          50644
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 287.78000000000003,
        "id": 95,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 285.84000000000003,
        "temperature": 0,
        "text": " and I look for a model.fit,",
        "tokens": [
          50644,
          293,
          286,
          574,
          337,
          257,
          2316,
          13,
          6845,
          11,
          50741
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 289.64,
        "id": 96,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 287.78000000000003,
        "temperature": 0,
        "text": " oops, I was right there already,",
        "tokens": [
          50741,
          34166,
          11,
          286,
          390,
          558,
          456,
          1217,
          11,
          50834
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 291.40000000000003,
        "id": 97,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 289.64,
        "temperature": 0,
        "text": " we can see now these are the various options,",
        "tokens": [
          50834,
          321,
          393,
          536,
          586,
          613,
          366,
          264,
          3683,
          3956,
          11,
          50922
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 292.72,
        "id": 98,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 291.40000000000003,
        "temperature": 0,
        "text": " and I'm going to be using a bunch of these,",
        "tokens": [
          50922,
          293,
          286,
          478,
          516,
          281,
          312,
          1228,
          257,
          3840,
          295,
          613,
          11,
          50988
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 294.04,
        "id": 99,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 292.72,
        "temperature": 0,
        "text": " but epochs is one of them,",
        "tokens": [
          50988,
          457,
          30992,
          28346,
          307,
          472,
          295,
          552,
          11,
          51054
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 296.68,
        "id": 100,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 294.04,
        "temperature": 0,
        "text": " the number of times to iterate over the training data.",
        "tokens": [
          51054,
          264,
          1230,
          295,
          1413,
          281,
          44497,
          670,
          264,
          3097,
          1412,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 301,
        "id": 101,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 298.28000000000003,
        "temperature": 0,
        "text": " So, let's rub this now,",
        "tokens": [
          51266,
          407,
          11,
          718,
          311,
          5915,
          341,
          586,
          11,
          51402
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 303.64,
        "id": 102,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 302.8,
        "temperature": 0,
        "text": " and you know what I'm going to do?",
        "tokens": [
          51492,
          293,
          291,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          30,
          51534
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 306.54,
        "id": 103,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 303.64,
        "temperature": 0,
        "text": " I don't think we need all of this printing stuff,",
        "tokens": [
          51534,
          286,
          500,
          380,
          519,
          321,
          643,
          439,
          295,
          341,
          14699,
          1507,
          11,
          51679
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 307.6,
        "id": 104,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 306.54,
        "temperature": 0,
        "text": " so I'm going to get rid of some",
        "tokens": [
          51679,
          370,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          512,
          51732
        ]
      },
      {
        "avg_logprob": -0.23254690107130846,
        "compression_ratio": 1.7347670250896057,
        "end": 309.52,
        "id": 105,
        "no_speech_prob": 0.0000020580469026754145,
        "seek": 28024,
        "start": 307.6,
        "temperature": 0,
        "text": " of the earlier printing things,",
        "tokens": [
          51732,
          295,
          264,
          3071,
          14699,
          721,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 312.59999999999997,
        "id": 106,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 309.52,
        "temperature": 0,
        "text": " because I don't need to look at all of that so much.",
        "tokens": [
          50364,
          570,
          286,
          500,
          380,
          643,
          281,
          574,
          412,
          439,
          295,
          300,
          370,
          709,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 316.84,
        "id": 107,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 312.59999999999997,
        "temperature": 0,
        "text": " So let's run this, whoops, options is not defined,",
        "tokens": [
          50518,
          407,
          718,
          311,
          1190,
          341,
          11,
          567,
          3370,
          11,
          3956,
          307,
          406,
          7642,
          11,
          50730
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 317.96,
        "id": 108,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 316.84,
        "temperature": 0,
        "text": " I spelled that wrong.",
        "tokens": [
          50730,
          286,
          34388,
          300,
          2085,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 324.64,
        "id": 109,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 319.64,
        "temperature": 0,
        "text": " I guess I still have 44 and 45 console logging stuff,",
        "tokens": [
          50870,
          286,
          2041,
          286,
          920,
          362,
          16408,
          293,
          6905,
          11076,
          27991,
          1507,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 326.12,
        "id": 110,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 325.12,
        "temperature": 0,
        "text": " which I don't need.",
        "tokens": [
          51144,
          597,
          286,
          500,
          380,
          643,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 328.79999999999995,
        "id": 111,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 327.44,
        "temperature": 0,
        "text": " I didn't get an error that I expected to get,",
        "tokens": [
          51260,
          286,
          994,
          380,
          483,
          364,
          6713,
          300,
          286,
          5176,
          281,
          483,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 330.24,
        "id": 112,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 328.79999999999995,
        "temperature": 0,
        "text": " which is kind of interesting.",
        "tokens": [
          51328,
          597,
          307,
          733,
          295,
          1880,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 335.02,
        "id": 113,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 332.32,
        "temperature": 0,
        "text": " And, oh, you know why?",
        "tokens": [
          51504,
          400,
          11,
          1954,
          11,
          291,
          458,
          983,
          30,
          51639
        ]
      },
      {
        "avg_logprob": -0.2497374794699929,
        "compression_ratio": 1.563063063063063,
        "end": 338.64,
        "id": 114,
        "no_speech_prob": 0.000023552529455628246,
        "seek": 30952,
        "start": 336,
        "temperature": 0,
        "text": " One thing that I want to do is I want to update,",
        "tokens": [
          51688,
          1485,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          5623,
          11,
          51820
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 340.56,
        "id": 115,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 338.64,
        "temperature": 0,
        "text": " you know, at the time of this recording,",
        "tokens": [
          50364,
          291,
          458,
          11,
          412,
          264,
          565,
          295,
          341,
          6613,
          11,
          50460
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 343.24,
        "id": 116,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 340.56,
        "temperature": 0,
        "text": " I think the most recent version of TensorFlow.js",
        "tokens": [
          50460,
          286,
          519,
          264,
          881,
          5162,
          3037,
          295,
          37624,
          13,
          25530,
          50594
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 348.24,
        "id": 117,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 343.24,
        "temperature": 0,
        "text": " is 0.11.7, and when I was previously recording,",
        "tokens": [
          50594,
          307,
          1958,
          13,
          5348,
          13,
          22,
          11,
          293,
          562,
          286,
          390,
          8046,
          6613,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 352.08,
        "id": 118,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 349.47999999999996,
        "temperature": 0,
        "text": " I was using.4, and I think some things have changed.",
        "tokens": [
          50906,
          286,
          390,
          1228,
          2411,
          19,
          11,
          293,
          286,
          519,
          512,
          721,
          362,
          3105,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 354.71999999999997,
        "id": 119,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 353.03999999999996,
        "temperature": 0,
        "text": " All right, so let's let this run.",
        "tokens": [
          51084,
          1057,
          558,
          11,
          370,
          718,
          311,
          718,
          341,
          1190,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 358.36,
        "id": 120,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 354.71999999999997,
        "temperature": 0,
        "text": " It's running for two epochs right now, it finished,",
        "tokens": [
          51168,
          467,
          311,
          2614,
          337,
          732,
          30992,
          28346,
          558,
          586,
          11,
          309,
          4335,
          11,
          51350
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 360.71999999999997,
        "id": 121,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 358.36,
        "temperature": 0,
        "text": " and I can look at the history, and I can see both lost.",
        "tokens": [
          51350,
          293,
          286,
          393,
          574,
          412,
          264,
          2503,
          11,
          293,
          286,
          393,
          536,
          1293,
          2731,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 364.03999999999996,
        "id": 122,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 360.71999999999997,
        "temperature": 0,
        "text": " So we can see, the loss went down for the second epoch,",
        "tokens": [
          51468,
          407,
          321,
          393,
          536,
          11,
          264,
          4470,
          1437,
          760,
          337,
          264,
          1150,
          30992,
          339,
          11,
          51634
        ]
      },
      {
        "avg_logprob": -0.2526496124267578,
        "compression_ratio": 1.6611570247933884,
        "end": 365.28,
        "id": 123,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 33864,
        "start": 364.03999999999996,
        "temperature": 0,
        "text": " that's great!",
        "tokens": [
          51634,
          300,
          311,
          869,
          0,
          51696
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 370.79999999999995,
        "id": 124,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 366.28,
        "temperature": 0,
        "text": " Now, let's run this over 10 epochs,",
        "tokens": [
          50414,
          823,
          11,
          718,
          311,
          1190,
          341,
          670,
          1266,
          30992,
          28346,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 376.44,
        "id": 125,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 372.64,
        "temperature": 0,
        "text": " and let's run this, and let's just console log",
        "tokens": [
          50732,
          293,
          718,
          311,
          1190,
          341,
          11,
          293,
          718,
          311,
          445,
          11076,
          3565,
          50922
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 379.11999999999995,
        "id": 126,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 376.44,
        "temperature": 0,
        "text": " results.loss, by the way, or what was it?",
        "tokens": [
          50922,
          3542,
          13,
          75,
          772,
          11,
          538,
          264,
          636,
          11,
          420,
          437,
          390,
          309,
          30,
          51056
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 381.32,
        "id": 127,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 379.11999999999995,
        "temperature": 0,
        "text": " Is it results.history.loss?",
        "tokens": [
          51056,
          1119,
          309,
          3542,
          13,
          33236,
          827,
          13,
          75,
          772,
          30,
          51166
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 382.15999999999997,
        "id": 128,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 381.32,
        "temperature": 0,
        "text": " Might be that.",
        "tokens": [
          51166,
          23964,
          312,
          300,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 384.47999999999996,
        "id": 129,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 383.23999999999995,
        "temperature": 0,
        "text": " Now let's look at what it is.",
        "tokens": [
          51262,
          823,
          718,
          311,
          574,
          412,
          437,
          309,
          307,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 387.79999999999995,
        "id": 130,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 384.47999999999996,
        "temperature": 0,
        "text": " The history, history.loss, okay?",
        "tokens": [
          51324,
          440,
          2503,
          11,
          2503,
          13,
          75,
          772,
          11,
          1392,
          30,
          51490
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 391.03999999999996,
        "id": 131,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 387.79999999999995,
        "temperature": 0,
        "text": " So let's do this, whoops, I don't need that.",
        "tokens": [
          51490,
          407,
          718,
          311,
          360,
          341,
          11,
          567,
          3370,
          11,
          286,
          500,
          380,
          643,
          300,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.22100098112709501,
        "compression_ratio": 1.6377551020408163,
        "end": 394.67999999999995,
        "id": 132,
        "no_speech_prob": 0.000004289328444428975,
        "seek": 36528,
        "start": 391.03999999999996,
        "temperature": 0,
        "text": " Let's go back here, hit refresh, and waiting.",
        "tokens": [
          51652,
          961,
          311,
          352,
          646,
          510,
          11,
          2045,
          15134,
          11,
          293,
          3806,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 396.72,
        "id": 133,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 395.12,
        "temperature": 0,
        "text": " I'm going to edit out this waiting part.",
        "tokens": [
          50386,
          286,
          478,
          516,
          281,
          8129,
          484,
          341,
          3806,
          644,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 399.38,
        "id": 134,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 396.72,
        "temperature": 0,
        "text": " ♪ Upbeat music ♪",
        "tokens": [
          50466,
          220,
          158,
          247,
          103,
          220,
          22164,
          4169,
          1318,
          220,
          158,
          247,
          103,
          50599
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 404.04,
        "id": 135,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 401.04,
        "temperature": 0,
        "text": " Okay, great, so look at this, over 10 epochs,",
        "tokens": [
          50682,
          1033,
          11,
          869,
          11,
          370,
          574,
          412,
          341,
          11,
          670,
          1266,
          30992,
          28346,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 406.08,
        "id": 136,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 404.04,
        "temperature": 0,
        "text": " the loss is going down, this is good,",
        "tokens": [
          50832,
          264,
          4470,
          307,
          516,
          760,
          11,
          341,
          307,
          665,
          11,
          50934
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 407.32,
        "id": 137,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 406.08,
        "temperature": 0,
        "text": " this is what we want to see.",
        "tokens": [
          50934,
          341,
          307,
          437,
          321,
          528,
          281,
          536,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 410.48,
        "id": 138,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 407.32,
        "temperature": 0,
        "text": " Now here's the thing, what's it using to calculate",
        "tokens": [
          50996,
          823,
          510,
          311,
          264,
          551,
          11,
          437,
          311,
          309,
          1228,
          281,
          8873,
          51154
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 413.2,
        "id": 139,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 410.48,
        "temperature": 0,
        "text": " that loss, huh?",
        "tokens": [
          51154,
          300,
          4470,
          11,
          7020,
          30,
          51290
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 415.08,
        "id": 140,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 413.2,
        "temperature": 0,
        "text": " Oh, there's so much to discuss, I got to get myself",
        "tokens": [
          51290,
          876,
          11,
          456,
          311,
          370,
          709,
          281,
          2248,
          11,
          286,
          658,
          281,
          483,
          2059,
          51384
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 416.2,
        "id": 141,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 415.08,
        "temperature": 0,
        "text": " organized, my thoughts here.",
        "tokens": [
          51384,
          9983,
          11,
          452,
          4598,
          510,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 421.16,
        "id": 142,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 416.2,
        "temperature": 0,
        "text": " I want to, I think maybe, maybe I've done this video,",
        "tokens": [
          51440,
          286,
          528,
          281,
          11,
          286,
          519,
          1310,
          11,
          1310,
          286,
          600,
          1096,
          341,
          960,
          11,
          51688
        ]
      },
      {
        "avg_logprob": -0.32272244176120624,
        "compression_ratio": 1.5932835820895523,
        "end": 424.48,
        "id": 143,
        "no_speech_prob": 0.0000042228293750667945,
        "seek": 39468,
        "start": 421.16,
        "temperature": 0,
        "text": " I'm really breaking this into lots of small parts,",
        "tokens": [
          51688,
          286,
          478,
          534,
          7697,
          341,
          666,
          3195,
          295,
          1359,
          3166,
          11,
          51854
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 427.44,
        "id": 144,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 425.28000000000003,
        "temperature": 0,
        "text": " and really what I've done now is call model.fit",
        "tokens": [
          50404,
          293,
          534,
          437,
          286,
          600,
          1096,
          586,
          307,
          818,
          2316,
          13,
          6845,
          50512
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 429.68,
        "id": 145,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 427.44,
        "temperature": 0,
        "text": " with one single option.",
        "tokens": [
          50512,
          365,
          472,
          2167,
          3614,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 432.44,
        "id": 146,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 429.68,
        "temperature": 0,
        "text": " The two things I need to do that are next.",
        "tokens": [
          50624,
          440,
          732,
          721,
          286,
          643,
          281,
          360,
          300,
          366,
          958,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 435.52000000000004,
        "id": 147,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 432.44,
        "temperature": 0,
        "text": " One is, I need to figure out what's it getting that loss,",
        "tokens": [
          50762,
          1485,
          307,
          11,
          286,
          643,
          281,
          2573,
          484,
          437,
          311,
          309,
          1242,
          300,
          4470,
          11,
          50916
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 438.20000000000005,
        "id": 148,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 435.52000000000004,
        "temperature": 0,
        "text": " like what data is it using to calculate that loss?",
        "tokens": [
          50916,
          411,
          437,
          1412,
          307,
          309,
          1228,
          281,
          8873,
          300,
          4470,
          30,
          51050
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 439.6,
        "id": 149,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 438.20000000000005,
        "temperature": 0,
        "text": " Is it the training data?",
        "tokens": [
          51050,
          1119,
          309,
          264,
          3097,
          1412,
          30,
          51120
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 442,
        "id": 150,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 439.6,
        "temperature": 0,
        "text": " Didn't I talk about testing data and validation data?",
        "tokens": [
          51120,
          11151,
          380,
          286,
          751,
          466,
          4997,
          1412,
          293,
          24071,
          1412,
          30,
          51240
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 443.52000000000004,
        "id": 151,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 442,
        "temperature": 0,
        "text": " Should I be thinking about that at some point?",
        "tokens": [
          51240,
          6454,
          286,
          312,
          1953,
          466,
          300,
          412,
          512,
          935,
          30,
          51316
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 444.82,
        "id": 152,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 443.52000000000004,
        "temperature": 0,
        "text": " So I've got to deal with that.",
        "tokens": [
          51316,
          407,
          286,
          600,
          658,
          281,
          2028,
          365,
          300,
          13,
          51381
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 448.34000000000003,
        "id": 153,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 444.82,
        "temperature": 0,
        "text": " Number two is, I would like to,",
        "tokens": [
          51381,
          5118,
          732,
          307,
          11,
          286,
          576,
          411,
          281,
          11,
          51557
        ]
      },
      {
        "avg_logprob": -0.21574115753173828,
        "compression_ratio": 1.7159090909090908,
        "end": 451.36,
        "id": 154,
        "no_speech_prob": 0.000011478763553895988,
        "seek": 42448,
        "start": 448.34000000000003,
        "temperature": 0,
        "text": " the point of this is I'm in a p5 sketch,",
        "tokens": [
          51557,
          264,
          935,
          295,
          341,
          307,
          286,
          478,
          294,
          257,
          280,
          20,
          12325,
          11,
          51708
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 455.42,
        "id": 155,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 451.36,
        "temperature": 0,
        "text": " and I can say function draw background zero,",
        "tokens": [
          50364,
          293,
          286,
          393,
          584,
          2445,
          2642,
          3678,
          4018,
          11,
          50567
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 457.2,
        "id": 156,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 455.42,
        "temperature": 0,
        "text": " and I can run this, but look at this,",
        "tokens": [
          50567,
          293,
          286,
          393,
          1190,
          341,
          11,
          457,
          574,
          412,
          341,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 459.72,
        "id": 157,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 457.2,
        "temperature": 0,
        "text": " it just says loading up there all the while",
        "tokens": [
          50656,
          309,
          445,
          1619,
          15114,
          493,
          456,
          439,
          264,
          1339,
          50782
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 461.2,
        "id": 158,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 459.72,
        "temperature": 0,
        "text": " while it's training.",
        "tokens": [
          50782,
          1339,
          309,
          311,
          3097,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 464.56,
        "id": 159,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 461.2,
        "temperature": 0,
        "text": " I've locked, I don't have any ability to run an animation.",
        "tokens": [
          50856,
          286,
          600,
          9376,
          11,
          286,
          500,
          380,
          362,
          604,
          3485,
          281,
          1190,
          364,
          9603,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 466.84000000000003,
        "id": 160,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 464.56,
        "temperature": 0,
        "text": " I want, once it finishes, I see the canvas.",
        "tokens": [
          51024,
          286,
          528,
          11,
          1564,
          309,
          23615,
          11,
          286,
          536,
          264,
          16267,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 469.44,
        "id": 161,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 466.84000000000003,
        "temperature": 0,
        "text": " I want the canvas to animate while it's training,",
        "tokens": [
          51138,
          286,
          528,
          264,
          16267,
          281,
          36439,
          1339,
          309,
          311,
          3097,
          11,
          51268
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 471.82,
        "id": 162,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 469.44,
        "temperature": 0,
        "text": " and I want to see the loss over time.",
        "tokens": [
          51268,
          293,
          286,
          528,
          281,
          536,
          264,
          4470,
          670,
          565,
          13,
          51387
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 473.96000000000004,
        "id": 163,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 471.82,
        "temperature": 0,
        "text": " I want to have that reported back to me.",
        "tokens": [
          51387,
          286,
          528,
          281,
          362,
          300,
          7055,
          646,
          281,
          385,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 476.76,
        "id": 164,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 473.96000000000004,
        "temperature": 0,
        "text": " So those are the two things that I need to do.",
        "tokens": [
          51494,
          407,
          729,
          366,
          264,
          732,
          721,
          300,
          286,
          643,
          281,
          360,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.18614770384395823,
        "compression_ratio": 1.8588709677419355,
        "end": 479.78000000000003,
        "id": 165,
        "no_speech_prob": 8.446225479019631e-7,
        "seek": 45136,
        "start": 476.76,
        "temperature": 0,
        "text": " I think I can tackle the training,",
        "tokens": [
          51634,
          286,
          519,
          286,
          393,
          14896,
          264,
          3097,
          11,
          51785
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 482.46,
        "id": 166,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 479.78,
        "temperature": 0,
        "text": " the testing and validation data thing right now,",
        "tokens": [
          50364,
          264,
          4997,
          293,
          24071,
          1412,
          551,
          558,
          586,
          11,
          50498
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 484.05999999999995,
        "id": 167,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 482.46,
        "temperature": 0,
        "text": " because let's do that in this video,",
        "tokens": [
          50498,
          570,
          718,
          311,
          360,
          300,
          294,
          341,
          960,
          11,
          50578
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 486.41999999999996,
        "id": 168,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 484.05999999999995,
        "temperature": 0,
        "text": " and I'm going to add the animation stuff in the next video.",
        "tokens": [
          50578,
          293,
          286,
          478,
          516,
          281,
          909,
          264,
          9603,
          1507,
          294,
          264,
          958,
          960,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 489.78,
        "id": 169,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 486.41999999999996,
        "temperature": 0,
        "text": " So first of all, okay, so,",
        "tokens": [
          50696,
          407,
          700,
          295,
          439,
          11,
          1392,
          11,
          370,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 493.11999999999995,
        "id": 170,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 491.26,
        "temperature": 0,
        "text": " I have my data set.",
        "tokens": [
          50938,
          286,
          362,
          452,
          1412,
          992,
          13,
          51031
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 498.11999999999995,
        "id": 171,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 493.11999999999995,
        "temperature": 0,
        "text": " My data set has, I think it was 5,643 elements,",
        "tokens": [
          51031,
          1222,
          1412,
          992,
          575,
          11,
          286,
          519,
          309,
          390,
          1025,
          11,
          21,
          17201,
          4959,
          11,
          51281
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 501.53999999999996,
        "id": 172,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 499.65999999999997,
        "temperature": 0,
        "text": " data points in it.",
        "tokens": [
          51358,
          1412,
          2793,
          294,
          309,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 503.58,
        "id": 173,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 501.53999999999996,
        "temperature": 0,
        "text": " I said at the very beginning of this series",
        "tokens": [
          51452,
          286,
          848,
          412,
          264,
          588,
          2863,
          295,
          341,
          2638,
          51554
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 505,
        "id": 174,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 503.58,
        "temperature": 0,
        "text": " when I was preparing the data set,",
        "tokens": [
          51554,
          562,
          286,
          390,
          10075,
          264,
          1412,
          992,
          11,
          51625
        ]
      },
      {
        "avg_logprob": -0.22356892447186333,
        "compression_ratio": 1.6382978723404256,
        "end": 507.9,
        "id": 175,
        "no_speech_prob": 9.570827614879818e-7,
        "seek": 47978,
        "start": 505,
        "temperature": 0,
        "text": " that a typical thing to do is divide the data,",
        "tokens": [
          51625,
          300,
          257,
          7476,
          551,
          281,
          360,
          307,
          9845,
          264,
          1412,
          11,
          51770
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 510.02,
        "id": 176,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 507.9,
        "temperature": 0,
        "text": " and again, this is really small.",
        "tokens": [
          50364,
          293,
          797,
          11,
          341,
          307,
          534,
          1359,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 513.34,
        "id": 177,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 510.02,
        "temperature": 0,
        "text": " For proper machine learning model, robust,",
        "tokens": [
          50470,
          1171,
          2296,
          3479,
          2539,
          2316,
          11,
          13956,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 515.66,
        "id": 178,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 513.34,
        "temperature": 0,
        "text": " I probably want to have a much larger data set,",
        "tokens": [
          50636,
          286,
          1391,
          528,
          281,
          362,
          257,
          709,
          4833,
          1412,
          992,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 518.8199999999999,
        "id": 179,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 515.66,
        "temperature": 0,
        "text": " but this will actually kind of work just fine, as we'll see.",
        "tokens": [
          50752,
          457,
          341,
          486,
          767,
          733,
          295,
          589,
          445,
          2489,
          11,
          382,
          321,
          603,
          536,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 522.3199999999999,
        "id": 180,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 518.8199999999999,
        "temperature": 0,
        "text": " I want to use probably the 80-20 rule,",
        "tokens": [
          50910,
          286,
          528,
          281,
          764,
          1391,
          264,
          4688,
          12,
          2009,
          4978,
          11,
          51085
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 525.86,
        "id": 181,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 522.3199999999999,
        "temperature": 0,
        "text": " saying that 80% is actually the training data.",
        "tokens": [
          51085,
          1566,
          300,
          4688,
          4,
          307,
          767,
          264,
          3097,
          1412,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 528.6,
        "id": 182,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 525.86,
        "temperature": 0,
        "text": " So I want to just only use,",
        "tokens": [
          51262,
          407,
          286,
          528,
          281,
          445,
          787,
          764,
          11,
          51399
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 531.54,
        "id": 183,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 528.6,
        "temperature": 0,
        "text": " really, why does it,",
        "tokens": [
          51399,
          534,
          11,
          983,
          775,
          309,
          11,
          51546
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 533.64,
        "id": 184,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 531.54,
        "temperature": 0,
        "text": " it's because the keyboard is next to this.",
        "tokens": [
          51546,
          309,
          311,
          570,
          264,
          10186,
          307,
          958,
          281,
          341,
          13,
          51651
        ]
      },
      {
        "avg_logprob": -0.2903744573178499,
        "compression_ratio": 1.5761316872427984,
        "end": 536.26,
        "id": 185,
        "no_speech_prob": 0.000009818306352826767,
        "seek": 50790,
        "start": 533.64,
        "temperature": 0,
        "text": " Just go away, sound.",
        "tokens": [
          51651,
          1449,
          352,
          1314,
          11,
          1626,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 540.26,
        "id": 186,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 536.26,
        "temperature": 0,
        "text": " I want to, I want these Xs and Ys",
        "tokens": [
          50364,
          286,
          528,
          281,
          11,
          286,
          528,
          613,
          1783,
          82,
          293,
          398,
          82,
          50564
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 543.8199999999999,
        "id": 187,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 540.26,
        "temperature": 0,
        "text": " to only actually be 80% of that original data.",
        "tokens": [
          50564,
          281,
          787,
          767,
          312,
          4688,
          4,
          295,
          300,
          3380,
          1412,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 545.14,
        "id": 188,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 543.8199999999999,
        "temperature": 0,
        "text": " So I'm not doing that.",
        "tokens": [
          50742,
          407,
          286,
          478,
          406,
          884,
          300,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 546.9,
        "id": 189,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 545.14,
        "temperature": 0,
        "text": " Maybe I'll add that in at another point.",
        "tokens": [
          50808,
          2704,
          286,
          603,
          909,
          300,
          294,
          412,
          1071,
          935,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 549.9,
        "id": 190,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 546.9,
        "temperature": 0,
        "text": " That could be an exercise for you as the viewer,",
        "tokens": [
          50896,
          663,
          727,
          312,
          364,
          5380,
          337,
          291,
          382,
          264,
          16767,
          11,
          51046
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 552.8199999999999,
        "id": 191,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 549.9,
        "temperature": 0,
        "text": " to take out 20%, or maybe because my data set's so small,",
        "tokens": [
          51046,
          281,
          747,
          484,
          945,
          8923,
          420,
          1310,
          570,
          452,
          1412,
          992,
          311,
          370,
          1359,
          11,
          51192
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 554.52,
        "id": 192,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 552.8199999999999,
        "temperature": 0,
        "text": " just take out 10% of the data.",
        "tokens": [
          51192,
          445,
          747,
          484,
          1266,
          4,
          295,
          264,
          1412,
          13,
          51277
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 557.6,
        "id": 193,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 555.38,
        "temperature": 0,
        "text": " So that's what would be used to test the model",
        "tokens": [
          51320,
          407,
          300,
          311,
          437,
          576,
          312,
          1143,
          281,
          1500,
          264,
          2316,
          51431
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 561.3,
        "id": 194,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 557.6,
        "temperature": 0,
        "text": " after I finish training it, but while I'm training it,",
        "tokens": [
          51431,
          934,
          286,
          2413,
          3097,
          309,
          11,
          457,
          1339,
          286,
          478,
          3097,
          309,
          11,
          51616
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 563.66,
        "id": 195,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 561.3,
        "temperature": 0,
        "text": " while I'm actually training it and figuring out,",
        "tokens": [
          51616,
          1339,
          286,
          478,
          767,
          3097,
          309,
          293,
          15213,
          484,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.20394925470952388,
        "compression_ratio": 1.6942446043165467,
        "end": 565.66,
        "id": 196,
        "no_speech_prob": 0.0000019033842590943095,
        "seek": 53626,
        "start": 563.66,
        "temperature": 0,
        "text": " well, how many input nodes do I want?",
        "tokens": [
          51734,
          731,
          11,
          577,
          867,
          4846,
          13891,
          360,
          286,
          528,
          30,
          51834
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 567.66,
        "id": 197,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 566.06,
        "temperature": 0,
        "text": " What learning rate do I want?",
        "tokens": [
          50384,
          708,
          2539,
          3314,
          360,
          286,
          528,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 570.54,
        "id": 198,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 568.66,
        "temperature": 0,
        "text": " What are these hyperparameters?",
        "tokens": [
          50514,
          708,
          366,
          613,
          9848,
          2181,
          335,
          6202,
          30,
          50608
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 572.78,
        "id": 199,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 570.54,
        "temperature": 0,
        "text": " What are the parameters of this system",
        "tokens": [
          50608,
          708,
          366,
          264,
          9834,
          295,
          341,
          1185,
          50720
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 573.9399999999999,
        "id": 200,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 572.78,
        "temperature": 0,
        "text": " that I want to try different things?",
        "tokens": [
          50720,
          300,
          286,
          528,
          281,
          853,
          819,
          721,
          30,
          50778
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 577.2199999999999,
        "id": 201,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 573.9399999999999,
        "temperature": 0,
        "text": " How many epochs do I want to train the model for?",
        "tokens": [
          50778,
          1012,
          867,
          30992,
          28346,
          360,
          286,
          528,
          281,
          3847,
          264,
          2316,
          337,
          30,
          50942
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 578.98,
        "id": 202,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 577.2199999999999,
        "temperature": 0,
        "text": " What batch size do I want to use?",
        "tokens": [
          50942,
          708,
          15245,
          2744,
          360,
          286,
          528,
          281,
          764,
          30,
          51030
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 581.1,
        "id": 203,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 578.98,
        "temperature": 0,
        "text": " All these things are known as hyperparameters,",
        "tokens": [
          51030,
          1057,
          613,
          721,
          366,
          2570,
          382,
          9848,
          2181,
          335,
          6202,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 583.54,
        "id": 204,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 581.1,
        "temperature": 0,
        "text": " the parameters during the training process.",
        "tokens": [
          51136,
          264,
          9834,
          1830,
          264,
          3097,
          1399,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 585.6999999999999,
        "id": 205,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 583.54,
        "temperature": 0,
        "text": " If I want to be playing around with those,",
        "tokens": [
          51258,
          759,
          286,
          528,
          281,
          312,
          2433,
          926,
          365,
          729,
          11,
          51366
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 589.0799999999999,
        "id": 206,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 585.6999999999999,
        "temperature": 0,
        "text": " I need a separate data set to compute a loss",
        "tokens": [
          51366,
          286,
          643,
          257,
          4994,
          1412,
          992,
          281,
          14722,
          257,
          4470,
          51535
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 590.78,
        "id": 207,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 589.0799999999999,
        "temperature": 0,
        "text": " that's not part of the training data,",
        "tokens": [
          51535,
          300,
          311,
          406,
          644,
          295,
          264,
          3097,
          1412,
          11,
          51620
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 592.9399999999999,
        "id": 208,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 590.78,
        "temperature": 0,
        "text": " but also is not part of my testing data",
        "tokens": [
          51620,
          457,
          611,
          307,
          406,
          644,
          295,
          452,
          4997,
          1412,
          51728
        ]
      },
      {
        "avg_logprob": -0.20886599137479026,
        "compression_ratio": 1.9814814814814814,
        "end": 595.38,
        "id": 209,
        "no_speech_prob": 0.000012219070413266309,
        "seek": 56566,
        "start": 592.9399999999999,
        "temperature": 0,
        "text": " that I'm going to use when I'm completely done training.",
        "tokens": [
          51728,
          300,
          286,
          478,
          516,
          281,
          764,
          562,
          286,
          478,
          2584,
          1096,
          3097,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 597.66,
        "id": 210,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 596.06,
        "temperature": 0,
        "text": " That's what the validation data is.",
        "tokens": [
          50398,
          663,
          311,
          437,
          264,
          24071,
          1412,
          307,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 600.96,
        "id": 211,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 597.66,
        "temperature": 0,
        "text": " The validation data is basically a test data set,",
        "tokens": [
          50478,
          440,
          24071,
          1412,
          307,
          1936,
          257,
          1500,
          1412,
          992,
          11,
          50643
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 603.42,
        "id": 212,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 600.96,
        "temperature": 0,
        "text": " but it's not your test data set when you're done",
        "tokens": [
          50643,
          457,
          309,
          311,
          406,
          428,
          1500,
          1412,
          992,
          562,
          291,
          434,
          1096,
          50766
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 605.16,
        "id": 213,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 603.42,
        "temperature": 0,
        "text": " and you're ready to publish your model.",
        "tokens": [
          50766,
          293,
          291,
          434,
          1919,
          281,
          11374,
          428,
          2316,
          13,
          50853
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 607.9399999999999,
        "id": 214,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 605.16,
        "temperature": 0,
        "text": " It's your test data set while you're doing all the training.",
        "tokens": [
          50853,
          467,
          311,
          428,
          1500,
          1412,
          992,
          1339,
          291,
          434,
          884,
          439,
          264,
          3097,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 611.66,
        "id": 215,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 607.9399999999999,
        "temperature": 0,
        "text": " And TensorFlow.js has a configuration option",
        "tokens": [
          50992,
          400,
          37624,
          13,
          25530,
          575,
          257,
          11694,
          3614,
          51178
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 612.98,
        "id": 216,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 611.66,
        "temperature": 0,
        "text": " for model.fit that just says,",
        "tokens": [
          51178,
          337,
          2316,
          13,
          6845,
          300,
          445,
          1619,
          11,
          51244
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 615.98,
        "id": 217,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 612.98,
        "temperature": 0,
        "text": " hey, use this much as the validation data.",
        "tokens": [
          51244,
          4177,
          11,
          764,
          341,
          709,
          382,
          264,
          24071,
          1412,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 618.1,
        "id": 218,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 615.98,
        "temperature": 0,
        "text": " So let's go back over here.",
        "tokens": [
          51394,
          407,
          718,
          311,
          352,
          646,
          670,
          510,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 620.82,
        "id": 219,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 618.1,
        "temperature": 0,
        "text": " Let's go back to the documentation,",
        "tokens": [
          51500,
          961,
          311,
          352,
          646,
          281,
          264,
          14333,
          11,
          51636
        ]
      },
      {
        "avg_logprob": -0.22873745408169058,
        "compression_ratio": 1.8174603174603174,
        "end": 623.78,
        "id": 220,
        "no_speech_prob": 0.000010616127838147804,
        "seek": 59538,
        "start": 621.7,
        "temperature": 0,
        "text": " and we can see here, now I could specify",
        "tokens": [
          51680,
          293,
          321,
          393,
          536,
          510,
          11,
          586,
          286,
          727,
          16500,
          51784
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 627.62,
        "id": 221,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 623.8199999999999,
        "temperature": 0,
        "text": " validation data, or I could just specify validation split,",
        "tokens": [
          50366,
          24071,
          1412,
          11,
          420,
          286,
          727,
          445,
          16500,
          24071,
          7472,
          11,
          50556
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 629.64,
        "id": 222,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 627.62,
        "temperature": 0,
        "text": " which is a float between zero and one.",
        "tokens": [
          50556,
          597,
          307,
          257,
          15706,
          1296,
          4018,
          293,
          472,
          13,
          50657
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 631.42,
        "id": 223,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 629.64,
        "temperature": 0,
        "text": " It's the fraction of the training data",
        "tokens": [
          50657,
          467,
          311,
          264,
          14135,
          295,
          264,
          3097,
          1412,
          50746
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 633.36,
        "id": 224,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 631.42,
        "temperature": 0,
        "text": " to be used as the validation data.",
        "tokens": [
          50746,
          281,
          312,
          1143,
          382,
          264,
          24071,
          1412,
          13,
          50843
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 636.54,
        "id": 225,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 633.36,
        "temperature": 0,
        "text": " So if I come back here, and I just add an option,",
        "tokens": [
          50843,
          407,
          498,
          286,
          808,
          646,
          510,
          11,
          293,
          286,
          445,
          909,
          364,
          3614,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 639.18,
        "id": 226,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 636.54,
        "temperature": 0,
        "text": " validation data, and I say 0.1,",
        "tokens": [
          51002,
          24071,
          1412,
          11,
          293,
          286,
          584,
          1958,
          13,
          16,
          11,
          51134
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 643.5799999999999,
        "id": 227,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 639.18,
        "temperature": 0,
        "text": " I want to use 10% of my training data",
        "tokens": [
          51134,
          286,
          528,
          281,
          764,
          1266,
          4,
          295,
          452,
          3097,
          1412,
          51354
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 644.9,
        "id": 228,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 643.5799999999999,
        "temperature": 0,
        "text": " as the validation data.",
        "tokens": [
          51354,
          382,
          264,
          24071,
          1412,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 647.8399999999999,
        "id": 229,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 644.9,
        "temperature": 0,
        "text": " That's what's going to be used to calculate the loss,",
        "tokens": [
          51420,
          663,
          311,
          437,
          311,
          516,
          281,
          312,
          1143,
          281,
          8873,
          264,
          4470,
          11,
          51567
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 649.42,
        "id": 230,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 647.8399999999999,
        "temperature": 0,
        "text": " but it's not part of the training data.",
        "tokens": [
          51567,
          457,
          309,
          311,
          406,
          644,
          295,
          264,
          3097,
          1412,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.21967290538225986,
        "compression_ratio": 1.8559322033898304,
        "end": 651.1,
        "id": 231,
        "no_speech_prob": 0.000007183260549936676,
        "seek": 62378,
        "start": 649.42,
        "temperature": 0,
        "text": " Now there might be an issue.",
        "tokens": [
          51646,
          823,
          456,
          1062,
          312,
          364,
          2734,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 653.78,
        "id": 232,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 651.1,
        "temperature": 0,
        "text": " I also want to make sure I have shuffle on.",
        "tokens": [
          50364,
          286,
          611,
          528,
          281,
          652,
          988,
          286,
          362,
          39426,
          322,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 658.9,
        "id": 233,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 654.66,
        "temperature": 0,
        "text": " Shuffle is a parameter that shuffles the training data",
        "tokens": [
          50542,
          1160,
          21665,
          307,
          257,
          13075,
          300,
          402,
          1245,
          904,
          264,
          3097,
          1412,
          50754
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 661.94,
        "id": 234,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 658.9,
        "temperature": 0,
        "text": " at each epoch, because you don't always want to train",
        "tokens": [
          50754,
          412,
          1184,
          30992,
          339,
          11,
          570,
          291,
          500,
          380,
          1009,
          528,
          281,
          3847,
          50906
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 663.48,
        "id": 235,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 661.94,
        "temperature": 0,
        "text": " with the data in the same order",
        "tokens": [
          50906,
          365,
          264,
          1412,
          294,
          264,
          912,
          1668,
          50983
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 665.0600000000001,
        "id": 236,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 663.48,
        "temperature": 0,
        "text": " as you're tweaking all the weights and stuff,",
        "tokens": [
          50983,
          382,
          291,
          434,
          6986,
          2456,
          439,
          264,
          17443,
          293,
          1507,
          11,
          51062
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 666.14,
        "id": 237,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 665.0600000000001,
        "temperature": 0,
        "text": " as it's doing its training.",
        "tokens": [
          51062,
          382,
          309,
          311,
          884,
          1080,
          3097,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 668.28,
        "id": 238,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 666.14,
        "temperature": 0,
        "text": " If it's in a different order, it's going to help it out.",
        "tokens": [
          51116,
          759,
          309,
          311,
          294,
          257,
          819,
          1668,
          11,
          309,
          311,
          516,
          281,
          854,
          309,
          484,
          13,
          51223
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 672.96,
        "id": 239,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 668.28,
        "temperature": 0,
        "text": " But the validation data, I think, I looked at this before,",
        "tokens": [
          51223,
          583,
          264,
          24071,
          1412,
          11,
          286,
          519,
          11,
          286,
          2956,
          412,
          341,
          949,
          11,
          51457
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 676.86,
        "id": 240,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 672.96,
        "temperature": 0,
        "text": " is selected before shuffling.",
        "tokens": [
          51457,
          307,
          8209,
          949,
          402,
          1245,
          1688,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.2122542654821115,
        "compression_ratio": 1.7372549019607844,
        "end": 678.6600000000001,
        "id": 241,
        "no_speech_prob": 6.375545922310266e-7,
        "seek": 65110,
        "start": 676.86,
        "temperature": 0,
        "text": " So it's selected from the last sample.",
        "tokens": [
          51652,
          407,
          309,
          311,
          8209,
          490,
          264,
          1036,
          6889,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 680.54,
        "id": 242,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 678.66,
        "temperature": 0,
        "text": " So I might have a slight issue,",
        "tokens": [
          50364,
          407,
          286,
          1062,
          362,
          257,
          4036,
          2734,
          11,
          50458
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 683.24,
        "id": 243,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 680.54,
        "temperature": 0,
        "text": " where if for some reason the order my data is in,",
        "tokens": [
          50458,
          689,
          498,
          337,
          512,
          1778,
          264,
          1668,
          452,
          1412,
          307,
          294,
          11,
          50593
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 684.86,
        "id": 244,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 683.24,
        "temperature": 0,
        "text": " there's something weird about the end of it",
        "tokens": [
          50593,
          456,
          311,
          746,
          3657,
          466,
          264,
          917,
          295,
          309,
          50674
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 686.28,
        "id": 245,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 684.86,
        "temperature": 0,
        "text": " is all one label or something,",
        "tokens": [
          50674,
          307,
          439,
          472,
          7645,
          420,
          746,
          11,
          50745
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 688.14,
        "id": 246,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 686.28,
        "temperature": 0,
        "text": " I probably want to shuffle it myself manually.",
        "tokens": [
          50745,
          286,
          1391,
          528,
          281,
          39426,
          309,
          2059,
          16945,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 689.54,
        "id": 247,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 688.14,
        "temperature": 0,
        "text": " But let's not worry about that right now.",
        "tokens": [
          50838,
          583,
          718,
          311,
          406,
          3292,
          466,
          300,
          558,
          586,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 692.5,
        "id": 248,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 689.54,
        "temperature": 0,
        "text": " But that's something definitely to be conscious of.",
        "tokens": [
          50908,
          583,
          300,
          311,
          746,
          2138,
          281,
          312,
          6648,
          295,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 694.78,
        "id": 249,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 692.5,
        "temperature": 0,
        "text": " Boy, this is so much to think about.",
        "tokens": [
          51056,
          9486,
          11,
          341,
          307,
          370,
          709,
          281,
          519,
          466,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 695.8199999999999,
        "id": 250,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 694.78,
        "temperature": 0,
        "text": " All right, now.",
        "tokens": [
          51170,
          1057,
          558,
          11,
          586,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 697.4,
        "id": 251,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 695.8199999999999,
        "temperature": 0,
        "text": " So now that we've added shuffle,",
        "tokens": [
          51222,
          407,
          586,
          300,
          321,
          600,
          3869,
          39426,
          11,
          51301
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 702.38,
        "id": 252,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 697.4,
        "temperature": 0,
        "text": " and we've added 10% as validation data,",
        "tokens": [
          51301,
          293,
          321,
          600,
          3869,
          1266,
          4,
          382,
          24071,
          1412,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.23970954836779879,
        "compression_ratio": 1.7045454545454546,
        "end": 704.74,
        "id": 253,
        "no_speech_prob": 5.896416155337647e-7,
        "seek": 67866,
        "start": 702.38,
        "temperature": 0,
        "text": " let me now run this again.",
        "tokens": [
          51550,
          718,
          385,
          586,
          1190,
          341,
          797,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 710.0600000000001,
        "id": 254,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 705.74,
        "temperature": 0,
        "text": " Okay, so it finished, it trained.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          309,
          4335,
          11,
          309,
          8895,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 711.9,
        "id": 255,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 710.0600000000001,
        "temperature": 0,
        "text": " Now with the validation split.",
        "tokens": [
          50630,
          823,
          365,
          264,
          24071,
          7472,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 714.58,
        "id": 256,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 711.9,
        "temperature": 0,
        "text": " And oh, breaking news, breaking news.",
        "tokens": [
          50722,
          400,
          1954,
          11,
          7697,
          2583,
          11,
          7697,
          2583,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 716.3,
        "id": 257,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 714.58,
        "temperature": 0,
        "text": " Getting information from the chat",
        "tokens": [
          50856,
          13674,
          1589,
          490,
          264,
          5081,
          50942
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 717.98,
        "id": 258,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 716.3,
        "temperature": 0,
        "text": " that I wrote validation data here.",
        "tokens": [
          50942,
          300,
          286,
          4114,
          24071,
          1412,
          510,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 719.44,
        "id": 259,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 717.98,
        "temperature": 0,
        "text": " Interesting that it gave me an error.",
        "tokens": [
          51026,
          14711,
          300,
          309,
          2729,
          385,
          364,
          6713,
          13,
          51099
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 722.02,
        "id": 260,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 719.44,
        "temperature": 0,
        "text": " So if I wanted to give it specific validation data,",
        "tokens": [
          51099,
          407,
          498,
          286,
          1415,
          281,
          976,
          309,
          2685,
          24071,
          1412,
          11,
          51228
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 723,
        "id": 261,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 722.02,
        "temperature": 0,
        "text": " that's what I would use.",
        "tokens": [
          51228,
          300,
          311,
          437,
          286,
          576,
          764,
          13,
          51277
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 724.82,
        "id": 262,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 723,
        "temperature": 0,
        "text": " But I want to use validation split.",
        "tokens": [
          51277,
          583,
          286,
          528,
          281,
          764,
          24071,
          7472,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 726.98,
        "id": 263,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 724.82,
        "temperature": 0,
        "text": " Thank you to the chat for correcting me there.",
        "tokens": [
          51368,
          1044,
          291,
          281,
          264,
          5081,
          337,
          47032,
          385,
          456,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 728.72,
        "id": 264,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 726.98,
        "temperature": 0,
        "text": " Let's try running this again.",
        "tokens": [
          51476,
          961,
          311,
          853,
          2614,
          341,
          797,
          13,
          51563
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 730.62,
        "id": 265,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 728.72,
        "temperature": 0,
        "text": " Let's give it just more epochs,",
        "tokens": [
          51563,
          961,
          311,
          976,
          309,
          445,
          544,
          30992,
          28346,
          11,
          51658
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 731.58,
        "id": 266,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 730.62,
        "temperature": 0,
        "text": " a little bit more time to wait.",
        "tokens": [
          51658,
          257,
          707,
          857,
          544,
          565,
          281,
          1699,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2461792851837588,
        "compression_ratio": 1.789090909090909,
        "end": 733.14,
        "id": 267,
        "no_speech_prob": 0.0000013925439361628378,
        "seek": 70474,
        "start": 731.58,
        "temperature": 0,
        "text": " Let's give it 50, all right?",
        "tokens": [
          51706,
          961,
          311,
          976,
          309,
          2625,
          11,
          439,
          558,
          30,
          51784
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 739.74,
        "id": 268,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 734.74,
        "temperature": 0.2,
        "text": " Okay, it's back.",
        "tokens": [
          50364,
          1033,
          11,
          309,
          311,
          646,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 744.0600000000001,
        "id": 269,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 740.14,
        "temperature": 0.2,
        "text": " Let's take a look at our loss function over 50 epochs.",
        "tokens": [
          50634,
          961,
          311,
          747,
          257,
          574,
          412,
          527,
          4470,
          2445,
          670,
          2625,
          30992,
          28346,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 746.82,
        "id": 270,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 744.0600000000001,
        "temperature": 0.2,
        "text": " And we can see it's going way down to 0.75.",
        "tokens": [
          50830,
          400,
          321,
          393,
          536,
          309,
          311,
          516,
          636,
          760,
          281,
          1958,
          13,
          11901,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 747.98,
        "id": 271,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 746.82,
        "temperature": 0.2,
        "text": " You can see it's kind of stopped.",
        "tokens": [
          50968,
          509,
          393,
          536,
          309,
          311,
          733,
          295,
          5936,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 750.86,
        "id": 272,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 747.98,
        "temperature": 0.2,
        "text": " Actually, we kind of accidentally might have,",
        "tokens": [
          51026,
          5135,
          11,
          321,
          733,
          295,
          15715,
          1062,
          362,
          11,
          51170
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 752.54,
        "id": 273,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 750.86,
        "temperature": 0.2,
        "text": " you can see how it kind of goes up now.",
        "tokens": [
          51170,
          291,
          393,
          536,
          577,
          309,
          733,
          295,
          1709,
          493,
          586,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 754.78,
        "id": 274,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 752.54,
        "temperature": 0.2,
        "text": " We can see like it's not able to get any better.",
        "tokens": [
          51254,
          492,
          393,
          536,
          411,
          309,
          311,
          406,
          1075,
          281,
          483,
          604,
          1101,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 756.82,
        "id": 275,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 754.78,
        "temperature": 0.2,
        "text": " So we might not even need 50 epochs.",
        "tokens": [
          51366,
          407,
          321,
          1062,
          406,
          754,
          643,
          2625,
          30992,
          28346,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 758.82,
        "id": 276,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 756.82,
        "temperature": 0.2,
        "text": " But we might want to tune various parameters to see.",
        "tokens": [
          51468,
          583,
          321,
          1062,
          528,
          281,
          10864,
          3683,
          9834,
          281,
          536,
          13,
          51568
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 761.0600000000001,
        "id": 277,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 758.82,
        "temperature": 0.2,
        "text": " But anyway, I'm not going to worry about all that right now.",
        "tokens": [
          51568,
          583,
          4033,
          11,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          439,
          300,
          558,
          586,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.2520130183421025,
        "compression_ratio": 1.6950354609929077,
        "end": 764.28,
        "id": 278,
        "no_speech_prob": 0.000035912893508793786,
        "seek": 73474,
        "start": 761.0600000000001,
        "temperature": 0.2,
        "text": " The point is, I have now trained the model",
        "tokens": [
          51680,
          314,
          675,
          935,
          307,
          11,
          286,
          362,
          586,
          8895,
          264,
          2316,
          51841
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 767.8399999999999,
        "id": 279,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 764.8199999999999,
        "temperature": 0,
        "text": " using model.fit, shuffling the data",
        "tokens": [
          50391,
          1228,
          2316,
          13,
          6845,
          11,
          402,
          1245,
          1688,
          264,
          1412,
          50542
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 770.76,
        "id": 280,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 767.8399999999999,
        "temperature": 0,
        "text": " with a certain validation, saving 10% for validation.",
        "tokens": [
          50542,
          365,
          257,
          1629,
          24071,
          11,
          6816,
          1266,
          4,
          337,
          24071,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 773.24,
        "id": 281,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 770.76,
        "temperature": 0,
        "text": " I'm not doing proper testing data yet.",
        "tokens": [
          50688,
          286,
          478,
          406,
          884,
          2296,
          4997,
          1412,
          1939,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 774.48,
        "id": 282,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 773.24,
        "temperature": 0,
        "text": " That would come later.",
        "tokens": [
          50812,
          663,
          576,
          808,
          1780,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 777.16,
        "id": 283,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 774.48,
        "temperature": 0,
        "text": " And 50 epochs, okay?",
        "tokens": [
          50874,
          400,
          2625,
          30992,
          28346,
          11,
          1392,
          30,
          51008
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 781.1999999999999,
        "id": 284,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 777.16,
        "temperature": 0,
        "text": " So in the next video, what I want to do",
        "tokens": [
          51008,
          407,
          294,
          264,
          958,
          960,
          11,
          437,
          286,
          528,
          281,
          360,
          51210
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 784.4,
        "id": 285,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 781.1999999999999,
        "temperature": 0,
        "text": " is make it so that I can run an animation,",
        "tokens": [
          51210,
          307,
          652,
          309,
          370,
          300,
          286,
          393,
          1190,
          364,
          9603,
          11,
          51370
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 787,
        "id": 286,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 784.4,
        "temperature": 0,
        "text": " I can graph the loss function over time,",
        "tokens": [
          51370,
          286,
          393,
          4295,
          264,
          4470,
          2445,
          670,
          565,
          11,
          51500
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 789.24,
        "id": 287,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 787,
        "temperature": 0,
        "text": " all that sort of stuff, and not have it kind of like",
        "tokens": [
          51500,
          439,
          300,
          1333,
          295,
          1507,
          11,
          293,
          406,
          362,
          309,
          733,
          295,
          411,
          51612
        ]
      },
      {
        "avg_logprob": -0.22195538903912929,
        "compression_ratio": 1.564516129032258,
        "end": 792.64,
        "id": 288,
        "no_speech_prob": 0.000004356875706434948,
        "seek": 76428,
        "start": 789.24,
        "temperature": 0,
        "text": " blocking the way it's doing right now,",
        "tokens": [
          51612,
          17776,
          264,
          636,
          309,
          311,
          884,
          558,
          586,
          11,
          51782
        ]
      },
      {
        "avg_logprob": -0.37908299763997394,
        "compression_ratio": 1.391304347826087,
        "end": 794.1999999999999,
        "id": 289,
        "no_speech_prob": 0.000010953081982734147,
        "seek": 79264,
        "start": 792.64,
        "temperature": 0.6000000000000001,
        "text": " the animation thread.",
        "tokens": [
          50364,
          264,
          9603,
          7207,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.37908299763997394,
        "compression_ratio": 1.391304347826087,
        "end": 797.6,
        "id": 290,
        "no_speech_prob": 0.000010953081982734147,
        "seek": 79264,
        "start": 795.08,
        "temperature": 0.6000000000000001,
        "text": " And then of course I also need to allow the user",
        "tokens": [
          50486,
          400,
          550,
          295,
          1164,
          286,
          611,
          643,
          281,
          2089,
          264,
          4195,
          50612
        ]
      },
      {
        "avg_logprob": -0.37908299763997394,
        "compression_ratio": 1.391304347826087,
        "end": 799.48,
        "id": 291,
        "no_speech_prob": 0.000010953081982734147,
        "seek": 79264,
        "start": 797.6,
        "temperature": 0.6000000000000001,
        "text": " to specify a color and get a label for that.",
        "tokens": [
          50612,
          281,
          16500,
          257,
          2017,
          293,
          483,
          257,
          7645,
          337,
          300,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.37908299763997394,
        "compression_ratio": 1.391304347826087,
        "end": 801.3199999999999,
        "id": 292,
        "no_speech_prob": 0.000010953081982734147,
        "seek": 79264,
        "start": 799.48,
        "temperature": 0.6000000000000001,
        "text": " So those are the next two steps I need to do.",
        "tokens": [
          50706,
          407,
          729,
          366,
          264,
          958,
          732,
          4439,
          286,
          643,
          281,
          360,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.37908299763997394,
        "compression_ratio": 1.391304347826087,
        "end": 802.8,
        "id": 293,
        "no_speech_prob": 0.000010953081982734147,
        "seek": 79264,
        "start": 801.3199999999999,
        "temperature": 0.6000000000000001,
        "text": " See you in those videos!",
        "tokens": [
          50798,
          3008,
          291,
          294,
          729,
          2145,
          0,
          50872
        ]
      },
      {
        "avg_logprob": -0.37908299763997394,
        "compression_ratio": 1.391304347826087,
        "end": 803.64,
        "id": 294,
        "no_speech_prob": 0.000010953081982734147,
        "seek": 79264,
        "start": 802.8,
        "temperature": 0.6000000000000001,
        "text": " Ding!",
        "tokens": [
          50872,
          20558,
          0,
          50914
        ]
      }
    ],
    "transcription": " It's time, it's time to fit our model. Here we go, so, so far, you know, hopefully you've watched all the previous parts of this series, if you haven't, that's fine too, but what I have so far is I prepared my data set, loaded it from a JSON file, I've turned everything into tensors, and then I created a model, tf, using TensorFlow.js, a tf.sequential.model, which is designed to receive RGB inputs and output a probability distribution for color labels. And, you know, again, this is somewhat of a trivial scenario but I'm classifying data, simple data with just three values all between zero, one, and nine possible categories or labels. Okay, so, that's what I've done so far, so now that I have this, this is actually like, in some ways this video's going to be over in like two seconds, not really, all I need to do is call model.fit. So model.fit, now what do I need to pass to model.fit? Well, the idea of model.fit is that I'm saying, hey, here's the training data, here are all the inputs and their associated target outputs, which I have called x's and y's. Now, I think I'm going to get an error right now. Let me just actually run this, and I'm going to, whoops, let me run this and see if I get the error that I'm expecting, yeah, so look at this, oh, okay, so a couple things. Ah, welcome to your life, doing machine learning, shape mismatching, I didn't even expect this error, so I have to think about this one. Error when checking input, expected dense input to have shape three, but got array with shape 5,643.3, so I guess, right, I'm sending in not just three inputs, the shape of my inputs is many, so I think if I just do, ah-ha, so I made a mistake and I used input dimensions, where what I really meant was input shape. All right, let's go look at the documentation and see what it says there, and I actually, I've got it pulled up already. Okay, so you can see what I specified was input dimensions. If specified defines input shape as bracket input dimensions, oh, so actually, I don't even need those array brackets there, and that should fix it, there we go, but if I wanted to use those array brackets because I'm sending in many data points, I could actually just specify the input shape directly, and this would then have the array brackets around it, so it's a subtle distinction, I think because only input dimensions is documented, let's use that one and let's put a three here. Okay, so now we've got the, I wonder why that didn't, oh, because I didn't call fit before. Okay, so now I'm fitting the model. Hmm, I don't see an error, I expected an error. Let's, so what happens when I fit the model? Well, it returns a promise, model.fit returns a promise. If you don't know what a promise is, guess what? I have a whole set of videos about what a promise is, and I'm also going to be using eventually await and async, which I also have videos about, but right now I can just write the dot then, a prompt, fit returns a promise, which I can then call a function called then to where the results will be passed in, and I'm just going to say, and I'm going to use this arrow syntax, this ES6 arrow syntax, console.log results, and eventually I might want to do more with this, so I'm actually going to make it a full function, so this is what I'm saying is, once you fit the model, then log the results. Let's see what happens. Waiting, waiting, ah, okay, great, look at this. History, loss, and there's my loss. So it fit that model, it did one epoch, and gave me a loss, great. So, done, trained the model, here's the thing. What I want to do ultimately, so this is actually in a way done, what I want to do is, first of all, I want to train the model for more than just one epoch, so one thing that I need to do here is pass in some options. So I'm going to create a variable called options, and one thing I can specify is epochs, I'm going to say do it for 10, and then I'm going to say, and let's actually, let's just say two right now, because it's going to take a while. So the third argument to model.fit is options, and if I go into TensorFlow.js, and I look for a model.fit, oops, I was right there already, we can see now these are the various options, and I'm going to be using a bunch of these, but epochs is one of them, the number of times to iterate over the training data. So, let's rub this now, and you know what I'm going to do? I don't think we need all of this printing stuff, so I'm going to get rid of some of the earlier printing things, because I don't need to look at all of that so much. So let's run this, whoops, options is not defined, I spelled that wrong. I guess I still have 44 and 45 console logging stuff, which I don't need. I didn't get an error that I expected to get, which is kind of interesting. And, oh, you know why? One thing that I want to do is I want to update, you know, at the time of this recording, I think the most recent version of TensorFlow.js is 0.11.7, and when I was previously recording, I was using.4, and I think some things have changed. All right, so let's let this run. It's running for two epochs right now, it finished, and I can look at the history, and I can see both lost. So we can see, the loss went down for the second epoch, that's great! Now, let's run this over 10 epochs, and let's run this, and let's just console log results.loss, by the way, or what was it? Is it results.history.loss? Might be that. Now let's look at what it is. The history, history.loss, okay? So let's do this, whoops, I don't need that. Let's go back here, hit refresh, and waiting. I'm going to edit out this waiting part. ♪ Upbeat music ♪ Okay, great, so look at this, over 10 epochs, the loss is going down, this is good, this is what we want to see. Now here's the thing, what's it using to calculate that loss, huh? Oh, there's so much to discuss, I got to get myself organized, my thoughts here. I want to, I think maybe, maybe I've done this video, I'm really breaking this into lots of small parts, and really what I've done now is call model.fit with one single option. The two things I need to do that are next. One is, I need to figure out what's it getting that loss, like what data is it using to calculate that loss? Is it the training data? Didn't I talk about testing data and validation data? Should I be thinking about that at some point? So I've got to deal with that. Number two is, I would like to, the point of this is I'm in a p5 sketch, and I can say function draw background zero, and I can run this, but look at this, it just says loading up there all the while while it's training. I've locked, I don't have any ability to run an animation. I want, once it finishes, I see the canvas. I want the canvas to animate while it's training, and I want to see the loss over time. I want to have that reported back to me. So those are the two things that I need to do. I think I can tackle the training, the testing and validation data thing right now, because let's do that in this video, and I'm going to add the animation stuff in the next video. So first of all, okay, so, I have my data set. My data set has, I think it was 5,643 elements, data points in it. I said at the very beginning of this series when I was preparing the data set, that a typical thing to do is divide the data, and again, this is really small. For proper machine learning model, robust, I probably want to have a much larger data set, but this will actually kind of work just fine, as we'll see. I want to use probably the 80-20 rule, saying that 80% is actually the training data. So I want to just only use, really, why does it, it's because the keyboard is next to this. Just go away, sound. I want to, I want these Xs and Ys to only actually be 80% of that original data. So I'm not doing that. Maybe I'll add that in at another point. That could be an exercise for you as the viewer, to take out 20%, or maybe because my data set's so small, just take out 10% of the data. So that's what would be used to test the model after I finish training it, but while I'm training it, while I'm actually training it and figuring out, well, how many input nodes do I want? What learning rate do I want? What are these hyperparameters? What are the parameters of this system that I want to try different things? How many epochs do I want to train the model for? What batch size do I want to use? All these things are known as hyperparameters, the parameters during the training process. If I want to be playing around with those, I need a separate data set to compute a loss that's not part of the training data, but also is not part of my testing data that I'm going to use when I'm completely done training. That's what the validation data is. The validation data is basically a test data set, but it's not your test data set when you're done and you're ready to publish your model. It's your test data set while you're doing all the training. And TensorFlow.js has a configuration option for model.fit that just says, hey, use this much as the validation data. So let's go back over here. Let's go back to the documentation, and we can see here, now I could specify validation data, or I could just specify validation split, which is a float between zero and one. It's the fraction of the training data to be used as the validation data. So if I come back here, and I just add an option, validation data, and I say 0.1, I want to use 10% of my training data as the validation data. That's what's going to be used to calculate the loss, but it's not part of the training data. Now there might be an issue. I also want to make sure I have shuffle on. Shuffle is a parameter that shuffles the training data at each epoch, because you don't always want to train with the data in the same order as you're tweaking all the weights and stuff, as it's doing its training. If it's in a different order, it's going to help it out. But the validation data, I think, I looked at this before, is selected before shuffling. So it's selected from the last sample. So I might have a slight issue, where if for some reason the order my data is in, there's something weird about the end of it is all one label or something, I probably want to shuffle it myself manually. But let's not worry about that right now. But that's something definitely to be conscious of. Boy, this is so much to think about. All right, now. So now that we've added shuffle, and we've added 10% as validation data, let me now run this again. Okay, so it finished, it trained. Now with the validation split. And oh, breaking news, breaking news. Getting information from the chat that I wrote validation data here. Interesting that it gave me an error. So if I wanted to give it specific validation data, that's what I would use. But I want to use validation split. Thank you to the chat for correcting me there. Let's try running this again. Let's give it just more epochs, a little bit more time to wait. Let's give it 50, all right? Okay, it's back. Let's take a look at our loss function over 50 epochs. And we can see it's going way down to 0.75. You can see it's kind of stopped. Actually, we kind of accidentally might have, you can see how it kind of goes up now. We can see like it's not able to get any better. So we might not even need 50 epochs. But we might want to tune various parameters to see. But anyway, I'm not going to worry about all that right now. The point is, I have now trained the model using model.fit, shuffling the data with a certain validation, saving 10% for validation. I'm not doing proper testing data yet. That would come later. And 50 epochs, okay? So in the next video, what I want to do is make it so that I can run an animation, I can graph the loss function over time, all that sort of stuff, and not have it kind of like blocking the way it's doing right now, the animation thread. And then of course I also need to allow the user to specify a color and get a label for that. So those are the next two steps I need to do. See you in those videos! Ding!",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:34.451385Z",
  "started_at": "2023-09-26T21:15:24.173894Z",
  "completed_at": "2023-09-26T21:20:36.96604Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=SyEZ5Yo2ec8",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 312.792146
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/wi24y5bb4fhb5ubkj2besigf2a/cancel",
    "get": "https://api.replicate.com/v1/predictions/wi24y5bb4fhb5ubkj2besigf2a"
  }
}