{
  "id": "tdcxtmrbl5ulpzuhh57wipgifm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/KtPpoMThKUs.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/226466 [00:00<?, ?frames/s]\n  1%|▏         | 2990/226466 [00:09<11:14, 331.50frames/s]\n  3%|▎         | 5970/226466 [00:18<11:19, 324.39frames/s]\n  4%|▍         | 8890/226466 [00:26<10:32, 344.25frames/s]\n  5%|▌         | 11884/226466 [00:32<09:28, 377.54frames/s]\n  6%|▋         | 14696/226466 [00:40<09:26, 373.62frames/s]\n  8%|▊         | 17320/226466 [00:46<08:56, 390.11frames/s]\n  9%|▉         | 19980/226466 [00:52<08:14, 417.78frames/s]\n 10%|█         | 22978/226466 [00:57<07:32, 450.07frames/s]\n 11%|█▏        | 25974/226466 [01:03<07:10, 465.56frames/s]\n 13%|█▎        | 28870/226466 [01:13<08:14, 399.57frames/s]\n 14%|█▍        | 31726/226466 [01:21<08:30, 381.53frames/s]\n 15%|█▌        | 34502/226466 [01:25<07:25, 431.00frames/s]\n 16%|█▋        | 36906/226466 [01:31<07:15, 435.60frames/s]\n 18%|█▊        | 39706/226466 [01:38<07:14, 429.36frames/s]\n 19%|█▉        | 42512/226466 [01:45<07:32, 406.56frames/s]\n 20%|█▉        | 45228/226466 [01:51<07:15, 415.73frames/s]\n 21%|██        | 48036/226466 [02:00<07:49, 380.04frames/s]\n 22%|██▏       | 50768/226466 [02:07<07:29, 390.81frames/s]\n 24%|██▎       | 53740/226466 [02:16<07:50, 366.91frames/s]\n 25%|██▌       | 56728/226466 [02:25<08:01, 352.22frames/s]\n 26%|██▋       | 59548/226466 [02:34<08:07, 342.29frames/s]\n 27%|██▋       | 62112/226466 [02:42<08:12, 333.39frames/s]\n 29%|██▊       | 64972/226466 [02:48<07:14, 371.45frames/s]\n 30%|██▉       | 67722/226466 [02:56<07:21, 359.41frames/s]\n 31%|███       | 70602/226466 [03:03<06:51, 379.10frames/s]\n 33%|███▎      | 73602/226466 [03:09<06:17, 404.84frames/s]\n 34%|███▍      | 76602/226466 [03:15<05:52, 424.55frames/s]\n 35%|███▌      | 79418/226466 [03:23<06:02, 405.77frames/s]\n 36%|███▋      | 82350/226466 [03:32<06:20, 378.71frames/s]\n 38%|███▊      | 84974/226466 [03:40<06:30, 362.78frames/s]\n 39%|███▊      | 87650/226466 [03:48<06:38, 348.72frames/s]\n 40%|████      | 90650/226466 [03:53<05:33, 407.72frames/s]\n 41%|████      | 93342/226466 [03:58<05:05, 436.44frames/s]\n 42%|████▏     | 96194/226466 [04:05<05:06, 424.50frames/s]\n 44%|████▍     | 99130/226466 [04:12<04:56, 428.81frames/s]\n 45%|████▍     | 101770/226466 [04:19<05:07, 406.14frames/s]\n 46%|████▌     | 104638/226466 [04:27<05:04, 400.09frames/s]\n 48%|████▊     | 107638/226466 [04:34<04:53, 405.00frames/s]\n 49%|████▊     | 110390/226466 [04:43<05:08, 376.45frames/s]\n 50%|█████     | 113390/226466 [04:51<05:01, 375.32frames/s]\n 51%|█████▏    | 116342/226466 [04:59<04:54, 373.96frames/s]\n 53%|█████▎    | 119146/226466 [05:07<04:57, 360.24frames/s]\n 54%|█████▍    | 121886/226466 [05:14<04:37, 377.30frames/s]\n 55%|█████▌    | 124846/226466 [05:23<04:51, 349.11frames/s]\n 56%|█████▋    | 127674/226466 [05:29<04:20, 378.96frames/s]\n 58%|█████▊    | 130630/226466 [05:38<04:21, 366.00frames/s]\n 59%|█████▉    | 133362/226466 [05:44<03:58, 389.92frames/s]\n 60%|██████    | 136294/226466 [05:52<03:57, 378.87frames/s]\n 60%|██████    | 136294/226466 [06:02<03:57, 378.87frames/s]\n 61%|██████▏   | 139218/226466 [06:03<04:16, 340.09frames/s]\n 63%|██████▎   | 142006/226466 [06:10<04:03, 347.14frames/s]\n 64%|██████▍   | 144722/226466 [06:18<03:55, 347.69frames/s]\n 65%|██████▌   | 147486/226466 [06:25<03:37, 362.70frames/s]\n 66%|██████▋   | 150442/226466 [06:32<03:20, 379.39frames/s]\n 68%|██████▊   | 153170/226466 [06:39<03:12, 379.98frames/s]\n 69%|██████▉   | 155898/226466 [06:46<03:02, 386.15frames/s]\n 70%|███████   | 158570/226466 [06:52<02:47, 406.19frames/s]\n 71%|███████▏  | 161482/226466 [07:01<02:54, 373.36frames/s]\n 72%|███████▏  | 164118/226466 [07:09<02:56, 352.95frames/s]\n 74%|███████▍  | 167042/226466 [07:16<02:35, 383.36frames/s]\n 75%|███████▌  | 169858/226466 [07:23<02:25, 389.47frames/s]\n 76%|███████▋  | 172690/226466 [07:32<02:31, 355.19frames/s]\n 77%|███████▋  | 174974/226466 [07:39<02:27, 349.10frames/s]\n 77%|███████▋  | 174974/226466 [07:52<02:27, 349.10frames/s]\n 78%|███████▊  | 177040/226466 [07:53<03:08, 262.90frames/s]\n 78%|███████▊  | 177040/226466 [08:12<03:08, 262.90frames/s]\n 79%|███████▉  | 180028/226466 [09:14<09:07, 84.79frames/s] \n 81%|████████  | 182892/226466 [09:24<06:37, 109.50frames/s]\n 82%|████████▏ | 185828/226466 [09:30<04:37, 146.37frames/s]\n 83%|████████▎ | 188380/226466 [09:35<03:28, 182.58frames/s]\n 84%|████████▍ | 191244/226466 [09:42<02:41, 218.45frames/s]\n 86%|████████▌ | 194096/226466 [09:50<02:10, 248.75frames/s]\n 87%|████████▋ | 196896/226466 [09:58<01:49, 269.90frames/s]\n 88%|████████▊ | 199896/226466 [10:06<01:29, 297.72frames/s]\n 90%|████████▉ | 202744/226466 [10:12<01:10, 337.51frames/s]\n 91%|█████████ | 205562/226466 [10:20<01:00, 344.07frames/s]\n 92%|█████████▏| 208386/226466 [10:29<00:54, 330.50frames/s]\n 93%|█████████▎| 211040/226466 [10:35<00:42, 364.10frames/s]\n 94%|█████████▍| 213756/226466 [10:41<00:32, 387.50frames/s]\n 96%|█████████▌| 216724/226466 [10:47<00:23, 409.06frames/s]\n 97%|█████████▋| 219660/226466 [10:54<00:16, 409.43frames/s]\n 98%|█████████▊| 222402/226466 [11:01<00:10, 399.56frames/s]\n 99%|█████████▉| 225114/226466 [11:10<00:03, 365.24frames/s]\n 99%|█████████▉| 225114/226466 [11:22<00:03, 365.24frames/s]\n100%|██████████| 226466/226466 [11:43<00:00, 156.33frames/s]\n100%|██████████| 226466/226466 [11:43<00:00, 322.01frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 3,
        "id": 0,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello and welcome to another coding challenge.",
        "tokens": [
          50364,
          2425,
          293,
          2928,
          281,
          1071,
          17720,
          3430,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 6.44,
        "id": 1,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 3,
        "temperature": 0,
        "text": " Now this coding challenge is number 99,",
        "tokens": [
          50514,
          823,
          341,
          17720,
          3430,
          307,
          1230,
          11803,
          11,
          50686
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 10.8,
        "id": 2,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 6.44,
        "temperature": 0,
        "text": " which means the next coding challenge is number 100.",
        "tokens": [
          50686,
          597,
          1355,
          264,
          958,
          17720,
          3430,
          307,
          1230,
          2319,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 11.92,
        "id": 3,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 10.8,
        "temperature": 0,
        "text": " And I have no idea what to do.",
        "tokens": [
          50904,
          400,
          286,
          362,
          572,
          1558,
          437,
          281,
          360,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 13.84,
        "id": 4,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 11.92,
        "temperature": 0,
        "text": " I feel this pressure to do something special.",
        "tokens": [
          50960,
          286,
          841,
          341,
          3321,
          281,
          360,
          746,
          2121,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 16.080000000000002,
        "id": 5,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 13.84,
        "temperature": 0,
        "text": " So please, in the comments, write your suggestions",
        "tokens": [
          51056,
          407,
          1767,
          11,
          294,
          264,
          3053,
          11,
          2464,
          428,
          13396,
          51168
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 18.16,
        "id": 6,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 16.080000000000002,
        "temperature": 0,
        "text": " for coding challenge number 100,",
        "tokens": [
          51168,
          337,
          17720,
          3430,
          1230,
          2319,
          11,
          51272
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 19.2,
        "id": 7,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 18.16,
        "temperature": 0,
        "text": " and maybe I'll think of something,",
        "tokens": [
          51272,
          293,
          1310,
          286,
          603,
          519,
          295,
          746,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 21.400000000000002,
        "id": 8,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 19.2,
        "temperature": 0,
        "text": " or you'll help me think of something.",
        "tokens": [
          51324,
          420,
          291,
          603,
          854,
          385,
          519,
          295,
          746,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 22.52,
        "id": 9,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 21.400000000000002,
        "temperature": 0,
        "text": " Okay, so what's happening now?",
        "tokens": [
          51434,
          1033,
          11,
          370,
          437,
          311,
          2737,
          586,
          30,
          51490
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 24.6,
        "id": 10,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 22.52,
        "temperature": 0,
        "text": " I am going to do a coding challenge",
        "tokens": [
          51490,
          286,
          669,
          516,
          281,
          360,
          257,
          17720,
          3430,
          51594
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 26.88,
        "id": 11,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 24.6,
        "temperature": 0,
        "text": " to make a neural network color predictor.",
        "tokens": [
          51594,
          281,
          652,
          257,
          18161,
          3209,
          2017,
          6069,
          284,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.23988205278423472,
        "compression_ratio": 1.7993197278911566,
        "end": 29.900000000000002,
        "id": 12,
        "no_speech_prob": 0.013016645796597004,
        "seek": 0,
        "start": 26.88,
        "temperature": 0,
        "text": " This is based off of a project made by Jabril.",
        "tokens": [
          51708,
          639,
          307,
          2361,
          766,
          295,
          257,
          1716,
          1027,
          538,
          40319,
          24216,
          13,
          51859
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 31.86,
        "id": 13,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 30.099999999999998,
        "temperature": 0,
        "text": " Check out his YouTube channel.",
        "tokens": [
          50374,
          6881,
          484,
          702,
          3088,
          2269,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 34.58,
        "id": 14,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 31.86,
        "temperature": 0,
        "text": " There's a link in this video's description.",
        "tokens": [
          50462,
          821,
          311,
          257,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 37.06,
        "id": 15,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 34.58,
        "temperature": 0,
        "text": " He has a video called Color Predictor Machine Learning Demo",
        "tokens": [
          50598,
          634,
          575,
          257,
          960,
          1219,
          10458,
          430,
          24945,
          284,
          22155,
          15205,
          4686,
          78,
          50722
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 38.14,
        "id": 16,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 37.06,
        "temperature": 0,
        "text": " that I'd encourage you to watch.",
        "tokens": [
          50722,
          300,
          286,
          1116,
          5373,
          291,
          281,
          1159,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 39.86,
        "id": 17,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 38.14,
        "temperature": 0,
        "text": " He also actually came on as a guest,",
        "tokens": [
          50776,
          634,
          611,
          767,
          1361,
          322,
          382,
          257,
          8341,
          11,
          50862
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 41.739999999999995,
        "id": 18,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 39.86,
        "temperature": 0,
        "text": " and I'll link to a video with Jabril",
        "tokens": [
          50862,
          293,
          286,
          603,
          2113,
          281,
          257,
          960,
          365,
          40319,
          24216,
          50956
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 43.78,
        "id": 19,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 41.739999999999995,
        "temperature": 0,
        "text": " where he talks through this color predictor.",
        "tokens": [
          50956,
          689,
          415,
          6686,
          807,
          341,
          2017,
          6069,
          284,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 45.54,
        "id": 20,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 43.78,
        "temperature": 0,
        "text": " But I'm going to make my own version of it,",
        "tokens": [
          51058,
          583,
          286,
          478,
          516,
          281,
          652,
          452,
          1065,
          3037,
          295,
          309,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 48.26,
        "id": 21,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 45.54,
        "temperature": 0,
        "text": " and I'm going to use my Toy Neural Network",
        "tokens": [
          51146,
          293,
          286,
          478,
          516,
          281,
          764,
          452,
          15708,
          1734,
          1807,
          12640,
          51282
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 49.58,
        "id": 22,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 48.26,
        "temperature": 0,
        "text": " JavaScript library.",
        "tokens": [
          51282,
          15778,
          6405,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 53.92,
        "id": 23,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 49.58,
        "temperature": 0,
        "text": " Okay, so first, before I start coding,",
        "tokens": [
          51348,
          1033,
          11,
          370,
          700,
          11,
          949,
          286,
          722,
          17720,
          11,
          51565
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 57.66,
        "id": 24,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 53.92,
        "temperature": 0,
        "text": " I want to spend some time with you, the viewer,",
        "tokens": [
          51565,
          286,
          528,
          281,
          3496,
          512,
          565,
          365,
          291,
          11,
          264,
          16767,
          11,
          51752
        ]
      },
      {
        "avg_logprob": -0.22932548263446004,
        "compression_ratio": 1.5993788819875776,
        "end": 59.7,
        "id": 25,
        "no_speech_prob": 0.00002468234561092686,
        "seek": 2990,
        "start": 57.66,
        "temperature": 0,
        "text": " just taking deep breaths together,",
        "tokens": [
          51752,
          445,
          1940,
          2452,
          33769,
          1214,
          11,
          51854
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 61.5,
        "id": 26,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 60.5,
        "temperature": 0,
        "text": " thinking about flowers.",
        "tokens": [
          50404,
          1953,
          466,
          8085,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 64.14,
        "id": 27,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 61.5,
        "temperature": 0,
        "text": " Okay, well, I guess I should talk through",
        "tokens": [
          50454,
          1033,
          11,
          731,
          11,
          286,
          2041,
          286,
          820,
          751,
          807,
          50586
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 64.98,
        "id": 28,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 64.14,
        "temperature": 0,
        "text": " what the problem is.",
        "tokens": [
          50586,
          437,
          264,
          1154,
          307,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 67.68,
        "id": 29,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 64.98,
        "temperature": 0,
        "text": " So here's the problem, so to speak.",
        "tokens": [
          50628,
          407,
          510,
          311,
          264,
          1154,
          11,
          370,
          281,
          1710,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 69.74000000000001,
        "id": 30,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 67.68,
        "temperature": 0,
        "text": " Now, one of the reasons why I love this idea,",
        "tokens": [
          50763,
          823,
          11,
          472,
          295,
          264,
          4112,
          983,
          286,
          959,
          341,
          1558,
          11,
          50866
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 72.26,
        "id": 31,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 69.74000000000001,
        "temperature": 0,
        "text": " which came from Jabril, is that I'm always looking",
        "tokens": [
          50866,
          597,
          1361,
          490,
          40319,
          24216,
          11,
          307,
          300,
          286,
          478,
          1009,
          1237,
          50992
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 76.14,
        "id": 32,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 72.26,
        "temperature": 0,
        "text": " for really simple, almost trivial scenarios",
        "tokens": [
          50992,
          337,
          534,
          2199,
          11,
          1920,
          26703,
          15077,
          51186
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 78.7,
        "id": 33,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 76.14,
        "temperature": 0,
        "text": " to demonstrate a machine learning concept",
        "tokens": [
          51186,
          281,
          11698,
          257,
          3479,
          2539,
          3410,
          51314
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 82.36,
        "id": 34,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 78.7,
        "temperature": 0,
        "text": " where all the pieces of how the algorithm works,",
        "tokens": [
          51314,
          689,
          439,
          264,
          3755,
          295,
          577,
          264,
          9284,
          1985,
          11,
          51497
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 85.34,
        "id": 35,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 82.36,
        "temperature": 0,
        "text": " it's visual, it involves interaction, it involves drawing,",
        "tokens": [
          51497,
          309,
          311,
          5056,
          11,
          309,
          11626,
          9285,
          11,
          309,
          11626,
          6316,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 87.46000000000001,
        "id": 36,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 85.34,
        "temperature": 0,
        "text": " because this, to me, is a good basis",
        "tokens": [
          51646,
          570,
          341,
          11,
          281,
          385,
          11,
          307,
          257,
          665,
          5143,
          51752
        ]
      },
      {
        "avg_logprob": -0.2347327091897181,
        "compression_ratio": 1.6262626262626263,
        "end": 88.9,
        "id": 37,
        "no_speech_prob": 0.000026688385332818143,
        "seek": 5970,
        "start": 87.46000000000001,
        "temperature": 0,
        "text": " for people watching and learning",
        "tokens": [
          51752,
          337,
          561,
          1976,
          293,
          2539,
          51824
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 90.66000000000001,
        "id": 38,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 88.9,
        "temperature": 0,
        "text": " to then build their own more complex",
        "tokens": [
          50364,
          281,
          550,
          1322,
          641,
          1065,
          544,
          3997,
          50452
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 95.10000000000001,
        "id": 39,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 90.66000000000001,
        "temperature": 0,
        "text": " or sophisticated design machine learning system things.",
        "tokens": [
          50452,
          420,
          16950,
          1715,
          3479,
          2539,
          1185,
          721,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 97.26,
        "id": 40,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 95.10000000000001,
        "temperature": 0,
        "text": " So this is incredibly simple, and in fact,",
        "tokens": [
          50674,
          407,
          341,
          307,
          6252,
          2199,
          11,
          293,
          294,
          1186,
          11,
          50782
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 100.18,
        "id": 41,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 97.26,
        "temperature": 0,
        "text": " just to be clear, you do not need a neural network for this.",
        "tokens": [
          50782,
          445,
          281,
          312,
          1850,
          11,
          291,
          360,
          406,
          643,
          257,
          18161,
          3209,
          337,
          341,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 101.86000000000001,
        "id": 42,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 100.18,
        "temperature": 0,
        "text": " It almost makes no sense at all",
        "tokens": [
          50928,
          467,
          1920,
          1669,
          572,
          2020,
          412,
          439,
          51012
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 103.2,
        "id": 43,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 101.86000000000001,
        "temperature": 0,
        "text": " to use a neural network for this.",
        "tokens": [
          51012,
          281,
          764,
          257,
          18161,
          3209,
          337,
          341,
          13,
          51079
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 105.94,
        "id": 44,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 103.2,
        "temperature": 0,
        "text": " But it makes the point, you might have heard this,",
        "tokens": [
          51079,
          583,
          309,
          1669,
          264,
          935,
          11,
          291,
          1062,
          362,
          2198,
          341,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 107.34,
        "id": 45,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 105.94,
        "temperature": 0,
        "text": " you might have heard this idea",
        "tokens": [
          51216,
          291,
          1062,
          362,
          2198,
          341,
          1558,
          51286
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 112.34,
        "id": 46,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 107.34,
        "temperature": 0,
        "text": " that a neural network is a universal function approximator.",
        "tokens": [
          51286,
          300,
          257,
          18161,
          3209,
          307,
          257,
          11455,
          2445,
          8542,
          1639,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.22147868612538213,
        "compression_ratio": 1.8130081300813008,
        "end": 118.84,
        "id": 47,
        "no_speech_prob": 0.0000036688579712063074,
        "seek": 8890,
        "start": 116.10000000000001,
        "temperature": 0,
        "text": " So I think that this video and this topic",
        "tokens": [
          51724,
          407,
          286,
          519,
          300,
          341,
          960,
          293,
          341,
          4829,
          51861
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 121.48,
        "id": 48,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 119.68,
        "temperature": 0,
        "text": " and this demonstration will unpack",
        "tokens": [
          50406,
          293,
          341,
          16520,
          486,
          26699,
          50496
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 123.8,
        "id": 49,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 121.48,
        "temperature": 0,
        "text": " what this means in a nice way.",
        "tokens": [
          50496,
          437,
          341,
          1355,
          294,
          257,
          1481,
          636,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 124.96000000000001,
        "id": 50,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 123.8,
        "temperature": 0,
        "text": " What do I mean by that?",
        "tokens": [
          50612,
          708,
          360,
          286,
          914,
          538,
          300,
          30,
          50670
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 128.6,
        "id": 51,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 124.96000000000001,
        "temperature": 0,
        "text": " So what is the problem that we're trying to solve?",
        "tokens": [
          50670,
          407,
          437,
          307,
          264,
          1154,
          300,
          321,
          434,
          1382,
          281,
          5039,
          30,
          50852
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 132.4,
        "id": 52,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 128.6,
        "temperature": 0,
        "text": " So the problem is, let's say I have a color,",
        "tokens": [
          50852,
          407,
          264,
          1154,
          307,
          11,
          718,
          311,
          584,
          286,
          362,
          257,
          2017,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 137.4,
        "id": 53,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 132.4,
        "temperature": 0,
        "text": " some RGB color, some RGB color,",
        "tokens": [
          51042,
          512,
          31231,
          2017,
          11,
          512,
          31231,
          2017,
          11,
          51292
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 140.4,
        "id": 54,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 137.68,
        "temperature": 0,
        "text": " and I want to put text on top of that color.",
        "tokens": [
          51306,
          293,
          286,
          528,
          281,
          829,
          2487,
          322,
          1192,
          295,
          300,
          2017,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 142.34,
        "id": 55,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 140.4,
        "temperature": 0,
        "text": " So I could make a more complex problem,",
        "tokens": [
          51442,
          407,
          286,
          727,
          652,
          257,
          544,
          3997,
          1154,
          11,
          51539
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 144.04,
        "id": 56,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 142.34,
        "temperature": 0,
        "text": " which I would encourage you to do as an exercise",
        "tokens": [
          51539,
          597,
          286,
          576,
          5373,
          291,
          281,
          360,
          382,
          364,
          5380,
          51624
        ]
      },
      {
        "avg_logprob": -0.18786585229074854,
        "compression_ratio": 1.677685950413223,
        "end": 146.96,
        "id": 57,
        "no_speech_prob": 0.00001341994538961444,
        "seek": 11884,
        "start": 144.04,
        "temperature": 0,
        "text": " after watching this, what would be the most pleasantly",
        "tokens": [
          51624,
          934,
          1976,
          341,
          11,
          437,
          576,
          312,
          264,
          881,
          35122,
          3627,
          51770
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 150.64000000000001,
        "id": 58,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 147,
        "temperature": 0,
        "text": " looking or complimentary, that's an actual thing,",
        "tokens": [
          50366,
          1237,
          420,
          47162,
          11,
          300,
          311,
          364,
          3539,
          551,
          11,
          50548
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 153.68,
        "id": 59,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 150.64000000000001,
        "temperature": 0,
        "text": " color to overlay on that RGB color?",
        "tokens": [
          50548,
          2017,
          281,
          31741,
          322,
          300,
          31231,
          2017,
          30,
          50700
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 155.52,
        "id": 60,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 153.68,
        "temperature": 0,
        "text": " But I'm just going to ask a simple question.",
        "tokens": [
          50700,
          583,
          286,
          478,
          445,
          516,
          281,
          1029,
          257,
          2199,
          1168,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 160.12,
        "id": 61,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 155.52,
        "temperature": 0,
        "text": " Which looks better, black or white?",
        "tokens": [
          50792,
          3013,
          1542,
          1101,
          11,
          2211,
          420,
          2418,
          30,
          51022
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 163.76000000000002,
        "id": 62,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 161.88,
        "temperature": 0,
        "text": " And we could get into a whole discussion of why,",
        "tokens": [
          51110,
          400,
          321,
          727,
          483,
          666,
          257,
          1379,
          5017,
          295,
          983,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 165.64000000000001,
        "id": 63,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 163.76000000000002,
        "temperature": 0,
        "text": " you know, perception, what looks better,",
        "tokens": [
          51204,
          291,
          458,
          11,
          12860,
          11,
          437,
          1542,
          1101,
          11,
          51298
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 168.24,
        "id": 64,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 165.64000000000001,
        "temperature": 0,
        "text": " but I just mean just in the sort of arbitrary sense,",
        "tokens": [
          51298,
          457,
          286,
          445,
          914,
          445,
          294,
          264,
          1333,
          295,
          23211,
          2020,
          11,
          51428
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 171.14000000000001,
        "id": 65,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 168.24,
        "temperature": 0,
        "text": " like which is easier to read, which is more legible?",
        "tokens": [
          51428,
          411,
          597,
          307,
          3571,
          281,
          1401,
          11,
          597,
          307,
          544,
          1676,
          964,
          30,
          51573
        ]
      },
      {
        "avg_logprob": -0.2628825419657939,
        "compression_ratio": 1.6129032258064515,
        "end": 173.20000000000002,
        "id": 66,
        "no_speech_prob": 0.0001195976510643959,
        "seek": 14696,
        "start": 171.14000000000001,
        "temperature": 0,
        "text": " And we could write a function, right?",
        "tokens": [
          51573,
          400,
          321,
          727,
          2464,
          257,
          2445,
          11,
          558,
          30,
          51676
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 178.2,
        "id": 67,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 173.2,
        "temperature": 0,
        "text": " We could write a function, a JavaScript function,",
        "tokens": [
          50364,
          492,
          727,
          2464,
          257,
          2445,
          11,
          257,
          15778,
          2445,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 179.88,
        "id": 68,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 178.79999999999998,
        "temperature": 0,
        "text": " I'm just checking to see, right?",
        "tokens": [
          50644,
          286,
          478,
          445,
          8568,
          281,
          536,
          11,
          558,
          30,
          50698
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 184.06,
        "id": 69,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 179.88,
        "temperature": 0,
        "text": " And that JavaScript function takes as its arguments",
        "tokens": [
          50698,
          400,
          300,
          15778,
          2445,
          2516,
          382,
          1080,
          12869,
          50907
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 189.06,
        "id": 70,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 184.06,
        "temperature": 0,
        "text": " an R, a G, and a B, and what it does is it returns,",
        "tokens": [
          50907,
          364,
          497,
          11,
          257,
          460,
          11,
          293,
          257,
          363,
          11,
          293,
          437,
          309,
          775,
          307,
          309,
          11247,
          11,
          51157
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 192.95999999999998,
        "id": 71,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 190.16,
        "temperature": 0,
        "text": " maybe it returns, I mean, black,",
        "tokens": [
          51212,
          1310,
          309,
          11247,
          11,
          286,
          914,
          11,
          2211,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 197.33999999999997,
        "id": 72,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 192.95999999999998,
        "temperature": 0,
        "text": " or maybe somewhere else in the function, it returns white.",
        "tokens": [
          51352,
          420,
          1310,
          4079,
          1646,
          294,
          264,
          2445,
          11,
          309,
          11247,
          2418,
          13,
          51571
        ]
      },
      {
        "avg_logprob": -0.20851075130960214,
        "compression_ratio": 1.6414141414141414,
        "end": 199.79999999999998,
        "id": 73,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 17320,
        "start": 197.33999999999997,
        "temperature": 0,
        "text": " And maybe we just have like this if statement,",
        "tokens": [
          51571,
          400,
          1310,
          321,
          445,
          362,
          411,
          341,
          498,
          5629,
          11,
          51694
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 203.56,
        "id": 74,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 199.8,
        "temperature": 0,
        "text": " and maybe I'm doing something like if R plus G plus B",
        "tokens": [
          50364,
          293,
          1310,
          286,
          478,
          884,
          746,
          411,
          498,
          497,
          1804,
          460,
          1804,
          363,
          50552
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 207.36,
        "id": 75,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 203.56,
        "temperature": 0,
        "text": " is less than 100, or less than 200,",
        "tokens": [
          50552,
          307,
          1570,
          813,
          2319,
          11,
          420,
          1570,
          813,
          2331,
          11,
          50742
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 210.52,
        "id": 76,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 207.36,
        "temperature": 0,
        "text": " return black, otherwise return white.",
        "tokens": [
          50742,
          2736,
          2211,
          11,
          5911,
          2736,
          2418,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 213.86,
        "id": 77,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 210.52,
        "temperature": 0,
        "text": " So this is the idea, this is a function,",
        "tokens": [
          50900,
          407,
          341,
          307,
          264,
          1558,
          11,
          341,
          307,
          257,
          2445,
          11,
          51067
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 217.8,
        "id": 78,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 213.86,
        "temperature": 0,
        "text": " it takes inputs, how many inputs?",
        "tokens": [
          51067,
          309,
          2516,
          15743,
          11,
          577,
          867,
          15743,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 222.06,
        "id": 79,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 217.8,
        "temperature": 0,
        "text": " Three, and it returns an output, how many outputs?",
        "tokens": [
          51264,
          6244,
          11,
          293,
          309,
          11247,
          364,
          5598,
          11,
          577,
          867,
          23930,
          30,
          51477
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 225.76000000000002,
        "id": 80,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 222.06,
        "temperature": 0,
        "text": " One, but out of two possibilities is important here.",
        "tokens": [
          51477,
          1485,
          11,
          457,
          484,
          295,
          732,
          12178,
          307,
          1021,
          510,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.20941024780273437,
        "compression_ratio": 1.6481481481481481,
        "end": 229.78,
        "id": 81,
        "no_speech_prob": 0.0000012679267911153147,
        "seek": 19980,
        "start": 225.76000000000002,
        "temperature": 0,
        "text": " There are two possible, out to two possibilities.",
        "tokens": [
          51662,
          821,
          366,
          732,
          1944,
          11,
          484,
          281,
          732,
          12178,
          13,
          51863
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 233.94,
        "id": 82,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 230.62,
        "temperature": 0,
        "text": " It takes one output, it's a function that takes three inputs",
        "tokens": [
          50406,
          467,
          2516,
          472,
          5598,
          11,
          309,
          311,
          257,
          2445,
          300,
          2516,
          1045,
          15743,
          50572
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 235.3,
        "id": 83,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 233.94,
        "temperature": 0,
        "text": " and returns one output.",
        "tokens": [
          50572,
          293,
          11247,
          472,
          5598,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 240.3,
        "id": 84,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 235.3,
        "temperature": 0,
        "text": " The inputs are numbers between zero and 255,",
        "tokens": [
          50640,
          440,
          15743,
          366,
          3547,
          1296,
          4018,
          293,
          3552,
          20,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 244.14,
        "id": 85,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 240.46,
        "temperature": 0,
        "text": " and the output is one label, which is a string.",
        "tokens": [
          50898,
          293,
          264,
          5598,
          307,
          472,
          7645,
          11,
          597,
          307,
          257,
          6798,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 245.76,
        "id": 86,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 244.14,
        "temperature": 0,
        "text": " But another way I could think about this",
        "tokens": [
          51082,
          583,
          1071,
          636,
          286,
          727,
          519,
          466,
          341,
          51163
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 248.98,
        "id": 87,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 245.76,
        "temperature": 0,
        "text": " is it could return a kind of probability value.",
        "tokens": [
          51163,
          307,
          309,
          727,
          2736,
          257,
          733,
          295,
          8482,
          2158,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 251.22,
        "id": 88,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 248.98,
        "temperature": 0,
        "text": " How likely is it that black looks better,",
        "tokens": [
          51324,
          1012,
          3700,
          307,
          309,
          300,
          2211,
          1542,
          1101,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 253.14,
        "id": 89,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 251.22,
        "temperature": 0,
        "text": " and how likely is it that white looks better?",
        "tokens": [
          51436,
          293,
          577,
          3700,
          307,
          309,
          300,
          2418,
          1542,
          1101,
          30,
          51532
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 256.86,
        "id": 90,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 253.14,
        "temperature": 0,
        "text": " And that would be kind of also two,",
        "tokens": [
          51532,
          400,
          300,
          576,
          312,
          733,
          295,
          611,
          732,
          11,
          51718
        ]
      },
      {
        "avg_logprob": -0.24581412018322554,
        "compression_ratio": 1.8414634146341464,
        "end": 259.74,
        "id": 91,
        "no_speech_prob": 0.00000435687661592965,
        "seek": 22978,
        "start": 256.86,
        "temperature": 0,
        "text": " so two floating point numbers, you could think of it that way.",
        "tokens": [
          51718,
          370,
          732,
          12607,
          935,
          3547,
          11,
          291,
          727,
          519,
          295,
          309,
          300,
          636,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 263.06,
        "id": 92,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 260.58,
        "temperature": 0,
        "text": " So this is a function, so a lot of machine,",
        "tokens": [
          50406,
          407,
          341,
          307,
          257,
          2445,
          11,
          370,
          257,
          688,
          295,
          3479,
          11,
          50530
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 265.42,
        "id": 93,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 263.06,
        "temperature": 0,
        "text": " like imagine this, so now this function takes an RGB color.",
        "tokens": [
          50530,
          411,
          3811,
          341,
          11,
          370,
          586,
          341,
          2445,
          2516,
          364,
          31231,
          2017,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 268.06,
        "id": 94,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 265.42,
        "temperature": 0,
        "text": " Now let me give you another function.",
        "tokens": [
          50648,
          823,
          718,
          385,
          976,
          291,
          1071,
          2445,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 271.06,
        "id": 95,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 268.06,
        "temperature": 0,
        "text": " Write a function that takes an image data,",
        "tokens": [
          50780,
          23499,
          257,
          2445,
          300,
          2516,
          364,
          3256,
          1412,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 273.86,
        "id": 96,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 271.06,
        "temperature": 0,
        "text": " a 200 by 200 pixel image,",
        "tokens": [
          50930,
          257,
          2331,
          538,
          2331,
          19261,
          3256,
          11,
          51070
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 276.36,
        "id": 97,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 273.86,
        "temperature": 0,
        "text": " and then returns what's in that image.",
        "tokens": [
          51070,
          293,
          550,
          11247,
          437,
          311,
          294,
          300,
          3256,
          13,
          51195
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 279.02,
        "id": 98,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 276.36,
        "temperature": 0,
        "text": " Now you could imagine, in this case,",
        "tokens": [
          51195,
          823,
          291,
          727,
          3811,
          11,
          294,
          341,
          1389,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 280.64,
        "id": 99,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 279.02,
        "temperature": 0,
        "text": " deciding whether it should be black or white",
        "tokens": [
          51328,
          17990,
          1968,
          309,
          820,
          312,
          2211,
          420,
          2418,
          51409
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 283.84000000000003,
        "id": 100,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 280.64,
        "temperature": 0,
        "text": " is just a matter of, okay, is it bright, is it dark,",
        "tokens": [
          51409,
          307,
          445,
          257,
          1871,
          295,
          11,
          1392,
          11,
          307,
          309,
          4730,
          11,
          307,
          309,
          2877,
          11,
          51569
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 285.46000000000004,
        "id": 101,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 283.84000000000003,
        "temperature": 0,
        "text": " which color's going to be, like a bright color",
        "tokens": [
          51569,
          597,
          2017,
          311,
          516,
          281,
          312,
          11,
          411,
          257,
          4730,
          2017,
          51650
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 286.82,
        "id": 102,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 285.46000000000004,
        "temperature": 0,
        "text": " looks better on a dark color,",
        "tokens": [
          51650,
          1542,
          1101,
          322,
          257,
          2877,
          2017,
          11,
          51718
        ]
      },
      {
        "avg_logprob": -0.25089937407394935,
        "compression_ratio": 1.867158671586716,
        "end": 288.7,
        "id": 103,
        "no_speech_prob": 0.00002144489553757012,
        "seek": 25974,
        "start": 286.82,
        "temperature": 0,
        "text": " a dark color looks better on a bright color.",
        "tokens": [
          51718,
          257,
          2877,
          2017,
          1542,
          1101,
          322,
          257,
          4730,
          2017,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 291.14,
        "id": 104,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 288.7,
        "temperature": 0,
        "text": " But if I took in a full image and needed to return,",
        "tokens": [
          50364,
          583,
          498,
          286,
          1890,
          294,
          257,
          1577,
          3256,
          293,
          2978,
          281,
          2736,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 293.9,
        "id": 105,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 291.14,
        "temperature": 0,
        "text": " whether it's a cat, a dog, a turtle, a coffee mug,",
        "tokens": [
          50486,
          1968,
          309,
          311,
          257,
          3857,
          11,
          257,
          3000,
          11,
          257,
          22866,
          11,
          257,
          4982,
          23610,
          11,
          50624
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 297.82,
        "id": 106,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 293.9,
        "temperature": 0,
        "text": " a cell phone, a walking stick, a conductor's baton,",
        "tokens": [
          50624,
          257,
          2815,
          2593,
          11,
          257,
          4494,
          2897,
          11,
          257,
          29957,
          311,
          7362,
          266,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 302.82,
        "id": 107,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 297.82,
        "temperature": 0,
        "text": " I don't know where my brain is going here, a toy train.",
        "tokens": [
          50820,
          286,
          500,
          380,
          458,
          689,
          452,
          3567,
          307,
          516,
          510,
          11,
          257,
          12058,
          3847,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 307.06,
        "id": 108,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 304.94,
        "temperature": 0,
        "text": " Try writing a bunch of if statements to do that.",
        "tokens": [
          51176,
          6526,
          3579,
          257,
          3840,
          295,
          498,
          12363,
          281,
          360,
          300,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 311.3,
        "id": 109,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 307.06,
        "temperature": 0,
        "text": " Well, if the pixel colors are this and shaped like this,",
        "tokens": [
          51282,
          1042,
          11,
          498,
          264,
          19261,
          4577,
          366,
          341,
          293,
          13475,
          411,
          341,
          11,
          51494
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 313.78,
        "id": 110,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 311.3,
        "temperature": 0,
        "text": " having to hard code an algorithm,",
        "tokens": [
          51494,
          1419,
          281,
          1152,
          3089,
          364,
          9284,
          11,
          51618
        ]
      },
      {
        "avg_logprob": -0.20001866899687668,
        "compression_ratio": 1.5992063492063493,
        "end": 317.26,
        "id": 111,
        "no_speech_prob": 0.000009080459676624741,
        "seek": 28870,
        "start": 313.78,
        "temperature": 0,
        "text": " a function that takes inputs and generates an output",
        "tokens": [
          51618,
          257,
          2445,
          300,
          2516,
          15743,
          293,
          23815,
          364,
          5598,
          51792
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 319.24,
        "id": 112,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 317.26,
        "temperature": 0,
        "text": " would be really difficult.",
        "tokens": [
          50364,
          576,
          312,
          534,
          2252,
          13,
          50463
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 322.84,
        "id": 113,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 319.24,
        "temperature": 0,
        "text": " This is what a neural network is for.",
        "tokens": [
          50463,
          639,
          307,
          437,
          257,
          18161,
          3209,
          307,
          337,
          13,
          50643
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 327.06,
        "id": 114,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 322.84,
        "temperature": 0,
        "text": " And just to make this case here, the idea here is that",
        "tokens": [
          50643,
          400,
          445,
          281,
          652,
          341,
          1389,
          510,
          11,
          264,
          1558,
          510,
          307,
          300,
          50854
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 332.7,
        "id": 115,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 328.3,
        "temperature": 0,
        "text": " a neural network can approximate any function.",
        "tokens": [
          50916,
          257,
          18161,
          3209,
          393,
          30874,
          604,
          2445,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 337.62,
        "id": 116,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 332.7,
        "temperature": 0,
        "text": " It can learn to receive inputs and return the outputs",
        "tokens": [
          51136,
          467,
          393,
          1466,
          281,
          4774,
          15743,
          293,
          2736,
          264,
          23930,
          51382
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 341.53999999999996,
        "id": 117,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 337.62,
        "temperature": 0,
        "text": " for any input data for any sort of problem.",
        "tokens": [
          51382,
          337,
          604,
          4846,
          1412,
          337,
          604,
          1333,
          295,
          1154,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.24927815095877942,
        "compression_ratio": 1.6157894736842104,
        "end": 345.02,
        "id": 118,
        "no_speech_prob": 0.000056497796322219074,
        "seek": 31726,
        "start": 341.53999999999996,
        "temperature": 0,
        "text": " Is this true that any, in capital letters,",
        "tokens": [
          51578,
          1119,
          341,
          2074,
          300,
          604,
          11,
          294,
          4238,
          7825,
          11,
          51752
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 346.29999999999995,
        "id": 119,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 345.02,
        "temperature": 0,
        "text": " the big underline is true?",
        "tokens": [
          50364,
          264,
          955,
          833,
          1889,
          307,
          2074,
          30,
          50428
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 347.41999999999996,
        "id": 120,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 346.29999999999995,
        "temperature": 0,
        "text": " That's an open question.",
        "tokens": [
          50428,
          663,
          311,
          364,
          1269,
          1168,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 348.78,
        "id": 121,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 347.41999999999996,
        "temperature": 0,
        "text": " What are the limitations?",
        "tokens": [
          50484,
          708,
          366,
          264,
          15705,
          30,
          50552
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 350.59999999999997,
        "id": 122,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 348.78,
        "temperature": 0,
        "text": " What should and should not we be doing?",
        "tokens": [
          50552,
          708,
          820,
          293,
          820,
          406,
          321,
          312,
          884,
          30,
          50643
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 353.26,
        "id": 123,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 350.59999999999997,
        "temperature": 0,
        "text": " Should we even be using a neural network for this task?",
        "tokens": [
          50643,
          6454,
          321,
          754,
          312,
          1228,
          257,
          18161,
          3209,
          337,
          341,
          5633,
          30,
          50776
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 356.35999999999996,
        "id": 124,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 353.26,
        "temperature": 0,
        "text": " Are we causing harm by doing this machine learning task?",
        "tokens": [
          50776,
          2014,
          321,
          9853,
          6491,
          538,
          884,
          341,
          3479,
          2539,
          5633,
          30,
          50931
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 359.28,
        "id": 125,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 356.35999999999996,
        "temperature": 0,
        "text": " But those questions aside, now we can say,",
        "tokens": [
          50931,
          583,
          729,
          1651,
          7359,
          11,
          586,
          321,
          393,
          584,
          11,
          51077
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 362.53999999999996,
        "id": 126,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 359.28,
        "temperature": 0,
        "text": " well, if I have this quote unquote neural network thing,",
        "tokens": [
          51077,
          731,
          11,
          498,
          286,
          362,
          341,
          6513,
          37557,
          18161,
          3209,
          551,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.22008609771728516,
        "compression_ratio": 1.641350210970464,
        "end": 369.06,
        "id": 127,
        "no_speech_prob": 0.00005562196747632697,
        "seek": 34502,
        "start": 364.06,
        "temperature": 0,
        "text": " what if I were to just send three inputs into it, R, G, B,",
        "tokens": [
          51316,
          437,
          498,
          286,
          645,
          281,
          445,
          2845,
          1045,
          15743,
          666,
          309,
          11,
          497,
          11,
          460,
          11,
          363,
          11,
          51566
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 374.74,
        "id": 128,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 370.06,
        "temperature": 0,
        "text": " and then I want to receive two outputs,",
        "tokens": [
          50414,
          293,
          550,
          286,
          528,
          281,
          4774,
          732,
          23930,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 379.74,
        "id": 129,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 374.74,
        "temperature": 0,
        "text": " probability of black, probability of white?",
        "tokens": [
          50648,
          8482,
          295,
          2211,
          11,
          8482,
          295,
          2418,
          30,
          50898
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 384.38,
        "id": 130,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 380.62,
        "temperature": 0,
        "text": " This is now a universal function approximator.",
        "tokens": [
          50942,
          639,
          307,
          586,
          257,
          11455,
          2445,
          8542,
          1639,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 387.18,
        "id": 131,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 384.38,
        "temperature": 0,
        "text": " It is going to stand in, so what is neural net,",
        "tokens": [
          51130,
          467,
          307,
          516,
          281,
          1463,
          294,
          11,
          370,
          437,
          307,
          18161,
          2533,
          11,
          51270
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 389.28,
        "id": 132,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 387.18,
        "temperature": 0,
        "text": " machine learning doesn't necessarily replace,",
        "tokens": [
          51270,
          3479,
          2539,
          1177,
          380,
          4725,
          7406,
          11,
          51375
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 390.54,
        "id": 133,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 389.28,
        "temperature": 0,
        "text": " you can think of it as, I mean,",
        "tokens": [
          51375,
          291,
          393,
          519,
          295,
          309,
          382,
          11,
          286,
          914,
          11,
          51438
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 392.02,
        "id": 134,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 390.54,
        "temperature": 0,
        "text": " will machine learning replace the need",
        "tokens": [
          51438,
          486,
          3479,
          2539,
          7406,
          264,
          643,
          51512
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 393.94,
        "id": 135,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 392.02,
        "temperature": 0,
        "text": " to write code completely at some point?",
        "tokens": [
          51512,
          281,
          2464,
          3089,
          2584,
          412,
          512,
          935,
          30,
          51608
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 395.06,
        "id": 136,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 393.94,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          51608,
          2704,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23362842741466705,
        "compression_ratio": 1.5991735537190082,
        "end": 397.06,
        "id": 137,
        "no_speech_prob": 0.000007766941052977927,
        "seek": 36906,
        "start": 395.06,
        "temperature": 0,
        "text": " But here, what I would make the case is that",
        "tokens": [
          51664,
          583,
          510,
          11,
          437,
          286,
          576,
          652,
          264,
          1389,
          307,
          300,
          51764
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 398.66,
        "id": 138,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 397.06,
        "temperature": 0,
        "text": " machine learning, a neural network,",
        "tokens": [
          50364,
          3479,
          2539,
          11,
          257,
          18161,
          3209,
          11,
          50444
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 401.1,
        "id": 139,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 398.66,
        "temperature": 0,
        "text": " might replace the guts of a function",
        "tokens": [
          50444,
          1062,
          7406,
          264,
          28560,
          295,
          257,
          2445,
          50566
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 403.26,
        "id": 140,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 401.1,
        "temperature": 0,
        "text": " that you might hard code otherwise.",
        "tokens": [
          50566,
          300,
          291,
          1062,
          1152,
          3089,
          5911,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 407.18,
        "id": 141,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 404.26,
        "temperature": 0,
        "text": " Okay, boy, am I spending a long time explaining this.",
        "tokens": [
          50724,
          1033,
          11,
          3237,
          11,
          669,
          286,
          6434,
          257,
          938,
          565,
          13468,
          341,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 410.62,
        "id": 142,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 407.18,
        "temperature": 0,
        "text": " So now, what goes here, what goes here?",
        "tokens": [
          50870,
          407,
          586,
          11,
          437,
          1709,
          510,
          11,
          437,
          1709,
          510,
          30,
          51042
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 413.82,
        "id": 143,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 410.62,
        "temperature": 0,
        "text": " Now, if you want to learn more about the structure",
        "tokens": [
          51042,
          823,
          11,
          498,
          291,
          528,
          281,
          1466,
          544,
          466,
          264,
          3877,
          51202
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 415.98,
        "id": 144,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 413.82,
        "temperature": 0,
        "text": " of a neural network and the internals of it,",
        "tokens": [
          51202,
          295,
          257,
          18161,
          3209,
          293,
          264,
          2154,
          1124,
          295,
          309,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 418.8,
        "id": 145,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 415.98,
        "temperature": 0,
        "text": " I would refer you to the 3Blue1Brown video series,",
        "tokens": [
          51310,
          286,
          576,
          2864,
          291,
          281,
          264,
          805,
          45231,
          16,
          22170,
          648,
          960,
          2638,
          11,
          51451
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 421.66,
        "id": 146,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 418.8,
        "temperature": 0,
        "text": " as well as my video series, which goes through",
        "tokens": [
          51451,
          382,
          731,
          382,
          452,
          960,
          2638,
          11,
          597,
          1709,
          807,
          51594
        ]
      },
      {
        "avg_logprob": -0.21291860470101853,
        "compression_ratio": 1.6842105263157894,
        "end": 425.12,
        "id": 147,
        "no_speech_prob": 0.00006922162720002234,
        "seek": 39706,
        "start": 421.66,
        "temperature": 0,
        "text": " building this neural network library in JavaScript.",
        "tokens": [
          51594,
          2390,
          341,
          18161,
          3209,
          6405,
          294,
          15778,
          13,
          51767
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 428.12,
        "id": 148,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 425.12,
        "temperature": 0,
        "text": " For us, as the user of the neural network library,",
        "tokens": [
          50364,
          1171,
          505,
          11,
          382,
          264,
          4195,
          295,
          264,
          18161,
          3209,
          6405,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 432.88,
        "id": 149,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 428.12,
        "temperature": 0,
        "text": " the only things we need to decide are how many inputs,",
        "tokens": [
          50514,
          264,
          787,
          721,
          321,
          643,
          281,
          4536,
          366,
          577,
          867,
          15743,
          11,
          50752
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 441.16,
        "id": 150,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 436.16,
        "temperature": 0,
        "text": " and how many outputs, and then,",
        "tokens": [
          50916,
          293,
          577,
          867,
          23930,
          11,
          293,
          550,
          11,
          51166
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 443.84000000000003,
        "id": 151,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 441.48,
        "temperature": 0,
        "text": " so this is, inputs and outputs are the things",
        "tokens": [
          51182,
          370,
          341,
          307,
          11,
          15743,
          293,
          23930,
          366,
          264,
          721,
          51300
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 446.8,
        "id": 152,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 443.84000000000003,
        "temperature": 0,
        "text": " we, as the end user of the neural network,",
        "tokens": [
          51300,
          321,
          11,
          382,
          264,
          917,
          4195,
          295,
          264,
          18161,
          3209,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 447.96,
        "id": 153,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 446.8,
        "temperature": 0,
        "text": " look at and control.",
        "tokens": [
          51448,
          574,
          412,
          293,
          1969,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 450.78000000000003,
        "id": 154,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 447.96,
        "temperature": 0,
        "text": " We're sending in the input, we're reading the output,",
        "tokens": [
          51506,
          492,
          434,
          7750,
          294,
          264,
          4846,
          11,
          321,
          434,
          3760,
          264,
          5598,
          11,
          51647
        ]
      },
      {
        "avg_logprob": -0.22016222452379994,
        "compression_ratio": 1.92090395480226,
        "end": 452.28000000000003,
        "id": 155,
        "no_speech_prob": 0.0000036688493310066406,
        "seek": 42512,
        "start": 450.78000000000003,
        "temperature": 0,
        "text": " we're doing something with the output.",
        "tokens": [
          51647,
          321,
          434,
          884,
          746,
          365,
          264,
          5598,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 455.23999999999995,
        "id": 156,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 452.28,
        "temperature": 0,
        "text": " We're sending in the input, we're reading the output,",
        "tokens": [
          50364,
          492,
          434,
          7750,
          294,
          264,
          4846,
          11,
          321,
          434,
          3760,
          264,
          5598,
          11,
          50512
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 456.52,
        "id": 157,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 455.23999999999995,
        "temperature": 0,
        "text": " we're doing something with the output.",
        "tokens": [
          50512,
          321,
          434,
          884,
          746,
          365,
          264,
          5598,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 458.84,
        "id": 158,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 456.52,
        "temperature": 0,
        "text": " But, the sort of quote unquote magic,",
        "tokens": [
          50576,
          583,
          11,
          264,
          1333,
          295,
          6513,
          37557,
          5585,
          11,
          50692
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 460.55999999999995,
        "id": 159,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 458.84,
        "temperature": 0,
        "text": " which isn't magic, it's just math,",
        "tokens": [
          50692,
          597,
          1943,
          380,
          5585,
          11,
          309,
          311,
          445,
          5221,
          11,
          50778
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 462.64,
        "id": 160,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 460.55999999999995,
        "temperature": 0,
        "text": " numbers multiplied and added together,",
        "tokens": [
          50778,
          3547,
          17207,
          293,
          3869,
          1214,
          11,
          50882
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 466.91999999999996,
        "id": 161,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 462.64,
        "temperature": 0,
        "text": " all sorts of other stuff, is this idea of a hidden layer.",
        "tokens": [
          50882,
          439,
          7527,
          295,
          661,
          1507,
          11,
          307,
          341,
          1558,
          295,
          257,
          7633,
          4583,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 469.11999999999995,
        "id": 162,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 466.91999999999996,
        "temperature": 0,
        "text": " And there could be multiple hidden layer,",
        "tokens": [
          51096,
          400,
          456,
          727,
          312,
          3866,
          7633,
          4583,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 471.08,
        "id": 163,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 469.11999999999995,
        "temperature": 0,
        "text": " there could be hidden layers of different nodes,",
        "tokens": [
          51206,
          456,
          727,
          312,
          7633,
          7914,
          295,
          819,
          13891,
          11,
          51304
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 472.28,
        "id": 164,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 471.08,
        "temperature": 0,
        "text": " but for the sake of argument,",
        "tokens": [
          51304,
          457,
          337,
          264,
          9717,
          295,
          6770,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 474.71999999999997,
        "id": 165,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 472.28,
        "temperature": 0,
        "text": " this is such an incredibly simple problem,",
        "tokens": [
          51364,
          341,
          307,
          1270,
          364,
          6252,
          2199,
          1154,
          11,
          51486
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 476.96,
        "id": 166,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 474.71999999999997,
        "temperature": 0,
        "text": " who knows if we even need the hidden layer for it,",
        "tokens": [
          51486,
          567,
          3255,
          498,
          321,
          754,
          643,
          264,
          7633,
          4583,
          337,
          309,
          11,
          51598
        ]
      },
      {
        "avg_logprob": -0.22060661315917968,
        "compression_ratio": 1.8664259927797835,
        "end": 480.35999999999996,
        "id": 167,
        "no_speech_prob": 0.00006014123573550023,
        "seek": 45228,
        "start": 476.96,
        "temperature": 0,
        "text": " we probably do, but we can just kind of",
        "tokens": [
          51598,
          321,
          1391,
          360,
          11,
          457,
          321,
          393,
          445,
          733,
          295,
          51768
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 482.32,
        "id": 168,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 480.36,
        "temperature": 0,
        "text": " pick something somewhat arbitrarily.",
        "tokens": [
          50364,
          1888,
          746,
          8344,
          19071,
          3289,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 485.2,
        "id": 169,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 482.32,
        "temperature": 0,
        "text": " So I'm going to say there are three inputs,",
        "tokens": [
          50462,
          407,
          286,
          478,
          516,
          281,
          584,
          456,
          366,
          1045,
          15743,
          11,
          50606
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 491.64,
        "id": 170,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 487.16,
        "temperature": 0,
        "text": " there are two outputs, and what I'm going to do",
        "tokens": [
          50704,
          456,
          366,
          732,
          23930,
          11,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          50928
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 493.52000000000004,
        "id": 171,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 491.64,
        "temperature": 0,
        "text": " is just say this is what Jabril used,",
        "tokens": [
          50928,
          307,
          445,
          584,
          341,
          307,
          437,
          40319,
          24216,
          1143,
          11,
          51022
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 494.96000000000004,
        "id": 172,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 493.52000000000004,
        "temperature": 0,
        "text": " so why not use the same?",
        "tokens": [
          51022,
          370,
          983,
          406,
          764,
          264,
          912,
          30,
          51094
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 497.24,
        "id": 173,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 494.96000000000004,
        "temperature": 0,
        "text": " I'm going to add three hidden nodes.",
        "tokens": [
          51094,
          286,
          478,
          516,
          281,
          909,
          1045,
          7633,
          13891,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 502.16,
        "id": 174,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 498.68,
        "temperature": 0,
        "text": " And the idea of a neural network is the inputs",
        "tokens": [
          51280,
          400,
          264,
          1558,
          295,
          257,
          18161,
          3209,
          307,
          264,
          15743,
          51454
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 505.18,
        "id": 175,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 502.16,
        "temperature": 0,
        "text": " all go into each hidden node,",
        "tokens": [
          51454,
          439,
          352,
          666,
          1184,
          7633,
          9984,
          11,
          51605
        ]
      },
      {
        "avg_logprob": -0.22798801422119142,
        "compression_ratio": 1.764102564102564,
        "end": 507.68,
        "id": 176,
        "no_speech_prob": 0.00022341434669215232,
        "seek": 48036,
        "start": 505.18,
        "temperature": 0,
        "text": " they get processed by the hidden node,",
        "tokens": [
          51605,
          436,
          483,
          18846,
          538,
          264,
          7633,
          9984,
          11,
          51730
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 510.56,
        "id": 177,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 507.68,
        "temperature": 0,
        "text": " and each hidden node connects to every output,",
        "tokens": [
          50364,
          293,
          1184,
          7633,
          9984,
          16967,
          281,
          633,
          5598,
          11,
          50508
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 512.8,
        "id": 178,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 510.56,
        "temperature": 0,
        "text": " whoops, I did that, and then they get processed",
        "tokens": [
          50508,
          567,
          3370,
          11,
          286,
          630,
          300,
          11,
          293,
          550,
          436,
          483,
          18846,
          50620
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 514.84,
        "id": 179,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 512.8,
        "temperature": 0,
        "text": " by the outputs, and we get the results.",
        "tokens": [
          50620,
          538,
          264,
          23930,
          11,
          293,
          321,
          483,
          264,
          3542,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 516.76,
        "id": 180,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 514.84,
        "temperature": 0,
        "text": " That's known as feed forward.",
        "tokens": [
          50722,
          663,
          311,
          2570,
          382,
          3154,
          2128,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 518.02,
        "id": 181,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 516.76,
        "temperature": 0,
        "text": " What is that processing?",
        "tokens": [
          50818,
          708,
          307,
          300,
          9007,
          30,
          50881
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 520.44,
        "id": 182,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 518.02,
        "temperature": 0,
        "text": " It has to do with the weights of the connections,",
        "tokens": [
          50881,
          467,
          575,
          281,
          360,
          365,
          264,
          17443,
          295,
          264,
          9271,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 521.66,
        "id": 183,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 520.44,
        "temperature": 0,
        "text": " the summing of the values,",
        "tokens": [
          51002,
          264,
          2408,
          2810,
          295,
          264,
          4190,
          11,
          51063
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 523.5600000000001,
        "id": 184,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 521.66,
        "temperature": 0,
        "text": " the activation of the neural network.",
        "tokens": [
          51063,
          264,
          24433,
          295,
          264,
          18161,
          3209,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 525.84,
        "id": 185,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 523.5600000000001,
        "temperature": 0,
        "text": " I think at this point, it probably makes more sense",
        "tokens": [
          51158,
          286,
          519,
          412,
          341,
          935,
          11,
          309,
          1391,
          1669,
          544,
          2020,
          51272
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 528.2,
        "id": 186,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 525.84,
        "temperature": 0,
        "text": " for me to refer you to my other tutorials",
        "tokens": [
          51272,
          337,
          385,
          281,
          2864,
          291,
          281,
          452,
          661,
          17616,
          51390
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 529.84,
        "id": 187,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 528.2,
        "temperature": 0,
        "text": " that go through the mechanics of this.",
        "tokens": [
          51390,
          300,
          352,
          807,
          264,
          12939,
          295,
          341,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 534.04,
        "id": 188,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 529.84,
        "temperature": 0,
        "text": " I just want to now use it in a sort of higher level way",
        "tokens": [
          51472,
          286,
          445,
          528,
          281,
          586,
          764,
          309,
          294,
          257,
          1333,
          295,
          2946,
          1496,
          636,
          51682
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 536.4,
        "id": 189,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 534.04,
        "temperature": 0,
        "text": " as a library, where I'm going to send in my inputs",
        "tokens": [
          51682,
          382,
          257,
          6405,
          11,
          689,
          286,
          478,
          516,
          281,
          2845,
          294,
          452,
          15743,
          51800
        ]
      },
      {
        "avg_logprob": -0.2114678628789554,
        "compression_ratio": 1.7347560975609757,
        "end": 537.4,
        "id": 190,
        "no_speech_prob": 0.00009610172128304839,
        "seek": 50768,
        "start": 536.4,
        "temperature": 0,
        "text": " and look at the outputs.",
        "tokens": [
          51800,
          293,
          574,
          412,
          264,
          23930,
          13,
          51850
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 539.28,
        "id": 191,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 538.12,
        "temperature": 0,
        "text": " And of course, I'm going to have to train it.",
        "tokens": [
          50400,
          400,
          295,
          1164,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          3847,
          309,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 540.8,
        "id": 192,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 539.28,
        "temperature": 0,
        "text": " I'm going to have to teach the neural network",
        "tokens": [
          50458,
          286,
          478,
          516,
          281,
          362,
          281,
          2924,
          264,
          18161,
          3209,
          50534
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 543.12,
        "id": 193,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 540.8,
        "temperature": 0,
        "text": " to give me certain outputs that I want.",
        "tokens": [
          50534,
          281,
          976,
          385,
          1629,
          23930,
          300,
          286,
          528,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 544.48,
        "id": 194,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 543.12,
        "temperature": 0,
        "text": " So that's what I'm going to get into",
        "tokens": [
          50650,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          483,
          666,
          50718
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 548,
        "id": 195,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 544.48,
        "temperature": 0,
        "text": " when I go and write the code right now.",
        "tokens": [
          50718,
          562,
          286,
          352,
          293,
          2464,
          264,
          3089,
          558,
          586,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 551.12,
        "id": 196,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 548,
        "temperature": 0,
        "text": " Okay, so first, let's take a look at Jabril's code.",
        "tokens": [
          50894,
          1033,
          11,
          370,
          700,
          11,
          718,
          311,
          747,
          257,
          574,
          412,
          40319,
          24216,
          311,
          3089,
          13,
          51050
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 552.84,
        "id": 197,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 551.12,
        "temperature": 0,
        "text": " He might have a newer version by now,",
        "tokens": [
          51050,
          634,
          1062,
          362,
          257,
          17628,
          3037,
          538,
          586,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 555.4,
        "id": 198,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 552.84,
        "temperature": 0,
        "text": " but this is what he demonstrated last week",
        "tokens": [
          51136,
          457,
          341,
          307,
          437,
          415,
          18772,
          1036,
          1243,
          51264
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 556.6,
        "id": 199,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 555.4,
        "temperature": 0,
        "text": " on the coding train.",
        "tokens": [
          51264,
          322,
          264,
          17720,
          3847,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 558.86,
        "id": 200,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 556.6,
        "temperature": 0,
        "text": " So I could say like, oh, I think white looks better",
        "tokens": [
          51324,
          407,
          286,
          727,
          584,
          411,
          11,
          1954,
          11,
          286,
          519,
          2418,
          1542,
          1101,
          51437
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 560.48,
        "id": 201,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 558.86,
        "temperature": 0,
        "text": " on this color.",
        "tokens": [
          51437,
          322,
          341,
          2017,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 565.0799999999999,
        "id": 202,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 560.48,
        "temperature": 0,
        "text": " By the way, I have no ability for,",
        "tokens": [
          51518,
          3146,
          264,
          636,
          11,
          286,
          362,
          572,
          3485,
          337,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.23073680777298777,
        "compression_ratio": 1.7027027027027026,
        "end": 567.28,
        "id": 203,
        "no_speech_prob": 0.00010889566328842193,
        "seek": 53740,
        "start": 565.0799999999999,
        "temperature": 0,
        "text": " or talent for visual design whatsoever,",
        "tokens": [
          51748,
          420,
          8301,
          337,
          5056,
          1715,
          17076,
          11,
          51858
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 570.4,
        "id": 204,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 568.16,
        "temperature": 0,
        "text": " I don't know, black looks better,",
        "tokens": [
          50408,
          286,
          500,
          380,
          458,
          11,
          2211,
          1542,
          1101,
          11,
          50520
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 572.72,
        "id": 205,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 570.4,
        "temperature": 0,
        "text": " black looks better, white looks better.",
        "tokens": [
          50520,
          2211,
          1542,
          1101,
          11,
          2418,
          1542,
          1101,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 574.72,
        "id": 206,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 572.72,
        "temperature": 0,
        "text": " So you can see, this is me active.",
        "tokens": [
          50636,
          407,
          291,
          393,
          536,
          11,
          341,
          307,
          385,
          4967,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 578.64,
        "id": 207,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 574.72,
        "temperature": 0,
        "text": " This dot represents the computer guessing",
        "tokens": [
          50736,
          639,
          5893,
          8855,
          264,
          3820,
          17939,
          50932
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 580.4399999999999,
        "id": 208,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 578.64,
        "temperature": 0,
        "text": " which ones it thinks it should be.",
        "tokens": [
          50932,
          597,
          2306,
          309,
          7309,
          309,
          820,
          312,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 584.0799999999999,
        "id": 209,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 580.4399999999999,
        "temperature": 0,
        "text": " And me clicking has to do with me giving",
        "tokens": [
          51022,
          400,
          385,
          9697,
          575,
          281,
          360,
          365,
          385,
          2902,
          51204
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 585.24,
        "id": 210,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 584.0799999999999,
        "temperature": 0,
        "text": " this sort of training information.",
        "tokens": [
          51204,
          341,
          1333,
          295,
          3097,
          1589,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 587.9,
        "id": 211,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 585.24,
        "temperature": 0,
        "text": " Like, hey, neural network, it should be this one.",
        "tokens": [
          51262,
          1743,
          11,
          4177,
          11,
          18161,
          3209,
          11,
          309,
          820,
          312,
          341,
          472,
          13,
          51395
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 589.9599999999999,
        "id": 212,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 587.9,
        "temperature": 0,
        "text": " So I'm going to go through and build all the pieces of this.",
        "tokens": [
          51395,
          407,
          286,
          478,
          516,
          281,
          352,
          807,
          293,
          1322,
          439,
          264,
          3755,
          295,
          341,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 591.4,
        "id": 213,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 589.9599999999999,
        "temperature": 0,
        "text": " There's some other stuff going on in here",
        "tokens": [
          51498,
          821,
          311,
          512,
          661,
          1507,
          516,
          322,
          294,
          510,
          51570
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 593.5799999999999,
        "id": 214,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 591.4,
        "temperature": 0,
        "text": " where Jabril is using a genetic algorithm,",
        "tokens": [
          51570,
          689,
          40319,
          24216,
          307,
          1228,
          257,
          12462,
          9284,
          11,
          51679
        ]
      },
      {
        "avg_logprob": -0.23977781885819469,
        "compression_ratio": 1.7657342657342658,
        "end": 595.48,
        "id": 215,
        "no_speech_prob": 0.00011235231795581058,
        "seek": 56728,
        "start": 593.5799999999999,
        "temperature": 0,
        "text": " and there's this sort of voting thing going on.",
        "tokens": [
          51679,
          293,
          456,
          311,
          341,
          1333,
          295,
          10419,
          551,
          516,
          322,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 598.4,
        "id": 216,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 595.48,
        "temperature": 0,
        "text": " But let's just start building some code from scratch,",
        "tokens": [
          50364,
          583,
          718,
          311,
          445,
          722,
          2390,
          512,
          3089,
          490,
          8459,
          11,
          50510
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 600.52,
        "id": 217,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 598.4,
        "temperature": 0,
        "text": " and we can kind of compare and contrast,",
        "tokens": [
          50510,
          293,
          321,
          393,
          733,
          295,
          6794,
          293,
          8712,
          11,
          50616
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 602.62,
        "id": 218,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 600.52,
        "temperature": 0,
        "text": " or you can compare and contrast on your own later.",
        "tokens": [
          50616,
          420,
          291,
          393,
          6794,
          293,
          8712,
          322,
          428,
          1065,
          1780,
          13,
          50721
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 604.88,
        "id": 219,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 602.62,
        "temperature": 0,
        "text": " Okay, so this is my color predictor.",
        "tokens": [
          50721,
          1033,
          11,
          370,
          341,
          307,
          452,
          2017,
          6069,
          284,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 606.9200000000001,
        "id": 220,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 604.88,
        "temperature": 0,
        "text": " I'm going to go to an empty sketch.",
        "tokens": [
          50834,
          286,
          478,
          516,
          281,
          352,
          281,
          364,
          6707,
          12325,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 608.7,
        "id": 221,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 606.9200000000001,
        "temperature": 0,
        "text": " The first thing that I want to do",
        "tokens": [
          50936,
          440,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          51025
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 611.64,
        "id": 222,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 608.7,
        "temperature": 0,
        "text": " is I'm just going to create variables for R, G, and B.",
        "tokens": [
          51025,
          307,
          286,
          478,
          445,
          516,
          281,
          1884,
          9102,
          337,
          497,
          11,
          460,
          11,
          293,
          363,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 615.8000000000001,
        "id": 223,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 612.62,
        "temperature": 0,
        "text": " And when the, I'm going to write,",
        "tokens": [
          51221,
          400,
          562,
          264,
          11,
          286,
          478,
          516,
          281,
          2464,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 619.64,
        "id": 224,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 615.8000000000001,
        "temperature": 0,
        "text": " maybe I'll write a function, pick color,",
        "tokens": [
          51380,
          1310,
          286,
          603,
          2464,
          257,
          2445,
          11,
          1888,
          2017,
          11,
          51572
        ]
      },
      {
        "avg_logprob": -0.23642152547836304,
        "compression_ratio": 1.6865079365079365,
        "end": 621.12,
        "id": 225,
        "no_speech_prob": 0.0000211123660847079,
        "seek": 59548,
        "start": 619.64,
        "temperature": 0,
        "text": " and I'm just going to say R equals random,",
        "tokens": [
          51572,
          293,
          286,
          478,
          445,
          516,
          281,
          584,
          497,
          6915,
          4974,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 626.12,
        "id": 226,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 621.12,
        "temperature": 0,
        "text": " 255, GB, and I am going to then draw the background,",
        "tokens": [
          50364,
          3552,
          20,
          11,
          26809,
          11,
          293,
          286,
          669,
          516,
          281,
          550,
          2642,
          264,
          3678,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 635.84,
        "id": 227,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 630.84,
        "temperature": 0,
        "text": " R, G, B, and I'm going to say mouse pressed,",
        "tokens": [
          50850,
          497,
          11,
          460,
          11,
          363,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          9719,
          17355,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 639.5600000000001,
        "id": 228,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 638.6,
        "temperature": 0,
        "text": " pick color.",
        "tokens": [
          51238,
          1888,
          2017,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 643.2,
        "id": 229,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 640.84,
        "temperature": 0,
        "text": " So let me make a few key points here.",
        "tokens": [
          51350,
          407,
          718,
          385,
          652,
          257,
          1326,
          2141,
          2793,
          510,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 645.76,
        "id": 230,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 643.2,
        "temperature": 0,
        "text": " Me, in creating this example and writing this code,",
        "tokens": [
          51468,
          1923,
          11,
          294,
          4084,
          341,
          1365,
          293,
          3579,
          341,
          3089,
          11,
          51596
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 647.52,
        "id": 231,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 645.76,
        "temperature": 0,
        "text": " I'm not thinking about interaction design.",
        "tokens": [
          51596,
          286,
          478,
          406,
          1953,
          466,
          9285,
          1715,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2300280637519304,
        "compression_ratio": 1.530054644808743,
        "end": 649.72,
        "id": 232,
        "no_speech_prob": 0.0002378201315877959,
        "seek": 62112,
        "start": 647.52,
        "temperature": 0,
        "text": " I'm not thinking about visual design.",
        "tokens": [
          51684,
          286,
          478,
          406,
          1953,
          466,
          5056,
          1715,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 652.2,
        "id": 233,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 649.72,
        "temperature": 0,
        "text": " I'm not thinking about optimized, efficient code.",
        "tokens": [
          50364,
          286,
          478,
          406,
          1953,
          466,
          26941,
          11,
          7148,
          3089,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 654.08,
        "id": 234,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 652.2,
        "temperature": 0,
        "text": " I just want to sort of demonstrate the idea",
        "tokens": [
          50488,
          286,
          445,
          528,
          281,
          1333,
          295,
          11698,
          264,
          1558,
          50582
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 656.28,
        "id": 235,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 654.08,
        "temperature": 0,
        "text": " and get something up and working quickly.",
        "tokens": [
          50582,
          293,
          483,
          746,
          493,
          293,
          1364,
          2661,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 658.9200000000001,
        "id": 236,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 656.28,
        "temperature": 0,
        "text": " You, the viewer, can then take this",
        "tokens": [
          50692,
          509,
          11,
          264,
          16767,
          11,
          393,
          550,
          747,
          341,
          50824
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 661.6800000000001,
        "id": 237,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 658.9200000000001,
        "temperature": 0,
        "text": " and make a more interesting, thoughtful,",
        "tokens": [
          50824,
          293,
          652,
          257,
          544,
          1880,
          11,
          21566,
          11,
          50962
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 663.5600000000001,
        "id": 238,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 661.6800000000001,
        "temperature": 0,
        "text": " designed version of it, even perhaps",
        "tokens": [
          50962,
          4761,
          3037,
          295,
          309,
          11,
          754,
          4317,
          51056
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 665.1,
        "id": 239,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 663.5600000000001,
        "temperature": 0,
        "text": " with a different algorithm",
        "tokens": [
          51056,
          365,
          257,
          819,
          9284,
          51133
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 666.88,
        "id": 240,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 665.1,
        "temperature": 0,
        "text": " or a different problem altogether.",
        "tokens": [
          51133,
          420,
          257,
          819,
          1154,
          19051,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 669.74,
        "id": 241,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 666.88,
        "temperature": 0,
        "text": " But let's just see now, this should be enough code for me",
        "tokens": [
          51222,
          583,
          718,
          311,
          445,
          536,
          586,
          11,
          341,
          820,
          312,
          1547,
          3089,
          337,
          385,
          51365
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 673.6600000000001,
        "id": 242,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 669.74,
        "temperature": 0,
        "text": " to, every time I click the mouse, get a new random color.",
        "tokens": [
          51365,
          281,
          11,
          633,
          565,
          286,
          2052,
          264,
          9719,
          11,
          483,
          257,
          777,
          4974,
          2017,
          13,
          51561
        ]
      },
      {
        "avg_logprob": -0.2024269700050354,
        "compression_ratio": 1.6208053691275168,
        "end": 677.22,
        "id": 243,
        "no_speech_prob": 0.00003120183464488946,
        "seek": 64972,
        "start": 673.6600000000001,
        "temperature": 0,
        "text": " Okay, so I might as well also pick that color in setup.",
        "tokens": [
          51561,
          1033,
          11,
          370,
          286,
          1062,
          382,
          731,
          611,
          1888,
          300,
          2017,
          294,
          8657,
          13,
          51739
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 682.22,
        "id": 244,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 677.22,
        "temperature": 0,
        "text": " Now, I also want to draw, let me say text size, 64.",
        "tokens": [
          50364,
          823,
          11,
          286,
          611,
          528,
          281,
          2642,
          11,
          718,
          385,
          584,
          2487,
          2744,
          11,
          12145,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 687.78,
        "id": 245,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 684.7,
        "temperature": 0,
        "text": " Then I want to say, let me do no stroke, I think.",
        "tokens": [
          50738,
          1396,
          286,
          528,
          281,
          584,
          11,
          718,
          385,
          360,
          572,
          12403,
          11,
          286,
          519,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 689.94,
        "id": 246,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 687.78,
        "temperature": 0,
        "text": " A text can have an outline and a fill,",
        "tokens": [
          50892,
          316,
          2487,
          393,
          362,
          364,
          16387,
          293,
          257,
          2836,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 694.0600000000001,
        "id": 247,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 689.94,
        "temperature": 0,
        "text": " but I'm going to do fill zero, text black,",
        "tokens": [
          51000,
          457,
          286,
          478,
          516,
          281,
          360,
          2836,
          4018,
          11,
          2487,
          2211,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 699.0600000000001,
        "id": 248,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 694.0600000000001,
        "temperature": 0,
        "text": " and let me do text align center also.",
        "tokens": [
          51206,
          293,
          718,
          385,
          360,
          2487,
          7975,
          3056,
          611,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 703.62,
        "id": 249,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 699.14,
        "temperature": 0,
        "text": " So black, and that should be, what is my,",
        "tokens": [
          51460,
          407,
          2211,
          11,
          293,
          300,
          820,
          312,
          11,
          437,
          307,
          452,
          11,
          51684
        ]
      },
      {
        "avg_logprob": -0.2130963920366646,
        "compression_ratio": 1.572139303482587,
        "end": 706.02,
        "id": 250,
        "no_speech_prob": 0.00001834286013036035,
        "seek": 67722,
        "start": 703.62,
        "temperature": 0,
        "text": " let me make the dimensions of this a little simpler,",
        "tokens": [
          51684,
          718,
          385,
          652,
          264,
          12819,
          295,
          341,
          257,
          707,
          18587,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 709.3,
        "id": 251,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 706.02,
        "temperature": 0,
        "text": " 400 by 300, so this would be,",
        "tokens": [
          50364,
          8423,
          538,
          6641,
          11,
          370,
          341,
          576,
          312,
          11,
          50528
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 712.42,
        "id": 252,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 709.3,
        "temperature": 0,
        "text": " 100, 200, 150 then, I guess.",
        "tokens": [
          50528,
          2319,
          11,
          2331,
          11,
          8451,
          550,
          11,
          286,
          2041,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 715.78,
        "id": 253,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 712.42,
        "temperature": 0,
        "text": " 150, 150, I don't know.",
        "tokens": [
          50684,
          8451,
          11,
          8451,
          11,
          286,
          500,
          380,
          458,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 720.38,
        "id": 254,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 715.78,
        "temperature": 0,
        "text": " And 250, 150, and this would say white.",
        "tokens": [
          50852,
          400,
          11650,
          11,
          8451,
          11,
          293,
          341,
          576,
          584,
          2418,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 722.16,
        "id": 255,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 720.38,
        "temperature": 0,
        "text": " So let's see how this goes.",
        "tokens": [
          51082,
          407,
          718,
          311,
          536,
          577,
          341,
          1709,
          13,
          51171
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 726.78,
        "id": 256,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 724.5799999999999,
        "temperature": 0,
        "text": " All right, so that's a little bit too big,",
        "tokens": [
          51292,
          1057,
          558,
          11,
          370,
          300,
          311,
          257,
          707,
          857,
          886,
          955,
          11,
          51402
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 729.9,
        "id": 257,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 726.78,
        "temperature": 0,
        "text": " but I could also just make it wider.",
        "tokens": [
          51402,
          457,
          286,
          727,
          611,
          445,
          652,
          309,
          11842,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.26410793771549146,
        "compression_ratio": 1.553072625698324,
        "end": 734.9,
        "id": 258,
        "no_speech_prob": 0.0011335406452417374,
        "seek": 70602,
        "start": 729.9,
        "temperature": 0,
        "text": " 600, and then this would be 200 and 400, right?",
        "tokens": [
          51558,
          11849,
          11,
          293,
          550,
          341,
          576,
          312,
          2331,
          293,
          8423,
          11,
          558,
          30,
          51808
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 737.8199999999999,
        "id": 259,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 736.98,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50412,
          821,
          321,
          352,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 743.74,
        "id": 260,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 738.74,
        "temperature": 0,
        "text": " And this one should be fill 255.",
        "tokens": [
          50500,
          400,
          341,
          472,
          820,
          312,
          2836,
          3552,
          20,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 749.86,
        "id": 261,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 745.3,
        "temperature": 0,
        "text": " Okay, so now I have a system where at least I am seeing",
        "tokens": [
          50828,
          1033,
          11,
          370,
          586,
          286,
          362,
          257,
          1185,
          689,
          412,
          1935,
          286,
          669,
          2577,
          51056
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 753.62,
        "id": 262,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 750.78,
        "temperature": 0,
        "text": " which one it should be, black or white.",
        "tokens": [
          51102,
          597,
          472,
          309,
          820,
          312,
          11,
          2211,
          420,
          2418,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 756.86,
        "id": 263,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 753.62,
        "temperature": 0,
        "text": " I'm seeing both colors written on top of the background.",
        "tokens": [
          51244,
          286,
          478,
          2577,
          1293,
          4577,
          3720,
          322,
          1192,
          295,
          264,
          3678,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 759.04,
        "id": 264,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 756.86,
        "temperature": 0,
        "text": " Let's draw a line down the middle.",
        "tokens": [
          51406,
          961,
          311,
          2642,
          257,
          1622,
          760,
          264,
          2808,
          13,
          51515
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 760.3,
        "id": 265,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 759.04,
        "temperature": 0,
        "text": " I think maybe visually it needs that.",
        "tokens": [
          51515,
          286,
          519,
          1310,
          19622,
          309,
          2203,
          300,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2707938144081517,
        "compression_ratio": 1.4863636363636363,
        "end": 763.5,
        "id": 266,
        "no_speech_prob": 0.00002931148264906369,
        "seek": 73602,
        "start": 760.3,
        "temperature": 0,
        "text": " I don't think I centered these correctly, but whatever.",
        "tokens": [
          51578,
          286,
          500,
          380,
          519,
          286,
          18988,
          613,
          8944,
          11,
          457,
          2035,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 769.62,
        "id": 267,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 766.6999999999999,
        "temperature": 0,
        "text": " Okay, okay, we're getting somewhere.",
        "tokens": [
          50398,
          1033,
          11,
          1392,
          11,
          321,
          434,
          1242,
          4079,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 771.3,
        "id": 268,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 769.62,
        "temperature": 0,
        "text": " Center, center, someone in the chat",
        "tokens": [
          50544,
          5169,
          11,
          3056,
          11,
          1580,
          294,
          264,
          5081,
          50628
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 774.42,
        "id": 269,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 771.3,
        "temperature": 0,
        "text": " is telling me to use center, center, why not?",
        "tokens": [
          50628,
          307,
          3585,
          385,
          281,
          764,
          3056,
          11,
          3056,
          11,
          983,
          406,
          30,
          50784
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 776.34,
        "id": 270,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 774.42,
        "temperature": 0,
        "text": " So that aligned it center vertically too.",
        "tokens": [
          50784,
          407,
          300,
          17962,
          309,
          3056,
          28450,
          886,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 778.9399999999999,
        "id": 271,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 776.34,
        "temperature": 0,
        "text": " Beautiful, thank you, well, that was an excellent suggestion.",
        "tokens": [
          50880,
          14724,
          11,
          1309,
          291,
          11,
          731,
          11,
          300,
          390,
          364,
          7103,
          16541,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 781.16,
        "id": 272,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 778.9399999999999,
        "temperature": 0,
        "text": " Okay, so now what I want to do is,",
        "tokens": [
          51010,
          1033,
          11,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          51121
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 782.78,
        "id": 273,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 781.16,
        "temperature": 0,
        "text": " guess what, we're ready.",
        "tokens": [
          51121,
          2041,
          437,
          11,
          321,
          434,
          1919,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 785.74,
        "id": 274,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 782.78,
        "temperature": 0,
        "text": " This is so, this is what I love about this problem.",
        "tokens": [
          51202,
          639,
          307,
          370,
          11,
          341,
          307,
          437,
          286,
          959,
          466,
          341,
          1154,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 790.74,
        "id": 275,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 785.74,
        "temperature": 0,
        "text": " We're ready for the neural network because we can do it.",
        "tokens": [
          51350,
          492,
          434,
          1919,
          337,
          264,
          18161,
          3209,
          570,
          321,
          393,
          360,
          309,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.24939754361011943,
        "compression_ratio": 1.64,
        "end": 794.18,
        "id": 276,
        "no_speech_prob": 0.00005225224595051259,
        "seek": 76602,
        "start": 792.26,
        "temperature": 0,
        "text": " So what do I need?",
        "tokens": [
          51676,
          407,
          437,
          360,
          286,
          643,
          30,
          51772
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 796.9399999999999,
        "id": 277,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 794.18,
        "temperature": 0,
        "text": " I want to make a, I'm going to call it brain.",
        "tokens": [
          50364,
          286,
          528,
          281,
          652,
          257,
          11,
          286,
          478,
          516,
          281,
          818,
          309,
          3567,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 798.38,
        "id": 278,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 796.9399999999999,
        "temperature": 0,
        "text": " I'm going to make a variable called brain.",
        "tokens": [
          50502,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          3567,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 799.4599999999999,
        "id": 279,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 798.38,
        "temperature": 0,
        "text": " It's going to be the neural network.",
        "tokens": [
          50574,
          467,
          311,
          516,
          281,
          312,
          264,
          18161,
          3209,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 802.7399999999999,
        "id": 280,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 799.4599999999999,
        "temperature": 0,
        "text": " Now, I just don't get a neural network in JavaScript",
        "tokens": [
          50628,
          823,
          11,
          286,
          445,
          500,
          380,
          483,
          257,
          18161,
          3209,
          294,
          15778,
          50792
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 805.2199999999999,
        "id": 281,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 802.7399999999999,
        "temperature": 0,
        "text": " just by the nature of programming JavaScript.",
        "tokens": [
          50792,
          445,
          538,
          264,
          3687,
          295,
          9410,
          15778,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 808.06,
        "id": 282,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 805.2199999999999,
        "temperature": 0,
        "text": " I'm getting it because I have imported already",
        "tokens": [
          50916,
          286,
          478,
          1242,
          309,
          570,
          286,
          362,
          25524,
          1217,
          51058
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 812.3399999999999,
        "id": 283,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 808.06,
        "temperature": 0,
        "text": " into my HTML file two files, nn.js and matrix.js.",
        "tokens": [
          51058,
          666,
          452,
          17995,
          3991,
          732,
          7098,
          11,
          297,
          77,
          13,
          25530,
          293,
          8141,
          13,
          25530,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 814.3,
        "id": 284,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 812.3399999999999,
        "temperature": 0,
        "text": " This is a little toy neural network library",
        "tokens": [
          51272,
          639,
          307,
          257,
          707,
          12058,
          18161,
          3209,
          6405,
          51370
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 816.66,
        "id": 285,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 814.3,
        "temperature": 0,
        "text": " that I developed and a whole set of video tutorials.",
        "tokens": [
          51370,
          300,
          286,
          4743,
          293,
          257,
          1379,
          992,
          295,
          960,
          17616,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 818.6999999999999,
        "id": 286,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 816.66,
        "temperature": 0,
        "text": " At some point in the future, I'm going to replace this",
        "tokens": [
          51488,
          1711,
          512,
          935,
          294,
          264,
          2027,
          11,
          286,
          478,
          516,
          281,
          7406,
          341,
          51590
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 821.6999999999999,
        "id": 287,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 818.6999999999999,
        "temperature": 0,
        "text": " with this new project called TensorFlow.js,",
        "tokens": [
          51590,
          365,
          341,
          777,
          1716,
          1219,
          37624,
          13,
          25530,
          11,
          51740
        ]
      },
      {
        "avg_logprob": -0.17168809230031531,
        "compression_ratio": 1.7711598746081505,
        "end": 823.5,
        "id": 288,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 79418,
        "start": 821.6999999999999,
        "temperature": 0,
        "text": " which is a lower level machine learning library",
        "tokens": [
          51740,
          597,
          307,
          257,
          3126,
          1496,
          3479,
          2539,
          6405,
          51830
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 825.46,
        "id": 289,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 823.9,
        "temperature": 0,
        "text": " also ML5 is this other library,",
        "tokens": [
          50384,
          611,
          21601,
          20,
          307,
          341,
          661,
          6405,
          11,
          50462
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 826.86,
        "id": 290,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 825.46,
        "temperature": 0,
        "text": " but I'll come back to that another time.",
        "tokens": [
          50462,
          457,
          286,
          603,
          808,
          646,
          281,
          300,
          1071,
          565,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 829.66,
        "id": 291,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 826.86,
        "temperature": 0,
        "text": " I'm still using this little toy neural network.",
        "tokens": [
          50532,
          286,
          478,
          920,
          1228,
          341,
          707,
          12058,
          18161,
          3209,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 831.66,
        "id": 292,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 829.66,
        "temperature": 0,
        "text": " So what I want to do now in the code",
        "tokens": [
          50672,
          407,
          437,
          286,
          528,
          281,
          360,
          586,
          294,
          264,
          3089,
          50772
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 834.14,
        "id": 293,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 831.66,
        "temperature": 0,
        "text": " is I just want to say brain in setup.",
        "tokens": [
          50772,
          307,
          286,
          445,
          528,
          281,
          584,
          3567,
          294,
          8657,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 837.86,
        "id": 294,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 834.14,
        "temperature": 0,
        "text": " I want to say brain equals a new neural network.",
        "tokens": [
          50896,
          286,
          528,
          281,
          584,
          3567,
          6915,
          257,
          777,
          18161,
          3209,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 842.86,
        "id": 295,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 837.86,
        "temperature": 0,
        "text": " Now, it expects three arguments, three arguments.",
        "tokens": [
          51082,
          823,
          11,
          309,
          33280,
          1045,
          12869,
          11,
          1045,
          12869,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 844.62,
        "id": 296,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 843.18,
        "temperature": 0,
        "text": " Now, this is not universal",
        "tokens": [
          51348,
          823,
          11,
          341,
          307,
          406,
          11455,
          51420
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 846.54,
        "id": 297,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 844.62,
        "temperature": 0,
        "text": " to how neural network libraries work.",
        "tokens": [
          51420,
          281,
          577,
          18161,
          3209,
          15148,
          589,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.22428505996177936,
        "compression_ratio": 1.7811158798283262,
        "end": 849.74,
        "id": 298,
        "no_speech_prob": 0.000019223149138269946,
        "seek": 82350,
        "start": 846.54,
        "temperature": 0,
        "text": " This is a very simple one that has very basic features.",
        "tokens": [
          51516,
          639,
          307,
          257,
          588,
          2199,
          472,
          300,
          575,
          588,
          3875,
          4122,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 854.1800000000001,
        "id": 299,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 849.74,
        "temperature": 0,
        "text": " And what it expects is how many inputs,",
        "tokens": [
          50364,
          400,
          437,
          309,
          33280,
          307,
          577,
          867,
          15743,
          11,
          50586
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 856.58,
        "id": 300,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 854.1800000000001,
        "temperature": 0,
        "text": " how many outputs and how many hidden nodes,",
        "tokens": [
          50586,
          577,
          867,
          23930,
          293,
          577,
          867,
          7633,
          13891,
          11,
          50706
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 859.3,
        "id": 301,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 856.58,
        "temperature": 0,
        "text": " but not in that order, inputs, hidden, outputs.",
        "tokens": [
          50706,
          457,
          406,
          294,
          300,
          1668,
          11,
          15743,
          11,
          7633,
          11,
          23930,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 861.66,
        "id": 302,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 859.3,
        "temperature": 0,
        "text": " So this we can see is three, three, two.",
        "tokens": [
          50842,
          407,
          341,
          321,
          393,
          536,
          307,
          1045,
          11,
          1045,
          11,
          732,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 863.0600000000001,
        "id": 303,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 861.66,
        "temperature": 0,
        "text": " That's the architecture,",
        "tokens": [
          50960,
          663,
          311,
          264,
          9482,
          11,
          51030
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 866.24,
        "id": 304,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 863.0600000000001,
        "temperature": 0,
        "text": " the model architecture that I have designed.",
        "tokens": [
          51030,
          264,
          2316,
          9482,
          300,
          286,
          362,
          4761,
          13,
          51189
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 868.4,
        "id": 305,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 866.24,
        "temperature": 0,
        "text": " Three, three, two.",
        "tokens": [
          51189,
          6244,
          11,
          1045,
          11,
          732,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 869.24,
        "id": 306,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 868.4,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          51297,
          22768,
          13,
          51339
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 871.66,
        "id": 307,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 869.24,
        "temperature": 0,
        "text": " Now, I'm done, I got it.",
        "tokens": [
          51339,
          823,
          11,
          286,
          478,
          1096,
          11,
          286,
          658,
          309,
          13,
          51460
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 873.34,
        "id": 308,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 871.66,
        "temperature": 0,
        "text": " Woohoo, okay, no, I have to keep going.",
        "tokens": [
          51460,
          10468,
          19069,
          11,
          1392,
          11,
          572,
          11,
          286,
          362,
          281,
          1066,
          516,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2850095717633357,
        "compression_ratio": 1.7272727272727273,
        "end": 876.5,
        "id": 309,
        "no_speech_prob": 0.000022125595933175646,
        "seek": 84974,
        "start": 873.34,
        "temperature": 0,
        "text": " Now what I can do is let's say every time,",
        "tokens": [
          51544,
          823,
          437,
          286,
          393,
          360,
          307,
          718,
          311,
          584,
          633,
          565,
          11,
          51702
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 881.5,
        "id": 310,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 876.5,
        "temperature": 0,
        "text": " so let's make a variable called which,",
        "tokens": [
          50364,
          370,
          718,
          311,
          652,
          257,
          7006,
          1219,
          597,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 884.5,
        "id": 311,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 882.06,
        "temperature": 0,
        "text": " like which one is better, black or white?",
        "tokens": [
          50642,
          411,
          597,
          472,
          307,
          1101,
          11,
          2211,
          420,
          2418,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 889.02,
        "id": 312,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 885.54,
        "temperature": 0,
        "text": " And I will just start with saying black.",
        "tokens": [
          50816,
          400,
          286,
          486,
          445,
          722,
          365,
          1566,
          2211,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 894.38,
        "id": 313,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 891.02,
        "temperature": 0,
        "text": " And what I'm going to do is let's do the same",
        "tokens": [
          51090,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          718,
          311,
          360,
          264,
          912,
          51258
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 896.84,
        "id": 314,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 894.38,
        "temperature": 0,
        "text": " sort of technique that Jibril did.",
        "tokens": [
          51258,
          1333,
          295,
          6532,
          300,
          508,
          6414,
          388,
          630,
          13,
          51381
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 899.98,
        "id": 315,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 896.84,
        "temperature": 0,
        "text": " If which equals black,",
        "tokens": [
          51381,
          759,
          597,
          6915,
          2211,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.28128071072735367,
        "compression_ratio": 1.5176470588235293,
        "end": 904.32,
        "id": 316,
        "no_speech_prob": 0.000008530239938409068,
        "seek": 87650,
        "start": 900.82,
        "temperature": 0,
        "text": " then I'm going to draw a circle.",
        "tokens": [
          51580,
          550,
          286,
          478,
          516,
          281,
          2642,
          257,
          6329,
          13,
          51755
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 910.5,
        "id": 317,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 906.78,
        "temperature": 0,
        "text": " A circle which is where?",
        "tokens": [
          50378,
          316,
          6329,
          597,
          307,
          689,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 915.5,
        "id": 318,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 910.5,
        "temperature": 0,
        "text": " At 200, 200, 300, 60, 60.",
        "tokens": [
          50564,
          1711,
          2331,
          11,
          2331,
          11,
          6641,
          11,
          4060,
          11,
          4060,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 922.94,
        "id": 319,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 917.94,
        "temperature": 0,
        "text": " There, and then else, if it's white,",
        "tokens": [
          50936,
          821,
          11,
          293,
          550,
          1646,
          11,
          498,
          309,
          311,
          2418,
          11,
          51186
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 926.06,
        "id": 320,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 923.7,
        "temperature": 0,
        "text": " then draw it at 400.",
        "tokens": [
          51224,
          550,
          2642,
          309,
          412,
          8423,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 928.64,
        "id": 321,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 926.06,
        "temperature": 0,
        "text": " And so this would be fill zero,",
        "tokens": [
          51342,
          400,
          370,
          341,
          576,
          312,
          2836,
          4018,
          11,
          51471
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 931.62,
        "id": 322,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 928.64,
        "temperature": 0,
        "text": " this would be fill 255, and we're still no stroke.",
        "tokens": [
          51471,
          341,
          576,
          312,
          2836,
          3552,
          20,
          11,
          293,
          321,
          434,
          920,
          572,
          12403,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.3137152535574777,
        "compression_ratio": 1.4335664335664335,
        "end": 933.42,
        "id": 323,
        "no_speech_prob": 0.00013341853627935052,
        "seek": 90650,
        "start": 931.62,
        "temperature": 0,
        "text": " Okay, so now,",
        "tokens": [
          51620,
          1033,
          11,
          370,
          586,
          11,
          51710
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 936.74,
        "id": 324,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 934.42,
        "temperature": 0,
        "text": " we see, oh, that's very far down.",
        "tokens": [
          50414,
          321,
          536,
          11,
          1954,
          11,
          300,
          311,
          588,
          1400,
          760,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 941.74,
        "id": 325,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 936.74,
        "temperature": 0,
        "text": " So let me move this up to 200.",
        "tokens": [
          50530,
          407,
          718,
          385,
          1286,
          341,
          493,
          281,
          2331,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 944.66,
        "id": 326,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 943.8199999999999,
        "temperature": 0,
        "text": " That's 200.",
        "tokens": [
          50884,
          663,
          311,
          2331,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 948.06,
        "id": 327,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 944.66,
        "temperature": 0,
        "text": " I have no sense of dimensions whatsoever.",
        "tokens": [
          50926,
          286,
          362,
          572,
          2020,
          295,
          12819,
          17076,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 948.9,
        "id": 328,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 948.06,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51096,
          10246,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 951.3399999999999,
        "id": 329,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 948.9,
        "temperature": 0,
        "text": " Oh, this looks weird now, it's not all centered, but fine.",
        "tokens": [
          51138,
          876,
          11,
          341,
          1542,
          3657,
          586,
          11,
          309,
          311,
          406,
          439,
          18988,
          11,
          457,
          2489,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 954.3,
        "id": 330,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 951.3399999999999,
        "temperature": 0,
        "text": " Oh, I can't, I can't take it, I can't take it.",
        "tokens": [
          51260,
          876,
          11,
          286,
          393,
          380,
          11,
          286,
          393,
          380,
          747,
          309,
          11,
          286,
          393,
          380,
          747,
          309,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 956.62,
        "id": 331,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 954.3,
        "temperature": 0,
        "text": " Let's move this.",
        "tokens": [
          51408,
          961,
          311,
          1286,
          341,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 959.4,
        "id": 332,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 956.62,
        "temperature": 0,
        "text": " I really shouldn't be doing this, but I'm going to.",
        "tokens": [
          51524,
          286,
          534,
          4659,
          380,
          312,
          884,
          341,
          11,
          457,
          286,
          478,
          516,
          281,
          13,
          51663
        ]
      },
      {
        "avg_logprob": -0.32183593358748996,
        "compression_ratio": 1.6237623762376239,
        "end": 961.9399999999999,
        "id": 333,
        "no_speech_prob": 0.00008092730422504246,
        "seek": 93342,
        "start": 959.4,
        "temperature": 0,
        "text": " Let's make this 100, 100,",
        "tokens": [
          51663,
          961,
          311,
          652,
          341,
          2319,
          11,
          2319,
          11,
          51790
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 965.94,
        "id": 334,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 962.94,
        "temperature": 0,
        "text": " and let's make this 200, 200.",
        "tokens": [
          50414,
          293,
          718,
          311,
          652,
          341,
          2331,
          11,
          2331,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 970.3800000000001,
        "id": 335,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 967.7800000000001,
        "temperature": 0,
        "text": " Ah, phew, okay, I feel better now.",
        "tokens": [
          50656,
          2438,
          11,
          280,
          17418,
          11,
          1392,
          11,
          286,
          841,
          1101,
          586,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 974.96,
        "id": 336,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 970.3800000000001,
        "temperature": 0,
        "text": " Okay, so it's always going to pick black right now,",
        "tokens": [
          50786,
          1033,
          11,
          370,
          309,
          311,
          1009,
          516,
          281,
          1888,
          2211,
          558,
          586,
          11,
          51015
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 979.36,
        "id": 337,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 974.96,
        "temperature": 0,
        "text": " because no matter what, I've just made which equal to black.",
        "tokens": [
          51015,
          570,
          572,
          1871,
          437,
          11,
          286,
          600,
          445,
          1027,
          597,
          2681,
          281,
          2211,
          13,
          51235
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 982.3000000000001,
        "id": 338,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 979.36,
        "temperature": 0,
        "text": " But I can use the neural network now.",
        "tokens": [
          51235,
          583,
          286,
          393,
          764,
          264,
          18161,
          3209,
          586,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 983.82,
        "id": 339,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 982.3000000000001,
        "temperature": 0,
        "text": " I can use the neural network.",
        "tokens": [
          51382,
          286,
          393,
          764,
          264,
          18161,
          3209,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 986.22,
        "id": 340,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 983.82,
        "temperature": 0,
        "text": " The neural network is my function approximator.",
        "tokens": [
          51458,
          440,
          18161,
          3209,
          307,
          452,
          2445,
          8542,
          1639,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 989.1800000000001,
        "id": 341,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 986.22,
        "temperature": 0,
        "text": " Let's actually write this code",
        "tokens": [
          51578,
          961,
          311,
          767,
          2464,
          341,
          3089,
          51726
        ]
      },
      {
        "avg_logprob": -0.2621472209965417,
        "compression_ratio": 1.635135135135135,
        "end": 991.3000000000001,
        "id": 342,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 96194,
        "start": 989.1800000000001,
        "temperature": 0,
        "text": " with our own non-neural network first,",
        "tokens": [
          51726,
          365,
          527,
          1065,
          2107,
          12,
          716,
          1807,
          3209,
          700,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 992.4399999999999,
        "id": 343,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 991.62,
        "temperature": 0,
        "text": " just to make this case.",
        "tokens": [
          50380,
          445,
          281,
          652,
          341,
          1389,
          13,
          50421
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 995.4599999999999,
        "id": 344,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 992.4399999999999,
        "temperature": 0,
        "text": " I'm going to write color predictor,",
        "tokens": [
          50421,
          286,
          478,
          516,
          281,
          2464,
          2017,
          6069,
          284,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 997.5799999999999,
        "id": 345,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 995.4599999999999,
        "temperature": 0,
        "text": " and I'm going to say get an RGB,",
        "tokens": [
          50572,
          293,
          286,
          478,
          516,
          281,
          584,
          483,
          364,
          31231,
          11,
          50678
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 999.3199999999999,
        "id": 346,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 997.5799999999999,
        "temperature": 0,
        "text": " and now if, I'm going to just say,",
        "tokens": [
          50678,
          293,
          586,
          498,
          11,
          286,
          478,
          516,
          281,
          445,
          584,
          11,
          50765
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1003.4,
        "id": 347,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 999.3199999999999,
        "temperature": 0,
        "text": " if R plus G plus B is greater than 300,",
        "tokens": [
          50765,
          498,
          497,
          1804,
          460,
          1804,
          363,
          307,
          5044,
          813,
          6641,
          11,
          50969
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1006.8199999999999,
        "id": 348,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 1003.4,
        "temperature": 0,
        "text": " then return black,",
        "tokens": [
          50969,
          550,
          2736,
          2211,
          11,
          51140
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1009.3,
        "id": 349,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 1006.8199999999999,
        "temperature": 0,
        "text": " else return white.",
        "tokens": [
          51140,
          1646,
          2736,
          2418,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1011.3,
        "id": 350,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 1009.3,
        "temperature": 0,
        "text": " So I'm going to do a hard-coded,",
        "tokens": [
          51264,
          407,
          286,
          478,
          516,
          281,
          360,
          257,
          1152,
          12,
          66,
          12340,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1013.8,
        "id": 351,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 1011.3,
        "temperature": 0,
        "text": " this is my own human learning algorithm.",
        "tokens": [
          51364,
          341,
          307,
          452,
          1065,
          1952,
          2539,
          9284,
          13,
          51489
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1015.6999999999999,
        "id": 352,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 1013.8,
        "temperature": 0,
        "text": " I've decided that this is what it means",
        "tokens": [
          51489,
          286,
          600,
          3047,
          300,
          341,
          307,
          437,
          309,
          1355,
          51584
        ]
      },
      {
        "avg_logprob": -0.2183704376220703,
        "compression_ratio": 1.646788990825688,
        "end": 1017.6999999999999,
        "id": 353,
        "no_speech_prob": 0.00009610196138964966,
        "seek": 99130,
        "start": 1015.6999999999999,
        "temperature": 0,
        "text": " to predict which color would be better,",
        "tokens": [
          51584,
          281,
          6069,
          597,
          2017,
          576,
          312,
          1101,
          11,
          51684
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1022.7,
        "id": 354,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1017.7,
        "temperature": 0,
        "text": " and then I'm going to say let which equal color predictor,",
        "tokens": [
          50364,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          718,
          597,
          2681,
          2017,
          6069,
          284,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1024.94,
        "id": 355,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1023.5400000000001,
        "temperature": 0,
        "text": " RGB.",
        "tokens": [
          50656,
          31231,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1029.5800000000002,
        "id": 356,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1024.94,
        "temperature": 0,
        "text": " So now, we can see it's making that prediction,",
        "tokens": [
          50726,
          407,
          586,
          11,
          321,
          393,
          536,
          309,
          311,
          1455,
          300,
          17630,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1030.94,
        "id": 357,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1029.5800000000002,
        "temperature": 0,
        "text": " based on my algorithm.",
        "tokens": [
          50958,
          2361,
          322,
          452,
          9284,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1034.02,
        "id": 358,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1030.94,
        "temperature": 0,
        "text": " I wrote an algorithm to make that prediction.",
        "tokens": [
          51026,
          286,
          4114,
          364,
          9284,
          281,
          652,
          300,
          17630,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1036.14,
        "id": 359,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1034.02,
        "temperature": 0,
        "text": " Now, so we've got this, we could be done.",
        "tokens": [
          51180,
          823,
          11,
          370,
          321,
          600,
          658,
          341,
          11,
          321,
          727,
          312,
          1096,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1037.74,
        "id": 360,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1036.14,
        "temperature": 0,
        "text": " No machine learning necessary.",
        "tokens": [
          51286,
          883,
          3479,
          2539,
          4818,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1039.8600000000001,
        "id": 361,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1037.74,
        "temperature": 0,
        "text": " I finished this project.",
        "tokens": [
          51366,
          286,
          4335,
          341,
          1716,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1041.3,
        "id": 362,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1039.8600000000001,
        "temperature": 0,
        "text": " Now what I want to do, though,",
        "tokens": [
          51472,
          823,
          437,
          286,
          528,
          281,
          360,
          11,
          1673,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1044.02,
        "id": 363,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1041.3,
        "temperature": 0,
        "text": " is I want to comment this out,",
        "tokens": [
          51544,
          307,
          286,
          528,
          281,
          2871,
          341,
          484,
          11,
          51680
        ]
      },
      {
        "avg_logprob": -0.1949290116628011,
        "compression_ratio": 1.685589519650655,
        "end": 1046.38,
        "id": 364,
        "no_speech_prob": 0.00000344657814821403,
        "seek": 101770,
        "start": 1044.02,
        "temperature": 0,
        "text": " and I'm going to say, what am I going to say?",
        "tokens": [
          51680,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          437,
          669,
          286,
          516,
          281,
          584,
          30,
          51798
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1049.7,
        "id": 365,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1046.38,
        "temperature": 0,
        "text": " I'm going to say, first, I need to make some inputs.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          11,
          700,
          11,
          286,
          643,
          281,
          652,
          512,
          15743,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1054.46,
        "id": 366,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1049.7,
        "temperature": 0,
        "text": " So the neural network library expects as inputs, right?",
        "tokens": [
          50530,
          407,
          264,
          18161,
          3209,
          6405,
          33280,
          382,
          15743,
          11,
          558,
          30,
          50768
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1057.16,
        "id": 367,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1054.46,
        "temperature": 0,
        "text": " My library expects, and this is pretty typical",
        "tokens": [
          50768,
          1222,
          6405,
          33280,
          11,
          293,
          341,
          307,
          1238,
          7476,
          50903
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1059.7800000000002,
        "id": 368,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1057.16,
        "temperature": 0,
        "text": " of any kind of machine learning-based library",
        "tokens": [
          50903,
          295,
          604,
          733,
          295,
          3479,
          2539,
          12,
          6032,
          6405,
          51034
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1060.8600000000001,
        "id": 369,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1059.7800000000002,
        "temperature": 0,
        "text": " that you might use.",
        "tokens": [
          51034,
          300,
          291,
          1062,
          764,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1063.3000000000002,
        "id": 370,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1060.8600000000001,
        "temperature": 0,
        "text": " It expects the inputs to come in",
        "tokens": [
          51088,
          467,
          33280,
          264,
          15743,
          281,
          808,
          294,
          51210
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1065.8400000000001,
        "id": 371,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1063.3000000000002,
        "temperature": 0,
        "text": " as an array of three numbers,",
        "tokens": [
          51210,
          382,
          364,
          10225,
          295,
          1045,
          3547,
          11,
          51337
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1069.42,
        "id": 372,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1067.0600000000002,
        "temperature": 0,
        "text": " and typically, you're going to want to have those numbers",
        "tokens": [
          51398,
          293,
          5850,
          11,
          291,
          434,
          516,
          281,
          528,
          281,
          362,
          729,
          3547,
          51516
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1072.1000000000001,
        "id": 373,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1069.42,
        "temperature": 0,
        "text": " normalized between zero and one.",
        "tokens": [
          51516,
          48704,
          1296,
          4018,
          293,
          472,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.21013677845830503,
        "compression_ratio": 1.7591836734693878,
        "end": 1074.94,
        "id": 374,
        "no_speech_prob": 0.0000018448236005497165,
        "seek": 104638,
        "start": 1072.1000000000001,
        "temperature": 0,
        "text": " So this is what I need to send into the neural network.",
        "tokens": [
          51650,
          407,
          341,
          307,
          437,
          286,
          643,
          281,
          2845,
          666,
          264,
          18161,
          3209,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1078.5200000000002,
        "id": 375,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1076.74,
        "temperature": 0,
        "text": " So inputs equals an array,",
        "tokens": [
          50382,
          407,
          15743,
          6915,
          364,
          10225,
          11,
          50471
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1080.38,
        "id": 376,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1078.5200000000002,
        "temperature": 0,
        "text": " and so how do I normalize these values?",
        "tokens": [
          50471,
          293,
          370,
          577,
          360,
          286,
          2710,
          1125,
          613,
          4190,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1082.5,
        "id": 377,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1080.38,
        "temperature": 0,
        "text": " I can just divide them all by 255.",
        "tokens": [
          50564,
          286,
          393,
          445,
          9845,
          552,
          439,
          538,
          3552,
          20,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1085.74,
        "id": 378,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1083.42,
        "temperature": 0,
        "text": " And again, more likely, there's going to be",
        "tokens": [
          50716,
          400,
          797,
          11,
          544,
          3700,
          11,
          456,
          311,
          516,
          281,
          312,
          50832
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1088.2800000000002,
        "id": 379,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1085.74,
        "temperature": 0,
        "text": " a much longer process of sort of cleaning",
        "tokens": [
          50832,
          257,
          709,
          2854,
          1399,
          295,
          1333,
          295,
          8924,
          50959
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1089.8200000000002,
        "id": 380,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1088.2800000000002,
        "temperature": 0,
        "text": " and normalizing your data,",
        "tokens": [
          50959,
          293,
          2710,
          3319,
          428,
          1412,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1093.0200000000002,
        "id": 381,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1089.8200000000002,
        "temperature": 0,
        "text": " but in this case of a single color, super easy to do.",
        "tokens": [
          51036,
          457,
          294,
          341,
          1389,
          295,
          257,
          2167,
          2017,
          11,
          1687,
          1858,
          281,
          360,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1095.7800000000002,
        "id": 382,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1093.0200000000002,
        "temperature": 0,
        "text": " Now, what I'm going to do is I'm going to ask",
        "tokens": [
          51196,
          823,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          1029,
          51334
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1097.74,
        "id": 383,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1095.7800000000002,
        "temperature": 0,
        "text": " for the output from the neural network.",
        "tokens": [
          51334,
          337,
          264,
          5598,
          490,
          264,
          18161,
          3209,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1101.22,
        "id": 384,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1098.72,
        "temperature": 0,
        "text": " Let outputs equal, and I'm going to say,",
        "tokens": [
          51481,
          961,
          23930,
          2681,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          51606
        ]
      },
      {
        "avg_logprob": -0.2220122067982914,
        "compression_ratio": 1.6082089552238805,
        "end": 1103.9,
        "id": 385,
        "no_speech_prob": 0.000009368705832457636,
        "seek": 107638,
        "start": 1101.22,
        "temperature": 0,
        "text": " brain dot, and the function, right?",
        "tokens": [
          51606,
          3567,
          5893,
          11,
          293,
          264,
          2445,
          11,
          558,
          30,
          51740
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1106.7,
        "id": 386,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1103.9,
        "temperature": 0,
        "text": " The function to do the feed forward algorithm",
        "tokens": [
          50364,
          440,
          2445,
          281,
          360,
          264,
          3154,
          2128,
          9284,
          50504
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1109.18,
        "id": 387,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1106.7,
        "temperature": 0,
        "text": " to send the data through and get the result back",
        "tokens": [
          50504,
          281,
          2845,
          264,
          1412,
          807,
          293,
          483,
          264,
          1874,
          646,
          50628
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1111.5,
        "id": 388,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1109.18,
        "temperature": 0,
        "text": " in my library is called predict,",
        "tokens": [
          50628,
          294,
          452,
          6405,
          307,
          1219,
          6069,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1112.6200000000001,
        "id": 389,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1111.5,
        "temperature": 0,
        "text": " because I'm making a prediction.",
        "tokens": [
          50744,
          570,
          286,
          478,
          1455,
          257,
          17630,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1114.8200000000002,
        "id": 390,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1112.6200000000001,
        "temperature": 0,
        "text": " Another term for this might be inference,",
        "tokens": [
          50800,
          3996,
          1433,
          337,
          341,
          1062,
          312,
          38253,
          11,
          50910
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1116.74,
        "id": 391,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1114.8200000000002,
        "temperature": 0,
        "text": " guess, that type of thing.",
        "tokens": [
          50910,
          2041,
          11,
          300,
          2010,
          295,
          551,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1119.5400000000002,
        "id": 392,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1117.5800000000002,
        "temperature": 0,
        "text": " So I'm going to say brain dot predict,",
        "tokens": [
          51048,
          407,
          286,
          478,
          516,
          281,
          584,
          3567,
          5893,
          6069,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1122.5600000000002,
        "id": 393,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1120.42,
        "temperature": 0,
        "text": " and I'm going to pass in the inputs.",
        "tokens": [
          51190,
          293,
          286,
          478,
          516,
          281,
          1320,
          294,
          264,
          15743,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1127.3400000000001,
        "id": 394,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1122.5600000000002,
        "temperature": 0,
        "text": " Now, let me just, let me just console log those outputs",
        "tokens": [
          51297,
          823,
          11,
          718,
          385,
          445,
          11,
          718,
          385,
          445,
          11076,
          3565,
          729,
          23930,
          51536
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1131.46,
        "id": 395,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1128.7,
        "temperature": 0,
        "text": " just so we can see, and this is going to sort of break,",
        "tokens": [
          51604,
          445,
          370,
          321,
          393,
          536,
          11,
          293,
          341,
          307,
          516,
          281,
          1333,
          295,
          1821,
          11,
          51742
        ]
      },
      {
        "avg_logprob": -0.21337668840275253,
        "compression_ratio": 1.724907063197026,
        "end": 1133.7,
        "id": 396,
        "no_speech_prob": 8.579224868299207e-7,
        "seek": 110390,
        "start": 1131.46,
        "temperature": 0,
        "text": " but let's just see what the outputs look like.",
        "tokens": [
          51742,
          457,
          718,
          311,
          445,
          536,
          437,
          264,
          23930,
          574,
          411,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1136.98,
        "id": 397,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1134.9,
        "temperature": 0,
        "text": " Whoa, hold on.",
        "tokens": [
          50414,
          7521,
          11,
          1797,
          322,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1140.66,
        "id": 398,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1138.7,
        "temperature": 0,
        "text": " Why is this, oh, because draw is,",
        "tokens": [
          50604,
          1545,
          307,
          341,
          11,
          1954,
          11,
          570,
          2642,
          307,
          11,
          50702
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1143.5800000000002,
        "id": 399,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1140.66,
        "temperature": 0,
        "text": " so one thing I just realized is I'm kind of,",
        "tokens": [
          50702,
          370,
          472,
          551,
          286,
          445,
          5334,
          307,
          286,
          478,
          733,
          295,
          11,
          50848
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1145.26,
        "id": 400,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1143.5800000000002,
        "temperature": 0,
        "text": " I'm doing all this in the draw loop,",
        "tokens": [
          50848,
          286,
          478,
          884,
          439,
          341,
          294,
          264,
          2642,
          6367,
          11,
          50932
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1149.9,
        "id": 401,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1145.26,
        "temperature": 0,
        "text": " which is sort of silly, so let me actually just say no loop,",
        "tokens": [
          50932,
          597,
          307,
          1333,
          295,
          11774,
          11,
          370,
          718,
          385,
          767,
          445,
          584,
          572,
          6367,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1151.7800000000002,
        "id": 402,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1149.9,
        "temperature": 0,
        "text": " and then in pick color,",
        "tokens": [
          51164,
          293,
          550,
          294,
          1888,
          2017,
          11,
          51258
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1156.3200000000002,
        "id": 403,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1154.14,
        "temperature": 0,
        "text": " in pick color, which is where,",
        "tokens": [
          51376,
          294,
          1888,
          2017,
          11,
          597,
          307,
          689,
          11,
          51485
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1158.14,
        "id": 404,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1157.3000000000002,
        "temperature": 0,
        "text": " where's the pick color?",
        "tokens": [
          51534,
          689,
          311,
          264,
          1888,
          2017,
          30,
          51576
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1160.0600000000002,
        "id": 405,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1158.14,
        "temperature": 0,
        "text": " Oh, right here, I'm going to say redraw.",
        "tokens": [
          51576,
          876,
          11,
          558,
          510,
          11,
          286,
          478,
          516,
          281,
          584,
          2182,
          5131,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1162.22,
        "id": 406,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1160.0600000000002,
        "temperature": 0,
        "text": " So I only want to like redraw the canvas up there.",
        "tokens": [
          51672,
          407,
          286,
          787,
          528,
          281,
          411,
          2182,
          5131,
          264,
          16267,
          493,
          456,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.26268448462853067,
        "compression_ratio": 1.688034188034188,
        "end": 1163.42,
        "id": 407,
        "no_speech_prob": 0.000033737152989488095,
        "seek": 113390,
        "start": 1162.22,
        "temperature": 0,
        "text": " I don't have anything animating,",
        "tokens": [
          51780,
          286,
          500,
          380,
          362,
          1340,
          2383,
          990,
          11,
          51840
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1164.78,
        "id": 408,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1163.94,
        "temperature": 0,
        "text": " so I don't need the draw loop",
        "tokens": [
          50390,
          370,
          286,
          500,
          380,
          643,
          264,
          2642,
          6367,
          50432
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1166.1000000000001,
        "id": 409,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1164.78,
        "temperature": 0,
        "text": " to be going over and over again.",
        "tokens": [
          50432,
          281,
          312,
          516,
          670,
          293,
          670,
          797,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1171.66,
        "id": 410,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1166.98,
        "temperature": 0,
        "text": " So cannot read property predict of undefined sketch such as,",
        "tokens": [
          50542,
          407,
          2644,
          1401,
          4707,
          6069,
          295,
          674,
          5666,
          2001,
          12325,
          1270,
          382,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1175.1000000000001,
        "id": 411,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1173.3000000000002,
        "temperature": 0,
        "text": " oh, you know what?",
        "tokens": [
          50858,
          1954,
          11,
          291,
          458,
          437,
          30,
          50948
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1176.46,
        "id": 412,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1175.1000000000001,
        "temperature": 0,
        "text": " Why do I have that bug?",
        "tokens": [
          50948,
          1545,
          360,
          286,
          362,
          300,
          7426,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1179.6000000000001,
        "id": 413,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1176.46,
        "temperature": 0,
        "text": " I created the neural network after I called pick color.",
        "tokens": [
          51016,
          286,
          2942,
          264,
          18161,
          3209,
          934,
          286,
          1219,
          1888,
          2017,
          13,
          51173
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1181.18,
        "id": 414,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1179.6000000000001,
        "temperature": 0,
        "text": " The neural network needs to exist",
        "tokens": [
          51173,
          440,
          18161,
          3209,
          2203,
          281,
          2514,
          51252
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1183.0800000000002,
        "id": 415,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1181.18,
        "temperature": 0,
        "text": " before I call pick color, okay?",
        "tokens": [
          51252,
          949,
          286,
          818,
          1888,
          2017,
          11,
          1392,
          30,
          51347
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1185.14,
        "id": 416,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1183.0800000000002,
        "temperature": 0,
        "text": " That's good to know, great.",
        "tokens": [
          51347,
          663,
          311,
          665,
          281,
          458,
          11,
          869,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1186.3400000000001,
        "id": 417,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1185.14,
        "temperature": 0,
        "text": " So we can see, look at this,",
        "tokens": [
          51450,
          407,
          321,
          393,
          536,
          11,
          574,
          412,
          341,
          11,
          51510
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1188.8000000000002,
        "id": 418,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1186.3400000000001,
        "temperature": 0,
        "text": " and why do I have this happen twice?",
        "tokens": [
          51510,
          293,
          983,
          360,
          286,
          362,
          341,
          1051,
          6091,
          30,
          51633
        ]
      },
      {
        "avg_logprob": -0.2756007937934455,
        "compression_ratio": 1.66,
        "end": 1191.46,
        "id": 419,
        "no_speech_prob": 0.00011061138502554968,
        "seek": 116342,
        "start": 1188.8000000000002,
        "temperature": 0,
        "text": " 29, why is that happening twice?",
        "tokens": [
          51633,
          9413,
          11,
          983,
          307,
          300,
          2737,
          6091,
          30,
          51766
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1196.7,
        "id": 420,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1192.3,
        "temperature": 0,
        "text": " You know, I guess it's going through the draw loop once.",
        "tokens": [
          50406,
          509,
          458,
          11,
          286,
          2041,
          309,
          311,
          516,
          807,
          264,
          2642,
          6367,
          1564,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1198.14,
        "id": 421,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1196.7,
        "temperature": 0,
        "text": " So maybe,",
        "tokens": [
          50626,
          407,
          1310,
          11,
          50698
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1202.78,
        "id": 422,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1201.94,
        "temperature": 0,
        "text": " yeah, interestingly.",
        "tokens": [
          50888,
          1338,
          11,
          25873,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1203.74,
        "id": 423,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1202.78,
        "temperature": 0,
        "text": " Okay, I'm not going to worry about,",
        "tokens": [
          50930,
          1033,
          11,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          11,
          50978
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1206.94,
        "id": 424,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1203.74,
        "temperature": 0,
        "text": " I'm not going to get, I'll fiddle with that later.",
        "tokens": [
          50978,
          286,
          478,
          406,
          516,
          281,
          483,
          11,
          286,
          603,
          24553,
          2285,
          365,
          300,
          1780,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1209.22,
        "id": 425,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1206.94,
        "temperature": 0,
        "text": " The point is, whoops.",
        "tokens": [
          51138,
          440,
          935,
          307,
          11,
          567,
          3370,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1213.42,
        "id": 426,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1211.08,
        "temperature": 0,
        "text": " Every time I click, we can see,",
        "tokens": [
          51345,
          2048,
          565,
          286,
          2052,
          11,
          321,
          393,
          536,
          11,
          51462
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1215.92,
        "id": 427,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1213.42,
        "temperature": 0,
        "text": " this is the output of the neural network.",
        "tokens": [
          51462,
          341,
          307,
          264,
          5598,
          295,
          264,
          18161,
          3209,
          13,
          51587
        ]
      },
      {
        "avg_logprob": -0.28609177617743464,
        "compression_ratio": 1.5240384615384615,
        "end": 1218.8600000000001,
        "id": 428,
        "no_speech_prob": 0.00001544629776617512,
        "seek": 119146,
        "start": 1215.92,
        "temperature": 0,
        "text": " It's an array with two floating point numbers,",
        "tokens": [
          51587,
          467,
          311,
          364,
          10225,
          365,
          732,
          12607,
          935,
          3547,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1222.4599999999998,
        "id": 429,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1218.9799999999998,
        "temperature": 0,
        "text": " and those I'm considering to be like the probability, right?",
        "tokens": [
          50370,
          293,
          729,
          286,
          478,
          8079,
          281,
          312,
          411,
          264,
          8482,
          11,
          558,
          30,
          50544
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1226.2199999999998,
        "id": 430,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1222.4599999999998,
        "temperature": 0,
        "text": " If this number is higher, it should be a white,",
        "tokens": [
          50544,
          759,
          341,
          1230,
          307,
          2946,
          11,
          309,
          820,
          312,
          257,
          2418,
          11,
          50732
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1228.02,
        "id": 431,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1226.2199999999998,
        "temperature": 0,
        "text": " maybe black is the correct color.",
        "tokens": [
          50732,
          1310,
          2211,
          307,
          264,
          3006,
          2017,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1229.82,
        "id": 432,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1228.02,
        "temperature": 0,
        "text": " If this number is higher, the other one,",
        "tokens": [
          50822,
          759,
          341,
          1230,
          307,
          2946,
          11,
          264,
          661,
          472,
          11,
          50912
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1230.8999999999999,
        "id": 433,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1229.82,
        "temperature": 0,
        "text": " whoops, my hand disappeared,",
        "tokens": [
          50912,
          567,
          3370,
          11,
          452,
          1011,
          13954,
          11,
          50966
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1232.1599999999999,
        "id": 434,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1230.8999999999999,
        "temperature": 0,
        "text": " the white color should be the one.",
        "tokens": [
          50966,
          264,
          2418,
          2017,
          820,
          312,
          264,
          472,
          13,
          51029
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1234.4199999999998,
        "id": 435,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1232.1599999999999,
        "temperature": 0,
        "text": " Now, I haven't implemented some things.",
        "tokens": [
          51029,
          823,
          11,
          286,
          2378,
          380,
          12270,
          512,
          721,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1236.4599999999998,
        "id": 436,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1234.4199999999998,
        "temperature": 0,
        "text": " There's a particular algorithm which I really should put",
        "tokens": [
          51142,
          821,
          311,
          257,
          1729,
          9284,
          597,
          286,
          534,
          820,
          829,
          51244
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1239.06,
        "id": 437,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1236.4599999999998,
        "temperature": 0,
        "text": " into my neural network library called Softmax.",
        "tokens": [
          51244,
          666,
          452,
          18161,
          3209,
          6405,
          1219,
          16985,
          41167,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1241.3,
        "id": 438,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1239.06,
        "temperature": 0,
        "text": " I'll have to make a video tutorial about that in the future",
        "tokens": [
          51374,
          286,
          603,
          362,
          281,
          652,
          257,
          960,
          7073,
          466,
          300,
          294,
          264,
          2027,
          51486
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1244.4199999999998,
        "id": 439,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1241.3,
        "temperature": 0,
        "text": " which would ensure that these two numbers,",
        "tokens": [
          51486,
          597,
          576,
          5586,
          300,
          613,
          732,
          3547,
          11,
          51642
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1246.58,
        "id": 440,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1244.4199999999998,
        "temperature": 0,
        "text": " these add up to a total of one",
        "tokens": [
          51642,
          613,
          909,
          493,
          281,
          257,
          3217,
          295,
          472,
          51750
        ]
      },
      {
        "avg_logprob": -0.22911958436708194,
        "compression_ratio": 1.7476635514018692,
        "end": 1248.4599999999998,
        "id": 441,
        "no_speech_prob": 0.00013982196105644107,
        "seek": 121886,
        "start": 1246.58,
        "temperature": 0,
        "text": " and really represent a probability,",
        "tokens": [
          51750,
          293,
          534,
          2906,
          257,
          8482,
          11,
          51844
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1249.9,
        "id": 442,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1249.06,
        "temperature": 0,
        "text": " but my neural network is very simple.",
        "tokens": [
          50394,
          457,
          452,
          18161,
          3209,
          307,
          588,
          2199,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1252.9,
        "id": 443,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1249.9,
        "temperature": 0,
        "text": " I can just look at which of these output numbers is bigger.",
        "tokens": [
          50436,
          286,
          393,
          445,
          574,
          412,
          597,
          295,
          613,
          5598,
          3547,
          307,
          3801,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1257.9,
        "id": 444,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1252.9,
        "temperature": 0,
        "text": " So I can say then, right here, I can say now,",
        "tokens": [
          50586,
          407,
          286,
          393,
          584,
          550,
          11,
          558,
          510,
          11,
          286,
          393,
          584,
          586,
          11,
          50836
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1262.58,
        "id": 445,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1257.94,
        "temperature": 0,
        "text": " if outputs index zero is greater than outputs index one,",
        "tokens": [
          50838,
          498,
          23930,
          8186,
          4018,
          307,
          5044,
          813,
          23930,
          8186,
          472,
          11,
          51070
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1266.82,
        "id": 446,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1262.58,
        "temperature": 0,
        "text": " we'll make that mean return black,",
        "tokens": [
          51070,
          321,
          603,
          652,
          300,
          914,
          2736,
          2211,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1272.7,
        "id": 447,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1268.98,
        "temperature": 0,
        "text": " otherwise, return white.",
        "tokens": [
          51390,
          5911,
          11,
          2736,
          2418,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.24732255374684053,
        "compression_ratio": 1.5538461538461539,
        "end": 1276.74,
        "id": 448,
        "no_speech_prob": 0.000005093703293823637,
        "seek": 124846,
        "start": 1272.7,
        "temperature": 0,
        "text": " So now, I have my color predictor function",
        "tokens": [
          51576,
          407,
          586,
          11,
          286,
          362,
          452,
          2017,
          6069,
          284,
          2445,
          51778
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1279.7,
        "id": 449,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1276.74,
        "temperature": 0,
        "text": " no longer uses a hard-coded algorithm,",
        "tokens": [
          50364,
          572,
          2854,
          4960,
          257,
          1152,
          12,
          66,
          12340,
          9284,
          11,
          50512
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1282.5,
        "id": 450,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1279.7,
        "temperature": 0,
        "text": " it uses the results of sending the input data",
        "tokens": [
          50512,
          309,
          4960,
          264,
          3542,
          295,
          7750,
          264,
          4846,
          1412,
          50652
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1284.02,
        "id": 451,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1282.5,
        "temperature": 0,
        "text": " through a neural network.",
        "tokens": [
          50652,
          807,
          257,
          18161,
          3209,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1287.26,
        "id": 452,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1284.02,
        "temperature": 0,
        "text": " So let's go ahead and run this.",
        "tokens": [
          50728,
          407,
          718,
          311,
          352,
          2286,
          293,
          1190,
          341,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1289.66,
        "id": 453,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1288.34,
        "temperature": 0,
        "text": " And I can click, now you can see here,",
        "tokens": [
          50944,
          400,
          286,
          393,
          2052,
          11,
          586,
          291,
          393,
          536,
          510,
          11,
          51010
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1292.6200000000001,
        "id": 454,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1289.66,
        "temperature": 0,
        "text": " it's kind of always picking white.",
        "tokens": [
          51010,
          309,
          311,
          733,
          295,
          1009,
          8867,
          2418,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1295.22,
        "id": 455,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1292.6200000000001,
        "temperature": 0,
        "text": " If I refresh, still always picking white.",
        "tokens": [
          51158,
          759,
          286,
          15134,
          11,
          920,
          1009,
          8867,
          2418,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1297.58,
        "id": 456,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1295.22,
        "temperature": 0,
        "text": " If I refresh, it's kind of always picking black.",
        "tokens": [
          51288,
          759,
          286,
          15134,
          11,
          309,
          311,
          733,
          295,
          1009,
          8867,
          2211,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1299.1,
        "id": 457,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1297.58,
        "temperature": 0,
        "text": " So what's going on here?",
        "tokens": [
          51406,
          407,
          437,
          311,
          516,
          322,
          510,
          30,
          51482
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1300.54,
        "id": 458,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1299.1,
        "temperature": 0,
        "text": " How come this isn't working?",
        "tokens": [
          51482,
          1012,
          808,
          341,
          1943,
          380,
          1364,
          30,
          51554
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1302.7,
        "id": 459,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1300.54,
        "temperature": 0,
        "text": " Why is this not learned properly?",
        "tokens": [
          51554,
          1545,
          307,
          341,
          406,
          3264,
          6108,
          30,
          51662
        ]
      },
      {
        "avg_logprob": -0.21962283767816673,
        "compression_ratio": 1.776,
        "end": 1306.3,
        "id": 460,
        "no_speech_prob": 0.00015843583969399333,
        "seek": 127674,
        "start": 1302.7,
        "temperature": 0,
        "text": " Which color should go on top of the other color?",
        "tokens": [
          51662,
          3013,
          2017,
          820,
          352,
          322,
          1192,
          295,
          264,
          661,
          2017,
          30,
          51842
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1307.6599999999999,
        "id": 461,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1306.3,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          50364,
          17795,
          437,
          30,
          50432
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1311.6599999999999,
        "id": 462,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1307.6599999999999,
        "temperature": 0,
        "text": " The entire mechanic, all of the settings,",
        "tokens": [
          50432,
          440,
          2302,
          23860,
          11,
          439,
          295,
          264,
          6257,
          11,
          50632
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1313.3,
        "id": 463,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1311.6599999999999,
        "temperature": 0,
        "text": " all of the parameters, all of the weights",
        "tokens": [
          50632,
          439,
          295,
          264,
          9834,
          11,
          439,
          295,
          264,
          17443,
          50714
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1315.18,
        "id": 464,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1313.3,
        "temperature": 0,
        "text": " of all these connections of the neural network",
        "tokens": [
          50714,
          295,
          439,
          613,
          9271,
          295,
          264,
          18161,
          3209,
          50808
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1318.02,
        "id": 465,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1315.18,
        "temperature": 0,
        "text": " were initialized completely randomly.",
        "tokens": [
          50808,
          645,
          5883,
          1602,
          2584,
          16979,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1320.3,
        "id": 466,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1318.02,
        "temperature": 0,
        "text": " A neural network isn't just going to learn",
        "tokens": [
          50950,
          316,
          18161,
          3209,
          1943,
          380,
          445,
          516,
          281,
          1466,
          51064
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1323.3799999999999,
        "id": 467,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1320.3,
        "temperature": 0,
        "text": " as if by magic, it needs to be taught.",
        "tokens": [
          51064,
          382,
          498,
          538,
          5585,
          11,
          309,
          2203,
          281,
          312,
          5928,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1325.54,
        "id": 468,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1323.3799999999999,
        "temperature": 0,
        "text": " And there are lots of different strategies",
        "tokens": [
          51218,
          400,
          456,
          366,
          3195,
          295,
          819,
          9029,
          51326
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1327.82,
        "id": 469,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1325.54,
        "temperature": 0,
        "text": " for training and working with a neural network.",
        "tokens": [
          51326,
          337,
          3097,
          293,
          1364,
          365,
          257,
          18161,
          3209,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1330.22,
        "id": 470,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1327.82,
        "temperature": 0,
        "text": " One of those strategies is something called",
        "tokens": [
          51440,
          1485,
          295,
          729,
          9029,
          307,
          746,
          1219,
          51560
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1331.6599999999999,
        "id": 471,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1330.22,
        "temperature": 0,
        "text": " supervised learning.",
        "tokens": [
          51560,
          46533,
          2539,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.23641726066326274,
        "compression_ratio": 1.773076923076923,
        "end": 1333.62,
        "id": 472,
        "no_speech_prob": 0.000007889250809967052,
        "seek": 130630,
        "start": 1331.6599999999999,
        "temperature": 0,
        "text": " And you probably can't supervise learning,",
        "tokens": [
          51632,
          400,
          291,
          1391,
          393,
          380,
          37971,
          908,
          2539,
          11,
          51730
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1336.02,
        "id": 473,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1333.62,
        "temperature": 0,
        "text": " which I have covered in other videos,",
        "tokens": [
          50364,
          597,
          286,
          362,
          5343,
          294,
          661,
          2145,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1339.9799999999998,
        "id": 474,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1336.02,
        "temperature": 0,
        "text": " in particular, my doodle classification coding challenge.",
        "tokens": [
          50484,
          294,
          1729,
          11,
          452,
          360,
          30013,
          21538,
          17720,
          3430,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1342.4799999999998,
        "id": 475,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1339.9799999999998,
        "temperature": 0,
        "text": " So you might look at that as an example.",
        "tokens": [
          50682,
          407,
          291,
          1062,
          574,
          412,
          300,
          382,
          364,
          1365,
          13,
          50807
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1343.32,
        "id": 476,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1342.4799999999998,
        "temperature": 0,
        "text": " But what's going on here?",
        "tokens": [
          50807,
          583,
          437,
          311,
          516,
          322,
          510,
          30,
          50849
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1347.1999999999998,
        "id": 477,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1343.32,
        "temperature": 0,
        "text": " So in a sort of normal, more data science-driven",
        "tokens": [
          50849,
          407,
          294,
          257,
          1333,
          295,
          2710,
          11,
          544,
          1412,
          3497,
          12,
          25456,
          51043
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1350.1599999999999,
        "id": 478,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1347.1999999999998,
        "temperature": 0,
        "text": " machine learning context, we might prepare",
        "tokens": [
          51043,
          3479,
          2539,
          4319,
          11,
          321,
          1062,
          5940,
          51191
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1352.1,
        "id": 479,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1350.1599999999999,
        "temperature": 0,
        "text": " a giant training set.",
        "tokens": [
          51191,
          257,
          7410,
          3097,
          992,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1353.76,
        "id": 480,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1352.1,
        "temperature": 0,
        "text": " I'm going to make a big spreadsheet",
        "tokens": [
          51288,
          286,
          478,
          516,
          281,
          652,
          257,
          955,
          27733,
          51371
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1355.7399999999998,
        "id": 481,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1353.76,
        "temperature": 0,
        "text": " of every RGB color I can think of,",
        "tokens": [
          51371,
          295,
          633,
          31231,
          2017,
          286,
          393,
          519,
          295,
          11,
          51470
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1358.26,
        "id": 482,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1355.7399999999998,
        "temperature": 0,
        "text": " and which one looks better, black or white.",
        "tokens": [
          51470,
          293,
          597,
          472,
          1542,
          1101,
          11,
          2211,
          420,
          2418,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1361.28,
        "id": 483,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1358.26,
        "temperature": 0,
        "text": " That's my training data set to pass through",
        "tokens": [
          51596,
          663,
          311,
          452,
          3097,
          1412,
          992,
          281,
          1320,
          807,
          51747
        ]
      },
      {
        "avg_logprob": -0.2209954410791397,
        "compression_ratio": 1.5858585858585859,
        "end": 1362.9399999999998,
        "id": 484,
        "no_speech_prob": 0.00006709212902933359,
        "seek": 133362,
        "start": 1361.28,
        "temperature": 0,
        "text": " and train this neural network with.",
        "tokens": [
          51747,
          293,
          3847,
          341,
          18161,
          3209,
          365,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1365.14,
        "id": 485,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1362.94,
        "temperature": 0,
        "text": " Then I'm going to have a testing data set.",
        "tokens": [
          50364,
          1396,
          286,
          478,
          516,
          281,
          362,
          257,
          4997,
          1412,
          992,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1367.78,
        "id": 486,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1365.14,
        "temperature": 0,
        "text": " And that testing data set is not part",
        "tokens": [
          50474,
          400,
          300,
          4997,
          1412,
          992,
          307,
          406,
          644,
          50606
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1369.74,
        "id": 487,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1367.78,
        "temperature": 0,
        "text": " of the training data set, because I don't want",
        "tokens": [
          50606,
          295,
          264,
          3097,
          1412,
          992,
          11,
          570,
          286,
          500,
          380,
          528,
          50704
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1371.06,
        "id": 488,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1369.74,
        "temperature": 0,
        "text": " the neural network to know about it,",
        "tokens": [
          50704,
          264,
          18161,
          3209,
          281,
          458,
          466,
          309,
          11,
          50770
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1373.4,
        "id": 489,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1371.06,
        "temperature": 0,
        "text": " but it also has a bunch of label data,",
        "tokens": [
          50770,
          457,
          309,
          611,
          575,
          257,
          3840,
          295,
          7645,
          1412,
          11,
          50887
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1376.1000000000001,
        "id": 490,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1373.4,
        "temperature": 0,
        "text": " colors with black or white labels.",
        "tokens": [
          50887,
          4577,
          365,
          2211,
          420,
          2418,
          16949,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1377.3,
        "id": 491,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1376.1000000000001,
        "temperature": 0,
        "text": " Then I'm going to pass that through",
        "tokens": [
          51022,
          1396,
          286,
          478,
          516,
          281,
          1320,
          300,
          807,
          51082
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1379.42,
        "id": 492,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1377.3,
        "temperature": 0,
        "text": " and see how well the neural network does",
        "tokens": [
          51082,
          293,
          536,
          577,
          731,
          264,
          18161,
          3209,
          775,
          51188
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1380.74,
        "id": 493,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1379.42,
        "temperature": 0,
        "text": " guessing against those.",
        "tokens": [
          51188,
          17939,
          1970,
          729,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1382.54,
        "id": 494,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1380.74,
        "temperature": 0,
        "text": " And if it starts to do well, then I can say",
        "tokens": [
          51254,
          400,
          498,
          309,
          3719,
          281,
          360,
          731,
          11,
          550,
          286,
          393,
          584,
          51344
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1384.72,
        "id": 495,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1382.54,
        "temperature": 0,
        "text": " my model is complete, it has been trained,",
        "tokens": [
          51344,
          452,
          2316,
          307,
          3566,
          11,
          309,
          575,
          668,
          8895,
          11,
          51453
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1386.3400000000001,
        "id": 496,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1384.72,
        "temperature": 0,
        "text": " I can save it, and I can deploy it",
        "tokens": [
          51453,
          286,
          393,
          3155,
          309,
          11,
          293,
          286,
          393,
          7274,
          309,
          51534
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1388.2,
        "id": 497,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1386.3400000000001,
        "temperature": 0,
        "text": " in some application which has to pick",
        "tokens": [
          51534,
          294,
          512,
          3861,
          597,
          575,
          281,
          1888,
          51627
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1389.96,
        "id": 498,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1388.2,
        "temperature": 0,
        "text": " black or white on the fly.",
        "tokens": [
          51627,
          2211,
          420,
          2418,
          322,
          264,
          3603,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.2073894889054898,
        "compression_ratio": 1.855305466237942,
        "end": 1392.18,
        "id": 499,
        "no_speech_prob": 0.000057387496781302616,
        "seek": 136294,
        "start": 1389.96,
        "temperature": 0,
        "text": " But I'm not going to do any of that in this video.",
        "tokens": [
          51715,
          583,
          286,
          478,
          406,
          516,
          281,
          360,
          604,
          295,
          300,
          294,
          341,
          960,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1394.18,
        "id": 500,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1392.18,
        "temperature": 0,
        "text": " I'm going to live in sort of a loosey-goosey",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          1621,
          294,
          1333,
          295,
          257,
          9612,
          88,
          12,
          1571,
          541,
          88,
          50464
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1396.22,
        "id": 501,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1394.18,
        "temperature": 0,
        "text": " interactive world where I'm just going to",
        "tokens": [
          50464,
          15141,
          1002,
          689,
          286,
          478,
          445,
          516,
          281,
          50566
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1399.3,
        "id": 502,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1396.22,
        "temperature": 0,
        "text": " let it guess randomly, and I'm going to click",
        "tokens": [
          50566,
          718,
          309,
          2041,
          16979,
          11,
          293,
          286,
          478,
          516,
          281,
          2052,
          50720
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1400.5,
        "id": 503,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1399.3,
        "temperature": 0,
        "text": " in order to correct it.",
        "tokens": [
          50720,
          294,
          1668,
          281,
          3006,
          309,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1403.5800000000002,
        "id": 504,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1400.5,
        "temperature": 0,
        "text": " So I'm going to train the neural network",
        "tokens": [
          50780,
          407,
          286,
          478,
          516,
          281,
          3847,
          264,
          18161,
          3209,
          50934
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1406.54,
        "id": 505,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1403.5800000000002,
        "temperature": 0,
        "text": " one data point at a time with no training data,",
        "tokens": [
          50934,
          472,
          1412,
          935,
          412,
          257,
          565,
          365,
          572,
          3097,
          1412,
          11,
          51082
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1409.38,
        "id": 506,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1406.54,
        "temperature": 0,
        "text": " no testing data, just random data as I go.",
        "tokens": [
          51082,
          572,
          4997,
          1412,
          11,
          445,
          4974,
          1412,
          382,
          286,
          352,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1412.5,
        "id": 507,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1409.38,
        "temperature": 0,
        "text": " So you might think about how would you restructure this",
        "tokens": [
          51224,
          407,
          291,
          1062,
          519,
          466,
          577,
          576,
          291,
          1472,
          2885,
          341,
          51380
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1416.14,
        "id": 508,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1412.5,
        "temperature": 0,
        "text": " to in a more sort of traditional training,",
        "tokens": [
          51380,
          281,
          294,
          257,
          544,
          1333,
          295,
          5164,
          3097,
          11,
          51562
        ]
      },
      {
        "avg_logprob": -0.23557685593427238,
        "compression_ratio": 1.7478991596638656,
        "end": 1420.0600000000002,
        "id": 509,
        "no_speech_prob": 0.000008139679266605526,
        "seek": 139218,
        "start": 1416.14,
        "temperature": 0,
        "text": " testing, deployment context.",
        "tokens": [
          51562,
          4997,
          11,
          19317,
          4319,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1422.3799999999999,
        "id": 510,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1420.06,
        "temperature": 0,
        "text": " Okay, so I want to click, what I'm going to do here",
        "tokens": [
          50364,
          1033,
          11,
          370,
          286,
          528,
          281,
          2052,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          50480
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1425.2,
        "id": 511,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1422.3799999999999,
        "temperature": 0,
        "text": " is as the trainer, I'm going to click on the side",
        "tokens": [
          50480,
          307,
          382,
          264,
          21110,
          11,
          286,
          478,
          516,
          281,
          2052,
          322,
          264,
          1252,
          50621
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1427.06,
        "id": 512,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1425.2,
        "temperature": 0,
        "text": " of the canvas that I think looks better.",
        "tokens": [
          50621,
          295,
          264,
          16267,
          300,
          286,
          519,
          1542,
          1101,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1428.3,
        "id": 513,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1427.06,
        "temperature": 0,
        "text": " Like I think white looks better,",
        "tokens": [
          50714,
          1743,
          286,
          519,
          2418,
          1542,
          1101,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1429.36,
        "id": 514,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1428.3,
        "temperature": 0,
        "text": " so I'm going to click over here.",
        "tokens": [
          50776,
          370,
          286,
          478,
          516,
          281,
          2052,
          670,
          510,
          13,
          50829
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1432.22,
        "id": 515,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1429.36,
        "temperature": 0,
        "text": " Just to make this a little bit easier to follow,",
        "tokens": [
          50829,
          1449,
          281,
          652,
          341,
          257,
          707,
          857,
          3571,
          281,
          1524,
          11,
          50972
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1436.02,
        "id": 516,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1432.22,
        "temperature": 0,
        "text": " I'm also going into draw, I'm going to draw",
        "tokens": [
          50972,
          286,
          478,
          611,
          516,
          666,
          2642,
          11,
          286,
          478,
          516,
          281,
          2642,
          51162
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1441.02,
        "id": 517,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1436.02,
        "temperature": 0,
        "text": " a stroke weight four, stroke 255, zero,",
        "tokens": [
          51162,
          257,
          12403,
          3364,
          1451,
          11,
          12403,
          3552,
          20,
          11,
          4018,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.23163080997154362,
        "compression_ratio": 1.7882882882882882,
        "end": 1447.22,
        "id": 518,
        "no_speech_prob": 0.0000018448196215103962,
        "seek": 142006,
        "start": 1444.1599999999999,
        "temperature": 0,
        "text": " I guess I'm going to align, width divided by two, zero,",
        "tokens": [
          51569,
          286,
          2041,
          286,
          478,
          516,
          281,
          7975,
          11,
          11402,
          6666,
          538,
          732,
          11,
          4018,
          11,
          51722
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1449.9,
        "id": 519,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1447.22,
        "temperature": 0,
        "text": " width divided by two, height.",
        "tokens": [
          50364,
          11402,
          6666,
          538,
          732,
          11,
          6681,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1455.06,
        "id": 520,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1454.22,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50714,
          821,
          321,
          352,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1456.78,
        "id": 521,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1455.06,
        "temperature": 0,
        "text": " So I'm going to draw this so I can click,",
        "tokens": [
          50756,
          407,
          286,
          478,
          516,
          281,
          2642,
          341,
          370,
          286,
          393,
          2052,
          11,
          50842
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1459.8600000000001,
        "id": 522,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1456.78,
        "temperature": 0,
        "text": " why is these are totally not centered at all?",
        "tokens": [
          50842,
          983,
          307,
          613,
          366,
          3879,
          406,
          18988,
          412,
          439,
          30,
          50996
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1461.2,
        "id": 523,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1459.8600000000001,
        "temperature": 0,
        "text": " I'm like a lunatic.",
        "tokens": [
          50996,
          286,
          478,
          411,
          257,
          19039,
          2399,
          13,
          51063
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1463.7,
        "id": 524,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1462.06,
        "temperature": 0,
        "text": " These are not in the right place.",
        "tokens": [
          51106,
          1981,
          366,
          406,
          294,
          264,
          558,
          1081,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1466.02,
        "id": 525,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1463.7,
        "temperature": 0,
        "text": " I'm sorry, I have to correct that.",
        "tokens": [
          51188,
          286,
          478,
          2597,
          11,
          286,
          362,
          281,
          3006,
          300,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1467.3,
        "id": 526,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1466.02,
        "temperature": 0,
        "text": " It's making me crazy.",
        "tokens": [
          51304,
          467,
          311,
          1455,
          385,
          3219,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1470.26,
        "id": 527,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1468.18,
        "temperature": 0,
        "text": " It is, how wide is the window?",
        "tokens": [
          51412,
          467,
          307,
          11,
          577,
          4874,
          307,
          264,
          4910,
          30,
          51516
        ]
      },
      {
        "avg_logprob": -0.24810279499400745,
        "compression_ratio": 1.5384615384615385,
        "end": 1474.8600000000001,
        "id": 528,
        "no_speech_prob": 0.000023187427359516732,
        "seek": 144722,
        "start": 1470.26,
        "temperature": 0,
        "text": " It's 600 wide, 300 is the middle, oh, silly me.",
        "tokens": [
          51516,
          467,
          311,
          11849,
          4874,
          11,
          6641,
          307,
          264,
          2808,
          11,
          1954,
          11,
          11774,
          385,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1479.2199999999998,
        "id": 529,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1474.86,
        "temperature": 0,
        "text": " 150, 350, thank you very much.",
        "tokens": [
          50364,
          8451,
          11,
          18065,
          11,
          1309,
          291,
          588,
          709,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1483.78,
        "id": 530,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1479.2199999999998,
        "temperature": 0,
        "text": " No, 450, 450, thank you very much.",
        "tokens": [
          50582,
          883,
          11,
          26034,
          11,
          26034,
          11,
          1309,
          291,
          588,
          709,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1487.06,
        "id": 531,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1485.1399999999999,
        "temperature": 0,
        "text": " 150, just please bear with me.",
        "tokens": [
          50878,
          8451,
          11,
          445,
          1767,
          6155,
          365,
          385,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1491.6999999999998,
        "id": 532,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1488.62,
        "temperature": 0,
        "text": " 450, okay, now we're doing well.",
        "tokens": [
          51052,
          26034,
          11,
          1392,
          11,
          586,
          321,
          434,
          884,
          731,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1495.7199999999998,
        "id": 533,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1491.6999999999998,
        "temperature": 0,
        "text": " Okay, so now the idea here is every time I click over here,",
        "tokens": [
          51206,
          1033,
          11,
          370,
          586,
          264,
          1558,
          510,
          307,
          633,
          565,
          286,
          2052,
          670,
          510,
          11,
          51407
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1497.6999999999998,
        "id": 534,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1495.7199999999998,
        "temperature": 0,
        "text": " I want to teach the neural network",
        "tokens": [
          51407,
          286,
          528,
          281,
          2924,
          264,
          18161,
          3209,
          51506
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1499.9799999999998,
        "id": 535,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1497.6999999999998,
        "temperature": 0,
        "text": " which one I think it should be.",
        "tokens": [
          51506,
          597,
          472,
          286,
          519,
          309,
          820,
          312,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1501.4599999999998,
        "id": 536,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1499.9799999999998,
        "temperature": 0,
        "text": " So how do I do that?",
        "tokens": [
          51620,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          51694
        ]
      },
      {
        "avg_logprob": -0.2647916685860112,
        "compression_ratio": 1.5769230769230769,
        "end": 1504.4199999999998,
        "id": 537,
        "no_speech_prob": 0.00021995253337081522,
        "seek": 147486,
        "start": 1501.4599999999998,
        "temperature": 0,
        "text": " So I told you there was a function called predict,",
        "tokens": [
          51694,
          407,
          286,
          1907,
          291,
          456,
          390,
          257,
          2445,
          1219,
          6069,
          11,
          51842
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1508.9,
        "id": 538,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1504.94,
        "temperature": 0,
        "text": " and the function called predict would send in",
        "tokens": [
          50390,
          293,
          264,
          2445,
          1219,
          6069,
          576,
          2845,
          294,
          50588
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1511.8600000000001,
        "id": 539,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1508.9,
        "temperature": 0,
        "text": " the input data and give me an output prediction.",
        "tokens": [
          50588,
          264,
          4846,
          1412,
          293,
          976,
          385,
          364,
          5598,
          17630,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1513.22,
        "id": 540,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1511.8600000000001,
        "temperature": 0,
        "text": " Now what I want to do is I want to use",
        "tokens": [
          50736,
          823,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          764,
          50804
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1514.94,
        "id": 541,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1513.22,
        "temperature": 0,
        "text": " a different function called train.",
        "tokens": [
          50804,
          257,
          819,
          2445,
          1219,
          3847,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1520.1200000000001,
        "id": 542,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1516.02,
        "temperature": 0,
        "text": " So each time I click the mouse, where is that mouse, Pris?",
        "tokens": [
          50944,
          407,
          1184,
          565,
          286,
          2052,
          264,
          9719,
          11,
          689,
          307,
          300,
          9719,
          11,
          2114,
          271,
          30,
          51149
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1523.7,
        "id": 543,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1520.1200000000001,
        "temperature": 0,
        "text": " Before I pick the new color, I want to determine",
        "tokens": [
          51149,
          4546,
          286,
          1888,
          264,
          777,
          2017,
          11,
          286,
          528,
          281,
          6997,
          51328
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1526.7,
        "id": 544,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1523.7,
        "temperature": 0,
        "text": " is the mouse on the right side or the left side?",
        "tokens": [
          51328,
          307,
          264,
          9719,
          322,
          264,
          558,
          1252,
          420,
          264,
          1411,
          1252,
          30,
          51478
        ]
      },
      {
        "avg_logprob": -0.25660343523378726,
        "compression_ratio": 1.7534246575342465,
        "end": 1531.7,
        "id": 545,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 150442,
        "start": 1526.7,
        "temperature": 0,
        "text": " So if, so I want to create some inputs, which is an array.",
        "tokens": [
          51478,
          407,
          498,
          11,
          370,
          286,
          528,
          281,
          1884,
          512,
          15743,
          11,
          597,
          307,
          364,
          10225,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1537.7,
        "id": 546,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1532.7,
        "temperature": 0,
        "text": " Let me just, let puts, inputs, and if mouse x",
        "tokens": [
          50414,
          961,
          385,
          445,
          11,
          718,
          8137,
          11,
          15743,
          11,
          293,
          498,
          9719,
          2031,
          50664
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1541.66,
        "id": 547,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1539.06,
        "temperature": 0,
        "text": " is greater than width divided by two,",
        "tokens": [
          50732,
          307,
          5044,
          813,
          11402,
          6666,
          538,
          732,
          11,
          50862
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1546.1000000000001,
        "id": 548,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1541.66,
        "temperature": 0,
        "text": " then the correct, the correct, actually,",
        "tokens": [
          50862,
          550,
          264,
          3006,
          11,
          264,
          3006,
          11,
          767,
          11,
          51084
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1548.02,
        "id": 549,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1546.1000000000001,
        "temperature": 0,
        "text": " so I'm sorry, I want to create some targets.",
        "tokens": [
          51084,
          370,
          286,
          478,
          2597,
          11,
          286,
          528,
          281,
          1884,
          512,
          12911,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1549.06,
        "id": 550,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1548.02,
        "temperature": 0,
        "text": " This is known as targets.",
        "tokens": [
          51180,
          639,
          307,
          2570,
          382,
          12911,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1550.94,
        "id": 551,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1549.06,
        "temperature": 0,
        "text": " I mean, you can use different terms for all these things,",
        "tokens": [
          51232,
          286,
          914,
          11,
          291,
          393,
          764,
          819,
          2115,
          337,
          439,
          613,
          721,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1553.66,
        "id": 552,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1550.94,
        "temperature": 0,
        "text": " but targets are the target outputs I want.",
        "tokens": [
          51326,
          457,
          12911,
          366,
          264,
          3779,
          23930,
          286,
          528,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1556.46,
        "id": 553,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1553.66,
        "temperature": 0,
        "text": " So if I click on the right side,",
        "tokens": [
          51462,
          407,
          498,
          286,
          2052,
          322,
          264,
          558,
          1252,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.22993428239198488,
        "compression_ratio": 1.6788990825688073,
        "end": 1558.98,
        "id": 554,
        "no_speech_prob": 0.000020462895918171853,
        "seek": 153170,
        "start": 1556.46,
        "temperature": 0,
        "text": " I want the target outputs for white,",
        "tokens": [
          51602,
          286,
          528,
          264,
          3779,
          23930,
          337,
          2418,
          11,
          51728
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1561.78,
        "id": 555,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1559.18,
        "temperature": 0,
        "text": " and white means the second number",
        "tokens": [
          50374,
          293,
          2418,
          1355,
          264,
          1150,
          1230,
          50504
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1563.78,
        "id": 556,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1561.78,
        "temperature": 0,
        "text": " is greater than the first number.",
        "tokens": [
          50504,
          307,
          5044,
          813,
          264,
          700,
          1230,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1568.78,
        "id": 557,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1563.78,
        "temperature": 0,
        "text": " So the targets, if I click on the right, should be zero, one.",
        "tokens": [
          50604,
          407,
          264,
          12911,
          11,
          498,
          286,
          2052,
          322,
          264,
          558,
          11,
          820,
          312,
          4018,
          11,
          472,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1574.42,
        "id": 558,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1569.42,
        "temperature": 0,
        "text": " This is the correct, this is the correct output",
        "tokens": [
          50886,
          639,
          307,
          264,
          3006,
          11,
          341,
          307,
          264,
          3006,
          5598,
          51136
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1578.1,
        "id": 559,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1575.18,
        "temperature": 0,
        "text": " if, that I'm telling the neural network should be",
        "tokens": [
          51174,
          498,
          11,
          300,
          286,
          478,
          3585,
          264,
          18161,
          3209,
          820,
          312,
          51320
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1580.7,
        "id": 560,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1578.1,
        "temperature": 0,
        "text": " if I'm clicking on the right side.",
        "tokens": [
          51320,
          498,
          286,
          478,
          9697,
          322,
          264,
          558,
          1252,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.2499243637611126,
        "compression_ratio": 1.6612021857923498,
        "end": 1585.7,
        "id": 561,
        "no_speech_prob": 0.000015446301404153928,
        "seek": 155898,
        "start": 1580.7,
        "temperature": 0,
        "text": " Else, the targets, and I know I could use",
        "tokens": [
          51450,
          45472,
          11,
          264,
          12911,
          11,
          293,
          286,
          458,
          286,
          727,
          764,
          51700
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1589.14,
        "id": 562,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1586.66,
        "temperature": 0,
        "text": " one of those ternary blah blah blah things,",
        "tokens": [
          50412,
          472,
          295,
          729,
          256,
          1248,
          822,
          12288,
          12288,
          12288,
          721,
          11,
          50536
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1590.5800000000002,
        "id": 563,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1589.14,
        "temperature": 0,
        "text": " but this is just going to have to do.",
        "tokens": [
          50536,
          457,
          341,
          307,
          445,
          516,
          281,
          362,
          281,
          360,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1594.94,
        "id": 564,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1590.5800000000002,
        "temperature": 0,
        "text": " The targets are, if they're on the left,",
        "tokens": [
          50608,
          440,
          12911,
          366,
          11,
          498,
          436,
          434,
          322,
          264,
          1411,
          11,
          50826
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1596.3,
        "id": 565,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1594.94,
        "temperature": 0,
        "text": " should be one comma zero.",
        "tokens": [
          50826,
          820,
          312,
          472,
          22117,
          4018,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1598.38,
        "id": 566,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1596.3,
        "temperature": 0,
        "text": " Let's pick up the pace here, people.",
        "tokens": [
          50894,
          961,
          311,
          1888,
          493,
          264,
          11638,
          510,
          11,
          561,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1599.54,
        "id": 567,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1598.38,
        "temperature": 0,
        "text": " By people, I mean me, not you.",
        "tokens": [
          50998,
          3146,
          561,
          11,
          286,
          914,
          385,
          11,
          406,
          291,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1603.1000000000001,
        "id": 568,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1599.54,
        "temperature": 0,
        "text": " You're doing great if you're actually still watching this.",
        "tokens": [
          51056,
          509,
          434,
          884,
          869,
          498,
          291,
          434,
          767,
          920,
          1976,
          341,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1604.78,
        "id": 569,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1603.1000000000001,
        "temperature": 0,
        "text": " And now what I'm going to do is I'm going to say",
        "tokens": [
          51234,
          400,
          586,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          51318
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1608.44,
        "id": 570,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1604.78,
        "temperature": 0,
        "text": " brain.train, oh, I need those inputs.",
        "tokens": [
          51318,
          3567,
          13,
          83,
          7146,
          11,
          1954,
          11,
          286,
          643,
          729,
          15743,
          13,
          51501
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1611.42,
        "id": 571,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1608.44,
        "temperature": 0,
        "text": " So the inputs are the same exact thing I did here.",
        "tokens": [
          51501,
          407,
          264,
          15743,
          366,
          264,
          912,
          1900,
          551,
          286,
          630,
          510,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.21110599123198412,
        "compression_ratio": 1.7043795620437956,
        "end": 1614.82,
        "id": 572,
        "no_speech_prob": 0.00006709183071507141,
        "seek": 158570,
        "start": 1611.42,
        "temperature": 0,
        "text": " The inputs are the current RGB, and what I want to do",
        "tokens": [
          51650,
          440,
          15743,
          366,
          264,
          2190,
          31231,
          11,
          293,
          437,
          286,
          528,
          281,
          360,
          51820
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1618.1799999999998,
        "id": 573,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1614.86,
        "temperature": 0,
        "text": " is I want to say, hey, brain, train yourself",
        "tokens": [
          50366,
          307,
          286,
          528,
          281,
          584,
          11,
          4177,
          11,
          3567,
          11,
          3847,
          1803,
          50532
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1622.54,
        "id": 574,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1618.1799999999998,
        "temperature": 0,
        "text": " with these inputs with these targets.",
        "tokens": [
          50532,
          365,
          613,
          15743,
          365,
          613,
          12911,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1625.26,
        "id": 575,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1622.54,
        "temperature": 0,
        "text": " And in fact, this now is going to,",
        "tokens": [
          50750,
          400,
          294,
          1186,
          11,
          341,
          586,
          307,
          516,
          281,
          11,
          50886
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1627.1399999999999,
        "id": 576,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1625.26,
        "temperature": 0,
        "text": " neural network is going to, what is it going to do?",
        "tokens": [
          50886,
          18161,
          3209,
          307,
          516,
          281,
          11,
          437,
          307,
          309,
          516,
          281,
          360,
          30,
          50980
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1628.6599999999999,
        "id": 577,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1627.1399999999999,
        "temperature": 0,
        "text": " I'm saying, here are the inputs,",
        "tokens": [
          50980,
          286,
          478,
          1566,
          11,
          510,
          366,
          264,
          15743,
          11,
          51056
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1631.22,
        "id": 578,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1628.6599999999999,
        "temperature": 0,
        "text": " here are the correct outputs that go with those inputs.",
        "tokens": [
          51056,
          510,
          366,
          264,
          3006,
          23930,
          300,
          352,
          365,
          729,
          15743,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1633.1799999999998,
        "id": 579,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1631.22,
        "temperature": 0,
        "text": " Do whatever adjustments you need to do,",
        "tokens": [
          51184,
          1144,
          2035,
          18624,
          291,
          643,
          281,
          360,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1635.82,
        "id": 580,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1633.1799999999998,
        "temperature": 0,
        "text": " whether you were right or wrong, just figure it out.",
        "tokens": [
          51282,
          1968,
          291,
          645,
          558,
          420,
          2085,
          11,
          445,
          2573,
          309,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1637.34,
        "id": 581,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1635.82,
        "temperature": 0,
        "text": " And what is that figuring out?",
        "tokens": [
          51414,
          400,
          437,
          307,
          300,
          15213,
          484,
          30,
          51490
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1639.26,
        "id": 582,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1637.34,
        "temperature": 0,
        "text": " So interestingly enough, I think this is worth,",
        "tokens": [
          51490,
          407,
          25873,
          1547,
          11,
          286,
          519,
          341,
          307,
          3163,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.2409175237019857,
        "compression_ratio": 1.8037735849056604,
        "end": 1641.1799999999998,
        "id": 583,
        "no_speech_prob": 0.00004539774454315193,
        "seek": 161482,
        "start": 1639.26,
        "temperature": 0,
        "text": " even though this is covered in much more detail",
        "tokens": [
          51586,
          754,
          1673,
          341,
          307,
          5343,
          294,
          709,
          544,
          2607,
          51682
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1646.0600000000002,
        "id": 584,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1641.18,
        "temperature": 0,
        "text": " in my other videos, let's say the neural network,",
        "tokens": [
          50364,
          294,
          452,
          661,
          2145,
          11,
          718,
          311,
          584,
          264,
          18161,
          3209,
          11,
          50608
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1649.5800000000002,
        "id": 585,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1646.0600000000002,
        "temperature": 0,
        "text": " I feed in some inputs, and what it actually gives me",
        "tokens": [
          50608,
          286,
          3154,
          294,
          512,
          15743,
          11,
          293,
          437,
          309,
          767,
          2709,
          385,
          50784
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1654.5800000000002,
        "id": 586,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1649.5800000000002,
        "temperature": 0,
        "text": " is like 0.8, 0.2, right?",
        "tokens": [
          50784,
          307,
          411,
          1958,
          13,
          23,
          11,
          1958,
          13,
          17,
          11,
          558,
          30,
          51034
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1657.04,
        "id": 587,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1654.8200000000002,
        "temperature": 0,
        "text": " This is what it gives me as the outputs.",
        "tokens": [
          51046,
          639,
          307,
          437,
          309,
          2709,
          385,
          382,
          264,
          23930,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1661.3400000000001,
        "id": 588,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1657.9,
        "temperature": 0,
        "text": " But I gave it, I'm training it, I'm going to give it targets.",
        "tokens": [
          51200,
          583,
          286,
          2729,
          309,
          11,
          286,
          478,
          3097,
          309,
          11,
          286,
          478,
          516,
          281,
          976,
          309,
          12911,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1665.66,
        "id": 589,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1661.3400000000001,
        "temperature": 0,
        "text": " And the correct targets are zero, one.",
        "tokens": [
          51372,
          400,
          264,
          3006,
          12911,
          366,
          4018,
          11,
          472,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1668.98,
        "id": 590,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1665.66,
        "temperature": 0,
        "text": " That's the output that I wanted to get.",
        "tokens": [
          51588,
          663,
          311,
          264,
          5598,
          300,
          286,
          1415,
          281,
          483,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.20057858262106637,
        "compression_ratio": 1.6231884057971016,
        "end": 1670.42,
        "id": 591,
        "no_speech_prob": 0.0025509041734039783,
        "seek": 164118,
        "start": 1668.98,
        "temperature": 0,
        "text": " That's the correct output.",
        "tokens": [
          51754,
          663,
          311,
          264,
          3006,
          5598,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1671.78,
        "id": 592,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1670.46,
        "temperature": 0,
        "text": " So what the neural network does",
        "tokens": [
          50366,
          407,
          437,
          264,
          18161,
          3209,
          775,
          50432
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1674.9,
        "id": 593,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1671.78,
        "temperature": 0,
        "text": " is actually calculate something called an error.",
        "tokens": [
          50432,
          307,
          767,
          8873,
          746,
          1219,
          364,
          6713,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1677.14,
        "id": 594,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1674.9,
        "temperature": 0,
        "text": " And the error is really simple.",
        "tokens": [
          50588,
          400,
          264,
          6713,
          307,
          534,
          2199,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1682.14,
        "id": 595,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1677.14,
        "temperature": 0,
        "text": " It's simply the desired minus the guess,",
        "tokens": [
          50700,
          467,
          311,
          2935,
          264,
          14721,
          3175,
          264,
          2041,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1685.3000000000002,
        "id": 596,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1682.3400000000001,
        "temperature": 0,
        "text": " or the targets minus the prediction,",
        "tokens": [
          50960,
          420,
          264,
          12911,
          3175,
          264,
          17630,
          11,
          51108
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1687.18,
        "id": 597,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1685.3000000000002,
        "temperature": 0,
        "text": " or the targets minus the outputs.",
        "tokens": [
          51108,
          420,
          264,
          12911,
          3175,
          264,
          23930,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1691.38,
        "id": 598,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1687.18,
        "temperature": 0,
        "text": " So the error would actually be negative 0.8,",
        "tokens": [
          51202,
          407,
          264,
          6713,
          576,
          767,
          312,
          3671,
          1958,
          13,
          23,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1694.74,
        "id": 599,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1691.38,
        "temperature": 0,
        "text": " one minus, and 0.8, interestingly enough.",
        "tokens": [
          51412,
          472,
          3175,
          11,
          293,
          1958,
          13,
          23,
          11,
          25873,
          1547,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1695.94,
        "id": 600,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1694.74,
        "temperature": 0,
        "text": " Very symmetrical there.",
        "tokens": [
          51580,
          4372,
          40360,
          456,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1697.0600000000002,
        "id": 601,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1695.94,
        "temperature": 0,
        "text": " So this would be the error.",
        "tokens": [
          51640,
          407,
          341,
          576,
          312,
          264,
          6713,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.23497379950757297,
        "compression_ratio": 1.7625570776255708,
        "end": 1698.5800000000002,
        "id": 602,
        "no_speech_prob": 0.0000126069380712579,
        "seek": 167042,
        "start": 1697.0600000000002,
        "temperature": 0,
        "text": " And then what happens?",
        "tokens": [
          51696,
          400,
          550,
          437,
          2314,
          30,
          51772
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1700.4199999999998,
        "id": 603,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1698.58,
        "temperature": 0,
        "text": " Inside that train function,",
        "tokens": [
          50364,
          15123,
          300,
          3847,
          2445,
          11,
          50456
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1703.22,
        "id": 604,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1700.4199999999998,
        "temperature": 0,
        "text": " an algorithm called backpropagation happens.",
        "tokens": [
          50456,
          364,
          9284,
          1219,
          646,
          79,
          1513,
          559,
          399,
          2314,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1707.02,
        "id": 605,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1703.22,
        "temperature": 0,
        "text": " The backpropagation takes this error and sends it backwards.",
        "tokens": [
          50596,
          440,
          646,
          79,
          1513,
          559,
          399,
          2516,
          341,
          6713,
          293,
          14790,
          309,
          12204,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1709.8799999999999,
        "id": 606,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1707.02,
        "temperature": 0,
        "text": " So when I do prediction, I'm sending the data forward",
        "tokens": [
          50786,
          407,
          562,
          286,
          360,
          17630,
          11,
          286,
          478,
          7750,
          264,
          1412,
          2128,
          50929
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1711.1,
        "id": 607,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1709.8799999999999,
        "temperature": 0,
        "text": " through the neural network.",
        "tokens": [
          50929,
          807,
          264,
          18161,
          3209,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1713.76,
        "id": 608,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1711.1,
        "temperature": 0,
        "text": " The training process is about looking at the outputs,",
        "tokens": [
          50990,
          440,
          3097,
          1399,
          307,
          466,
          1237,
          412,
          264,
          23930,
          11,
          51123
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1716.3999999999999,
        "id": 609,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1713.76,
        "temperature": 0,
        "text": " calculating an error, and sending the error backwards",
        "tokens": [
          51123,
          28258,
          364,
          6713,
          11,
          293,
          7750,
          264,
          6713,
          12204,
          51255
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1717.24,
        "id": 610,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1716.3999999999999,
        "temperature": 0,
        "text": " through the network.",
        "tokens": [
          51255,
          807,
          264,
          3209,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1719.3,
        "id": 611,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1717.24,
        "temperature": 0,
        "text": " And all these little changes, all these weights",
        "tokens": [
          51297,
          400,
          439,
          613,
          707,
          2962,
          11,
          439,
          613,
          17443,
          51400
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1720.78,
        "id": 612,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1719.3,
        "temperature": 0,
        "text": " that are adding up numbers and doing all this math,",
        "tokens": [
          51400,
          300,
          366,
          5127,
          493,
          3547,
          293,
          884,
          439,
          341,
          5221,
          11,
          51474
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1721.8999999999999,
        "id": 613,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1720.78,
        "temperature": 0,
        "text": " they all get adjusted.",
        "tokens": [
          51474,
          436,
          439,
          483,
          19871,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1723.8999999999999,
        "id": 614,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1721.8999999999999,
        "temperature": 0,
        "text": " So the errors would adjust all the parameters.",
        "tokens": [
          51530,
          407,
          264,
          13603,
          576,
          4369,
          439,
          264,
          9834,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1724.82,
        "id": 615,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1723.8999999999999,
        "temperature": 0,
        "text": " And that's what's happening.",
        "tokens": [
          51630,
          400,
          300,
          311,
          437,
          311,
          2737,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.22042234792005297,
        "compression_ratio": 1.8517350157728707,
        "end": 1726.8999999999999,
        "id": 616,
        "no_speech_prob": 0.0005033338675275445,
        "seek": 169858,
        "start": 1724.82,
        "temperature": 0,
        "text": " Again, you can dive into my other tutorials",
        "tokens": [
          51676,
          3764,
          11,
          291,
          393,
          9192,
          666,
          452,
          661,
          17616,
          51780
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1729.02,
        "id": 617,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1726.9,
        "temperature": 0,
        "text": " which go through this in more detail.",
        "tokens": [
          50364,
          597,
          352,
          807,
          341,
          294,
          544,
          2607,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1731.66,
        "id": 618,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1729.02,
        "temperature": 0,
        "text": " But that's what's happening right here in this function.",
        "tokens": [
          50470,
          583,
          300,
          311,
          437,
          311,
          2737,
          558,
          510,
          294,
          341,
          2445,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1736.14,
        "id": 619,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1731.66,
        "temperature": 0,
        "text": " So we are ready to go.",
        "tokens": [
          50602,
          407,
          321,
          366,
          1919,
          281,
          352,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1738.46,
        "id": 620,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1737.6200000000001,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50900,
          1779,
          30,
          50942
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1739.2800000000002,
        "id": 621,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1738.46,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50942,
          1057,
          558,
          13,
          50983
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1742.26,
        "id": 622,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1740.3400000000001,
        "temperature": 0,
        "text": " So what I'm going to do, maybe we'll do,",
        "tokens": [
          51036,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          1310,
          321,
          603,
          360,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1744.0600000000002,
        "id": 623,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1742.26,
        "temperature": 0,
        "text": " I'm going to train this for a while.",
        "tokens": [
          51132,
          286,
          478,
          516,
          281,
          3847,
          341,
          337,
          257,
          1339,
          13,
          51222
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1746.5800000000002,
        "id": 624,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1745.38,
        "temperature": 0,
        "text": " If you're watching the edited version of this,",
        "tokens": [
          51288,
          759,
          291,
          434,
          1976,
          264,
          23016,
          3037,
          295,
          341,
          11,
          51348
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1747.7,
        "id": 625,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1746.5800000000002,
        "temperature": 0,
        "text": " it'll speed through fast.",
        "tokens": [
          51348,
          309,
          603,
          3073,
          807,
          2370,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.2955027726980356,
        "compression_ratio": 1.6482412060301508,
        "end": 1749.74,
        "id": 626,
        "no_speech_prob": 0.0001233921357197687,
        "seek": 172690,
        "start": 1747.7,
        "temperature": 0,
        "text": " If you're watching this live, here we go.",
        "tokens": [
          51404,
          759,
          291,
          434,
          1976,
          341,
          1621,
          11,
          510,
          321,
          352,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1751.22,
        "id": 627,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1750.38,
        "temperature": 0,
        "text": " Okay, I'm back.",
        "tokens": [
          50396,
          1033,
          11,
          286,
          478,
          646,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1752.06,
        "id": 628,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1751.22,
        "temperature": 0,
        "text": " So I tried training this for a while.",
        "tokens": [
          50438,
          407,
          286,
          3031,
          3097,
          341,
          337,
          257,
          1339,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1752.9,
        "id": 629,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1752.06,
        "temperature": 0,
        "text": " I tried talking about it for a little bit.",
        "tokens": [
          50480,
          286,
          3031,
          1417,
          466,
          309,
          337,
          257,
          707,
          857,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1753.74,
        "id": 630,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1752.9,
        "temperature": 0,
        "text": " I didn't really get very far, even though I think",
        "tokens": [
          50522,
          286,
          994,
          380,
          534,
          483,
          588,
          1400,
          11,
          754,
          1673,
          286,
          519,
          50564
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1754.56,
        "id": 631,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1753.74,
        "temperature": 0,
        "text": " you can see like, ah, I'm going to like, I'm picking.",
        "tokens": [
          50564,
          291,
          393,
          536,
          411,
          11,
          3716,
          11,
          286,
          478,
          516,
          281,
          411,
          11,
          286,
          478,
          8867,
          13,
          50605
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1755.4,
        "id": 632,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1754.56,
        "temperature": 0,
        "text": " And it's kind of actually, oops, no, I should really move.",
        "tokens": [
          50605,
          400,
          309,
          311,
          733,
          295,
          767,
          11,
          34166,
          11,
          572,
          11,
          286,
          820,
          534,
          1286,
          13,
          50647
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1756.24,
        "id": 633,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1755.4,
        "temperature": 0,
        "text": " It's giving me sort of different results.",
        "tokens": [
          50647,
          467,
          311,
          2902,
          385,
          1333,
          295,
          819,
          3542,
          13,
          50689
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1757.06,
        "id": 634,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1756.24,
        "temperature": 0,
        "text": " That's black.",
        "tokens": [
          50689,
          663,
          311,
          2211,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1757.9,
        "id": 635,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1757.06,
        "temperature": 0,
        "text": " This one is black.",
        "tokens": [
          50730,
          639,
          472,
          307,
          2211,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1758.74,
        "id": 636,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1757.9,
        "temperature": 0,
        "text": " That's correct.",
        "tokens": [
          50772,
          663,
          311,
          3006,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1759.56,
        "id": 637,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1758.74,
        "temperature": 0,
        "text": " That one is white.",
        "tokens": [
          50814,
          663,
          472,
          307,
          2418,
          13,
          50855
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1760.4,
        "id": 638,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1759.56,
        "temperature": 0,
        "text": " That's correct.",
        "tokens": [
          50855,
          663,
          311,
          3006,
          13,
          50897
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1761.24,
        "id": 639,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1760.4,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50897,
          2053,
          412,
          341,
          13,
          50939
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1762.06,
        "id": 640,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1761.24,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50939,
          865,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1762.9,
        "id": 641,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1762.06,
        "temperature": 0,
        "text": " Hey, I think we're good.",
        "tokens": [
          50980,
          1911,
          11,
          286,
          519,
          321,
          434,
          665,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1763.74,
        "id": 642,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1762.9,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51022,
          286,
          519,
          321,
          434,
          665,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1764.56,
        "id": 643,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1763.74,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51064,
          286,
          519,
          321,
          434,
          665,
          13,
          51105
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1765.4,
        "id": 644,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1764.56,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51105,
          286,
          519,
          321,
          434,
          665,
          13,
          51147
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1766.24,
        "id": 645,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1765.4,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51147,
          286,
          519,
          321,
          434,
          665,
          13,
          51189
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1767.06,
        "id": 646,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1766.24,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51189,
          286,
          519,
          321,
          434,
          665,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1767.9,
        "id": 647,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1767.06,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51230,
          286,
          519,
          321,
          434,
          665,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1768.74,
        "id": 648,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1767.9,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51272,
          286,
          519,
          321,
          434,
          665,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1769.56,
        "id": 649,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1768.74,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51314,
          286,
          519,
          321,
          434,
          665,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.3056745999597113,
        "compression_ratio": 2.381679389312977,
        "end": 1770.4,
        "id": 650,
        "no_speech_prob": 0.0008969131158664823,
        "seek": 174974,
        "start": 1769.56,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          51355,
          286,
          519,
          321,
          434,
          665,
          13,
          51397
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1772.22,
        "id": 651,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1770.72,
        "temperature": 1,
        "text": " Black is better with this one.",
        "tokens": [
          50380,
          4076,
          307,
          1101,
          365,
          341,
          472,
          13,
          50455
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1774.02,
        "id": 652,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1772.22,
        "temperature": 1,
        "text": " White is better.",
        "tokens": [
          50455,
          5552,
          307,
          1101,
          13,
          50545
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1775.74,
        "id": 653,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1774.9,
        "temperature": 1,
        "text": " I don't know.",
        "tokens": [
          50589,
          286,
          500,
          380,
          458,
          13,
          50631
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1776.5600000000002,
        "id": 654,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1775.74,
        "temperature": 1,
        "text": " White.",
        "tokens": [
          50631,
          5552,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1778.7,
        "id": 655,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1777.6200000000001,
        "temperature": 1,
        "text": " Anyway, you're done.",
        "tokens": [
          50725,
          316,
          1634,
          676,
          11,
          291,
          6,
          81,
          68,
          274,
          546,
          13,
          50779
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1780.3400000000001,
        "id": 656,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1778.7,
        "temperature": 1,
        "text": " So now now we moving to white.",
        "tokens": [
          50779,
          407,
          586,
          586,
          321,
          2684,
          281,
          2418,
          13,
          50861
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1781.94,
        "id": 657,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1780.3400000000001,
        "temperature": 1,
        "text": " So now I'm going to try,",
        "tokens": [
          50861,
          220,
          6455,
          586,
          286,
          478,
          352,
          72,
          872,
          220,
          1353,
          853,
          11,
          50941
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1783.18,
        "id": 658,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1781.94,
        "temperature": 1,
        "text": " let's try thinking.",
        "tokens": [
          50941,
          718,
          311,
          853,
          1953,
          13,
          51003
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1784.7800000000002,
        "id": 659,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1783.18,
        "temperature": 1,
        "text": " I mean, I don't know if we're going to get it,",
        "tokens": [
          51003,
          286,
          914,
          11,
          286,
          500,
          380,
          458,
          498,
          321,
          6,
          81,
          68,
          516,
          281,
          483,
          309,
          11,
          51083
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1786.2800000000002,
        "id": 660,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1784.7800000000002,
        "temperature": 1,
        "text": " but you get the idea.",
        "tokens": [
          51083,
          457,
          291,
          483,
          264,
          1558,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1787.1000000000001,
        "id": 661,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1786.2800000000002,
        "temperature": 1,
        "text": " Okay then.",
        "tokens": [
          51158,
          1033,
          220,
          19096,
          13,
          51199
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1787.88,
        "id": 662,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1787.1000000000001,
        "temperature": 1,
        "text": " Let's strike this option,",
        "tokens": [
          51199,
          961,
          311,
          9302,
          341,
          3614,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1789.72,
        "id": 663,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1787.88,
        "temperature": 1,
        "text": " and I don't know if we're going to be able to have",
        "tokens": [
          51238,
          220,
          282,
          67,
          286,
          500,
          380,
          458,
          498,
          321,
          434,
          516,
          281,
          312,
          1075,
          220,
          1353,
          362,
          51330
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1791.0800000000002,
        "id": 664,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1789.72,
        "temperature": 1,
        "text": " it flip over, because I think it's because",
        "tokens": [
          51330,
          309,
          7929,
          670,
          11,
          570,
          286,
          256,
          4954,
          77,
          74,
          309,
          311,
          570,
          51398
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1793.1200000000001,
        "id": 665,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1791.0800000000002,
        "temperature": 1,
        "text": " of, I don't know, I don't know if I found right here",
        "tokens": [
          51398,
          220,
          2670,
          11,
          286,
          500,
          380,
          458,
          11,
          286,
          500,
          380,
          458,
          498,
          286,
          1352,
          558,
          510,
          51500
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1795.42,
        "id": 666,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1793.1200000000001,
        "temperature": 1,
        "text": " but oh, wow, how dramatic of a turn that is?",
        "tokens": [
          51500,
          457,
          1954,
          11,
          6076,
          11,
          577,
          12023,
          295,
          257,
          1261,
          300,
          307,
          30,
          51615
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1796.88,
        "id": 667,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1795.42,
        "temperature": 1,
        "text": " How dramatic.",
        "tokens": [
          51615,
          1012,
          12023,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1798.42,
        "id": 668,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1796.88,
        "temperature": 1,
        "text": " I bought what I was looking for.",
        "tokens": [
          51688,
          286,
          4243,
          437,
          286,
          390,
          1237,
          337,
          13,
          51765
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1799.4,
        "id": 669,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1798.42,
        "temperature": 1,
        "text": " Wait, actually, wait, hold on, hold on, hold on.",
        "tokens": [
          51765,
          3802,
          11,
          767,
          11,
          1699,
          11,
          1797,
          322,
          11,
          1797,
          322,
          11,
          4091,
          67,
          322,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -2.2219889044217322,
        "compression_ratio": 1.9189189189189189,
        "end": 1800.2800000000002,
        "id": 670,
        "no_speech_prob": 0.4185756742954254,
        "seek": 177040,
        "start": 1799.4,
        "temperature": 1,
        "text": " Hold on.",
        "tokens": [
          51814,
          6962,
          322,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1801.94,
        "id": 671,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1801.1,
        "temperature": 0,
        "text": " Anyway, you can see it's kind of getting,",
        "tokens": [
          50405,
          5684,
          11,
          291,
          393,
          536,
          309,
          311,
          733,
          295,
          1242,
          11,
          50447
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1804.16,
        "id": 672,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1801.94,
        "temperature": 0,
        "text": " I don't know that I've really given it enough training data",
        "tokens": [
          50447,
          286,
          500,
          380,
          458,
          300,
          286,
          600,
          534,
          2212,
          309,
          1547,
          3097,
          1412,
          50558
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1805.56,
        "id": 673,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1804.16,
        "temperature": 0,
        "text": " to really work optimally.",
        "tokens": [
          50558,
          281,
          534,
          589,
          5028,
          379,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1807.44,
        "id": 674,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1805.56,
        "temperature": 0,
        "text": " Maybe I, this could be an interesting project",
        "tokens": [
          50628,
          2704,
          286,
          11,
          341,
          727,
          312,
          364,
          1880,
          1716,
          50722
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1810.28,
        "id": 675,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1807.44,
        "temperature": 0,
        "text": " if this were like deployed in a distributed way on the web,",
        "tokens": [
          50722,
          498,
          341,
          645,
          411,
          17826,
          294,
          257,
          12631,
          636,
          322,
          264,
          3670,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1812.96,
        "id": 676,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1810.28,
        "temperature": 0,
        "text": " and thousands of people could all come and click on it,",
        "tokens": [
          50864,
          293,
          5383,
          295,
          561,
          727,
          439,
          808,
          293,
          2052,
          322,
          309,
          11,
          50998
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1815.56,
        "id": 677,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1812.96,
        "temperature": 0,
        "text": " and like through and train it together",
        "tokens": [
          50998,
          293,
          411,
          807,
          293,
          3847,
          309,
          1214,
          51128
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1817.34,
        "id": 678,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1815.56,
        "temperature": 0,
        "text": " as a group of people in the world.",
        "tokens": [
          51128,
          382,
          257,
          1594,
          295,
          561,
          294,
          264,
          1002,
          13,
          51217
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1819.48,
        "id": 679,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1817.34,
        "temperature": 0,
        "text": " But let's try training it automatically",
        "tokens": [
          51217,
          583,
          718,
          311,
          853,
          3097,
          309,
          6772,
          51324
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1821.86,
        "id": 680,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1819.48,
        "temperature": 0,
        "text": " to see if that works a little bit better.",
        "tokens": [
          51324,
          281,
          536,
          498,
          300,
          1985,
          257,
          707,
          857,
          1101,
          13,
          51443
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1823.52,
        "id": 681,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1821.86,
        "temperature": 0,
        "text": " So how are we going to do that?",
        "tokens": [
          51443,
          407,
          577,
          366,
          321,
          516,
          281,
          360,
          300,
          30,
          51526
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1824.8,
        "id": 682,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1823.52,
        "temperature": 0,
        "text": " So let me go back to the code.",
        "tokens": [
          51526,
          407,
          718,
          385,
          352,
          646,
          281,
          264,
          3089,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.27011232252244827,
        "compression_ratio": 1.716923076923077,
        "end": 1828.92,
        "id": 683,
        "no_speech_prob": 0.00014202282181940973,
        "seek": 180028,
        "start": 1824.8,
        "temperature": 0,
        "text": " Remember this nice little bit of code I had here?",
        "tokens": [
          51590,
          5459,
          341,
          1481,
          707,
          857,
          295,
          3089,
          286,
          632,
          510,
          30,
          51796
        ]
      },
      {
        "avg_logprob": -0.20739197731018066,
        "compression_ratio": 1.5628415300546448,
        "end": 1833.16,
        "id": 684,
        "no_speech_prob": 0.000005255391442915425,
        "seek": 182892,
        "start": 1829.44,
        "temperature": 0,
        "text": " Let's train it to actually learn a certain threshold.",
        "tokens": [
          50390,
          961,
          311,
          3847,
          309,
          281,
          767,
          1466,
          257,
          1629,
          14678,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.20739197731018066,
        "compression_ratio": 1.5628415300546448,
        "end": 1837.48,
        "id": 685,
        "no_speech_prob": 0.000005255391442915425,
        "seek": 182892,
        "start": 1833.16,
        "temperature": 0,
        "text": " So I'm going to, I'm going to write a function here",
        "tokens": [
          50576,
          407,
          286,
          478,
          516,
          281,
          11,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          510,
          50792
        ]
      },
      {
        "avg_logprob": -0.20739197731018066,
        "compression_ratio": 1.5628415300546448,
        "end": 1842.48,
        "id": 686,
        "no_speech_prob": 0.000005255391442915425,
        "seek": 182892,
        "start": 1837.48,
        "temperature": 0,
        "text": " called train color, and it gets an R, G, and B,",
        "tokens": [
          50792,
          1219,
          3847,
          2017,
          11,
          293,
          309,
          2170,
          364,
          497,
          11,
          460,
          11,
          293,
          363,
          11,
          51042
        ]
      },
      {
        "avg_logprob": -0.20739197731018066,
        "compression_ratio": 1.5628415300546448,
        "end": 1851,
        "id": 687,
        "no_speech_prob": 0.000005255391442915425,
        "seek": 182892,
        "start": 1847.28,
        "temperature": 0,
        "text": " and it's going to return black or white.",
        "tokens": [
          51282,
          293,
          309,
          311,
          516,
          281,
          2736,
          2211,
          420,
          2418,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.20739197731018066,
        "compression_ratio": 1.5628415300546448,
        "end": 1854.52,
        "id": 688,
        "no_speech_prob": 0.000005255391442915425,
        "seek": 182892,
        "start": 1851,
        "temperature": 0,
        "text": " And what I'm going to do now is in setup,",
        "tokens": [
          51468,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          294,
          8657,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.20739197731018066,
        "compression_ratio": 1.5628415300546448,
        "end": 1858.28,
        "id": 689,
        "no_speech_prob": 0.000005255391442915425,
        "seek": 182892,
        "start": 1854.52,
        "temperature": 0,
        "text": " this is a little bit silly, before I do anything,",
        "tokens": [
          51644,
          341,
          307,
          257,
          707,
          857,
          11774,
          11,
          949,
          286,
          360,
          1340,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.20604688693315554,
        "compression_ratio": 1.657718120805369,
        "end": 1860.72,
        "id": 690,
        "no_speech_prob": 0.000009223412234860007,
        "seek": 185828,
        "start": 1858.28,
        "temperature": 0,
        "text": " I'm just going to say for let i equal zero,",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          584,
          337,
          718,
          741,
          2681,
          4018,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.20604688693315554,
        "compression_ratio": 1.657718120805369,
        "end": 1865.72,
        "id": 691,
        "no_speech_prob": 0.000009223412234860007,
        "seek": 185828,
        "start": 1860.72,
        "temperature": 0,
        "text": " i is less than 1,000, i++, and I'm going to pick a,",
        "tokens": [
          50486,
          741,
          307,
          1570,
          813,
          502,
          11,
          1360,
          11,
          741,
          25472,
          11,
          293,
          286,
          478,
          516,
          281,
          1888,
          257,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.20604688693315554,
        "compression_ratio": 1.657718120805369,
        "end": 1872.04,
        "id": 692,
        "no_speech_prob": 0.000009223412234860007,
        "seek": 185828,
        "start": 1867.3999999999999,
        "temperature": 0,
        "text": " I'm going to pick a different set of random colors",
        "tokens": [
          50820,
          286,
          478,
          516,
          281,
          1888,
          257,
          819,
          992,
          295,
          4974,
          4577,
          51052
        ]
      },
      {
        "avg_logprob": -0.20604688693315554,
        "compression_ratio": 1.657718120805369,
        "end": 1874.48,
        "id": 693,
        "no_speech_prob": 0.000009223412234860007,
        "seek": 185828,
        "start": 1872.04,
        "temperature": 0,
        "text": " that are different from the global random colors.",
        "tokens": [
          51052,
          300,
          366,
          819,
          490,
          264,
          4338,
          4974,
          4577,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.20604688693315554,
        "compression_ratio": 1.657718120805369,
        "end": 1883.8,
        "id": 694,
        "no_speech_prob": 0.000009223412234860007,
        "seek": 185828,
        "start": 1878.8,
        "temperature": 0,
        "text": " Then I'm going to, I'm going to say the answer is,",
        "tokens": [
          51390,
          1396,
          286,
          478,
          516,
          281,
          11,
          286,
          478,
          516,
          281,
          584,
          264,
          1867,
          307,
          11,
          51640
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1888.8,
        "id": 695,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1883.8,
        "temperature": 0,
        "text": " what is it, train color, train color with R, G, B,",
        "tokens": [
          50364,
          437,
          307,
          309,
          11,
          3847,
          2017,
          11,
          3847,
          2017,
          365,
          497,
          11,
          460,
          11,
          363,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1895.6,
        "id": 696,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1893.44,
        "temperature": 0,
        "text": " and you know what I'm going to do?",
        "tokens": [
          50846,
          293,
          291,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          30,
          50954
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1898.06,
        "id": 697,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1895.6,
        "temperature": 0,
        "text": " I'm just going to do this, targets.",
        "tokens": [
          50954,
          286,
          478,
          445,
          516,
          281,
          360,
          341,
          11,
          12911,
          13,
          51077
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1901.78,
        "id": 698,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1898.06,
        "temperature": 0,
        "text": " Let's skip a step here, and this,",
        "tokens": [
          51077,
          961,
          311,
          10023,
          257,
          1823,
          510,
          11,
          293,
          341,
          11,
          51263
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1903.6399999999999,
        "id": 699,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1901.78,
        "temperature": 0,
        "text": " I can't remember which is which.",
        "tokens": [
          51263,
          286,
          393,
          380,
          1604,
          597,
          307,
          597,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1904.76,
        "id": 700,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1903.6399999999999,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51356,
          45263,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1907.12,
        "id": 701,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1904.76,
        "temperature": 0,
        "text": " Let's just return the targets.",
        "tokens": [
          51412,
          961,
          311,
          445,
          2736,
          264,
          12911,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1907.94,
        "id": 702,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1907.12,
        "temperature": 0,
        "text": " Is this right?",
        "tokens": [
          51530,
          1119,
          341,
          558,
          30,
          51571
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1909.44,
        "id": 703,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1907.94,
        "temperature": 0,
        "text": " Somebody in the chat tell me if I've got these backwards",
        "tokens": [
          51571,
          13463,
          294,
          264,
          5081,
          980,
          385,
          498,
          286,
          600,
          658,
          613,
          12204,
          51646
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1910.28,
        "id": 704,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1909.44,
        "temperature": 0,
        "text": " or not.",
        "tokens": [
          51646,
          420,
          406,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2292298173482439,
        "compression_ratio": 1.681592039800995,
        "end": 1912.44,
        "id": 705,
        "no_speech_prob": 0.000017231506717507727,
        "seek": 188380,
        "start": 1911.28,
        "temperature": 0,
        "text": " Let's just return the targets.",
        "tokens": [
          51738,
          961,
          311,
          445,
          2736,
          264,
          12911,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1914.3200000000002,
        "id": 706,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1912.44,
        "temperature": 0,
        "text": " I'm kind of skipping some steps here.",
        "tokens": [
          50364,
          286,
          478,
          733,
          295,
          31533,
          512,
          4439,
          510,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1915.28,
        "id": 707,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1914.3200000000002,
        "temperature": 0,
        "text": " Now I'm not being as thoughtful",
        "tokens": [
          50458,
          823,
          286,
          478,
          406,
          885,
          382,
          21566,
          50506
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1916.9,
        "id": 708,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1915.28,
        "temperature": 0,
        "text": " about how I'm organizing this,",
        "tokens": [
          50506,
          466,
          577,
          286,
          478,
          17608,
          341,
          11,
          50587
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1918.72,
        "id": 709,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1916.9,
        "temperature": 0,
        "text": " but I want to get those targets.",
        "tokens": [
          50587,
          457,
          286,
          528,
          281,
          483,
          729,
          12911,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1923.72,
        "id": 710,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1918.72,
        "temperature": 0,
        "text": " Then I want to say the inputs are R divided by 255G,",
        "tokens": [
          50678,
          1396,
          286,
          528,
          281,
          584,
          264,
          15743,
          366,
          497,
          6666,
          538,
          3552,
          20,
          38,
          11,
          50928
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1927.6200000000001,
        "id": 711,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1924.68,
        "temperature": 0,
        "text": " G divided by 255B divided by 255,",
        "tokens": [
          50976,
          460,
          6666,
          538,
          3552,
          20,
          33,
          6666,
          538,
          3552,
          20,
          11,
          51123
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1930.28,
        "id": 712,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1927.6200000000001,
        "temperature": 0,
        "text": " and this should say inputs,",
        "tokens": [
          51123,
          293,
          341,
          820,
          584,
          15743,
          11,
          51256
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1932.28,
        "id": 713,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1930.28,
        "temperature": 0,
        "text": " and then I'm going to say brain,",
        "tokens": [
          51256,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          3567,
          11,
          51356
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1935.1200000000001,
        "id": 714,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1932.28,
        "temperature": 0,
        "text": " train inputs with these targets.",
        "tokens": [
          51356,
          3847,
          15743,
          365,
          613,
          12911,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1937.04,
        "id": 715,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1935.1200000000001,
        "temperature": 0,
        "text": " So this is me just running through",
        "tokens": [
          51498,
          407,
          341,
          307,
          385,
          445,
          2614,
          807,
          51594
        ]
      },
      {
        "avg_logprob": -0.25630073860043384,
        "compression_ratio": 1.684873949579832,
        "end": 1940.96,
        "id": 716,
        "no_speech_prob": 0.0003569688997231424,
        "seek": 191244,
        "start": 1937.04,
        "temperature": 0,
        "text": " and kind of quickly using 1,000 colors to train it,",
        "tokens": [
          51594,
          293,
          733,
          295,
          2661,
          1228,
          502,
          11,
          1360,
          4577,
          281,
          3847,
          309,
          11,
          51790
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1944.52,
        "id": 717,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1940.96,
        "temperature": 0,
        "text": " and I'm being told that this is probably backwards.",
        "tokens": [
          50364,
          293,
          286,
          478,
          885,
          1907,
          300,
          341,
          307,
          1391,
          12204,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1947.42,
        "id": 718,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1944.52,
        "temperature": 0,
        "text": " There's no way I could have possibly guessed that correctly.",
        "tokens": [
          50542,
          821,
          311,
          572,
          636,
          286,
          727,
          362,
          6264,
          21852,
          300,
          8944,
          13,
          50687
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1949.56,
        "id": 719,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1947.42,
        "temperature": 0,
        "text": " Okay, so let's, and actually I'm going to even,",
        "tokens": [
          50687,
          1033,
          11,
          370,
          718,
          311,
          11,
          293,
          767,
          286,
          478,
          516,
          281,
          754,
          11,
          50794
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1952.8600000000001,
        "id": 720,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1949.56,
        "temperature": 0,
        "text": " I'm just going to, let's let it run 10,000 times.",
        "tokens": [
          50794,
          286,
          478,
          445,
          516,
          281,
          11,
          718,
          311,
          718,
          309,
          1190,
          1266,
          11,
          1360,
          1413,
          13,
          50959
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1954.56,
        "id": 721,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1952.8600000000001,
        "temperature": 0,
        "text": " So I'm going to run 10,000 colors",
        "tokens": [
          50959,
          407,
          286,
          478,
          516,
          281,
          1190,
          1266,
          11,
          1360,
          4577,
          51044
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1956.68,
        "id": 722,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1954.56,
        "temperature": 0,
        "text": " through the network right in setup",
        "tokens": [
          51044,
          807,
          264,
          3209,
          558,
          294,
          8657,
          51150
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1958.28,
        "id": 723,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1956.68,
        "temperature": 0,
        "text": " as like training data basically.",
        "tokens": [
          51150,
          382,
          411,
          3097,
          1412,
          1936,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1964.26,
        "id": 724,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1960.18,
        "temperature": 0,
        "text": " Okay, so now let's just,",
        "tokens": [
          51325,
          1033,
          11,
          370,
          586,
          718,
          311,
          445,
          11,
          51529
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1966.6000000000001,
        "id": 725,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1964.26,
        "temperature": 0,
        "text": " and actually in a way what I'm going to do now,",
        "tokens": [
          51529,
          293,
          767,
          294,
          257,
          636,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          11,
          51646
        ]
      },
      {
        "avg_logprob": -0.2006235122680664,
        "compression_ratio": 1.75,
        "end": 1968.96,
        "id": 726,
        "no_speech_prob": 0.00000764653395890491,
        "seek": 194096,
        "start": 1966.6000000000001,
        "temperature": 0,
        "text": " just to see, I'm not even going to click.",
        "tokens": [
          51646,
          445,
          281,
          536,
          11,
          286,
          478,
          406,
          754,
          516,
          281,
          2052,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1972,
        "id": 727,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1968.96,
        "temperature": 0,
        "text": " I'm going to not bother to train it anymore.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          406,
          8677,
          281,
          3847,
          309,
          3602,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1974.7,
        "id": 728,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1973.04,
        "temperature": 0,
        "text": " I'm just going to pick,",
        "tokens": [
          50568,
          286,
          478,
          445,
          516,
          281,
          1888,
          11,
          50651
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1978.04,
        "id": 729,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1974.7,
        "temperature": 0,
        "text": " let me comment out my own interactive training,",
        "tokens": [
          50651,
          718,
          385,
          2871,
          484,
          452,
          1065,
          15141,
          3097,
          11,
          50818
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1981.24,
        "id": 730,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1978.04,
        "temperature": 0,
        "text": " and let me just pick new colors, okay?",
        "tokens": [
          50818,
          293,
          718,
          385,
          445,
          1888,
          777,
          4577,
          11,
          1392,
          30,
          50978
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1984.64,
        "id": 731,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1981.24,
        "temperature": 0,
        "text": " So every time I click, yeah,",
        "tokens": [
          50978,
          407,
          633,
          565,
          286,
          2052,
          11,
          1338,
          11,
          51148
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1985.96,
        "id": 732,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1984.64,
        "temperature": 0,
        "text": " you can see it's making guesses.",
        "tokens": [
          51148,
          291,
          393,
          536,
          309,
          311,
          1455,
          42703,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1987.18,
        "id": 733,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1985.96,
        "temperature": 0,
        "text": " Are they good guesses?",
        "tokens": [
          51214,
          2014,
          436,
          665,
          42703,
          30,
          51275
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1989.8,
        "id": 734,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1987.18,
        "temperature": 0,
        "text": " I don't know, but I bet you those guesses",
        "tokens": [
          51275,
          286,
          500,
          380,
          458,
          11,
          457,
          286,
          778,
          291,
          729,
          42703,
          51406
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1993.44,
        "id": 735,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1989.8,
        "temperature": 0,
        "text": " are pretty accurately aligned with that threshold of 300.",
        "tokens": [
          51406,
          366,
          1238,
          20095,
          17962,
          365,
          300,
          14678,
          295,
          6641,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1996.08,
        "id": 736,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1993.44,
        "temperature": 0,
        "text": " So I could continue to train it a little bit,",
        "tokens": [
          51588,
          407,
          286,
          727,
          2354,
          281,
          3847,
          309,
          257,
          707,
          857,
          11,
          51720
        ]
      },
      {
        "avg_logprob": -0.21925719579060873,
        "compression_ratio": 1.62109375,
        "end": 1997.96,
        "id": 737,
        "no_speech_prob": 0.00000402945033783908,
        "seek": 196896,
        "start": 1996.08,
        "temperature": 0,
        "text": " but I feel pretty happy now.",
        "tokens": [
          51720,
          457,
          286,
          841,
          1238,
          2055,
          586,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2001.2,
        "id": 738,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 1999.24,
        "temperature": 0,
        "text": " With this color predictor.",
        "tokens": [
          50378,
          2022,
          341,
          2017,
          6069,
          284,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2004.52,
        "id": 739,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2001.2,
        "temperature": 0,
        "text": " Okay, what's going on?",
        "tokens": [
          50476,
          1033,
          11,
          437,
          311,
          516,
          322,
          30,
          50642
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2006.08,
        "id": 740,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2004.52,
        "temperature": 0,
        "text": " I finished this coding challenge.",
        "tokens": [
          50642,
          286,
          4335,
          341,
          17720,
          3430,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2007.52,
        "id": 741,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2006.08,
        "temperature": 0,
        "text": " I'm going to release this code.",
        "tokens": [
          50720,
          286,
          478,
          516,
          281,
          4374,
          341,
          3089,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2008.74,
        "id": 742,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2007.52,
        "temperature": 0,
        "text": " What can you do with it?",
        "tokens": [
          50792,
          708,
          393,
          291,
          360,
          365,
          309,
          30,
          50853
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2009.72,
        "id": 743,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2008.74,
        "temperature": 0,
        "text": " So a couple things.",
        "tokens": [
          50853,
          407,
          257,
          1916,
          721,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2013.24,
        "id": 744,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2009.72,
        "temperature": 0,
        "text": " One is, could you make this same exact project,",
        "tokens": [
          50902,
          1485,
          307,
          11,
          727,
          291,
          652,
          341,
          912,
          1900,
          1716,
          11,
          51078
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2015.2,
        "id": 745,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2013.24,
        "temperature": 0,
        "text": " but instead of having it just pick",
        "tokens": [
          51078,
          457,
          2602,
          295,
          1419,
          309,
          445,
          1888,
          51176
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2018,
        "id": 746,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2015.2,
        "temperature": 0,
        "text": " whether black or white goes on top,",
        "tokens": [
          51176,
          1968,
          2211,
          420,
          2418,
          1709,
          322,
          1192,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2021,
        "id": 747,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2018,
        "temperature": 0,
        "text": " could you pick a RGB color that looks nice?",
        "tokens": [
          51316,
          727,
          291,
          1888,
          257,
          31231,
          2017,
          300,
          1542,
          1481,
          30,
          51466
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2024.08,
        "id": 748,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2021,
        "temperature": 0,
        "text": " Maybe it's a, maybe you could have a neural network",
        "tokens": [
          51466,
          2704,
          309,
          311,
          257,
          11,
          1310,
          291,
          727,
          362,
          257,
          18161,
          3209,
          51620
        ]
      },
      {
        "avg_logprob": -0.19493513107299804,
        "compression_ratio": 1.5811320754716982,
        "end": 2027.44,
        "id": 749,
        "no_speech_prob": 0.00013135159679222852,
        "seek": 199896,
        "start": 2024.08,
        "temperature": 0,
        "text": " solve the formula for complementary colors.",
        "tokens": [
          51620,
          5039,
          264,
          8513,
          337,
          40705,
          4577,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2029.92,
        "id": 750,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2027.48,
        "temperature": 0,
        "text": " Could you think of a more thoughtful way to design this?",
        "tokens": [
          50366,
          7497,
          291,
          519,
          295,
          257,
          544,
          21566,
          636,
          281,
          1715,
          341,
          30,
          50488
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2032.52,
        "id": 751,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2029.92,
        "temperature": 0,
        "text": " Could you use some other data entirely?",
        "tokens": [
          50488,
          7497,
          291,
          764,
          512,
          661,
          1412,
          7696,
          30,
          50618
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2036.64,
        "id": 752,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2032.52,
        "temperature": 0,
        "text": " Could you train based on like font, which font to pick?",
        "tokens": [
          50618,
          7497,
          291,
          3847,
          2361,
          322,
          411,
          10703,
          11,
          597,
          10703,
          281,
          1888,
          30,
          50824
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2039.3600000000001,
        "id": 753,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2036.64,
        "temperature": 0,
        "text": " Could you train a system to make design decisions",
        "tokens": [
          50824,
          7497,
          291,
          3847,
          257,
          1185,
          281,
          652,
          1715,
          5327,
          50960
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2042.3600000000001,
        "id": 754,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2039.3600000000001,
        "temperature": 0,
        "text": " based on some set of training data",
        "tokens": [
          50960,
          2361,
          322,
          512,
          992,
          295,
          3097,
          1412,
          51110
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2044.38,
        "id": 755,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2042.3600000000001,
        "temperature": 0,
        "text": " or some user interaction, something like that?",
        "tokens": [
          51110,
          420,
          512,
          4195,
          9285,
          11,
          746,
          411,
          300,
          30,
          51211
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2046,
        "id": 756,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2044.38,
        "temperature": 0,
        "text": " So I hope you make your own",
        "tokens": [
          51211,
          407,
          286,
          1454,
          291,
          652,
          428,
          1065,
          51292
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2048.46,
        "id": 757,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2046,
        "temperature": 0,
        "text": " neural network design predictor thingy,",
        "tokens": [
          51292,
          18161,
          3209,
          1715,
          6069,
          284,
          551,
          88,
          11,
          51415
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2051.04,
        "id": 758,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2049.4,
        "temperature": 0,
        "text": " and share it with me.",
        "tokens": [
          51462,
          293,
          2073,
          309,
          365,
          385,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2053.4,
        "id": 759,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2051.04,
        "temperature": 0,
        "text": " You can go to the CodingTrain.com website.",
        "tokens": [
          51544,
          509,
          393,
          352,
          281,
          264,
          383,
          8616,
          51,
          7146,
          13,
          1112,
          3144,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.21575137329101562,
        "compression_ratio": 1.7252747252747254,
        "end": 2055.62,
        "id": 760,
        "no_speech_prob": 0.00006502797623397782,
        "seek": 202744,
        "start": 2053.4,
        "temperature": 0,
        "text": " There's some instructions there for how to contribute",
        "tokens": [
          51662,
          821,
          311,
          512,
          9415,
          456,
          337,
          577,
          281,
          10586,
          51773
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2057.58,
        "id": 761,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2055.62,
        "temperature": 0,
        "text": " your version of a project like this.",
        "tokens": [
          50364,
          428,
          3037,
          295,
          257,
          1716,
          411,
          341,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2059.06,
        "id": 762,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2057.58,
        "temperature": 0,
        "text": " You can write in the comments.",
        "tokens": [
          50462,
          509,
          393,
          2464,
          294,
          264,
          3053,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2060.72,
        "id": 763,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2059.06,
        "temperature": 0,
        "text": " You can tweet me at Schiffman.",
        "tokens": [
          50536,
          509,
          393,
          15258,
          385,
          412,
          2065,
          3661,
          1601,
          13,
          50619
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2062.4,
        "id": 764,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2060.72,
        "temperature": 0,
        "text": " I guess I'm supposed to say you should subscribe",
        "tokens": [
          50619,
          286,
          2041,
          286,
          478,
          3442,
          281,
          584,
          291,
          820,
          3022,
          50703
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2064.54,
        "id": 765,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2062.4,
        "temperature": 0,
        "text": " to the channel, blah, blah, blah, blah, blah.",
        "tokens": [
          50703,
          281,
          264,
          2269,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2069.54,
        "id": 766,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2064.54,
        "temperature": 0,
        "text": " Thank you for tuning in, and there is the color predictor.",
        "tokens": [
          50810,
          1044,
          291,
          337,
          15164,
          294,
          11,
          293,
          456,
          307,
          264,
          2017,
          6069,
          284,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2072.72,
        "id": 767,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2070.46,
        "temperature": 0,
        "text": " Wait, hold on, stop, time out.",
        "tokens": [
          51106,
          3802,
          11,
          1797,
          322,
          11,
          1590,
          11,
          565,
          484,
          13,
          51219
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2075.22,
        "id": 768,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2072.72,
        "temperature": 0,
        "text": " I'm getting a good suggestion in the chat.",
        "tokens": [
          51219,
          286,
          478,
          1242,
          257,
          665,
          16541,
          294,
          264,
          5081,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2078.2999999999997,
        "id": 769,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2075.22,
        "temperature": 0,
        "text": " It might be nice to see like what the number is.",
        "tokens": [
          51344,
          467,
          1062,
          312,
          1481,
          281,
          536,
          411,
          437,
          264,
          1230,
          307,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2079.94,
        "id": 770,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2078.2999999999997,
        "temperature": 0,
        "text": " So hold on.",
        "tokens": [
          51498,
          407,
          1797,
          322,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2081.54,
        "id": 771,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2079.94,
        "temperature": 0,
        "text": " Let's, this is a good idea.",
        "tokens": [
          51580,
          961,
          311,
          11,
          341,
          307,
          257,
          665,
          1558,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2082.38,
        "id": 772,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2081.54,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51660,
          961,
          311,
          360,
          341,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.23895650194180723,
        "compression_ratio": 1.7306273062730628,
        "end": 2083.8599999999997,
        "id": 773,
        "no_speech_prob": 0.016656510531902313,
        "seek": 205562,
        "start": 2082.38,
        "temperature": 0,
        "text": " Hold on, hold on, time out, everybody.",
        "tokens": [
          51702,
          6962,
          322,
          11,
          1797,
          322,
          11,
          565,
          484,
          11,
          2201,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2085.2200000000003,
        "id": 774,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2083.94,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50368,
          1033,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2087.5,
        "id": 775,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2085.2200000000003,
        "temperature": 0,
        "text": " Where do I have, I have some console log going on here.",
        "tokens": [
          50432,
          2305,
          360,
          286,
          362,
          11,
          286,
          362,
          512,
          11076,
          3565,
          516,
          322,
          510,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2091.78,
        "id": 776,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2087.5,
        "temperature": 0,
        "text": " Let me get rid of this console log, and let me in here,",
        "tokens": [
          50546,
          961,
          385,
          483,
          3973,
          295,
          341,
          11076,
          3565,
          11,
          293,
          718,
          385,
          294,
          510,
          11,
          50760
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2096.78,
        "id": 777,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2091.78,
        "temperature": 0,
        "text": " let's console log r plus g plus b.",
        "tokens": [
          50760,
          718,
          311,
          11076,
          3565,
          367,
          1804,
          290,
          1804,
          272,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2101.56,
        "id": 778,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2098.58,
        "temperature": 0,
        "text": " So let's see if this value is bigger,",
        "tokens": [
          51100,
          407,
          718,
          311,
          536,
          498,
          341,
          2158,
          307,
          3801,
          11,
          51249
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2103.98,
        "id": 779,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2101.56,
        "temperature": 0,
        "text": " and I'm just going to floor it so it looks,",
        "tokens": [
          51249,
          293,
          286,
          478,
          445,
          516,
          281,
          4123,
          309,
          370,
          309,
          1542,
          11,
          51370
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2106.82,
        "id": 780,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2105.78,
        "temperature": 0,
        "text": " I don't need to see the decimal.",
        "tokens": [
          51460,
          286,
          500,
          380,
          643,
          281,
          536,
          264,
          26601,
          13,
          51512
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2108.98,
        "id": 781,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2106.82,
        "temperature": 0,
        "text": " Let's see if this, let's see if it really learned",
        "tokens": [
          51512,
          961,
          311,
          536,
          498,
          341,
          11,
          718,
          311,
          536,
          498,
          309,
          534,
          3264,
          51620
        ]
      },
      {
        "avg_logprob": -0.2582796790383079,
        "compression_ratio": 1.7474226804123711,
        "end": 2110.4,
        "id": 782,
        "no_speech_prob": 0.00006605187809327617,
        "seek": 208386,
        "start": 2108.98,
        "temperature": 0,
        "text": " the threshold of 300.",
        "tokens": [
          51620,
          264,
          14678,
          295,
          6641,
          13,
          51691
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2111.2400000000002,
        "id": 783,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2110.4,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50364,
          1779,
          30,
          50406
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2115.48,
        "id": 784,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2113.7200000000003,
        "temperature": 0,
        "text": " Right, 319.",
        "tokens": [
          50530,
          1779,
          11,
          805,
          3405,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2116.7200000000003,
        "id": 785,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2115.48,
        "temperature": 0,
        "text": " That should be white.",
        "tokens": [
          50618,
          663,
          820,
          312,
          2418,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2118.12,
        "id": 786,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2116.7200000000003,
        "temperature": 0,
        "text": " So it didn't get that right.",
        "tokens": [
          50680,
          407,
          309,
          994,
          380,
          483,
          300,
          558,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2120.2400000000002,
        "id": 787,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2118.12,
        "temperature": 0,
        "text": " Whoops, 376, ah.",
        "tokens": [
          50750,
          45263,
          11,
          13435,
          21,
          11,
          3716,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2124.14,
        "id": 788,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2120.2400000000002,
        "temperature": 0,
        "text": " 442, 289, oh wait.",
        "tokens": [
          50856,
          1017,
          15628,
          11,
          7562,
          24,
          11,
          1954,
          1699,
          13,
          51051
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2125.2400000000002,
        "id": 789,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2124.14,
        "temperature": 0,
        "text": " No, no, no, it did get it right.",
        "tokens": [
          51051,
          883,
          11,
          572,
          11,
          572,
          11,
          309,
          630,
          483,
          309,
          558,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2126.88,
        "id": 790,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2125.2400000000002,
        "temperature": 0,
        "text": " I've got it backwards.",
        "tokens": [
          51106,
          286,
          600,
          658,
          309,
          12204,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2130,
        "id": 791,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2126.88,
        "temperature": 0,
        "text": " If it's higher than 300, it should be over black.",
        "tokens": [
          51188,
          759,
          309,
          311,
          2946,
          813,
          6641,
          11,
          309,
          820,
          312,
          670,
          2211,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2132.56,
        "id": 792,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2130,
        "temperature": 0,
        "text": " If it's lower than 300, it should be over white.",
        "tokens": [
          51344,
          759,
          309,
          311,
          3126,
          813,
          6641,
          11,
          309,
          820,
          312,
          670,
          2418,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2975226230308658,
        "compression_ratio": 1.6507936507936507,
        "end": 2137.56,
        "id": 793,
        "no_speech_prob": 0.00034599093487486243,
        "seek": 211040,
        "start": 2132.56,
        "temperature": 0,
        "text": " And we can see here, right, 289, white, 431, black,",
        "tokens": [
          51472,
          400,
          321,
          393,
          536,
          510,
          11,
          558,
          11,
          7562,
          24,
          11,
          2418,
          11,
          1017,
          12967,
          11,
          2211,
          11,
          51722
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2141.7599999999998,
        "id": 794,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2138,
        "temperature": 0,
        "text": " 513, black, 561, black, 527, right?",
        "tokens": [
          50386,
          1025,
          7668,
          11,
          2211,
          11,
          19687,
          16,
          11,
          2211,
          11,
          1025,
          10076,
          11,
          558,
          30,
          50574
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2143.7799999999997,
        "id": 795,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2141.7599999999998,
        "temperature": 0,
        "text": " This is working, and just to prove this point,",
        "tokens": [
          50574,
          639,
          307,
          1364,
          11,
          293,
          445,
          281,
          7081,
          341,
          935,
          11,
          50675
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2147.48,
        "id": 796,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2143.7799999999997,
        "temperature": 0,
        "text": " let me run it again with a different threshold.",
        "tokens": [
          50675,
          718,
          385,
          1190,
          309,
          797,
          365,
          257,
          819,
          14678,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2151.44,
        "id": 797,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2150.12,
        "temperature": 0,
        "text": " Where do I add that?",
        "tokens": [
          50992,
          2305,
          360,
          286,
          909,
          300,
          30,
          51058
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2152.36,
        "id": 798,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2151.44,
        "temperature": 0,
        "text": " In the training.",
        "tokens": [
          51058,
          682,
          264,
          3097,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2155.32,
        "id": 799,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2153.24,
        "temperature": 0,
        "text": " Let me give it a silly threshold of 100.",
        "tokens": [
          51148,
          961,
          385,
          976,
          309,
          257,
          11774,
          14678,
          295,
          2319,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2157.52,
        "id": 800,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2155.32,
        "temperature": 0,
        "text": " That's much too low for it to be visually correct,",
        "tokens": [
          51252,
          663,
          311,
          709,
          886,
          2295,
          337,
          309,
          281,
          312,
          19622,
          3006,
          11,
          51362
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2159.16,
        "id": 801,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2157.52,
        "temperature": 0,
        "text": " probably, whatever that means.",
        "tokens": [
          51362,
          1391,
          11,
          2035,
          300,
          1355,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2163.04,
        "id": 802,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2159.16,
        "temperature": 0,
        "text": " But we can see now, it's going to only go to white",
        "tokens": [
          51444,
          583,
          321,
          393,
          536,
          586,
          11,
          309,
          311,
          516,
          281,
          787,
          352,
          281,
          2418,
          51638
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2165.7999999999997,
        "id": 803,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2163.04,
        "temperature": 0,
        "text": " if it's below 100.",
        "tokens": [
          51638,
          498,
          309,
          311,
          2507,
          2319,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.22972477890375093,
        "compression_ratio": 1.4904214559386972,
        "end": 2167.24,
        "id": 804,
        "no_speech_prob": 0.000014285508768807631,
        "seek": 213756,
        "start": 2165.7999999999997,
        "temperature": 0,
        "text": " Oh, it didn't, actually 97.",
        "tokens": [
          51776,
          876,
          11,
          309,
          994,
          380,
          11,
          767,
          23399,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2168.7599999999998,
        "id": 805,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2167.9199999999996,
        "temperature": 0,
        "text": " It didn't even get there.",
        "tokens": [
          50398,
          467,
          994,
          380,
          754,
          483,
          456,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2170.56,
        "id": 806,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2168.7599999999998,
        "temperature": 0,
        "text": " Now, I'm going to have to do this for quite a while",
        "tokens": [
          50440,
          823,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          360,
          341,
          337,
          1596,
          257,
          1339,
          50530
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2173.2,
        "id": 807,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2170.56,
        "temperature": 0,
        "text": " to get lucky enough to pick something lower than 100.",
        "tokens": [
          50530,
          281,
          483,
          6356,
          1547,
          281,
          1888,
          746,
          3126,
          813,
          2319,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2181.2799999999997,
        "id": 808,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2176.7599999999998,
        "temperature": 0,
        "text": " I'm very unlikely to get a number lower than 100",
        "tokens": [
          50840,
          286,
          478,
          588,
          17518,
          281,
          483,
          257,
          1230,
          3126,
          813,
          2319,
          51066
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2184.2999999999997,
        "id": 809,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2181.2799999999997,
        "temperature": 0,
        "text": " because I'm picking three random numbers",
        "tokens": [
          51066,
          570,
          286,
          478,
          8867,
          1045,
          4974,
          3547,
          51217
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2186.3399999999997,
        "id": 810,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2184.2999999999997,
        "temperature": 0,
        "text": " between zero and 255.",
        "tokens": [
          51217,
          1296,
          4018,
          293,
          3552,
          20,
          13,
          51319
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2190.52,
        "id": 811,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2186.3399999999997,
        "temperature": 0,
        "text": " So I actually have, I'd have to pick three random numbers",
        "tokens": [
          51319,
          407,
          286,
          767,
          362,
          11,
          286,
          1116,
          362,
          281,
          1888,
          1045,
          4974,
          3547,
          51528
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2195.3199999999997,
        "id": 812,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2190.52,
        "temperature": 0,
        "text": " basically lower than 33, which has a pretty low probability",
        "tokens": [
          51528,
          1936,
          3126,
          813,
          11816,
          11,
          597,
          575,
          257,
          1238,
          2295,
          8482,
          51768
        ]
      },
      {
        "avg_logprob": -0.2564090122686368,
        "compression_ratio": 1.6594827586206897,
        "end": 2196.6,
        "id": 813,
        "no_speech_prob": 0.000047576395445503294,
        "seek": 216724,
        "start": 2195.3199999999997,
        "temperature": 0,
        "text": " of doing that in a row.",
        "tokens": [
          51768,
          295,
          884,
          300,
          294,
          257,
          5386,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2198.22,
        "id": 814,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2196.64,
        "temperature": 0,
        "text": " So let's do the opposite thing.",
        "tokens": [
          50366,
          407,
          718,
          311,
          360,
          264,
          6182,
          551,
          13,
          50445
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2201.92,
        "id": 815,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2198.22,
        "temperature": 0,
        "text": " Let's say, let's do this only if it's greater than 500.",
        "tokens": [
          50445,
          961,
          311,
          584,
          11,
          718,
          311,
          360,
          341,
          787,
          498,
          309,
          311,
          5044,
          813,
          5923,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2208.52,
        "id": 816,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2204.16,
        "temperature": 0,
        "text": " 296, white, so if I ever get it greater than 500, black.",
        "tokens": [
          50742,
          9413,
          21,
          11,
          2418,
          11,
          370,
          498,
          286,
          1562,
          483,
          309,
          5044,
          813,
          5923,
          11,
          2211,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2210.7999999999997,
        "id": 817,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2209.88,
        "temperature": 0,
        "text": " 393 is white.",
        "tokens": [
          51028,
          15238,
          18,
          307,
          2418,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2213.3199999999997,
        "id": 818,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2210.7999999999997,
        "temperature": 0,
        "text": " So it is learning that threshold,",
        "tokens": [
          51074,
          407,
          309,
          307,
          2539,
          300,
          14678,
          11,
          51200
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2215.68,
        "id": 819,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2213.3199999999997,
        "temperature": 0,
        "text": " whatever I kind of, whatever I had.",
        "tokens": [
          51200,
          2035,
          286,
          733,
          295,
          11,
          2035,
          286,
          632,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2217.9,
        "id": 820,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2215.68,
        "temperature": 0,
        "text": " And I picked 300, and probably what would make sense",
        "tokens": [
          51318,
          400,
          286,
          6183,
          6641,
          11,
          293,
          1391,
          437,
          576,
          652,
          2020,
          51429
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2221.6,
        "id": 821,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2217.9,
        "temperature": 0,
        "text": " for me to pick is just, you know, 256,",
        "tokens": [
          51429,
          337,
          385,
          281,
          1888,
          307,
          445,
          11,
          291,
          458,
          11,
          38882,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.29823924376901273,
        "compression_ratio": 1.56,
        "end": 2224.02,
        "id": 822,
        "no_speech_prob": 0.0000076465285019367,
        "seek": 219660,
        "start": 2221.6,
        "temperature": 0,
        "text": " or 255 times three divided by,",
        "tokens": [
          51614,
          420,
          3552,
          20,
          1413,
          1045,
          6666,
          538,
          11,
          51735
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2227.66,
        "id": 823,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2224.86,
        "temperature": 0,
        "text": " yeah, 255 times three, divided by two.",
        "tokens": [
          50406,
          1338,
          11,
          3552,
          20,
          1413,
          1045,
          11,
          6666,
          538,
          732,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2230.82,
        "id": 824,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2229.54,
        "temperature": 0,
        "text": " I really should have stopped this video",
        "tokens": [
          50640,
          286,
          534,
          820,
          362,
          5936,
          341,
          960,
          50704
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2232.5,
        "id": 825,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2230.82,
        "temperature": 0,
        "text": " of two or three minutes ago when I had the chance.",
        "tokens": [
          50704,
          295,
          732,
          420,
          1045,
          2077,
          2057,
          562,
          286,
          632,
          264,
          2931,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2235.42,
        "id": 826,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2232.5,
        "temperature": 0,
        "text": " So we can see now, here's my color predictor.",
        "tokens": [
          50788,
          407,
          321,
          393,
          536,
          586,
          11,
          510,
          311,
          452,
          2017,
          6069,
          284,
          13,
          50934
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2238.2599999999998,
        "id": 827,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2235.42,
        "temperature": 0,
        "text": " It's trying to predict which text looks better",
        "tokens": [
          50934,
          467,
          311,
          1382,
          281,
          6069,
          597,
          2487,
          1542,
          1101,
          51076
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2239.38,
        "id": 828,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2238.2599999999998,
        "temperature": 0,
        "text": " over the color behind the scenes.",
        "tokens": [
          51076,
          670,
          264,
          2017,
          2261,
          264,
          8026,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2240.5,
        "id": 829,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2239.38,
        "temperature": 0,
        "text": " Now we're finally done.",
        "tokens": [
          51132,
          823,
          321,
          434,
          2721,
          1096,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2242.78,
        "id": 830,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2240.5,
        "temperature": 0,
        "text": " Oh, please, please, creative, wonderful people",
        "tokens": [
          51188,
          876,
          11,
          1767,
          11,
          1767,
          11,
          5880,
          11,
          3715,
          561,
          51302
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2244.7,
        "id": 831,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2242.78,
        "temperature": 0,
        "text": " of the internet, make a more interesting,",
        "tokens": [
          51302,
          295,
          264,
          4705,
          11,
          652,
          257,
          544,
          1880,
          11,
          51398
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2246.86,
        "id": 832,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2244.7,
        "temperature": 0,
        "text": " better version of this, and I will see you",
        "tokens": [
          51398,
          1101,
          3037,
          295,
          341,
          11,
          293,
          286,
          486,
          536,
          291,
          51506
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2247.94,
        "id": 833,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2246.86,
        "temperature": 0,
        "text": " in a future coding challenge.",
        "tokens": [
          51506,
          294,
          257,
          2027,
          17720,
          3430,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2249.74,
        "id": 834,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2247.94,
        "temperature": 0,
        "text": " Goodbye, thank you again to Jabril",
        "tokens": [
          51560,
          15528,
          11,
          1309,
          291,
          797,
          281,
          40319,
          24216,
          51650
        ]
      },
      {
        "avg_logprob": -0.2606658394455064,
        "compression_ratio": 1.6121794871794872,
        "end": 2251.14,
        "id": 835,
        "no_speech_prob": 0.00002668847082532011,
        "seek": 222402,
        "start": 2249.74,
        "temperature": 0,
        "text": " for this particular idea.",
        "tokens": [
          51650,
          337,
          341,
          1729,
          1558,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.36717810997596156,
        "compression_ratio": 2.348314606741573,
        "end": 2254.7599999999998,
        "id": 836,
        "no_speech_prob": 0.08626986294984818,
        "seek": 225114,
        "start": 2251.14,
        "temperature": 0.4,
        "text": " Subscribe to his channel, link in this video's description.",
        "tokens": [
          50364,
          10611,
          281,
          702,
          2269,
          11,
          2113,
          294,
          341,
          960,
          311,
          3855,
          13,
          50545
        ]
      },
      {
        "avg_logprob": -0.36717810997596156,
        "compression_ratio": 2.348314606741573,
        "end": 2255.6,
        "id": 837,
        "no_speech_prob": 0.08626986294984818,
        "seek": 225114,
        "start": 2254.7599999999998,
        "temperature": 0.4,
        "text": " Ding.",
        "tokens": [
          50545,
          220,
          35,
          278,
          13,
          50587
        ]
      },
      {
        "avg_logprob": -0.36717810997596156,
        "compression_ratio": 2.348314606741573,
        "end": 2260.6,
        "id": 838,
        "no_speech_prob": 0.08626986294984818,
        "seek": 225114,
        "start": 2255.6,
        "temperature": 0.4,
        "text": " ♪ Hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey ♪",
        "tokens": [
          50587,
          220,
          158,
          247,
          103,
          1911,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          220,
          158,
          247,
          103,
          50837
        ]
      },
      {
        "avg_logprob": -0.36717810997596156,
        "compression_ratio": 2.348314606741573,
        "end": 2265.7799999999997,
        "id": 839,
        "no_speech_prob": 0.08626986294984818,
        "seek": 225114,
        "start": 2260.7799999999997,
        "temperature": 0.4,
        "text": " ♪ Hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey ♪",
        "tokens": [
          50846,
          220,
          158,
          247,
          103,
          1911,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          11,
          4177,
          220,
          158,
          247,
          103,
          51096
        ]
      }
    ],
    "transcription": " Hello and welcome to another coding challenge. Now this coding challenge is number 99, which means the next coding challenge is number 100. And I have no idea what to do. I feel this pressure to do something special. So please, in the comments, write your suggestions for coding challenge number 100, and maybe I'll think of something, or you'll help me think of something. Okay, so what's happening now? I am going to do a coding challenge to make a neural network color predictor. This is based off of a project made by Jabril. Check out his YouTube channel. There's a link in this video's description. He has a video called Color Predictor Machine Learning Demo that I'd encourage you to watch. He also actually came on as a guest, and I'll link to a video with Jabril where he talks through this color predictor. But I'm going to make my own version of it, and I'm going to use my Toy Neural Network JavaScript library. Okay, so first, before I start coding, I want to spend some time with you, the viewer, just taking deep breaths together, thinking about flowers. Okay, well, I guess I should talk through what the problem is. So here's the problem, so to speak. Now, one of the reasons why I love this idea, which came from Jabril, is that I'm always looking for really simple, almost trivial scenarios to demonstrate a machine learning concept where all the pieces of how the algorithm works, it's visual, it involves interaction, it involves drawing, because this, to me, is a good basis for people watching and learning to then build their own more complex or sophisticated design machine learning system things. So this is incredibly simple, and in fact, just to be clear, you do not need a neural network for this. It almost makes no sense at all to use a neural network for this. But it makes the point, you might have heard this, you might have heard this idea that a neural network is a universal function approximator. So I think that this video and this topic and this demonstration will unpack what this means in a nice way. What do I mean by that? So what is the problem that we're trying to solve? So the problem is, let's say I have a color, some RGB color, some RGB color, and I want to put text on top of that color. So I could make a more complex problem, which I would encourage you to do as an exercise after watching this, what would be the most pleasantly looking or complimentary, that's an actual thing, color to overlay on that RGB color? But I'm just going to ask a simple question. Which looks better, black or white? And we could get into a whole discussion of why, you know, perception, what looks better, but I just mean just in the sort of arbitrary sense, like which is easier to read, which is more legible? And we could write a function, right? We could write a function, a JavaScript function, I'm just checking to see, right? And that JavaScript function takes as its arguments an R, a G, and a B, and what it does is it returns, maybe it returns, I mean, black, or maybe somewhere else in the function, it returns white. And maybe we just have like this if statement, and maybe I'm doing something like if R plus G plus B is less than 100, or less than 200, return black, otherwise return white. So this is the idea, this is a function, it takes inputs, how many inputs? Three, and it returns an output, how many outputs? One, but out of two possibilities is important here. There are two possible, out to two possibilities. It takes one output, it's a function that takes three inputs and returns one output. The inputs are numbers between zero and 255, and the output is one label, which is a string. But another way I could think about this is it could return a kind of probability value. How likely is it that black looks better, and how likely is it that white looks better? And that would be kind of also two, so two floating point numbers, you could think of it that way. So this is a function, so a lot of machine, like imagine this, so now this function takes an RGB color. Now let me give you another function. Write a function that takes an image data, a 200 by 200 pixel image, and then returns what's in that image. Now you could imagine, in this case, deciding whether it should be black or white is just a matter of, okay, is it bright, is it dark, which color's going to be, like a bright color looks better on a dark color, a dark color looks better on a bright color. But if I took in a full image and needed to return, whether it's a cat, a dog, a turtle, a coffee mug, a cell phone, a walking stick, a conductor's baton, I don't know where my brain is going here, a toy train. Try writing a bunch of if statements to do that. Well, if the pixel colors are this and shaped like this, having to hard code an algorithm, a function that takes inputs and generates an output would be really difficult. This is what a neural network is for. And just to make this case here, the idea here is that a neural network can approximate any function. It can learn to receive inputs and return the outputs for any input data for any sort of problem. Is this true that any, in capital letters, the big underline is true? That's an open question. What are the limitations? What should and should not we be doing? Should we even be using a neural network for this task? Are we causing harm by doing this machine learning task? But those questions aside, now we can say, well, if I have this quote unquote neural network thing, what if I were to just send three inputs into it, R, G, B, and then I want to receive two outputs, probability of black, probability of white? This is now a universal function approximator. It is going to stand in, so what is neural net, machine learning doesn't necessarily replace, you can think of it as, I mean, will machine learning replace the need to write code completely at some point? Maybe. But here, what I would make the case is that machine learning, a neural network, might replace the guts of a function that you might hard code otherwise. Okay, boy, am I spending a long time explaining this. So now, what goes here, what goes here? Now, if you want to learn more about the structure of a neural network and the internals of it, I would refer you to the 3Blue1Brown video series, as well as my video series, which goes through building this neural network library in JavaScript. For us, as the user of the neural network library, the only things we need to decide are how many inputs, and how many outputs, and then, so this is, inputs and outputs are the things we, as the end user of the neural network, look at and control. We're sending in the input, we're reading the output, we're doing something with the output. We're sending in the input, we're reading the output, we're doing something with the output. But, the sort of quote unquote magic, which isn't magic, it's just math, numbers multiplied and added together, all sorts of other stuff, is this idea of a hidden layer. And there could be multiple hidden layer, there could be hidden layers of different nodes, but for the sake of argument, this is such an incredibly simple problem, who knows if we even need the hidden layer for it, we probably do, but we can just kind of pick something somewhat arbitrarily. So I'm going to say there are three inputs, there are two outputs, and what I'm going to do is just say this is what Jabril used, so why not use the same? I'm going to add three hidden nodes. And the idea of a neural network is the inputs all go into each hidden node, they get processed by the hidden node, and each hidden node connects to every output, whoops, I did that, and then they get processed by the outputs, and we get the results. That's known as feed forward. What is that processing? It has to do with the weights of the connections, the summing of the values, the activation of the neural network. I think at this point, it probably makes more sense for me to refer you to my other tutorials that go through the mechanics of this. I just want to now use it in a sort of higher level way as a library, where I'm going to send in my inputs and look at the outputs. And of course, I'm going to have to train it. I'm going to have to teach the neural network to give me certain outputs that I want. So that's what I'm going to get into when I go and write the code right now. Okay, so first, let's take a look at Jabril's code. He might have a newer version by now, but this is what he demonstrated last week on the coding train. So I could say like, oh, I think white looks better on this color. By the way, I have no ability for, or talent for visual design whatsoever, I don't know, black looks better, black looks better, white looks better. So you can see, this is me active. This dot represents the computer guessing which ones it thinks it should be. And me clicking has to do with me giving this sort of training information. Like, hey, neural network, it should be this one. So I'm going to go through and build all the pieces of this. There's some other stuff going on in here where Jabril is using a genetic algorithm, and there's this sort of voting thing going on. But let's just start building some code from scratch, and we can kind of compare and contrast, or you can compare and contrast on your own later. Okay, so this is my color predictor. I'm going to go to an empty sketch. The first thing that I want to do is I'm just going to create variables for R, G, and B. And when the, I'm going to write, maybe I'll write a function, pick color, and I'm just going to say R equals random, 255, GB, and I am going to then draw the background, R, G, B, and I'm going to say mouse pressed, pick color. So let me make a few key points here. Me, in creating this example and writing this code, I'm not thinking about interaction design. I'm not thinking about visual design. I'm not thinking about optimized, efficient code. I just want to sort of demonstrate the idea and get something up and working quickly. You, the viewer, can then take this and make a more interesting, thoughtful, designed version of it, even perhaps with a different algorithm or a different problem altogether. But let's just see now, this should be enough code for me to, every time I click the mouse, get a new random color. Okay, so I might as well also pick that color in setup. Now, I also want to draw, let me say text size, 64. Then I want to say, let me do no stroke, I think. A text can have an outline and a fill, but I'm going to do fill zero, text black, and let me do text align center also. So black, and that should be, what is my, let me make the dimensions of this a little simpler, 400 by 300, so this would be, 100, 200, 150 then, I guess. 150, 150, I don't know. And 250, 150, and this would say white. So let's see how this goes. All right, so that's a little bit too big, but I could also just make it wider. 600, and then this would be 200 and 400, right? There we go. And this one should be fill 255. Okay, so now I have a system where at least I am seeing which one it should be, black or white. I'm seeing both colors written on top of the background. Let's draw a line down the middle. I think maybe visually it needs that. I don't think I centered these correctly, but whatever. Okay, okay, we're getting somewhere. Center, center, someone in the chat is telling me to use center, center, why not? So that aligned it center vertically too. Beautiful, thank you, well, that was an excellent suggestion. Okay, so now what I want to do is, guess what, we're ready. This is so, this is what I love about this problem. We're ready for the neural network because we can do it. So what do I need? I want to make a, I'm going to call it brain. I'm going to make a variable called brain. It's going to be the neural network. Now, I just don't get a neural network in JavaScript just by the nature of programming JavaScript. I'm getting it because I have imported already into my HTML file two files, nn.js and matrix.js. This is a little toy neural network library that I developed and a whole set of video tutorials. At some point in the future, I'm going to replace this with this new project called TensorFlow.js, which is a lower level machine learning library also ML5 is this other library, but I'll come back to that another time. I'm still using this little toy neural network. So what I want to do now in the code is I just want to say brain in setup. I want to say brain equals a new neural network. Now, it expects three arguments, three arguments. Now, this is not universal to how neural network libraries work. This is a very simple one that has very basic features. And what it expects is how many inputs, how many outputs and how many hidden nodes, but not in that order, inputs, hidden, outputs. So this we can see is three, three, two. That's the architecture, the model architecture that I have designed. Three, three, two. Wonderful. Now, I'm done, I got it. Woohoo, okay, no, I have to keep going. Now what I can do is let's say every time, so let's make a variable called which, like which one is better, black or white? And I will just start with saying black. And what I'm going to do is let's do the same sort of technique that Jibril did. If which equals black, then I'm going to draw a circle. A circle which is where? At 200, 200, 300, 60, 60. There, and then else, if it's white, then draw it at 400. And so this would be fill zero, this would be fill 255, and we're still no stroke. Okay, so now, we see, oh, that's very far down. So let me move this up to 200. That's 200. I have no sense of dimensions whatsoever. Perfect. Oh, this looks weird now, it's not all centered, but fine. Oh, I can't, I can't take it, I can't take it. Let's move this. I really shouldn't be doing this, but I'm going to. Let's make this 100, 100, and let's make this 200, 200. Ah, phew, okay, I feel better now. Okay, so it's always going to pick black right now, because no matter what, I've just made which equal to black. But I can use the neural network now. I can use the neural network. The neural network is my function approximator. Let's actually write this code with our own non-neural network first, just to make this case. I'm going to write color predictor, and I'm going to say get an RGB, and now if, I'm going to just say, if R plus G plus B is greater than 300, then return black, else return white. So I'm going to do a hard-coded, this is my own human learning algorithm. I've decided that this is what it means to predict which color would be better, and then I'm going to say let which equal color predictor, RGB. So now, we can see it's making that prediction, based on my algorithm. I wrote an algorithm to make that prediction. Now, so we've got this, we could be done. No machine learning necessary. I finished this project. Now what I want to do, though, is I want to comment this out, and I'm going to say, what am I going to say? I'm going to say, first, I need to make some inputs. So the neural network library expects as inputs, right? My library expects, and this is pretty typical of any kind of machine learning-based library that you might use. It expects the inputs to come in as an array of three numbers, and typically, you're going to want to have those numbers normalized between zero and one. So this is what I need to send into the neural network. So inputs equals an array, and so how do I normalize these values? I can just divide them all by 255. And again, more likely, there's going to be a much longer process of sort of cleaning and normalizing your data, but in this case of a single color, super easy to do. Now, what I'm going to do is I'm going to ask for the output from the neural network. Let outputs equal, and I'm going to say, brain dot, and the function, right? The function to do the feed forward algorithm to send the data through and get the result back in my library is called predict, because I'm making a prediction. Another term for this might be inference, guess, that type of thing. So I'm going to say brain dot predict, and I'm going to pass in the inputs. Now, let me just, let me just console log those outputs just so we can see, and this is going to sort of break, but let's just see what the outputs look like. Whoa, hold on. Why is this, oh, because draw is, so one thing I just realized is I'm kind of, I'm doing all this in the draw loop, which is sort of silly, so let me actually just say no loop, and then in pick color, in pick color, which is where, where's the pick color? Oh, right here, I'm going to say redraw. So I only want to like redraw the canvas up there. I don't have anything animating, so I don't need the draw loop to be going over and over again. So cannot read property predict of undefined sketch such as, oh, you know what? Why do I have that bug? I created the neural network after I called pick color. The neural network needs to exist before I call pick color, okay? That's good to know, great. So we can see, look at this, and why do I have this happen twice? 29, why is that happening twice? You know, I guess it's going through the draw loop once. So maybe, yeah, interestingly. Okay, I'm not going to worry about, I'm not going to get, I'll fiddle with that later. The point is, whoops. Every time I click, we can see, this is the output of the neural network. It's an array with two floating point numbers, and those I'm considering to be like the probability, right? If this number is higher, it should be a white, maybe black is the correct color. If this number is higher, the other one, whoops, my hand disappeared, the white color should be the one. Now, I haven't implemented some things. There's a particular algorithm which I really should put into my neural network library called Softmax. I'll have to make a video tutorial about that in the future which would ensure that these two numbers, these add up to a total of one and really represent a probability, but my neural network is very simple. I can just look at which of these output numbers is bigger. So I can say then, right here, I can say now, if outputs index zero is greater than outputs index one, we'll make that mean return black, otherwise, return white. So now, I have my color predictor function no longer uses a hard-coded algorithm, it uses the results of sending the input data through a neural network. So let's go ahead and run this. And I can click, now you can see here, it's kind of always picking white. If I refresh, still always picking white. If I refresh, it's kind of always picking black. So what's going on here? How come this isn't working? Why is this not learned properly? Which color should go on top of the other color? Guess what? The entire mechanic, all of the settings, all of the parameters, all of the weights of all these connections of the neural network were initialized completely randomly. A neural network isn't just going to learn as if by magic, it needs to be taught. And there are lots of different strategies for training and working with a neural network. One of those strategies is something called supervised learning. And you probably can't supervise learning, which I have covered in other videos, in particular, my doodle classification coding challenge. So you might look at that as an example. But what's going on here? So in a sort of normal, more data science-driven machine learning context, we might prepare a giant training set. I'm going to make a big spreadsheet of every RGB color I can think of, and which one looks better, black or white. That's my training data set to pass through and train this neural network with. Then I'm going to have a testing data set. And that testing data set is not part of the training data set, because I don't want the neural network to know about it, but it also has a bunch of label data, colors with black or white labels. Then I'm going to pass that through and see how well the neural network does guessing against those. And if it starts to do well, then I can say my model is complete, it has been trained, I can save it, and I can deploy it in some application which has to pick black or white on the fly. But I'm not going to do any of that in this video. I'm going to live in sort of a loosey-goosey interactive world where I'm just going to let it guess randomly, and I'm going to click in order to correct it. So I'm going to train the neural network one data point at a time with no training data, no testing data, just random data as I go. So you might think about how would you restructure this to in a more sort of traditional training, testing, deployment context. Okay, so I want to click, what I'm going to do here is as the trainer, I'm going to click on the side of the canvas that I think looks better. Like I think white looks better, so I'm going to click over here. Just to make this a little bit easier to follow, I'm also going into draw, I'm going to draw a stroke weight four, stroke 255, zero, I guess I'm going to align, width divided by two, zero, width divided by two, height. There we go. So I'm going to draw this so I can click, why is these are totally not centered at all? I'm like a lunatic. These are not in the right place. I'm sorry, I have to correct that. It's making me crazy. It is, how wide is the window? It's 600 wide, 300 is the middle, oh, silly me. 150, 350, thank you very much. No, 450, 450, thank you very much. 150, just please bear with me. 450, okay, now we're doing well. Okay, so now the idea here is every time I click over here, I want to teach the neural network which one I think it should be. So how do I do that? So I told you there was a function called predict, and the function called predict would send in the input data and give me an output prediction. Now what I want to do is I want to use a different function called train. So each time I click the mouse, where is that mouse, Pris? Before I pick the new color, I want to determine is the mouse on the right side or the left side? So if, so I want to create some inputs, which is an array. Let me just, let puts, inputs, and if mouse x is greater than width divided by two, then the correct, the correct, actually, so I'm sorry, I want to create some targets. This is known as targets. I mean, you can use different terms for all these things, but targets are the target outputs I want. So if I click on the right side, I want the target outputs for white, and white means the second number is greater than the first number. So the targets, if I click on the right, should be zero, one. This is the correct, this is the correct output if, that I'm telling the neural network should be if I'm clicking on the right side. Else, the targets, and I know I could use one of those ternary blah blah blah things, but this is just going to have to do. The targets are, if they're on the left, should be one comma zero. Let's pick up the pace here, people. By people, I mean me, not you. You're doing great if you're actually still watching this. And now what I'm going to do is I'm going to say brain.train, oh, I need those inputs. So the inputs are the same exact thing I did here. The inputs are the current RGB, and what I want to do is I want to say, hey, brain, train yourself with these inputs with these targets. And in fact, this now is going to, neural network is going to, what is it going to do? I'm saying, here are the inputs, here are the correct outputs that go with those inputs. Do whatever adjustments you need to do, whether you were right or wrong, just figure it out. And what is that figuring out? So interestingly enough, I think this is worth, even though this is covered in much more detail in my other videos, let's say the neural network, I feed in some inputs, and what it actually gives me is like 0.8, 0.2, right? This is what it gives me as the outputs. But I gave it, I'm training it, I'm going to give it targets. And the correct targets are zero, one. That's the output that I wanted to get. That's the correct output. So what the neural network does is actually calculate something called an error. And the error is really simple. It's simply the desired minus the guess, or the targets minus the prediction, or the targets minus the outputs. So the error would actually be negative 0.8, one minus, and 0.8, interestingly enough. Very symmetrical there. So this would be the error. And then what happens? Inside that train function, an algorithm called backpropagation happens. The backpropagation takes this error and sends it backwards. So when I do prediction, I'm sending the data forward through the neural network. The training process is about looking at the outputs, calculating an error, and sending the error backwards through the network. And all these little changes, all these weights that are adding up numbers and doing all this math, they all get adjusted. So the errors would adjust all the parameters. And that's what's happening. Again, you can dive into my other tutorials which go through this in more detail. But that's what's happening right here in this function. So we are ready to go. Right? All right. So what I'm going to do, maybe we'll do, I'm going to train this for a while. If you're watching the edited version of this, it'll speed through fast. If you're watching this live, here we go. Okay, I'm back. So I tried training this for a while. I tried talking about it for a little bit. I didn't really get very far, even though I think you can see like, ah, I'm going to like, I'm picking. And it's kind of actually, oops, no, I should really move. It's giving me sort of different results. That's black. This one is black. That's correct. That one is white. That's correct. Look at this. Yeah. Hey, I think we're good. I think we're good. I think we're good. I think we're good. I think we're good. I think we're good. I think we're good. I think we're good. I think we're good. I think we're good. Black is better with this one. White is better. I don't know. White. Anyway, you're done. So now now we moving to white. So now I'm going to try, let's try thinking. I mean, I don't know if we're going to get it, but you get the idea. Okay then. Let's strike this option, and I don't know if we're going to be able to have it flip over, because I think it's because of, I don't know, I don't know if I found right here but oh, wow, how dramatic of a turn that is? How dramatic. I bought what I was looking for. Wait, actually, wait, hold on, hold on, hold on. Hold on. Anyway, you can see it's kind of getting, I don't know that I've really given it enough training data to really work optimally. Maybe I, this could be an interesting project if this were like deployed in a distributed way on the web, and thousands of people could all come and click on it, and like through and train it together as a group of people in the world. But let's try training it automatically to see if that works a little bit better. So how are we going to do that? So let me go back to the code. Remember this nice little bit of code I had here? Let's train it to actually learn a certain threshold. So I'm going to, I'm going to write a function here called train color, and it gets an R, G, and B, and it's going to return black or white. And what I'm going to do now is in setup, this is a little bit silly, before I do anything, I'm just going to say for let i equal zero, i is less than 1,000, i++, and I'm going to pick a, I'm going to pick a different set of random colors that are different from the global random colors. Then I'm going to, I'm going to say the answer is, what is it, train color, train color with R, G, B, and you know what I'm going to do? I'm just going to do this, targets. Let's skip a step here, and this, I can't remember which is which. Whoops. Let's just return the targets. Is this right? Somebody in the chat tell me if I've got these backwards or not. Let's just return the targets. I'm kind of skipping some steps here. Now I'm not being as thoughtful about how I'm organizing this, but I want to get those targets. Then I want to say the inputs are R divided by 255G, G divided by 255B divided by 255, and this should say inputs, and then I'm going to say brain, train inputs with these targets. So this is me just running through and kind of quickly using 1,000 colors to train it, and I'm being told that this is probably backwards. There's no way I could have possibly guessed that correctly. Okay, so let's, and actually I'm going to even, I'm just going to, let's let it run 10,000 times. So I'm going to run 10,000 colors through the network right in setup as like training data basically. Okay, so now let's just, and actually in a way what I'm going to do now, just to see, I'm not even going to click. I'm going to not bother to train it anymore. I'm just going to pick, let me comment out my own interactive training, and let me just pick new colors, okay? So every time I click, yeah, you can see it's making guesses. Are they good guesses? I don't know, but I bet you those guesses are pretty accurately aligned with that threshold of 300. So I could continue to train it a little bit, but I feel pretty happy now. With this color predictor. Okay, what's going on? I finished this coding challenge. I'm going to release this code. What can you do with it? So a couple things. One is, could you make this same exact project, but instead of having it just pick whether black or white goes on top, could you pick a RGB color that looks nice? Maybe it's a, maybe you could have a neural network solve the formula for complementary colors. Could you think of a more thoughtful way to design this? Could you use some other data entirely? Could you train based on like font, which font to pick? Could you train a system to make design decisions based on some set of training data or some user interaction, something like that? So I hope you make your own neural network design predictor thingy, and share it with me. You can go to the CodingTrain.com website. There's some instructions there for how to contribute your version of a project like this. You can write in the comments. You can tweet me at Schiffman. I guess I'm supposed to say you should subscribe to the channel, blah, blah, blah, blah, blah. Thank you for tuning in, and there is the color predictor. Wait, hold on, stop, time out. I'm getting a good suggestion in the chat. It might be nice to see like what the number is. So hold on. Let's, this is a good idea. Let's do this. Hold on, hold on, time out, everybody. Okay. Where do I have, I have some console log going on here. Let me get rid of this console log, and let me in here, let's console log r plus g plus b. So let's see if this value is bigger, and I'm just going to floor it so it looks, I don't need to see the decimal. Let's see if this, let's see if it really learned the threshold of 300. Right? Right, 319. That should be white. So it didn't get that right. Whoops, 376, ah. 442, 289, oh wait. No, no, no, it did get it right. I've got it backwards. If it's higher than 300, it should be over black. If it's lower than 300, it should be over white. And we can see here, right, 289, white, 431, black, 513, black, 561, black, 527, right? This is working, and just to prove this point, let me run it again with a different threshold. Where do I add that? In the training. Let me give it a silly threshold of 100. That's much too low for it to be visually correct, probably, whatever that means. But we can see now, it's going to only go to white if it's below 100. Oh, it didn't, actually 97. It didn't even get there. Now, I'm going to have to do this for quite a while to get lucky enough to pick something lower than 100. I'm very unlikely to get a number lower than 100 because I'm picking three random numbers between zero and 255. So I actually have, I'd have to pick three random numbers basically lower than 33, which has a pretty low probability of doing that in a row. So let's do the opposite thing. Let's say, let's do this only if it's greater than 500. 296, white, so if I ever get it greater than 500, black. 393 is white. So it is learning that threshold, whatever I kind of, whatever I had. And I picked 300, and probably what would make sense for me to pick is just, you know, 256, or 255 times three divided by, yeah, 255 times three, divided by two. I really should have stopped this video of two or three minutes ago when I had the chance. So we can see now, here's my color predictor. It's trying to predict which text looks better over the color behind the scenes. Now we're finally done. Oh, please, please, creative, wonderful people of the internet, make a more interesting, better version of this, and I will see you in a future coding challenge. Goodbye, thank you again to Jabril for this particular idea. Subscribe to his channel, link in this video's description. Ding. ♪ Hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey ♪ ♪ Hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey, hey ♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:32.289045Z",
  "started_at": "2023-09-26T21:13:55.150533Z",
  "completed_at": "2023-09-26T21:25:49.812162Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=KtPpoMThKUs",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 714.661629
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/tdcxtmrbl5ulpzuhh57wipgifm/cancel",
    "get": "https://api.replicate.com/v1/predictions/tdcxtmrbl5ulpzuhh57wipgifm"
  }
}