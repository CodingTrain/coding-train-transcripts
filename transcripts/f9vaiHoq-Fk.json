{
  "id": "csgckgzbcxexrw6faut35xuosu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/f9vaiHoq-Fk.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/811096 [00:00<?, ?frames/s]\n  0%|          | 2200/811096 [00:04<24:44, 544.93frames/s]\n  1%|          | 4300/811096 [00:08<27:28, 489.27frames/s]\n  1%|          | 6500/811096 [00:13<27:21, 490.25frames/s]\n  1%|          | 9100/811096 [00:18<27:01, 494.67frames/s]\n  1%|▏         | 11300/811096 [00:24<30:19, 439.65frames/s]\n  2%|▏         | 13200/811096 [00:27<28:31, 466.08frames/s]\n  2%|▏         | 16100/811096 [00:32<26:04, 508.31frames/s]\n  2%|▏         | 19000/811096 [00:37<24:11, 545.84frames/s]\n  3%|▎         | 21700/811096 [00:42<24:44, 531.78frames/s]\n  3%|▎         | 24400/811096 [00:47<24:16, 539.97frames/s]\n  3%|▎         | 27200/811096 [00:52<23:54, 546.55frames/s]\n  4%|▎         | 29900/811096 [00:57<23:16, 559.59frames/s]\n  4%|▍         | 31500/811096 [01:00<24:05, 539.21frames/s]\n  4%|▍         | 33600/811096 [01:04<23:36, 548.75frames/s]\n  5%|▍         | 36500/811096 [01:10<25:05, 514.64frames/s]\n  5%|▍         | 39000/811096 [01:16<26:31, 485.15frames/s]\n  5%|▌         | 41600/811096 [01:21<26:51, 477.59frames/s]\n  5%|▌         | 44100/811096 [01:28<28:11, 453.52frames/s]\n  6%|▌         | 46900/811096 [01:33<27:38, 460.65frames/s]\n  6%|▌         | 49800/811096 [01:40<27:25, 462.53frames/s]\n  6%|▋         | 52100/811096 [01:44<26:13, 482.31frames/s]\n  7%|▋         | 54900/811096 [01:49<25:25, 495.73frames/s]\n  7%|▋         | 57500/811096 [01:56<27:30, 456.61frames/s]\n  7%|▋         | 60300/811096 [02:01<25:47, 485.14frames/s]\n  8%|▊         | 62800/811096 [02:06<25:56, 480.65frames/s]\n  8%|▊         | 65500/811096 [02:11<24:49, 500.50frames/s]\n  8%|▊         | 68200/811096 [02:18<26:19, 470.35frames/s]\n  9%|▊         | 70800/811096 [02:24<26:42, 462.07frames/s]\n  9%|▉         | 73500/811096 [02:29<26:33, 462.90frames/s]\n  9%|▉         | 76400/811096 [02:36<26:57, 454.28frames/s]\n 10%|▉         | 79100/811096 [02:41<25:52, 471.59frames/s]\n 10%|█         | 81500/811096 [02:45<24:39, 493.10frames/s]\n 10%|█         | 84100/811096 [02:51<24:44, 489.57frames/s]\n 11%|█         | 86800/811096 [02:56<24:18, 496.62frames/s]\n 11%|█         | 89600/811096 [03:02<25:01, 480.61frames/s]\n 11%|█▏        | 92200/811096 [03:08<24:45, 484.07frames/s]\n 12%|█▏        | 94400/811096 [03:12<24:58, 478.12frames/s]\n 12%|█▏        | 97200/811096 [03:16<22:19, 532.81frames/s]\n 12%|█▏        | 99900/811096 [03:20<20:53, 567.49frames/s]\n 13%|█▎        | 102600/811096 [03:26<21:41, 544.40frames/s]\n 13%|█▎        | 104500/811096 [03:29<21:46, 540.94frames/s]\n 13%|█▎        | 106800/811096 [03:32<19:07, 613.62frames/s]\n 14%|█▎        | 109800/811096 [03:37<19:40, 594.19frames/s]\n 14%|█▍        | 112600/811096 [03:41<18:24, 632.22frames/s]\n 14%|█▍        | 115500/811096 [03:47<19:26, 596.17frames/s]\n 15%|█▍        | 118400/811096 [03:52<20:12, 571.48frames/s]\n 15%|█▍        | 121200/811096 [03:56<19:14, 597.69frames/s]\n 15%|█▌        | 123500/811096 [04:01<19:40, 582.40frames/s]\n 16%|█▌        | 126500/811096 [04:05<18:08, 629.06frames/s]\n 16%|█▌        | 129400/811096 [04:11<19:42, 576.35frames/s]\n 16%|█▋        | 132000/811096 [04:15<19:29, 580.74frames/s]\n 17%|█▋        | 135000/811096 [04:19<18:36, 605.39frames/s]\n 17%|█▋        | 137300/811096 [04:22<17:12, 652.40frames/s]\n 17%|█▋        | 139700/811096 [04:27<18:17, 611.67frames/s]\n 18%|█▊        | 142600/811096 [04:33<19:34, 568.95frames/s]\n 18%|█▊        | 145300/811096 [04:38<20:36, 538.43frames/s]\n 18%|█▊        | 148100/811096 [04:44<21:40, 509.64frames/s]\n 19%|█▊        | 150800/811096 [04:49<20:56, 525.38frames/s]\n 19%|█▉        | 153500/811096 [04:54<20:12, 542.49frames/s]\n 19%|█▉        | 156100/811096 [05:00<21:30, 507.44frames/s]\n 20%|█▉        | 158500/811096 [05:04<21:14, 512.22frames/s]\n 20%|█▉        | 161300/811096 [05:07<17:55, 603.99frames/s]\n 20%|██        | 164100/811096 [05:14<20:17, 531.61frames/s]\n 21%|██        | 166600/811096 [05:18<19:24, 553.56frames/s]\n 21%|██        | 169300/811096 [05:23<19:28, 549.21frames/s]\n 21%|██        | 172100/811096 [05:28<19:10, 555.32frames/s]\n 22%|██▏       | 174900/811096 [05:33<19:49, 534.87frames/s]\n 22%|██▏       | 177700/811096 [05:40<21:00, 502.57frames/s]\n 22%|██▏       | 180600/811096 [05:47<22:39, 463.85frames/s]\n 23%|██▎       | 183200/811096 [05:53<23:10, 451.57frames/s]\n 23%|██▎       | 186100/811096 [06:00<23:15, 447.96frames/s]\n 23%|██▎       | 188900/811096 [06:06<22:46, 455.46frames/s]\n 24%|██▎       | 191600/811096 [06:11<21:41, 476.08frames/s]\n 24%|██▍       | 194300/811096 [06:18<23:20, 440.56frames/s]\n 24%|██▍       | 197200/811096 [06:24<23:03, 443.88frames/s]\n 25%|██▍       | 200000/811096 [06:30<22:04, 461.28frames/s]\n 25%|██▍       | 202500/811096 [06:34<20:58, 483.66frames/s]\n 25%|██▌       | 205300/811096 [06:40<20:59, 481.08frames/s]\n 26%|██▌       | 208100/811096 [06:45<19:32, 514.18frames/s]\n 26%|██▌       | 210500/811096 [06:49<19:14, 520.24frames/s]\n 26%|██▋       | 213200/811096 [06:53<18:01, 553.01frames/s]\n 27%|██▋       | 216000/811096 [06:56<15:22, 645.17frames/s]\n 27%|██▋       | 218600/811096 [07:01<16:22, 603.04frames/s]\n 27%|██▋       | 221500/811096 [07:07<16:57, 579.56frames/s]\n 27%|██▋       | 221500/811096 [07:24<16:57, 579.56frames/s]\n 28%|██▊       | 224300/811096 [07:30<36:44, 266.17frames/s]\n 28%|██▊       | 227100/811096 [07:34<29:54, 325.36frames/s]\n 28%|██▊       | 229800/811096 [07:40<26:37, 363.80frames/s]\n 29%|██▊       | 232500/811096 [07:43<22:25, 430.04frames/s]\n 29%|██▉       | 235200/811096 [07:46<18:27, 520.00frames/s]\n 29%|██▉       | 237900/811096 [07:51<18:47, 508.18frames/s]\n 30%|██▉       | 240800/811096 [07:56<17:23, 546.68frames/s]\n 30%|███       | 243700/811096 [08:02<17:55, 527.71frames/s]\n 30%|███       | 246600/811096 [08:06<16:01, 586.90frames/s]\n 31%|███       | 249500/811096 [08:11<16:54, 553.81frames/s]\n 31%|███       | 251800/811096 [08:15<16:41, 558.21frames/s]\n 31%|███▏      | 254000/811096 [08:18<14:47, 627.50frames/s]\n 32%|███▏      | 256600/811096 [08:21<13:42, 674.16frames/s]\n 32%|███▏      | 259200/811096 [08:26<14:58, 614.53frames/s]\n 32%|███▏      | 261900/811096 [08:30<14:12, 644.43frames/s]\n 33%|███▎      | 264700/811096 [08:34<13:55, 654.11frames/s]\n 33%|███▎      | 267500/811096 [08:37<12:55, 700.55frames/s]\n 33%|███▎      | 270200/811096 [08:40<11:49, 762.03frames/s]\n 33%|███▎      | 271100/811096 [08:42<13:08, 685.09frames/s]\n 34%|███▍      | 274100/811096 [08:43<09:11, 973.25frames/s]\n 34%|███▍      | 277000/811096 [08:45<07:26, 1196.24frames/s]\n 34%|███▍      | 279500/811096 [08:46<06:14, 1418.85frames/s]\n 35%|███▍      | 282200/811096 [08:46<05:14, 1681.20frames/s]\n 35%|███▌      | 284900/811096 [08:50<07:07, 1230.57frames/s]\n 35%|███▌      | 287800/811096 [08:54<08:36, 1012.38frames/s]\n 36%|███▌      | 290700/811096 [08:58<09:20, 928.01frames/s] \n 36%|███▌      | 293300/811096 [09:01<10:14, 842.07frames/s]\n 36%|███▋      | 296000/811096 [09:07<12:44, 673.99frames/s]\n 37%|███▋      | 298600/811096 [09:12<13:29, 632.86frames/s]\n 37%|███▋      | 301500/811096 [09:16<13:05, 648.91frames/s]\n 38%|███▊      | 304400/811096 [09:22<13:59, 603.82frames/s]\n 38%|███▊      | 307400/811096 [09:25<12:04, 695.48frames/s]\n 38%|███▊      | 309200/811096 [09:26<11:13, 744.82frames/s]\n 38%|███▊      | 312200/811096 [09:28<09:04, 915.71frames/s]\n 39%|███▉      | 315100/811096 [09:41<17:55, 461.26frames/s]\n 39%|███▉      | 318000/811096 [09:47<16:56, 485.26frames/s]\n 40%|███▉      | 320900/811096 [09:52<16:34, 492.77frames/s]\n 40%|███▉      | 323400/811096 [09:58<16:49, 483.14frames/s]\n 40%|████      | 326300/811096 [10:03<16:19, 494.86frames/s]\n 41%|████      | 329000/811096 [10:08<15:43, 511.01frames/s]\n 41%|████      | 331700/811096 [10:13<15:20, 520.90frames/s]\n 41%|████      | 334400/811096 [10:18<15:18, 519.16frames/s]\n 42%|████▏     | 337000/811096 [10:22<14:26, 547.36frames/s]\n 42%|████▏     | 339600/811096 [10:28<15:27, 508.49frames/s]\n 42%|████▏     | 341900/811096 [10:32<14:16, 547.90frames/s]\n 43%|████▎     | 344800/811096 [10:37<14:16, 544.43frames/s]\n 43%|████▎     | 347600/811096 [10:41<12:57, 596.36frames/s]\n 43%|████▎     | 350300/811096 [10:46<13:02, 588.60frames/s]\n 44%|████▎     | 353200/811096 [10:50<12:17, 620.87frames/s]\n 44%|████▍     | 355900/811096 [10:56<13:31, 561.06frames/s]\n 44%|████▍     | 358600/811096 [10:59<12:36, 598.20frames/s]\n 45%|████▍     | 361500/811096 [11:05<13:21, 560.61frames/s]\n 45%|████▍     | 364100/811096 [11:10<13:42, 543.65frames/s]\n 45%|████▌     | 366800/811096 [11:17<15:11, 487.62frames/s]\n 46%|████▌     | 369600/811096 [11:21<13:12, 557.04frames/s]\n 46%|████▌     | 372300/811096 [11:24<12:00, 609.22frames/s]\n 46%|████▌     | 375100/811096 [11:29<12:29, 581.37frames/s]\n 47%|████▋     | 377700/811096 [11:35<13:35, 531.40frames/s]\n 47%|████▋     | 380500/811096 [11:42<14:23, 498.41frames/s]\n 47%|████▋     | 383000/811096 [11:47<14:33, 490.00frames/s]\n 48%|████▊     | 385900/811096 [11:53<14:10, 499.82frames/s]\n 48%|████▊     | 388400/811096 [11:57<13:46, 511.67frames/s]\n 48%|████▊     | 391200/811096 [12:02<13:08, 532.49frames/s]\n 49%|████▊     | 394100/811096 [12:08<13:32, 513.48frames/s]\n 49%|████▉     | 396800/811096 [12:14<14:14, 484.59frames/s]\n 49%|████▉     | 399300/811096 [12:19<13:41, 501.39frames/s]\n 50%|████▉     | 401900/811096 [12:24<13:42, 497.48frames/s]\n 50%|████▉     | 404700/811096 [12:29<12:41, 533.86frames/s]\n 50%|█████     | 407400/811096 [12:34<12:40, 530.72frames/s]\n 51%|█████     | 410200/811096 [12:39<12:43, 524.89frames/s]\n 51%|█████     | 412600/811096 [12:43<11:51, 560.00frames/s]\n 51%|█████     | 415500/811096 [12:49<12:09, 542.12frames/s]\n 52%|█████▏    | 418400/811096 [12:54<12:16, 533.37frames/s]\n 52%|█████▏    | 420500/811096 [12:58<12:08, 535.84frames/s]\n 52%|█████▏    | 422700/811096 [13:01<11:18, 572.18frames/s]\n 52%|█████▏    | 424900/811096 [13:04<10:47, 596.40frames/s]\n 53%|█████▎    | 427200/811096 [13:09<11:22, 562.53frames/s]\n 53%|█████▎    | 430000/811096 [13:16<12:27, 509.90frames/s]\n 53%|█████▎    | 432700/811096 [13:21<12:23, 508.74frames/s]\n 54%|█████▎    | 435500/811096 [13:28<13:35, 460.48frames/s]\n 54%|█████▍    | 438300/811096 [13:33<12:15, 507.03frames/s]\n 54%|█████▍    | 441000/811096 [13:37<11:27, 538.23frames/s]\n 55%|█████▍    | 443600/811096 [13:42<11:41, 523.51frames/s]\n 55%|█████▌    | 446400/811096 [13:47<11:23, 533.43frames/s]\n 55%|█████▌    | 449300/811096 [13:53<11:22, 530.32frames/s]\n 56%|█████▌    | 451900/811096 [13:58<11:35, 516.62frames/s]\n 56%|█████▌    | 454700/811096 [14:04<11:35, 512.65frames/s]\n 56%|█████▋    | 457300/811096 [14:10<12:29, 472.04frames/s]\n 57%|█████▋    | 460200/811096 [14:14<10:41, 546.61frames/s]\n 57%|█████▋    | 463200/811096 [14:18<10:06, 573.89frames/s]\n 57%|█████▋    | 466200/811096 [14:23<09:36, 598.00frames/s]\n 58%|█████▊    | 469200/811096 [14:25<07:44, 735.42frames/s]\n 58%|█████▊    | 472000/811096 [14:28<07:05, 797.08frames/s]\n 59%|█████▊    | 474600/811096 [14:33<08:07, 690.79frames/s]\n 59%|█████▉    | 477500/811096 [14:37<08:00, 693.79frames/s]\n 59%|█████▉    | 480100/811096 [14:43<09:20, 591.03frames/s]\n 59%|█████▉    | 481800/811096 [14:46<09:20, 587.98frames/s]\n 60%|█████▉    | 484500/811096 [14:48<07:53, 689.31frames/s]\n 60%|██████    | 486900/811096 [14:53<08:43, 619.35frames/s]\n 60%|██████    | 488500/811096 [14:56<08:57, 600.15frames/s]\n 61%|██████    | 491000/811096 [14:58<07:35, 703.48frames/s]\n 61%|██████    | 493600/811096 [15:03<07:51, 673.29frames/s]\n 61%|██████    | 496200/811096 [15:08<08:51, 592.25frames/s]\n 61%|██████▏   | 498300/811096 [15:12<08:46, 593.67frames/s]\n 62%|██████▏   | 501200/811096 [15:17<09:13, 559.95frames/s]\n 62%|██████▏   | 504100/811096 [15:24<09:58, 512.70frames/s]\n 62%|██████▏   | 506900/811096 [15:30<10:05, 502.45frames/s]\n 63%|██████▎   | 509700/811096 [15:36<10:02, 500.38frames/s]\n 63%|██████▎   | 512200/811096 [15:39<09:06, 547.18frames/s]\n 63%|██████▎   | 514400/811096 [15:41<07:52, 627.37frames/s]\n 64%|██████▎   | 516000/811096 [15:42<06:54, 711.95frames/s]\n 64%|██████▍   | 518700/811096 [15:45<06:16, 777.23frames/s]\n 64%|██████▍   | 521300/811096 [15:48<06:13, 775.21frames/s]\n 65%|██████▍   | 524000/811096 [15:52<06:25, 744.79frames/s]\n 65%|██████▍   | 526900/811096 [15:57<06:41, 707.00frames/s]\n 65%|██████▌   | 529200/811096 [16:00<06:48, 690.29frames/s]\n 66%|██████▌   | 531900/811096 [16:05<07:15, 640.59frames/s]\n 66%|██████▌   | 534500/811096 [16:08<06:22, 722.52frames/s]\n 66%|██████▌   | 536900/811096 [16:12<06:40, 684.27frames/s]\n 67%|██████▋   | 539600/811096 [16:17<07:03, 641.19frames/s]\n 67%|██████▋   | 541700/811096 [16:21<07:43, 581.05frames/s]\n 67%|██████▋   | 544500/811096 [16:25<07:02, 631.67frames/s]\n 67%|██████▋   | 547100/811096 [16:29<06:58, 630.61frames/s]\n 68%|██████▊   | 550000/811096 [16:32<06:08, 708.96frames/s]\n 68%|██████▊   | 552400/811096 [16:36<06:32, 659.76frames/s]\n 68%|██████▊   | 555100/811096 [16:39<05:59, 711.10frames/s]\n 69%|██████▉   | 557800/811096 [16:44<06:08, 687.97frames/s]\n 69%|██████▉   | 560700/811096 [16:50<07:00, 595.28frames/s]\n 69%|██████▉   | 563600/811096 [16:55<06:53, 598.65frames/s]\n 70%|██████▉   | 566500/811096 [17:01<07:36, 535.59frames/s]\n 70%|███████   | 569100/811096 [17:05<07:05, 568.65frames/s]\n 71%|███████   | 572000/811096 [17:11<07:06, 561.04frames/s]\n 71%|███████   | 574800/811096 [17:15<06:39, 591.44frames/s]\n 71%|███████   | 577700/811096 [17:19<06:09, 630.94frames/s]\n 72%|███████▏  | 580500/811096 [17:23<06:09, 623.49frames/s]\n 72%|███████▏  | 583200/811096 [17:27<05:50, 651.09frames/s]\n 72%|███████▏  | 585400/811096 [17:30<05:31, 681.56frames/s]\n 73%|███████▎  | 588100/811096 [17:32<04:52, 763.65frames/s]\n 73%|███████▎  | 590300/811096 [17:36<04:58, 740.69frames/s]\n 73%|███████▎  | 593000/811096 [17:38<04:34, 793.71frames/s]\n 73%|███████▎  | 595900/811096 [17:43<05:00, 716.94frames/s]\n 74%|███████▍  | 598400/811096 [17:50<06:17, 563.72frames/s]\n 74%|███████▍  | 601300/811096 [17:54<05:55, 590.74frames/s]\n 74%|███████▍  | 603900/811096 [17:59<05:55, 583.36frames/s]\n 75%|███████▍  | 606400/811096 [18:00<04:43, 721.31frames/s]\n 75%|███████▌  | 609000/811096 [18:04<04:47, 703.72frames/s]\n 75%|███████▌  | 611300/811096 [18:08<04:42, 706.36frames/s]\n 76%|███████▌  | 614000/811096 [18:12<04:50, 679.26frames/s]\n 76%|███████▌  | 616900/811096 [18:17<05:02, 641.97frames/s]\n 76%|███████▋  | 619300/811096 [18:21<05:01, 635.30frames/s]\n 77%|███████▋  | 621800/811096 [18:24<04:33, 692.63frames/s]\n 77%|███████▋  | 624700/811096 [18:26<03:55, 792.89frames/s]\n 77%|███████▋  | 627500/811096 [18:31<04:14, 721.62frames/s]\n 78%|███████▊  | 629700/811096 [18:34<04:13, 716.55frames/s]\n 78%|███████▊  | 631600/811096 [18:35<03:38, 821.01frames/s]\n 78%|███████▊  | 634300/811096 [18:38<03:16, 900.25frames/s]\n 79%|███████▊  | 636900/811096 [18:41<03:12, 906.10frames/s]\n 79%|███████▉  | 639700/811096 [18:43<03:00, 949.42frames/s]\n 79%|███████▉  | 642600/811096 [18:47<03:03, 918.87frames/s]\n 80%|███████▉  | 644900/811096 [18:48<02:46, 999.78frames/s]\n 80%|███████▉  | 647800/811096 [18:49<02:10, 1247.77frames/s]\n 80%|████████  | 649800/811096 [18:51<02:16, 1181.04frames/s]\n 80%|████████  | 652500/811096 [18:53<01:58, 1339.36frames/s]\n 81%|████████  | 655300/811096 [18:56<02:21, 1099.85frames/s]\n 81%|████████  | 657800/811096 [18:59<02:26, 1044.08frames/s]\n 81%|████████▏ | 660200/811096 [19:02<02:32, 987.81frames/s] \n 82%|████████▏ | 663200/811096 [19:03<01:54, 1295.38frames/s]\n 82%|████████▏ | 665500/811096 [19:03<01:35, 1525.38frames/s]\n 82%|████████▏ | 668500/811096 [19:04<01:17, 1836.31frames/s]\n 83%|████████▎ | 669900/811096 [19:05<01:20, 1749.62frames/s]\n 83%|████████▎ | 672600/811096 [19:06<01:09, 2001.30frames/s]\n 83%|████████▎ | 675500/811096 [19:08<01:08, 1977.71frames/s]\n 84%|████████▎ | 678200/811096 [19:12<01:52, 1185.04frames/s]\n 84%|████████▎ | 679100/811096 [19:14<02:10, 1009.26frames/s]\n 84%|████████▍ | 682100/811096 [19:15<01:29, 1437.75frames/s]\n 84%|████████▍ | 684600/811096 [19:17<01:45, 1201.15frames/s]\n 85%|████████▍ | 687100/811096 [19:20<01:55, 1072.04frames/s]\n 85%|████████▌ | 689900/811096 [19:23<02:00, 1005.79frames/s]\n 85%|████████▌ | 691100/811096 [19:26<02:20, 856.82frames/s] \n 86%|████████▌ | 694100/811096 [19:27<01:36, 1207.30frames/s]\n 86%|████████▌ | 697100/811096 [19:27<01:09, 1629.32frames/s]\n 86%|████████▋ | 699800/811096 [19:30<01:18, 1424.84frames/s]\n 87%|████████▋ | 702600/811096 [19:33<01:29, 1217.29frames/s]\n 87%|████████▋ | 705400/811096 [19:38<01:58, 895.48frames/s] \n 87%|████████▋ | 708300/811096 [19:42<02:04, 828.20frames/s]\n 88%|████████▊ | 711200/811096 [19:49<02:37, 635.13frames/s]\n 88%|████████▊ | 714100/811096 [19:54<02:40, 605.84frames/s]\n 88%|████████▊ | 716600/811096 [19:59<02:42, 580.05frames/s]\n 89%|████████▊ | 719200/811096 [20:03<02:33, 599.49frames/s]\n 89%|████████▉ | 722200/811096 [20:08<02:25, 609.18frames/s]\n 89%|████████▉ | 725000/811096 [20:12<02:23, 598.68frames/s]\n 90%|████████▉ | 727800/811096 [20:19<02:36, 530.67frames/s]\n 90%|█████████ | 730400/811096 [20:25<02:38, 510.04frames/s]\n 90%|█████████ | 733200/811096 [20:30<02:30, 516.59frames/s]\n 91%|█████████ | 736000/811096 [20:36<02:27, 510.78frames/s]\n 91%|█████████ | 738800/811096 [20:42<02:28, 487.43frames/s]\n 91%|█████████▏| 741400/811096 [20:49<02:32, 455.67frames/s]\n 92%|█████████▏| 744100/811096 [20:56<02:36, 428.20frames/s]\n 92%|█████████▏| 747000/811096 [21:03<02:35, 411.52frames/s]\n 92%|█████████▏| 750000/811096 [21:09<02:19, 438.12frames/s]\n 93%|█████████▎| 752600/811096 [21:16<02:15, 430.61frames/s]\n 93%|█████████▎| 755600/811096 [21:19<01:48, 512.33frames/s]\n 93%|█████████▎| 758300/811096 [21:26<01:51, 472.46frames/s]\n 94%|█████████▍| 761300/811096 [21:32<01:45, 470.43frames/s]\n 94%|█████████▍| 763700/811096 [21:37<01:40, 469.41frames/s]\n 94%|█████████▍| 766400/811096 [21:41<01:23, 535.12frames/s]\n 95%|█████████▍| 768700/811096 [21:45<01:18, 540.91frames/s]\n 95%|█████████▌| 771400/811096 [21:51<01:17, 514.62frames/s]\n 95%|█████████▌| 774200/811096 [21:55<01:04, 568.52frames/s]\n 96%|█████████▌| 776700/811096 [22:00<01:05, 526.49frames/s]\n 96%|█████████▌| 779400/811096 [22:06<01:02, 508.38frames/s]\n 96%|█████████▋| 782100/811096 [22:11<00:54, 530.10frames/s]\n 97%|█████████▋| 784800/811096 [22:15<00:48, 545.20frames/s]\n 97%|█████████▋| 787600/811096 [22:21<00:45, 519.14frames/s]\n 97%|█████████▋| 790400/811096 [22:26<00:37, 547.68frames/s]\n 98%|█████████▊| 793100/811096 [22:30<00:31, 577.30frames/s]\n 98%|█████████▊| 796000/811096 [22:34<00:25, 591.32frames/s]\n 98%|█████████▊| 798500/811096 [22:39<00:21, 588.36frames/s]\n 99%|█████████▉| 801300/811096 [22:44<00:17, 560.50frames/s]\n 99%|█████████▉| 804100/811096 [22:50<00:13, 518.64frames/s]\n 99%|█████████▉| 806900/811096 [22:55<00:07, 537.13frames/s]\n100%|█████████▉| 809100/811096 [23:00<00:03, 529.30frames/s]\n100%|██████████| 811096/811096 [23:04<00:00, 521.99frames/s]\n100%|██████████| 811096/811096 [23:04<00:00, 586.02frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.341474038583261,
        "compression_ratio": 1.5515463917525774,
        "end": 7,
        "id": 0,
        "no_speech_prob": 0.06542010605335236,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Good afternoon and welcome to a special extra bonus live stream.",
        "tokens": [
          50364,
          2205,
          6499,
          293,
          2928,
          281,
          257,
          2121,
          2857,
          10882,
          1621,
          4309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.341474038583261,
        "compression_ratio": 1.5515463917525774,
        "end": 16,
        "id": 1,
        "no_speech_prob": 0.06542010605335236,
        "seek": 0,
        "start": 7,
        "temperature": 0,
        "text": " As you know, I typically, well I don't know if you know this, but if you're watching or if you watched before, I typically live stream on Fridays.",
        "tokens": [
          50714,
          1018,
          291,
          458,
          11,
          286,
          5850,
          11,
          731,
          286,
          500,
          380,
          458,
          498,
          291,
          458,
          341,
          11,
          457,
          498,
          291,
          434,
          1976,
          420,
          498,
          291,
          6337,
          949,
          11,
          286,
          5850,
          1621,
          4309,
          322,
          46306,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.341474038583261,
        "compression_ratio": 1.5515463917525774,
        "end": 21,
        "id": 2,
        "no_speech_prob": 0.06542010605335236,
        "seek": 0,
        "start": 16,
        "temperature": 0,
        "text": " I'm sorry, this music is just so catchy, can't stop enjoying it.",
        "tokens": [
          51164,
          286,
          478,
          2597,
          11,
          341,
          1318,
          307,
          445,
          370,
          47168,
          11,
          393,
          380,
          1590,
          9929,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.341474038583261,
        "compression_ratio": 1.5515463917525774,
        "end": 22,
        "id": 3,
        "no_speech_prob": 0.06542010605335236,
        "seek": 0,
        "start": 21,
        "temperature": 0,
        "text": " It's gonna be over soon.",
        "tokens": [
          51414,
          467,
          311,
          799,
          312,
          670,
          2321,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2410347436064033,
        "compression_ratio": 1.4885844748858448,
        "end": 30,
        "id": 4,
        "no_speech_prob": 0.10223795473575592,
        "seek": 2200,
        "start": 22,
        "temperature": 0,
        "text": " I try to time it where I come in right when there's about 10 to 15 seconds left so the music can trail off to the end.",
        "tokens": [
          50364,
          286,
          853,
          281,
          565,
          309,
          689,
          286,
          808,
          294,
          558,
          562,
          456,
          311,
          466,
          1266,
          281,
          2119,
          3949,
          1411,
          370,
          264,
          1318,
          393,
          9924,
          766,
          281,
          264,
          917,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2410347436064033,
        "compression_ratio": 1.4885844748858448,
        "end": 35,
        "id": 5,
        "no_speech_prob": 0.10223795473575592,
        "seek": 2200,
        "start": 30,
        "temperature": 0,
        "text": " But it was at like 35 seconds, so now I'm just kind of waiting for it to end.",
        "tokens": [
          50764,
          583,
          309,
          390,
          412,
          411,
          6976,
          3949,
          11,
          370,
          586,
          286,
          478,
          445,
          733,
          295,
          3806,
          337,
          309,
          281,
          917,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2410347436064033,
        "compression_ratio": 1.4885844748858448,
        "end": 36,
        "id": 6,
        "no_speech_prob": 0.10223795473575592,
        "seek": 2200,
        "start": 35,
        "temperature": 0,
        "text": " Okay, it's over now.",
        "tokens": [
          51014,
          1033,
          11,
          309,
          311,
          670,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2410347436064033,
        "compression_ratio": 1.4885844748858448,
        "end": 38,
        "id": 7,
        "no_speech_prob": 0.10223795473575592,
        "seek": 2200,
        "start": 36,
        "temperature": 0,
        "text": " So here I am.",
        "tokens": [
          51064,
          407,
          510,
          286,
          669,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2410347436064033,
        "compression_ratio": 1.4885844748858448,
        "end": 43,
        "id": 8,
        "no_speech_prob": 0.10223795473575592,
        "seek": 2200,
        "start": 38,
        "temperature": 0,
        "text": " I had something get cancelled today that I typically often have to do on Wednesday afternoons.",
        "tokens": [
          51164,
          286,
          632,
          746,
          483,
          25103,
          965,
          300,
          286,
          5850,
          2049,
          362,
          281,
          360,
          322,
          10579,
          934,
          1771,
          892,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19717840714888138,
        "compression_ratio": 1.6324786324786325,
        "end": 51,
        "id": 9,
        "no_speech_prob": 0.561814546585083,
        "seek": 4300,
        "start": 43,
        "temperature": 0,
        "text": " I have been aspiring for a while to do more often shorter live streams than less frequent longer live streams.",
        "tokens": [
          50364,
          286,
          362,
          668,
          45405,
          337,
          257,
          1339,
          281,
          360,
          544,
          2049,
          11639,
          1621,
          15842,
          813,
          1570,
          18004,
          2854,
          1621,
          15842,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19717840714888138,
        "compression_ratio": 1.6324786324786325,
        "end": 60,
        "id": 10,
        "no_speech_prob": 0.561814546585083,
        "seek": 4300,
        "start": 51,
        "temperature": 0,
        "text": " As much as some people might enjoy the three or four hours at a time of live streaming on a Friday, I do find that the content somewhat suffers, especially towards the end.",
        "tokens": [
          50764,
          1018,
          709,
          382,
          512,
          561,
          1062,
          2103,
          264,
          1045,
          420,
          1451,
          2496,
          412,
          257,
          565,
          295,
          1621,
          11791,
          322,
          257,
          6984,
          11,
          286,
          360,
          915,
          300,
          264,
          2701,
          8344,
          33776,
          11,
          2318,
          3030,
          264,
          917,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19717840714888138,
        "compression_ratio": 1.6324786324786325,
        "end": 65,
        "id": 11,
        "no_speech_prob": 0.561814546585083,
        "seek": 4300,
        "start": 60,
        "temperature": 0,
        "text": " And if I can find little pockets of time to record a video, to do a tutorial, to update something.",
        "tokens": [
          51214,
          400,
          498,
          286,
          393,
          915,
          707,
          16491,
          295,
          565,
          281,
          2136,
          257,
          960,
          11,
          281,
          360,
          257,
          7073,
          11,
          281,
          5623,
          746,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23124095628846367,
        "compression_ratio": 1.5893536121673004,
        "end": 77,
        "id": 12,
        "no_speech_prob": 0.3205891251564026,
        "seek": 6500,
        "start": 65,
        "temperature": 0,
        "text": " And so today actually I was thinking, oh I have this extra bit of time, what I'm gonna do is I'm gonna sit at my computer and go through a bunch of pull requests on the toy neural network library that I built last Friday.",
        "tokens": [
          50364,
          400,
          370,
          965,
          767,
          286,
          390,
          1953,
          11,
          1954,
          286,
          362,
          341,
          2857,
          857,
          295,
          565,
          11,
          437,
          286,
          478,
          799,
          360,
          307,
          286,
          478,
          799,
          1394,
          412,
          452,
          3820,
          293,
          352,
          807,
          257,
          3840,
          295,
          2235,
          12475,
          322,
          264,
          12058,
          18161,
          3209,
          6405,
          300,
          286,
          3094,
          1036,
          6984,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23124095628846367,
        "compression_ratio": 1.5893536121673004,
        "end": 84,
        "id": 13,
        "no_speech_prob": 0.3205891251564026,
        "seek": 6500,
        "start": 77,
        "temperature": 0,
        "text": " And then I thought, eh, I might as well just live stream that because I've got some questions around that and I can talk about it.",
        "tokens": [
          50964,
          400,
          550,
          286,
          1194,
          11,
          7670,
          11,
          286,
          1062,
          382,
          731,
          445,
          1621,
          4309,
          300,
          570,
          286,
          600,
          658,
          512,
          1651,
          926,
          300,
          293,
          286,
          393,
          751,
          466,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23124095628846367,
        "compression_ratio": 1.5893536121673004,
        "end": 90,
        "id": 14,
        "no_speech_prob": 0.3205891251564026,
        "seek": 6500,
        "start": 84,
        "temperature": 0,
        "text": " I don't see anybody saying that they are listening.",
        "tokens": [
          51314,
          286,
          500,
          380,
          536,
          4472,
          1566,
          300,
          436,
          366,
          4764,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23124095628846367,
        "compression_ratio": 1.5893536121673004,
        "end": 91,
        "id": 15,
        "no_speech_prob": 0.3205891251564026,
        "seek": 6500,
        "start": 90,
        "temperature": 0,
        "text": " Oh, they are.",
        "tokens": [
          51614,
          876,
          11,
          436,
          366,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25871548887159,
        "compression_ratio": 1.6091549295774648,
        "end": 95,
        "id": 16,
        "no_speech_prob": 0.2333717942237854,
        "seek": 9100,
        "start": 91,
        "temperature": 0,
        "text": " Okay, for a second there I thought, did I just totally not hit the start streaming button?",
        "tokens": [
          50364,
          1033,
          11,
          337,
          257,
          1150,
          456,
          286,
          1194,
          11,
          630,
          286,
          445,
          3879,
          406,
          2045,
          264,
          722,
          11791,
          2960,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.25871548887159,
        "compression_ratio": 1.6091549295774648,
        "end": 103,
        "id": 17,
        "no_speech_prob": 0.2333717942237854,
        "seek": 9100,
        "start": 95,
        "temperature": 0,
        "text": " The other thing was, is I've had this cold and I was kind of sick on a little bit last Friday and much more over the weekend and Monday and I thought, oh I'm all the way better now.",
        "tokens": [
          50564,
          440,
          661,
          551,
          390,
          11,
          307,
          286,
          600,
          632,
          341,
          3554,
          293,
          286,
          390,
          733,
          295,
          4998,
          322,
          257,
          707,
          857,
          1036,
          6984,
          293,
          709,
          544,
          670,
          264,
          6711,
          293,
          8138,
          293,
          286,
          1194,
          11,
          1954,
          286,
          478,
          439,
          264,
          636,
          1101,
          586,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.25871548887159,
        "compression_ratio": 1.6091549295774648,
        "end": 108,
        "id": 18,
        "no_speech_prob": 0.2333717942237854,
        "seek": 9100,
        "start": 103,
        "temperature": 0,
        "text": " And then all of a sudden I'm talking and realizing, eh, there's still a little bit of scratchiness there.",
        "tokens": [
          50964,
          400,
          550,
          439,
          295,
          257,
          3990,
          286,
          478,
          1417,
          293,
          16734,
          11,
          7670,
          11,
          456,
          311,
          920,
          257,
          707,
          857,
          295,
          8459,
          1324,
          456,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.25871548887159,
        "compression_ratio": 1.6091549295774648,
        "end": 113,
        "id": 19,
        "no_speech_prob": 0.2333717942237854,
        "seek": 9100,
        "start": 108,
        "temperature": 0,
        "text": " So I will be here, it's about 2.30 my time, Eastern time now in New York City.",
        "tokens": [
          51214,
          407,
          286,
          486,
          312,
          510,
          11,
          309,
          311,
          466,
          568,
          13,
          3446,
          452,
          565,
          11,
          12901,
          565,
          586,
          294,
          1873,
          3609,
          4392,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21025863815756404,
        "compression_ratio": 1.5741935483870968,
        "end": 121,
        "id": 20,
        "no_speech_prob": 0.6788599491119385,
        "seek": 11300,
        "start": 113,
        "temperature": 0,
        "text": " I will probably live stream for one hour, possibly a little bit longer, but this is gonna be a shorter live stream.",
        "tokens": [
          50364,
          286,
          486,
          1391,
          1621,
          4309,
          337,
          472,
          1773,
          11,
          6264,
          257,
          707,
          857,
          2854,
          11,
          457,
          341,
          307,
          799,
          312,
          257,
          11639,
          1621,
          4309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21025863815756404,
        "compression_ratio": 1.5741935483870968,
        "end": 126,
        "id": 21,
        "no_speech_prob": 0.6788599491119385,
        "seek": 11300,
        "start": 121,
        "temperature": 0,
        "text": " And I have two plans, I have two plans for today.",
        "tokens": [
          50764,
          400,
          286,
          362,
          732,
          5482,
          11,
          286,
          362,
          732,
          5482,
          337,
          965,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21025863815756404,
        "compression_ratio": 1.5741935483870968,
        "end": 132,
        "id": 22,
        "no_speech_prob": 0.6788599491119385,
        "seek": 11300,
        "start": 126,
        "temperature": 0,
        "text": " One is, let me just open this up here, a web browser, is to use a web browser.",
        "tokens": [
          51014,
          1485,
          307,
          11,
          718,
          385,
          445,
          1269,
          341,
          493,
          510,
          11,
          257,
          3670,
          11185,
          11,
          307,
          281,
          764,
          257,
          3670,
          11185,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23952328790094435,
        "compression_ratio": 1.5545023696682465,
        "end": 139,
        "id": 23,
        "no_speech_prob": 0.4686138331890106,
        "seek": 13200,
        "start": 133,
        "temperature": 0,
        "text": " And I'm going to go to this GitHub repository.",
        "tokens": [
          50414,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          341,
          23331,
          25841,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23952328790094435,
        "compression_ratio": 1.5545023696682465,
        "end": 145,
        "id": 24,
        "no_speech_prob": 0.4686138331890106,
        "seek": 13200,
        "start": 139,
        "temperature": 0,
        "text": " This is the CodingTrainToyNeuralNetwork-JS GitHub repository.",
        "tokens": [
          50714,
          639,
          307,
          264,
          383,
          8616,
          51,
          7146,
          51,
          939,
          15496,
          1807,
          31890,
          1902,
          12,
          41,
          50,
          23331,
          25841,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23952328790094435,
        "compression_ratio": 1.5545023696682465,
        "end": 148,
        "id": 25,
        "no_speech_prob": 0.4686138331890106,
        "seek": 13200,
        "start": 145,
        "temperature": 0,
        "text": " I have actually now, oh, a couple of things.",
        "tokens": [
          51014,
          286,
          362,
          767,
          586,
          11,
          1954,
          11,
          257,
          1916,
          295,
          721,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23952328790094435,
        "compression_ratio": 1.5545023696682465,
        "end": 153,
        "id": 26,
        "no_speech_prob": 0.4686138331890106,
        "seek": 13200,
        "start": 148,
        "temperature": 0,
        "text": " One is, you can now go to, I have arrived finally.",
        "tokens": [
          51164,
          1485,
          307,
          11,
          291,
          393,
          586,
          352,
          281,
          11,
          286,
          362,
          6678,
          2721,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23952328790094435,
        "compression_ratio": 1.5545023696682465,
        "end": 161,
        "id": 27,
        "no_speech_prob": 0.4686138331890106,
        "seek": 13200,
        "start": 153,
        "temperature": 0,
        "text": " You can now go to YouTube.com slash TheCodingTrain and it will take you directly to this channel of which you are watching.",
        "tokens": [
          51414,
          509,
          393,
          586,
          352,
          281,
          3088,
          13,
          1112,
          17330,
          440,
          34,
          8616,
          51,
          7146,
          293,
          309,
          486,
          747,
          291,
          3838,
          281,
          341,
          2269,
          295,
          597,
          291,
          366,
          1976,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2453958262567935,
        "compression_ratio": 1.6149732620320856,
        "end": 169,
        "id": 28,
        "no_speech_prob": 0.009858262725174427,
        "seek": 16100,
        "start": 162,
        "temperature": 0,
        "text": " And there you will see a check mark, because I am verified.",
        "tokens": [
          50414,
          400,
          456,
          291,
          486,
          536,
          257,
          1520,
          1491,
          11,
          570,
          286,
          669,
          31197,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2453958262567935,
        "compression_ratio": 1.6149732620320856,
        "end": 172,
        "id": 29,
        "no_speech_prob": 0.009858262725174427,
        "seek": 16100,
        "start": 169,
        "temperature": 0,
        "text": " It is me, a verified person.",
        "tokens": [
          50764,
          467,
          307,
          385,
          11,
          257,
          31197,
          954,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2453958262567935,
        "compression_ratio": 1.6149732620320856,
        "end": 176,
        "id": 30,
        "no_speech_prob": 0.009858262725174427,
        "seek": 16100,
        "start": 172,
        "temperature": 0,
        "text": " Check, check, I am here, I am truly here.",
        "tokens": [
          50914,
          6881,
          11,
          1520,
          11,
          286,
          669,
          510,
          11,
          286,
          669,
          4908,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2453958262567935,
        "compression_ratio": 1.6149732620320856,
        "end": 182,
        "id": 31,
        "no_speech_prob": 0.009858262725174427,
        "seek": 16100,
        "start": 176,
        "temperature": 0,
        "text": " And if you're wondering if it's true, it says it right there, that it's me, that says it's me.",
        "tokens": [
          51114,
          400,
          498,
          291,
          434,
          6359,
          498,
          309,
          311,
          2074,
          11,
          309,
          1619,
          309,
          558,
          456,
          11,
          300,
          309,
          311,
          385,
          11,
          300,
          1619,
          309,
          311,
          385,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2453958262567935,
        "compression_ratio": 1.6149732620320856,
        "end": 190,
        "id": 32,
        "no_speech_prob": 0.009858262725174427,
        "seek": 16100,
        "start": 182,
        "temperature": 0,
        "text": " So I have been releasing these, and in fact let me find the playlist for it.",
        "tokens": [
          51414,
          407,
          286,
          362,
          668,
          16327,
          613,
          11,
          293,
          294,
          1186,
          718,
          385,
          915,
          264,
          16788,
          337,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 193,
        "id": 33,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 190,
        "temperature": 0,
        "text": " Because I think that will be most useful.",
        "tokens": [
          50364,
          1436,
          286,
          519,
          300,
          486,
          312,
          881,
          4420,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 195,
        "id": 34,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 193,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50514,
          1692,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 198,
        "id": 35,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 195,
        "temperature": 0,
        "text": " Oops, don't play the video.",
        "tokens": [
          50614,
          21726,
          11,
          500,
          380,
          862,
          264,
          960,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 201,
        "id": 36,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 198,
        "temperature": 0,
        "text": " Just go here.",
        "tokens": [
          50764,
          1449,
          352,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 207,
        "id": 37,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 201,
        "temperature": 0,
        "text": " So this is the playlist, starting off just with an introductory video to the idea of neural networks.",
        "tokens": [
          50914,
          407,
          341,
          307,
          264,
          16788,
          11,
          2891,
          766,
          445,
          365,
          364,
          39048,
          960,
          281,
          264,
          1558,
          295,
          18161,
          9590,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 213,
        "id": 38,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 207,
        "temperature": 0,
        "text": " I built a simple perceptron, I talk about a multilayer perceptron, then I do a bunch of matrix math things.",
        "tokens": [
          51214,
          286,
          3094,
          257,
          2199,
          43276,
          2044,
          11,
          286,
          751,
          466,
          257,
          2120,
          388,
          11167,
          43276,
          2044,
          11,
          550,
          286,
          360,
          257,
          3840,
          295,
          8141,
          5221,
          721,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21221587771461123,
        "compression_ratio": 1.5673469387755101,
        "end": 217,
        "id": 39,
        "no_speech_prob": 0.08752111345529556,
        "seek": 19000,
        "start": 213,
        "temperature": 0,
        "text": " Then I look at the feedforward algorithm, and then I continue looking at that.",
        "tokens": [
          51514,
          1396,
          286,
          574,
          412,
          264,
          3154,
          13305,
          9284,
          11,
          293,
          550,
          286,
          2354,
          1237,
          412,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23656605136009953,
        "compression_ratio": 1.5815899581589958,
        "end": 227,
        "id": 40,
        "no_speech_prob": 0.23921826481819153,
        "seek": 21700,
        "start": 217,
        "temperature": 0,
        "text": " And then, as you know, I struggled massively through the backpropagation training process, but I did five videos and finished that off.",
        "tokens": [
          50364,
          400,
          550,
          11,
          382,
          291,
          458,
          11,
          286,
          19023,
          29379,
          807,
          264,
          646,
          79,
          1513,
          559,
          399,
          3097,
          1399,
          11,
          457,
          286,
          630,
          1732,
          2145,
          293,
          4335,
          300,
          766,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23656605136009953,
        "compression_ratio": 1.5815899581589958,
        "end": 235,
        "id": 41,
        "no_speech_prob": 0.23921826481819153,
        "seek": 21700,
        "start": 227,
        "temperature": 0,
        "text": " So that's, everything in all of those videos has now gone into this neural network JavaScript library.",
        "tokens": [
          50864,
          407,
          300,
          311,
          11,
          1203,
          294,
          439,
          295,
          729,
          2145,
          575,
          586,
          2780,
          666,
          341,
          18161,
          3209,
          15778,
          6405,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23656605136009953,
        "compression_ratio": 1.5815899581589958,
        "end": 243,
        "id": 42,
        "no_speech_prob": 0.23921826481819153,
        "seek": 21700,
        "start": 235,
        "temperature": 0,
        "text": " So, and I've been getting some lovely pull requests, and so I want to look through some of these and merge them.",
        "tokens": [
          51264,
          407,
          11,
          293,
          286,
          600,
          668,
          1242,
          512,
          7496,
          2235,
          12475,
          11,
          293,
          370,
          286,
          528,
          281,
          574,
          807,
          512,
          295,
          613,
          293,
          22183,
          552,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23656605136009953,
        "compression_ratio": 1.5815899581589958,
        "end": 244,
        "id": 43,
        "no_speech_prob": 0.23921826481819153,
        "seek": 21700,
        "start": 243,
        "temperature": 0,
        "text": " So that's item number one.",
        "tokens": [
          51664,
          407,
          300,
          311,
          3174,
          1230,
          472,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21446645636307565,
        "compression_ratio": 1.5863636363636364,
        "end": 248,
        "id": 44,
        "no_speech_prob": 0.23643511533737183,
        "seek": 24400,
        "start": 244,
        "temperature": 0,
        "text": " And I will mention, in case you're wondering, oh, so much stuff to talk about.",
        "tokens": [
          50364,
          400,
          286,
          486,
          2152,
          11,
          294,
          1389,
          291,
          434,
          6359,
          11,
          1954,
          11,
          370,
          709,
          1507,
          281,
          751,
          466,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21446645636307565,
        "compression_ratio": 1.5863636363636364,
        "end": 259,
        "id": 45,
        "no_speech_prob": 0.23643511533737183,
        "seek": 24400,
        "start": 248,
        "temperature": 0,
        "text": " I will also mention that if you are looking for the code in the state exactly as is when I finished that part five,",
        "tokens": [
          50564,
          286,
          486,
          611,
          2152,
          300,
          498,
          291,
          366,
          1237,
          337,
          264,
          3089,
          294,
          264,
          1785,
          2293,
          382,
          307,
          562,
          286,
          4335,
          300,
          644,
          1732,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.21446645636307565,
        "compression_ratio": 1.5863636363636364,
        "end": 268,
        "id": 46,
        "no_speech_prob": 0.23643511533737183,
        "seek": 24400,
        "start": 259,
        "temperature": 0,
        "text": " that I am putting here under courses, nature of code, 10.18, toy neural network.",
        "tokens": [
          51114,
          300,
          286,
          669,
          3372,
          510,
          833,
          7712,
          11,
          3687,
          295,
          3089,
          11,
          1266,
          13,
          6494,
          11,
          12058,
          18161,
          3209,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21446645636307565,
        "compression_ratio": 1.5863636363636364,
        "end": 272,
        "id": 47,
        "no_speech_prob": 0.23643511533737183,
        "seek": 24400,
        "start": 268,
        "temperature": 0,
        "text": " So that's in my, the repo that has all of the code for all of the videos.",
        "tokens": [
          51564,
          407,
          300,
          311,
          294,
          452,
          11,
          264,
          49040,
          300,
          575,
          439,
          295,
          264,
          3089,
          337,
          439,
          295,
          264,
          2145,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17541524496945468,
        "compression_ratio": 1.5580357142857142,
        "end": 278,
        "id": 48,
        "no_speech_prob": 0.0063859568908810616,
        "seek": 27200,
        "start": 272,
        "temperature": 0,
        "text": " And so this is kind of like a frozen state of the code as it stands at the end of that particular video.",
        "tokens": [
          50364,
          400,
          370,
          341,
          307,
          733,
          295,
          411,
          257,
          12496,
          1785,
          295,
          264,
          3089,
          382,
          309,
          7382,
          412,
          264,
          917,
          295,
          300,
          1729,
          960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17541524496945468,
        "compression_ratio": 1.5580357142857142,
        "end": 285,
        "id": 49,
        "no_speech_prob": 0.0063859568908810616,
        "seek": 27200,
        "start": 278,
        "temperature": 0,
        "text": " And then I will allow this repository to grow and improve.",
        "tokens": [
          50664,
          400,
          550,
          286,
          486,
          2089,
          341,
          25841,
          281,
          1852,
          293,
          3470,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17541524496945468,
        "compression_ratio": 1.5580357142857142,
        "end": 292,
        "id": 50,
        "no_speech_prob": 0.0063859568908810616,
        "seek": 27200,
        "start": 285,
        "temperature": 0,
        "text": " And one of the reasons why I'm doing this project is I intend to start using two other frameworks.",
        "tokens": [
          51014,
          400,
          472,
          295,
          264,
          4112,
          983,
          286,
          478,
          884,
          341,
          1716,
          307,
          286,
          19759,
          281,
          722,
          1228,
          732,
          661,
          29834,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17541524496945468,
        "compression_ratio": 1.5580357142857142,
        "end": 299,
        "id": 51,
        "no_speech_prob": 0.0063859568908810616,
        "seek": 27200,
        "start": 292,
        "temperature": 0,
        "text": " So I've mentioned before, deeplearn.js is a project from the Google Big Picture group,",
        "tokens": [
          51364,
          407,
          286,
          600,
          2835,
          949,
          11,
          2452,
          306,
          1083,
          13,
          25530,
          307,
          257,
          1716,
          490,
          264,
          3329,
          5429,
          35730,
          1594,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.22152228509226152,
        "compression_ratio": 1.4506172839506173,
        "end": 302,
        "id": 52,
        "no_speech_prob": 0.0791492685675621,
        "seek": 29900,
        "start": 299,
        "temperature": 0,
        "text": " Google pair initiative, people and AI research.",
        "tokens": [
          50364,
          3329,
          6119,
          11552,
          11,
          561,
          293,
          7318,
          2132,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22152228509226152,
        "compression_ratio": 1.4506172839506173,
        "end": 307,
        "id": 53,
        "no_speech_prob": 0.0791492685675621,
        "seek": 29900,
        "start": 302,
        "temperature": 0,
        "text": " It is a, you know, one way you might think of it is a TensorFlow, but in the browser.",
        "tokens": [
          50514,
          467,
          307,
          257,
          11,
          291,
          458,
          11,
          472,
          636,
          291,
          1062,
          519,
          295,
          309,
          307,
          257,
          37624,
          11,
          457,
          294,
          264,
          11185,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22152228509226152,
        "compression_ratio": 1.4506172839506173,
        "end": 315,
        "id": 54,
        "no_speech_prob": 0.0791492685675621,
        "seek": 29900,
        "start": 307,
        "temperature": 0,
        "text": " So this is a library that I intend to use in further tutorials as I get further along down this road.",
        "tokens": [
          50764,
          407,
          341,
          307,
          257,
          6405,
          300,
          286,
          19759,
          281,
          764,
          294,
          3052,
          17616,
          382,
          286,
          483,
          3052,
          2051,
          760,
          341,
          3060,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23470513716987942,
        "compression_ratio": 1.3431952662721893,
        "end": 328,
        "id": 55,
        "no_speech_prob": 0.4185708165168762,
        "seek": 31500,
        "start": 315,
        "temperature": 0,
        "text": " And in fact, related to that is a project that is being worked on at ITP, itp.nyu.github.io.ml5-js.",
        "tokens": [
          50364,
          400,
          294,
          1186,
          11,
          4077,
          281,
          300,
          307,
          257,
          1716,
          300,
          307,
          885,
          2732,
          322,
          412,
          6783,
          47,
          11,
          309,
          79,
          13,
          1634,
          84,
          13,
          70,
          355,
          836,
          13,
          1004,
          13,
          15480,
          20,
          12,
          25530,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23470513716987942,
        "compression_ratio": 1.3431952662721893,
        "end": 333,
        "id": 56,
        "no_speech_prob": 0.4185708165168762,
        "seek": 31500,
        "start": 328,
        "temperature": 0,
        "text": " This is another repository URL that you might take a peek at.",
        "tokens": [
          51014,
          639,
          307,
          1071,
          25841,
          12905,
          300,
          291,
          1062,
          747,
          257,
          19604,
          412,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23470513716987942,
        "compression_ratio": 1.3431952662721893,
        "end": 336,
        "id": 57,
        "no_speech_prob": 0.4185708165168762,
        "seek": 31500,
        "start": 333,
        "temperature": 0,
        "text": " This is now a high level JavaScript library for machine learning.",
        "tokens": [
          51264,
          639,
          307,
          586,
          257,
          1090,
          1496,
          15778,
          6405,
          337,
          3479,
          2539,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17547093789408527,
        "compression_ratio": 1.7508896797153024,
        "end": 345,
        "id": 58,
        "no_speech_prob": 0.3172844350337982,
        "seek": 33600,
        "start": 337,
        "temperature": 0,
        "text": " So this is a library that's built on top of deeplearn.js to make using deeplearn.js a bit easier for beginners,",
        "tokens": [
          50414,
          407,
          341,
          307,
          257,
          6405,
          300,
          311,
          3094,
          322,
          1192,
          295,
          2452,
          306,
          1083,
          13,
          25530,
          281,
          652,
          1228,
          2452,
          306,
          1083,
          13,
          25530,
          257,
          857,
          3571,
          337,
          26992,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.17547093789408527,
        "compression_ratio": 1.7508896797153024,
        "end": 348,
        "id": 59,
        "no_speech_prob": 0.3172844350337982,
        "seek": 33600,
        "start": 345,
        "temperature": 0,
        "text": " specifically beginners who might be learning to code with p5.js.",
        "tokens": [
          50814,
          4682,
          26992,
          567,
          1062,
          312,
          2539,
          281,
          3089,
          365,
          280,
          20,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17547093789408527,
        "compression_ratio": 1.7508896797153024,
        "end": 351,
        "id": 60,
        "no_speech_prob": 0.3172844350337982,
        "seek": 33600,
        "start": 348,
        "temperature": 0,
        "text": " And so for example, there's some nice examples here.",
        "tokens": [
          50964,
          400,
          370,
          337,
          1365,
          11,
          456,
          311,
          512,
          1481,
          5110,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17547093789408527,
        "compression_ratio": 1.7508896797153024,
        "end": 355,
        "id": 61,
        "no_speech_prob": 0.3172844350337982,
        "seek": 33600,
        "start": 351,
        "temperature": 0,
        "text": " Here is an example of simple image classification using a pre-trained model.",
        "tokens": [
          51114,
          1692,
          307,
          364,
          1365,
          295,
          2199,
          3256,
          21538,
          1228,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17547093789408527,
        "compression_ratio": 1.7508896797153024,
        "end": 357,
        "id": 62,
        "no_speech_prob": 0.3172844350337982,
        "seek": 33600,
        "start": 355,
        "temperature": 0,
        "text": " I will talk about eventually what all these things are.",
        "tokens": [
          51314,
          286,
          486,
          751,
          466,
          4728,
          437,
          439,
          613,
          721,
          366,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17547093789408527,
        "compression_ratio": 1.7508896797153024,
        "end": 365,
        "id": 63,
        "no_speech_prob": 0.3172844350337982,
        "seek": 33600,
        "start": 357,
        "temperature": 0,
        "text": " And you can see here the code is simple in that you can just say, you can ask the model to predict what it thinks about an image.",
        "tokens": [
          51414,
          400,
          291,
          393,
          536,
          510,
          264,
          3089,
          307,
          2199,
          294,
          300,
          291,
          393,
          445,
          584,
          11,
          291,
          393,
          1029,
          264,
          2316,
          281,
          6069,
          437,
          309,
          7309,
          466,
          364,
          3256,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17633133575695903,
        "compression_ratio": 1.7434944237918215,
        "end": 368,
        "id": 64,
        "no_speech_prob": 0.009854263626039028,
        "seek": 36500,
        "start": 365,
        "temperature": 0,
        "text": " You can look at the results and update what's on the page with the results.",
        "tokens": [
          50364,
          509,
          393,
          574,
          412,
          264,
          3542,
          293,
          5623,
          437,
          311,
          322,
          264,
          3028,
          365,
          264,
          3542,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17633133575695903,
        "compression_ratio": 1.7434944237918215,
        "end": 372,
        "id": 65,
        "no_speech_prob": 0.009854263626039028,
        "seek": 36500,
        "start": 368,
        "temperature": 0,
        "text": " So there's a lot of stuff like this that you can start to look at.",
        "tokens": [
          50514,
          407,
          456,
          311,
          257,
          688,
          295,
          1507,
          411,
          341,
          300,
          291,
          393,
          722,
          281,
          574,
          412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17633133575695903,
        "compression_ratio": 1.7434944237918215,
        "end": 376,
        "id": 66,
        "no_speech_prob": 0.009854263626039028,
        "seek": 36500,
        "start": 372,
        "temperature": 0,
        "text": " You can look under experiments, which are some things that people have built with this.",
        "tokens": [
          50714,
          509,
          393,
          574,
          833,
          12050,
          11,
          597,
          366,
          512,
          721,
          300,
          561,
          362,
          3094,
          365,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17633133575695903,
        "compression_ratio": 1.7434944237918215,
        "end": 380,
        "id": 67,
        "no_speech_prob": 0.009854263626039028,
        "seek": 36500,
        "start": 376,
        "temperature": 0,
        "text": " But this library is, you know, less than two months old.",
        "tokens": [
          50914,
          583,
          341,
          6405,
          307,
          11,
          291,
          458,
          11,
          1570,
          813,
          732,
          2493,
          1331,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17633133575695903,
        "compression_ratio": 1.7434944237918215,
        "end": 385,
        "id": 68,
        "no_speech_prob": 0.009854263626039028,
        "seek": 36500,
        "start": 380,
        "temperature": 0,
        "text": " So this is a brand new thing, and I will be doing many more videos with this library.",
        "tokens": [
          51114,
          407,
          341,
          307,
          257,
          3360,
          777,
          551,
          11,
          293,
          286,
          486,
          312,
          884,
          867,
          544,
          2145,
          365,
          341,
          6405,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17633133575695903,
        "compression_ratio": 1.7434944237918215,
        "end": 390,
        "id": 69,
        "no_speech_prob": 0.009854263626039028,
        "seek": 36500,
        "start": 385,
        "temperature": 0,
        "text": " So part of the reason why I'm building my own kind of toy version of a machine learning library",
        "tokens": [
          51364,
          407,
          644,
          295,
          264,
          1778,
          983,
          286,
          478,
          2390,
          452,
          1065,
          733,
          295,
          12058,
          3037,
          295,
          257,
          3479,
          2539,
          6405,
          51614
        ]
      },
      {
        "avg_logprob": -0.18914312176999792,
        "compression_ratio": 1.5546218487394958,
        "end": 395,
        "id": 70,
        "no_speech_prob": 0.14406561851501465,
        "seek": 39000,
        "start": 390,
        "temperature": 0,
        "text": " is just to really understand how all the pieces work, so that when I start to use other libraries and frameworks,",
        "tokens": [
          50364,
          307,
          445,
          281,
          534,
          1223,
          577,
          439,
          264,
          3755,
          589,
          11,
          370,
          300,
          562,
          286,
          722,
          281,
          764,
          661,
          15148,
          293,
          29834,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.18914312176999792,
        "compression_ratio": 1.5546218487394958,
        "end": 401,
        "id": 71,
        "no_speech_prob": 0.14406561851501465,
        "seek": 39000,
        "start": 395,
        "temperature": 0,
        "text": " I can have a kind of language to speak about them and, I don't know, some experience.",
        "tokens": [
          50614,
          286,
          393,
          362,
          257,
          733,
          295,
          2856,
          281,
          1710,
          466,
          552,
          293,
          11,
          286,
          500,
          380,
          458,
          11,
          512,
          1752,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18914312176999792,
        "compression_ratio": 1.5546218487394958,
        "end": 408,
        "id": 72,
        "no_speech_prob": 0.14406561851501465,
        "seek": 39000,
        "start": 401,
        "temperature": 0,
        "text": " So anyway, so did I say I'd be streaming until 2.30?",
        "tokens": [
          50914,
          407,
          4033,
          11,
          370,
          630,
          286,
          584,
          286,
          1116,
          312,
          11791,
          1826,
          568,
          13,
          3446,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.18914312176999792,
        "compression_ratio": 1.5546218487394958,
        "end": 410,
        "id": 73,
        "no_speech_prob": 0.14406561851501465,
        "seek": 39000,
        "start": 408,
        "temperature": 0,
        "text": " I did, yeah. I meant an hour or so.",
        "tokens": [
          51264,
          286,
          630,
          11,
          1338,
          13,
          286,
          4140,
          364,
          1773,
          420,
          370,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18914312176999792,
        "compression_ratio": 1.5546218487394958,
        "end": 413,
        "id": 74,
        "no_speech_prob": 0.14406561851501465,
        "seek": 39000,
        "start": 410,
        "temperature": 0,
        "text": " So it's 2.30 now, until 3.30 or so.",
        "tokens": [
          51364,
          407,
          309,
          311,
          568,
          13,
          3446,
          586,
          11,
          1826,
          805,
          13,
          3446,
          420,
          370,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18914312176999792,
        "compression_ratio": 1.5546218487394958,
        "end": 416,
        "id": 75,
        "no_speech_prob": 0.14406561851501465,
        "seek": 39000,
        "start": 413,
        "temperature": 0,
        "text": " Okay, so that's two things I want to mention.",
        "tokens": [
          51514,
          1033,
          11,
          370,
          300,
          311,
          732,
          721,
          286,
          528,
          281,
          2152,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 423,
        "id": 76,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 417,
        "temperature": 0,
        "text": " And then on Friday, I did the XOR coding challenge.",
        "tokens": [
          50414,
          400,
          550,
          322,
          6984,
          11,
          286,
          630,
          264,
          1783,
          2483,
          17720,
          3430,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 427,
        "id": 77,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 423,
        "temperature": 0,
        "text": " And I thought I would just, for some reason, I don't know why, I just felt like I wanted to do it again.",
        "tokens": [
          50714,
          400,
          286,
          1194,
          286,
          576,
          445,
          11,
          337,
          512,
          1778,
          11,
          286,
          500,
          380,
          458,
          983,
          11,
          286,
          445,
          2762,
          411,
          286,
          1415,
          281,
          360,
          309,
          797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 430,
        "id": 78,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 427,
        "temperature": 0,
        "text": " Because a couple things.",
        "tokens": [
          50914,
          1436,
          257,
          1916,
          721,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 432,
        "id": 79,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 430,
        "temperature": 0,
        "text": " One is I got some interesting comments.",
        "tokens": [
          51064,
          1485,
          307,
          286,
          658,
          512,
          1880,
          3053,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 435,
        "id": 80,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 432,
        "temperature": 0,
        "text": " One thing that I think would be really useful to demonstrate is if I manipulate, like,",
        "tokens": [
          51164,
          1485,
          551,
          300,
          286,
          519,
          576,
          312,
          534,
          4420,
          281,
          11698,
          307,
          498,
          286,
          20459,
          11,
          411,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 438,
        "id": 81,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 435,
        "temperature": 0,
        "text": " okay, well, what if I use four hidden nodes instead of two hidden nodes?",
        "tokens": [
          51314,
          1392,
          11,
          731,
          11,
          437,
          498,
          286,
          764,
          1451,
          7633,
          13891,
          2602,
          295,
          732,
          7633,
          13891,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.24287320697118367,
        "compression_ratio": 1.728937728937729,
        "end": 441,
        "id": 82,
        "no_speech_prob": 0.5036897659301758,
        "seek": 41600,
        "start": 438,
        "temperature": 0,
        "text": " And I just didn't have that as part of the tutorial, which I think would be really useful.",
        "tokens": [
          51464,
          400,
          286,
          445,
          994,
          380,
          362,
          300,
          382,
          644,
          295,
          264,
          7073,
          11,
          597,
          286,
          519,
          576,
          312,
          534,
          4420,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 446,
        "id": 83,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 442,
        "temperature": 0,
        "text": " But also, I felt like I wanted to have some distance from the library.",
        "tokens": [
          50414,
          583,
          611,
          11,
          286,
          2762,
          411,
          286,
          1415,
          281,
          362,
          512,
          4560,
          490,
          264,
          6405,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 450,
        "id": 84,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 446,
        "temperature": 0,
        "text": " I just was at the end of, like, hours and hours and hours of doing the backpropagation.",
        "tokens": [
          50614,
          286,
          445,
          390,
          412,
          264,
          917,
          295,
          11,
          411,
          11,
          2496,
          293,
          2496,
          293,
          2496,
          295,
          884,
          264,
          646,
          79,
          1513,
          559,
          399,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 455,
        "id": 85,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 450,
        "temperature": 0,
        "text": " And I really want that video to kind of stand alone in its own way and be disconnected from that.",
        "tokens": [
          50814,
          400,
          286,
          534,
          528,
          300,
          960,
          281,
          733,
          295,
          1463,
          3312,
          294,
          1080,
          1065,
          636,
          293,
          312,
          29426,
          490,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 458,
        "id": 86,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 455,
        "temperature": 0,
        "text": " So I thought maybe I would try it again and see what happens.",
        "tokens": [
          51064,
          407,
          286,
          1194,
          1310,
          286,
          576,
          853,
          309,
          797,
          293,
          536,
          437,
          2314,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 462,
        "id": 87,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 458,
        "temperature": 0,
        "text": " Okay, let's see.",
        "tokens": [
          51214,
          1033,
          11,
          718,
          311,
          536,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 464,
        "id": 88,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 462,
        "temperature": 0,
        "text": " So now, what do I want?",
        "tokens": [
          51414,
          407,
          586,
          11,
          437,
          360,
          286,
          528,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.19882360555357853,
        "compression_ratio": 1.625984251968504,
        "end": 469,
        "id": 89,
        "no_speech_prob": 0.27191975712776184,
        "seek": 44100,
        "start": 464,
        "temperature": 0,
        "text": " While I'm here, let me mention a couple other things.",
        "tokens": [
          51514,
          3987,
          286,
          478,
          510,
          11,
          718,
          385,
          2152,
          257,
          1916,
          661,
          721,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 478,
        "id": 90,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 470,
        "temperature": 0,
        "text": " This repository, coding train slash rainbow code, which ostensibly, if you're not looking very closely,",
        "tokens": [
          50414,
          639,
          25841,
          11,
          17720,
          3847,
          17330,
          18526,
          3089,
          11,
          597,
          32946,
          694,
          3545,
          11,
          498,
          291,
          434,
          406,
          1237,
          588,
          8185,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 483,
        "id": 91,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 478,
        "temperature": 0,
        "text": " is just a repository that has all the source code from all of my video tutorials.",
        "tokens": [
          50814,
          307,
          445,
          257,
          25841,
          300,
          575,
          439,
          264,
          4009,
          3089,
          490,
          439,
          295,
          452,
          960,
          17616,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 484,
        "id": 92,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 483,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51064,
          1779,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 487,
        "id": 93,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 484,
        "temperature": 0,
        "text": " You can say, like, oh, look, I want to find code for one of the coding challenges",
        "tokens": [
          51114,
          509,
          393,
          584,
          11,
          411,
          11,
          1954,
          11,
          574,
          11,
          286,
          528,
          281,
          915,
          3089,
          337,
          472,
          295,
          264,
          17720,
          4759,
          51264
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 494,
        "id": 94,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 487,
        "temperature": 0,
        "text": " or one of the p5.js courses or the node sockets playlist or code that was one of the Q&A videos.",
        "tokens": [
          51264,
          420,
          472,
          295,
          264,
          280,
          20,
          13,
          25530,
          7712,
          420,
          264,
          9984,
          370,
          11984,
          16788,
          420,
          3089,
          300,
          390,
          472,
          295,
          264,
          1249,
          5,
          32,
          2145,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 496,
        "id": 95,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 494,
        "temperature": 0,
        "text": " I don't know, tutorials, courses.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          11,
          17616,
          11,
          7712,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2311129913330078,
        "compression_ratio": 1.6775362318840579,
        "end": 498,
        "id": 96,
        "no_speech_prob": 0.01883205585181713,
        "seek": 46900,
        "start": 496,
        "temperature": 0,
        "text": " There still could be some work done on organization here.",
        "tokens": [
          51714,
          821,
          920,
          727,
          312,
          512,
          589,
          1096,
          322,
          4475,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23033921512556665,
        "compression_ratio": 1.5108695652173914,
        "end": 501,
        "id": 97,
        "no_speech_prob": 0.027167297899723053,
        "seek": 49800,
        "start": 498,
        "temperature": 0,
        "text": " But you'll start to notice, oh, what is this underscore, underscore, underscore?",
        "tokens": [
          50364,
          583,
          291,
          603,
          722,
          281,
          3449,
          11,
          1954,
          11,
          437,
          307,
          341,
          37556,
          11,
          37556,
          11,
          37556,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.23033921512556665,
        "compression_ratio": 1.5108695652173914,
        "end": 503,
        "id": 98,
        "no_speech_prob": 0.027167297899723053,
        "seek": 49800,
        "start": 501,
        "temperature": 0,
        "text": " There's all this stuff.",
        "tokens": [
          50514,
          821,
          311,
          439,
          341,
          1507,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23033921512556665,
        "compression_ratio": 1.5108695652173914,
        "end": 504,
        "id": 99,
        "no_speech_prob": 0.027167297899723053,
        "seek": 49800,
        "start": 503,
        "temperature": 0,
        "text": " Landing page.",
        "tokens": [
          50614,
          49458,
          3028,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23033921512556665,
        "compression_ratio": 1.5108695652173914,
        "end": 508,
        "id": 100,
        "no_speech_prob": 0.027167297899723053,
        "seek": 49800,
        "start": 504,
        "temperature": 0,
        "text": " And then all of a sudden there's readme.md and contributing.md.",
        "tokens": [
          50664,
          400,
          550,
          439,
          295,
          257,
          3990,
          456,
          311,
          1401,
          1398,
          13,
          76,
          67,
          293,
          19270,
          13,
          76,
          67,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23033921512556665,
        "compression_ratio": 1.5108695652173914,
        "end": 513,
        "id": 101,
        "no_speech_prob": 0.027167297899723053,
        "seek": 49800,
        "start": 508,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50864,
          876,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23033921512556665,
        "compression_ratio": 1.5108695652173914,
        "end": 521,
        "id": 102,
        "no_speech_prob": 0.027167297899723053,
        "seek": 49800,
        "start": 513,
        "temperature": 0,
        "text": " So this repository, thanks in large part to many contributors, but most notably Neils Webb,",
        "tokens": [
          51114,
          407,
          341,
          25841,
          11,
          3231,
          294,
          2416,
          644,
          281,
          867,
          45627,
          11,
          457,
          881,
          31357,
          1734,
          4174,
          49649,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.21099566505068823,
        "compression_ratio": 1.6416666666666666,
        "end": 529,
        "id": 103,
        "no_speech_prob": 0.41479551792144775,
        "seek": 52100,
        "start": 522,
        "temperature": 0,
        "text": " has turned into the repository which is also the coding train website.",
        "tokens": [
          50414,
          575,
          3574,
          666,
          264,
          25841,
          597,
          307,
          611,
          264,
          17720,
          3847,
          3144,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21099566505068823,
        "compression_ratio": 1.6416666666666666,
        "end": 532,
        "id": 104,
        "no_speech_prob": 0.41479551792144775,
        "seek": 52100,
        "start": 529,
        "temperature": 0,
        "text": " Now, I will open this up a bit wider.",
        "tokens": [
          50764,
          823,
          11,
          286,
          486,
          1269,
          341,
          493,
          257,
          857,
          11842,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21099566505068823,
        "compression_ratio": 1.6416666666666666,
        "end": 537,
        "id": 105,
        "no_speech_prob": 0.41479551792144775,
        "seek": 52100,
        "start": 532,
        "temperature": 0,
        "text": " So this is the new coding train website, a sort of work in progress.",
        "tokens": [
          50914,
          407,
          341,
          307,
          264,
          777,
          17720,
          3847,
          3144,
          11,
          257,
          1333,
          295,
          589,
          294,
          4205,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21099566505068823,
        "compression_ratio": 1.6416666666666666,
        "end": 543,
        "id": 106,
        "no_speech_prob": 0.41479551792144775,
        "seek": 52100,
        "start": 537,
        "temperature": 0,
        "text": " And each video now has its, if it's put into the website, has its own page.",
        "tokens": [
          51164,
          400,
          1184,
          960,
          586,
          575,
          1080,
          11,
          498,
          309,
          311,
          829,
          666,
          264,
          3144,
          11,
          575,
          1080,
          1065,
          3028,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21099566505068823,
        "compression_ratio": 1.6416666666666666,
        "end": 546,
        "id": 107,
        "no_speech_prob": 0.41479551792144775,
        "seek": 52100,
        "start": 543,
        "temperature": 0,
        "text": " So, for example, the latest video is here, snakes and ladders part three.",
        "tokens": [
          51464,
          407,
          11,
          337,
          1365,
          11,
          264,
          6792,
          960,
          307,
          510,
          11,
          21817,
          293,
          6632,
          15633,
          644,
          1045,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21099566505068823,
        "compression_ratio": 1.6416666666666666,
        "end": 549,
        "id": 108,
        "no_speech_prob": 0.41479551792144775,
        "seek": 52100,
        "start": 546,
        "temperature": 0,
        "text": " And this would obviously take me directly to the video on YouTube.",
        "tokens": [
          51614,
          400,
          341,
          576,
          2745,
          747,
          385,
          3838,
          281,
          264,
          960,
          322,
          3088,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 554,
        "id": 109,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 549,
        "temperature": 0,
        "text": " But if I click on this link here, it will take me to a page which has the video in bed.",
        "tokens": [
          50364,
          583,
          498,
          286,
          2052,
          322,
          341,
          2113,
          510,
          11,
          309,
          486,
          747,
          385,
          281,
          257,
          3028,
          597,
          575,
          264,
          960,
          294,
          2901,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 557,
        "id": 110,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 554,
        "temperature": 0,
        "text": " It has a link to run the example in the browser.",
        "tokens": [
          50614,
          467,
          575,
          257,
          2113,
          281,
          1190,
          264,
          1365,
          294,
          264,
          11185,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 559,
        "id": 111,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 557,
        "temperature": 0,
        "text": " So here's the example running in the browser.",
        "tokens": [
          50764,
          407,
          510,
          311,
          264,
          1365,
          2614,
          294,
          264,
          11185,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 563,
        "id": 112,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 559,
        "temperature": 0,
        "text": " It has a link, this link will download the code, a little description here.",
        "tokens": [
          50864,
          467,
          575,
          257,
          2113,
          11,
          341,
          2113,
          486,
          5484,
          264,
          3089,
          11,
          257,
          707,
          3855,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 566,
        "id": 113,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 563,
        "temperature": 0,
        "text": " And then, ah, a place for community contributions.",
        "tokens": [
          51064,
          400,
          550,
          11,
          3716,
          11,
          257,
          1081,
          337,
          1768,
          15725,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 568,
        "id": 114,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 566,
        "temperature": 0,
        "text": " But there aren't any yet.",
        "tokens": [
          51214,
          583,
          456,
          3212,
          380,
          604,
          1939,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 570,
        "id": 115,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 568,
        "temperature": 0,
        "text": " But you can add your own by looking at this guide.",
        "tokens": [
          51314,
          583,
          291,
          393,
          909,
          428,
          1065,
          538,
          1237,
          412,
          341,
          5934,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 572,
        "id": 116,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 570,
        "temperature": 0,
        "text": " So you can submit a pull request to add yours.",
        "tokens": [
          51414,
          407,
          291,
          393,
          10315,
          257,
          2235,
          5308,
          281,
          909,
          6342,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15960512229864546,
        "compression_ratio": 1.797872340425532,
        "end": 575,
        "id": 117,
        "no_speech_prob": 0.14799071848392487,
        "seek": 54900,
        "start": 572,
        "temperature": 0,
        "text": " There's links that were discussed, links to the other parts of the video.",
        "tokens": [
          51514,
          821,
          311,
          6123,
          300,
          645,
          7152,
          11,
          6123,
          281,
          264,
          661,
          3166,
          295,
          264,
          960,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21079372406005858,
        "compression_ratio": 1.6629213483146068,
        "end": 581,
        "id": 118,
        "no_speech_prob": 0.05029325187206268,
        "seek": 57500,
        "start": 575,
        "temperature": 0,
        "text": " So this is an attempt to create a more navigable version, a more navigable system,",
        "tokens": [
          50364,
          407,
          341,
          307,
          364,
          5217,
          281,
          1884,
          257,
          544,
          7407,
          712,
          3037,
          11,
          257,
          544,
          7407,
          712,
          1185,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.21079372406005858,
        "compression_ratio": 1.6629213483146068,
        "end": 585,
        "id": 119,
        "no_speech_prob": 0.05029325187206268,
        "seek": 57500,
        "start": 581,
        "temperature": 0,
        "text": " for finding and looking through all the videos separate from the YouTube interface,",
        "tokens": [
          50664,
          337,
          5006,
          293,
          1237,
          807,
          439,
          264,
          2145,
          4994,
          490,
          264,
          3088,
          9226,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.21079372406005858,
        "compression_ratio": 1.6629213483146068,
        "end": 593,
        "id": 120,
        "no_speech_prob": 0.05029325187206268,
        "seek": 57500,
        "start": 585,
        "temperature": 0,
        "text": " as well as aggregating and collecting community contributions and relevant links and source code and that sort of thing.",
        "tokens": [
          50864,
          382,
          731,
          382,
          16743,
          990,
          293,
          12510,
          1768,
          15725,
          293,
          7340,
          6123,
          293,
          4009,
          3089,
          293,
          300,
          1333,
          295,
          551,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21079372406005858,
        "compression_ratio": 1.6629213483146068,
        "end": 598,
        "id": 121,
        "no_speech_prob": 0.05029325187206268,
        "seek": 57500,
        "start": 593,
        "temperature": 0,
        "text": " So I think this website, as remarkable and amazing and beautiful as it is,",
        "tokens": [
          51264,
          407,
          286,
          519,
          341,
          3144,
          11,
          382,
          12802,
          293,
          2243,
          293,
          2238,
          382,
          309,
          307,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.21079372406005858,
        "compression_ratio": 1.6629213483146068,
        "end": 603,
        "id": 122,
        "no_speech_prob": 0.05029325187206268,
        "seek": 57500,
        "start": 598,
        "temperature": 0,
        "text": " it's just like tremendous that Niels Webb was able to just put this all together.",
        "tokens": [
          51514,
          309,
          311,
          445,
          411,
          10048,
          300,
          426,
          44189,
          49649,
          390,
          1075,
          281,
          445,
          829,
          341,
          439,
          1214,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20710134506225586,
        "compression_ratio": 1.606060606060606,
        "end": 610,
        "id": 123,
        "no_speech_prob": 0.2843499481678009,
        "seek": 60300,
        "start": 603,
        "temperature": 0,
        "text": " It runs on something called Jekyll, which is a static site-generated templating engine that works well with GitHub Pages.",
        "tokens": [
          50364,
          467,
          6676,
          322,
          746,
          1219,
          508,
          916,
          34353,
          11,
          597,
          307,
          257,
          13437,
          3621,
          12,
          21848,
          770,
          9100,
          990,
          2848,
          300,
          1985,
          731,
          365,
          23331,
          430,
          1660,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20710134506225586,
        "compression_ratio": 1.606060606060606,
        "end": 614,
        "id": 124,
        "no_speech_prob": 0.2843499481678009,
        "seek": 60300,
        "start": 610,
        "temperature": 0,
        "text": " I think it could still use work in visual design, and it's missing a lot of content.",
        "tokens": [
          50714,
          286,
          519,
          309,
          727,
          920,
          764,
          589,
          294,
          5056,
          1715,
          11,
          293,
          309,
          311,
          5361,
          257,
          688,
          295,
          2701,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20710134506225586,
        "compression_ratio": 1.606060606060606,
        "end": 621,
        "id": 125,
        "no_speech_prob": 0.2843499481678009,
        "seek": 60300,
        "start": 614,
        "temperature": 0,
        "text": " So I encourage any of you who are interested in kind of learning to participate in an open-source project,",
        "tokens": [
          50914,
          407,
          286,
          5373,
          604,
          295,
          291,
          567,
          366,
          3102,
          294,
          733,
          295,
          2539,
          281,
          8197,
          294,
          364,
          1269,
          12,
          41676,
          1716,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20710134506225586,
        "compression_ratio": 1.606060606060606,
        "end": 622,
        "id": 126,
        "no_speech_prob": 0.2843499481678009,
        "seek": 60300,
        "start": 621,
        "temperature": 0,
        "text": " here's one for you.",
        "tokens": [
          51264,
          510,
          311,
          472,
          337,
          291,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20710134506225586,
        "compression_ratio": 1.606060606060606,
        "end": 628,
        "id": 127,
        "no_speech_prob": 0.2843499481678009,
        "seek": 60300,
        "start": 622,
        "temperature": 0,
        "text": " If you want to make a design contribution or add some content that's missing, let me know.",
        "tokens": [
          51314,
          759,
          291,
          528,
          281,
          652,
          257,
          1715,
          13150,
          420,
          909,
          512,
          2701,
          300,
          311,
          5361,
          11,
          718,
          385,
          458,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 630,
        "id": 128,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 628,
        "temperature": 0,
        "text": " Let me know at Shiffman on Twitter.",
        "tokens": [
          50364,
          961,
          385,
          458,
          412,
          1160,
          3661,
          1601,
          322,
          5794,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 633,
        "id": 129,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 630,
        "temperature": 0,
        "text": " You can read, hopefully, the documentation that's in the GitHub repository.",
        "tokens": [
          50464,
          509,
          393,
          1401,
          11,
          4696,
          11,
          264,
          14333,
          300,
          311,
          294,
          264,
          23331,
          25841,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 635,
        "id": 130,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 633,
        "temperature": 0,
        "text": " I would love to have people help with that.",
        "tokens": [
          50614,
          286,
          576,
          959,
          281,
          362,
          561,
          854,
          365,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 636,
        "id": 131,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 635,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50714,
          1057,
          558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 643,
        "id": 132,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 641,
        "temperature": 0,
        "text": " Is he sick? Right? Yes.",
        "tokens": [
          51014,
          1119,
          415,
          4998,
          30,
          1779,
          30,
          1079,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 648,
        "id": 133,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 643,
        "temperature": 0,
        "text": " Yeah, I thought my cold was gone, and that's why I felt comfortable.",
        "tokens": [
          51114,
          865,
          11,
          286,
          1194,
          452,
          3554,
          390,
          2780,
          11,
          293,
          300,
          311,
          983,
          286,
          2762,
          4619,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21639884870076917,
        "compression_ratio": 1.4678111587982832,
        "end": 655,
        "id": 134,
        "no_speech_prob": 0.3959294557571411,
        "seek": 62800,
        "start": 648,
        "temperature": 0,
        "text": " I feel so much better, but I think the congestion is still lingering in my throat.",
        "tokens": [
          51364,
          286,
          841,
          370,
          709,
          1101,
          11,
          457,
          286,
          519,
          264,
          40816,
          307,
          920,
          49542,
          294,
          452,
          12394,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 657,
        "id": 135,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 655,
        "temperature": 0,
        "text": " So I don't know.",
        "tokens": [
          50364,
          407,
          286,
          500,
          380,
          458,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 660,
        "id": 136,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 657,
        "temperature": 0,
        "text": " Oh, I have a—hold on. Let me just check here.",
        "tokens": [
          50464,
          876,
          11,
          286,
          362,
          257,
          2958,
          4104,
          322,
          13,
          961,
          385,
          445,
          1520,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 662,
        "id": 137,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 660,
        "temperature": 0,
        "text": " Okay, okay, okay.",
        "tokens": [
          50614,
          1033,
          11,
          1392,
          11,
          1392,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 664,
        "id": 138,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 662,
        "temperature": 0,
        "text": " All right. Just looking at some messages here.",
        "tokens": [
          50714,
          1057,
          558,
          13,
          1449,
          1237,
          412,
          512,
          7897,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 666,
        "id": 139,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 664,
        "temperature": 0,
        "text": " Let me go back to the live channel.",
        "tokens": [
          50814,
          961,
          385,
          352,
          646,
          281,
          264,
          1621,
          2269,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 668,
        "id": 140,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 666,
        "temperature": 0,
        "text": " What I'm looking at over here, by the way, is a Slack channel.",
        "tokens": [
          50914,
          708,
          286,
          478,
          1237,
          412,
          670,
          510,
          11,
          538,
          264,
          636,
          11,
          307,
          257,
          37211,
          2269,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 672,
        "id": 141,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 668,
        "temperature": 0,
        "text": " I often get the question, oh, how can I ask a question or get help?",
        "tokens": [
          51014,
          286,
          2049,
          483,
          264,
          1168,
          11,
          1954,
          11,
          577,
          393,
          286,
          1029,
          257,
          1168,
          420,
          483,
          854,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 676,
        "id": 142,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 672,
        "temperature": 0,
        "text": " So, of course, I would always recommend that you use—",
        "tokens": [
          51214,
          407,
          11,
          295,
          1164,
          11,
          286,
          576,
          1009,
          2748,
          300,
          291,
          764,
          2958,
          51414
        ]
      },
      {
        "avg_logprob": -0.19005229060811207,
        "compression_ratio": 1.5531135531135531,
        "end": 682,
        "id": 143,
        "no_speech_prob": 0.002590471412986517,
        "seek": 65500,
        "start": 676,
        "temperature": 0,
        "text": " a forum that goes well with a lot of my videos is forum.processing.org.",
        "tokens": [
          51414,
          257,
          17542,
          300,
          1709,
          731,
          365,
          257,
          688,
          295,
          452,
          2145,
          307,
          17542,
          13,
          41075,
          278,
          13,
          4646,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20809131198459202,
        "compression_ratio": 1.691449814126394,
        "end": 687,
        "id": 144,
        "no_speech_prob": 0.0994492843747139,
        "seek": 68200,
        "start": 682,
        "temperature": 0,
        "text": " You can get in contact with me on Twitter, but I also have a Patreon.",
        "tokens": [
          50364,
          509,
          393,
          483,
          294,
          3385,
          365,
          385,
          322,
          5794,
          11,
          457,
          286,
          611,
          362,
          257,
          15692,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20809131198459202,
        "compression_ratio": 1.691449814126394,
        "end": 691,
        "id": 145,
        "no_speech_prob": 0.0994492843747139,
        "seek": 68200,
        "start": 687,
        "temperature": 0,
        "text": " And if you join the Patreon at patreon.com slash codingtrain,",
        "tokens": [
          50614,
          400,
          498,
          291,
          3917,
          264,
          15692,
          412,
          33161,
          13,
          1112,
          17330,
          17720,
          83,
          7146,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.20809131198459202,
        "compression_ratio": 1.691449814126394,
        "end": 697,
        "id": 146,
        "no_speech_prob": 0.0994492843747139,
        "seek": 68200,
        "start": 691,
        "temperature": 0,
        "text": " that's where you'll get an invitation to the Slack channel, which I participate in.",
        "tokens": [
          50814,
          300,
          311,
          689,
          291,
          603,
          483,
          364,
          17890,
          281,
          264,
          37211,
          2269,
          11,
          597,
          286,
          8197,
          294,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20809131198459202,
        "compression_ratio": 1.691449814126394,
        "end": 700,
        "id": 147,
        "no_speech_prob": 0.0994492843747139,
        "seek": 68200,
        "start": 697,
        "temperature": 0,
        "text": " But honestly, the thing about the Slack channel that's great,",
        "tokens": [
          51114,
          583,
          6095,
          11,
          264,
          551,
          466,
          264,
          37211,
          2269,
          300,
          311,
          869,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20809131198459202,
        "compression_ratio": 1.691449814126394,
        "end": 704,
        "id": 148,
        "no_speech_prob": 0.0994492843747139,
        "seek": 68200,
        "start": 700,
        "temperature": 0,
        "text": " the idea was like, oh, I could help people with their code if they sign up and subscribe.",
        "tokens": [
          51264,
          264,
          1558,
          390,
          411,
          11,
          1954,
          11,
          286,
          727,
          854,
          561,
          365,
          641,
          3089,
          498,
          436,
          1465,
          493,
          293,
          3022,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20809131198459202,
        "compression_ratio": 1.691449814126394,
        "end": 708,
        "id": 149,
        "no_speech_prob": 0.0994492843747139,
        "seek": 68200,
        "start": 704,
        "temperature": 0,
        "text": " But there's so many people already now in the Slack channel who know way more than I do",
        "tokens": [
          51464,
          583,
          456,
          311,
          370,
          867,
          561,
          1217,
          586,
          294,
          264,
          37211,
          2269,
          567,
          458,
          636,
          544,
          813,
          286,
          360,
          51664
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 709,
        "id": 150,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 708,
        "temperature": 0,
        "text": " and are much more helpful.",
        "tokens": [
          50364,
          293,
          366,
          709,
          544,
          4961,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 713,
        "id": 151,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 709,
        "temperature": 0,
        "text": " So it's kind of built itself into a nice community there.",
        "tokens": [
          50414,
          407,
          309,
          311,
          733,
          295,
          3094,
          2564,
          666,
          257,
          1481,
          1768,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 716,
        "id": 152,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 713,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 719,
        "id": 153,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 716,
        "temperature": 0,
        "text": " I'll take a couple questions from the chat.",
        "tokens": [
          50764,
          286,
          603,
          747,
          257,
          1916,
          1651,
          490,
          264,
          5081,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 723,
        "id": 154,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 719,
        "temperature": 0,
        "text": " Ricardo asks, have you ever thought about going full-time YouTuber?",
        "tokens": [
          50914,
          42634,
          8962,
          11,
          362,
          291,
          1562,
          1194,
          466,
          516,
          1577,
          12,
          3766,
          23349,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 726,
        "id": 155,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 723,
        "temperature": 0,
        "text": " Actually, I have thought about it.",
        "tokens": [
          51114,
          5135,
          11,
          286,
          362,
          1194,
          466,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 730,
        "id": 156,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 726,
        "temperature": 0,
        "text": " Some ways I might be interested in doing it, just so I can say full-time YouTuber.",
        "tokens": [
          51264,
          2188,
          2098,
          286,
          1062,
          312,
          3102,
          294,
          884,
          309,
          11,
          445,
          370,
          286,
          393,
          584,
          1577,
          12,
          3766,
          23349,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 732,
        "id": 157,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 730,
        "temperature": 0,
        "text": " It sounds like a weird thing, like a crazy thing to say.",
        "tokens": [
          51464,
          467,
          3263,
          411,
          257,
          3657,
          551,
          11,
          411,
          257,
          3219,
          551,
          281,
          584,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1884927829774488,
        "compression_ratio": 1.606177606177606,
        "end": 735,
        "id": 158,
        "no_speech_prob": 0.5885979533195496,
        "seek": 70800,
        "start": 732,
        "temperature": 0,
        "text": " I do have a full-time job that I love.",
        "tokens": [
          51564,
          286,
          360,
          362,
          257,
          1577,
          12,
          3766,
          1691,
          300,
          286,
          959,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 739,
        "id": 159,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 735,
        "temperature": 0,
        "text": " I live in New York City, which is a very expensive and complicated place to live.",
        "tokens": [
          50364,
          286,
          1621,
          294,
          1873,
          3609,
          4392,
          11,
          597,
          307,
          257,
          588,
          5124,
          293,
          6179,
          1081,
          281,
          1621,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 743,
        "id": 160,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 739,
        "temperature": 0,
        "text": " And the job where I have is at a program called ITP at NYU.",
        "tokens": [
          50564,
          400,
          264,
          1691,
          689,
          286,
          362,
          307,
          412,
          257,
          1461,
          1219,
          6783,
          47,
          412,
          42682,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 745,
        "id": 161,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 743,
        "temperature": 0,
        "text": " In fact, that's where I'm recording these videos.",
        "tokens": [
          50764,
          682,
          1186,
          11,
          300,
          311,
          689,
          286,
          478,
          6613,
          613,
          2145,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 748,
        "id": 162,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 745,
        "temperature": 0,
        "text": " So while I fantasize and think about it sometimes,",
        "tokens": [
          50864,
          407,
          1339,
          286,
          31255,
          1125,
          293,
          519,
          466,
          309,
          2171,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 751,
        "id": 163,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 748,
        "temperature": 0,
        "text": " I don't know if it's realistic for me at this point.",
        "tokens": [
          51014,
          286,
          500,
          380,
          458,
          498,
          309,
          311,
          12465,
          337,
          385,
          412,
          341,
          935,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 754,
        "id": 164,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 751,
        "temperature": 0,
        "text": " And I wouldn't want to give up the wonderful in-person community",
        "tokens": [
          51164,
          400,
          286,
          2759,
          380,
          528,
          281,
          976,
          493,
          264,
          3715,
          294,
          12,
          10813,
          1768,
          51314
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 757,
        "id": 165,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 754,
        "temperature": 0,
        "text": " and teaching stuff that I'm able to do through working here.",
        "tokens": [
          51314,
          293,
          4571,
          1507,
          300,
          286,
          478,
          1075,
          281,
          360,
          807,
          1364,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 760,
        "id": 166,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 757,
        "temperature": 0,
        "text": " But it's an interesting question.",
        "tokens": [
          51464,
          583,
          309,
          311,
          364,
          1880,
          1168,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14067245375180076,
        "compression_ratio": 1.5811209439528024,
        "end": 764,
        "id": 167,
        "no_speech_prob": 0.06006702780723572,
        "seek": 73500,
        "start": 760,
        "temperature": 0,
        "text": " Ben Anderson asks, could you explain to me the basic premise of neural networks?",
        "tokens": [
          51614,
          3964,
          18768,
          8962,
          11,
          727,
          291,
          2903,
          281,
          385,
          264,
          3875,
          22045,
          295,
          18161,
          9590,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 769,
        "id": 168,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 764,
        "temperature": 0,
        "text": " So that's where I would recommend starting with this neural networks playlist.",
        "tokens": [
          50364,
          407,
          300,
          311,
          689,
          286,
          576,
          2748,
          2891,
          365,
          341,
          18161,
          9590,
          16788,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 774,
        "id": 169,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 769,
        "temperature": 0,
        "text": " So in theory, I don't remember at all what's in this video.",
        "tokens": [
          50614,
          407,
          294,
          5261,
          11,
          286,
          500,
          380,
          1604,
          412,
          439,
          437,
          311,
          294,
          341,
          960,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 776,
        "id": 170,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 774,
        "temperature": 0,
        "text": " I made it quite a while ago.",
        "tokens": [
          50864,
          286,
          1027,
          309,
          1596,
          257,
          1339,
          2057,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 778,
        "id": 171,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 776,
        "temperature": 0,
        "text": " But it does say introduction to neural networks.",
        "tokens": [
          50964,
          583,
          309,
          775,
          584,
          9339,
          281,
          18161,
          9590,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 782,
        "id": 172,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 778,
        "temperature": 0,
        "text": " And I believe I do cover in that video the basic premise of neural networks.",
        "tokens": [
          51064,
          400,
          286,
          1697,
          286,
          360,
          2060,
          294,
          300,
          960,
          264,
          3875,
          22045,
          295,
          18161,
          9590,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 785,
        "id": 173,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 782,
        "temperature": 0,
        "text": " And I will rehash that again when I start doing the XOR coding challenge.",
        "tokens": [
          51264,
          400,
          286,
          486,
          22355,
          1299,
          300,
          797,
          562,
          286,
          722,
          884,
          264,
          1783,
          2483,
          17720,
          3430,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1881347518783432,
        "compression_ratio": 1.715415019762846,
        "end": 791,
        "id": 174,
        "no_speech_prob": 0.021283630281686783,
        "seek": 76400,
        "start": 785,
        "temperature": 0,
        "text": " And I also would recommend the 3Blue1Brown neural network channel.",
        "tokens": [
          51414,
          400,
          286,
          611,
          576,
          2748,
          264,
          805,
          45231,
          16,
          22170,
          648,
          18161,
          3209,
          2269,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 796,
        "id": 175,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 792,
        "temperature": 0,
        "text": " Yes, moving upstate and becoming a hermit is an excellent idea,",
        "tokens": [
          50414,
          1079,
          11,
          2684,
          493,
          15406,
          293,
          5617,
          257,
          720,
          3508,
          307,
          364,
          7103,
          1558,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 799,
        "id": 176,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 796,
        "temperature": 0,
        "text": " was the suggestion for how I could become a full-time YouTuber.",
        "tokens": [
          50614,
          390,
          264,
          16541,
          337,
          577,
          286,
          727,
          1813,
          257,
          1577,
          12,
          3766,
          23349,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 801,
        "id": 177,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 799,
        "temperature": 0,
        "text": " And dye my hair green.",
        "tokens": [
          50764,
          400,
          20179,
          452,
          2578,
          3092,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 803,
        "id": 178,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 801,
        "temperature": 0,
        "text": " Okay, ah, this cold.",
        "tokens": [
          50864,
          1033,
          11,
          3716,
          11,
          341,
          3554,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 808,
        "id": 179,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 803,
        "temperature": 0,
        "text": " This is not, this is not, I've been silent I guess all day and didn't realize.",
        "tokens": [
          50964,
          639,
          307,
          406,
          11,
          341,
          307,
          406,
          11,
          286,
          600,
          668,
          12784,
          286,
          2041,
          439,
          786,
          293,
          994,
          380,
          4325,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 812,
        "id": 180,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 810,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.29047335935442636,
        "compression_ratio": 1.4489795918367347,
        "end": 815,
        "id": 181,
        "no_speech_prob": 0.0460168719291687,
        "seek": 79100,
        "start": 813,
        "temperature": 0,
        "text": " So I'm looking at the chat.",
        "tokens": [
          51464,
          407,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 819,
        "id": 182,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 816,
        "temperature": 0,
        "text": " There's a class going in behind this wall.",
        "tokens": [
          50414,
          821,
          311,
          257,
          1508,
          516,
          294,
          2261,
          341,
          2929,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 821,
        "id": 183,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 819,
        "temperature": 0,
        "text": " And they're watching a movie right now.",
        "tokens": [
          50564,
          400,
          436,
          434,
          1976,
          257,
          3169,
          558,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 823,
        "id": 184,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 821,
        "temperature": 0,
        "text": " I can almost hear what it is.",
        "tokens": [
          50664,
          286,
          393,
          1920,
          1568,
          437,
          309,
          307,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 827,
        "id": 185,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 823,
        "temperature": 0,
        "text": " What's the chance you can hear it if I put my microphone up to the wall?",
        "tokens": [
          50764,
          708,
          311,
          264,
          2931,
          291,
          393,
          1568,
          309,
          498,
          286,
          829,
          452,
          10952,
          493,
          281,
          264,
          2929,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 832,
        "id": 186,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 827,
        "temperature": 0,
        "text": " I probably just made a horrible scratching sound as I put the microphone on the wall.",
        "tokens": [
          50964,
          286,
          1391,
          445,
          1027,
          257,
          9263,
          29699,
          1626,
          382,
          286,
          829,
          264,
          10952,
          322,
          264,
          2929,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 834,
        "id": 187,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 832,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 837,
        "id": 188,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 834,
        "temperature": 0,
        "text": " So let's get set here.",
        "tokens": [
          51314,
          407,
          718,
          311,
          483,
          992,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2137432098388672,
        "compression_ratio": 1.6378600823045268,
        "end": 841,
        "id": 189,
        "no_speech_prob": 0.024387793615460396,
        "seek": 81500,
        "start": 837,
        "temperature": 0,
        "text": " Okay, so the first thing that I want to do is I want to look through the pull requests here.",
        "tokens": [
          51464,
          1033,
          11,
          370,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          574,
          807,
          264,
          2235,
          12475,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 846,
        "id": 190,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 842,
        "temperature": 0,
        "text": " And let's think about, let's do this backwards.",
        "tokens": [
          50414,
          400,
          718,
          311,
          519,
          466,
          11,
          718,
          311,
          360,
          341,
          12204,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 851,
        "id": 191,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 846,
        "temperature": 0,
        "text": " So I'm going to look at the oldest pull request and move up and see which of these I can merge.",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          14026,
          2235,
          5308,
          293,
          1286,
          493,
          293,
          536,
          597,
          295,
          613,
          286,
          393,
          22183,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 854,
        "id": 192,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 851,
        "temperature": 0,
        "text": " Now one thing you'll notice is they all have a green check mark.",
        "tokens": [
          50864,
          823,
          472,
          551,
          291,
          603,
          3449,
          307,
          436,
          439,
          362,
          257,
          3092,
          1520,
          1491,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 857,
        "id": 193,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 854,
        "temperature": 0,
        "text": " And that green check mark is because I added unit testing.",
        "tokens": [
          51014,
          400,
          300,
          3092,
          1520,
          1491,
          307,
          570,
          286,
          3869,
          4985,
          4997,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 863,
        "id": 194,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 857,
        "temperature": 0,
        "text": " Testing to make sure the code does what it should be doing before it can be merged.",
        "tokens": [
          51164,
          45517,
          281,
          652,
          988,
          264,
          3089,
          775,
          437,
          309,
          820,
          312,
          884,
          949,
          309,
          393,
          312,
          36427,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 865,
        "id": 195,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 863,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          51464,
          407,
          718,
          311,
          536,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1881707332752369,
        "compression_ratio": 1.611336032388664,
        "end": 868,
        "id": 196,
        "no_speech_prob": 0.01262445654720068,
        "seek": 84100,
        "start": 865,
        "temperature": 0,
        "text": " Use matrix constructor to, okay.",
        "tokens": [
          51564,
          8278,
          8141,
          47479,
          281,
          11,
          1392,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 871,
        "id": 197,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 868,
        "temperature": 0,
        "text": " So tidied up the construct, this is from Phila Turner.",
        "tokens": [
          50364,
          407,
          9422,
          1091,
          493,
          264,
          7690,
          11,
          341,
          307,
          490,
          2623,
          7371,
          28950,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 873,
        "id": 198,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 871,
        "temperature": 0,
        "text": " Tidied up the constructor a little bit.",
        "tokens": [
          50514,
          314,
          327,
          1091,
          493,
          264,
          47479,
          257,
          707,
          857,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 875,
        "id": 199,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 873,
        "temperature": 0,
        "text": " Plus I've never done a pull request before.",
        "tokens": [
          50614,
          7721,
          286,
          600,
          1128,
          1096,
          257,
          2235,
          5308,
          949,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 879,
        "id": 200,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 875,
        "temperature": 0,
        "text": " Amazing.",
        "tokens": [
          50714,
          14165,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 884,
        "id": 201,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 879,
        "temperature": 0,
        "text": " Could this possibly be Phil A. Turner's first pull request that we are hopefully going to merge?",
        "tokens": [
          50914,
          7497,
          341,
          6264,
          312,
          7777,
          316,
          13,
          28950,
          311,
          700,
          2235,
          5308,
          300,
          321,
          366,
          4696,
          516,
          281,
          22183,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 887,
        "id": 202,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 884,
        "temperature": 0,
        "text": " Okay, then I wrote apologies, can you resolve the conflicts?",
        "tokens": [
          51164,
          1033,
          11,
          550,
          286,
          4114,
          34929,
          11,
          393,
          291,
          14151,
          264,
          19807,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 892,
        "id": 203,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 887,
        "temperature": 0,
        "text": " I love this change, but since I haven't explained Phil in a video yet, I wonder if it will be confusing.",
        "tokens": [
          51314,
          286,
          959,
          341,
          1319,
          11,
          457,
          1670,
          286,
          2378,
          380,
          8825,
          7777,
          294,
          257,
          960,
          1939,
          11,
          286,
          2441,
          498,
          309,
          486,
          312,
          13181,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 894,
        "id": 204,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 892,
        "temperature": 0,
        "text": " I'm just here reading my comment.",
        "tokens": [
          51564,
          286,
          478,
          445,
          510,
          3760,
          452,
          2871,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20973061803561538,
        "compression_ratio": 1.6233766233766234,
        "end": 896,
        "id": 205,
        "no_speech_prob": 0.021286601200699806,
        "seek": 86800,
        "start": 894,
        "temperature": 0,
        "text": " Or maybe this means I better just get to explaining it.",
        "tokens": [
          51664,
          1610,
          1310,
          341,
          1355,
          286,
          1101,
          445,
          483,
          281,
          13468,
          309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 898,
        "id": 206,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 896,
        "temperature": 0,
        "text": " Conflicts are resolved.",
        "tokens": [
          50364,
          2656,
          3423,
          985,
          82,
          366,
          20772,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 902,
        "id": 207,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 898,
        "temperature": 0,
        "text": " And I'm noting another issue that I discussed this in.",
        "tokens": [
          50464,
          400,
          286,
          478,
          26801,
          1071,
          2734,
          300,
          286,
          7152,
          341,
          294,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 904,
        "id": 208,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 902,
        "temperature": 0,
        "text": " But let's take a look at the code changes here.",
        "tokens": [
          50664,
          583,
          718,
          311,
          747,
          257,
          574,
          412,
          264,
          3089,
          2962,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 906,
        "id": 209,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 904,
        "temperature": 0,
        "text": " Under files change.",
        "tokens": [
          50764,
          6974,
          7098,
          1319,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 907,
        "id": 210,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 906,
        "temperature": 0,
        "text": " Excuse me.",
        "tokens": [
          50864,
          11359,
          385,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 912,
        "id": 211,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 907,
        "temperature": 0,
        "text": " Ah, so first of all, this is a wonderful little addition here, but I'll come back to that.",
        "tokens": [
          50914,
          2438,
          11,
          370,
          700,
          295,
          439,
          11,
          341,
          307,
          257,
          3715,
          707,
          4500,
          510,
          11,
          457,
          286,
          603,
          808,
          646,
          281,
          300,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 915,
        "id": 212,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 912,
        "temperature": 0,
        "text": " So look, this is the change.",
        "tokens": [
          51164,
          407,
          574,
          11,
          341,
          307,
          264,
          1319,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2078817912510463,
        "compression_ratio": 1.5546558704453441,
        "end": 922,
        "id": 213,
        "no_speech_prob": 0.04534752666950226,
        "seek": 89600,
        "start": 915,
        "temperature": 0,
        "text": " This is my ugly long-winded way of creating the two-dimensional array to store all the values in a matrix.",
        "tokens": [
          51314,
          639,
          307,
          452,
          12246,
          938,
          12,
          12199,
          292,
          636,
          295,
          4084,
          264,
          732,
          12,
          18759,
          10225,
          281,
          3531,
          439,
          264,
          4190,
          294,
          257,
          8141,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23540149688720702,
        "compression_ratio": 1.545,
        "end": 927,
        "id": 214,
        "no_speech_prob": 0.03567582741379738,
        "seek": 92200,
        "start": 922,
        "temperature": 0,
        "text": " And now instead, and shouldn't this say, should this say new array?",
        "tokens": [
          50364,
          400,
          586,
          2602,
          11,
          293,
          4659,
          380,
          341,
          584,
          11,
          820,
          341,
          584,
          777,
          10225,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.23540149688720702,
        "compression_ratio": 1.545,
        "end": 933,
        "id": 215,
        "no_speech_prob": 0.03567582741379738,
        "seek": 92200,
        "start": 927,
        "temperature": 0,
        "text": " Or is it okay to say, oh no, it's array.phil.map, array.phil.0.",
        "tokens": [
          50614,
          1610,
          307,
          309,
          1392,
          281,
          584,
          11,
          1954,
          572,
          11,
          309,
          311,
          10225,
          13,
          950,
          388,
          13,
          24223,
          11,
          10225,
          13,
          950,
          388,
          13,
          15,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23540149688720702,
        "compression_ratio": 1.545,
        "end": 938,
        "id": 216,
        "no_speech_prob": 0.03567582741379738,
        "seek": 92200,
        "start": 933,
        "temperature": 0,
        "text": " So it passed the test, so I can assume that, I think this looks pretty good to me.",
        "tokens": [
          50914,
          407,
          309,
          4678,
          264,
          1500,
          11,
          370,
          286,
          393,
          6552,
          300,
          11,
          286,
          519,
          341,
          1542,
          1238,
          665,
          281,
          385,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23540149688720702,
        "compression_ratio": 1.545,
        "end": 942,
        "id": 217,
        "no_speech_prob": 0.03567582741379738,
        "seek": 92200,
        "start": 938,
        "temperature": 0,
        "text": " But let's, just so I have this on record here, if you haven't seen Phil before.",
        "tokens": [
          51164,
          583,
          718,
          311,
          11,
          445,
          370,
          286,
          362,
          341,
          322,
          2136,
          510,
          11,
          498,
          291,
          2378,
          380,
          1612,
          7777,
          949,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23540149688720702,
        "compression_ratio": 1.545,
        "end": 944,
        "id": 218,
        "no_speech_prob": 0.03567582741379738,
        "seek": 92200,
        "start": 942,
        "temperature": 0,
        "text": " Where is Phil?",
        "tokens": [
          51364,
          2305,
          307,
          7777,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.2145451005682888,
        "compression_ratio": 1.4851485148514851,
        "end": 952,
        "id": 219,
        "no_speech_prob": 0.03308367729187012,
        "seek": 94400,
        "start": 944,
        "temperature": 0,
        "text": " Now, if you haven't seen Phil before, JavaScript array functions.",
        "tokens": [
          50364,
          823,
          11,
          498,
          291,
          2378,
          380,
          1612,
          7777,
          949,
          11,
          15778,
          10225,
          6828,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2145451005682888,
        "compression_ratio": 1.4851485148514851,
        "end": 956,
        "id": 220,
        "no_speech_prob": 0.03308367729187012,
        "seek": 94400,
        "start": 952,
        "temperature": 0,
        "text": " Alka in the patron group is saying it's fine, it's ugly either way.",
        "tokens": [
          50764,
          967,
          2330,
          294,
          264,
          21843,
          1594,
          307,
          1566,
          309,
          311,
          2489,
          11,
          309,
          311,
          12246,
          2139,
          636,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2145451005682888,
        "compression_ratio": 1.4851485148514851,
        "end": 967,
        "id": 221,
        "no_speech_prob": 0.03308367729187012,
        "seek": 94400,
        "start": 956,
        "temperature": 0,
        "text": " So the array object has a whole bunch of functions built into it like fill, find, filter, map, reduce.",
        "tokens": [
          50964,
          407,
          264,
          10225,
          2657,
          575,
          257,
          1379,
          3840,
          295,
          6828,
          3094,
          666,
          309,
          411,
          2836,
          11,
          915,
          11,
          6608,
          11,
          4471,
          11,
          5407,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2145451005682888,
        "compression_ratio": 1.4851485148514851,
        "end": 972,
        "id": 222,
        "no_speech_prob": 0.03308367729187012,
        "seek": 94400,
        "start": 967,
        "temperature": 0,
        "text": " And I really should make a list of, let's make a list of these.",
        "tokens": [
          51514,
          400,
          286,
          534,
          820,
          652,
          257,
          1329,
          295,
          11,
          718,
          311,
          652,
          257,
          1329,
          295,
          613,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20065213371725643,
        "compression_ratio": 1.5101010101010102,
        "end": 977,
        "id": 223,
        "no_speech_prob": 0.0049050129018723965,
        "seek": 97200,
        "start": 972,
        "temperature": 0,
        "text": " Let's go to rainbow topics under issues.",
        "tokens": [
          50364,
          961,
          311,
          352,
          281,
          18526,
          8378,
          833,
          2663,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20065213371725643,
        "compression_ratio": 1.5101010101010102,
        "end": 983,
        "id": 224,
        "no_speech_prob": 0.0049050129018723965,
        "seek": 97200,
        "start": 977,
        "temperature": 0,
        "text": " And let me look at array, let's see if there, I think I have one that's talking about arrays.",
        "tokens": [
          50614,
          400,
          718,
          385,
          574,
          412,
          10225,
          11,
          718,
          311,
          536,
          498,
          456,
          11,
          286,
          519,
          286,
          362,
          472,
          300,
          311,
          1417,
          466,
          41011,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20065213371725643,
        "compression_ratio": 1.5101010101010102,
        "end": 987,
        "id": 225,
        "no_speech_prob": 0.0049050129018723965,
        "seek": 97200,
        "start": 983,
        "temperature": 0,
        "text": " Like array higher order functions in JavaScript.",
        "tokens": [
          50914,
          1743,
          10225,
          2946,
          1668,
          6828,
          294,
          15778,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20065213371725643,
        "compression_ratio": 1.5101010101010102,
        "end": 989,
        "id": 226,
        "no_speech_prob": 0.0049050129018723965,
        "seek": 97200,
        "start": 987,
        "temperature": 0,
        "text": " So I definitely should do this.",
        "tokens": [
          51114,
          407,
          286,
          2138,
          820,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20065213371725643,
        "compression_ratio": 1.5101010101010102,
        "end": 995,
        "id": 227,
        "no_speech_prob": 0.0049050129018723965,
        "seek": 97200,
        "start": 989,
        "temperature": 0,
        "text": " Okay, let's, making a list of functions to cover.",
        "tokens": [
          51214,
          1033,
          11,
          718,
          311,
          11,
          1455,
          257,
          1329,
          295,
          6828,
          281,
          2060,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20065213371725643,
        "compression_ratio": 1.5101010101010102,
        "end": 999,
        "id": 228,
        "no_speech_prob": 0.0049050129018723965,
        "seek": 97200,
        "start": 995,
        "temperature": 0,
        "text": " So I am going to add a fill here.",
        "tokens": [
          51514,
          407,
          286,
          669,
          516,
          281,
          909,
          257,
          2836,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2021311735495543,
        "compression_ratio": 1.8552036199095023,
        "end": 1007,
        "id": 229,
        "no_speech_prob": 0.008445169776678085,
        "seek": 99900,
        "start": 999,
        "temperature": 0,
        "text": " So by the way, in GitHub at issue, if you do, you might not be aware of this, if you put this notation, this will leave a checkbox.",
        "tokens": [
          50364,
          407,
          538,
          264,
          636,
          11,
          294,
          23331,
          412,
          2734,
          11,
          498,
          291,
          360,
          11,
          291,
          1062,
          406,
          312,
          3650,
          295,
          341,
          11,
          498,
          291,
          829,
          341,
          24657,
          11,
          341,
          486,
          1856,
          257,
          1520,
          4995,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2021311735495543,
        "compression_ratio": 1.8552036199095023,
        "end": 1011,
        "id": 230,
        "no_speech_prob": 0.008445169776678085,
        "seek": 99900,
        "start": 1007,
        "temperature": 0,
        "text": " And if I put this notation, it will leave a checkbox that's checked.",
        "tokens": [
          50764,
          400,
          498,
          286,
          829,
          341,
          24657,
          11,
          309,
          486,
          1856,
          257,
          1520,
          4995,
          300,
          311,
          10033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2021311735495543,
        "compression_ratio": 1.8552036199095023,
        "end": 1012,
        "id": 231,
        "no_speech_prob": 0.008445169776678085,
        "seek": 99900,
        "start": 1011,
        "temperature": 0,
        "text": " But I haven't made it yet.",
        "tokens": [
          50964,
          583,
          286,
          2378,
          380,
          1027,
          309,
          1939,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2021311735495543,
        "compression_ratio": 1.8552036199095023,
        "end": 1018,
        "id": 232,
        "no_speech_prob": 0.008445169776678085,
        "seek": 99900,
        "start": 1012,
        "temperature": 0,
        "text": " So I know I want to cover fill, I know I want to cover map, I know I want to cover reduce.",
        "tokens": [
          51014,
          407,
          286,
          458,
          286,
          528,
          281,
          2060,
          2836,
          11,
          286,
          458,
          286,
          528,
          281,
          2060,
          4471,
          11,
          286,
          458,
          286,
          528,
          281,
          2060,
          5407,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2021311735495543,
        "compression_ratio": 1.8552036199095023,
        "end": 1022,
        "id": 233,
        "no_speech_prob": 0.008445169776678085,
        "seek": 99900,
        "start": 1018,
        "temperature": 0,
        "text": " And probably filter, right?",
        "tokens": [
          51314,
          400,
          1391,
          6608,
          11,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2021311735495543,
        "compression_ratio": 1.8552036199095023,
        "end": 1026,
        "id": 234,
        "no_speech_prob": 0.008445169776678085,
        "seek": 99900,
        "start": 1022,
        "temperature": 0,
        "text": " These are some array functions that I want to eventually cover.",
        "tokens": [
          51514,
          1981,
          366,
          512,
          10225,
          6828,
          300,
          286,
          528,
          281,
          4728,
          2060,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1032,
        "id": 235,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1027,
        "temperature": 0,
        "text": " So maybe in the chat, if there's some that would be important.",
        "tokens": [
          50414,
          407,
          1310,
          294,
          264,
          5081,
          11,
          498,
          456,
          311,
          512,
          300,
          576,
          312,
          1021,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1037,
        "id": 236,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1032,
        "temperature": 0,
        "text": " So I am now going to, where am I?",
        "tokens": [
          50664,
          407,
          286,
          669,
          586,
          516,
          281,
          11,
          689,
          669,
          286,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1039,
        "id": 237,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1037,
        "temperature": 0,
        "text": " Merge this pull request.",
        "tokens": [
          50914,
          6124,
          432,
          341,
          2235,
          5308,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1040,
        "id": 238,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1039,
        "temperature": 0,
        "text": " Whoops, not this one.",
        "tokens": [
          51014,
          45263,
          11,
          406,
          341,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1042,
        "id": 239,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1040,
        "temperature": 0,
        "text": " Where is it?",
        "tokens": [
          51064,
          2305,
          307,
          309,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1043,
        "id": 240,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1042,
        "temperature": 0,
        "text": " Ah, here we are.",
        "tokens": [
          51164,
          2438,
          11,
          510,
          321,
          366,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21797224593489137,
        "compression_ratio": 1.388157894736842,
        "end": 1045,
        "id": 241,
        "no_speech_prob": 0.04813210666179657,
        "seek": 102600,
        "start": 1043,
        "temperature": 0,
        "text": " I'm going to go back to conversation.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          3761,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24742524167324634,
        "compression_ratio": 1.247787610619469,
        "end": 1059,
        "id": 242,
        "no_speech_prob": 0.6074525117874146,
        "seek": 104500,
        "start": 1046,
        "temperature": 0,
        "text": " And I'm going to say merging this live on air and noting to make a video about fill here.",
        "tokens": [
          50414,
          400,
          286,
          478,
          516,
          281,
          584,
          44559,
          341,
          1621,
          322,
          1988,
          293,
          26801,
          281,
          652,
          257,
          960,
          466,
          2836,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24742524167324634,
        "compression_ratio": 1.247787610619469,
        "end": 1062,
        "id": 243,
        "no_speech_prob": 0.6074525117874146,
        "seek": 104500,
        "start": 1059,
        "temperature": 0,
        "text": " Okay, comment.",
        "tokens": [
          51064,
          1033,
          11,
          2871,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24742524167324634,
        "compression_ratio": 1.247787610619469,
        "end": 1066,
        "id": 244,
        "no_speech_prob": 0.6074525117874146,
        "seek": 104500,
        "start": 1062,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          51214,
          400,
          510,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24742524167324634,
        "compression_ratio": 1.247787610619469,
        "end": 1068,
        "id": 245,
        "no_speech_prob": 0.6074525117874146,
        "seek": 104500,
        "start": 1066,
        "temperature": 0,
        "text": " Okay, I kid you not.",
        "tokens": [
          51414,
          1033,
          11,
          286,
          1636,
          291,
          406,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1072,
        "id": 246,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1069,
        "temperature": 0,
        "text": " I'm in the middle floor, which is the film school here at NYU.",
        "tokens": [
          50414,
          286,
          478,
          294,
          264,
          2808,
          4123,
          11,
          597,
          307,
          264,
          2007,
          1395,
          510,
          412,
          42682,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1075,
        "id": 247,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1072,
        "temperature": 0,
        "text": " And so they're always watching movies, I think, in the classroom next to me.",
        "tokens": [
          50564,
          400,
          370,
          436,
          434,
          1009,
          1976,
          6233,
          11,
          286,
          519,
          11,
          294,
          264,
          7419,
          958,
          281,
          385,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1076,
        "id": 248,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1075,
        "temperature": 0,
        "text": " So I can hear the soundtrack.",
        "tokens": [
          50714,
          407,
          286,
          393,
          1568,
          264,
          27029,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1077,
        "id": 249,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1076,
        "temperature": 0,
        "text": " I don't know if you can hear that.",
        "tokens": [
          50764,
          286,
          500,
          380,
          458,
          498,
          291,
          393,
          1568,
          300,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1079,
        "id": 250,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1077,
        "temperature": 0,
        "text": " That was totally a train going by.",
        "tokens": [
          50814,
          663,
          390,
          3879,
          257,
          3847,
          516,
          538,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1083,
        "id": 251,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1079,
        "temperature": 0,
        "text": " It was like a very loud train going by.",
        "tokens": [
          50914,
          467,
          390,
          411,
          257,
          588,
          6588,
          3847,
          516,
          538,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1087,
        "id": 252,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1083,
        "temperature": 0,
        "text": " I'm here with you people in the next room.",
        "tokens": [
          51114,
          286,
          478,
          510,
          365,
          291,
          561,
          294,
          264,
          958,
          1808,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1090,
        "id": 253,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1087,
        "temperature": 0,
        "text": " We are one on the train.",
        "tokens": [
          51314,
          492,
          366,
          472,
          322,
          264,
          3847,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2080253269361413,
        "compression_ratio": 1.6059322033898304,
        "end": 1092,
        "id": 254,
        "no_speech_prob": 0.7573207020759583,
        "seek": 106800,
        "start": 1090,
        "temperature": 0,
        "text": " All right, here we go, merging.",
        "tokens": [
          51464,
          1057,
          558,
          11,
          510,
          321,
          352,
          11,
          44559,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1102,
        "id": 255,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1099,
        "temperature": 0,
        "text": " Confirming.",
        "tokens": [
          50414,
          11701,
          3692,
          278,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1115,
        "id": 256,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1112,
        "temperature": 0,
        "text": " All right, thank you, thank you.",
        "tokens": [
          51064,
          1057,
          558,
          11,
          1309,
          291,
          11,
          1309,
          291,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1116,
        "id": 257,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1115,
        "temperature": 0,
        "text": " That was a merge.",
        "tokens": [
          51214,
          663,
          390,
          257,
          22183,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1118,
        "id": 258,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1116,
        "temperature": 0,
        "text": " That was a pull request merged.",
        "tokens": [
          51264,
          663,
          390,
          257,
          2235,
          5308,
          36427,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1120,
        "id": 259,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1118,
        "temperature": 0,
        "text": " Alka is mentioning sort.",
        "tokens": [
          51364,
          967,
          2330,
          307,
          18315,
          1333,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1122,
        "id": 260,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1120,
        "temperature": 0,
        "text": " I've actually talked about sort in a video.",
        "tokens": [
          51464,
          286,
          600,
          767,
          2825,
          466,
          1333,
          294,
          257,
          960,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1124,
        "id": 261,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1122,
        "temperature": 0,
        "text": " I don't remember which one.",
        "tokens": [
          51564,
          286,
          500,
          380,
          1604,
          597,
          472,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2412793543431666,
        "compression_ratio": 1.4723926380368098,
        "end": 1126,
        "id": 262,
        "no_speech_prob": 0.03113958239555359,
        "seek": 109800,
        "start": 1124,
        "temperature": 0,
        "text": " But I have a very distinct memory of using sort.",
        "tokens": [
          51664,
          583,
          286,
          362,
          257,
          588,
          10644,
          4675,
          295,
          1228,
          1333,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1129,
        "id": 263,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1126,
        "temperature": 0,
        "text": " But it would be worth mentioning or covering in that context as well.",
        "tokens": [
          50364,
          583,
          309,
          576,
          312,
          3163,
          18315,
          420,
          10322,
          294,
          300,
          4319,
          382,
          731,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1131,
        "id": 264,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1129,
        "temperature": 0,
        "text": " Thank you for that.",
        "tokens": [
          50514,
          1044,
          291,
          337,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1134,
        "id": 265,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1131,
        "temperature": 0,
        "text": " All right, so we got one pull request done.",
        "tokens": [
          50614,
          1057,
          558,
          11,
          370,
          321,
          658,
          472,
          2235,
          5308,
          1096,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1139,
        "id": 266,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1134,
        "temperature": 0,
        "text": " Now, use ES6 exported import functions.",
        "tokens": [
          50764,
          823,
          11,
          764,
          12564,
          21,
          42055,
          974,
          6828,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1142,
        "id": 267,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1139,
        "temperature": 0,
        "text": " Okay, this I'm not ready for yet.",
        "tokens": [
          51014,
          1033,
          11,
          341,
          286,
          478,
          406,
          1919,
          337,
          1939,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1145,
        "id": 268,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1142,
        "temperature": 0,
        "text": " There's a nice discussion here.",
        "tokens": [
          51164,
          821,
          311,
          257,
          1481,
          5017,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1147,
        "id": 269,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1145,
        "temperature": 0,
        "text": " It's also out of date.",
        "tokens": [
          51314,
          467,
          311,
          611,
          484,
          295,
          4002,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1149,
        "id": 270,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1147,
        "temperature": 0,
        "text": " But let me see if I can update it.",
        "tokens": [
          51414,
          583,
          718,
          385,
          536,
          498,
          286,
          393,
          5623,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1152,
        "id": 271,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1149,
        "temperature": 0,
        "text": " That should be fine because I merged that other pull request.",
        "tokens": [
          51514,
          663,
          820,
          312,
          2489,
          570,
          286,
          36427,
          300,
          661,
          2235,
          5308,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18640636575633082,
        "compression_ratio": 1.5511811023622046,
        "end": 1155,
        "id": 272,
        "no_speech_prob": 0.007935678586363792,
        "seek": 112600,
        "start": 1152,
        "temperature": 0,
        "text": " It's going to run the tests again.",
        "tokens": [
          51664,
          467,
          311,
          516,
          281,
          1190,
          264,
          6921,
          797,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1159,
        "id": 273,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1156,
        "temperature": 0,
        "text": " Let's look at the files changed here.",
        "tokens": [
          50414,
          961,
          311,
          574,
          412,
          264,
          7098,
          3105,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1162,
        "id": 274,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1159,
        "temperature": 0,
        "text": " Yeah, so this is using ES6 modules.",
        "tokens": [
          50564,
          865,
          11,
          370,
          341,
          307,
          1228,
          12564,
          21,
          16679,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1165,
        "id": 275,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1162,
        "temperature": 0,
        "text": " And I feel like I'm not ready for that yet.",
        "tokens": [
          50714,
          400,
          286,
          841,
          411,
          286,
          478,
          406,
          1919,
          337,
          300,
          1939,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1167,
        "id": 276,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1165,
        "temperature": 0,
        "text": " But I really should add that soon.",
        "tokens": [
          50864,
          583,
          286,
          534,
          820,
          909,
          300,
          2321,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1169,
        "id": 277,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1167,
        "temperature": 0,
        "text": " It will fix the whole testing stuff.",
        "tokens": [
          50964,
          467,
          486,
          3191,
          264,
          1379,
          4997,
          1507,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1174,
        "id": 278,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1169,
        "temperature": 0,
        "text": " So maybe I need to do a video about that and understand that better.",
        "tokens": [
          51064,
          407,
          1310,
          286,
          643,
          281,
          360,
          257,
          960,
          466,
          300,
          293,
          1223,
          300,
          1101,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1176,
        "id": 279,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1174,
        "temperature": 0,
        "text": " Because it's got the export here.",
        "tokens": [
          51314,
          1436,
          309,
          311,
          658,
          264,
          10725,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1181,
        "id": 280,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1178,
        "temperature": 0,
        "text": " And it needs this like babble thing.",
        "tokens": [
          51514,
          400,
          309,
          2203,
          341,
          411,
          7564,
          638,
          551,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1182,
        "id": 281,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1181,
        "temperature": 0,
        "text": " So I could be talked into this.",
        "tokens": [
          51664,
          407,
          286,
          727,
          312,
          2825,
          666,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17221696498030323,
        "compression_ratio": 1.5887096774193548,
        "end": 1184,
        "id": 282,
        "no_speech_prob": 0.004829238634556532,
        "seek": 115500,
        "start": 1182,
        "temperature": 0,
        "text": " But this I don't feel ready for.",
        "tokens": [
          51714,
          583,
          341,
          286,
          500,
          380,
          841,
          1919,
          337,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22486658529801803,
        "compression_ratio": 1.5654450261780104,
        "end": 1189,
        "id": 283,
        "no_speech_prob": 0.009266010485589504,
        "seek": 118400,
        "start": 1184,
        "temperature": 0,
        "text": " Even though I'm super thankful for this wonderful thoughtful pull requests.",
        "tokens": [
          50364,
          2754,
          1673,
          286,
          478,
          1687,
          13611,
          337,
          341,
          3715,
          21566,
          2235,
          12475,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22486658529801803,
        "compression_ratio": 1.5654450261780104,
        "end": 1193,
        "id": 284,
        "no_speech_prob": 0.009266010485589504,
        "seek": 118400,
        "start": 1189,
        "temperature": 0,
        "text": " Okay, so now updated to-do list.",
        "tokens": [
          50614,
          1033,
          11,
          370,
          586,
          10588,
          281,
          12,
          2595,
          1329,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22486658529801803,
        "compression_ratio": 1.5654450261780104,
        "end": 1199,
        "id": 285,
        "no_speech_prob": 0.009266010485589504,
        "seek": 118400,
        "start": 1196,
        "temperature": 0,
        "text": " Oh yeah, this was a...",
        "tokens": [
          50964,
          876,
          1338,
          11,
          341,
          390,
          257,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.22486658529801803,
        "compression_ratio": 1.5654450261780104,
        "end": 1203,
        "id": 286,
        "no_speech_prob": 0.009266010485589504,
        "seek": 118400,
        "start": 1199,
        "temperature": 0,
        "text": " Oh yeah, this was somebody who added and fixed up the to-do list",
        "tokens": [
          51114,
          876,
          1338,
          11,
          341,
          390,
          2618,
          567,
          3869,
          293,
          6806,
          493,
          264,
          281,
          12,
          2595,
          1329,
          51314
        ]
      },
      {
        "avg_logprob": -0.22486658529801803,
        "compression_ratio": 1.5654450261780104,
        "end": 1208,
        "id": 287,
        "no_speech_prob": 0.009266010485589504,
        "seek": 118400,
        "start": 1203,
        "temperature": 0,
        "text": " that was in my nn.js file that I just put in the comments.",
        "tokens": [
          51314,
          300,
          390,
          294,
          452,
          297,
          77,
          13,
          25530,
          3991,
          300,
          286,
          445,
          829,
          294,
          264,
          3053,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22486658529801803,
        "compression_ratio": 1.5654450261780104,
        "end": 1212,
        "id": 288,
        "no_speech_prob": 0.009266010485589504,
        "seek": 118400,
        "start": 1208,
        "temperature": 0,
        "text": " And I guess I've done all these things now.",
        "tokens": [
          51564,
          400,
          286,
          2041,
          286,
          600,
          1096,
          439,
          613,
          721,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1213,
        "id": 289,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1212,
        "temperature": 0,
        "text": " Except for the MNIST coding challenge.",
        "tokens": [
          50364,
          16192,
          337,
          264,
          376,
          45,
          19756,
          17720,
          3430,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1216,
        "id": 290,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1213,
        "temperature": 0,
        "text": " I'm going to redo the XOR coding challenge today.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          29956,
          264,
          1783,
          2483,
          17720,
          3430,
          965,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1219,
        "id": 291,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1216,
        "temperature": 0,
        "text": " But I did make a comment about this one.",
        "tokens": [
          50564,
          583,
          286,
          630,
          652,
          257,
          2871,
          466,
          341,
          472,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1225,
        "id": 292,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1219,
        "temperature": 0,
        "text": " Which is I thought this might be better in say the readme.",
        "tokens": [
          50714,
          3013,
          307,
          286,
          1194,
          341,
          1062,
          312,
          1101,
          294,
          584,
          264,
          1401,
          1398,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1228,
        "id": 293,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1225,
        "temperature": 0,
        "text": " So I'm going to...",
        "tokens": [
          51014,
          407,
          286,
          478,
          516,
          281,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1232,
        "id": 294,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1230,
        "temperature": 0,
        "text": " I'm going to merge this right now.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          22183,
          341,
          558,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1233,
        "id": 295,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1232,
        "temperature": 0,
        "text": " Because why not merge?",
        "tokens": [
          51364,
          1436,
          983,
          406,
          22183,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.21423669879356128,
        "compression_ratio": 1.5833333333333333,
        "end": 1235,
        "id": 296,
        "no_speech_prob": 0.0002492169733159244,
        "seek": 121200,
        "start": 1233,
        "temperature": 0,
        "text": " Merge this for now.",
        "tokens": [
          51414,
          6124,
          432,
          341,
          337,
          586,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1236,
        "id": 297,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1235,
        "temperature": 0,
        "text": " Merge this for now.",
        "tokens": [
          50364,
          6124,
          432,
          341,
          337,
          586,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1248,
        "id": 298,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1236,
        "temperature": 0,
        "text": " But maybe someone will pull request a new place for the to-do list.",
        "tokens": [
          50414,
          583,
          1310,
          1580,
          486,
          2235,
          5308,
          257,
          777,
          1081,
          337,
          264,
          281,
          12,
          2595,
          1329,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1255,
        "id": 299,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1251,
        "temperature": 0,
        "text": " Now interestingly enough, I cannot merge it.",
        "tokens": [
          51164,
          823,
          25873,
          1547,
          11,
          286,
          2644,
          22183,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1257,
        "id": 300,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1255,
        "temperature": 0,
        "text": " Why is this there?",
        "tokens": [
          51364,
          1545,
          307,
          341,
          456,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1260,
        "id": 301,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1257,
        "temperature": 0,
        "text": " It's because it's got to run the tests again.",
        "tokens": [
          51464,
          467,
          311,
          570,
          309,
          311,
          658,
          281,
          1190,
          264,
          6921,
          797,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1261,
        "id": 302,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1260,
        "temperature": 0,
        "text": " And it's probably waiting.",
        "tokens": [
          51614,
          400,
          309,
          311,
          1391,
          3806,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1263,
        "id": 303,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1261,
        "temperature": 0,
        "text": " Let's see, show all checks.",
        "tokens": [
          51664,
          961,
          311,
          536,
          11,
          855,
          439,
          13834,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2107278278895787,
        "compression_ratio": 1.3979057591623036,
        "end": 1264,
        "id": 304,
        "no_speech_prob": 0.023688485845923424,
        "seek": 123500,
        "start": 1263,
        "temperature": 0,
        "text": " Oh, it passed.",
        "tokens": [
          51764,
          876,
          11,
          309,
          4678,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1269,
        "id": 305,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1266,
        "temperature": 0,
        "text": " So what test has it not run yet?",
        "tokens": [
          50414,
          407,
          437,
          1500,
          575,
          309,
          406,
          1190,
          1939,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1271,
        "id": 306,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1269,
        "temperature": 0,
        "text": " That it won't...",
        "tokens": [
          50564,
          663,
          309,
          1582,
          380,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1274,
        "id": 307,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1272,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          50714,
          14711,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1275,
        "id": 308,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1274,
        "temperature": 0,
        "text": " So I'll come back.",
        "tokens": [
          50814,
          407,
          286,
          603,
          808,
          646,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1278,
        "id": 309,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1275,
        "temperature": 0,
        "text": " I'm not sure why this one won't allow me to merge it.",
        "tokens": [
          50864,
          286,
          478,
          406,
          988,
          983,
          341,
          472,
          1582,
          380,
          2089,
          385,
          281,
          22183,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1282,
        "id": 310,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1278,
        "temperature": 0,
        "text": " By the way, if you're wondering what's going on with why this merge button is not available.",
        "tokens": [
          51014,
          3146,
          264,
          636,
          11,
          498,
          291,
          434,
          6359,
          437,
          311,
          516,
          322,
          365,
          983,
          341,
          22183,
          2960,
          307,
          406,
          2435,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1286,
        "id": 311,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1282,
        "temperature": 0,
        "text": " I did a whole video tutorial series about unit testing and continuous integration.",
        "tokens": [
          51214,
          286,
          630,
          257,
          1379,
          960,
          7073,
          2638,
          466,
          4985,
          4997,
          293,
          10957,
          10980,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1289,
        "id": 312,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1286,
        "temperature": 0,
        "text": " And there's a live stream which already is online and archived.",
        "tokens": [
          51414,
          400,
          456,
          311,
          257,
          1621,
          4309,
          597,
          1217,
          307,
          2950,
          293,
          3912,
          3194,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1292,
        "id": 313,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1289,
        "temperature": 0,
        "text": " But the actual edited videos are prepared but haven't been released yet.",
        "tokens": [
          51564,
          583,
          264,
          3539,
          23016,
          2145,
          366,
          4927,
          457,
          2378,
          380,
          668,
          4736,
          1939,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19274933154766377,
        "compression_ratio": 1.6521739130434783,
        "end": 1294,
        "id": 314,
        "no_speech_prob": 0.016401274129748344,
        "seek": 126500,
        "start": 1292,
        "temperature": 0,
        "text": " Those will start coming out tomorrow morning.",
        "tokens": [
          51714,
          3950,
          486,
          722,
          1348,
          484,
          4153,
          2446,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1297,
        "id": 315,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1295,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1301,
        "id": 316,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1300,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50664,
          2798,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1304,
        "id": 317,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1301,
        "temperature": 0,
        "text": " Yeah, me, I am, so me is...",
        "tokens": [
          50714,
          865,
          11,
          385,
          11,
          286,
          669,
          11,
          370,
          385,
          307,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1311,
        "id": 318,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1304,
        "temperature": 0,
        "text": " Yeah, so if I were doing this properly, I would probably want to check a bunch of these things locally.",
        "tokens": [
          50864,
          865,
          11,
          370,
          498,
          286,
          645,
          884,
          341,
          6108,
          11,
          286,
          576,
          1391,
          528,
          281,
          1520,
          257,
          3840,
          295,
          613,
          721,
          16143,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1314,
        "id": 319,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1311,
        "temperature": 0,
        "text": " But I'm just living on the edge.",
        "tokens": [
          51214,
          583,
          286,
          478,
          445,
          2647,
          322,
          264,
          4691,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1316,
        "id": 320,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1314,
        "temperature": 0,
        "text": " I'm doing this just through the GitHub interface.",
        "tokens": [
          51364,
          286,
          478,
          884,
          341,
          445,
          807,
          264,
          23331,
          9226,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2764351547405284,
        "compression_ratio": 1.5422885572139304,
        "end": 1320,
        "id": 321,
        "no_speech_prob": 0.008442123420536518,
        "seek": 129400,
        "start": 1316,
        "temperature": 0,
        "text": " But I could pull the branch and have it local, test it out, run the test myself.",
        "tokens": [
          51464,
          583,
          286,
          727,
          2235,
          264,
          9819,
          293,
          362,
          309,
          2654,
          11,
          1500,
          309,
          484,
          11,
          1190,
          264,
          1500,
          2059,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1323,
        "id": 322,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1321,
        "temperature": 0,
        "text": " And I really don't understand why this one is not merging.",
        "tokens": [
          50414,
          400,
          286,
          534,
          500,
          380,
          1223,
          983,
          341,
          472,
          307,
          406,
          44559,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1326,
        "id": 323,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1323,
        "temperature": 0,
        "text": " But I'm going to come back to here.",
        "tokens": [
          50514,
          583,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1329,
        "id": 324,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1326,
        "temperature": 0,
        "text": " Updating transposed tests.",
        "tokens": [
          50664,
          5858,
          67,
          990,
          7132,
          1744,
          6921,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1337,
        "id": 325,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1331,
        "temperature": 0,
        "text": " So this is a pull request that came in about the transposed test.",
        "tokens": [
          50914,
          407,
          341,
          307,
          257,
          2235,
          5308,
          300,
          1361,
          294,
          466,
          264,
          7132,
          1744,
          1500,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1340,
        "id": 326,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1337,
        "temperature": 0,
        "text": " And I added some comments and requested those changes.",
        "tokens": [
          51214,
          400,
          286,
          3869,
          512,
          3053,
          293,
          16436,
          729,
          2962,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1342,
        "id": 327,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1340,
        "temperature": 0,
        "text": " Those changes have not come in yet.",
        "tokens": [
          51364,
          3950,
          2962,
          362,
          406,
          808,
          294,
          1939,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1344,
        "id": 328,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1342,
        "temperature": 0,
        "text": " So I'm going to leave this one alone.",
        "tokens": [
          51464,
          407,
          286,
          478,
          516,
          281,
          1856,
          341,
          472,
          3312,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1834058073378101,
        "compression_ratio": 1.7164179104477613,
        "end": 1348,
        "id": 329,
        "no_speech_prob": 0.003074091160669923,
        "seek": 132000,
        "start": 1346,
        "temperature": 0,
        "text": " Added more transposed tests.",
        "tokens": [
          51664,
          5349,
          292,
          544,
          7132,
          1744,
          6921,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18783320320977104,
        "compression_ratio": 1.368,
        "end": 1354,
        "id": 330,
        "no_speech_prob": 0.0003005636972375214,
        "seek": 135000,
        "start": 1351,
        "temperature": 0,
        "text": " And let's see if I can, let's run this update.",
        "tokens": [
          50414,
          400,
          718,
          311,
          536,
          498,
          286,
          393,
          11,
          718,
          311,
          1190,
          341,
          5623,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18783320320977104,
        "compression_ratio": 1.368,
        "end": 1359,
        "id": 331,
        "no_speech_prob": 0.0003005636972375214,
        "seek": 135000,
        "start": 1357,
        "temperature": 0,
        "text": " So it's running the tests.",
        "tokens": [
          50714,
          407,
          309,
          311,
          2614,
          264,
          6921,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18783320320977104,
        "compression_ratio": 1.368,
        "end": 1371,
        "id": 332,
        "no_speech_prob": 0.0003005636972375214,
        "seek": 135000,
        "start": 1369,
        "temperature": 0,
        "text": " Now there's some music playing in the other room.",
        "tokens": [
          51314,
          823,
          456,
          311,
          512,
          1318,
          2433,
          294,
          264,
          661,
          1808,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18783320320977104,
        "compression_ratio": 1.368,
        "end": 1373,
        "id": 333,
        "no_speech_prob": 0.0003005636972375214,
        "seek": 135000,
        "start": 1371,
        "temperature": 0,
        "text": " Alright, we got to wait for the test to finish.",
        "tokens": [
          51414,
          2798,
          11,
          321,
          658,
          281,
          1699,
          337,
          264,
          1500,
          281,
          2413,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1375,
        "id": 334,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1373,
        "temperature": 0,
        "text": " I could go on to a different pull request.",
        "tokens": [
          50364,
          286,
          727,
          352,
          322,
          281,
          257,
          819,
          2235,
          5308,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1376,
        "id": 335,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1375,
        "temperature": 0,
        "text": " But I like just waiting.",
        "tokens": [
          50464,
          583,
          286,
          411,
          445,
          3806,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1378,
        "id": 336,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1376,
        "temperature": 0,
        "text": " I like to see it just like...",
        "tokens": [
          50514,
          286,
          411,
          281,
          536,
          309,
          445,
          411,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1383,
        "id": 337,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1379,
        "temperature": 0,
        "text": " By the way, we could see the test, I think under details.",
        "tokens": [
          50664,
          3146,
          264,
          636,
          11,
          321,
          727,
          536,
          264,
          1500,
          11,
          286,
          519,
          833,
          4365,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1385,
        "id": 338,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1384,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          50914,
          7010,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1387,
        "id": 339,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1385,
        "temperature": 0,
        "text": " Let's watch the test going.",
        "tokens": [
          50964,
          961,
          311,
          1159,
          264,
          1500,
          516,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1390,
        "id": 340,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1389,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          51164,
          1692,
          309,
          307,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1391,
        "id": 341,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1390,
        "temperature": 0,
        "text": " It's running it.",
        "tokens": [
          51214,
          467,
          311,
          2614,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1392,
        "id": 342,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1391,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51264,
          21726,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1393,
        "id": 343,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1392,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51314,
          4919,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1395,
        "id": 344,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1393,
        "temperature": 0,
        "text": " Oh, they all passed.",
        "tokens": [
          51364,
          876,
          11,
          436,
          439,
          4678,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2555137751053791,
        "compression_ratio": 1.5251396648044693,
        "end": 1397,
        "id": 345,
        "no_speech_prob": 0.0005357588524930179,
        "seek": 137300,
        "start": 1395,
        "temperature": 0,
        "text": " All the tests passed.",
        "tokens": [
          51464,
          1057,
          264,
          6921,
          4678,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1398,
        "id": 346,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1397,
        "temperature": 0,
        "text": " So it should now...",
        "tokens": [
          50364,
          407,
          309,
          820,
          586,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1401,
        "id": 347,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1400,
        "temperature": 0,
        "text": " Say the test passed.",
        "tokens": [
          50514,
          6463,
          264,
          1500,
          4678,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1402,
        "id": 348,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1401,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          50564,
          7010,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1403,
        "id": 349,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1402,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          50614,
          2798,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1405,
        "id": 350,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1403,
        "temperature": 0,
        "text": " Let's look at what this code was.",
        "tokens": [
          50664,
          961,
          311,
          574,
          412,
          437,
          341,
          3089,
          390,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1411,
        "id": 351,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1407,
        "temperature": 0,
        "text": " So this looks like it's adding a test for transpose.",
        "tokens": [
          50864,
          407,
          341,
          1542,
          411,
          309,
          311,
          5127,
          257,
          1500,
          337,
          25167,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1414,
        "id": 352,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1411,
        "temperature": 0,
        "text": " It's checking a 1x1 matrix.",
        "tokens": [
          51064,
          467,
          311,
          8568,
          257,
          502,
          87,
          16,
          8141,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1417,
        "id": 353,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1414,
        "temperature": 0,
        "text": " Then it's checking a 2x3 to 3x2.",
        "tokens": [
          51214,
          1396,
          309,
          311,
          8568,
          257,
          568,
          87,
          18,
          281,
          805,
          87,
          17,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1420,
        "id": 354,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1418,
        "temperature": 0,
        "text": " Checking a 3x2 to 3x3.",
        "tokens": [
          51414,
          6881,
          278,
          257,
          805,
          87,
          17,
          281,
          805,
          87,
          18,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1422,
        "id": 355,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1420,
        "temperature": 0,
        "text": " Checking a 3x3 to 3x3.",
        "tokens": [
          51514,
          6881,
          278,
          257,
          805,
          87,
          18,
          281,
          805,
          87,
          18,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1424,
        "id": 356,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1422,
        "temperature": 0,
        "text": " Checking a 3x3 to 3x3.",
        "tokens": [
          51614,
          6881,
          278,
          257,
          805,
          87,
          18,
          281,
          805,
          87,
          18,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23657193521815023,
        "compression_ratio": 1.8148148148148149,
        "end": 1426,
        "id": 357,
        "no_speech_prob": 0.006902977824211121,
        "seek": 139700,
        "start": 1424,
        "temperature": 0,
        "text": " Checking a 3x3 to 3x3.",
        "tokens": [
          51714,
          6881,
          278,
          257,
          805,
          87,
          18,
          281,
          805,
          87,
          18,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1428,
        "id": 358,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1426,
        "temperature": 0,
        "text": " Checking a 3x2 to 2x3.",
        "tokens": [
          50364,
          6881,
          278,
          257,
          805,
          87,
          17,
          281,
          568,
          87,
          18,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1429,
        "id": 359,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1428,
        "temperature": 0,
        "text": " This looks good.",
        "tokens": [
          50464,
          639,
          1542,
          665,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1430,
        "id": 360,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1429,
        "temperature": 0,
        "text": " Checking a 1x5.",
        "tokens": [
          50514,
          6881,
          278,
          257,
          502,
          87,
          20,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1431,
        "id": 361,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1430,
        "temperature": 0,
        "text": " This is nice.",
        "tokens": [
          50564,
          639,
          307,
          1481,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1432,
        "id": 362,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1431,
        "temperature": 0,
        "text": " I love this test.",
        "tokens": [
          50614,
          286,
          959,
          341,
          1500,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1433,
        "id": 363,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1432,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1434,
        "id": 364,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1433,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50714,
          3769,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1435,
        "id": 365,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1434,
        "temperature": 0,
        "text": " I think this looks good to me.",
        "tokens": [
          50764,
          286,
          519,
          341,
          1542,
          665,
          281,
          385,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1436,
        "id": 366,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1435,
        "temperature": 0,
        "text": " We need tests for the tests.",
        "tokens": [
          50814,
          492,
          643,
          6921,
          337,
          264,
          6921,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1439,
        "id": 367,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1436,
        "temperature": 0,
        "text": " And again, I should look this over more carefully.",
        "tokens": [
          50864,
          400,
          797,
          11,
          286,
          820,
          574,
          341,
          670,
          544,
          7500,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1441,
        "id": 368,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1439,
        "temperature": 0,
        "text": " But you know, this is just an open source project for fun.",
        "tokens": [
          51014,
          583,
          291,
          458,
          11,
          341,
          307,
          445,
          364,
          1269,
          4009,
          1716,
          337,
          1019,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1443,
        "id": 369,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1441,
        "temperature": 0,
        "text": " I'm so appreciative.",
        "tokens": [
          51114,
          286,
          478,
          370,
          43239,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1448,
        "id": 370,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1447,
        "temperature": 0,
        "text": " Merge.",
        "tokens": [
          51414,
          6124,
          432,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1449,
        "id": 371,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1448,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51464,
          400,
          550,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.13240213863185193,
        "compression_ratio": 1.4908256880733946,
        "end": 1453,
        "id": 372,
        "no_speech_prob": 0.0010986537672579288,
        "seek": 142600,
        "start": 1451,
        "temperature": 0,
        "text": " Confirm merge.",
        "tokens": [
          51614,
          11701,
          3692,
          22183,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1456,
        "id": 373,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1454,
        "temperature": 0,
        "text": " And we have merged this pull request.",
        "tokens": [
          50414,
          400,
          321,
          362,
          36427,
          341,
          2235,
          5308,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1460,
        "id": 374,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1456,
        "temperature": 0,
        "text": " Thank you to Mikhail Sousa.",
        "tokens": [
          50514,
          1044,
          291,
          281,
          16380,
          48909,
          318,
          563,
          64,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1462,
        "id": 375,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1460,
        "temperature": 0,
        "text": " Who submitted that pull request that is now merged.",
        "tokens": [
          50714,
          2102,
          14405,
          300,
          2235,
          5308,
          300,
          307,
          586,
          36427,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1463,
        "id": 376,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1462,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1465,
        "id": 377,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1463,
        "temperature": 0,
        "text": " Now, map improvements.",
        "tokens": [
          50864,
          823,
          11,
          4471,
          13797,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1467,
        "id": 378,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1465,
        "temperature": 0,
        "text": " Oh, this one I'm excited about.",
        "tokens": [
          50964,
          876,
          11,
          341,
          472,
          286,
          478,
          2919,
          466,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1471,
        "id": 379,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1467,
        "temperature": 0,
        "text": " Map improvements and using map instead of two nested for loops.",
        "tokens": [
          51064,
          22053,
          13797,
          293,
          1228,
          4471,
          2602,
          295,
          732,
          15646,
          292,
          337,
          16121,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1474,
        "id": 380,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1471,
        "temperature": 0,
        "text": " Oh, another reason why I want to redo the XOR challenge",
        "tokens": [
          51264,
          876,
          11,
          1071,
          1778,
          983,
          286,
          528,
          281,
          29956,
          264,
          1783,
          2483,
          3430,
          51414
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1476,
        "id": 381,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1474,
        "temperature": 0,
        "text": " is I was playing with the learning rate",
        "tokens": [
          51414,
          307,
          286,
          390,
          2433,
          365,
          264,
          2539,
          3314,
          51514
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1478,
        "id": 382,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1476,
        "temperature": 0,
        "text": " and it wasn't working the whole time",
        "tokens": [
          51514,
          293,
          309,
          2067,
          380,
          1364,
          264,
          1379,
          565,
          51614
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1479,
        "id": 383,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1478,
        "temperature": 0,
        "text": " because I had the wrong variable name.",
        "tokens": [
          51614,
          570,
          286,
          632,
          264,
          2085,
          7006,
          1315,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21753161190120318,
        "compression_ratio": 1.667857142857143,
        "end": 1481,
        "id": 384,
        "no_speech_prob": 0.014278686605393887,
        "seek": 145300,
        "start": 1479,
        "temperature": 0,
        "text": " And this pull request is going to help us with that.",
        "tokens": [
          51664,
          400,
          341,
          2235,
          5308,
          307,
          516,
          281,
          854,
          505,
          365,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1486,
        "id": 385,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1481,
        "temperature": 0,
        "text": " So, I am now going to go to map improvements.",
        "tokens": [
          50364,
          407,
          11,
          286,
          669,
          586,
          516,
          281,
          352,
          281,
          4471,
          13797,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1489,
        "id": 386,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1486,
        "temperature": 0,
        "text": " So, let's do this.",
        "tokens": [
          50614,
          407,
          11,
          718,
          311,
          360,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1490,
        "id": 387,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1489,
        "temperature": 0,
        "text": " Let me look at this one.",
        "tokens": [
          50764,
          961,
          385,
          574,
          412,
          341,
          472,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1494,
        "id": 388,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1493,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1497,
        "id": 389,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1494,
        "temperature": 0,
        "text": " So, made map pass the row and column to the callback function.",
        "tokens": [
          51014,
          407,
          11,
          1027,
          4471,
          1320,
          264,
          5386,
          293,
          7738,
          281,
          264,
          818,
          3207,
          2445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1499,
        "id": 390,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1497,
        "temperature": 0,
        "text": " So, this is really useful.",
        "tokens": [
          51164,
          407,
          11,
          341,
          307,
          534,
          4420,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1503,
        "id": 391,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1499,
        "temperature": 0,
        "text": " I have a map function in the library, which I could pull up.",
        "tokens": [
          51264,
          286,
          362,
          257,
          4471,
          2445,
          294,
          264,
          6405,
          11,
          597,
          286,
          727,
          2235,
          493,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1506,
        "id": 392,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1503,
        "temperature": 0,
        "text": " And the map function expects a callback function",
        "tokens": [
          51464,
          400,
          264,
          4471,
          2445,
          33280,
          257,
          818,
          3207,
          2445,
          51614
        ]
      },
      {
        "avg_logprob": -0.19197571631705407,
        "compression_ratio": 1.5817307692307692,
        "end": 1508,
        "id": 393,
        "no_speech_prob": 0.00658925948664546,
        "seek": 148100,
        "start": 1506,
        "temperature": 0,
        "text": " that it applies to every element.",
        "tokens": [
          51614,
          300,
          309,
          13165,
          281,
          633,
          4478,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1510,
        "id": 394,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1508,
        "temperature": 0,
        "text": " And sometimes you want to know the column and row",
        "tokens": [
          50364,
          400,
          2171,
          291,
          528,
          281,
          458,
          264,
          7738,
          293,
          5386,
          50464
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1512,
        "id": 395,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1510,
        "temperature": 0,
        "text": " or the row and column indices.",
        "tokens": [
          50464,
          420,
          264,
          5386,
          293,
          7738,
          43840,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1513,
        "id": 396,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1512,
        "temperature": 0,
        "text": " And I didn't implement that.",
        "tokens": [
          50564,
          400,
          286,
          994,
          380,
          4445,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1514,
        "id": 397,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1513,
        "temperature": 0,
        "text": " So, this implements that.",
        "tokens": [
          50614,
          407,
          11,
          341,
          704,
          17988,
          300,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1521,
        "id": 398,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1517,
        "temperature": 0,
        "text": " And then it also has a lot of use of the ES6 arrow notation.",
        "tokens": [
          50814,
          400,
          550,
          309,
          611,
          575,
          257,
          688,
          295,
          764,
          295,
          264,
          12564,
          21,
          11610,
          24657,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1527,
        "id": 399,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1522,
        "temperature": 0,
        "text": " So, I wasn't sure about merging this just yet.",
        "tokens": [
          51064,
          407,
          11,
          286,
          2067,
          380,
          988,
          466,
          44559,
          341,
          445,
          1939,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1533,
        "id": 400,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1527,
        "temperature": 0,
        "text": " But now that I have the original source code backed up,",
        "tokens": [
          51314,
          583,
          586,
          300,
          286,
          362,
          264,
          3380,
          4009,
          3089,
          20391,
          493,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.1865044819939997,
        "compression_ratio": 1.5598086124401913,
        "end": 1535,
        "id": 401,
        "no_speech_prob": 0.02635425515472889,
        "seek": 150800,
        "start": 1533,
        "temperature": 0,
        "text": " let's take a look at this.",
        "tokens": [
          51614,
          718,
          311,
          747,
          257,
          574,
          412,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1539,
        "id": 402,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1536,
        "temperature": 0,
        "text": " So, first of all, let's run the tests again",
        "tokens": [
          50414,
          407,
          11,
          700,
          295,
          439,
          11,
          718,
          311,
          1190,
          264,
          6921,
          797,
          50564
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1540,
        "id": 403,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1539,
        "temperature": 0,
        "text": " because I'm sure it's...",
        "tokens": [
          50564,
          570,
          286,
          478,
          988,
          309,
          311,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1542,
        "id": 404,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1540,
        "temperature": 0,
        "text": " Oh, we've got conflicts now.",
        "tokens": [
          50614,
          876,
          11,
          321,
          600,
          658,
          19807,
          586,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1544,
        "id": 405,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1542,
        "temperature": 0,
        "text": " Oh, so sad.",
        "tokens": [
          50714,
          876,
          11,
          370,
          4227,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1546,
        "id": 406,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1544,
        "temperature": 0,
        "text": " So, unfortunately, there's some conflicts here",
        "tokens": [
          50814,
          407,
          11,
          7015,
          11,
          456,
          311,
          512,
          19807,
          510,
          50914
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1551,
        "id": 407,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1546,
        "temperature": 0,
        "text": " because some of the other merges changed the same.",
        "tokens": [
          50914,
          570,
          512,
          295,
          264,
          661,
          3551,
          2880,
          3105,
          264,
          912,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1553,
        "id": 408,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1551,
        "temperature": 0,
        "text": " So, you get a merge conflict.",
        "tokens": [
          51164,
          407,
          11,
          291,
          483,
          257,
          22183,
          6596,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1555,
        "id": 409,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1553,
        "temperature": 0,
        "text": " And I need to do a whole video about this.",
        "tokens": [
          51264,
          400,
          286,
          643,
          281,
          360,
          257,
          1379,
          960,
          466,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1557,
        "id": 410,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1555,
        "temperature": 0,
        "text": " I have this on my list in my GitHub series.",
        "tokens": [
          51364,
          286,
          362,
          341,
          322,
          452,
          1329,
          294,
          452,
          23331,
          2638,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1558,
        "id": 411,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1557,
        "temperature": 0,
        "text": " You need to do a merge...",
        "tokens": [
          51464,
          509,
          643,
          281,
          360,
          257,
          22183,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1559,
        "id": 412,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1558,
        "temperature": 0,
        "text": " Oh, all right.",
        "tokens": [
          51514,
          876,
          11,
          439,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1987431159386268,
        "compression_ratio": 1.6962025316455696,
        "end": 1561,
        "id": 413,
        "no_speech_prob": 0.001896846224553883,
        "seek": 153500,
        "start": 1559,
        "temperature": 0,
        "text": " Let's do a video about it right now.",
        "tokens": [
          51564,
          961,
          311,
          360,
          257,
          960,
          466,
          309,
          558,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1564,
        "id": 414,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1561,
        "temperature": 0,
        "text": " This is great.",
        "tokens": [
          50364,
          639,
          307,
          869,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1571,
        "id": 415,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1564,
        "temperature": 0,
        "text": " This is going to now be a tutorial that will go in my GitHub list.",
        "tokens": [
          50514,
          639,
          307,
          516,
          281,
          586,
          312,
          257,
          7073,
          300,
          486,
          352,
          294,
          452,
          23331,
          1329,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1573,
        "id": 416,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1571,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50864,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1574,
        "id": 417,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1573,
        "temperature": 0,
        "text": " We're going to resolve this live.",
        "tokens": [
          50964,
          492,
          434,
          516,
          281,
          14151,
          341,
          1621,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1577,
        "id": 418,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1574,
        "temperature": 0,
        "text": " I have a new sponsor.",
        "tokens": [
          51014,
          286,
          362,
          257,
          777,
          16198,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1579,
        "id": 419,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1577,
        "temperature": 0,
        "text": " You know I've always sponsored by water.",
        "tokens": [
          51164,
          509,
          458,
          286,
          600,
          1009,
          16621,
          538,
          1281,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1580,
        "id": 420,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1579,
        "temperature": 0,
        "text": " But this was...",
        "tokens": [
          51264,
          583,
          341,
          390,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1582,
        "id": 421,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1580,
        "temperature": 0,
        "text": " I don't usually like to destroy the earth.",
        "tokens": [
          51314,
          286,
          500,
          380,
          2673,
          411,
          281,
          5293,
          264,
          4120,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21974839766820273,
        "compression_ratio": 1.555,
        "end": 1585,
        "id": 422,
        "no_speech_prob": 0.001455016783438623,
        "seek": 156100,
        "start": 1582,
        "temperature": 0,
        "text": " I have to stand over here and drink my earth-destroying water.",
        "tokens": [
          51414,
          286,
          362,
          281,
          1463,
          670,
          510,
          293,
          2822,
          452,
          4120,
          12,
          23748,
          340,
          1840,
          1281,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2640239340918405,
        "compression_ratio": 1.3695652173913044,
        "end": 1590,
        "id": 423,
        "no_speech_prob": 0.015187515877187252,
        "seek": 158500,
        "start": 1585,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2640239340918405,
        "compression_ratio": 1.3695652173913044,
        "end": 1599,
        "id": 424,
        "no_speech_prob": 0.015187515877187252,
        "seek": 158500,
        "start": 1590,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50614,
          1057,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2640239340918405,
        "compression_ratio": 1.3695652173913044,
        "end": 1602,
        "id": 425,
        "no_speech_prob": 0.015187515877187252,
        "seek": 158500,
        "start": 1599,
        "temperature": 0,
        "text": " Hello, surprise!",
        "tokens": [
          51064,
          2425,
          11,
          6365,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.2640239340918405,
        "compression_ratio": 1.3695652173913044,
        "end": 1605,
        "id": 426,
        "no_speech_prob": 0.015187515877187252,
        "seek": 158500,
        "start": 1602,
        "temperature": 0,
        "text": " It's a video about Git and GitHub.",
        "tokens": [
          51214,
          467,
          311,
          257,
          960,
          466,
          16939,
          293,
          23331,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2640239340918405,
        "compression_ratio": 1.3695652173913044,
        "end": 1608,
        "id": 427,
        "no_speech_prob": 0.015187515877187252,
        "seek": 158500,
        "start": 1605,
        "temperature": 0,
        "text": " And this video is about resolving merge conflicts.",
        "tokens": [
          51364,
          400,
          341,
          960,
          307,
          466,
          49940,
          22183,
          19807,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2640239340918405,
        "compression_ratio": 1.3695652173913044,
        "end": 1613,
        "id": 428,
        "no_speech_prob": 0.015187515877187252,
        "seek": 158500,
        "start": 1608,
        "temperature": 0,
        "text": " So, I probably should be doing this video in my poem repository,",
        "tokens": [
          51514,
          407,
          11,
          286,
          1391,
          820,
          312,
          884,
          341,
          960,
          294,
          452,
          13065,
          25841,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1617,
        "id": 429,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1613,
        "temperature": 0,
        "text": " which I use for all of my intro to Git and GitHub videos.",
        "tokens": [
          50364,
          597,
          286,
          764,
          337,
          439,
          295,
          452,
          12897,
          281,
          16939,
          293,
          23331,
          2145,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1622,
        "id": 430,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1617,
        "temperature": 0,
        "text": " But I happen to be here streaming live and working on this neural network library",
        "tokens": [
          50564,
          583,
          286,
          1051,
          281,
          312,
          510,
          11791,
          1621,
          293,
          1364,
          322,
          341,
          18161,
          3209,
          6405,
          50814
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1624,
        "id": 431,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1622,
        "temperature": 0,
        "text": " that I've been building in a bunch of other video tutorials.",
        "tokens": [
          50814,
          300,
          286,
          600,
          668,
          2390,
          294,
          257,
          3840,
          295,
          661,
          960,
          17616,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1627,
        "id": 432,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1624,
        "temperature": 0,
        "text": " So, if you just watch those Git and GitHub videos,",
        "tokens": [
          50914,
          407,
          11,
          498,
          291,
          445,
          1159,
          729,
          16939,
          293,
          23331,
          2145,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1631,
        "id": 433,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1627,
        "temperature": 0,
        "text": " all about using a poem to sort of demonstrate how Git and GitHub works,",
        "tokens": [
          51064,
          439,
          466,
          1228,
          257,
          13065,
          281,
          1333,
          295,
          11698,
          577,
          16939,
          293,
          23331,
          1985,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1633,
        "id": 434,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1631,
        "temperature": 0,
        "text": " there will be some aspects of this that are confusing.",
        "tokens": [
          51264,
          456,
          486,
          312,
          512,
          7270,
          295,
          341,
          300,
          366,
          13181,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1635,
        "id": 435,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1633,
        "temperature": 0,
        "text": " But hopefully this will be helpful anyway.",
        "tokens": [
          51364,
          583,
          4696,
          341,
          486,
          312,
          4961,
          4033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1638,
        "id": 436,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1635,
        "temperature": 0,
        "text": " And I can always double back and make another video if this one doesn't work.",
        "tokens": [
          51464,
          400,
          286,
          393,
          1009,
          3834,
          646,
          293,
          652,
          1071,
          960,
          498,
          341,
          472,
          1177,
          380,
          589,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1639,
        "id": 437,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1638,
        "temperature": 0,
        "text": " But let's just try it.",
        "tokens": [
          51614,
          583,
          718,
          311,
          445,
          853,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1766446387931092,
        "compression_ratio": 1.779874213836478,
        "end": 1641,
        "id": 438,
        "no_speech_prob": 0.1732458770275116,
        "seek": 161300,
        "start": 1639,
        "temperature": 0,
        "text": " So, what is a merge conflict, first of all?",
        "tokens": [
          51664,
          407,
          11,
          437,
          307,
          257,
          22183,
          6596,
          11,
          700,
          295,
          439,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.19917382632984834,
        "compression_ratio": 1.567251461988304,
        "end": 1648,
        "id": 439,
        "no_speech_prob": 0.028004847466945648,
        "seek": 164100,
        "start": 1641,
        "temperature": 0,
        "text": " So, a merge conflict is when you have, let's say, this is a file.",
        "tokens": [
          50364,
          407,
          11,
          257,
          22183,
          6596,
          307,
          562,
          291,
          362,
          11,
          718,
          311,
          584,
          11,
          341,
          307,
          257,
          3991,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19917382632984834,
        "compression_ratio": 1.567251461988304,
        "end": 1653,
        "id": 440,
        "no_speech_prob": 0.028004847466945648,
        "seek": 164100,
        "start": 1648,
        "temperature": 0,
        "text": " And in this case, it's my file called matrix.js.",
        "tokens": [
          50714,
          400,
          294,
          341,
          1389,
          11,
          309,
          311,
          452,
          3991,
          1219,
          8141,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19917382632984834,
        "compression_ratio": 1.567251461988304,
        "end": 1658,
        "id": 441,
        "no_speech_prob": 0.028004847466945648,
        "seek": 164100,
        "start": 1653,
        "temperature": 0,
        "text": " So, I have a file called matrix.js, and it has code in it.",
        "tokens": [
          50964,
          407,
          11,
          286,
          362,
          257,
          3991,
          1219,
          8141,
          13,
          25530,
          11,
          293,
          309,
          575,
          3089,
          294,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19917382632984834,
        "compression_ratio": 1.567251461988304,
        "end": 1664,
        "id": 442,
        "no_speech_prob": 0.028004847466945648,
        "seek": 164100,
        "start": 1658,
        "temperature": 0,
        "text": " Now, I had two people, two separate people of the internet,",
        "tokens": [
          51214,
          823,
          11,
          286,
          632,
          732,
          561,
          11,
          732,
          4994,
          561,
          295,
          264,
          4705,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.19917382632984834,
        "compression_ratio": 1.567251461988304,
        "end": 1666,
        "id": 443,
        "no_speech_prob": 0.028004847466945648,
        "seek": 164100,
        "start": 1664,
        "temperature": 0,
        "text": " happen to be working on this file.",
        "tokens": [
          51514,
          1051,
          281,
          312,
          1364,
          322,
          341,
          3991,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14870098149665048,
        "compression_ratio": 1.6275510204081634,
        "end": 1673,
        "id": 444,
        "no_speech_prob": 0.020330680534243584,
        "seek": 166600,
        "start": 1667,
        "temperature": 0,
        "text": " So, we'll call one person A and one person B.",
        "tokens": [
          50414,
          407,
          11,
          321,
          603,
          818,
          472,
          954,
          316,
          293,
          472,
          954,
          363,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14870098149665048,
        "compression_ratio": 1.6275510204081634,
        "end": 1676,
        "id": 445,
        "no_speech_prob": 0.020330680534243584,
        "seek": 166600,
        "start": 1673,
        "temperature": 0,
        "text": " Now, any text file has lines in it.",
        "tokens": [
          50714,
          823,
          11,
          604,
          2487,
          3991,
          575,
          3876,
          294,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14870098149665048,
        "compression_ratio": 1.6275510204081634,
        "end": 1679,
        "id": 446,
        "no_speech_prob": 0.020330680534243584,
        "seek": 166600,
        "start": 1676,
        "temperature": 0,
        "text": " So, even if it were a poem, it would have lines of the poem.",
        "tokens": [
          50864,
          407,
          11,
          754,
          498,
          309,
          645,
          257,
          13065,
          11,
          309,
          576,
          362,
          3876,
          295,
          264,
          13065,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14870098149665048,
        "compression_ratio": 1.6275510204081634,
        "end": 1682,
        "id": 447,
        "no_speech_prob": 0.020330680534243584,
        "seek": 166600,
        "start": 1679,
        "temperature": 0,
        "text": " If it's a source code file, it has lines of the source code.",
        "tokens": [
          51014,
          759,
          309,
          311,
          257,
          4009,
          3089,
          3991,
          11,
          309,
          575,
          3876,
          295,
          264,
          4009,
          3089,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14870098149665048,
        "compression_ratio": 1.6275510204081634,
        "end": 1686,
        "id": 448,
        "no_speech_prob": 0.020330680534243584,
        "seek": 166600,
        "start": 1682,
        "temperature": 0,
        "text": " So, we can think of the lines as like 1, 2, 3, 4, 5, 6.",
        "tokens": [
          51164,
          407,
          11,
          321,
          393,
          519,
          295,
          264,
          3876,
          382,
          411,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14870098149665048,
        "compression_ratio": 1.6275510204081634,
        "end": 1693,
        "id": 449,
        "no_speech_prob": 0.020330680534243584,
        "seek": 166600,
        "start": 1686,
        "temperature": 0,
        "text": " Now, if person A makes a change and submits a pull request,",
        "tokens": [
          51364,
          823,
          11,
          498,
          954,
          316,
          1669,
          257,
          1319,
          293,
          8286,
          1208,
          257,
          2235,
          5308,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.23493000246443838,
        "compression_ratio": 1.8653846153846154,
        "end": 1699,
        "id": 450,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 169300,
        "start": 1694,
        "temperature": 0,
        "text": " meaning, hey, hey, you, the library, please pull my changes, right?",
        "tokens": [
          50414,
          3620,
          11,
          4177,
          11,
          4177,
          11,
          291,
          11,
          264,
          6405,
          11,
          1767,
          2235,
          452,
          2962,
          11,
          558,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.23493000246443838,
        "compression_ratio": 1.8653846153846154,
        "end": 1703,
        "id": 451,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 169300,
        "start": 1699,
        "temperature": 0,
        "text": " I want to push my changes to you, but I'm asking, requesting that you pull my changes.",
        "tokens": [
          50664,
          286,
          528,
          281,
          2944,
          452,
          2962,
          281,
          291,
          11,
          457,
          286,
          478,
          3365,
          11,
          31937,
          300,
          291,
          2235,
          452,
          2962,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23493000246443838,
        "compression_ratio": 1.8653846153846154,
        "end": 1708,
        "id": 452,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 169300,
        "start": 1703,
        "temperature": 0,
        "text": " If this person just made changes to lines 5 and 6,",
        "tokens": [
          50864,
          759,
          341,
          954,
          445,
          1027,
          2962,
          281,
          3876,
          1025,
          293,
          1386,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.23493000246443838,
        "compression_ratio": 1.8653846153846154,
        "end": 1712,
        "id": 453,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 169300,
        "start": 1708,
        "temperature": 0,
        "text": " and this person just made, and this person's doing the same thing,",
        "tokens": [
          51114,
          293,
          341,
          954,
          445,
          1027,
          11,
          293,
          341,
          954,
          311,
          884,
          264,
          912,
          551,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.23493000246443838,
        "compression_ratio": 1.8653846153846154,
        "end": 1716,
        "id": 454,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 169300,
        "start": 1712,
        "temperature": 0,
        "text": " but made changes to lines 2 and 3,",
        "tokens": [
          51314,
          457,
          1027,
          2962,
          281,
          3876,
          568,
          293,
          805,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.23493000246443838,
        "compression_ratio": 1.8653846153846154,
        "end": 1721,
        "id": 455,
        "no_speech_prob": 0.00017130558262579143,
        "seek": 169300,
        "start": 1716,
        "temperature": 0,
        "text": " the git system is smart enough to figure out how to pull both of these things in",
        "tokens": [
          51514,
          264,
          18331,
          1185,
          307,
          4069,
          1547,
          281,
          2573,
          484,
          577,
          281,
          2235,
          1293,
          295,
          613,
          721,
          294,
          51764
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1724,
        "id": 456,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1721,
        "temperature": 0,
        "text": " with no conflicts, because there are no conflicts.",
        "tokens": [
          50364,
          365,
          572,
          19807,
          11,
          570,
          456,
          366,
          572,
          19807,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1727,
        "id": 457,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1724,
        "temperature": 0,
        "text": " If I want to accept changes to lines 2 and 3,",
        "tokens": [
          50514,
          759,
          286,
          528,
          281,
          3241,
          2962,
          281,
          3876,
          568,
          293,
          805,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1731,
        "id": 458,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1727,
        "temperature": 0,
        "text": " I can accept those at the same time, one before the other, simultaneously,",
        "tokens": [
          50664,
          286,
          393,
          3241,
          729,
          412,
          264,
          912,
          565,
          11,
          472,
          949,
          264,
          661,
          11,
          16561,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1734,
        "id": 459,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1731,
        "temperature": 0,
        "text": " you can't really do it simultaneously, as lines 5 and 6.",
        "tokens": [
          50864,
          291,
          393,
          380,
          534,
          360,
          309,
          16561,
          11,
          382,
          3876,
          1025,
          293,
          1386,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1740,
        "id": 460,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1734,
        "temperature": 0,
        "text": " However, if right here, person B makes a change to line 4,",
        "tokens": [
          51014,
          2908,
          11,
          498,
          558,
          510,
          11,
          954,
          363,
          1669,
          257,
          1319,
          281,
          1622,
          1017,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1743,
        "id": 461,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1740,
        "temperature": 0,
        "text": " and person A also makes a change to line 4,",
        "tokens": [
          51314,
          293,
          954,
          316,
          611,
          1669,
          257,
          1319,
          281,
          1622,
          1017,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1746,
        "id": 462,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1743,
        "temperature": 0,
        "text": " then we have what's known as a conflict.",
        "tokens": [
          51464,
          550,
          321,
          362,
          437,
          311,
          2570,
          382,
          257,
          6596,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1708890883648982,
        "compression_ratio": 1.78,
        "end": 1749,
        "id": 463,
        "no_speech_prob": 0.003537864191457629,
        "seek": 172100,
        "start": 1746,
        "temperature": 0,
        "text": " And typically, what will happen, and what just happened to me right now,",
        "tokens": [
          51614,
          400,
          5850,
          11,
          437,
          486,
          1051,
          11,
          293,
          437,
          445,
          2011,
          281,
          385,
          558,
          586,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1751,
        "id": 464,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1749,
        "temperature": 0,
        "text": " is I merged this one.",
        "tokens": [
          50364,
          307,
          286,
          36427,
          341,
          472,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1755,
        "id": 465,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1751,
        "temperature": 0,
        "text": " I merged this one, wasn't thinking about it, it was done, it's finished,",
        "tokens": [
          50464,
          286,
          36427,
          341,
          472,
          11,
          2067,
          380,
          1953,
          466,
          309,
          11,
          309,
          390,
          1096,
          11,
          309,
          311,
          4335,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1758,
        "id": 466,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1755,
        "temperature": 0,
        "text": " and it worked fine, it merged with no problems.",
        "tokens": [
          50664,
          293,
          309,
          2732,
          2489,
          11,
          309,
          36427,
          365,
          572,
          2740,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1761,
        "id": 467,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1758,
        "temperature": 0,
        "text": " But now when I went to merge this one, I got a message saying,",
        "tokens": [
          50814,
          583,
          586,
          562,
          286,
          1437,
          281,
          22183,
          341,
          472,
          11,
          286,
          658,
          257,
          3636,
          1566,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1763,
        "id": 468,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1761,
        "temperature": 0,
        "text": " resolve conflicts.",
        "tokens": [
          50964,
          14151,
          19807,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1767,
        "id": 469,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1763,
        "temperature": 0,
        "text": " Now, there are a variety of ways you can resolve conflicts,",
        "tokens": [
          51064,
          823,
          11,
          456,
          366,
          257,
          5673,
          295,
          2098,
          291,
          393,
          14151,
          19807,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1770,
        "id": 470,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1767,
        "temperature": 0,
        "text": " and I think that I've, in some of my previous tutorials,",
        "tokens": [
          51264,
          293,
          286,
          519,
          300,
          286,
          600,
          11,
          294,
          512,
          295,
          452,
          3894,
          17616,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1773,
        "id": 471,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1770,
        "temperature": 0,
        "text": " looked at working with git command line locally,",
        "tokens": [
          51414,
          2956,
          412,
          1364,
          365,
          18331,
          5622,
          1622,
          16143,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1775,
        "id": 472,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1773,
        "temperature": 0,
        "text": " and I could have the text file there,",
        "tokens": [
          51564,
          293,
          286,
          727,
          362,
          264,
          2487,
          3991,
          456,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21128540317507555,
        "compression_ratio": 1.8014705882352942,
        "end": 1777,
        "id": 473,
        "no_speech_prob": 0.009124117903411388,
        "seek": 174900,
        "start": 1775,
        "temperature": 0,
        "text": " but what I'm going to do is see if I can resolve the conflict",
        "tokens": [
          51664,
          457,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          536,
          498,
          286,
          393,
          14151,
          264,
          6596,
          51764
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1780,
        "id": 474,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1777,
        "temperature": 0,
        "text": " just through the github interface itself.",
        "tokens": [
          50364,
          445,
          807,
          264,
          290,
          355,
          836,
          9226,
          2564,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1782,
        "id": 475,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1780,
        "temperature": 0,
        "text": " So let's take a look at how that works.",
        "tokens": [
          50514,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          577,
          300,
          1985,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1786,
        "id": 476,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1782,
        "temperature": 0,
        "text": " Now, once again, this isn't the best scenario,",
        "tokens": [
          50614,
          823,
          11,
          1564,
          797,
          11,
          341,
          1943,
          380,
          264,
          1151,
          9005,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1788,
        "id": 477,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1786,
        "temperature": 0,
        "text": " and I might come back and do a follow-up,",
        "tokens": [
          50814,
          293,
          286,
          1062,
          808,
          646,
          293,
          360,
          257,
          1524,
          12,
          1010,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1790,
        "id": 478,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1788,
        "temperature": 0,
        "text": " because it would be nice to see a trivial example",
        "tokens": [
          50914,
          570,
          309,
          576,
          312,
          1481,
          281,
          536,
          257,
          26703,
          1365,
          51014
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1792,
        "id": 479,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1790,
        "temperature": 0,
        "text": " where I can really know what the changes are,",
        "tokens": [
          51014,
          689,
          286,
          393,
          534,
          458,
          437,
          264,
          2962,
          366,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1795,
        "id": 480,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1792,
        "temperature": 0,
        "text": " but I'm just going to look and see, there's a whole discussion here,",
        "tokens": [
          51114,
          457,
          286,
          478,
          445,
          516,
          281,
          574,
          293,
          536,
          11,
          456,
          311,
          257,
          1379,
          5017,
          510,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1797,
        "id": 481,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1795,
        "temperature": 0,
        "text": " and we can see these are the files.",
        "tokens": [
          51264,
          293,
          321,
          393,
          536,
          613,
          366,
          264,
          7098,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1799,
        "id": 482,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1797,
        "temperature": 0,
        "text": " These are the files that have conflicts in them.",
        "tokens": [
          51364,
          1981,
          366,
          264,
          7098,
          300,
          362,
          19807,
          294,
          552,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1802,
        "id": 483,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1799,
        "temperature": 0,
        "text": " Matrix.js and Matrix.test.js.",
        "tokens": [
          51464,
          36274,
          13,
          25530,
          293,
          36274,
          13,
          31636,
          13,
          25530,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1804,
        "id": 484,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1802,
        "temperature": 0,
        "text": " So hopefully you can continue to watch this,",
        "tokens": [
          51614,
          407,
          4696,
          291,
          393,
          2354,
          281,
          1159,
          341,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.19275349378585815,
        "compression_ratio": 1.7112462006079028,
        "end": 1806,
        "id": 485,
        "no_speech_prob": 0.10228558629751205,
        "seek": 177700,
        "start": 1804,
        "temperature": 0,
        "text": " even if you don't understand what the code in those files is doing.",
        "tokens": [
          51714,
          754,
          498,
          291,
          500,
          380,
          1223,
          437,
          264,
          3089,
          294,
          729,
          7098,
          307,
          884,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1810,
        "id": 486,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1806,
        "temperature": 0,
        "text": " I'm going to look and see what the conflicts are.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          574,
          293,
          536,
          437,
          264,
          19807,
          366,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1816,
        "id": 487,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1810,
        "temperature": 0,
        "text": " Oh, this is definitely going to go down the internet tubes really quickly.",
        "tokens": [
          50564,
          876,
          11,
          341,
          307,
          2138,
          516,
          281,
          352,
          760,
          264,
          4705,
          21458,
          534,
          2661,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1818,
        "id": 488,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1816,
        "temperature": 0,
        "text": " So I'm going to click this Resolve Conflicts button,",
        "tokens": [
          50864,
          407,
          286,
          478,
          516,
          281,
          2052,
          341,
          5015,
          37361,
          2656,
          3423,
          985,
          82,
          2960,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1820,
        "id": 489,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1818,
        "temperature": 0,
        "text": " and now it's, ooh, look at this.",
        "tokens": [
          50964,
          293,
          586,
          309,
          311,
          11,
          17024,
          11,
          574,
          412,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1822,
        "id": 490,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1820,
        "temperature": 0,
        "text": " Ooh, okay, alright.",
        "tokens": [
          51064,
          7951,
          11,
          1392,
          11,
          5845,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1824,
        "id": 491,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1822,
        "temperature": 0,
        "text": " Oh, I'm in Matrix.js.",
        "tokens": [
          51164,
          876,
          11,
          286,
          478,
          294,
          36274,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1827,
        "id": 492,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1824,
        "temperature": 0,
        "text": " Hmm, okay, I have to figure out what's going on here.",
        "tokens": [
          51264,
          8239,
          11,
          1392,
          11,
          286,
          362,
          281,
          2573,
          484,
          437,
          311,
          516,
          322,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1829,
        "id": 493,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1827,
        "temperature": 0,
        "text": " So we can see, ah, look, this is where the conflict is.",
        "tokens": [
          51414,
          407,
          321,
          393,
          536,
          11,
          3716,
          11,
          574,
          11,
          341,
          307,
          689,
          264,
          6596,
          307,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20161946614583334,
        "compression_ratio": 1.7215189873417722,
        "end": 1832,
        "id": 494,
        "no_speech_prob": 0.0015247276751324534,
        "seek": 180600,
        "start": 1829,
        "temperature": 0,
        "text": " Oh, look, I think I know how to resolve this.",
        "tokens": [
          51514,
          876,
          11,
          574,
          11,
          286,
          519,
          286,
          458,
          577,
          281,
          14151,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1836,
        "id": 495,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1832,
        "temperature": 0,
        "text": " Okay, so this is where the conflict is.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          341,
          307,
          689,
          264,
          6596,
          307,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1838,
        "id": 496,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1836,
        "temperature": 0,
        "text": " Now, what is it telling me here?",
        "tokens": [
          50564,
          823,
          11,
          437,
          307,
          309,
          3585,
          385,
          510,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1842,
        "id": 497,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1838,
        "temperature": 0,
        "text": " Map improvements, master, equals, equals, equals, equals,",
        "tokens": [
          50664,
          22053,
          13797,
          11,
          4505,
          11,
          6915,
          11,
          6915,
          11,
          6915,
          11,
          6915,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1844,
        "id": 498,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1842,
        "temperature": 0,
        "text": " greater than, greater than, greater than, greater than.",
        "tokens": [
          50864,
          5044,
          813,
          11,
          5044,
          813,
          11,
          5044,
          813,
          11,
          5044,
          813,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1847,
        "id": 499,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1844,
        "temperature": 0,
        "text": " So what this is showing me is, this is showing me through",
        "tokens": [
          50964,
          407,
          437,
          341,
          307,
          4099,
          385,
          307,
          11,
          341,
          307,
          4099,
          385,
          807,
          51114
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1849,
        "id": 500,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1847,
        "temperature": 0,
        "text": " kind of like a visual interface of the text file",
        "tokens": [
          51114,
          733,
          295,
          411,
          257,
          5056,
          9226,
          295,
          264,
          2487,
          3991,
          51214
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1854,
        "id": 501,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1849,
        "temperature": 0,
        "text": " that there are two proposed ways that this code could run.",
        "tokens": [
          51214,
          300,
          456,
          366,
          732,
          10348,
          2098,
          300,
          341,
          3089,
          727,
          1190,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1857,
        "id": 502,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1854,
        "temperature": 0,
        "text": " One of the files had it this way, and one of the files had it this way.",
        "tokens": [
          51464,
          1485,
          295,
          264,
          7098,
          632,
          309,
          341,
          636,
          11,
          293,
          472,
          295,
          264,
          7098,
          632,
          309,
          341,
          636,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1859,
        "id": 503,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1857,
        "temperature": 0,
        "text": " In fact, the current master has it this way,",
        "tokens": [
          51614,
          682,
          1186,
          11,
          264,
          2190,
          4505,
          575,
          309,
          341,
          636,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.18803562295847925,
        "compression_ratio": 2.0509803921568626,
        "end": 1861,
        "id": 504,
        "no_speech_prob": 0.025564119219779968,
        "seek": 183200,
        "start": 1859,
        "temperature": 0,
        "text": " but the one that I'm trying to merge has it this way.",
        "tokens": [
          51714,
          457,
          264,
          472,
          300,
          286,
          478,
          1382,
          281,
          22183,
          575,
          309,
          341,
          636,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1863,
        "id": 505,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1861,
        "temperature": 0,
        "text": " And why does this one have it this way?",
        "tokens": [
          50364,
          400,
          983,
          775,
          341,
          472,
          362,
          309,
          341,
          636,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1865,
        "id": 506,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1863,
        "temperature": 0,
        "text": " This is the thing that I changed. I want it this.",
        "tokens": [
          50464,
          639,
          307,
          264,
          551,
          300,
          286,
          3105,
          13,
          286,
          528,
          309,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1866,
        "id": 507,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1865,
        "temperature": 0,
        "text": " So it's up to me.",
        "tokens": [
          50564,
          407,
          309,
          311,
          493,
          281,
          385,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1868,
        "id": 508,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1866,
        "temperature": 0,
        "text": " Now, there's no right or wrong answer here.",
        "tokens": [
          50614,
          823,
          11,
          456,
          311,
          572,
          558,
          420,
          2085,
          1867,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1871,
        "id": 509,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1868,
        "temperature": 0,
        "text": " As the kind of proprietor of this GitHub repository,",
        "tokens": [
          50714,
          1018,
          264,
          733,
          295,
          27881,
          284,
          295,
          341,
          23331,
          25841,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1877,
        "id": 510,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1871,
        "temperature": 0,
        "text": " I've got to decide if both pull requests worked on,",
        "tokens": [
          50864,
          286,
          600,
          658,
          281,
          4536,
          498,
          1293,
          2235,
          12475,
          2732,
          322,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1882,
        "id": 511,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1877,
        "temperature": 0,
        "text": " worked on, sorry, if both pull requests worked on the same line,",
        "tokens": [
          51164,
          2732,
          322,
          11,
          2597,
          11,
          498,
          1293,
          2235,
          12475,
          2732,
          322,
          264,
          912,
          1622,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1883,
        "id": 512,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1882,
        "temperature": 0,
        "text": " I have to pick one.",
        "tokens": [
          51414,
          286,
          362,
          281,
          1888,
          472,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1885,
        "id": 513,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1883,
        "temperature": 0,
        "text": " Which one do I want?",
        "tokens": [
          51464,
          3013,
          472,
          360,
          286,
          528,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19038227200508118,
        "compression_ratio": 1.7049180327868851,
        "end": 1889,
        "id": 514,
        "no_speech_prob": 0.013222196139395237,
        "seek": 186100,
        "start": 1885,
        "temperature": 0,
        "text": " And I want, I'm going to take this one at the bottom.",
        "tokens": [
          51564,
          400,
          286,
          528,
          11,
          286,
          478,
          516,
          281,
          747,
          341,
          472,
          412,
          264,
          2767,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1894,
        "id": 515,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1889,
        "temperature": 0,
        "text": " So I'm going to delete, delete this,",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          12097,
          11,
          12097,
          341,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1898,
        "id": 516,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1894,
        "temperature": 0,
        "text": " and I'm going to delete this.",
        "tokens": [
          50614,
          293,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1900,
        "id": 517,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1898,
        "temperature": 0,
        "text": " Whoops! What did I just do?",
        "tokens": [
          50814,
          45263,
          0,
          708,
          630,
          286,
          445,
          360,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1902,
        "id": 518,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1900,
        "temperature": 0,
        "text": " I'm going to delete this.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1905,
        "id": 519,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1902,
        "temperature": 0,
        "text": " Now, if only I knew how to use a computer.",
        "tokens": [
          51014,
          823,
          11,
          498,
          787,
          286,
          2586,
          577,
          281,
          764,
          257,
          3820,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1907,
        "id": 520,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1905,
        "temperature": 0,
        "text": " I'm going to delete this.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1910,
        "id": 521,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1907,
        "temperature": 0,
        "text": " And now, are there any other conflicts?",
        "tokens": [
          51264,
          400,
          586,
          11,
          366,
          456,
          604,
          661,
          19807,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1912,
        "id": 522,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1910,
        "temperature": 0,
        "text": " Please be, no other conflicts.",
        "tokens": [
          51414,
          2555,
          312,
          11,
          572,
          661,
          19807,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1913,
        "id": 523,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1912,
        "temperature": 0,
        "text": " Oh, I'm so lucky.",
        "tokens": [
          51514,
          876,
          11,
          286,
          478,
          370,
          6356,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20325001963862666,
        "compression_ratio": 1.8275862068965518,
        "end": 1916,
        "id": 524,
        "no_speech_prob": 0.03461625799536705,
        "seek": 188900,
        "start": 1913,
        "temperature": 0,
        "text": " I'm going to now say, mark as resolved.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          586,
          584,
          11,
          1491,
          382,
          20772,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1920,
        "id": 525,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1916,
        "temperature": 0,
        "text": " Now, one thing you can do if you're the proprietor of a GitHub repository",
        "tokens": [
          50364,
          823,
          11,
          472,
          551,
          291,
          393,
          360,
          498,
          291,
          434,
          264,
          27881,
          284,
          295,
          257,
          23331,
          25841,
          50564
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1923,
        "id": 526,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1920,
        "temperature": 0,
        "text": " is you could just write to the person submitting the pull request,",
        "tokens": [
          50564,
          307,
          291,
          727,
          445,
          2464,
          281,
          264,
          954,
          31836,
          264,
          2235,
          5308,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1925,
        "id": 527,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1923,
        "temperature": 0,
        "text": " I'm so sorry, but some conflicts arose.",
        "tokens": [
          50714,
          286,
          478,
          370,
          2597,
          11,
          457,
          512,
          19807,
          37192,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1926,
        "id": 528,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1925,
        "temperature": 0,
        "text": " I love your pull request.",
        "tokens": [
          50814,
          286,
          959,
          428,
          2235,
          5308,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1927,
        "id": 529,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1926,
        "temperature": 0,
        "text": " Do you think you could refactor it?",
        "tokens": [
          50864,
          1144,
          291,
          519,
          291,
          727,
          1895,
          15104,
          309,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1929,
        "id": 530,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1927,
        "temperature": 0,
        "text": " Because you could leave this up to the contributor, certainly.",
        "tokens": [
          50914,
          1436,
          291,
          727,
          1856,
          341,
          493,
          281,
          264,
          42859,
          11,
          3297,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1931,
        "id": 531,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1929,
        "temperature": 0,
        "text": " But I'm here, live on the internet.",
        "tokens": [
          51014,
          583,
          286,
          478,
          510,
          11,
          1621,
          322,
          264,
          4705,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1933,
        "id": 532,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1931,
        "temperature": 0,
        "text": " I mean, maybe I'm not live anymore.",
        "tokens": [
          51114,
          286,
          914,
          11,
          1310,
          286,
          478,
          406,
          1621,
          3602,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1935,
        "id": 533,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1933,
        "temperature": 0,
        "text": " I'm recorded.",
        "tokens": [
          51214,
          286,
          478,
          8287,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1936,
        "id": 534,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1935,
        "temperature": 0,
        "text": " And so there we go.",
        "tokens": [
          51314,
          400,
          370,
          456,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1937,
        "id": 535,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1936,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          51364,
          876,
          11,
          572,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1939,
        "id": 536,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1937,
        "temperature": 0,
        "text": " Okay, ah, so now I have this other file.",
        "tokens": [
          51414,
          1033,
          11,
          3716,
          11,
          370,
          586,
          286,
          362,
          341,
          661,
          3991,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1941,
        "id": 537,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1939,
        "temperature": 0,
        "text": " Let's look at this.",
        "tokens": [
          51514,
          961,
          311,
          574,
          412,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18994236592226807,
        "compression_ratio": 1.6774193548387097,
        "end": 1943,
        "id": 538,
        "no_speech_prob": 0.6000799536705017,
        "seek": 191600,
        "start": 1941,
        "temperature": 0,
        "text": " I might just quit while I'm ahead here,",
        "tokens": [
          51614,
          286,
          1062,
          445,
          10366,
          1339,
          286,
          478,
          2286,
          510,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1946,
        "id": 539,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1943,
        "temperature": 0,
        "text": " but let's see if I can look at this other file.",
        "tokens": [
          50364,
          457,
          718,
          311,
          536,
          498,
          286,
          393,
          574,
          412,
          341,
          661,
          3991,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1949,
        "id": 540,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1946,
        "temperature": 0,
        "text": " So this code might look very strange to you.",
        "tokens": [
          50514,
          407,
          341,
          3089,
          1062,
          574,
          588,
          5861,
          281,
          291,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1951,
        "id": 541,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1949,
        "temperature": 0,
        "text": " This is something called unit testing.",
        "tokens": [
          50664,
          639,
          307,
          746,
          1219,
          4985,
          4997,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1952,
        "id": 542,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1951,
        "temperature": 0,
        "text": " And actually, related to this video series,",
        "tokens": [
          50764,
          400,
          767,
          11,
          4077,
          281,
          341,
          960,
          2638,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1955,
        "id": 543,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1952,
        "temperature": 0,
        "text": " I have a video series that I will link to in this video's description",
        "tokens": [
          50814,
          286,
          362,
          257,
          960,
          2638,
          300,
          286,
          486,
          2113,
          281,
          294,
          341,
          960,
          311,
          3855,
          50964
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1957,
        "id": 544,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1955,
        "temperature": 0,
        "text": " about how you can run automated tests",
        "tokens": [
          50964,
          466,
          577,
          291,
          393,
          1190,
          18473,
          6921,
          51064
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1960,
        "id": 545,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1957,
        "temperature": 0,
        "text": " that make sure a change in your code doesn't actually break your code.",
        "tokens": [
          51064,
          300,
          652,
          988,
          257,
          1319,
          294,
          428,
          3089,
          1177,
          380,
          767,
          1821,
          428,
          3089,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1963,
        "id": 546,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1960,
        "temperature": 0,
        "text": " That's what this is doing here.",
        "tokens": [
          51214,
          663,
          311,
          437,
          341,
          307,
          884,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1965,
        "id": 547,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1963,
        "temperature": 0,
        "text": " So there's map improvements.",
        "tokens": [
          51364,
          407,
          456,
          311,
          4471,
          13797,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1966,
        "id": 548,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1965,
        "temperature": 0,
        "text": " That's the pull request.",
        "tokens": [
          51464,
          663,
          311,
          264,
          2235,
          5308,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1967,
        "id": 549,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1966,
        "temperature": 0,
        "text": " And master.",
        "tokens": [
          51514,
          400,
          4505,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1968,
        "id": 550,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1967,
        "temperature": 0,
        "text": " You know what?",
        "tokens": [
          51564,
          509,
          458,
          437,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1656041009085519,
        "compression_ratio": 1.7630662020905923,
        "end": 1972,
        "id": 551,
        "no_speech_prob": 0.21467068791389465,
        "seek": 194300,
        "start": 1968,
        "temperature": 0,
        "text": " I think this is a very trivial change.",
        "tokens": [
          51614,
          286,
          519,
          341,
          307,
          257,
          588,
          26703,
          1319,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1975,
        "id": 552,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1972,
        "temperature": 0,
        "text": " It looks to me like this was just added at the end,",
        "tokens": [
          50364,
          467,
          1542,
          281,
          385,
          411,
          341,
          390,
          445,
          3869,
          412,
          264,
          917,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1978,
        "id": 553,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1975,
        "temperature": 0,
        "text": " and there was a line break or something that caused a merge conflict.",
        "tokens": [
          50514,
          293,
          456,
          390,
          257,
          1622,
          1821,
          420,
          746,
          300,
          7008,
          257,
          22183,
          6596,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1983,
        "id": 554,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1978,
        "temperature": 0,
        "text": " So this looks like something that I could actually just completely delete here",
        "tokens": [
          50664,
          407,
          341,
          1542,
          411,
          746,
          300,
          286,
          727,
          767,
          445,
          2584,
          12097,
          510,
          50914
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1984,
        "id": 555,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1983,
        "temperature": 0,
        "text": " and then delete here.",
        "tokens": [
          50914,
          293,
          550,
          12097,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1988,
        "id": 556,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1984,
        "temperature": 0,
        "text": " And this is just some new stuff that got added to the end as part of this pull request.",
        "tokens": [
          50964,
          400,
          341,
          307,
          445,
          512,
          777,
          1507,
          300,
          658,
          3869,
          281,
          264,
          917,
          382,
          644,
          295,
          341,
          2235,
          5308,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1990,
        "id": 557,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1988,
        "temperature": 0,
        "text": " There was an extra line break or something,",
        "tokens": [
          51164,
          821,
          390,
          364,
          2857,
          1622,
          1821,
          420,
          746,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 1994,
        "id": 558,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1990,
        "temperature": 0,
        "text": " so GitHub detected a conflict, but it really was not a conflict.",
        "tokens": [
          51264,
          370,
          23331,
          21896,
          257,
          6596,
          11,
          457,
          309,
          534,
          390,
          406,
          257,
          6596,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20566053951487823,
        "compression_ratio": 1.9065040650406504,
        "end": 2000,
        "id": 559,
        "no_speech_prob": 0.0016743489541113377,
        "seek": 197200,
        "start": 1994,
        "temperature": 0,
        "text": " So now I can go and I can click mark as resolved.",
        "tokens": [
          51464,
          407,
          586,
          286,
          393,
          352,
          293,
          286,
          393,
          2052,
          1491,
          382,
          20772,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2001,
        "id": 560,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2000,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          50364,
          400,
          574,
          412,
          341,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2002,
        "id": 561,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2001,
        "temperature": 0,
        "text": " Commit merge.",
        "tokens": [
          50414,
          3046,
          270,
          22183,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2004,
        "id": 562,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2002,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50464,
          407,
          510,
          311,
          264,
          551,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2005,
        "id": 563,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2004,
        "temperature": 0,
        "text": " Where am I right now?",
        "tokens": [
          50564,
          2305,
          669,
          286,
          558,
          586,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2008,
        "id": 564,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2005,
        "temperature": 0,
        "text": " So I resolved all the conflicts.",
        "tokens": [
          50614,
          407,
          286,
          20772,
          439,
          264,
          19807,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2010,
        "id": 565,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2008,
        "temperature": 0,
        "text": " Do I want to do this?",
        "tokens": [
          50764,
          1144,
          286,
          528,
          281,
          360,
          341,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2019,
        "id": 566,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2010,
        "temperature": 0,
        "text": " I think this button, if I'm right, is not actually",
        "tokens": [
          50864,
          286,
          519,
          341,
          2960,
          11,
          498,
          286,
          478,
          558,
          11,
          307,
          406,
          767,
          51314
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2023,
        "id": 567,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2019,
        "temperature": 0,
        "text": " I'm looking at the chat to see if anybody's complaining about what I've done.",
        "tokens": [
          51314,
          286,
          478,
          1237,
          412,
          264,
          5081,
          281,
          536,
          498,
          4472,
          311,
          20740,
          466,
          437,
          286,
          600,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16800532090036494,
        "compression_ratio": 1.5408163265306123,
        "end": 2025,
        "id": 568,
        "no_speech_prob": 0.008061760105192661,
        "seek": 200000,
        "start": 2023,
        "temperature": 0,
        "text": " It's not actually merging the pull request.",
        "tokens": [
          51514,
          467,
          311,
          406,
          767,
          44559,
          264,
          2235,
          5308,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2030,
        "id": 569,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2025,
        "temperature": 0,
        "text": " I think this is the committing the resolution of the conflicts to the pull request.",
        "tokens": [
          50364,
          286,
          519,
          341,
          307,
          264,
          26659,
          264,
          8669,
          295,
          264,
          19807,
          281,
          264,
          2235,
          5308,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2031,
        "id": 570,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2030,
        "temperature": 0,
        "text": " Let's find out.",
        "tokens": [
          50614,
          961,
          311,
          915,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2033,
        "id": 571,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2031,
        "temperature": 0,
        "text": " It's a green button.",
        "tokens": [
          50664,
          467,
          311,
          257,
          3092,
          2960,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2035,
        "id": 572,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2033,
        "temperature": 0,
        "text": " When I see a green button, it just makes me want to click it.",
        "tokens": [
          50764,
          1133,
          286,
          536,
          257,
          3092,
          2960,
          11,
          309,
          445,
          1669,
          385,
          528,
          281,
          2052,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2038,
        "id": 573,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2035,
        "temperature": 0,
        "text": " Click.",
        "tokens": [
          50864,
          8230,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2041,
        "id": 574,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2038,
        "temperature": 0,
        "text": " So I think the pull request is still going to be live and active.",
        "tokens": [
          51014,
          407,
          286,
          519,
          264,
          2235,
          5308,
          307,
          920,
          516,
          281,
          312,
          1621,
          293,
          4967,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2042,
        "id": 575,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2041,
        "temperature": 0,
        "text": " Boy, it's taking a while.",
        "tokens": [
          51164,
          9486,
          11,
          309,
          311,
          1940,
          257,
          1339,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2043,
        "id": 576,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2042,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51214,
          1079,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2047,
        "id": 577,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2043,
        "temperature": 0,
        "text": " All it did was fix the conflicts.",
        "tokens": [
          51264,
          1057,
          309,
          630,
          390,
          3191,
          264,
          19807,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2050,
        "id": 578,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2047,
        "temperature": 0,
        "text": " Where can I find that that was done here?",
        "tokens": [
          51464,
          2305,
          393,
          286,
          915,
          300,
          300,
          390,
          1096,
          510,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2052,
        "id": 579,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2050,
        "temperature": 0,
        "text": " Yes, that was this.",
        "tokens": [
          51614,
          1079,
          11,
          300,
          390,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1557796630859375,
        "compression_ratio": 1.7186147186147187,
        "end": 2053,
        "id": 580,
        "no_speech_prob": 0.08631756156682968,
        "seek": 202500,
        "start": 2052,
        "temperature": 0,
        "text": " So this is me.",
        "tokens": [
          51714,
          407,
          341,
          307,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2058,
        "id": 581,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2053,
        "temperature": 0,
        "text": " Now there's a little note that I merged branch master into map improvements.",
        "tokens": [
          50364,
          823,
          456,
          311,
          257,
          707,
          3637,
          300,
          286,
          36427,
          9819,
          4505,
          666,
          4471,
          13797,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2062,
        "id": 582,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2058,
        "temperature": 0,
        "text": " That's basically saying there were conflicts between master and map improvements.",
        "tokens": [
          50614,
          663,
          311,
          1936,
          1566,
          456,
          645,
          19807,
          1296,
          4505,
          293,
          4471,
          13797,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2064,
        "id": 583,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2062,
        "temperature": 0,
        "text": " This pull request was map improvements.",
        "tokens": [
          50814,
          639,
          2235,
          5308,
          390,
          4471,
          13797,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2067,
        "id": 584,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2064,
        "temperature": 0,
        "text": " And there was me merging them together and resolving the conflicts.",
        "tokens": [
          50914,
          400,
          456,
          390,
          385,
          44559,
          552,
          1214,
          293,
          49940,
          264,
          19807,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2070,
        "id": 585,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2067,
        "temperature": 0,
        "text": " And now I can actually go ahead.",
        "tokens": [
          51064,
          400,
          586,
          286,
          393,
          767,
          352,
          2286,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2079,
        "id": 586,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2070,
        "temperature": 0,
        "text": " The conflicts are resolved, and I can merge the pull request.",
        "tokens": [
          51214,
          440,
          19807,
          366,
          20772,
          11,
          293,
          286,
          393,
          22183,
          264,
          2235,
          5308,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2080,
        "id": 587,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2079,
        "temperature": 0,
        "text": " Nothing exciting is going to happen.",
        "tokens": [
          51664,
          6693,
          4670,
          307,
          516,
          281,
          1051,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19970622505109334,
        "compression_ratio": 1.8407079646017699,
        "end": 2081,
        "id": 588,
        "no_speech_prob": 0.2309042513370514,
        "seek": 205300,
        "start": 2080,
        "temperature": 0,
        "text": " It really should.",
        "tokens": [
          51714,
          467,
          534,
          820,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2083,
        "id": 589,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2081,
        "temperature": 0,
        "text": " Confetti should explode.",
        "tokens": [
          50364,
          11701,
          12495,
          820,
          21411,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2085,
        "id": 590,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2083,
        "temperature": 0,
        "text": " Confirm.",
        "tokens": [
          50464,
          11701,
          3692,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2087,
        "id": 591,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2085,
        "temperature": 0,
        "text": " But I can make something happen.",
        "tokens": [
          50564,
          583,
          286,
          393,
          652,
          746,
          1051,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2090,
        "id": 592,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2087,
        "temperature": 0,
        "text": " Yay.",
        "tokens": [
          50664,
          13268,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2091,
        "id": 593,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2090,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2095,
        "id": 594,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2091,
        "temperature": 0,
        "text": " So that was a video about resolving merge conflicts through the GitHub interface,",
        "tokens": [
          50864,
          407,
          300,
          390,
          257,
          960,
          466,
          49940,
          22183,
          19807,
          807,
          264,
          23331,
          9226,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2097,
        "id": 595,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2095,
        "temperature": 0,
        "text": " the sort of basic gist of it.",
        "tokens": [
          51064,
          264,
          1333,
          295,
          3875,
          290,
          468,
          295,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2102,
        "id": 596,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2097,
        "temperature": 0,
        "text": " Perhaps I missed something important, and I will certainly make a follow-up video.",
        "tokens": [
          51164,
          10517,
          286,
          6721,
          746,
          1021,
          11,
          293,
          286,
          486,
          3297,
          652,
          257,
          1524,
          12,
          1010,
          960,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.216236034192537,
        "compression_ratio": 1.491304347826087,
        "end": 2105,
        "id": 597,
        "no_speech_prob": 0.33454811573028564,
        "seek": 208100,
        "start": 2102,
        "temperature": 0,
        "text": " So let me know what I missed, what questions you have in the comments.",
        "tokens": [
          51414,
          407,
          718,
          385,
          458,
          437,
          286,
          6721,
          11,
          437,
          1651,
          291,
          362,
          294,
          264,
          3053,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2110,
        "id": 598,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2106,
        "temperature": 0,
        "text": " And thanks for watching this video about merging or resolving conflicts,",
        "tokens": [
          50414,
          400,
          3231,
          337,
          1976,
          341,
          960,
          466,
          44559,
          220,
          284,
          49940,
          19807,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2113,
        "id": 599,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2110,
        "temperature": 0,
        "text": " merging them with a pull request, something, something, GitHub.",
        "tokens": [
          50614,
          44559,
          552,
          365,
          257,
          2235,
          5308,
          11,
          746,
          11,
          746,
          11,
          23331,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2115,
        "id": 600,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2113,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50764,
          286,
          500,
          380,
          458,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2117,
        "id": 601,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2115,
        "temperature": 0,
        "text": " Search engine optimized keywords.",
        "tokens": [
          50864,
          17180,
          2848,
          26941,
          21009,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2118,
        "id": 602,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2117,
        "temperature": 0,
        "text": " Throw them in there.",
        "tokens": [
          50964,
          22228,
          552,
          294,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2124,
        "id": 603,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2118,
        "temperature": 0,
        "text": " Okay. Bye-bye.",
        "tokens": [
          51014,
          1033,
          13,
          4621,
          12,
          6650,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2127,
        "id": 604,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2124,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2908969309138156,
        "compression_ratio": 1.4511627906976745,
        "end": 2132,
        "id": 605,
        "no_speech_prob": 0.37380146980285645,
        "seek": 210500,
        "start": 2127,
        "temperature": 0,
        "text": " What's wrong with the – is the mic – is the mic performing poorly right now?",
        "tokens": [
          51464,
          708,
          311,
          2085,
          365,
          264,
          220,
          5815,
          307,
          264,
          3123,
          1662,
          307,
          264,
          3123,
          10205,
          22271,
          558,
          586,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.15393924713134766,
        "compression_ratio": 1.2333333333333334,
        "end": 2137,
        "id": 606,
        "no_speech_prob": 0.027555208653211594,
        "seek": 213200,
        "start": 2132,
        "temperature": 0,
        "text": " Am I having sound issues?",
        "tokens": [
          50364,
          2012,
          286,
          1419,
          1626,
          2663,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.15393924713134766,
        "compression_ratio": 1.2333333333333334,
        "end": 2148,
        "id": 607,
        "no_speech_prob": 0.027555208653211594,
        "seek": 213200,
        "start": 2137,
        "temperature": 0,
        "text": " Because if it is, I would like to fix those.",
        "tokens": [
          50614,
          1436,
          498,
          309,
          307,
          11,
          286,
          576,
          411,
          281,
          3191,
          729,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15393924713134766,
        "compression_ratio": 1.2333333333333334,
        "end": 2149,
        "id": 608,
        "no_speech_prob": 0.027555208653211594,
        "seek": 213200,
        "start": 2148,
        "temperature": 0,
        "text": " No sound issues.",
        "tokens": [
          51164,
          883,
          1626,
          2663,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15393924713134766,
        "compression_ratio": 1.2333333333333334,
        "end": 2151,
        "id": 609,
        "no_speech_prob": 0.027555208653211594,
        "seek": 213200,
        "start": 2149,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          51214,
          1033,
          11,
          869,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15393924713134766,
        "compression_ratio": 1.2333333333333334,
        "end": 2152,
        "id": 610,
        "no_speech_prob": 0.027555208653211594,
        "seek": 213200,
        "start": 2151,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15393924713134766,
        "compression_ratio": 1.2333333333333334,
        "end": 2160,
        "id": 611,
        "no_speech_prob": 0.027555208653211594,
        "seek": 213200,
        "start": 2152,
        "temperature": 0,
        "text": " So now that we did that, where am I?",
        "tokens": [
          51364,
          407,
          586,
          300,
          321,
          630,
          300,
          11,
          689,
          669,
          286,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2163,
        "id": 612,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2161,
        "temperature": 0,
        "text": " Add neural network.",
        "tokens": [
          50414,
          5349,
          18161,
          3209,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2168,
        "id": 613,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2163,
        "temperature": 0,
        "text": " Oh, look, I love how live while I'm streaming new pull requests are being opened.",
        "tokens": [
          50514,
          876,
          11,
          574,
          11,
          286,
          959,
          577,
          1621,
          1339,
          286,
          478,
          11791,
          777,
          2235,
          12475,
          366,
          885,
          5625,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2170,
        "id": 614,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2168,
        "temperature": 0,
        "text": " Thank you, Adam Morris, for that.",
        "tokens": [
          50764,
          1044,
          291,
          11,
          7938,
          23619,
          11,
          337,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2171,
        "id": 615,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2170,
        "temperature": 0,
        "text": " That's fantastic.",
        "tokens": [
          50864,
          663,
          311,
          5456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2172,
        "id": 616,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2171,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2175,
        "id": 617,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2172,
        "temperature": 0,
        "text": " Add a neural network learning rate setter.",
        "tokens": [
          50964,
          5349,
          257,
          18161,
          3209,
          2539,
          3314,
          992,
          391,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2178,
        "id": 618,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2175,
        "temperature": 0,
        "text": " Thank you to Arsanguinetti.",
        "tokens": [
          51114,
          1044,
          291,
          281,
          1587,
          82,
          656,
          9445,
          12495,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2181,
        "id": 619,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2178,
        "temperature": 0,
        "text": " You know, I really just need to work on pronouncing people's names.",
        "tokens": [
          51264,
          509,
          458,
          11,
          286,
          534,
          445,
          643,
          281,
          589,
          322,
          14144,
          2175,
          561,
          311,
          5288,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2184,
        "id": 620,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2181,
        "temperature": 0,
        "text": " Let's look at this.",
        "tokens": [
          51414,
          961,
          311,
          574,
          412,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2185,
        "id": 621,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2184,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19299395879109701,
        "compression_ratio": 1.509090909090909,
        "end": 2186,
        "id": 622,
        "no_speech_prob": 0.1422204077243805,
        "seek": 216000,
        "start": 2185,
        "temperature": 0,
        "text": " Oh, oh.",
        "tokens": [
          51614,
          876,
          11,
          1954,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2192,
        "id": 623,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2186,
        "temperature": 0,
        "text": " So is this actually, dare I say, using – oh, so this adds a setter.",
        "tokens": [
          50364,
          407,
          307,
          341,
          767,
          11,
          8955,
          286,
          584,
          11,
          1228,
          1662,
          1954,
          11,
          370,
          341,
          10860,
          257,
          992,
          391,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2194,
        "id": 624,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2192,
        "temperature": 0,
        "text": " I probably do want – oh, no, a setter.",
        "tokens": [
          50664,
          286,
          1391,
          360,
          528,
          1662,
          1954,
          11,
          572,
          11,
          257,
          992,
          391,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2195,
        "id": 625,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2194,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50764,
          865,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2201,
        "id": 626,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2195,
        "temperature": 0,
        "text": " So this – is this actually using this thing that I don't really know about,",
        "tokens": [
          50814,
          407,
          341,
          1662,
          307,
          341,
          767,
          1228,
          341,
          551,
          300,
          286,
          500,
          380,
          534,
          458,
          466,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2203,
        "id": 627,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2201,
        "temperature": 0,
        "text": " which is ES6 getters and setters?",
        "tokens": [
          51114,
          597,
          307,
          12564,
          21,
          483,
          1559,
          293,
          992,
          1559,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2208,
        "id": 628,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2203,
        "temperature": 0,
        "text": " Do I have a Rainbow Topics issue keeping track of that?",
        "tokens": [
          51214,
          1144,
          286,
          362,
          257,
          29477,
          8840,
          1167,
          2734,
          5145,
          2837,
          295,
          300,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2211,
        "id": 629,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2208,
        "temperature": 0,
        "text": " I kind of want to talk about that at some point soon.",
        "tokens": [
          51464,
          286,
          733,
          295,
          528,
          281,
          751,
          466,
          300,
          412,
          512,
          935,
          2321,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2213,
        "id": 630,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2211,
        "temperature": 0,
        "text": " Where is my – hold on.",
        "tokens": [
          51614,
          2305,
          307,
          452,
          1662,
          1797,
          322,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17077564989399707,
        "compression_ratio": 1.5879828326180256,
        "end": 2215,
        "id": 631,
        "no_speech_prob": 0.43777334690093994,
        "seek": 218600,
        "start": 2213,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51714,
          4919,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2222,
        "id": 632,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2215,
        "temperature": 0.4,
        "text": " I dripped some water on the track pad.",
        "tokens": [
          50364,
          286,
          1630,
          3320,
          512,
          1281,
          322,
          264,
          2837,
          6887,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2225,
        "id": 633,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2222,
        "temperature": 0.4,
        "text": " Then I pressed some buttons by accident.",
        "tokens": [
          50714,
          1396,
          286,
          17355,
          512,
          9905,
          538,
          6398,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2229,
        "id": 634,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2225,
        "temperature": 0.4,
        "text": " Rainbow Topics, where is that?",
        "tokens": [
          50864,
          29477,
          8840,
          1167,
          11,
          689,
          307,
          300,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2236,
        "id": 635,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2229,
        "temperature": 0.4,
        "text": " So ES6.",
        "tokens": [
          51064,
          407,
          12564,
          21,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2239,
        "id": 636,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2236,
        "temperature": 0.4,
        "text": " Prototype, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah.",
        "tokens": [
          51414,
          10019,
          13108,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2242,
        "id": 637,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2239,
        "temperature": 0.4,
        "text": " Getter.",
        "tokens": [
          51564,
          3240,
          391,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3400719874613994,
        "compression_ratio": 1.5615384615384615,
        "end": 2243,
        "id": 638,
        "no_speech_prob": 0.14221297204494476,
        "seek": 221500,
        "start": 2242,
        "temperature": 0.4,
        "text": " Nope.",
        "tokens": [
          51714,
          12172,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2249,
        "id": 639,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2243,
        "temperature": 0,
        "text": " So we need to do ES6 getters and setters.",
        "tokens": [
          50364,
          407,
          321,
          643,
          281,
          360,
          12564,
          21,
          483,
          1559,
          293,
          992,
          1559,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2256,
        "id": 640,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2249,
        "temperature": 0,
        "text": " I need to do a video on that at some point.",
        "tokens": [
          50664,
          286,
          643,
          281,
          360,
          257,
          960,
          322,
          300,
          412,
          512,
          935,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2257,
        "id": 641,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2256,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2260,
        "id": 642,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2257,
        "temperature": 0,
        "text": " So now we're back here.",
        "tokens": [
          51064,
          407,
          586,
          321,
          434,
          646,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2263,
        "id": 643,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2260,
        "temperature": 0,
        "text": " So I think this looks good to me.",
        "tokens": [
          51214,
          407,
          286,
          519,
          341,
          1542,
          665,
          281,
          385,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2267,
        "id": 644,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2263,
        "temperature": 0,
        "text": " There's some – so this can happen a lot, which is unfortunate.",
        "tokens": [
          51364,
          821,
          311,
          512,
          1662,
          370,
          341,
          393,
          1051,
          257,
          688,
          11,
          597,
          307,
          17843,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16070910250202994,
        "compression_ratio": 1.4545454545454546,
        "end": 2271,
        "id": 645,
        "no_speech_prob": 0.0027149501256644726,
        "seek": 224300,
        "start": 2267,
        "temperature": 0,
        "text": " It looks like in this pull request some extra white space was added here,",
        "tokens": [
          51564,
          467,
          1542,
          411,
          294,
          341,
          2235,
          5308,
          512,
          2857,
          2418,
          1901,
          390,
          3869,
          510,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2276,
        "id": 646,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2271,
        "temperature": 0,
        "text": " like either a tab or some spaces, which made Git think that these two lines are different.",
        "tokens": [
          50364,
          411,
          2139,
          257,
          4421,
          420,
          512,
          7673,
          11,
          597,
          1027,
          16939,
          519,
          300,
          613,
          732,
          3876,
          366,
          819,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2280,
        "id": 647,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2276,
        "temperature": 0,
        "text": " This is a little bit of noise that if I were a real stickler,",
        "tokens": [
          50614,
          639,
          307,
          257,
          707,
          857,
          295,
          5658,
          300,
          498,
          286,
          645,
          257,
          957,
          2897,
          1918,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2282,
        "id": 648,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2280,
        "temperature": 0,
        "text": " I would kind of want to not be in here.",
        "tokens": [
          50814,
          286,
          576,
          733,
          295,
          528,
          281,
          406,
          312,
          294,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2288,
        "id": 649,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2282,
        "temperature": 0,
        "text": " But I'm not a stickler, as you can tell from me just merging stuff.",
        "tokens": [
          50914,
          583,
          286,
          478,
          406,
          257,
          2897,
          1918,
          11,
          382,
          291,
          393,
          980,
          490,
          385,
          445,
          44559,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2293,
        "id": 650,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2288,
        "temperature": 0,
        "text": " And so now I'm going to say I'm going to update the branch.",
        "tokens": [
          51214,
          400,
          370,
          586,
          286,
          478,
          516,
          281,
          584,
          286,
          478,
          516,
          281,
          5623,
          264,
          9819,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2296,
        "id": 651,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2293,
        "temperature": 0,
        "text": " I'm going to write thank you.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          2464,
          1309,
          291,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1659634851776393,
        "compression_ratio": 1.6538461538461537,
        "end": 2298,
        "id": 652,
        "no_speech_prob": 0.01098672579973936,
        "seek": 227100,
        "start": 2296,
        "temperature": 0,
        "text": " It's going to be running its checks.",
        "tokens": [
          51614,
          467,
          311,
          516,
          281,
          312,
          2614,
          1080,
          13834,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2306,
        "id": 653,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2298,
        "temperature": 0,
        "text": " Let's watch the checks run.",
        "tokens": [
          50364,
          961,
          311,
          1159,
          264,
          13834,
          1190,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2309,
        "id": 654,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2306,
        "temperature": 0,
        "text": " It's running NPM install right now.",
        "tokens": [
          50764,
          467,
          311,
          2614,
          426,
          18819,
          3625,
          558,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2314,
        "id": 655,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2309,
        "temperature": 0,
        "text": " And now it's running the tests.",
        "tokens": [
          50914,
          400,
          586,
          309,
          311,
          2614,
          264,
          6921,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2315,
        "id": 656,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2314,
        "temperature": 0,
        "text": " Perfect timing.",
        "tokens": [
          51164,
          10246,
          10822,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2320,
        "id": 657,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2315,
        "temperature": 0,
        "text": " Wow, half an hour has passed.",
        "tokens": [
          51214,
          3153,
          11,
          1922,
          364,
          1773,
          575,
          4678,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2321,
        "id": 658,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2320,
        "temperature": 0,
        "text": " 3.15, boy.",
        "tokens": [
          51464,
          805,
          13,
          5211,
          11,
          3237,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2324,
        "id": 659,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2321,
        "temperature": 0,
        "text": " I take way longer to do anything than I think.",
        "tokens": [
          51514,
          286,
          747,
          636,
          2854,
          281,
          360,
          1340,
          813,
          286,
          519,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.191361665725708,
        "compression_ratio": 1.3398692810457515,
        "end": 2325,
        "id": 660,
        "no_speech_prob": 0.000925378524698317,
        "seek": 229800,
        "start": 2324,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2191382598876953,
        "compression_ratio": 1.144,
        "end": 2329,
        "id": 661,
        "no_speech_prob": 0.017441896721720695,
        "seek": 232500,
        "start": 2325,
        "temperature": 0,
        "text": " So now I think I've finished.",
        "tokens": [
          50364,
          407,
          586,
          286,
          519,
          286,
          600,
          4335,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2191382598876953,
        "compression_ratio": 1.144,
        "end": 2336,
        "id": 662,
        "no_speech_prob": 0.017441896721720695,
        "seek": 232500,
        "start": 2329,
        "temperature": 0,
        "text": " Yep, merge.",
        "tokens": [
          50564,
          7010,
          11,
          22183,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2191382598876953,
        "compression_ratio": 1.144,
        "end": 2339,
        "id": 663,
        "no_speech_prob": 0.017441896721720695,
        "seek": 232500,
        "start": 2336,
        "temperature": 0,
        "text": " Okay, that has been merged.",
        "tokens": [
          50914,
          1033,
          11,
          300,
          575,
          668,
          36427,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2191382598876953,
        "compression_ratio": 1.144,
        "end": 2343,
        "id": 664,
        "no_speech_prob": 0.017441896721720695,
        "seek": 232500,
        "start": 2339,
        "temperature": 0,
        "text": " Back to the pull requests.",
        "tokens": [
          51064,
          5833,
          281,
          264,
          2235,
          12475,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2191382598876953,
        "compression_ratio": 1.144,
        "end": 2352,
        "id": 665,
        "no_speech_prob": 0.017441896721720695,
        "seek": 232500,
        "start": 2343,
        "temperature": 0,
        "text": " Update readme link to – okay, let's do this.",
        "tokens": [
          51264,
          28923,
          1401,
          1398,
          2113,
          281,
          1662,
          1392,
          11,
          718,
          311,
          360,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2355,
        "id": 666,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2352,
        "temperature": 0,
        "text": " I think this is exactly what I think.",
        "tokens": [
          50364,
          286,
          519,
          341,
          307,
          2293,
          437,
          286,
          519,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2356,
        "id": 667,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2355,
        "temperature": 0,
        "text": " Oh, yeah, perfect.",
        "tokens": [
          50514,
          876,
          11,
          1338,
          11,
          2176,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2357,
        "id": 668,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2356,
        "temperature": 0,
        "text": " So this is great.",
        "tokens": [
          50564,
          407,
          341,
          307,
          869,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2365,
        "id": 669,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2357,
        "temperature": 0,
        "text": " This is a nice link to – this is a nice link that if anyone is looking for the original source code with the video,",
        "tokens": [
          50614,
          639,
          307,
          257,
          1481,
          2113,
          281,
          1662,
          341,
          307,
          257,
          1481,
          2113,
          300,
          498,
          2878,
          307,
          1237,
          337,
          264,
          3380,
          4009,
          3089,
          365,
          264,
          960,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2366,
        "id": 670,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2365,
        "temperature": 0,
        "text": " they can find it.",
        "tokens": [
          51014,
          436,
          393,
          915,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2368,
        "id": 671,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2366,
        "temperature": 0,
        "text": " And by the way, if anybody else wants to do this pull request,",
        "tokens": [
          51064,
          400,
          538,
          264,
          636,
          11,
          498,
          4472,
          1646,
          2738,
          281,
          360,
          341,
          2235,
          5308,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2373,
        "id": 672,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2368,
        "temperature": 0,
        "text": " if you can go to this repo and add a link from here back to here, that would be awesome.",
        "tokens": [
          51164,
          498,
          291,
          393,
          352,
          281,
          341,
          49040,
          293,
          909,
          257,
          2113,
          490,
          510,
          646,
          281,
          510,
          11,
          300,
          576,
          312,
          3476,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2375,
        "id": 673,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2373,
        "temperature": 0,
        "text": " It might already be there.",
        "tokens": [
          51414,
          467,
          1062,
          1217,
          312,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18262465926241284,
        "compression_ratio": 1.6428571428571428,
        "end": 2379,
        "id": 674,
        "no_speech_prob": 0.17104537785053253,
        "seek": 235200,
        "start": 2375,
        "temperature": 0,
        "text": " So let's merge this one.",
        "tokens": [
          51514,
          407,
          718,
          311,
          22183,
          341,
          472,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2385,
        "id": 675,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2379,
        "temperature": 0,
        "text": " Tests are still running.",
        "tokens": [
          50364,
          314,
          4409,
          366,
          920,
          2614,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2389,
        "id": 676,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2385,
        "temperature": 0,
        "text": " Looks like it's finished now.",
        "tokens": [
          50664,
          10027,
          411,
          309,
          311,
          4335,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2391,
        "id": 677,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2389,
        "temperature": 0,
        "text": " Merge pull requests.",
        "tokens": [
          50864,
          6124,
          432,
          2235,
          12475,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2392,
        "id": 678,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2391,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50964,
          821,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2397,
        "id": 679,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2392,
        "temperature": 0,
        "text": " Oh, I didn't – okay, we'll merge the pull requests.",
        "tokens": [
          51014,
          876,
          11,
          286,
          994,
          380,
          1662,
          1392,
          11,
          321,
          603,
          22183,
          264,
          2235,
          12475,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2399,
        "id": 680,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2397,
        "temperature": 0,
        "text": " One more to go now.",
        "tokens": [
          51264,
          1485,
          544,
          281,
          352,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2401,
        "id": 681,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2399,
        "temperature": 0,
        "text": " Create a to-do list.",
        "tokens": [
          51364,
          20248,
          257,
          281,
          12,
          2595,
          1329,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2403,
        "id": 682,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2401,
        "temperature": 0,
        "text": " Oh, out of date.",
        "tokens": [
          51464,
          876,
          11,
          484,
          295,
          4002,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2405,
        "id": 683,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2403,
        "temperature": 0,
        "text": " Let's update it and let's take a look at it.",
        "tokens": [
          51564,
          961,
          311,
          5623,
          309,
          293,
          718,
          311,
          747,
          257,
          574,
          412,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16122454981650075,
        "compression_ratio": 1.4342857142857144,
        "end": 2408,
        "id": 684,
        "no_speech_prob": 0.014956303872168064,
        "seek": 237900,
        "start": 2405,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2410,
        "id": 685,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2408,
        "temperature": 0,
        "text": " We use semver for versioning.",
        "tokens": [
          50364,
          492,
          764,
          4361,
          331,
          337,
          3037,
          278,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2412,
        "id": 686,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2410,
        "temperature": 0,
        "text": " We do?",
        "tokens": [
          50464,
          492,
          360,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2414,
        "id": 687,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2412,
        "temperature": 0,
        "text": " I never even heard of that.",
        "tokens": [
          50564,
          286,
          1128,
          754,
          2198,
          295,
          300,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2416,
        "id": 688,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2414,
        "temperature": 0,
        "text": " That's something I have to learn about.",
        "tokens": [
          50664,
          663,
          311,
          746,
          286,
          362,
          281,
          1466,
          466,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2417,
        "id": 689,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2416,
        "temperature": 0,
        "text": " Semver for versioning.",
        "tokens": [
          50764,
          14421,
          331,
          337,
          3037,
          278,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2421,
        "id": 690,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2417,
        "temperature": 0,
        "text": " So this is like some noise, some line break noise that got added in here by accident.",
        "tokens": [
          50814,
          407,
          341,
          307,
          411,
          512,
          5658,
          11,
          512,
          1622,
          1821,
          5658,
          300,
          658,
          3869,
          294,
          510,
          538,
          6398,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2424,
        "id": 691,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2421,
        "temperature": 0,
        "text": " This is now the to-do list.",
        "tokens": [
          51014,
          639,
          307,
          586,
          264,
          281,
          12,
          2595,
          1329,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2428,
        "id": 692,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2424,
        "temperature": 0,
        "text": " And they got removed from here, which is great.",
        "tokens": [
          51164,
          400,
          436,
          658,
          7261,
          490,
          510,
          11,
          597,
          307,
          869,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2431,
        "id": 693,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2428,
        "temperature": 0,
        "text": " I will say that most of this to-do list is done.",
        "tokens": [
          51364,
          286,
          486,
          584,
          300,
          881,
          295,
          341,
          281,
          12,
          2595,
          1329,
          307,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17705212082973745,
        "compression_ratio": 1.6370656370656371,
        "end": 2437,
        "id": 694,
        "no_speech_prob": 0.16234347224235535,
        "seek": 240800,
        "start": 2431,
        "temperature": 0,
        "text": " So probably what I would do – but I'm just going to – I'll do this change myself.",
        "tokens": [
          51514,
          407,
          1391,
          437,
          286,
          576,
          360,
          1662,
          457,
          286,
          478,
          445,
          516,
          281,
          1662,
          286,
          603,
          360,
          341,
          1319,
          2059,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1747288146576324,
        "compression_ratio": 1.4842767295597483,
        "end": 2439,
        "id": 695,
        "no_speech_prob": 0.00970811489969492,
        "seek": 243700,
        "start": 2437,
        "temperature": 0,
        "text": " This is – and this page is out of date.",
        "tokens": [
          50364,
          639,
          307,
          1662,
          293,
          341,
          3028,
          307,
          484,
          295,
          4002,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1747288146576324,
        "compression_ratio": 1.4842767295597483,
        "end": 2442,
        "id": 696,
        "no_speech_prob": 0.00970811489969492,
        "seek": 243700,
        "start": 2439,
        "temperature": 0,
        "text": " Refresh.",
        "tokens": [
          50464,
          16957,
          3644,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1747288146576324,
        "compression_ratio": 1.4842767295597483,
        "end": 2446,
        "id": 697,
        "no_speech_prob": 0.00970811489969492,
        "seek": 243700,
        "start": 2442,
        "temperature": 0,
        "text": " I'm going to merge this.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          22183,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1747288146576324,
        "compression_ratio": 1.4842767295597483,
        "end": 2458,
        "id": 698,
        "no_speech_prob": 0.00970811489969492,
        "seek": 243700,
        "start": 2446,
        "temperature": 0,
        "text": " And there's some music playing in the room next door that you guys can't hear, but I can hear.",
        "tokens": [
          50814,
          400,
          456,
          311,
          512,
          1318,
          2433,
          294,
          264,
          1808,
          958,
          2853,
          300,
          291,
          1074,
          393,
          380,
          1568,
          11,
          457,
          286,
          393,
          1568,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1747288146576324,
        "compression_ratio": 1.4842767295597483,
        "end": 2462,
        "id": 699,
        "no_speech_prob": 0.00970811489969492,
        "seek": 243700,
        "start": 2458,
        "temperature": 0,
        "text": " I'm going to go here now to the read me.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          352,
          510,
          586,
          281,
          264,
          1401,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1747288146576324,
        "compression_ratio": 1.4842767295597483,
        "end": 2466,
        "id": 700,
        "no_speech_prob": 0.00970811489969492,
        "seek": 243700,
        "start": 2462,
        "temperature": 0,
        "text": " I'm going to click edit.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          2052,
          8129,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2470,
        "id": 701,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2466,
        "temperature": 0,
        "text": " And where's the to-do list?",
        "tokens": [
          50364,
          400,
          689,
          311,
          264,
          281,
          12,
          2595,
          1329,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2471,
        "id": 702,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2470,
        "temperature": 0,
        "text": " Where did that to-do list end up?",
        "tokens": [
          50564,
          2305,
          630,
          300,
          281,
          12,
          2595,
          1329,
          917,
          493,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2472,
        "id": 703,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2471,
        "temperature": 0,
        "text": " It wasn't in the read me?",
        "tokens": [
          50614,
          467,
          2067,
          380,
          294,
          264,
          1401,
          385,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2474,
        "id": 704,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2472,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          50664,
          876,
          11,
          1338,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2475,
        "id": 705,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2474,
        "temperature": 0,
        "text": " That's so funny.",
        "tokens": [
          50764,
          663,
          311,
          370,
          4074,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2479,
        "id": 706,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2475,
        "temperature": 0,
        "text": " I looked at that pull request and just assumed it went here.",
        "tokens": [
          50814,
          286,
          2956,
          412,
          300,
          2235,
          5308,
          293,
          445,
          15895,
          309,
          1437,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2480,
        "id": 707,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2479,
        "temperature": 0,
        "text": " Where did that pull request go?",
        "tokens": [
          51014,
          2305,
          630,
          300,
          2235,
          5308,
          352,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2482,
        "id": 708,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2480,
        "temperature": 0,
        "text": " Closed.",
        "tokens": [
          51064,
          2033,
          1744,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2486,
        "id": 709,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2482,
        "temperature": 0,
        "text": " Create to-do list.",
        "tokens": [
          51164,
          20248,
          281,
          12,
          2595,
          1329,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2488,
        "id": 710,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2486,
        "temperature": 0,
        "text": " Oh, separate to-do.md file.",
        "tokens": [
          51364,
          876,
          11,
          4994,
          281,
          12,
          2595,
          13,
          76,
          67,
          3991,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2489,
        "id": 711,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2488,
        "temperature": 0,
        "text": " Okay, there we go.",
        "tokens": [
          51464,
          1033,
          11,
          456,
          321,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2490,
        "id": 712,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2489,
        "temperature": 0,
        "text": " Obviously.",
        "tokens": [
          51514,
          7580,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2491,
        "id": 713,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2490,
        "temperature": 0,
        "text": " I'm going to go here.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16480384767055511,
        "compression_ratio": 1.6650246305418719,
        "end": 2495,
        "id": 714,
        "no_speech_prob": 0.07920641452074051,
        "seek": 246600,
        "start": 2491,
        "temperature": 0,
        "text": " I'm going to edit this.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          8129,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2501,
        "id": 715,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2495,
        "temperature": 0,
        "text": " This – whatever this is was done.",
        "tokens": [
          50364,
          639,
          1662,
          2035,
          341,
          307,
          390,
          1096,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2502,
        "id": 716,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2501,
        "temperature": 0,
        "text": " This was done.",
        "tokens": [
          50664,
          639,
          390,
          1096,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2506,
        "id": 717,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2502,
        "temperature": 0,
        "text": " I mean, this to-do list is almost silly now, but this was done.",
        "tokens": [
          50714,
          286,
          914,
          11,
          341,
          281,
          12,
          2595,
          1329,
          307,
          1920,
          11774,
          586,
          11,
          457,
          341,
          390,
          1096,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2508,
        "id": 718,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2506,
        "temperature": 0,
        "text": " This was not really done.",
        "tokens": [
          50914,
          639,
          390,
          406,
          534,
          1096,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2510,
        "id": 719,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2508,
        "temperature": 0,
        "text": " Different activation functions.",
        "tokens": [
          51014,
          20825,
          24433,
          6828,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2511,
        "id": 720,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2510,
        "temperature": 0,
        "text": " XOR coding challenge.",
        "tokens": [
          51114,
          1783,
          2483,
          17720,
          3430,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2513,
        "id": 721,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2511,
        "temperature": 0,
        "text": " Oh, this is not done.",
        "tokens": [
          51164,
          876,
          11,
          341,
          307,
          406,
          1096,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2516,
        "id": 722,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2513,
        "temperature": 0,
        "text": " This is not done.",
        "tokens": [
          51264,
          639,
          307,
          406,
          1096,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19897748161764706,
        "compression_ratio": 1.5739644970414202,
        "end": 2518,
        "id": 723,
        "no_speech_prob": 0.0013249131152406335,
        "seek": 249500,
        "start": 2516,
        "temperature": 0,
        "text": " And I'll add some other things.",
        "tokens": [
          51414,
          400,
          286,
          603,
          909,
          512,
          661,
          721,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2015163732129474,
        "compression_ratio": 1.3897058823529411,
        "end": 2529,
        "id": 724,
        "no_speech_prob": 0.1259133517742157,
        "seek": 251800,
        "start": 2519,
        "temperature": 0,
        "text": " Add support for multiple layers, multiple hidden layers.",
        "tokens": [
          50414,
          5349,
          1406,
          337,
          3866,
          7914,
          11,
          3866,
          7633,
          7914,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2015163732129474,
        "compression_ratio": 1.3897058823529411,
        "end": 2538,
        "id": 725,
        "no_speech_prob": 0.1259133517742157,
        "seek": 251800,
        "start": 2529,
        "temperature": 0,
        "text": " And I'll actually change this to support for different activation functions.",
        "tokens": [
          50914,
          400,
          286,
          603,
          767,
          1319,
          341,
          281,
          1406,
          337,
          819,
          24433,
          6828,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2015163732129474,
        "compression_ratio": 1.3897058823529411,
        "end": 2540,
        "id": 726,
        "no_speech_prob": 0.1259133517742157,
        "seek": 251800,
        "start": 2538,
        "temperature": 0,
        "text": " This is something I would like to do with this library.",
        "tokens": [
          51364,
          639,
          307,
          746,
          286,
          576,
          411,
          281,
          360,
          365,
          341,
          6405,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2095848023891449,
        "compression_ratio": 1.33125,
        "end": 2552,
        "id": 727,
        "no_speech_prob": 0.1225169450044632,
        "seek": 254000,
        "start": 2540,
        "temperature": 0,
        "text": " And these could be issues, but combine with ml5 slash deep learn js.",
        "tokens": [
          50364,
          400,
          613,
          727,
          312,
          2663,
          11,
          457,
          10432,
          365,
          23271,
          20,
          17330,
          2452,
          1466,
          42713,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2095848023891449,
        "compression_ratio": 1.33125,
        "end": 2555,
        "id": 728,
        "no_speech_prob": 0.1225169450044632,
        "seek": 254000,
        "start": 2552,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2095848023891449,
        "compression_ratio": 1.33125,
        "end": 2558,
        "id": 729,
        "no_speech_prob": 0.1225169450044632,
        "seek": 254000,
        "start": 2555,
        "temperature": 0,
        "text": " So let's add this.",
        "tokens": [
          51114,
          407,
          718,
          311,
          909,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2095848023891449,
        "compression_ratio": 1.33125,
        "end": 2560,
        "id": 730,
        "no_speech_prob": 0.1225169450044632,
        "seek": 254000,
        "start": 2558,
        "temperature": 0,
        "text": " And I'm going to make a pull request.",
        "tokens": [
          51264,
          400,
          286,
          478,
          516,
          281,
          652,
          257,
          2235,
          5308,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2095848023891449,
        "compression_ratio": 1.33125,
        "end": 2566,
        "id": 731,
        "no_speech_prob": 0.1225169450044632,
        "seek": 254000,
        "start": 2560,
        "temperature": 0,
        "text": " This repo is so protected that even if I'm just editing one of the markdown files",
        "tokens": [
          51364,
          639,
          49040,
          307,
          370,
          10594,
          300,
          754,
          498,
          286,
          478,
          445,
          10000,
          472,
          295,
          264,
          1491,
          5093,
          7098,
          51664
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2571,
        "id": 732,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2566,
        "temperature": 0,
        "text": " and I am the administrator of the repo, I cannot merge this change into master",
        "tokens": [
          50364,
          293,
          286,
          669,
          264,
          25529,
          295,
          264,
          49040,
          11,
          286,
          2644,
          22183,
          341,
          1319,
          666,
          4505,
          50614
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2573,
        "id": 733,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2571,
        "temperature": 0,
        "text": " without these tests running.",
        "tokens": [
          50614,
          1553,
          613,
          6921,
          2614,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2576,
        "id": 734,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2573,
        "temperature": 0,
        "text": " So we'll see if these tests run.",
        "tokens": [
          50714,
          407,
          321,
          603,
          536,
          498,
          613,
          6921,
          1190,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2577,
        "id": 735,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2576,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2578,
        "id": 736,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2577,
        "temperature": 0,
        "text": " They ran.",
        "tokens": [
          50914,
          814,
          5872,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2579,
        "id": 737,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2578,
        "temperature": 0,
        "text": " They passed.",
        "tokens": [
          50964,
          814,
          4678,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2580,
        "id": 738,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2579,
        "temperature": 0,
        "text": " I'm going to merge.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          22183,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2581,
        "id": 739,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2580,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51064,
          1057,
          558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2582,
        "id": 740,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2581,
        "temperature": 0,
        "text": " We're in good shape now.",
        "tokens": [
          51114,
          492,
          434,
          294,
          665,
          3909,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2585,
        "id": 741,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2582,
        "temperature": 0,
        "text": " We are now able to do some coding.",
        "tokens": [
          51164,
          492,
          366,
          586,
          1075,
          281,
          360,
          512,
          17720,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2591,
        "id": 742,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2585,
        "temperature": 0,
        "text": " And I really wish I had not closed the playlist because I'm going to need that.",
        "tokens": [
          51314,
          400,
          286,
          534,
          3172,
          286,
          632,
          406,
          5395,
          264,
          16788,
          570,
          286,
          478,
          516,
          281,
          643,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1843956167047674,
        "compression_ratio": 1.5936073059360731,
        "end": 2592,
        "id": 743,
        "no_speech_prob": 0.50385582447052,
        "seek": 256600,
        "start": 2591,
        "temperature": 0,
        "text": " Or this.",
        "tokens": [
          51614,
          1610,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2601,
        "id": 744,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2592,
        "temperature": 0,
        "text": " So now let me open up terminal.",
        "tokens": [
          50364,
          407,
          586,
          718,
          385,
          1269,
          493,
          14709,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2606,
        "id": 745,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2601,
        "temperature": 0,
        "text": " Let's go here.",
        "tokens": [
          50814,
          961,
          311,
          352,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2608,
        "id": 746,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2606,
        "temperature": 0,
        "text": " Open.",
        "tokens": [
          51064,
          7238,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2610,
        "id": 747,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2608,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          51164,
          2492,
          322,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2611,
        "id": 748,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2610,
        "temperature": 0,
        "text": " Come find your window.",
        "tokens": [
          51264,
          2492,
          915,
          428,
          4910,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2612,
        "id": 749,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2611,
        "temperature": 0,
        "text": " There you are.",
        "tokens": [
          51314,
          821,
          291,
          366,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2613,
        "id": 750,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2612,
        "temperature": 0,
        "text": " Examples.",
        "tokens": [
          51364,
          48591,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2614,
        "id": 751,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2613,
        "temperature": 0,
        "text": " XOR.",
        "tokens": [
          51414,
          1783,
          2483,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2618,
        "id": 752,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2614,
        "temperature": 0,
        "text": " So one thing I'm going to do is, yeah, I'm going to leave this here.",
        "tokens": [
          51464,
          407,
          472,
          551,
          286,
          478,
          516,
          281,
          360,
          307,
          11,
          1338,
          11,
          286,
          478,
          516,
          281,
          1856,
          341,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2115323482415615,
        "compression_ratio": 1.375886524822695,
        "end": 2619,
        "id": 753,
        "no_speech_prob": 0.4452456831932068,
        "seek": 259200,
        "start": 2618,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51664,
          467,
          311,
          2489,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2621,
        "id": 754,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2619,
        "temperature": 0,
        "text": " Git status.",
        "tokens": [
          50364,
          16939,
          6558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2622,
        "id": 755,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2621,
        "temperature": 0,
        "text": " Git pull origin.",
        "tokens": [
          50464,
          16939,
          2235,
          4957,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2628,
        "id": 756,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2622,
        "temperature": 0,
        "text": " Oh, I'm standing in front of this.",
        "tokens": [
          50514,
          876,
          11,
          286,
          478,
          4877,
          294,
          1868,
          295,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2634,
        "id": 757,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2628,
        "temperature": 0,
        "text": " So I want to get all those changes now to have them locally.",
        "tokens": [
          50814,
          407,
          286,
          528,
          281,
          483,
          439,
          729,
          2962,
          586,
          281,
          362,
          552,
          16143,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2639,
        "id": 758,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2634,
        "temperature": 0,
        "text": " Oh, what did I change here?",
        "tokens": [
          51114,
          876,
          11,
          437,
          630,
          286,
          1319,
          510,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2640,
        "id": 759,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2639,
        "temperature": 0,
        "text": " There's nothing there.",
        "tokens": [
          51364,
          821,
          311,
          1825,
          456,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2641,
        "id": 760,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2640,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19752526557308503,
        "compression_ratio": 1.4858757062146892,
        "end": 2647,
        "id": 761,
        "no_speech_prob": 0.6790504455566406,
        "seek": 261900,
        "start": 2641,
        "temperature": 0,
        "text": " And then what I want to do, ah, I should do that iterm tutorial now, shouldn't I?",
        "tokens": [
          51464,
          400,
          550,
          437,
          286,
          528,
          281,
          360,
          11,
          3716,
          11,
          286,
          820,
          360,
          300,
          309,
          966,
          7073,
          586,
          11,
          4659,
          380,
          286,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2656,
        "id": 762,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2647,
        "temperature": 0,
        "text": " And then let's just run the tests locally to make sure everything is kind of going well.",
        "tokens": [
          50364,
          400,
          550,
          718,
          311,
          445,
          1190,
          264,
          6921,
          16143,
          281,
          652,
          988,
          1203,
          307,
          733,
          295,
          516,
          731,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2657,
        "id": 763,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2656,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2658,
        "id": 764,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2657,
        "temperature": 0,
        "text": " There's 20 tests now.",
        "tokens": [
          50864,
          821,
          311,
          945,
          6921,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2659,
        "id": 765,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2658,
        "temperature": 0,
        "text": " They all passed.",
        "tokens": [
          50914,
          814,
          439,
          4678,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2663,
        "id": 766,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2659,
        "temperature": 0,
        "text": " That's awesome.",
        "tokens": [
          50964,
          663,
          311,
          3476,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2669,
        "id": 767,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2663,
        "temperature": 0,
        "text": " And let's open this up in Atom.",
        "tokens": [
          51164,
          400,
          718,
          311,
          1269,
          341,
          493,
          294,
          1711,
          298,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16719453475054571,
        "compression_ratio": 1.4081632653061225,
        "end": 2675,
        "id": 768,
        "no_speech_prob": 0.02228439971804619,
        "seek": 264700,
        "start": 2669,
        "temperature": 0,
        "text": " Let's run a local server.",
        "tokens": [
          51464,
          961,
          311,
          1190,
          257,
          2654,
          7154,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1456827852461073,
        "compression_ratio": 1.282258064516129,
        "end": 2681,
        "id": 769,
        "no_speech_prob": 0.053400397300720215,
        "seek": 267500,
        "start": 2675,
        "temperature": 0,
        "text": " Let's go to the browser.",
        "tokens": [
          50364,
          961,
          311,
          352,
          281,
          264,
          11185,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1456827852461073,
        "compression_ratio": 1.282258064516129,
        "end": 2683,
        "id": 770,
        "no_speech_prob": 0.053400397300720215,
        "seek": 267500,
        "start": 2681,
        "temperature": 0,
        "text": " Now, this is the example I made before.",
        "tokens": [
          50664,
          823,
          11,
          341,
          307,
          264,
          1365,
          286,
          1027,
          949,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1456827852461073,
        "compression_ratio": 1.282258064516129,
        "end": 2691,
        "id": 771,
        "no_speech_prob": 0.053400397300720215,
        "seek": 267500,
        "start": 2683,
        "temperature": 0,
        "text": " I'm going to completely wipe this example and start over.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          2584,
          14082,
          341,
          1365,
          293,
          722,
          670,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1456827852461073,
        "compression_ratio": 1.282258064516129,
        "end": 2697,
        "id": 772,
        "no_speech_prob": 0.053400397300720215,
        "seek": 267500,
        "start": 2691,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51164,
          407,
          718,
          311,
          360,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1456827852461073,
        "compression_ratio": 1.282258064516129,
        "end": 2700,
        "id": 773,
        "no_speech_prob": 0.053400397300720215,
        "seek": 267500,
        "start": 2697,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1456827852461073,
        "compression_ratio": 1.282258064516129,
        "end": 2702,
        "id": 774,
        "no_speech_prob": 0.053400397300720215,
        "seek": 267500,
        "start": 2700,
        "temperature": 0,
        "text": " Please hold.",
        "tokens": [
          51614,
          2555,
          1797,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22876981409584604,
        "compression_ratio": 1.1720430107526882,
        "end": 2705,
        "id": 775,
        "no_speech_prob": 0.4608953595161438,
        "seek": 270200,
        "start": 2702,
        "temperature": 0,
        "text": " I need to tie my shoe, drink some water, and blow my nose.",
        "tokens": [
          50364,
          286,
          643,
          281,
          7582,
          452,
          12796,
          11,
          2822,
          512,
          1281,
          11,
          293,
          6327,
          452,
          6690,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22876981409584604,
        "compression_ratio": 1.1720430107526882,
        "end": 2707,
        "id": 776,
        "no_speech_prob": 0.4608953595161438,
        "seek": 270200,
        "start": 2705,
        "temperature": 0,
        "text": " Oh, I'm out of tissue.",
        "tokens": [
          50514,
          876,
          11,
          286,
          478,
          484,
          295,
          12404,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22876981409584604,
        "compression_ratio": 1.1720430107526882,
        "end": 2711,
        "id": 777,
        "no_speech_prob": 0.4608953595161438,
        "seek": 270200,
        "start": 2707,
        "temperature": 0,
        "text": " Oh, no, I have another one.",
        "tokens": [
          50614,
          876,
          11,
          572,
          11,
          286,
          362,
          1071,
          472,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.39158406257629397,
        "compression_ratio": 0.7837837837837838,
        "end": 2714,
        "id": 778,
        "no_speech_prob": 0.6067646741867065,
        "seek": 271100,
        "start": 2711,
        "temperature": 0,
        "text": " I will mute myself right now.",
        "tokens": [
          50414,
          286,
          486,
          24523,
          2059,
          558,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.289834771837507,
        "compression_ratio": 0.9206349206349206,
        "end": 2760,
        "id": 779,
        "no_speech_prob": 0.06852918118238449,
        "seek": 274100,
        "start": 2741,
        "temperature": 0,
        "text": " I'm not sure why I have this extra jacket on.",
        "tokens": [
          50364,
          286,
          478,
          406,
          988,
          983,
          286,
          362,
          341,
          2857,
          11781,
          322,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.289834771837507,
        "compression_ratio": 0.9206349206349206,
        "end": 2770,
        "id": 780,
        "no_speech_prob": 0.06852918118238449,
        "seek": 274100,
        "start": 2760,
        "temperature": 0,
        "text": " Remove that.",
        "tokens": [
          51314,
          18831,
          300,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22477604945500693,
        "compression_ratio": 0.7714285714285715,
        "end": 2795,
        "id": 781,
        "no_speech_prob": 0.06852714717388153,
        "seek": 277000,
        "start": 2770,
        "temperature": 0,
        "text": " Let's do the job for today.",
        "tokens": [
          50364,
          961,
          311,
          360,
          264,
          1691,
          337,
          965,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.33215538660685223,
        "compression_ratio": 0.68,
        "end": 2797,
        "id": 782,
        "no_speech_prob": 0.5807853937149048,
        "seek": 279500,
        "start": 2796,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.33215538660685223,
        "compression_ratio": 0.68,
        "end": 2822,
        "id": 783,
        "no_speech_prob": 0.5807853937149048,
        "seek": 279500,
        "start": 2797,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50464,
          1692,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2824,
        "id": 784,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2823,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2825,
        "id": 785,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2824,
        "temperature": 0,
        "text": " It's all quiet now.",
        "tokens": [
          50464,
          467,
          311,
          439,
          5677,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2832,
        "id": 786,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2825,
        "temperature": 0,
        "text": " I think it's time to read just a few random numbers to get warmed up.",
        "tokens": [
          50514,
          286,
          519,
          309,
          311,
          565,
          281,
          1401,
          445,
          257,
          1326,
          4974,
          3547,
          281,
          483,
          38201,
          493,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2839,
        "id": 787,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2832,
        "temperature": 0,
        "text": " To relax, go into a sleepy slumbered state of neural network training.",
        "tokens": [
          50864,
          1407,
          5789,
          11,
          352,
          666,
          257,
          24908,
          1061,
          4182,
          292,
          1785,
          295,
          18161,
          3209,
          3097,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2842,
        "id": 788,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2839,
        "temperature": 0,
        "text": " 38,271.",
        "tokens": [
          51214,
          12843,
          11,
          10076,
          16,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2845,
        "id": 789,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2842,
        "temperature": 0,
        "text": " 54,967.",
        "tokens": [
          51364,
          20793,
          11,
          24,
          22452,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2690655655331082,
        "compression_ratio": 1.2582781456953642,
        "end": 2849,
        "id": 790,
        "no_speech_prob": 0.46856924891471863,
        "seek": 282200,
        "start": 2845,
        "temperature": 0,
        "text": " 58,046.",
        "tokens": [
          51514,
          21786,
          11,
          14565,
          21,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2852,
        "id": 791,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2849,
        "temperature": 0,
        "text": " I really need progressives.",
        "tokens": [
          50364,
          286,
          534,
          643,
          4205,
          1539,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2854,
        "id": 792,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2852,
        "temperature": 0,
        "text": " 22,950.",
        "tokens": [
          50514,
          5853,
          11,
          24,
          2803,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2857,
        "id": 793,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2854,
        "temperature": 0,
        "text": " This is actually how I read now, or I do this.",
        "tokens": [
          50614,
          639,
          307,
          767,
          577,
          286,
          1401,
          586,
          11,
          420,
          286,
          360,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2859,
        "id": 794,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2857,
        "temperature": 0,
        "text": " 22,950.",
        "tokens": [
          50764,
          5853,
          11,
          24,
          2803,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2862,
        "id": 795,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2859,
        "temperature": 0,
        "text": " 97,533.",
        "tokens": [
          50864,
          23399,
          11,
          20,
          10191,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2865,
        "id": 796,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2862,
        "temperature": 0,
        "text": " 61,932.",
        "tokens": [
          51014,
          28294,
          11,
          24,
          11440,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2868,
        "id": 797,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2865,
        "temperature": 0,
        "text": " 5,199.",
        "tokens": [
          51164,
          1025,
          11,
          3405,
          24,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2871,
        "id": 798,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2868,
        "temperature": 0,
        "text": " 65,968.",
        "tokens": [
          51314,
          11624,
          11,
          22962,
          23,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2875,
        "id": 799,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2871,
        "temperature": 0,
        "text": " 69,784.",
        "tokens": [
          51464,
          28267,
          11,
          22,
          25494,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17222716484540773,
        "compression_ratio": 1.1810344827586208,
        "end": 2878,
        "id": 800,
        "no_speech_prob": 0.8217602968215942,
        "seek": 284900,
        "start": 2875,
        "temperature": 0,
        "text": " 25,659.",
        "tokens": [
          51664,
          3552,
          11,
          16824,
          24,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1940535879754401,
        "compression_ratio": 1.36,
        "end": 2881,
        "id": 801,
        "no_speech_prob": 0.20684750378131866,
        "seek": 287800,
        "start": 2878,
        "temperature": 0,
        "text": " 74,954.",
        "tokens": [
          50364,
          28868,
          11,
          15718,
          19,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1940535879754401,
        "compression_ratio": 1.36,
        "end": 2884,
        "id": 802,
        "no_speech_prob": 0.20684750378131866,
        "seek": 287800,
        "start": 2881,
        "temperature": 0,
        "text": " 11,139.",
        "tokens": [
          50514,
          2975,
          11,
          7668,
          24,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1940535879754401,
        "compression_ratio": 1.36,
        "end": 2889,
        "id": 803,
        "no_speech_prob": 0.20684750378131866,
        "seek": 287800,
        "start": 2884,
        "temperature": 0,
        "text": " 32,340.",
        "tokens": [
          50664,
          8858,
          11,
          18,
          5254,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1940535879754401,
        "compression_ratio": 1.36,
        "end": 2892,
        "id": 804,
        "no_speech_prob": 0.20684750378131866,
        "seek": 287800,
        "start": 2889,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1940535879754401,
        "compression_ratio": 1.36,
        "end": 2898,
        "id": 805,
        "no_speech_prob": 0.20684750378131866,
        "seek": 287800,
        "start": 2892,
        "temperature": 0,
        "text": " Yeah, I know I said I was going to leave at 3.30, but I like to say I'm going to leave",
        "tokens": [
          51064,
          865,
          11,
          286,
          458,
          286,
          848,
          286,
          390,
          516,
          281,
          1856,
          412,
          805,
          13,
          3446,
          11,
          457,
          286,
          411,
          281,
          584,
          286,
          478,
          516,
          281,
          1856,
          51364
        ]
      },
      {
        "avg_logprob": -0.1940535879754401,
        "compression_ratio": 1.36,
        "end": 2907,
        "id": 806,
        "no_speech_prob": 0.20684750378131866,
        "seek": 287800,
        "start": 2898,
        "temperature": 0,
        "text": " like way earlier than I absolutely need to leave because, as you know, I never, as much",
        "tokens": [
          51364,
          411,
          636,
          3071,
          813,
          286,
          3122,
          643,
          281,
          1856,
          570,
          11,
          382,
          291,
          458,
          11,
          286,
          1128,
          11,
          382,
          709,
          51814
        ]
      },
      {
        "avg_logprob": -0.2329724547150847,
        "compression_ratio": 1.408839779005525,
        "end": 2910,
        "id": 807,
        "no_speech_prob": 0.06277306377887726,
        "seek": 290700,
        "start": 2907,
        "temperature": 0,
        "text": " as, I barely ever start on time, let alone finish on time.",
        "tokens": [
          50364,
          382,
          11,
          286,
          10268,
          1562,
          722,
          322,
          565,
          11,
          718,
          3312,
          2413,
          322,
          565,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2329724547150847,
        "compression_ratio": 1.408839779005525,
        "end": 2915,
        "id": 808,
        "no_speech_prob": 0.06277306377887726,
        "seek": 290700,
        "start": 2910,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50514,
          1057,
          558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2329724547150847,
        "compression_ratio": 1.408839779005525,
        "end": 2919,
        "id": 809,
        "no_speech_prob": 0.06277306377887726,
        "seek": 290700,
        "start": 2915,
        "temperature": 0,
        "text": " Energy, people, energy, places, places.",
        "tokens": [
          50764,
          14939,
          11,
          561,
          11,
          2281,
          11,
          3190,
          11,
          3190,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2329724547150847,
        "compression_ratio": 1.408839779005525,
        "end": 2921,
        "id": 810,
        "no_speech_prob": 0.06277306377887726,
        "seek": 290700,
        "start": 2919,
        "temperature": 0,
        "text": " We're about to get started with the coding challenge.",
        "tokens": [
          50964,
          492,
          434,
          466,
          281,
          483,
          1409,
          365,
          264,
          17720,
          3430,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2329724547150847,
        "compression_ratio": 1.408839779005525,
        "end": 2929,
        "id": 811,
        "no_speech_prob": 0.06277306377887726,
        "seek": 290700,
        "start": 2921,
        "temperature": 0,
        "text": " Why is my, I'm getting a notification on my Fitbit from Slack that someone said zzzz.",
        "tokens": [
          51064,
          1545,
          307,
          452,
          11,
          286,
          478,
          1242,
          257,
          11554,
          322,
          452,
          29263,
          5260,
          490,
          37211,
          300,
          1580,
          848,
          710,
          4313,
          89,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2329724547150847,
        "compression_ratio": 1.408839779005525,
        "end": 2933,
        "id": 812,
        "no_speech_prob": 0.06277306377887726,
        "seek": 290700,
        "start": 2929,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20571081340312958,
        "compression_ratio": 1.7311475409836066,
        "end": 2940,
        "id": 813,
        "no_speech_prob": 0.5542404055595398,
        "seek": 293300,
        "start": 2934,
        "temperature": 0,
        "text": " By the way, I am committed to somehow, most likely through the magic of artificial intelligence,",
        "tokens": [
          50414,
          3146,
          264,
          636,
          11,
          286,
          669,
          7784,
          281,
          6063,
          11,
          881,
          3700,
          807,
          264,
          5585,
          295,
          11677,
          7599,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20571081340312958,
        "compression_ratio": 1.7311475409836066,
        "end": 2946,
        "id": 814,
        "no_speech_prob": 0.5542404055595398,
        "seek": 293300,
        "start": 2940,
        "temperature": 0,
        "text": " if I ever hit 1 million subscribers, I will read all 1 million random digits in a video.",
        "tokens": [
          50714,
          498,
          286,
          1562,
          2045,
          502,
          2459,
          11092,
          11,
          286,
          486,
          1401,
          439,
          502,
          2459,
          4974,
          27011,
          294,
          257,
          960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20571081340312958,
        "compression_ratio": 1.7311475409836066,
        "end": 2950,
        "id": 815,
        "no_speech_prob": 0.5542404055595398,
        "seek": 293300,
        "start": 2946,
        "temperature": 0,
        "text": " Again, though, I have a feeling that it's going to end up being a computer generated",
        "tokens": [
          51014,
          3764,
          11,
          1673,
          11,
          286,
          362,
          257,
          2633,
          300,
          309,
          311,
          516,
          281,
          917,
          493,
          885,
          257,
          3820,
          10833,
          51214
        ]
      },
      {
        "avg_logprob": -0.20571081340312958,
        "compression_ratio": 1.7311475409836066,
        "end": 2953,
        "id": 816,
        "no_speech_prob": 0.5542404055595398,
        "seek": 293300,
        "start": 2950,
        "temperature": 0,
        "text": " me reading all of them because the amount of time it would take is absurd.",
        "tokens": [
          51214,
          385,
          3760,
          439,
          295,
          552,
          570,
          264,
          2372,
          295,
          565,
          309,
          576,
          747,
          307,
          19774,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20571081340312958,
        "compression_ratio": 1.7311475409836066,
        "end": 2956,
        "id": 817,
        "no_speech_prob": 0.5542404055595398,
        "seek": 293300,
        "start": 2953,
        "temperature": 0,
        "text": " I would love to do something, I could do something that takes like five or six hours, some kind",
        "tokens": [
          51364,
          286,
          576,
          959,
          281,
          360,
          746,
          11,
          286,
          727,
          360,
          746,
          300,
          2516,
          411,
          1732,
          420,
          2309,
          2496,
          11,
          512,
          733,
          51514
        ]
      },
      {
        "avg_logprob": -0.20571081340312958,
        "compression_ratio": 1.7311475409836066,
        "end": 2960,
        "id": 818,
        "no_speech_prob": 0.5542404055595398,
        "seek": 293300,
        "start": 2956,
        "temperature": 0,
        "text": " of marathon thing, but I think it would take me a week without sleeping, which is very",
        "tokens": [
          51514,
          295,
          27601,
          551,
          11,
          457,
          286,
          519,
          309,
          576,
          747,
          385,
          257,
          1243,
          1553,
          8296,
          11,
          597,
          307,
          588,
          51714
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2963,
        "id": 819,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2960,
        "temperature": 0,
        "text": " unrealistic and not good for my health.",
        "tokens": [
          50364,
          42867,
          293,
          406,
          665,
          337,
          452,
          1585,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2966,
        "id": 820,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2963,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2970,
        "id": 821,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2966,
        "temperature": 0,
        "text": " So, I'm looking at the chat.",
        "tokens": [
          50664,
          407,
          11,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2975,
        "id": 822,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2970,
        "temperature": 0,
        "text": " Let's see, I don't know how many viewers I've lost.",
        "tokens": [
          50864,
          961,
          311,
          536,
          11,
          286,
          500,
          380,
          458,
          577,
          867,
          8499,
          286,
          600,
          2731,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2977,
        "id": 823,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2975,
        "temperature": 0,
        "text": " Hopefully a lot.",
        "tokens": [
          51114,
          10429,
          257,
          688,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2979,
        "id": 824,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2977,
        "temperature": 0,
        "text": " Oh, I've been looking for this for the longest time.",
        "tokens": [
          51214,
          876,
          11,
          286,
          600,
          668,
          1237,
          337,
          341,
          337,
          264,
          15438,
          565,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2981,
        "id": 825,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2979,
        "temperature": 0,
        "text": " It's a sleeve.",
        "tokens": [
          51314,
          467,
          311,
          257,
          21138,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1809203650361748,
        "compression_ratio": 1.4771573604060915,
        "end": 2986,
        "id": 826,
        "no_speech_prob": 0.7121325135231018,
        "seek": 296000,
        "start": 2981,
        "temperature": 0,
        "text": " By the way, for this computer that goes here, this is going to blow your minds.",
        "tokens": [
          51414,
          3146,
          264,
          636,
          11,
          337,
          341,
          3820,
          300,
          1709,
          510,
          11,
          341,
          307,
          516,
          281,
          6327,
          428,
          9634,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 2991,
        "id": 827,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 2986,
        "temperature": 0,
        "text": " Whoa, look at my magic sleeve that doesn't fall down.",
        "tokens": [
          50364,
          7521,
          11,
          574,
          412,
          452,
          5585,
          21138,
          300,
          1177,
          380,
          2100,
          760,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 2992,
        "id": 828,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 2991,
        "temperature": 0,
        "text": " Magic trick.",
        "tokens": [
          50614,
          16154,
          4282,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 2996,
        "id": 829,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 2992,
        "temperature": 0,
        "text": " I'm like a regular internet video magician.",
        "tokens": [
          50664,
          286,
          478,
          411,
          257,
          3890,
          4705,
          960,
          38614,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 2998,
        "id": 830,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 2996,
        "temperature": 0,
        "text": " Watch this.",
        "tokens": [
          50864,
          7277,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 3003,
        "id": 831,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 2998,
        "temperature": 0,
        "text": " I am hiding from you.",
        "tokens": [
          50964,
          286,
          669,
          10596,
          490,
          291,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 3005,
        "id": 832,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 3003,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 3008,
        "id": 833,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 3005,
        "temperature": 0,
        "text": " Amazing what a little green paper will do.",
        "tokens": [
          51314,
          14165,
          437,
          257,
          707,
          3092,
          3035,
          486,
          360,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 3011,
        "id": 834,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 3008,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18905896918718204,
        "compression_ratio": 1.4742268041237114,
        "end": 3015,
        "id": 835,
        "no_speech_prob": 0.0017006760463118553,
        "seek": 298600,
        "start": 3011,
        "temperature": 0,
        "text": " It would be great if I could warn you about a mistake by making your watch notify you.",
        "tokens": [
          51614,
          467,
          576,
          312,
          869,
          498,
          286,
          727,
          12286,
          291,
          466,
          257,
          6146,
          538,
          1455,
          428,
          1159,
          36560,
          291,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3017,
        "id": 836,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3015,
        "temperature": 0,
        "text": " If you're at the whiteboard, it's impossible to get your attention.",
        "tokens": [
          50364,
          759,
          291,
          434,
          412,
          264,
          2418,
          3787,
          11,
          309,
          311,
          6243,
          281,
          483,
          428,
          3202,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3018,
        "id": 837,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3017,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50464,
          1079,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3027,
        "id": 838,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3018,
        "temperature": 0,
        "text": " So, the thing is, I will actually get in Slack, if you at shift in me, it will notify my phone,",
        "tokens": [
          50514,
          407,
          11,
          264,
          551,
          307,
          11,
          286,
          486,
          767,
          483,
          294,
          37211,
          11,
          498,
          291,
          412,
          5513,
          294,
          385,
          11,
          309,
          486,
          36560,
          452,
          2593,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3030,
        "id": 839,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3027,
        "temperature": 0,
        "text": " which will often, I usually turn it off.",
        "tokens": [
          50964,
          597,
          486,
          2049,
          11,
          286,
          2673,
          1261,
          309,
          766,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3035,
        "id": 840,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3030,
        "temperature": 0,
        "text": " I usually turn notifications off, but I did just have them on just now because I forgot",
        "tokens": [
          51114,
          286,
          2673,
          1261,
          13426,
          766,
          11,
          457,
          286,
          630,
          445,
          362,
          552,
          322,
          445,
          586,
          570,
          286,
          5298,
          51364
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3036,
        "id": 841,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3035,
        "temperature": 0,
        "text": " about that.",
        "tokens": [
          51364,
          466,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3043,
        "id": 842,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3036,
        "temperature": 0,
        "text": " And so, I can get, oh look, Simon sent me a nice picture of how getters and setters",
        "tokens": [
          51414,
          400,
          370,
          11,
          286,
          393,
          483,
          11,
          1954,
          574,
          11,
          13193,
          2279,
          385,
          257,
          1481,
          3036,
          295,
          577,
          483,
          1559,
          293,
          992,
          1559,
          51764
        ]
      },
      {
        "avg_logprob": -0.21463483066882116,
        "compression_ratio": 1.6352459016393444,
        "end": 3044,
        "id": 843,
        "no_speech_prob": 0.3040011525154114,
        "seek": 301500,
        "start": 3043,
        "temperature": 0,
        "text": " work.",
        "tokens": [
          51764,
          589,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.27194898170337345,
        "compression_ratio": 1.3611111111111112,
        "end": 3046,
        "id": 844,
        "no_speech_prob": 0.21989737451076508,
        "seek": 304400,
        "start": 3044,
        "temperature": 0,
        "text": " I could potentially, Alka, get a notification today.",
        "tokens": [
          50364,
          286,
          727,
          7263,
          11,
          967,
          2330,
          11,
          483,
          257,
          11554,
          965,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.27194898170337345,
        "compression_ratio": 1.3611111111111112,
        "end": 3054,
        "id": 845,
        "no_speech_prob": 0.21989737451076508,
        "seek": 304400,
        "start": 3046,
        "temperature": 0,
        "text": " You could try that if I really mess something up.",
        "tokens": [
          50464,
          509,
          727,
          853,
          300,
          498,
          286,
          534,
          2082,
          746,
          493,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.27194898170337345,
        "compression_ratio": 1.3611111111111112,
        "end": 3062,
        "id": 846,
        "no_speech_prob": 0.21989737451076508,
        "seek": 304400,
        "start": 3054,
        "temperature": 0,
        "text": " Now, I'm going to, I have a totally different way I'm going to do this video right now.",
        "tokens": [
          50864,
          823,
          11,
          286,
          478,
          516,
          281,
          11,
          286,
          362,
          257,
          3879,
          819,
          636,
          286,
          478,
          516,
          281,
          360,
          341,
          960,
          558,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.27194898170337345,
        "compression_ratio": 1.3611111111111112,
        "end": 3063,
        "id": 847,
        "no_speech_prob": 0.21989737451076508,
        "seek": 304400,
        "start": 3062,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3497143714658676,
        "compression_ratio": 1.069767441860465,
        "end": 3079,
        "id": 848,
        "no_speech_prob": 0.36280885338783264,
        "seek": 307400,
        "start": 3075,
        "temperature": 0,
        "text": " Hold on a second.",
        "tokens": [
          50414,
          6962,
          322,
          257,
          1150,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3497143714658676,
        "compression_ratio": 1.069767441860465,
        "end": 3088,
        "id": 849,
        "no_speech_prob": 0.36280885338783264,
        "seek": 307400,
        "start": 3087,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3497143714658676,
        "compression_ratio": 1.069767441860465,
        "end": 3092,
        "id": 850,
        "no_speech_prob": 0.36280885338783264,
        "seek": 307400,
        "start": 3088,
        "temperature": 0,
        "text": " Let's give this some time here and see if this will work itself out.",
        "tokens": [
          51064,
          961,
          311,
          976,
          341,
          512,
          565,
          510,
          293,
          536,
          498,
          341,
          486,
          589,
          2564,
          484,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2546525299549103,
        "compression_ratio": 1.2391304347826086,
        "end": 3109,
        "id": 851,
        "no_speech_prob": 0.0036491842474788427,
        "seek": 309200,
        "start": 3092,
        "temperature": 0,
        "text": " I'm just waiting for the neural network to learn.",
        "tokens": [
          50364,
          286,
          478,
          445,
          3806,
          337,
          264,
          18161,
          3209,
          281,
          1466,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2546525299549103,
        "compression_ratio": 1.2391304347826086,
        "end": 3114,
        "id": 852,
        "no_speech_prob": 0.0036491842474788427,
        "seek": 309200,
        "start": 3109,
        "temperature": 0,
        "text": " I'm going to use this as a visual, visual aid, visual reference.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          764,
          341,
          382,
          257,
          5056,
          11,
          5056,
          9418,
          11,
          5056,
          6408,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3127,
        "id": 853,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3123,
        "temperature": 0.2,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3130,
        "id": 854,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3127,
        "temperature": 0.2,
        "text": " That's good enough.",
        "tokens": [
          50614,
          663,
          311,
          665,
          1547,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3139,
        "id": 855,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3138,
        "temperature": 0.2,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3140,
        "id": 856,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3139,
        "temperature": 0.2,
        "text": " Hello.",
        "tokens": [
          51214,
          2425,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3144,
        "id": 857,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3140,
        "temperature": 0.2,
        "text": " Welcome to a coding challenge.",
        "tokens": [
          51264,
          4027,
          281,
          257,
          17720,
          3430,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3148,
        "id": 858,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3144,
        "temperature": 0.2,
        "text": " In this coding challenge, I'm going to make a version of this.",
        "tokens": [
          51464,
          682,
          341,
          17720,
          3430,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          3037,
          295,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3149,
        "id": 859,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3148,
        "temperature": 0.2,
        "text": " Wait a second.",
        "tokens": [
          51664,
          3802,
          257,
          1150,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3092392285664876,
        "compression_ratio": 1.310077519379845,
        "end": 3151,
        "id": 860,
        "no_speech_prob": 0.006487135309726,
        "seek": 312200,
        "start": 3149,
        "temperature": 0.2,
        "text": " Do you guys see?",
        "tokens": [
          51714,
          1144,
          291,
          1074,
          536,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3153,
        "id": 861,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3151,
        "temperature": 0,
        "text": " Is there like a smudge?",
        "tokens": [
          50364,
          1119,
          456,
          411,
          257,
          899,
          16032,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3154,
        "id": 862,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3153,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50464,
          6962,
          322,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3157,
        "id": 863,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3154,
        "temperature": 0,
        "text": " Is that just like, where is that smudge from?",
        "tokens": [
          50514,
          1119,
          300,
          445,
          411,
          11,
          689,
          307,
          300,
          899,
          16032,
          490,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3159,
        "id": 864,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3157,
        "temperature": 0,
        "text": " Oh, weird.",
        "tokens": [
          50664,
          876,
          11,
          3657,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3163,
        "id": 865,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3159,
        "temperature": 0,
        "text": " That's just like an artifact on my screen.",
        "tokens": [
          50764,
          663,
          311,
          445,
          411,
          364,
          34806,
          322,
          452,
          2568,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3164,
        "id": 866,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3163,
        "temperature": 0,
        "text": " That was so weird.",
        "tokens": [
          50964,
          663,
          390,
          370,
          3657,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3165,
        "id": 867,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3164,
        "temperature": 0,
        "text": " Did you see that?",
        "tokens": [
          51014,
          2589,
          291,
          536,
          300,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3167,
        "id": 868,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3165,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51064,
          876,
          452,
          8387,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3169,
        "id": 869,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3167,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51164,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3170,
        "id": 870,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3169,
        "temperature": 0,
        "text": " Starting over.",
        "tokens": [
          51264,
          16217,
          670,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3173,
        "id": 871,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3170,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          51314,
          2425,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3175,
        "id": 872,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3173,
        "temperature": 0,
        "text": " Welcome to a coding challenge.",
        "tokens": [
          51464,
          4027,
          281,
          257,
          17720,
          3430,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2139340966148714,
        "compression_ratio": 1.5971563981042654,
        "end": 3180,
        "id": 873,
        "no_speech_prob": 0.0013885057996958494,
        "seek": 315100,
        "start": 3175,
        "temperature": 0,
        "text": " In this coding challenge, I am going to, this is going to sound really weird, solve XOR",
        "tokens": [
          51564,
          682,
          341,
          17720,
          3430,
          11,
          286,
          669,
          516,
          281,
          11,
          341,
          307,
          516,
          281,
          1626,
          534,
          3657,
          11,
          5039,
          1783,
          2483,
          51814
        ]
      },
      {
        "avg_logprob": -0.1963030080326268,
        "compression_ratio": 1.8084291187739463,
        "end": 3181,
        "id": 874,
        "no_speech_prob": 0.08269108086824417,
        "seek": 318000,
        "start": 3180,
        "temperature": 0,
        "text": " with a neural network.",
        "tokens": [
          50364,
          365,
          257,
          18161,
          3209,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1963030080326268,
        "compression_ratio": 1.8084291187739463,
        "end": 3183,
        "id": 875,
        "no_speech_prob": 0.08269108086824417,
        "seek": 318000,
        "start": 3181,
        "temperature": 0,
        "text": " Now, why would anyone want to do this?",
        "tokens": [
          50414,
          823,
          11,
          983,
          576,
          2878,
          528,
          281,
          360,
          341,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.1963030080326268,
        "compression_ratio": 1.8084291187739463,
        "end": 3185,
        "id": 876,
        "no_speech_prob": 0.08269108086824417,
        "seek": 318000,
        "start": 3183,
        "temperature": 0,
        "text": " Why would I want to do this?",
        "tokens": [
          50514,
          1545,
          576,
          286,
          528,
          281,
          360,
          341,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.1963030080326268,
        "compression_ratio": 1.8084291187739463,
        "end": 3193,
        "id": 877,
        "no_speech_prob": 0.08269108086824417,
        "seek": 318000,
        "start": 3185,
        "temperature": 0,
        "text": " Well, what this is actually, this is a video in which I'm going to test a neural network library I've been building in JavaScript.",
        "tokens": [
          50614,
          1042,
          11,
          437,
          341,
          307,
          767,
          11,
          341,
          307,
          257,
          960,
          294,
          597,
          286,
          478,
          516,
          281,
          1500,
          257,
          18161,
          3209,
          6405,
          286,
          600,
          668,
          2390,
          294,
          15778,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1963030080326268,
        "compression_ratio": 1.8084291187739463,
        "end": 3201,
        "id": 878,
        "no_speech_prob": 0.08269108086824417,
        "seek": 318000,
        "start": 3193,
        "temperature": 0,
        "text": " And in fact, if you want to follow along with that process of building it, there is a giant playlist here starting with 10.1,",
        "tokens": [
          51014,
          400,
          294,
          1186,
          11,
          498,
          291,
          528,
          281,
          1524,
          2051,
          365,
          300,
          1399,
          295,
          2390,
          309,
          11,
          456,
          307,
          257,
          7410,
          16788,
          510,
          2891,
          365,
          1266,
          13,
          16,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1963030080326268,
        "compression_ratio": 1.8084291187739463,
        "end": 3209,
        "id": 879,
        "no_speech_prob": 0.08269108086824417,
        "seek": 318000,
        "start": 3201,
        "temperature": 0,
        "text": " introduction to neural networks, and I start building that library actually around, oops, don't play the video, around 10.4.",
        "tokens": [
          51414,
          9339,
          281,
          18161,
          9590,
          11,
          293,
          286,
          722,
          2390,
          300,
          6405,
          767,
          926,
          11,
          34166,
          11,
          500,
          380,
          862,
          264,
          960,
          11,
          926,
          1266,
          13,
          19,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18208385114910222,
        "compression_ratio": 1.7060931899641576,
        "end": 3216,
        "id": 880,
        "no_speech_prob": 0.0008969184709712863,
        "seek": 320900,
        "start": 3209,
        "temperature": 0,
        "text": " So this video is a standalone video where I'm going to make use of that library in a coding challenge.",
        "tokens": [
          50364,
          407,
          341,
          960,
          307,
          257,
          37454,
          960,
          689,
          286,
          478,
          516,
          281,
          652,
          764,
          295,
          300,
          6405,
          294,
          257,
          17720,
          3430,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18208385114910222,
        "compression_ratio": 1.7060931899641576,
        "end": 3226,
        "id": 881,
        "no_speech_prob": 0.0008969184709712863,
        "seek": 320900,
        "start": 3216,
        "temperature": 0,
        "text": " You don't have to have watched all those, but if you want the background with a bit more to go deeper in how the internal mechanics of this neural network that I'm going to use works, I would refer you to those videos.",
        "tokens": [
          50714,
          509,
          500,
          380,
          362,
          281,
          362,
          6337,
          439,
          729,
          11,
          457,
          498,
          291,
          528,
          264,
          3678,
          365,
          257,
          857,
          544,
          281,
          352,
          7731,
          294,
          577,
          264,
          6920,
          12939,
          295,
          341,
          18161,
          3209,
          300,
          286,
          478,
          516,
          281,
          764,
          1985,
          11,
          286,
          576,
          2864,
          291,
          281,
          729,
          2145,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18208385114910222,
        "compression_ratio": 1.7060931899641576,
        "end": 3230,
        "id": 882,
        "no_speech_prob": 0.0008969184709712863,
        "seek": 320900,
        "start": 3226,
        "temperature": 0,
        "text": " Now, what is this crazy weird visualization going on over here?",
        "tokens": [
          51214,
          823,
          11,
          437,
          307,
          341,
          3219,
          3657,
          25801,
          516,
          322,
          670,
          510,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.18208385114910222,
        "compression_ratio": 1.7060931899641576,
        "end": 3234,
        "id": 883,
        "no_speech_prob": 0.0008969184709712863,
        "seek": 320900,
        "start": 3230,
        "temperature": 0,
        "text": " So let's, I'm going to come back to it in a second, but let's come over to the whiteboard.",
        "tokens": [
          51414,
          407,
          718,
          311,
          11,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          309,
          294,
          257,
          1150,
          11,
          457,
          718,
          311,
          808,
          670,
          281,
          264,
          2418,
          3787,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1990935702283843,
        "compression_ratio": 1.8134328358208955,
        "end": 3240,
        "id": 884,
        "no_speech_prob": 0.12251313030719757,
        "seek": 323400,
        "start": 3234,
        "temperature": 0,
        "text": " So this is an example, a very beginning basic rather trivial example of machine learning.",
        "tokens": [
          50364,
          407,
          341,
          307,
          364,
          1365,
          11,
          257,
          588,
          2863,
          3875,
          2831,
          26703,
          1365,
          295,
          3479,
          2539,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1990935702283843,
        "compression_ratio": 1.8134328358208955,
        "end": 3242,
        "id": 885,
        "no_speech_prob": 0.12251313030719757,
        "seek": 323400,
        "start": 3240,
        "temperature": 0,
        "text": " And what do I mean by that?",
        "tokens": [
          50664,
          400,
          437,
          360,
          286,
          914,
          538,
          300,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.1990935702283843,
        "compression_ratio": 1.8134328358208955,
        "end": 3248,
        "id": 886,
        "no_speech_prob": 0.12251313030719757,
        "seek": 323400,
        "start": 3242,
        "temperature": 0,
        "text": " I mean, I'm going to draw a circle here, and I'm going to write ML, short for machine learning.",
        "tokens": [
          50764,
          286,
          914,
          11,
          286,
          478,
          516,
          281,
          2642,
          257,
          6329,
          510,
          11,
          293,
          286,
          478,
          516,
          281,
          2464,
          21601,
          11,
          2099,
          337,
          3479,
          2539,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1990935702283843,
        "compression_ratio": 1.8134328358208955,
        "end": 3254,
        "id": 887,
        "no_speech_prob": 0.12251313030719757,
        "seek": 323400,
        "start": 3248,
        "temperature": 0,
        "text": " And you can think of this as a place where there exists some machine learning recipe, some algorithm.",
        "tokens": [
          51064,
          400,
          291,
          393,
          519,
          295,
          341,
          382,
          257,
          1081,
          689,
          456,
          8198,
          512,
          3479,
          2539,
          6782,
          11,
          512,
          9284,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1990935702283843,
        "compression_ratio": 1.8134328358208955,
        "end": 3260,
        "id": 888,
        "no_speech_prob": 0.12251313030719757,
        "seek": 323400,
        "start": 3254,
        "temperature": 0,
        "text": " You might have heard of k-nearest neighbor or neural network, fill in the blank, support vector machines.",
        "tokens": [
          51364,
          509,
          1062,
          362,
          2198,
          295,
          350,
          12,
          716,
          17363,
          5987,
          420,
          18161,
          3209,
          11,
          2836,
          294,
          264,
          8247,
          11,
          1406,
          8062,
          8379,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1990935702283843,
        "compression_ratio": 1.8134328358208955,
        "end": 3263,
        "id": 889,
        "no_speech_prob": 0.12251313030719757,
        "seek": 323400,
        "start": 3260,
        "temperature": 0,
        "text": " So fill in the blank with your machine learning algorithm there.",
        "tokens": [
          51664,
          407,
          2836,
          294,
          264,
          8247,
          365,
          428,
          3479,
          2539,
          9284,
          456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18593181096590483,
        "compression_ratio": 1.7663934426229508,
        "end": 3268,
        "id": 890,
        "no_speech_prob": 0.0003301514661870897,
        "seek": 326300,
        "start": 3263,
        "temperature": 0,
        "text": " With a machine learning algorithm, something goes into it, data.",
        "tokens": [
          50364,
          2022,
          257,
          3479,
          2539,
          9284,
          11,
          746,
          1709,
          666,
          309,
          11,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18593181096590483,
        "compression_ratio": 1.7663934426229508,
        "end": 3275,
        "id": 891,
        "no_speech_prob": 0.0003301514661870897,
        "seek": 326300,
        "start": 3268,
        "temperature": 0,
        "text": " How you collect your data, how you're thoughtful about that, what the data is, how you quote unquote normalize your data.",
        "tokens": [
          50614,
          1012,
          291,
          2500,
          428,
          1412,
          11,
          577,
          291,
          434,
          21566,
          466,
          300,
          11,
          437,
          264,
          1412,
          307,
          11,
          577,
          291,
          6513,
          37557,
          2710,
          1125,
          428,
          1412,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18593181096590483,
        "compression_ratio": 1.7663934426229508,
        "end": 3281,
        "id": 892,
        "no_speech_prob": 0.0003301514661870897,
        "seek": 326300,
        "start": 3275,
        "temperature": 0,
        "text": " So there's so many questions, ethical questions, scientific questions that go into this piece.",
        "tokens": [
          50964,
          407,
          456,
          311,
          370,
          867,
          1651,
          11,
          18890,
          1651,
          11,
          8134,
          1651,
          300,
          352,
          666,
          341,
          2522,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18593181096590483,
        "compression_ratio": 1.7663934426229508,
        "end": 3288,
        "id": 893,
        "no_speech_prob": 0.0003301514661870897,
        "seek": 326300,
        "start": 3281,
        "temperature": 0,
        "text": " I am not covering that piece in this video, but there needs to be some data, something that I want to analyze or learn with.",
        "tokens": [
          51264,
          286,
          669,
          406,
          10322,
          300,
          2522,
          294,
          341,
          960,
          11,
          457,
          456,
          2203,
          281,
          312,
          512,
          1412,
          11,
          746,
          300,
          286,
          528,
          281,
          12477,
          420,
          1466,
          365,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18593181096590483,
        "compression_ratio": 1.7663934426229508,
        "end": 3290,
        "id": 894,
        "no_speech_prob": 0.0003301514661870897,
        "seek": 326300,
        "start": 3288,
        "temperature": 0,
        "text": " That's the data portion.",
        "tokens": [
          51614,
          663,
          311,
          264,
          1412,
          8044,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.182587770315317,
        "compression_ratio": 1.73109243697479,
        "end": 3299,
        "id": 895,
        "no_speech_prob": 0.04023369774222374,
        "seek": 329000,
        "start": 3290,
        "temperature": 0,
        "text": " And then, that data goes into the magical machine learning recipe, and out comes some output.",
        "tokens": [
          50364,
          400,
          550,
          11,
          300,
          1412,
          1709,
          666,
          264,
          12066,
          3479,
          2539,
          6782,
          11,
          293,
          484,
          1487,
          512,
          5598,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.182587770315317,
        "compression_ratio": 1.73109243697479,
        "end": 3304,
        "id": 896,
        "no_speech_prob": 0.04023369774222374,
        "seek": 329000,
        "start": 3299,
        "temperature": 0,
        "text": " Now what that output could be, it could be a piece of music that I've generated.",
        "tokens": [
          50814,
          823,
          437,
          300,
          5598,
          727,
          312,
          11,
          309,
          727,
          312,
          257,
          2522,
          295,
          1318,
          300,
          286,
          600,
          10833,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.182587770315317,
        "compression_ratio": 1.73109243697479,
        "end": 3306,
        "id": 897,
        "no_speech_prob": 0.04023369774222374,
        "seek": 329000,
        "start": 3304,
        "temperature": 0,
        "text": " It could be a classification of an image.",
        "tokens": [
          51064,
          467,
          727,
          312,
          257,
          21538,
          295,
          364,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.182587770315317,
        "compression_ratio": 1.73109243697479,
        "end": 3311,
        "id": 898,
        "no_speech_prob": 0.04023369774222374,
        "seek": 329000,
        "start": 3306,
        "temperature": 0,
        "text": " It could be the price of a house that I'm trying to predict based on some data.",
        "tokens": [
          51164,
          467,
          727,
          312,
          264,
          3218,
          295,
          257,
          1782,
          300,
          286,
          478,
          1382,
          281,
          6069,
          2361,
          322,
          512,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.182587770315317,
        "compression_ratio": 1.73109243697479,
        "end": 3317,
        "id": 899,
        "no_speech_prob": 0.04023369774222374,
        "seek": 329000,
        "start": 3311,
        "temperature": 0,
        "text": " So there's so much possibility here, and this output doesn't have to be a single thing, but can be multiple things.",
        "tokens": [
          51414,
          407,
          456,
          311,
          370,
          709,
          7959,
          510,
          11,
          293,
          341,
          5598,
          1177,
          380,
          362,
          281,
          312,
          257,
          2167,
          551,
          11,
          457,
          393,
          312,
          3866,
          721,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18505925791604177,
        "compression_ratio": 1.6231884057971016,
        "end": 3320,
        "id": 900,
        "no_speech_prob": 0.0005112530197948217,
        "seek": 331700,
        "start": 3317,
        "temperature": 0,
        "text": " The input obviously, the data can be multiple things.",
        "tokens": [
          50364,
          440,
          4846,
          2745,
          11,
          264,
          1412,
          393,
          312,
          3866,
          721,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18505925791604177,
        "compression_ratio": 1.6231884057971016,
        "end": 3322,
        "id": 901,
        "no_speech_prob": 0.0005112530197948217,
        "seek": 331700,
        "start": 3320,
        "temperature": 0,
        "text": " This is the idea of machine learning.",
        "tokens": [
          50514,
          639,
          307,
          264,
          1558,
          295,
          3479,
          2539,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18505925791604177,
        "compression_ratio": 1.6231884057971016,
        "end": 3328,
        "id": 902,
        "no_speech_prob": 0.0005112530197948217,
        "seek": 331700,
        "start": 3322,
        "temperature": 0,
        "text": " Now, I spent all this time building what is mostly like a toy neural network library.",
        "tokens": [
          50614,
          823,
          11,
          286,
          4418,
          439,
          341,
          565,
          2390,
          437,
          307,
          5240,
          411,
          257,
          12058,
          18161,
          3209,
          6405,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18505925791604177,
        "compression_ratio": 1.6231884057971016,
        "end": 3332,
        "id": 903,
        "no_speech_prob": 0.0005112530197948217,
        "seek": 331700,
        "start": 3328,
        "temperature": 0,
        "text": " It's written in JavaScript, there's nothing about it that's optimized, but just to kind of understand the pieces of how it works.",
        "tokens": [
          50914,
          467,
          311,
          3720,
          294,
          15778,
          11,
          456,
          311,
          1825,
          466,
          309,
          300,
          311,
          26941,
          11,
          457,
          445,
          281,
          733,
          295,
          1223,
          264,
          3755,
          295,
          577,
          309,
          1985,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18505925791604177,
        "compression_ratio": 1.6231884057971016,
        "end": 3337,
        "id": 904,
        "no_speech_prob": 0.0005112530197948217,
        "seek": 331700,
        "start": 3332,
        "temperature": 0,
        "text": " So what I want to do is have my recipe be in there, be a neural network.",
        "tokens": [
          51114,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          362,
          452,
          6782,
          312,
          294,
          456,
          11,
          312,
          257,
          18161,
          3209,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18505925791604177,
        "compression_ratio": 1.6231884057971016,
        "end": 3344,
        "id": 905,
        "no_speech_prob": 0.0005112530197948217,
        "seek": 331700,
        "start": 3337,
        "temperature": 0,
        "text": " And I want to create some scenario where I have some training data.",
        "tokens": [
          51364,
          400,
          286,
          528,
          281,
          1884,
          512,
          9005,
          689,
          286,
          362,
          512,
          3097,
          1412,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20219042160931755,
        "compression_ratio": 1.69377990430622,
        "end": 3350,
        "id": 906,
        "no_speech_prob": 0.00530180474743247,
        "seek": 334400,
        "start": 3344,
        "temperature": 0,
        "text": " So what I'm going to do, this is going to be a demonstration also of the machine learning process called supervised learning.",
        "tokens": [
          50364,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          341,
          307,
          516,
          281,
          312,
          257,
          16520,
          611,
          295,
          264,
          3479,
          2539,
          1399,
          1219,
          46533,
          2539,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20219042160931755,
        "compression_ratio": 1.69377990430622,
        "end": 3353,
        "id": 907,
        "no_speech_prob": 0.00530180474743247,
        "seek": 334400,
        "start": 3350,
        "temperature": 0,
        "text": " Supervised learning.",
        "tokens": [
          50664,
          4548,
          24420,
          2539,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20219042160931755,
        "compression_ratio": 1.69377990430622,
        "end": 3364,
        "id": 908,
        "no_speech_prob": 0.00530180474743247,
        "seek": 334400,
        "start": 3353,
        "temperature": 0,
        "text": " Meaning, I am the supervisor, and I am going to teach this machine learning recipe to produce output, that appropriate output for a given input.",
        "tokens": [
          50814,
          19948,
          11,
          286,
          669,
          264,
          24610,
          11,
          293,
          286,
          669,
          516,
          281,
          2924,
          341,
          3479,
          2539,
          6782,
          281,
          5258,
          5598,
          11,
          300,
          6854,
          5598,
          337,
          257,
          2212,
          4846,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20219042160931755,
        "compression_ratio": 1.69377990430622,
        "end": 3370,
        "id": 909,
        "no_speech_prob": 0.00530180474743247,
        "seek": 334400,
        "start": 3364,
        "temperature": 0,
        "text": " Now, if I just know all the answers, why would I even do this?",
        "tokens": [
          51364,
          823,
          11,
          498,
          286,
          445,
          458,
          439,
          264,
          6338,
          11,
          983,
          576,
          286,
          754,
          360,
          341,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.21500351245586688,
        "compression_ratio": 1.8884462151394423,
        "end": 3377,
        "id": 910,
        "no_speech_prob": 0.017983922734856606,
        "seek": 337000,
        "start": 3370,
        "temperature": 0,
        "text": " Well, likely there's a scenario, machine learning is going to be used with a scenario where I have a lot of labeled data.",
        "tokens": [
          50364,
          1042,
          11,
          3700,
          456,
          311,
          257,
          9005,
          11,
          3479,
          2539,
          307,
          516,
          281,
          312,
          1143,
          365,
          257,
          9005,
          689,
          286,
          362,
          257,
          688,
          295,
          21335,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21500351245586688,
        "compression_ratio": 1.8884462151394423,
        "end": 3386,
        "id": 911,
        "no_speech_prob": 0.017983922734856606,
        "seek": 337000,
        "start": 3377,
        "temperature": 0,
        "text": " I have a known data set that I can use to train this system, so that if I give it some unknown data, it will give me an output, a relevant output.",
        "tokens": [
          50714,
          286,
          362,
          257,
          2570,
          1412,
          992,
          300,
          286,
          393,
          764,
          281,
          3847,
          341,
          1185,
          11,
          370,
          300,
          498,
          286,
          976,
          309,
          512,
          9841,
          1412,
          11,
          309,
          486,
          976,
          385,
          364,
          5598,
          11,
          257,
          7340,
          5598,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21500351245586688,
        "compression_ratio": 1.8884462151394423,
        "end": 3390,
        "id": 912,
        "no_speech_prob": 0.017983922734856606,
        "seek": 337000,
        "start": 3386,
        "temperature": 0,
        "text": " Classic example of this, of course, is I have a whole bunch of images.",
        "tokens": [
          51164,
          25008,
          1365,
          295,
          341,
          11,
          295,
          1164,
          11,
          307,
          286,
          362,
          257,
          1379,
          3840,
          295,
          5267,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21500351245586688,
        "compression_ratio": 1.8884462151394423,
        "end": 3396,
        "id": 913,
        "no_speech_prob": 0.017983922734856606,
        "seek": 337000,
        "start": 3390,
        "temperature": 0,
        "text": " I'm going to say, here's a bunch of, I'm going to tell the recipe, here's a bunch of cats, here's a bunch of dogs, now here's a new...",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          584,
          11,
          510,
          311,
          257,
          3840,
          295,
          11,
          286,
          478,
          516,
          281,
          980,
          264,
          6782,
          11,
          510,
          311,
          257,
          3840,
          295,
          11111,
          11,
          510,
          311,
          257,
          3840,
          295,
          7197,
          11,
          586,
          510,
          311,
          257,
          777,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.2027095158894857,
        "compression_ratio": 1.522875816993464,
        "end": 3406,
        "id": 914,
        "no_speech_prob": 0.002216954715549946,
        "seek": 339600,
        "start": 3397,
        "temperature": 0,
        "text": " Here's a bunch of cats, here's a bunch of dogs, now here's a new image, which one is it?",
        "tokens": [
          50414,
          1692,
          311,
          257,
          3840,
          295,
          11111,
          11,
          510,
          311,
          257,
          3840,
          295,
          7197,
          11,
          586,
          510,
          311,
          257,
          777,
          3256,
          11,
          597,
          472,
          307,
          309,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2027095158894857,
        "compression_ratio": 1.522875816993464,
        "end": 3412,
        "id": 915,
        "no_speech_prob": 0.002216954715549946,
        "seek": 339600,
        "start": 3406,
        "temperature": 0,
        "text": " And along with this process, we will typically have training data.",
        "tokens": [
          50864,
          400,
          2051,
          365,
          341,
          1399,
          11,
          321,
          486,
          5850,
          362,
          3097,
          1412,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2027095158894857,
        "compression_ratio": 1.522875816993464,
        "end": 3416,
        "id": 916,
        "no_speech_prob": 0.002216954715549946,
        "seek": 339600,
        "start": 3412,
        "temperature": 0,
        "text": " This is labeled data for which we know the answer.",
        "tokens": [
          51164,
          639,
          307,
          21335,
          1412,
          337,
          597,
          321,
          458,
          264,
          1867,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2027095158894857,
        "compression_ratio": 1.522875816993464,
        "end": 3419,
        "id": 917,
        "no_speech_prob": 0.002216954715549946,
        "seek": 339600,
        "start": 3416,
        "temperature": 0,
        "text": " We will have testing data.",
        "tokens": [
          51364,
          492,
          486,
          362,
          4997,
          1412,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.195017173372466,
        "compression_ratio": 1.691699604743083,
        "end": 3426,
        "id": 918,
        "no_speech_prob": 0.10087110102176666,
        "seek": 341900,
        "start": 3419,
        "temperature": 0,
        "text": " This is data that we know the labels for, but we aren't using in the training set, so that we can see, is it working?",
        "tokens": [
          50364,
          639,
          307,
          1412,
          300,
          321,
          458,
          264,
          16949,
          337,
          11,
          457,
          321,
          3212,
          380,
          1228,
          294,
          264,
          3097,
          992,
          11,
          370,
          300,
          321,
          393,
          536,
          11,
          307,
          309,
          1364,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.195017173372466,
        "compression_ratio": 1.691699604743083,
        "end": 3430,
        "id": 919,
        "no_speech_prob": 0.10087110102176666,
        "seek": 341900,
        "start": 3426,
        "temperature": 0,
        "text": " Does it actually give us good outcomes with unknown data?",
        "tokens": [
          50714,
          4402,
          309,
          767,
          976,
          505,
          665,
          10070,
          365,
          9841,
          1412,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.195017173372466,
        "compression_ratio": 1.691699604743083,
        "end": 3435,
        "id": 920,
        "no_speech_prob": 0.10087110102176666,
        "seek": 341900,
        "start": 3430,
        "temperature": 0,
        "text": " And then, of course, we have the actual unknown new data that we want to use.",
        "tokens": [
          50914,
          400,
          550,
          11,
          295,
          1164,
          11,
          321,
          362,
          264,
          3539,
          9841,
          777,
          1412,
          300,
          321,
          528,
          281,
          764,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.195017173372466,
        "compression_ratio": 1.691699604743083,
        "end": 3438,
        "id": 921,
        "no_speech_prob": 0.10087110102176666,
        "seek": 341900,
        "start": 3435,
        "temperature": 0,
        "text": " Okay, so what's the scenario that I'm going to use?",
        "tokens": [
          51164,
          1033,
          11,
          370,
          437,
          311,
          264,
          9005,
          300,
          286,
          478,
          516,
          281,
          764,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.195017173372466,
        "compression_ratio": 1.691699604743083,
        "end": 3445,
        "id": 922,
        "no_speech_prob": 0.10087110102176666,
        "seek": 341900,
        "start": 3438,
        "temperature": 0,
        "text": " The trivial, almost rather ridiculous example that I'm going to use in this video is the XOR.",
        "tokens": [
          51314,
          440,
          26703,
          11,
          1920,
          2831,
          11083,
          1365,
          300,
          286,
          478,
          516,
          281,
          764,
          294,
          341,
          960,
          307,
          264,
          1783,
          2483,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.195017173372466,
        "compression_ratio": 1.691699604743083,
        "end": 3448,
        "id": 923,
        "no_speech_prob": 0.10087110102176666,
        "seek": 341900,
        "start": 3445,
        "temperature": 0,
        "text": " XOR stands for exclusive OR.",
        "tokens": [
          51664,
          1783,
          2483,
          7382,
          337,
          13005,
          19654,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1763926315307617,
        "compression_ratio": 1.6369426751592357,
        "end": 3453,
        "id": 924,
        "no_speech_prob": 0.002844882430508733,
        "seek": 344800,
        "start": 3448,
        "temperature": 0,
        "text": " It's a Boolean operation that resolves to true only if...",
        "tokens": [
          50364,
          467,
          311,
          257,
          23351,
          28499,
          6916,
          300,
          7923,
          977,
          281,
          2074,
          787,
          498,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.1763926315307617,
        "compression_ratio": 1.6369426751592357,
        "end": 3459,
        "id": 925,
        "no_speech_prob": 0.002844882430508733,
        "seek": 344800,
        "start": 3453,
        "temperature": 0,
        "text": " So you can think of true and if true XOR true is actually false.",
        "tokens": [
          50614,
          407,
          291,
          393,
          519,
          295,
          2074,
          293,
          498,
          2074,
          1783,
          2483,
          2074,
          307,
          767,
          7908,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1763926315307617,
        "compression_ratio": 1.6369426751592357,
        "end": 3461,
        "id": 926,
        "no_speech_prob": 0.002844882430508733,
        "seek": 344800,
        "start": 3459,
        "temperature": 0,
        "text": " I didn't finish my sentence.",
        "tokens": [
          50914,
          286,
          994,
          380,
          2413,
          452,
          8174,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1763926315307617,
        "compression_ratio": 1.6369426751592357,
        "end": 3472,
        "id": 927,
        "no_speech_prob": 0.002844882430508733,
        "seek": 344800,
        "start": 3461,
        "temperature": 0,
        "text": " It resolves to true only if one of the two Boolean expressions is true.",
        "tokens": [
          51014,
          467,
          7923,
          977,
          281,
          2074,
          787,
          498,
          472,
          295,
          264,
          732,
          23351,
          28499,
          15277,
          307,
          2074,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1763926315307617,
        "compression_ratio": 1.6369426751592357,
        "end": 3476,
        "id": 928,
        "no_speech_prob": 0.002844882430508733,
        "seek": 344800,
        "start": 3472,
        "temperature": 0,
        "text": " So false XOR false also is false.",
        "tokens": [
          51564,
          407,
          7908,
          1783,
          2483,
          7908,
          611,
          307,
          7908,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1729842484599412,
        "compression_ratio": 1.7606837606837606,
        "end": 3485,
        "id": 929,
        "no_speech_prob": 0.04145799204707146,
        "seek": 347600,
        "start": 3476,
        "temperature": 0,
        "text": " And if you go back to my video that's linked here about the perceptron, you'll see that this is a special problem",
        "tokens": [
          50364,
          400,
          498,
          291,
          352,
          646,
          281,
          452,
          960,
          300,
          311,
          9408,
          510,
          466,
          264,
          43276,
          2044,
          11,
          291,
          603,
          536,
          300,
          341,
          307,
          257,
          2121,
          1154,
          50814
        ]
      },
      {
        "avg_logprob": -0.1729842484599412,
        "compression_ratio": 1.7606837606837606,
        "end": 3493,
        "id": 930,
        "no_speech_prob": 0.04145799204707146,
        "seek": 347600,
        "start": 3485,
        "temperature": 0,
        "text": " because a single simple perceptron, a single neuron machine learning system cannot solve this problem.",
        "tokens": [
          50814,
          570,
          257,
          2167,
          2199,
          43276,
          2044,
          11,
          257,
          2167,
          34090,
          3479,
          2539,
          1185,
          2644,
          5039,
          341,
          1154,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1729842484599412,
        "compression_ratio": 1.7606837606837606,
        "end": 3495,
        "id": 931,
        "no_speech_prob": 0.04145799204707146,
        "seek": 347600,
        "start": 3493,
        "temperature": 0,
        "text": " It is not linearly separable.",
        "tokens": [
          51214,
          467,
          307,
          406,
          43586,
          3128,
          712,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1729842484599412,
        "compression_ratio": 1.7606837606837606,
        "end": 3501,
        "id": 932,
        "no_speech_prob": 0.04145799204707146,
        "seek": 347600,
        "start": 3495,
        "temperature": 0,
        "text": " The solution space is not a space where you can just draw a line and see all the categories of one on one side",
        "tokens": [
          51314,
          440,
          3827,
          1901,
          307,
          406,
          257,
          1901,
          689,
          291,
          393,
          445,
          2642,
          257,
          1622,
          293,
          536,
          439,
          264,
          10479,
          295,
          472,
          322,
          472,
          1252,
          51614
        ]
      },
      {
        "avg_logprob": -0.1729842484599412,
        "compression_ratio": 1.7606837606837606,
        "end": 3503,
        "id": 933,
        "no_speech_prob": 0.04145799204707146,
        "seek": 347600,
        "start": 3501,
        "temperature": 0,
        "text": " and all the categories of the other on the other side.",
        "tokens": [
          51614,
          293,
          439,
          264,
          10479,
          295,
          264,
          661,
          322,
          264,
          661,
          1252,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1861657528650193,
        "compression_ratio": 1.6173469387755102,
        "end": 3512,
        "id": 934,
        "no_speech_prob": 0.02931111492216587,
        "seek": 350300,
        "start": 3503,
        "temperature": 0,
        "text": " So you can dive into that deeper but this is where a neural network that involves a hidden layer can be used as the machine learning recipe.",
        "tokens": [
          50364,
          407,
          291,
          393,
          9192,
          666,
          300,
          7731,
          457,
          341,
          307,
          689,
          257,
          18161,
          3209,
          300,
          11626,
          257,
          7633,
          4583,
          393,
          312,
          1143,
          382,
          264,
          3479,
          2539,
          6782,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1861657528650193,
        "compression_ratio": 1.6173469387755102,
        "end": 3515,
        "id": 935,
        "no_speech_prob": 0.02931111492216587,
        "seek": 350300,
        "start": 3512,
        "temperature": 0,
        "text": " So what I mean by this is I need my training set.",
        "tokens": [
          50814,
          407,
          437,
          286,
          914,
          538,
          341,
          307,
          286,
          643,
          452,
          3097,
          992,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1861657528650193,
        "compression_ratio": 1.6173469387755102,
        "end": 3528,
        "id": 936,
        "no_speech_prob": 0.02931111492216587,
        "seek": 350300,
        "start": 3515,
        "temperature": 0,
        "text": " My training set is going to be 0 0 0 1 1 0 1 1.",
        "tokens": [
          50964,
          1222,
          3097,
          992,
          307,
          516,
          281,
          312,
          1958,
          1958,
          1958,
          502,
          502,
          1958,
          502,
          502,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1861657528650193,
        "compression_ratio": 1.6173469387755102,
        "end": 3532,
        "id": 937,
        "no_speech_prob": 0.02931111492216587,
        "seek": 350300,
        "start": 3528,
        "temperature": 0,
        "text": " I only have four elements in my training set and each one of these is labeled.",
        "tokens": [
          51614,
          286,
          787,
          362,
          1451,
          4959,
          294,
          452,
          3097,
          992,
          293,
          1184,
          472,
          295,
          613,
          307,
          21335,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3534,
        "id": 938,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3532,
        "temperature": 0,
        "text": " This is labeled with a 0.",
        "tokens": [
          50364,
          639,
          307,
          21335,
          365,
          257,
          1958,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3538,
        "id": 939,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3534,
        "temperature": 0,
        "text": " This is labeled with a 1.",
        "tokens": [
          50464,
          639,
          307,
          21335,
          365,
          257,
          502,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3541,
        "id": 940,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3538,
        "temperature": 0,
        "text": " This is labeled with a 1 and this is labeled with a 0.",
        "tokens": [
          50664,
          639,
          307,
          21335,
          365,
          257,
          502,
          293,
          341,
          307,
          21335,
          365,
          257,
          1958,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3543,
        "id": 941,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3541,
        "temperature": 0,
        "text": " This is the known data.",
        "tokens": [
          50814,
          639,
          307,
          264,
          2570,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3546,
        "id": 942,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3543,
        "temperature": 0,
        "text": " Again, this is a sort of trivial.",
        "tokens": [
          50914,
          3764,
          11,
          341,
          307,
          257,
          1333,
          295,
          26703,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3549,
        "id": 943,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3546,
        "temperature": 0,
        "text": " You could build a circuit.",
        "tokens": [
          51064,
          509,
          727,
          1322,
          257,
          9048,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3555,
        "id": 944,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3549,
        "temperature": 0,
        "text": " Imagine what it would take to build a circuit with two switches and the LED only lights up if one switch is on.",
        "tokens": [
          51214,
          11739,
          437,
          309,
          576,
          747,
          281,
          1322,
          257,
          9048,
          365,
          732,
          19458,
          293,
          264,
          11261,
          787,
          5811,
          493,
          498,
          472,
          3679,
          307,
          322,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3557,
        "id": 945,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3555,
        "temperature": 0,
        "text": " If they're both on it doesn't light up.",
        "tokens": [
          51514,
          759,
          436,
          434,
          1293,
          322,
          309,
          1177,
          380,
          1442,
          493,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3558,
        "id": 946,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3557,
        "temperature": 0,
        "text": " If they're both off it doesn't light up.",
        "tokens": [
          51614,
          759,
          436,
          434,
          1293,
          766,
          309,
          1177,
          380,
          1442,
          493,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19101904296875,
        "compression_ratio": 1.990566037735849,
        "end": 3559,
        "id": 947,
        "no_speech_prob": 0.020645037293434143,
        "seek": 353200,
        "start": 3558,
        "temperature": 0,
        "text": " Think about how you might build that.",
        "tokens": [
          51664,
          6557,
          466,
          577,
          291,
          1062,
          1322,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2124620510053031,
        "compression_ratio": 1.837837837837838,
        "end": 3566,
        "id": 948,
        "no_speech_prob": 0.014728336594998837,
        "seek": 355900,
        "start": 3559,
        "temperature": 0,
        "text": " That's essentially the going that that diagram of that circuit is essentially what we want the neural network to look like.",
        "tokens": [
          50364,
          663,
          311,
          4476,
          264,
          516,
          300,
          300,
          10686,
          295,
          300,
          9048,
          307,
          4476,
          437,
          321,
          528,
          264,
          18161,
          3209,
          281,
          574,
          411,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2124620510053031,
        "compression_ratio": 1.837837837837838,
        "end": 3581,
        "id": 949,
        "no_speech_prob": 0.014728336594998837,
        "seek": 355900,
        "start": 3566,
        "temperature": 0,
        "text": " So the way that it's going to look and let me erase this here is we can see here in my labeled data set that there are two inputs and one output.",
        "tokens": [
          50714,
          407,
          264,
          636,
          300,
          309,
          311,
          516,
          281,
          574,
          293,
          718,
          385,
          23525,
          341,
          510,
          307,
          321,
          393,
          536,
          510,
          294,
          452,
          21335,
          1412,
          992,
          300,
          456,
          366,
          732,
          15743,
          293,
          472,
          5598,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2124620510053031,
        "compression_ratio": 1.837837837837838,
        "end": 3586,
        "id": 950,
        "no_speech_prob": 0.014728336594998837,
        "seek": 355900,
        "start": 3581,
        "temperature": 0,
        "text": " So the neural network structure has to have two inputs and one output.",
        "tokens": [
          51464,
          407,
          264,
          18161,
          3209,
          3877,
          575,
          281,
          362,
          732,
          15743,
          293,
          472,
          5598,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3589,
        "id": 951,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3586,
        "temperature": 0,
        "text": " I'm going to send in X1 and X2.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          2845,
          294,
          1783,
          16,
          293,
          1783,
          17,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3595,
        "id": 952,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3589,
        "temperature": 0,
        "text": " These are true and true, true and false, false or true and somehow out of this I should get a Y.",
        "tokens": [
          50514,
          1981,
          366,
          2074,
          293,
          2074,
          11,
          2074,
          293,
          7908,
          11,
          7908,
          420,
          2074,
          293,
          6063,
          484,
          295,
          341,
          286,
          820,
          483,
          257,
          398,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3597,
        "id": 953,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3595,
        "temperature": 0,
        "text": " I should get a true or false.",
        "tokens": [
          50814,
          286,
          820,
          483,
          257,
          2074,
          420,
          7908,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3605,
        "id": 954,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3597,
        "temperature": 0,
        "text": " So how you architect and structural a neural network system this is something that I've gone into much more depth in the other videos.",
        "tokens": [
          50914,
          407,
          577,
          291,
          6331,
          293,
          15067,
          257,
          18161,
          3209,
          1185,
          341,
          307,
          746,
          300,
          286,
          600,
          2780,
          666,
          709,
          544,
          7161,
          294,
          264,
          661,
          2145,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3609,
        "id": 955,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3605,
        "temperature": 0,
        "text": " But the key to this problem is having what's known as a hidden layer.",
        "tokens": [
          51314,
          583,
          264,
          2141,
          281,
          341,
          1154,
          307,
          1419,
          437,
          311,
          2570,
          382,
          257,
          7633,
          4583,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3610,
        "id": 956,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3609,
        "temperature": 0,
        "text": " So the inputs come in here.",
        "tokens": [
          51514,
          407,
          264,
          15743,
          808,
          294,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1730892151359498,
        "compression_ratio": 1.6989247311827957,
        "end": 3615,
        "id": 957,
        "no_speech_prob": 0.1311657428741455,
        "seek": 358600,
        "start": 3610,
        "temperature": 0,
        "text": " I want to look at the output here but these neurons are going to exist in between.",
        "tokens": [
          51564,
          286,
          528,
          281,
          574,
          412,
          264,
          5598,
          510,
          457,
          613,
          22027,
          366,
          516,
          281,
          2514,
          294,
          1296,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3620,
        "id": 958,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3615,
        "temperature": 0,
        "text": " So everything this is also what's known as a fully connected network.",
        "tokens": [
          50364,
          407,
          1203,
          341,
          307,
          611,
          437,
          311,
          2570,
          382,
          257,
          4498,
          4582,
          3209,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3624,
        "id": 959,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3620,
        "temperature": 0,
        "text": " So as the inputs come here they both go into this hidden layer.",
        "tokens": [
          50614,
          407,
          382,
          264,
          15743,
          808,
          510,
          436,
          1293,
          352,
          666,
          341,
          7633,
          4583,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3626,
        "id": 960,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3624,
        "temperature": 0,
        "text": " Some math happens.",
        "tokens": [
          50814,
          2188,
          5221,
          2314,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3628,
        "id": 961,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3626,
        "temperature": 0,
        "text": " This is the math that I go over in a previous video.",
        "tokens": [
          50914,
          639,
          307,
          264,
          5221,
          300,
          286,
          352,
          670,
          294,
          257,
          3894,
          960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3630,
        "id": 962,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3628,
        "temperature": 0,
        "text": " It has to do with multiplying by weights.",
        "tokens": [
          51014,
          467,
          575,
          281,
          360,
          365,
          30955,
          538,
          17443,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3632,
        "id": 963,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3630,
        "temperature": 0,
        "text": " These are all weighted connections.",
        "tokens": [
          51114,
          1981,
          366,
          439,
          32807,
          9271,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3637,
        "id": 964,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3632,
        "temperature": 0,
        "text": " Then those go into this output layer and we get the answer.",
        "tokens": [
          51214,
          1396,
          729,
          352,
          666,
          341,
          5598,
          4583,
          293,
          321,
          483,
          264,
          1867,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3639,
        "id": 965,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3637,
        "temperature": 0,
        "text": " And then there is a training process.",
        "tokens": [
          51464,
          400,
          550,
          456,
          307,
          257,
          3097,
          1399,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20138874760380499,
        "compression_ratio": 1.6639344262295082,
        "end": 3641,
        "id": 966,
        "no_speech_prob": 0.001700692460872233,
        "seek": 361500,
        "start": 3639,
        "temperature": 0,
        "text": " We say try it with this.",
        "tokens": [
          51564,
          492,
          584,
          853,
          309,
          365,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3646,
        "id": 967,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3641,
        "temperature": 0,
        "text": " Internally in the training process what it does is if I give it 0, 0 with a 0 and it outputs a 1.",
        "tokens": [
          50364,
          4844,
          379,
          294,
          264,
          3097,
          1399,
          437,
          309,
          775,
          307,
          498,
          286,
          976,
          309,
          1958,
          11,
          1958,
          365,
          257,
          1958,
          293,
          309,
          23930,
          257,
          502,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3648,
        "id": 968,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3646,
        "temperature": 0,
        "text": " It's like I tell it hey you got that wrong.",
        "tokens": [
          50614,
          467,
          311,
          411,
          286,
          980,
          309,
          4177,
          291,
          658,
          300,
          2085,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3652,
        "id": 969,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3648,
        "temperature": 0,
        "text": " Adjust all those weights to try to see if you can get it more correct.",
        "tokens": [
          50714,
          34049,
          439,
          729,
          17443,
          281,
          853,
          281,
          536,
          498,
          291,
          393,
          483,
          309,
          544,
          3006,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3657,
        "id": 970,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3652,
        "temperature": 0,
        "text": " So what we're going to do is over and over again to train it to see if we can then later.",
        "tokens": [
          50914,
          407,
          437,
          321,
          434,
          516,
          281,
          360,
          307,
          670,
          293,
          670,
          797,
          281,
          3847,
          309,
          281,
          536,
          498,
          321,
          393,
          550,
          1780,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3660,
        "id": 971,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3657,
        "temperature": 0,
        "text": " We don't have a separate training and testing set in this scenario.",
        "tokens": [
          51164,
          492,
          500,
          380,
          362,
          257,
          4994,
          3097,
          293,
          4997,
          992,
          294,
          341,
          9005,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3666,
        "id": 972,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3660,
        "temperature": 0,
        "text": " We're just going to say I'm going to train it and see if you can start producing the correct answers for all of these numbers.",
        "tokens": [
          51314,
          492,
          434,
          445,
          516,
          281,
          584,
          286,
          478,
          516,
          281,
          3847,
          309,
          293,
          536,
          498,
          291,
          393,
          722,
          10501,
          264,
          3006,
          6338,
          337,
          439,
          295,
          613,
          3547,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3667,
        "id": 973,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3666,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19680991140352624,
        "compression_ratio": 1.739413680781759,
        "end": 3668,
        "id": 974,
        "no_speech_prob": 0.7877256870269775,
        "seek": 364100,
        "start": 3667,
        "temperature": 0,
        "text": " That's the background for XOR.",
        "tokens": [
          51664,
          663,
          311,
          264,
          3678,
          337,
          1783,
          2483,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23227998484735904,
        "compression_ratio": 1.4768211920529801,
        "end": 3674,
        "id": 975,
        "no_speech_prob": 0.11754975467920303,
        "seek": 366800,
        "start": 3668,
        "temperature": 0,
        "text": " Now I'm actually going to go and write the code to do all of this and hope that it works.",
        "tokens": [
          50364,
          823,
          286,
          478,
          767,
          516,
          281,
          352,
          293,
          2464,
          264,
          3089,
          281,
          360,
          439,
          295,
          341,
          293,
          1454,
          300,
          309,
          1985,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23227998484735904,
        "compression_ratio": 1.4768211920529801,
        "end": 3677,
        "id": 976,
        "no_speech_prob": 0.11754975467920303,
        "seek": 366800,
        "start": 3674,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23227998484735904,
        "compression_ratio": 1.4768211920529801,
        "end": 3684,
        "id": 977,
        "no_speech_prob": 0.11754975467920303,
        "seek": 366800,
        "start": 3677,
        "temperature": 0,
        "text": " So how's it going here?",
        "tokens": [
          50814,
          407,
          577,
          311,
          309,
          516,
          510,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.23227998484735904,
        "compression_ratio": 1.4768211920529801,
        "end": 3694,
        "id": 978,
        "no_speech_prob": 0.11754975467920303,
        "seek": 366800,
        "start": 3684,
        "temperature": 0,
        "text": " I just want to see did I miss anything kind of crucial there?",
        "tokens": [
          51164,
          286,
          445,
          528,
          281,
          536,
          630,
          286,
          1713,
          1340,
          733,
          295,
          11462,
          456,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.23227998484735904,
        "compression_ratio": 1.4768211920529801,
        "end": 3696,
        "id": 979,
        "no_speech_prob": 0.11754975467920303,
        "seek": 366800,
        "start": 3694,
        "temperature": 0,
        "text": " I'm going to go and do the code part now.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          352,
          293,
          360,
          264,
          3089,
          644,
          586,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3708,
        "id": 980,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3696,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3709,
        "id": 981,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3708,
        "temperature": 0,
        "text": " Sounds pretty good to me.",
        "tokens": [
          50964,
          14576,
          1238,
          665,
          281,
          385,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3710,
        "id": 982,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3709,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3711,
        "id": 983,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3710,
        "temperature": 0,
        "text": " Ringing endorsement.",
        "tokens": [
          51064,
          497,
          8716,
          29228,
          518,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3716,
        "id": 984,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3711,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3718,
        "id": 985,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3716,
        "temperature": 0,
        "text": " So you might recall that I started the video.",
        "tokens": [
          51364,
          407,
          291,
          1062,
          9901,
          300,
          286,
          1409,
          264,
          960,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3719,
        "id": 986,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3718,
        "temperature": 0,
        "text": " I had this thing up here.",
        "tokens": [
          51464,
          286,
          632,
          341,
          551,
          493,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22639740535191127,
        "compression_ratio": 1.4782608695652173,
        "end": 3723,
        "id": 987,
        "no_speech_prob": 0.05339875817298889,
        "seek": 369600,
        "start": 3719,
        "temperature": 0,
        "text": " So this is actually an example that I made in the processing Java based programming environment.",
        "tokens": [
          51514,
          407,
          341,
          307,
          767,
          364,
          1365,
          300,
          286,
          1027,
          294,
          264,
          9007,
          10745,
          2361,
          9410,
          2823,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3727,
        "id": 988,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3724,
        "temperature": 0,
        "text": " I probably like almost eight years ago at this point.",
        "tokens": [
          50414,
          286,
          1391,
          411,
          1920,
          3180,
          924,
          2057,
          412,
          341,
          935,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3731,
        "id": 989,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3727,
        "temperature": 0,
        "text": " So it's not using the same code base but it's actually solved the XOR problem.",
        "tokens": [
          50564,
          407,
          309,
          311,
          406,
          1228,
          264,
          912,
          3089,
          3096,
          457,
          309,
          311,
          767,
          13041,
          264,
          1783,
          2483,
          1154,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3737,
        "id": 990,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3731,
        "temperature": 0,
        "text": " And what's interesting about this and I'm going to come back to the whiteboard just for one more moment here.",
        "tokens": [
          50764,
          400,
          437,
          311,
          1880,
          466,
          341,
          293,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          264,
          2418,
          3787,
          445,
          337,
          472,
          544,
          1623,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3739,
        "id": 991,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3737,
        "temperature": 0,
        "text": " Let me find some room here.",
        "tokens": [
          51064,
          961,
          385,
          915,
          512,
          1808,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3745,
        "id": 992,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3739,
        "temperature": 0,
        "text": " If I draw a plane and I consider this to be 0, 0 and this to be 1, 1.",
        "tokens": [
          51164,
          759,
          286,
          2642,
          257,
          5720,
          293,
          286,
          1949,
          341,
          281,
          312,
          1958,
          11,
          1958,
          293,
          341,
          281,
          312,
          502,
          11,
          502,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3749,
        "id": 993,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3745,
        "temperature": 0,
        "text": " So this is 1, 0 and this is 0, 1.",
        "tokens": [
          51464,
          407,
          341,
          307,
          502,
          11,
          1958,
          293,
          341,
          307,
          1958,
          11,
          502,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1932542031271416,
        "compression_ratio": 1.6008403361344539,
        "end": 3751,
        "id": 994,
        "no_speech_prob": 0.861411988735199,
        "seek": 372300,
        "start": 3749,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51664,
          1779,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3761,
        "id": 995,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3751,
        "temperature": 0,
        "text": " Notice that if I take this idea of XOR and map it to here, I've got false here, false here, true here and true here.",
        "tokens": [
          50364,
          13428,
          300,
          498,
          286,
          747,
          341,
          1558,
          295,
          1783,
          2483,
          293,
          4471,
          309,
          281,
          510,
          11,
          286,
          600,
          658,
          7908,
          510,
          11,
          7908,
          510,
          11,
          2074,
          510,
          293,
          2074,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3763,
        "id": 996,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3761,
        "temperature": 0,
        "text": " And by the way, what did I write at 1 there?",
        "tokens": [
          50864,
          400,
          538,
          264,
          636,
          11,
          437,
          630,
          286,
          2464,
          412,
          502,
          456,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3765,
        "id": 997,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3763,
        "temperature": 0,
        "text": " 2 here and true here.",
        "tokens": [
          50964,
          568,
          510,
          293,
          2074,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3767,
        "id": 998,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3765,
        "temperature": 0,
        "text": " This, by the way, is why it's not linearly separable.",
        "tokens": [
          51064,
          639,
          11,
          538,
          264,
          636,
          11,
          307,
          983,
          309,
          311,
          406,
          43586,
          3128,
          712,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3769,
        "id": 999,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3767,
        "temperature": 0,
        "text": " You can't draw a line.",
        "tokens": [
          51164,
          509,
          393,
          380,
          2642,
          257,
          1622,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3772,
        "id": 1000,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3769,
        "temperature": 0,
        "text": " I can draw two lines like this or I can draw two lines like this.",
        "tokens": [
          51264,
          286,
          393,
          2642,
          732,
          3876,
          411,
          341,
          420,
          286,
          393,
          2642,
          732,
          3876,
          411,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3776,
        "id": 1001,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3772,
        "temperature": 0,
        "text": " You're going to see that result happen actually as I start to program this.",
        "tokens": [
          51414,
          509,
          434,
          516,
          281,
          536,
          300,
          1874,
          1051,
          767,
          382,
          286,
          722,
          281,
          1461,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18090112507343292,
        "compression_ratio": 1.773109243697479,
        "end": 3777,
        "id": 1002,
        "no_speech_prob": 0.10668647289276123,
        "seek": 375100,
        "start": 3776,
        "temperature": 0,
        "text": " I hope if it works.",
        "tokens": [
          51614,
          286,
          1454,
          498,
          309,
          1985,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3784,
        "id": 1003,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3777,
        "temperature": 0,
        "text": " But what this idea of a plane, this is a plane that's describing the whole solution space for the problem.",
        "tokens": [
          50364,
          583,
          437,
          341,
          1558,
          295,
          257,
          5720,
          11,
          341,
          307,
          257,
          5720,
          300,
          311,
          16141,
          264,
          1379,
          3827,
          1901,
          337,
          264,
          1154,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3786,
        "id": 1004,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3784,
        "temperature": 0,
        "text": " And if you come back over here, you'll see.",
        "tokens": [
          50714,
          400,
          498,
          291,
          808,
          646,
          670,
          510,
          11,
          291,
          603,
          536,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3787,
        "id": 1005,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3786,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          50814,
          2053,
          412,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3791,
        "id": 1006,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3787,
        "temperature": 0,
        "text": " Those corners, if I bring this over closer to me, I can try to point to it.",
        "tokens": [
          50864,
          3950,
          12413,
          11,
          498,
          286,
          1565,
          341,
          670,
          4966,
          281,
          385,
          11,
          286,
          393,
          853,
          281,
          935,
          281,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3794,
        "id": 1007,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3791,
        "temperature": 0,
        "text": " These corners are the true corners.",
        "tokens": [
          51064,
          1981,
          12413,
          366,
          264,
          2074,
          12413,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3795,
        "id": 1008,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3794,
        "temperature": 0,
        "text": " I need more practice.",
        "tokens": [
          51214,
          286,
          643,
          544,
          3124,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3798,
        "id": 1009,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3795,
        "temperature": 0,
        "text": " And these corners are the false corners.",
        "tokens": [
          51264,
          400,
          613,
          12413,
          366,
          264,
          7908,
          12413,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3800,
        "id": 1010,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3798,
        "temperature": 0,
        "text": " And this plane is all the other solutions.",
        "tokens": [
          51414,
          400,
          341,
          5720,
          307,
          439,
          264,
          661,
          6547,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3802,
        "id": 1011,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3800,
        "temperature": 0,
        "text": " Now this is a 3D rendering.",
        "tokens": [
          51514,
          823,
          341,
          307,
          257,
          805,
          35,
          22407,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3803,
        "id": 1012,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3802,
        "temperature": 0,
        "text": " It's doing some fancy stuff.",
        "tokens": [
          51614,
          467,
          311,
          884,
          512,
          10247,
          1507,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16947480906610904,
        "compression_ratio": 1.7545126353790614,
        "end": 3805,
        "id": 1013,
        "no_speech_prob": 0.4186491072177887,
        "seek": 377700,
        "start": 3803,
        "temperature": 0,
        "text": " I'm going to create a simpler version of this.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          1884,
          257,
          18587,
          3037,
          295,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3807,
        "id": 1014,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3805,
        "temperature": 0,
        "text": " So let's just actually start doing that.",
        "tokens": [
          50364,
          407,
          718,
          311,
          445,
          767,
          722,
          884,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3814,
        "id": 1015,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3809,
        "temperature": 0,
        "text": " So what you're going to need first of all is if you're writing this code along with me,",
        "tokens": [
          50564,
          407,
          437,
          291,
          434,
          516,
          281,
          643,
          700,
          295,
          439,
          307,
          498,
          291,
          434,
          3579,
          341,
          3089,
          2051,
          365,
          385,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3818,
        "id": 1016,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3814,
        "temperature": 0,
        "text": " you're going to need to have the toy neural network JS library.",
        "tokens": [
          50814,
          291,
          434,
          516,
          281,
          643,
          281,
          362,
          264,
          12058,
          18161,
          3209,
          33063,
          6405,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3821,
        "id": 1017,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3818,
        "temperature": 0,
        "text": " It has really just two files that you need.",
        "tokens": [
          51014,
          467,
          575,
          534,
          445,
          732,
          7098,
          300,
          291,
          643,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3825,
        "id": 1018,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3821,
        "temperature": 0,
        "text": " It has neural network.js and nn.js and matrix.js.",
        "tokens": [
          51164,
          467,
          575,
          18161,
          3209,
          13,
          25530,
          293,
          297,
          77,
          13,
          25530,
          293,
          8141,
          13,
          25530,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3826,
        "id": 1019,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3825,
        "temperature": 0,
        "text": " You can ignore this.",
        "tokens": [
          51364,
          509,
          393,
          11200,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3827,
        "id": 1020,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3826,
        "temperature": 0,
        "text": " This is for testing.",
        "tokens": [
          51414,
          639,
          307,
          337,
          4997,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17120217854997752,
        "compression_ratio": 1.7264957264957266,
        "end": 3830,
        "id": 1021,
        "no_speech_prob": 0.0015487109776586294,
        "seek": 380500,
        "start": 3827,
        "temperature": 0,
        "text": " That's something I cover in some other videos that you could probably find.",
        "tokens": [
          51464,
          663,
          311,
          746,
          286,
          2060,
          294,
          512,
          661,
          2145,
          300,
          291,
          727,
          1391,
          915,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3838,
        "id": 1022,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3831,
        "temperature": 0,
        "text": " And you'll see that in my index.html file, I am referencing those two JavaScript files.",
        "tokens": [
          50414,
          400,
          291,
          603,
          536,
          300,
          294,
          452,
          8186,
          13,
          357,
          15480,
          3991,
          11,
          286,
          669,
          40582,
          729,
          732,
          15778,
          7098,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3844,
        "id": 1023,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3838,
        "temperature": 0,
        "text": " I've got like a weird path thing going on, but when I publish the code, I'll publish it all as one thing.",
        "tokens": [
          50764,
          286,
          600,
          658,
          411,
          257,
          3657,
          3100,
          551,
          516,
          322,
          11,
          457,
          562,
          286,
          11374,
          264,
          3089,
          11,
          286,
          603,
          11374,
          309,
          439,
          382,
          472,
          551,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3845,
        "id": 1024,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3844,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3848,
        "id": 1025,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3845,
        "temperature": 0,
        "text": " So now I need to go over to sketch.js.",
        "tokens": [
          51114,
          407,
          586,
          286,
          643,
          281,
          352,
          670,
          281,
          12325,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3849,
        "id": 1026,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3848,
        "temperature": 0,
        "text": " Let's do some stuff here.",
        "tokens": [
          51264,
          961,
          311,
          360,
          512,
          1507,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3851,
        "id": 1027,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3849,
        "temperature": 0,
        "text": " Let's write a setup function.",
        "tokens": [
          51314,
          961,
          311,
          2464,
          257,
          8657,
          2445,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3854,
        "id": 1028,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3851,
        "temperature": 0,
        "text": " Let's write a draw function.",
        "tokens": [
          51414,
          961,
          311,
          2464,
          257,
          2642,
          2445,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3857,
        "id": 1029,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3854,
        "temperature": 0,
        "text": " Let's say let.",
        "tokens": [
          51564,
          961,
          311,
          584,
          718,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18185271246958587,
        "compression_ratio": 1.6160337552742616,
        "end": 3859,
        "id": 1030,
        "no_speech_prob": 0.006488137412816286,
        "seek": 383000,
        "start": 3857,
        "temperature": 0,
        "text": " I'm going to have a neural network variable.",
        "tokens": [
          51714,
          286,
          478,
          516,
          281,
          362,
          257,
          18161,
          3209,
          7006,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3863,
        "id": 1031,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3859,
        "temperature": 0,
        "text": " I'm going to say create canvas 400, 400.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          1884,
          16267,
          8423,
          11,
          8423,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3865,
        "id": 1032,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3863,
        "temperature": 0,
        "text": " Let's draw a background of zero.",
        "tokens": [
          50564,
          961,
          311,
          2642,
          257,
          3678,
          295,
          4018,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3869,
        "id": 1033,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3865,
        "temperature": 0,
        "text": " And let's go to the browser and see.",
        "tokens": [
          50664,
          400,
          718,
          311,
          352,
          281,
          264,
          11185,
          293,
          536,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3870,
        "id": 1034,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3869,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50864,
          821,
          321,
          352,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3871,
        "id": 1035,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3870,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          50914,
          821,
          309,
          307,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3873,
        "id": 1036,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3871,
        "temperature": 0,
        "text": " Step one.",
        "tokens": [
          50964,
          5470,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3875,
        "id": 1037,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3873,
        "temperature": 0,
        "text": " Now what I want to do is create a neural network.",
        "tokens": [
          51064,
          823,
          437,
          286,
          528,
          281,
          360,
          307,
          1884,
          257,
          18161,
          3209,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3878,
        "id": 1038,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3875,
        "temperature": 0,
        "text": " And I've written out how I want to create it.",
        "tokens": [
          51164,
          400,
          286,
          600,
          3720,
          484,
          577,
          286,
          528,
          281,
          1884,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16744649041559279,
        "compression_ratio": 1.523076923076923,
        "end": 3884,
        "id": 1039,
        "no_speech_prob": 0.0003920393355656415,
        "seek": 385900,
        "start": 3878,
        "temperature": 0,
        "text": " I want two inputs, two hidden neurons, and one output.",
        "tokens": [
          51314,
          286,
          528,
          732,
          15743,
          11,
          732,
          7633,
          22027,
          11,
          293,
          472,
          5598,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16498560008436147,
        "compression_ratio": 1.6951219512195121,
        "end": 3890,
        "id": 1040,
        "no_speech_prob": 0.02556474879384041,
        "seek": 388400,
        "start": 3884,
        "temperature": 0,
        "text": " So the neural network library, the toy library that I've built, expects those as arguments to the constructor.",
        "tokens": [
          50364,
          407,
          264,
          18161,
          3209,
          6405,
          11,
          264,
          12058,
          6405,
          300,
          286,
          600,
          3094,
          11,
          33280,
          729,
          382,
          12869,
          281,
          264,
          47479,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16498560008436147,
        "compression_ratio": 1.6951219512195121,
        "end": 3899,
        "id": 1041,
        "no_speech_prob": 0.02556474879384041,
        "seek": 388400,
        "start": 3890,
        "temperature": 0,
        "text": " So I can say neural network equals a new neural network with two inputs, two hidden neurons, and one output neuron.",
        "tokens": [
          50664,
          407,
          286,
          393,
          584,
          18161,
          3209,
          6915,
          257,
          777,
          18161,
          3209,
          365,
          732,
          15743,
          11,
          732,
          7633,
          22027,
          11,
          293,
          472,
          5598,
          34090,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16498560008436147,
        "compression_ratio": 1.6951219512195121,
        "end": 3906,
        "id": 1042,
        "no_speech_prob": 0.02556474879384041,
        "seek": 388400,
        "start": 3899,
        "temperature": 0,
        "text": " Now I should mention that modern so-called deep learning systems often have many, many, many hidden layers.",
        "tokens": [
          51114,
          823,
          286,
          820,
          2152,
          300,
          4363,
          370,
          12,
          11880,
          2452,
          2539,
          3652,
          2049,
          362,
          867,
          11,
          867,
          11,
          867,
          7633,
          7914,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16498560008436147,
        "compression_ratio": 1.6951219512195121,
        "end": 3908,
        "id": 1043,
        "no_speech_prob": 0.02556474879384041,
        "seek": 388400,
        "start": 3906,
        "temperature": 0,
        "text": " Hundreds of hidden nodes.",
        "tokens": [
          51464,
          45785,
          295,
          7633,
          13891,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16498560008436147,
        "compression_ratio": 1.6951219512195121,
        "end": 3910,
        "id": 1044,
        "no_speech_prob": 0.02556474879384041,
        "seek": 388400,
        "start": 3908,
        "temperature": 0,
        "text": " Big, massive networks.",
        "tokens": [
          51564,
          5429,
          11,
          5994,
          9590,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16498560008436147,
        "compression_ratio": 1.6951219512195121,
        "end": 3912,
        "id": 1045,
        "no_speech_prob": 0.02556474879384041,
        "seek": 388400,
        "start": 3910,
        "temperature": 0,
        "text": " This is a very small, simple one.",
        "tokens": [
          51664,
          639,
          307,
          257,
          588,
          1359,
          11,
          2199,
          472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3916,
        "id": 1046,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3912,
        "temperature": 0,
        "text": " The library only supports networks with these two layers.",
        "tokens": [
          50364,
          440,
          6405,
          787,
          9346,
          9590,
          365,
          613,
          732,
          7914,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3918,
        "id": 1047,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3916,
        "temperature": 0,
        "text": " If you consider the input, you could say three.",
        "tokens": [
          50564,
          759,
          291,
          1949,
          264,
          4846,
          11,
          291,
          727,
          584,
          1045,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3920,
        "id": 1048,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3918,
        "temperature": 0,
        "text": " But really these were the layers.",
        "tokens": [
          50664,
          583,
          534,
          613,
          645,
          264,
          7914,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3924,
        "id": 1049,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3920,
        "temperature": 0,
        "text": " The hidden and the output plus the inputs, three things.",
        "tokens": [
          50764,
          440,
          7633,
          293,
          264,
          5598,
          1804,
          264,
          15743,
          11,
          1045,
          721,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3925,
        "id": 1050,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3924,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3926,
        "id": 1051,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3925,
        "temperature": 0,
        "text": " Now what do I need to do?",
        "tokens": [
          51014,
          823,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3928,
        "id": 1052,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3926,
        "temperature": 0,
        "text": " I need my training data.",
        "tokens": [
          51064,
          286,
          643,
          452,
          3097,
          1412,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3933,
        "id": 1053,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3928,
        "temperature": 0,
        "text": " So I'm going to say let training equal, and I want to have it be in an array.",
        "tokens": [
          51164,
          407,
          286,
          478,
          516,
          281,
          584,
          718,
          3097,
          2681,
          11,
          293,
          286,
          528,
          281,
          362,
          309,
          312,
          294,
          364,
          10225,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3936,
        "id": 1054,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3933,
        "temperature": 0,
        "text": " And each element of the array, I want it to be an object.",
        "tokens": [
          51414,
          400,
          1184,
          4478,
          295,
          264,
          10225,
          11,
          286,
          528,
          309,
          281,
          312,
          364,
          2657,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21148499510342017,
        "compression_ratio": 1.755639097744361,
        "end": 3941,
        "id": 1055,
        "no_speech_prob": 0.010652109049260616,
        "seek": 391200,
        "start": 3936,
        "temperature": 0,
        "text": " And it's going to have the inputs, which would be like this, and the outputs.",
        "tokens": [
          51564,
          400,
          309,
          311,
          516,
          281,
          362,
          264,
          15743,
          11,
          597,
          576,
          312,
          411,
          341,
          11,
          293,
          264,
          23930,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3946,
        "id": 1056,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3941,
        "temperature": 0,
        "text": " Now even though I only have one output, right, one output, outputs can be an array.",
        "tokens": [
          50364,
          823,
          754,
          1673,
          286,
          787,
          362,
          472,
          5598,
          11,
          558,
          11,
          472,
          5598,
          11,
          23930,
          393,
          312,
          364,
          10225,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3948,
        "id": 1057,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3946,
        "temperature": 0,
        "text": " They're often referred to as a vector.",
        "tokens": [
          50614,
          814,
          434,
          2049,
          10839,
          281,
          382,
          257,
          8062,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3950,
        "id": 1058,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3948,
        "temperature": 0,
        "text": " So a list of numbers.",
        "tokens": [
          50714,
          407,
          257,
          1329,
          295,
          3547,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3953,
        "id": 1059,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3950,
        "temperature": 0,
        "text": " But in this case, 00 gives me just a single output.",
        "tokens": [
          50814,
          583,
          294,
          341,
          1389,
          11,
          7143,
          2709,
          385,
          445,
          257,
          2167,
          5598,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3956,
        "id": 1060,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3953,
        "temperature": 0,
        "text": " I have single outputs, but I'm going to put the array, the library expects an array.",
        "tokens": [
          50964,
          286,
          362,
          2167,
          23930,
          11,
          457,
          286,
          478,
          516,
          281,
          829,
          264,
          10225,
          11,
          264,
          6405,
          33280,
          364,
          10225,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3957,
        "id": 1061,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3956,
        "temperature": 0,
        "text": " So I have that.",
        "tokens": [
          51114,
          407,
          286,
          362,
          300,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3959,
        "id": 1062,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3957,
        "temperature": 0,
        "text": " Inputs out 00.",
        "tokens": [
          51164,
          682,
          2582,
          82,
          484,
          7143,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3963,
        "id": 1063,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3959,
        "temperature": 0,
        "text": " I have 01, and 00 gives me a 0, not a 1.",
        "tokens": [
          51264,
          286,
          362,
          23185,
          11,
          293,
          7143,
          2709,
          385,
          257,
          1958,
          11,
          406,
          257,
          502,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3966,
        "id": 1064,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3963,
        "temperature": 0,
        "text": " I have 01, which gives me a 1.",
        "tokens": [
          51464,
          286,
          362,
          23185,
          11,
          597,
          2709,
          385,
          257,
          502,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1711562521317426,
        "compression_ratio": 1.836283185840708,
        "end": 3968,
        "id": 1065,
        "no_speech_prob": 0.01384820882230997,
        "seek": 394100,
        "start": 3966,
        "temperature": 0,
        "text": " I have 10, which gives me a 1.",
        "tokens": [
          51614,
          286,
          362,
          1266,
          11,
          597,
          2709,
          385,
          257,
          502,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1992549695466694,
        "compression_ratio": 1.544186046511628,
        "end": 3972,
        "id": 1066,
        "no_speech_prob": 0.01168703194707632,
        "seek": 396800,
        "start": 3968,
        "temperature": 0,
        "text": " And then I also have, what's the last one?",
        "tokens": [
          50364,
          400,
          550,
          286,
          611,
          362,
          11,
          437,
          311,
          264,
          1036,
          472,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.1992549695466694,
        "compression_ratio": 1.544186046511628,
        "end": 3975,
        "id": 1067,
        "no_speech_prob": 0.01168703194707632,
        "seek": 396800,
        "start": 3972,
        "temperature": 0,
        "text": " 11, which should give me a 0.",
        "tokens": [
          50564,
          2975,
          11,
          597,
          820,
          976,
          385,
          257,
          1958,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1992549695466694,
        "compression_ratio": 1.544186046511628,
        "end": 3978,
        "id": 1068,
        "no_speech_prob": 0.01168703194707632,
        "seek": 396800,
        "start": 3975,
        "temperature": 0,
        "text": " So this is my training data.",
        "tokens": [
          50714,
          407,
          341,
          307,
          452,
          3097,
          1412,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1992549695466694,
        "compression_ratio": 1.544186046511628,
        "end": 3984,
        "id": 1069,
        "no_speech_prob": 0.01168703194707632,
        "seek": 396800,
        "start": 3978,
        "temperature": 0,
        "text": " Now ordinarily this data might be in a spreadsheet, it might come from an API, it might be in a JSON file.",
        "tokens": [
          50864,
          823,
          25376,
          3289,
          341,
          1412,
          1062,
          312,
          294,
          257,
          27733,
          11,
          309,
          1062,
          808,
          490,
          364,
          9362,
          11,
          309,
          1062,
          312,
          294,
          257,
          31828,
          3991,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1992549695466694,
        "compression_ratio": 1.544186046511628,
        "end": 3990,
        "id": 1070,
        "no_speech_prob": 0.01168703194707632,
        "seek": 396800,
        "start": 3984,
        "temperature": 0,
        "text": " But I'm just hard coding the training data directly into my program just to demonstrate the idea.",
        "tokens": [
          51164,
          583,
          286,
          478,
          445,
          1152,
          17720,
          264,
          3097,
          1412,
          3838,
          666,
          452,
          1461,
          445,
          281,
          11698,
          264,
          1558,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1992549695466694,
        "compression_ratio": 1.544186046511628,
        "end": 3993,
        "id": 1071,
        "no_speech_prob": 0.01168703194707632,
        "seek": 396800,
        "start": 3990,
        "temperature": 0,
        "text": " Now what do I want to do?",
        "tokens": [
          51464,
          823,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.19002686559626486,
        "compression_ratio": 1.7470817120622568,
        "end": 4001,
        "id": 1072,
        "no_speech_prob": 0.06754270195960999,
        "seek": 399300,
        "start": 3993,
        "temperature": 0,
        "text": " Well, in the draw function, what I want to do is, and now, if you look at how machine learning algorithms work,",
        "tokens": [
          50364,
          1042,
          11,
          294,
          264,
          2642,
          2445,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          293,
          586,
          11,
          498,
          291,
          574,
          412,
          577,
          3479,
          2539,
          14642,
          589,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19002686559626486,
        "compression_ratio": 1.7470817120622568,
        "end": 4005,
        "id": 1073,
        "no_speech_prob": 0.06754270195960999,
        "seek": 399300,
        "start": 4001,
        "temperature": 0,
        "text": " typically you'll see something called, you'll have a batch training process,",
        "tokens": [
          50764,
          5850,
          291,
          603,
          536,
          746,
          1219,
          11,
          291,
          603,
          362,
          257,
          15245,
          3097,
          1399,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.19002686559626486,
        "compression_ratio": 1.7470817120622568,
        "end": 4011,
        "id": 1074,
        "no_speech_prob": 0.06754270195960999,
        "seek": 399300,
        "start": 4005,
        "temperature": 0,
        "text": " where you give it a large batch of data, and then you adjust the weights and do the training in another batch.",
        "tokens": [
          50964,
          689,
          291,
          976,
          309,
          257,
          2416,
          15245,
          295,
          1412,
          11,
          293,
          550,
          291,
          4369,
          264,
          17443,
          293,
          360,
          264,
          3097,
          294,
          1071,
          15245,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19002686559626486,
        "compression_ratio": 1.7470817120622568,
        "end": 4013,
        "id": 1075,
        "no_speech_prob": 0.06754270195960999,
        "seek": 399300,
        "start": 4011,
        "temperature": 0,
        "text": " I'm going to do everything just one at a time.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          360,
          1203,
          445,
          472,
          412,
          257,
          565,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19002686559626486,
        "compression_ratio": 1.7470817120622568,
        "end": 4019,
        "id": 1076,
        "no_speech_prob": 0.06754270195960999,
        "seek": 399300,
        "start": 4013,
        "temperature": 0,
        "text": " And the way I'm going to do that is with a function called train that's in the neural network library.",
        "tokens": [
          51364,
          400,
          264,
          636,
          286,
          478,
          516,
          281,
          360,
          300,
          307,
          365,
          257,
          2445,
          1219,
          3847,
          300,
          311,
          294,
          264,
          18161,
          3209,
          6405,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2195841061171665,
        "compression_ratio": 1.7462686567164178,
        "end": 4026,
        "id": 1077,
        "no_speech_prob": 0.013636181131005287,
        "seek": 401900,
        "start": 4019,
        "temperature": 0,
        "text": " So if I say neural network train, this expects two arguments.",
        "tokens": [
          50364,
          407,
          498,
          286,
          584,
          18161,
          3209,
          3847,
          11,
          341,
          33280,
          732,
          12869,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2195841061171665,
        "compression_ratio": 1.7462686567164178,
        "end": 4032,
        "id": 1078,
        "no_speech_prob": 0.013636181131005287,
        "seek": 401900,
        "start": 4026,
        "temperature": 0,
        "text": " What it expects is to say, train the neural network with this input and this expected output.",
        "tokens": [
          50714,
          708,
          309,
          33280,
          307,
          281,
          584,
          11,
          3847,
          264,
          18161,
          3209,
          365,
          341,
          4846,
          293,
          341,
          5176,
          5598,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2195841061171665,
        "compression_ratio": 1.7462686567164178,
        "end": 4037,
        "id": 1079,
        "no_speech_prob": 0.013636181131005287,
        "seek": 401900,
        "start": 4032,
        "temperature": 0,
        "text": " And so the easy thing here that I could do is, what it should look like is something like this.",
        "tokens": [
          51014,
          400,
          370,
          264,
          1858,
          551,
          510,
          300,
          286,
          727,
          360,
          307,
          11,
          437,
          309,
          820,
          574,
          411,
          307,
          746,
          411,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2195841061171665,
        "compression_ratio": 1.7462686567164178,
        "end": 4042,
        "id": 1080,
        "no_speech_prob": 0.013636181131005287,
        "seek": 401900,
        "start": 4037,
        "temperature": 0,
        "text": " Train it with 0, 0 and with 1.",
        "tokens": [
          51264,
          28029,
          309,
          365,
          1958,
          11,
          1958,
          293,
          365,
          502,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2195841061171665,
        "compression_ratio": 1.7462686567164178,
        "end": 4045,
        "id": 1081,
        "no_speech_prob": 0.013636181131005287,
        "seek": 401900,
        "start": 4042,
        "temperature": 0,
        "text": " So this is what I'm saying.",
        "tokens": [
          51514,
          407,
          341,
          307,
          437,
          286,
          478,
          1566,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2195841061171665,
        "compression_ratio": 1.7462686567164178,
        "end": 4047,
        "id": 1082,
        "no_speech_prob": 0.013636181131005287,
        "seek": 401900,
        "start": 4045,
        "temperature": 0,
        "text": " These inputs should produce this output.",
        "tokens": [
          51664,
          1981,
          15743,
          820,
          5258,
          341,
          5598,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4049,
        "id": 1083,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4047,
        "temperature": 0,
        "text": " Train yourself on that.",
        "tokens": [
          50364,
          28029,
          1803,
          322,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4051,
        "id": 1084,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4049,
        "temperature": 0,
        "text": " But I have that all stored in an array.",
        "tokens": [
          50464,
          583,
          286,
          362,
          300,
          439,
          12187,
          294,
          364,
          10225,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4057,
        "id": 1085,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4051,
        "temperature": 0,
        "text": " What I'm going to do is I'm going to say data equals random training.",
        "tokens": [
          50564,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          1412,
          6915,
          4974,
          3097,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4059,
        "id": 1086,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4057,
        "temperature": 0,
        "text": " And what did I call that up here?",
        "tokens": [
          50864,
          400,
          437,
          630,
          286,
          818,
          300,
          493,
          510,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4061,
        "id": 1087,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4059,
        "temperature": 0,
        "text": " I called it training.",
        "tokens": [
          50964,
          286,
          1219,
          309,
          3097,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4062,
        "id": 1088,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4061,
        "temperature": 0,
        "text": " I just called it training.",
        "tokens": [
          51064,
          286,
          445,
          1219,
          309,
          3097,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4066,
        "id": 1089,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4062,
        "temperature": 0,
        "text": " Let's call it training underscore data.",
        "tokens": [
          51114,
          961,
          311,
          818,
          309,
          3097,
          37556,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4068,
        "id": 1090,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4066,
        "temperature": 0,
        "text": " Training underscore data.",
        "tokens": [
          51314,
          20620,
          37556,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17890322973968786,
        "compression_ratio": 1.8215962441314555,
        "end": 4074,
        "id": 1091,
        "no_speech_prob": 0.15816020965576172,
        "seek": 404700,
        "start": 4068,
        "temperature": 0,
        "text": " So the random function in p5 will pull a random element from that array, and it will put it here in data.",
        "tokens": [
          51414,
          407,
          264,
          4974,
          2445,
          294,
          280,
          20,
          486,
          2235,
          257,
          4974,
          4478,
          490,
          300,
          10225,
          11,
          293,
          309,
          486,
          829,
          309,
          510,
          294,
          1412,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4083,
        "id": 1092,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4074,
        "temperature": 0,
        "text": " So then I can just say train it with these inputs and expect these outputs.",
        "tokens": [
          50364,
          407,
          550,
          286,
          393,
          445,
          584,
          3847,
          309,
          365,
          613,
          15743,
          293,
          2066,
          613,
          23930,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4085,
        "id": 1093,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4083,
        "temperature": 0,
        "text": " It's only one output, but outputs.",
        "tokens": [
          50814,
          467,
          311,
          787,
          472,
          5598,
          11,
          457,
          23930,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4087,
        "id": 1094,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4085,
        "temperature": 0,
        "text": " So this is the process.",
        "tokens": [
          50914,
          407,
          341,
          307,
          264,
          1399,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4088,
        "id": 1095,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4087,
        "temperature": 0,
        "text": " This is the training process.",
        "tokens": [
          51014,
          639,
          307,
          264,
          3097,
          1399,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4096,
        "id": 1096,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4088,
        "temperature": 0,
        "text": " Of course, all of the work to adjust the weights of the neural network is in the library, and you can go, stop saying this, refer to those videos that go through that process.",
        "tokens": [
          51064,
          2720,
          1164,
          11,
          439,
          295,
          264,
          589,
          281,
          4369,
          264,
          17443,
          295,
          264,
          18161,
          3209,
          307,
          294,
          264,
          6405,
          11,
          293,
          291,
          393,
          352,
          11,
          1590,
          1566,
          341,
          11,
          2864,
          281,
          729,
          2145,
          300,
          352,
          807,
          300,
          1399,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4098,
        "id": 1097,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4096,
        "temperature": 0,
        "text": " Okay, we've got that.",
        "tokens": [
          51464,
          1033,
          11,
          321,
          600,
          658,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21030445422156382,
        "compression_ratio": 1.7408906882591093,
        "end": 4102,
        "id": 1098,
        "no_speech_prob": 0.008445401675999165,
        "seek": 407400,
        "start": 4098,
        "temperature": 0,
        "text": " Now I am going to, let's just run this and see if I get any errors.",
        "tokens": [
          51564,
          823,
          286,
          669,
          516,
          281,
          11,
          718,
          311,
          445,
          1190,
          341,
          293,
          536,
          498,
          286,
          483,
          604,
          13603,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4105,
        "id": 1099,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4103,
        "temperature": 0,
        "text": " Ah, syntax error.",
        "tokens": [
          50414,
          2438,
          11,
          28431,
          6713,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4107,
        "id": 1100,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4105,
        "temperature": 0,
        "text": " Sketch.js line four.",
        "tokens": [
          50514,
          49245,
          13,
          25530,
          1622,
          1451,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4109,
        "id": 1101,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4107,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          50614,
          876,
          11,
          574,
          412,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4110,
        "id": 1102,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4109,
        "temperature": 0,
        "text": " Horrible.",
        "tokens": [
          50714,
          10691,
          4457,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4113,
        "id": 1103,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4110,
        "temperature": 0,
        "text": " My JavaScript object syntax is just completely off.",
        "tokens": [
          50764,
          1222,
          15778,
          2657,
          28431,
          307,
          445,
          2584,
          766,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4115,
        "id": 1104,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4113,
        "temperature": 0,
        "text": " These are not semicolons.",
        "tokens": [
          50914,
          1981,
          366,
          406,
          27515,
          401,
          892,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4118,
        "id": 1105,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4115,
        "temperature": 0,
        "text": " You guys have all, everyone watching has been screaming at the screen.",
        "tokens": [
          51014,
          509,
          1074,
          362,
          439,
          11,
          1518,
          1976,
          575,
          668,
          12636,
          412,
          264,
          2568,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2533319500130667,
        "compression_ratio": 1.331360946745562,
        "end": 4126,
        "id": 1106,
        "no_speech_prob": 0.07262733578681946,
        "seek": 410200,
        "start": 4124,
        "temperature": 0,
        "text": " Take two.",
        "tokens": [
          51464,
          3664,
          732,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4128,
        "id": 1107,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4126,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4134,
        "id": 1108,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4132,
        "temperature": 0,
        "text": " Oh, I have semicolons here.",
        "tokens": [
          50664,
          876,
          11,
          286,
          362,
          27515,
          401,
          892,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4136,
        "id": 1109,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4134,
        "temperature": 0,
        "text": " These should be commas.",
        "tokens": [
          50764,
          1981,
          820,
          312,
          800,
          296,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4138,
        "id": 1110,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4136,
        "temperature": 0,
        "text": " My syntax is completely wrong.",
        "tokens": [
          50864,
          1222,
          28431,
          307,
          2584,
          2085,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4146,
        "id": 1111,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4138,
        "temperature": 0,
        "text": " If you're watching this, you were probably screaming at me or saying very nicely and sweetly to the computer, excuse me, excuse me, it's not semicolon.",
        "tokens": [
          50964,
          759,
          291,
          434,
          1976,
          341,
          11,
          291,
          645,
          1391,
          12636,
          412,
          385,
          420,
          1566,
          588,
          9594,
          293,
          3844,
          356,
          281,
          264,
          3820,
          11,
          8960,
          385,
          11,
          8960,
          385,
          11,
          309,
          311,
          406,
          27515,
          38780,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4148,
        "id": 1112,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4146,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4149,
        "id": 1113,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4148,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51464,
          821,
          321,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4150,
        "id": 1114,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4149,
        "temperature": 0,
        "text": " Now let's run again.",
        "tokens": [
          51514,
          823,
          718,
          311,
          1190,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4152,
        "id": 1115,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4150,
        "temperature": 0,
        "text": " All right, it's running, it's training.",
        "tokens": [
          51564,
          1057,
          558,
          11,
          309,
          311,
          2614,
          11,
          309,
          311,
          3097,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4153,
        "id": 1116,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4152,
        "temperature": 0,
        "text": " I think it's working.",
        "tokens": [
          51664,
          286,
          519,
          309,
          311,
          1364,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4154,
        "id": 1117,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4153,
        "temperature": 0,
        "text": " Is it working?",
        "tokens": [
          51714,
          1119,
          309,
          1364,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.20169025851834205,
        "compression_ratio": 1.5899581589958158,
        "end": 4155,
        "id": 1118,
        "no_speech_prob": 0.01771041937172413,
        "seek": 412600,
        "start": 4154,
        "temperature": 0,
        "text": " So now here's the thing.",
        "tokens": [
          51764,
          407,
          586,
          510,
          311,
          264,
          551,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4156,
        "id": 1119,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4155,
        "temperature": 0,
        "text": " It's doing its thing.",
        "tokens": [
          50364,
          467,
          311,
          884,
          1080,
          551,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4164,
        "id": 1120,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4156,
        "temperature": 0,
        "text": " Let's actually see if it's working because one thing I can do right now is I can just test the output here in the console itself.",
        "tokens": [
          50414,
          961,
          311,
          767,
          536,
          498,
          309,
          311,
          1364,
          570,
          472,
          551,
          286,
          393,
          360,
          558,
          586,
          307,
          286,
          393,
          445,
          1500,
          264,
          5598,
          510,
          294,
          264,
          11076,
          2564,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4168,
        "id": 1121,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4164,
        "temperature": 0,
        "text": " What is this weird graphics artifact going on here?",
        "tokens": [
          50814,
          708,
          307,
          341,
          3657,
          11837,
          34806,
          516,
          322,
          510,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4169,
        "id": 1122,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4168,
        "temperature": 0,
        "text": " I'm going to ignore that.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          11200,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4172,
        "id": 1123,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4169,
        "temperature": 0,
        "text": " I'm going to say nn predict.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          584,
          297,
          77,
          6069,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4180,
        "id": 1124,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4172,
        "temperature": 0,
        "text": " So the predict function is a function in the neural network library that doesn't take the inputs and a labeled output.",
        "tokens": [
          51214,
          407,
          264,
          6069,
          2445,
          307,
          257,
          2445,
          294,
          264,
          18161,
          3209,
          6405,
          300,
          1177,
          380,
          747,
          264,
          15743,
          293,
          257,
          21335,
          5598,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1788149746981534,
        "compression_ratio": 1.7769230769230768,
        "end": 4184,
        "id": 1125,
        "no_speech_prob": 0.03308491036295891,
        "seek": 415500,
        "start": 4180,
        "temperature": 0,
        "text": " It just says here's some inputs, tell me what you think, tell me what the output is.",
        "tokens": [
          51614,
          467,
          445,
          1619,
          510,
          311,
          512,
          15743,
          11,
          980,
          385,
          437,
          291,
          519,
          11,
          980,
          385,
          437,
          264,
          5598,
          307,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2118136794478805,
        "compression_ratio": 1.463768115942029,
        "end": 4190,
        "id": 1126,
        "no_speech_prob": 0.0016484734369441867,
        "seek": 418400,
        "start": 4184,
        "temperature": 0,
        "text": " So if I give it 00, shouldn't I get 1.0?",
        "tokens": [
          50364,
          407,
          498,
          286,
          976,
          309,
          7143,
          11,
          4659,
          380,
          286,
          483,
          502,
          13,
          15,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2118136794478805,
        "compression_ratio": 1.463768115942029,
        "end": 4195,
        "id": 1127,
        "no_speech_prob": 0.0016484734369441867,
        "seek": 418400,
        "start": 4190,
        "temperature": 0,
        "text": " Oh, that's not good,.49, that's not good.",
        "tokens": [
          50664,
          876,
          11,
          300,
          311,
          406,
          665,
          11,
          2411,
          14938,
          11,
          300,
          311,
          406,
          665,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2118136794478805,
        "compression_ratio": 1.463768115942029,
        "end": 4199,
        "id": 1128,
        "no_speech_prob": 0.0016484734369441867,
        "seek": 418400,
        "start": 4195,
        "temperature": 0,
        "text": ".51, oh, it's doing a little better, got a little higher, that's closer to 1.",
        "tokens": [
          50914,
          2411,
          18682,
          11,
          1954,
          11,
          309,
          311,
          884,
          257,
          707,
          1101,
          11,
          658,
          257,
          707,
          2946,
          11,
          300,
          311,
          4966,
          281,
          502,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2118136794478805,
        "compression_ratio": 1.463768115942029,
        "end": 4202,
        "id": 1129,
        "no_speech_prob": 0.0016484734369441867,
        "seek": 418400,
        "start": 4199,
        "temperature": 0,
        "text": ".51, oh no,.49 again.",
        "tokens": [
          51114,
          2411,
          18682,
          11,
          1954,
          572,
          11,
          2411,
          14938,
          797,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2118136794478805,
        "compression_ratio": 1.463768115942029,
        "end": 4205,
        "id": 1130,
        "no_speech_prob": 0.0016484734369441867,
        "seek": 418400,
        "start": 4202,
        "temperature": 0,
        "text": " So this is the thing.",
        "tokens": [
          51264,
          407,
          341,
          307,
          264,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23748320917929372,
        "compression_ratio": 1.5172413793103448,
        "end": 4220,
        "id": 1131,
        "no_speech_prob": 0.3848859965801239,
        "seek": 420500,
        "start": 4206,
        "temperature": 0,
        "text": " I have programmed this in such a way that first of all it needs to run these data points in thousands or possibly hundreds of thousands of times to be able to train itself.",
        "tokens": [
          50414,
          286,
          362,
          31092,
          341,
          294,
          1270,
          257,
          636,
          300,
          700,
          295,
          439,
          309,
          2203,
          281,
          1190,
          613,
          1412,
          2793,
          294,
          5383,
          420,
          6264,
          6779,
          295,
          5383,
          295,
          1413,
          281,
          312,
          1075,
          281,
          3847,
          2564,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23748320917929372,
        "compression_ratio": 1.5172413793103448,
        "end": 4227,
        "id": 1132,
        "no_speech_prob": 0.3848859965801239,
        "seek": 420500,
        "start": 4220,
        "temperature": 0,
        "text": " And also this is a problem that with only two hidden nodes it can kind of get stuck, right?",
        "tokens": [
          51114,
          400,
          611,
          341,
          307,
          257,
          1154,
          300,
          365,
          787,
          732,
          7633,
          13891,
          309,
          393,
          733,
          295,
          483,
          5541,
          11,
          558,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.24068288660761136,
        "compression_ratio": 1.493421052631579,
        "end": 4238,
        "id": 1133,
        "no_speech_prob": 0.6331911087036133,
        "seek": 422700,
        "start": 4227,
        "temperature": 0,
        "text": " It gets stuck in this sort of in-between state.",
        "tokens": [
          50364,
          467,
          2170,
          5541,
          294,
          341,
          1333,
          295,
          294,
          12,
          32387,
          1785,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24068288660761136,
        "compression_ratio": 1.493421052631579,
        "end": 4243,
        "id": 1134,
        "no_speech_prob": 0.6331911087036133,
        "seek": 422700,
        "start": 4238,
        "temperature": 0,
        "text": " I was trying to think of how to, I didn't want to cover the getting stuck thing.",
        "tokens": [
          50914,
          286,
          390,
          1382,
          281,
          519,
          295,
          577,
          281,
          11,
          286,
          994,
          380,
          528,
          281,
          2060,
          264,
          1242,
          5541,
          551,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24068288660761136,
        "compression_ratio": 1.493421052631579,
        "end": 4248,
        "id": 1135,
        "no_speech_prob": 0.6331911087036133,
        "seek": 422700,
        "start": 4243,
        "temperature": 0,
        "text": " Let me just go again and hope that it's a time that it doesn't get stuck.",
        "tokens": [
          51164,
          961,
          385,
          445,
          352,
          797,
          293,
          1454,
          300,
          309,
          311,
          257,
          565,
          300,
          309,
          1177,
          380,
          483,
          5541,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24068288660761136,
        "compression_ratio": 1.493421052631579,
        "end": 4249,
        "id": 1136,
        "no_speech_prob": 0.6331911087036133,
        "seek": 422700,
        "start": 4248,
        "temperature": 0,
        "text": " So this will get edited.",
        "tokens": [
          51414,
          407,
          341,
          486,
          483,
          23016,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22348604202270508,
        "compression_ratio": 1.7045454545454546,
        "end": 4258,
        "id": 1137,
        "no_speech_prob": 0.824330747127533,
        "seek": 424900,
        "start": 4249,
        "temperature": 0,
        "text": " I do want to cover the getting stuck thing because I think there's some things we can do by adjusting the learning rate and mucking around with it, but I just didn't want that to happen right now.",
        "tokens": [
          50364,
          286,
          360,
          528,
          281,
          2060,
          264,
          1242,
          5541,
          551,
          570,
          286,
          519,
          456,
          311,
          512,
          721,
          321,
          393,
          360,
          538,
          23559,
          264,
          2539,
          3314,
          293,
          275,
          33260,
          926,
          365,
          309,
          11,
          457,
          286,
          445,
          994,
          380,
          528,
          300,
          281,
          1051,
          558,
          586,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22348604202270508,
        "compression_ratio": 1.7045454545454546,
        "end": 4261,
        "id": 1138,
        "no_speech_prob": 0.824330747127533,
        "seek": 424900,
        "start": 4258,
        "temperature": 0,
        "text": " So I'm going to just run it again.",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          445,
          1190,
          309,
          797,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22348604202270508,
        "compression_ratio": 1.7045454545454546,
        "end": 4264,
        "id": 1139,
        "no_speech_prob": 0.824330747127533,
        "seek": 424900,
        "start": 4261,
        "temperature": 0,
        "text": " It's running, it's running.",
        "tokens": [
          50964,
          467,
          311,
          2614,
          11,
          309,
          311,
          2614,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22348604202270508,
        "compression_ratio": 1.7045454545454546,
        "end": 4272,
        "id": 1140,
        "no_speech_prob": 0.824330747127533,
        "seek": 424900,
        "start": 4264,
        "temperature": 0,
        "text": " So what I can do is right here in the console just to test it I can type nn. and there's a function called predict.",
        "tokens": [
          51114,
          407,
          437,
          286,
          393,
          360,
          307,
          558,
          510,
          294,
          264,
          11076,
          445,
          281,
          1500,
          309,
          286,
          393,
          2010,
          297,
          77,
          13,
          293,
          456,
          311,
          257,
          2445,
          1219,
          6069,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4281,
        "id": 1141,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4272,
        "temperature": 0,
        "text": " And what predict expects in the neural network library is the input data with no output because it's not labeled training data, it's just input data.",
        "tokens": [
          50364,
          400,
          437,
          6069,
          33280,
          294,
          264,
          18161,
          3209,
          6405,
          307,
          264,
          4846,
          1412,
          365,
          572,
          5598,
          570,
          309,
          311,
          406,
          21335,
          3097,
          1412,
          11,
          309,
          311,
          445,
          4846,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4284,
        "id": 1142,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4281,
        "temperature": 0,
        "text": " So let's see if we can get results that make sense.",
        "tokens": [
          50814,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          483,
          3542,
          300,
          652,
          2020,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4289,
        "id": 1143,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4284,
        "temperature": 0,
        "text": " It hasn't trained for very long and I don't know, but let's see.",
        "tokens": [
          50964,
          467,
          6132,
          380,
          8895,
          337,
          588,
          938,
          293,
          286,
          500,
          380,
          458,
          11,
          457,
          718,
          311,
          536,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4290,
        "id": 1144,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4289,
        "temperature": 0,
        "text": " Let's just try it.",
        "tokens": [
          51214,
          961,
          311,
          445,
          853,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4291,
        "id": 1145,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4290,
        "temperature": 0,
        "text": " Predict 0, 0.",
        "tokens": [
          51264,
          430,
          24945,
          1958,
          11,
          1958,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4292,
        "id": 1146,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4291,
        "temperature": 0,
        "text": " 0.45.",
        "tokens": [
          51314,
          1958,
          13,
          8465,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4293,
        "id": 1147,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4292,
        "temperature": 0,
        "text": " That's not right.",
        "tokens": [
          51364,
          663,
          311,
          406,
          558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4294,
        "id": 1148,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4293,
        "temperature": 0,
        "text": " So I should be seeing 0.1, right?",
        "tokens": [
          51414,
          407,
          286,
          820,
          312,
          2577,
          1958,
          13,
          16,
          11,
          558,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4295,
        "id": 1149,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4294,
        "temperature": 0,
        "text": " It's changing.",
        "tokens": [
          51464,
          467,
          311,
          4473,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4296,
        "id": 1150,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4295,
        "temperature": 0,
        "text": " 0.43.",
        "tokens": [
          51514,
          1958,
          13,
          17201,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1969941904847051,
        "compression_ratio": 1.6079136690647482,
        "end": 4300,
        "id": 1151,
        "no_speech_prob": 0.3276314437389374,
        "seek": 427200,
        "start": 4296,
        "temperature": 0,
        "text": " So my guess here is that we really need it to just train a lot more.",
        "tokens": [
          51564,
          407,
          452,
          2041,
          510,
          307,
          300,
          321,
          534,
          643,
          309,
          281,
          445,
          3847,
          257,
          688,
          544,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4310,
        "id": 1152,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4300,
        "temperature": 0,
        "text": " What I'm going to do is just for right now is I'm going to say in the draw loop itself I'm going to say i equals 0, i is less than 1,000.",
        "tokens": [
          50364,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          445,
          337,
          558,
          586,
          307,
          286,
          478,
          516,
          281,
          584,
          294,
          264,
          2642,
          6367,
          2564,
          286,
          478,
          516,
          281,
          584,
          741,
          6915,
          1958,
          11,
          741,
          307,
          1570,
          813,
          502,
          11,
          1360,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4317,
        "id": 1153,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4310,
        "temperature": 0,
        "text": " I'm going to have it do every time through draw 1,000 of these training points.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          362,
          309,
          360,
          633,
          565,
          807,
          2642,
          502,
          11,
          1360,
          295,
          613,
          3097,
          2793,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4320,
        "id": 1154,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4317,
        "temperature": 0,
        "text": " So this will hopefully get us there a little faster.",
        "tokens": [
          51214,
          407,
          341,
          486,
          4696,
          483,
          505,
          456,
          257,
          707,
          4663,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4322,
        "id": 1155,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4320,
        "temperature": 0,
        "text": " And I can look at this now.",
        "tokens": [
          51364,
          400,
          286,
          393,
          574,
          412,
          341,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4324,
        "id": 1156,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4322,
        "temperature": 0,
        "text": " We can see, ah, ooh.",
        "tokens": [
          51464,
          492,
          393,
          536,
          11,
          3716,
          11,
          17024,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4326,
        "id": 1157,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4324,
        "temperature": 0,
        "text": " Now that's wrong, right?",
        "tokens": [
          51564,
          823,
          300,
          311,
          2085,
          11,
          558,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.20924776998059502,
        "compression_ratio": 1.6211453744493391,
        "end": 4327,
        "id": 1158,
        "no_speech_prob": 0.1441313922405243,
        "seek": 430000,
        "start": 4326,
        "temperature": 0,
        "text": " Oh, no, that's correct.",
        "tokens": [
          51664,
          876,
          11,
          572,
          11,
          300,
          311,
          3006,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4329,
        "id": 1159,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4327,
        "temperature": 0,
        "text": " I should be getting false.",
        "tokens": [
          50364,
          286,
          820,
          312,
          1242,
          7908,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4330,
        "id": 1160,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4329,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50464,
          865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4331,
        "id": 1161,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4330,
        "temperature": 0,
        "text": " So that's right.",
        "tokens": [
          50514,
          407,
          300,
          311,
          558,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4332,
        "id": 1162,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4331,
        "temperature": 0,
        "text": " I got it backwards for a second.",
        "tokens": [
          50564,
          286,
          658,
          309,
          12204,
          337,
          257,
          1150,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4333,
        "id": 1163,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4332,
        "temperature": 0,
        "text": " I shouldn't be getting true.",
        "tokens": [
          50614,
          286,
          4659,
          380,
          312,
          1242,
          2074,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4334,
        "id": 1164,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4333,
        "temperature": 0,
        "text": " I should be getting false.",
        "tokens": [
          50664,
          286,
          820,
          312,
          1242,
          7908,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4335,
        "id": 1165,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4334,
        "temperature": 0,
        "text": " 0, 0.",
        "tokens": [
          50714,
          1958,
          11,
          1958,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4338,
        "id": 1166,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4335,
        "temperature": 0,
        "text": " So let's try 1, 0 and I've got something that's close to 1.",
        "tokens": [
          50764,
          407,
          718,
          311,
          853,
          502,
          11,
          1958,
          293,
          286,
          600,
          658,
          746,
          300,
          311,
          1998,
          281,
          502,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4339,
        "id": 1167,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4338,
        "temperature": 0,
        "text": " So you can see that this worked.",
        "tokens": [
          50914,
          407,
          291,
          393,
          536,
          300,
          341,
          2732,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4340,
        "id": 1168,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4339,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4341,
        "id": 1169,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4340,
        "temperature": 0,
        "text": " So the library is working.",
        "tokens": [
          51014,
          407,
          264,
          6405,
          307,
          1364,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4344,
        "id": 1170,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4341,
        "temperature": 0,
        "text": " But let's say I want to visualize it.",
        "tokens": [
          51064,
          583,
          718,
          311,
          584,
          286,
          528,
          281,
          23273,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4345,
        "id": 1171,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4344,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4346,
        "id": 1172,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4345,
        "temperature": 0,
        "text": " I want to visualize it.",
        "tokens": [
          51264,
          286,
          528,
          281,
          23273,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4348,
        "id": 1173,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4346,
        "temperature": 0,
        "text": " I want to see it working.",
        "tokens": [
          51314,
          286,
          528,
          281,
          536,
          309,
          1364,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4350,
        "id": 1174,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4348,
        "temperature": 0,
        "text": " I want to see it animating as it works.",
        "tokens": [
          51414,
          286,
          528,
          281,
          536,
          309,
          2383,
          990,
          382,
          309,
          1985,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16243185733724957,
        "compression_ratio": 1.9042145593869733,
        "end": 4355,
        "id": 1175,
        "no_speech_prob": 0.3242102265357971,
        "seek": 432700,
        "start": 4350,
        "temperature": 0,
        "text": " So one way I could do that is I could basically let's create some variables like resolution.",
        "tokens": [
          51514,
          407,
          472,
          636,
          286,
          727,
          360,
          300,
          307,
          286,
          727,
          1936,
          718,
          311,
          1884,
          512,
          9102,
          411,
          8669,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4360,
        "id": 1176,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4356,
        "temperature": 0,
        "text": " I'm going to make a grid of 10 by 10 pixels.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          652,
          257,
          10748,
          295,
          1266,
          538,
          1266,
          18668,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4366,
        "id": 1177,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4360,
        "temperature": 0,
        "text": " So the columns is the width of the canvas divided by the resolution.",
        "tokens": [
          50614,
          407,
          264,
          13766,
          307,
          264,
          11402,
          295,
          264,
          16267,
          6666,
          538,
          264,
          8669,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4374,
        "id": 1178,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4368,
        "temperature": 0,
        "text": " And the rows is the height of the canvas divided by the resolution.",
        "tokens": [
          51014,
          400,
          264,
          13241,
          307,
          264,
          6681,
          295,
          264,
          16267,
          6666,
          538,
          264,
          8669,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4377,
        "id": 1179,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4374,
        "temperature": 0,
        "text": " Then I am going to say x equals 0.",
        "tokens": [
          51314,
          1396,
          286,
          669,
          516,
          281,
          584,
          2031,
          6915,
          1958,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4378,
        "id": 1180,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4377,
        "temperature": 0,
        "text": " I'm going to use i.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          764,
          741,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4379,
        "id": 1181,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4378,
        "temperature": 0,
        "text": " i equals 0.",
        "tokens": [
          51514,
          741,
          6915,
          1958,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19028475019666885,
        "compression_ratio": 1.7852760736196318,
        "end": 4383,
        "id": 1182,
        "no_speech_prob": 0.07475718855857849,
        "seek": 435500,
        "start": 4379,
        "temperature": 0,
        "text": " i is less than the number of columns, i++.",
        "tokens": [
          51564,
          741,
          307,
          1570,
          813,
          264,
          1230,
          295,
          13766,
          11,
          741,
          25472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4387,
        "id": 1183,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4383,
        "temperature": 0,
        "text": " And I'm going to say j equals 0.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          584,
          361,
          6915,
          1958,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4389,
        "id": 1184,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4387,
        "temperature": 0,
        "text": " It's less than the number of rows.",
        "tokens": [
          50564,
          467,
          311,
          1570,
          813,
          264,
          1230,
          295,
          13241,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4398,
        "id": 1185,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4389,
        "temperature": 0,
        "text": " I'm going to do a nice little nested loop here just to now I'm going to say fill random 255.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          360,
          257,
          1481,
          707,
          15646,
          292,
          6367,
          510,
          445,
          281,
          586,
          286,
          478,
          516,
          281,
          584,
          2836,
          4974,
          3552,
          20,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4404,
        "id": 1186,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4398,
        "temperature": 0,
        "text": " And I'm going to say rectangle i times resolution, j times resolution.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          584,
          21930,
          741,
          1413,
          8669,
          11,
          361,
          1413,
          8669,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4405,
        "id": 1187,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4404,
        "temperature": 0,
        "text": " Resolution.",
        "tokens": [
          51414,
          5015,
          3386,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4408,
        "id": 1188,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4405,
        "temperature": 0,
        "text": " I should have picked a less long variable name.",
        "tokens": [
          51464,
          286,
          820,
          362,
          6183,
          257,
          1570,
          938,
          7006,
          1315,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18191861582326366,
        "compression_ratio": 1.6833333333333333,
        "end": 4410,
        "id": 1189,
        "no_speech_prob": 0.001573073910549283,
        "seek": 438300,
        "start": 4408,
        "temperature": 0,
        "text": " Resolution.",
        "tokens": [
          51614,
          5015,
          3386,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17817294703120679,
        "compression_ratio": 1.58130081300813,
        "end": 4416,
        "id": 1190,
        "no_speech_prob": 0.005384801886975765,
        "seek": 441000,
        "start": 4410,
        "temperature": 0,
        "text": " So what this should do is this is a nice little nested loop to just draw a grid of rectangles, 10 by 10.",
        "tokens": [
          50364,
          407,
          437,
          341,
          820,
          360,
          307,
          341,
          307,
          257,
          1481,
          707,
          15646,
          292,
          6367,
          281,
          445,
          2642,
          257,
          10748,
          295,
          24077,
          904,
          11,
          1266,
          538,
          1266,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17817294703120679,
        "compression_ratio": 1.58130081300813,
        "end": 4419,
        "id": 1191,
        "no_speech_prob": 0.005384801886975765,
        "seek": 441000,
        "start": 4416,
        "temperature": 0,
        "text": " And a little warning, this will be kind of flashy.",
        "tokens": [
          50664,
          400,
          257,
          707,
          9164,
          11,
          341,
          486,
          312,
          733,
          295,
          47873,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17817294703120679,
        "compression_ratio": 1.58130081300813,
        "end": 4423,
        "id": 1192,
        "no_speech_prob": 0.005384801886975765,
        "seek": 441000,
        "start": 4419,
        "temperature": 0,
        "text": " So you can see all of these elements are flashing out with a random color.",
        "tokens": [
          50814,
          407,
          291,
          393,
          536,
          439,
          295,
          613,
          4959,
          366,
          31049,
          484,
          365,
          257,
          4974,
          2017,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17817294703120679,
        "compression_ratio": 1.58130081300813,
        "end": 4425,
        "id": 1193,
        "no_speech_prob": 0.005384801886975765,
        "seek": 441000,
        "start": 4423,
        "temperature": 0,
        "text": " But I don't want a random color.",
        "tokens": [
          51014,
          583,
          286,
          500,
          380,
          528,
          257,
          4974,
          2017,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17817294703120679,
        "compression_ratio": 1.58130081300813,
        "end": 4428,
        "id": 1194,
        "no_speech_prob": 0.005384801886975765,
        "seek": 441000,
        "start": 4425,
        "temperature": 0,
        "text": " What I want to do is I want to create some inputs.",
        "tokens": [
          51114,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1884,
          512,
          15743,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17817294703120679,
        "compression_ratio": 1.58130081300813,
        "end": 4436,
        "id": 1195,
        "no_speech_prob": 0.005384801886975765,
        "seek": 441000,
        "start": 4428,
        "temperature": 0,
        "text": " So I'm going to say let x1 equal i divided by columns, right, from 0 to 1.",
        "tokens": [
          51264,
          407,
          286,
          478,
          516,
          281,
          584,
          718,
          2031,
          16,
          2681,
          741,
          6666,
          538,
          13766,
          11,
          558,
          11,
          490,
          1958,
          281,
          502,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4440,
        "id": 1196,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4436,
        "temperature": 0,
        "text": " Let x2 equals j divided by rows.",
        "tokens": [
          50364,
          961,
          2031,
          17,
          6915,
          361,
          6666,
          538,
          13241,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4445,
        "id": 1197,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4440,
        "temperature": 0,
        "text": " And the inputs then is an array x1, x2.",
        "tokens": [
          50564,
          400,
          264,
          15743,
          550,
          307,
          364,
          10225,
          2031,
          16,
          11,
          2031,
          17,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4447,
        "id": 1198,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4445,
        "temperature": 0,
        "text": " So what I want to do is I want to create a scenario.",
        "tokens": [
          50814,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1884,
          257,
          9005,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4450,
        "id": 1199,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4447,
        "temperature": 0,
        "text": " Let me just say no loop here so this stops.",
        "tokens": [
          50914,
          961,
          385,
          445,
          584,
          572,
          6367,
          510,
          370,
          341,
          10094,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4456,
        "id": 1200,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4450,
        "temperature": 0,
        "text": " I want to create a scenario where I am inputting in 0, 0 here.",
        "tokens": [
          51064,
          286,
          528,
          281,
          1884,
          257,
          9005,
          689,
          286,
          669,
          4846,
          783,
          294,
          1958,
          11,
          1958,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4458,
        "id": 1201,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4456,
        "temperature": 0,
        "text": " And at this corner 1, 0.",
        "tokens": [
          51364,
          400,
          412,
          341,
          4538,
          502,
          11,
          1958,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1834728918342947,
        "compression_ratio": 1.603960396039604,
        "end": 4464,
        "id": 1202,
        "no_speech_prob": 0.03358866274356842,
        "seek": 443600,
        "start": 4458,
        "temperature": 0,
        "text": " And 1, 1 and 0, 1 down here and all the numbers in between, right.",
        "tokens": [
          51464,
          400,
          502,
          11,
          502,
          293,
          1958,
          11,
          502,
          760,
          510,
          293,
          439,
          264,
          3547,
          294,
          1296,
          11,
          558,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4473,
        "id": 1203,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4464,
        "temperature": 0,
        "text": " So now and then I, what I can do is I can say let y equal neural network predict.",
        "tokens": [
          50364,
          407,
          586,
          293,
          550,
          286,
          11,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          584,
          718,
          288,
          2681,
          18161,
          3209,
          6069,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4475,
        "id": 1204,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4473,
        "temperature": 0,
        "text": " And this should be an equals here.",
        "tokens": [
          50814,
          400,
          341,
          820,
          312,
          364,
          6915,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4478,
        "id": 1205,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4475,
        "temperature": 0,
        "text": " It's this particular predict, those inputs.",
        "tokens": [
          50914,
          467,
          311,
          341,
          1729,
          6069,
          11,
          729,
          15743,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4480,
        "id": 1206,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4478,
        "temperature": 0,
        "text": " And then fill y times 255.",
        "tokens": [
          51064,
          400,
          550,
          2836,
          288,
          1413,
          3552,
          20,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4486,
        "id": 1207,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4480,
        "temperature": 0,
        "text": " So I should get a brightness value out that's between, I should get a y value that's between 0 and 1.",
        "tokens": [
          51164,
          407,
          286,
          820,
          483,
          257,
          21367,
          2158,
          484,
          300,
          311,
          1296,
          11,
          286,
          820,
          483,
          257,
          288,
          2158,
          300,
          311,
          1296,
          1958,
          293,
          502,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4488,
        "id": 1208,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4486,
        "temperature": 0,
        "text": " And I should get that, a brightness value.",
        "tokens": [
          51464,
          400,
          286,
          820,
          483,
          300,
          11,
          257,
          21367,
          2158,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4490,
        "id": 1209,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4488,
        "temperature": 0,
        "text": " I can multiply by 255 to get a brightness value.",
        "tokens": [
          51564,
          286,
          393,
          12972,
          538,
          3552,
          20,
          281,
          483,
          257,
          21367,
          2158,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19011077234300516,
        "compression_ratio": 1.8235294117647058,
        "end": 4493,
        "id": 1210,
        "no_speech_prob": 0.12251359224319458,
        "seek": 446400,
        "start": 4490,
        "temperature": 0,
        "text": " Okay, let's run this.",
        "tokens": [
          51664,
          1033,
          11,
          718,
          311,
          1190,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4494,
        "id": 1211,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4493,
        "temperature": 0,
        "text": " Boom.",
        "tokens": [
          50364,
          15523,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4501,
        "id": 1212,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4494,
        "temperature": 0,
        "text": " So we can see now and let's be a little more thoughtful about this and say no stroke.",
        "tokens": [
          50414,
          407,
          321,
          393,
          536,
          586,
          293,
          718,
          311,
          312,
          257,
          707,
          544,
          21566,
          466,
          341,
          293,
          584,
          572,
          12403,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4504,
        "id": 1213,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4501,
        "temperature": 0,
        "text": " And I'm going to refresh it.",
        "tokens": [
          50764,
          400,
          286,
          478,
          516,
          281,
          15134,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4507,
        "id": 1214,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4504,
        "temperature": 0,
        "text": " And very quickly, ah, so this, I'm so glad this happened.",
        "tokens": [
          50914,
          400,
          588,
          2661,
          11,
          3716,
          11,
          370,
          341,
          11,
          286,
          478,
          370,
          5404,
          341,
          2011,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4508,
        "id": 1215,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4507,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51064,
          407,
          510,
          311,
          264,
          551,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4510,
        "id": 1216,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4508,
        "temperature": 0,
        "text": " It worked for me a bunch of times.",
        "tokens": [
          51114,
          467,
          2732,
          337,
          385,
          257,
          3840,
          295,
          1413,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4513,
        "id": 1217,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4510,
        "temperature": 0,
        "text": " But actually here you can see it's totally getting stuck.",
        "tokens": [
          51214,
          583,
          767,
          510,
          291,
          393,
          536,
          309,
          311,
          3879,
          1242,
          5541,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4515,
        "id": 1218,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4513,
        "temperature": 0,
        "text": " Let's refresh it again.",
        "tokens": [
          51364,
          961,
          311,
          15134,
          309,
          797,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4517,
        "id": 1219,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4515,
        "temperature": 0,
        "text": " And that got stuck in a slightly different way.",
        "tokens": [
          51464,
          400,
          300,
          658,
          5541,
          294,
          257,
          4748,
          819,
          636,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19672595945178953,
        "compression_ratio": 1.625,
        "end": 4519,
        "id": 1220,
        "no_speech_prob": 0.00048785420949570835,
        "seek": 449300,
        "start": 4517,
        "temperature": 0,
        "text": " Let me hit refresh again.",
        "tokens": [
          51564,
          961,
          385,
          2045,
          15134,
          797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4523,
        "id": 1221,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4519,
        "temperature": 0,
        "text": " Whoa, it's just like going around the horn and getting stuck in every possible way.",
        "tokens": [
          50364,
          7521,
          11,
          309,
          311,
          445,
          411,
          516,
          926,
          264,
          13482,
          293,
          1242,
          5541,
          294,
          633,
          1944,
          636,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4524,
        "id": 1222,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4523,
        "temperature": 0,
        "text": " Now it worked.",
        "tokens": [
          50564,
          823,
          309,
          2732,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4526,
        "id": 1223,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4524,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50614,
          407,
          510,
          311,
          264,
          551,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4534,
        "id": 1224,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4526,
        "temperature": 0,
        "text": " Remember how I said a neural network is an interconnected set of nodes with each connection being a weight.",
        "tokens": [
          50714,
          5459,
          577,
          286,
          848,
          257,
          18161,
          3209,
          307,
          364,
          36611,
          992,
          295,
          13891,
          365,
          1184,
          4984,
          885,
          257,
          3364,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4536,
        "id": 1225,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4534,
        "temperature": 0,
        "text": " So there's a couple important factors here.",
        "tokens": [
          51114,
          407,
          456,
          311,
          257,
          1916,
          1021,
          6771,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4538,
        "id": 1226,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4536,
        "temperature": 0,
        "text": " One is those weights are initialized randomly.",
        "tokens": [
          51214,
          1485,
          307,
          729,
          17443,
          366,
          5883,
          1602,
          16979,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4542,
        "id": 1227,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4538,
        "temperature": 0,
        "text": " And there are thoughtful ways that you can initialize those weights.",
        "tokens": [
          51314,
          400,
          456,
          366,
          21566,
          2098,
          300,
          291,
          393,
          5883,
          1125,
          729,
          17443,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18770580449380164,
        "compression_ratio": 1.710344827586207,
        "end": 4547,
        "id": 1228,
        "no_speech_prob": 0.016914628446102142,
        "seek": 451900,
        "start": 4542,
        "temperature": 0,
        "text": " But I kind of think if you initialize them in a certain way, the problem is there's multiple solutions here.",
        "tokens": [
          51514,
          583,
          286,
          733,
          295,
          519,
          498,
          291,
          5883,
          1125,
          552,
          294,
          257,
          1629,
          636,
          11,
          264,
          1154,
          307,
          456,
          311,
          3866,
          6547,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4552,
        "id": 1229,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4547,
        "temperature": 0,
        "text": " So there's one solution here where there's white all the way along this way.",
        "tokens": [
          50364,
          407,
          456,
          311,
          472,
          3827,
          510,
          689,
          456,
          311,
          2418,
          439,
          264,
          636,
          2051,
          341,
          636,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4557,
        "id": 1230,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4552,
        "temperature": 0,
        "text": " And if I refresh this a bunch of times, you'll see there's another solution where there's black all the way down through the middle.",
        "tokens": [
          50614,
          400,
          498,
          286,
          15134,
          341,
          257,
          3840,
          295,
          1413,
          11,
          291,
          603,
          536,
          456,
          311,
          1071,
          3827,
          689,
          456,
          311,
          2211,
          439,
          264,
          636,
          760,
          807,
          264,
          2808,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4561,
        "id": 1231,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4557,
        "temperature": 0,
        "text": " Because honestly the only thing that's correct is what's in the corners.",
        "tokens": [
          50864,
          1436,
          6095,
          264,
          787,
          551,
          300,
          311,
          3006,
          307,
          437,
          311,
          294,
          264,
          12413,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4563,
        "id": 1232,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4561,
        "temperature": 0,
        "text": " So I've run this a bunch of times.",
        "tokens": [
          51064,
          407,
          286,
          600,
          1190,
          341,
          257,
          3840,
          295,
          1413,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4565,
        "id": 1233,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4563,
        "temperature": 0,
        "text": " Isn't this the opposite of what we got before?",
        "tokens": [
          51164,
          6998,
          380,
          341,
          264,
          6182,
          295,
          437,
          321,
          658,
          949,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4566,
        "id": 1234,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4565,
        "temperature": 0,
        "text": " I can't remember.",
        "tokens": [
          51264,
          286,
          393,
          380,
          1604,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4567,
        "id": 1235,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4566,
        "temperature": 0,
        "text": " So there's a bunch of different solutions here.",
        "tokens": [
          51314,
          407,
          456,
          311,
          257,
          3840,
          295,
          819,
          6547,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4569,
        "id": 1236,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4567,
        "temperature": 0,
        "text": " And it sometimes can get stuck in that middle.",
        "tokens": [
          51364,
          400,
          309,
          2171,
          393,
          483,
          5541,
          294,
          300,
          2808,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14065133456526133,
        "compression_ratio": 1.9212328767123288,
        "end": 4573,
        "id": 1237,
        "no_speech_prob": 0.013019988313317299,
        "seek": 454700,
        "start": 4569,
        "temperature": 0,
        "text": " So one thing I might be able to do is play with something called the learning rate.",
        "tokens": [
          51464,
          407,
          472,
          551,
          286,
          1062,
          312,
          1075,
          281,
          360,
          307,
          862,
          365,
          746,
          1219,
          264,
          2539,
          3314,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2608983483113034,
        "compression_ratio": 1.5112359550561798,
        "end": 4579,
        "id": 1238,
        "no_speech_prob": 0.009859643876552582,
        "seek": 457300,
        "start": 4573,
        "temperature": 0,
        "text": " So there is a variable in the library called learning rate.",
        "tokens": [
          50364,
          407,
          456,
          307,
          257,
          7006,
          294,
          264,
          6405,
          1219,
          2539,
          3314,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2608983483113034,
        "compression_ratio": 1.5112359550561798,
        "end": 4584,
        "id": 1239,
        "no_speech_prob": 0.009859643876552582,
        "seek": 457300,
        "start": 4579,
        "temperature": 0,
        "text": " And I could say neural network learning rate equals.",
        "tokens": [
          50664,
          400,
          286,
          727,
          584,
          18161,
          3209,
          2539,
          3314,
          6915,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2608983483113034,
        "compression_ratio": 1.5112359550561798,
        "end": 4587,
        "id": 1240,
        "no_speech_prob": 0.009859643876552582,
        "seek": 457300,
        "start": 4584,
        "temperature": 0,
        "text": " There's a set function, but I think...",
        "tokens": [
          50914,
          821,
          311,
          257,
          992,
          2445,
          11,
          457,
          286,
          519,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.2608983483113034,
        "compression_ratio": 1.5112359550561798,
        "end": 4590,
        "id": 1241,
        "no_speech_prob": 0.009859643876552582,
        "seek": 457300,
        "start": 4587,
        "temperature": 0,
        "text": " Time out here.",
        "tokens": [
          51064,
          6161,
          484,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2608983483113034,
        "compression_ratio": 1.5112359550561798,
        "end": 4596,
        "id": 1242,
        "no_speech_prob": 0.009859643876552582,
        "seek": 457300,
        "start": 4594,
        "temperature": 0,
        "text": " Just pause for a second.",
        "tokens": [
          51414,
          1449,
          10465,
          337,
          257,
          1150,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2608983483113034,
        "compression_ratio": 1.5112359550561798,
        "end": 4602,
        "id": 1243,
        "no_speech_prob": 0.009859643876552582,
        "seek": 457300,
        "start": 4596,
        "temperature": 0,
        "text": " Does somebody who is watching this know if this has this set learning rate...",
        "tokens": [
          51514,
          4402,
          2618,
          567,
          307,
          1976,
          341,
          458,
          498,
          341,
          575,
          341,
          992,
          2539,
          3314,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4604,
        "id": 1244,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4603,
        "temperature": 0,
        "text": " Does this mean I should...",
        "tokens": [
          50414,
          4402,
          341,
          914,
          286,
          820,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4608,
        "id": 1245,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4604,
        "temperature": 0,
        "text": " Maybe this isn't using this getter setter in the ES6 way.",
        "tokens": [
          50464,
          2704,
          341,
          1943,
          380,
          1228,
          341,
          483,
          391,
          992,
          391,
          294,
          264,
          12564,
          21,
          636,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4611,
        "id": 1246,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4608,
        "temperature": 0,
        "text": " Does this mean I should call a function called set learning rate?",
        "tokens": [
          50664,
          4402,
          341,
          914,
          286,
          820,
          818,
          257,
          2445,
          1219,
          992,
          2539,
          3314,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4615,
        "id": 1247,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4611,
        "temperature": 0,
        "text": " Or does this mean I'm supposed to do the thing where I can actually say learning rate equals",
        "tokens": [
          50814,
          1610,
          775,
          341,
          914,
          286,
          478,
          3442,
          281,
          360,
          264,
          551,
          689,
          286,
          393,
          767,
          584,
          2539,
          3314,
          6915,
          51014
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4618,
        "id": 1248,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4615,
        "temperature": 0,
        "text": " and it kind of automatically calls this function?",
        "tokens": [
          51014,
          293,
          309,
          733,
          295,
          6772,
          5498,
          341,
          2445,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4624,
        "id": 1249,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4622,
        "temperature": 0,
        "text": " I'm waiting for somebody to weigh in.",
        "tokens": [
          51364,
          286,
          478,
          3806,
          337,
          2618,
          281,
          13843,
          294,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19065662421802482,
        "compression_ratio": 1.7782805429864252,
        "end": 4630,
        "id": 1250,
        "no_speech_prob": 0.00017674030095804483,
        "seek": 460200,
        "start": 4624,
        "temperature": 0,
        "text": " So I should call set learning rate the way that it's written.",
        "tokens": [
          51464,
          407,
          286,
          820,
          818,
          992,
          2539,
          3314,
          264,
          636,
          300,
          309,
          311,
          3720,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4636,
        "id": 1251,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4633,
        "temperature": 0,
        "text": " Is there some fancy getter setter thing you can do?",
        "tokens": [
          50414,
          1119,
          456,
          512,
          10247,
          483,
          391,
          992,
          391,
          551,
          291,
          393,
          360,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4638,
        "id": 1252,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4636,
        "temperature": 0,
        "text": " That's not an ES6 setter.",
        "tokens": [
          50564,
          663,
          311,
          406,
          364,
          12564,
          21,
          992,
          391,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4639,
        "id": 1253,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4638,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4643,
        "id": 1254,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4639,
        "temperature": 0,
        "text": " So someday it might be an ES6 setter, but it's not going to be right now.",
        "tokens": [
          50714,
          407,
          19412,
          309,
          1062,
          312,
          364,
          12564,
          21,
          992,
          391,
          11,
          457,
          309,
          311,
          406,
          516,
          281,
          312,
          558,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4644,
        "id": 1255,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4643,
        "temperature": 0,
        "text": " No setter. Okay.",
        "tokens": [
          50914,
          883,
          992,
          391,
          13,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4646,
        "id": 1256,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4644,
        "temperature": 0,
        "text": " Should I make it a setter?",
        "tokens": [
          50964,
          6454,
          286,
          652,
          309,
          257,
          992,
          391,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4647,
        "id": 1257,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4646,
        "temperature": 0,
        "text": " Like should the library have a setter?",
        "tokens": [
          51064,
          1743,
          820,
          264,
          6405,
          362,
          257,
          992,
          391,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.1606462277864155,
        "compression_ratio": 1.631578947368421,
        "end": 4649,
        "id": 1258,
        "no_speech_prob": 0.000019833099941024557,
        "seek": 463200,
        "start": 4647,
        "temperature": 0,
        "text": " Would that be like a good thing to do?",
        "tokens": [
          51114,
          6068,
          300,
          312,
          411,
          257,
          665,
          551,
          281,
          360,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.2423751089307997,
        "compression_ratio": 1.2095238095238094,
        "end": 4667,
        "id": 1259,
        "no_speech_prob": 0.006692210678011179,
        "seek": 466200,
        "start": 4663,
        "temperature": 0,
        "text": " This is me just waiting for the internet to tell me which to do.",
        "tokens": [
          50414,
          639,
          307,
          385,
          445,
          3806,
          337,
          264,
          4705,
          281,
          980,
          385,
          597,
          281,
          360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2423751089307997,
        "compression_ratio": 1.2095238095238094,
        "end": 4678,
        "id": 1260,
        "no_speech_prob": 0.006692210678011179,
        "seek": 466200,
        "start": 4675,
        "temperature": 0,
        "text": " I mean, I don't really need to be getting into this right now.",
        "tokens": [
          51014,
          286,
          914,
          11,
          286,
          500,
          380,
          534,
          643,
          281,
          312,
          1242,
          666,
          341,
          558,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.232036001032049,
        "compression_ratio": 1.4179104477611941,
        "end": 4694,
        "id": 1261,
        "no_speech_prob": 0.002590922638773918,
        "seek": 469200,
        "start": 4693,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50414,
          1779,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.232036001032049,
        "compression_ratio": 1.4179104477611941,
        "end": 4706,
        "id": 1262,
        "no_speech_prob": 0.002590922638773918,
        "seek": 469200,
        "start": 4703,
        "temperature": 0,
        "text": " It's only really useful if I want to get the learning rate.",
        "tokens": [
          50914,
          467,
          311,
          787,
          534,
          4420,
          498,
          286,
          528,
          281,
          483,
          264,
          2539,
          3314,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.232036001032049,
        "compression_ratio": 1.4179104477611941,
        "end": 4707,
        "id": 1263,
        "no_speech_prob": 0.002590922638773918,
        "seek": 469200,
        "start": 4706,
        "temperature": 0,
        "text": " Okay. Okay.",
        "tokens": [
          51064,
          1033,
          13,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.232036001032049,
        "compression_ratio": 1.4179104477611941,
        "end": 4708,
        "id": 1264,
        "no_speech_prob": 0.002590922638773918,
        "seek": 469200,
        "start": 4707,
        "temperature": 0,
        "text": " Let's not worry about that right now.",
        "tokens": [
          51114,
          961,
          311,
          406,
          3292,
          466,
          300,
          558,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.232036001032049,
        "compression_ratio": 1.4179104477611941,
        "end": 4720,
        "id": 1265,
        "no_speech_prob": 0.002590922638773918,
        "seek": 469200,
        "start": 4715,
        "temperature": 0,
        "text": " So I forgot the library actually has a function called set learning rate.",
        "tokens": [
          51514,
          407,
          286,
          5298,
          264,
          6405,
          767,
          575,
          257,
          2445,
          1219,
          992,
          2539,
          3314,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4724,
        "id": 1266,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4721,
        "temperature": 0,
        "text": " And so what I can do is I can set this to some value.",
        "tokens": [
          50414,
          400,
          370,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          992,
          341,
          281,
          512,
          2158,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4726,
        "id": 1267,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4724,
        "temperature": 0,
        "text": " Now what should that learning rate be?",
        "tokens": [
          50564,
          823,
          437,
          820,
          300,
          2539,
          3314,
          312,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4728,
        "id": 1268,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4726,
        "temperature": 0,
        "text": " The learning rate is like how big are these steps?",
        "tokens": [
          50664,
          440,
          2539,
          3314,
          307,
          411,
          577,
          955,
          366,
          613,
          4439,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4730,
        "id": 1269,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4728,
        "temperature": 0,
        "text": " How big are these adjustments?",
        "tokens": [
          50764,
          1012,
          955,
          366,
          613,
          18624,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4737,
        "id": 1270,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4730,
        "temperature": 0,
        "text": " And so maybe what I'll do here is I will create a LR slider for learning rate slider.",
        "tokens": [
          50864,
          400,
          370,
          1310,
          437,
          286,
          603,
          360,
          510,
          307,
          286,
          486,
          1884,
          257,
          441,
          49,
          26046,
          337,
          2539,
          3314,
          26046,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4741,
        "id": 1271,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4737,
        "temperature": 0,
        "text": " And I'm going to say LR slider equals create slider.",
        "tokens": [
          51214,
          400,
          286,
          478,
          516,
          281,
          584,
          441,
          49,
          26046,
          6915,
          1884,
          26046,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1438531787307174,
        "compression_ratio": 1.8095238095238095,
        "end": 4746,
        "id": 1272,
        "no_speech_prob": 0.0007096607587300241,
        "seek": 472000,
        "start": 4741,
        "temperature": 0,
        "text": " And so I'm going to have learning rates that go between 0 and 0.5.",
        "tokens": [
          51414,
          400,
          370,
          286,
          478,
          516,
          281,
          362,
          2539,
          6846,
          300,
          352,
          1296,
          1958,
          293,
          1958,
          13,
          20,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19192025878212668,
        "compression_ratio": 1.518348623853211,
        "end": 4754,
        "id": 1273,
        "no_speech_prob": 0.01406308077275753,
        "seek": 474600,
        "start": 4746,
        "temperature": 0,
        "text": " That's probably a ridiculous range with an incremental step of 0.1 and an incremental step of 0.01.",
        "tokens": [
          50364,
          663,
          311,
          1391,
          257,
          11083,
          3613,
          365,
          364,
          35759,
          1823,
          295,
          1958,
          13,
          16,
          293,
          364,
          35759,
          1823,
          295,
          1958,
          13,
          10607,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19192025878212668,
        "compression_ratio": 1.518348623853211,
        "end": 4760,
        "id": 1274,
        "no_speech_prob": 0.01406308077275753,
        "seek": 474600,
        "start": 4754,
        "temperature": 0,
        "text": " So this is a P5 DOM function create slider that creates an HTML5 slider, puts it on the page.",
        "tokens": [
          50764,
          407,
          341,
          307,
          257,
          430,
          20,
          35727,
          2445,
          1884,
          26046,
          300,
          7829,
          364,
          17995,
          20,
          26046,
          11,
          8137,
          309,
          322,
          264,
          3028,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19192025878212668,
        "compression_ratio": 1.518348623853211,
        "end": 4767,
        "id": 1275,
        "no_speech_prob": 0.01406308077275753,
        "seek": 474600,
        "start": 4760,
        "temperature": 0,
        "text": " And so now I could just say LR underscore slider dot value.",
        "tokens": [
          51064,
          400,
          370,
          586,
          286,
          727,
          445,
          584,
          441,
          49,
          37556,
          26046,
          5893,
          2158,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19192025878212668,
        "compression_ratio": 1.518348623853211,
        "end": 4775,
        "id": 1276,
        "no_speech_prob": 0.01406308077275753,
        "seek": 474600,
        "start": 4767,
        "temperature": 0,
        "text": " So this should, if I'm right, always set the learning rate according to this.",
        "tokens": [
          51414,
          407,
          341,
          820,
          11,
          498,
          286,
          478,
          558,
          11,
          1009,
          992,
          264,
          2539,
          3314,
          4650,
          281,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4780,
        "id": 1277,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4775,
        "temperature": 0,
        "text": " So let's see if I put it up here and I say neural network learning rate, it's 0.5.",
        "tokens": [
          50364,
          407,
          718,
          311,
          536,
          498,
          286,
          829,
          309,
          493,
          510,
          293,
          286,
          584,
          18161,
          3209,
          2539,
          3314,
          11,
          309,
          311,
          1958,
          13,
          20,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4784,
        "id": 1278,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4780,
        "temperature": 0,
        "text": " And if I go down to here, it is 0.",
        "tokens": [
          50614,
          400,
          498,
          286,
          352,
          760,
          281,
          510,
          11,
          309,
          307,
          1958,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4786,
        "id": 1279,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4784,
        "temperature": 0,
        "text": " Now I shouldn't let it be 0, right?",
        "tokens": [
          50814,
          823,
          286,
          4659,
          380,
          718,
          309,
          312,
          1958,
          11,
          558,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4790,
        "id": 1280,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4786,
        "temperature": 0,
        "text": " So the lowest the learning rate should be is probably 0.01.",
        "tokens": [
          50914,
          407,
          264,
          12437,
          264,
          2539,
          3314,
          820,
          312,
          307,
          1391,
          1958,
          13,
          10607,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4793,
        "id": 1281,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4790,
        "temperature": 0,
        "text": " So let's see if we can get it stuck.",
        "tokens": [
          51114,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          483,
          309,
          5541,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4795,
        "id": 1282,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4793,
        "temperature": 0,
        "text": " Now of course I'm going to hit refresh.",
        "tokens": [
          51264,
          823,
          295,
          1164,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4796,
        "id": 1283,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4795,
        "temperature": 0,
        "text": " Okay, it's stuck.",
        "tokens": [
          51364,
          1033,
          11,
          309,
          311,
          5541,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17743474520169772,
        "compression_ratio": 1.6468253968253967,
        "end": 4801,
        "id": 1284,
        "no_speech_prob": 0.0022169724106788635,
        "seek": 477500,
        "start": 4796,
        "temperature": 0,
        "text": " Let's see if just like allowing it to take bigger steps one way or the other will sort of fix the problem.",
        "tokens": [
          51414,
          961,
          311,
          536,
          498,
          445,
          411,
          8293,
          309,
          281,
          747,
          3801,
          4439,
          472,
          636,
          420,
          264,
          661,
          486,
          1333,
          295,
          3191,
          264,
          1154,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.25853267209283237,
        "compression_ratio": 1.5138888888888888,
        "end": 4804,
        "id": 1285,
        "no_speech_prob": 0.001187895075418055,
        "seek": 480100,
        "start": 4802,
        "temperature": 0,
        "text": " It's still really stuck.",
        "tokens": [
          50414,
          467,
          311,
          920,
          534,
          5541,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25853267209283237,
        "compression_ratio": 1.5138888888888888,
        "end": 4806,
        "id": 1286,
        "no_speech_prob": 0.001187895075418055,
        "seek": 480100,
        "start": 4804,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          50514,
          14711,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.25853267209283237,
        "compression_ratio": 1.5138888888888888,
        "end": 4811,
        "id": 1287,
        "no_speech_prob": 0.001187895075418055,
        "seek": 480100,
        "start": 4806,
        "temperature": 0,
        "text": " Now I guess what I could do is if it's stuck, I could reset the neural network.",
        "tokens": [
          50614,
          823,
          286,
          2041,
          437,
          286,
          727,
          360,
          307,
          498,
          309,
          311,
          5541,
          11,
          286,
          727,
          14322,
          264,
          18161,
          3209,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.25853267209283237,
        "compression_ratio": 1.5138888888888888,
        "end": 4818,
        "id": 1288,
        "no_speech_prob": 0.001187895075418055,
        "seek": 480100,
        "start": 4811,
        "temperature": 0,
        "text": " So neural network, is there a function in the neural network library to randomize the weights again?",
        "tokens": [
          50864,
          407,
          18161,
          3209,
          11,
          307,
          456,
          257,
          2445,
          294,
          264,
          18161,
          3209,
          6405,
          281,
          4974,
          1125,
          264,
          17443,
          797,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.22756659984588623,
        "compression_ratio": 1.2520325203252032,
        "end": 4837,
        "id": 1289,
        "no_speech_prob": 0.010818114504218102,
        "seek": 481800,
        "start": 4819,
        "temperature": 0,
        "text": " Let me go from where I stopped with the slider.",
        "tokens": [
          50414,
          961,
          385,
          352,
          490,
          689,
          286,
          5936,
          365,
          264,
          26046,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22756659984588623,
        "compression_ratio": 1.2520325203252032,
        "end": 4840,
        "id": 1290,
        "no_speech_prob": 0.010818114504218102,
        "seek": 481800,
        "start": 4837,
        "temperature": 0,
        "text": " No, that doesn't really work.",
        "tokens": [
          51314,
          883,
          11,
          300,
          1177,
          380,
          534,
          589,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22756659984588623,
        "compression_ratio": 1.2520325203252032,
        "end": 4845,
        "id": 1291,
        "no_speech_prob": 0.010818114504218102,
        "seek": 481800,
        "start": 4840,
        "temperature": 0,
        "text": " Well, one thing I could do is I could kind of like re-randomize the weights.",
        "tokens": [
          51464,
          1042,
          11,
          472,
          551,
          286,
          727,
          360,
          307,
          286,
          727,
          733,
          295,
          411,
          319,
          12,
          3699,
          298,
          1125,
          264,
          17443,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2702414007747875,
        "compression_ratio": 1.7427184466019416,
        "end": 4850,
        "id": 1292,
        "no_speech_prob": 0.0758536159992218,
        "seek": 484500,
        "start": 4846,
        "temperature": 0,
        "text": " I could like, that could be something I don't know.",
        "tokens": [
          50414,
          286,
          727,
          411,
          11,
          300,
          727,
          312,
          746,
          286,
          500,
          380,
          458,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2702414007747875,
        "compression_ratio": 1.7427184466019416,
        "end": 4854,
        "id": 1293,
        "no_speech_prob": 0.0758536159992218,
        "seek": 484500,
        "start": 4850,
        "temperature": 0,
        "text": " Oh, the learning rate is only being applied after a thousand.",
        "tokens": [
          50614,
          876,
          11,
          264,
          2539,
          3314,
          307,
          787,
          885,
          6456,
          934,
          257,
          4714,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2702414007747875,
        "compression_ratio": 1.7427184466019416,
        "end": 4857,
        "id": 1294,
        "no_speech_prob": 0.0758536159992218,
        "seek": 484500,
        "start": 4854,
        "temperature": 0,
        "text": " No, but it'll come back.",
        "tokens": [
          50814,
          883,
          11,
          457,
          309,
          603,
          808,
          646,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2702414007747875,
        "compression_ratio": 1.7427184466019416,
        "end": 4864,
        "id": 1295,
        "no_speech_prob": 0.0758536159992218,
        "seek": 484500,
        "start": 4857,
        "temperature": 0,
        "text": " Because once it doesn't get, that's a good point in the chat to be saying it's learning rate is only being applied after a thousand iterations.",
        "tokens": [
          50964,
          1436,
          1564,
          309,
          1177,
          380,
          483,
          11,
          300,
          311,
          257,
          665,
          935,
          294,
          264,
          5081,
          281,
          312,
          1566,
          309,
          311,
          2539,
          3314,
          307,
          787,
          885,
          6456,
          934,
          257,
          4714,
          36540,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2702414007747875,
        "compression_ratio": 1.7427184466019416,
        "end": 4867,
        "id": 1296,
        "no_speech_prob": 0.0758536159992218,
        "seek": 484500,
        "start": 4864,
        "temperature": 0,
        "text": " But it just has to wait for that 1,000.",
        "tokens": [
          51314,
          583,
          309,
          445,
          575,
          281,
          1699,
          337,
          300,
          502,
          11,
          1360,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2702414007747875,
        "compression_ratio": 1.7427184466019416,
        "end": 4869,
        "id": 1297,
        "no_speech_prob": 0.0758536159992218,
        "seek": 484500,
        "start": 4867,
        "temperature": 0,
        "text": " It's not like, then it's back again.",
        "tokens": [
          51464,
          467,
          311,
          406,
          411,
          11,
          550,
          309,
          311,
          646,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2875587980625993,
        "compression_ratio": 1.3902439024390243,
        "end": 4874,
        "id": 1298,
        "no_speech_prob": 0.27823811769485474,
        "seek": 486900,
        "start": 4870,
        "temperature": 0,
        "text": " The reason why it gets stuck is because there's two possible solutions.",
        "tokens": [
          50414,
          440,
          1778,
          983,
          309,
          2170,
          5541,
          307,
          570,
          456,
          311,
          732,
          1944,
          6547,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2875587980625993,
        "compression_ratio": 1.3902439024390243,
        "end": 4880,
        "id": 1299,
        "no_speech_prob": 0.27823811769485474,
        "seek": 486900,
        "start": 4874,
        "temperature": 0,
        "text": " I was going to add four hidden nodes and I think that will help it.",
        "tokens": [
          50614,
          286,
          390,
          516,
          281,
          909,
          1451,
          7633,
          13891,
          293,
          286,
          519,
          300,
          486,
          854,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2875587980625993,
        "compression_ratio": 1.3902439024390243,
        "end": 4885,
        "id": 1300,
        "no_speech_prob": 0.27823811769485474,
        "seek": 486900,
        "start": 4880,
        "temperature": 0,
        "text": " But I'm trying to think of, I can't remember what I put into the neural network library.",
        "tokens": [
          50914,
          583,
          286,
          478,
          1382,
          281,
          519,
          295,
          11,
          286,
          393,
          380,
          1604,
          437,
          286,
          829,
          666,
          264,
          18161,
          3209,
          6405,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.5200010344039562,
        "compression_ratio": 1.2758620689655173,
        "end": 4892,
        "id": 1301,
        "no_speech_prob": 0.05665022134780884,
        "seek": 488500,
        "start": 4885,
        "temperature": 0,
        "text": " I guess to reset it.",
        "tokens": [
          50364,
          286,
          2041,
          281,
          14322,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.5200010344039562,
        "compression_ratio": 1.2758620689655173,
        "end": 4898,
        "id": 1302,
        "no_speech_prob": 0.05665022134780884,
        "seek": 488500,
        "start": 4892,
        "temperature": 0,
        "text": " Okay, I have an idea now.",
        "tokens": [
          50714,
          1033,
          11,
          286,
          362,
          364,
          1558,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.5200010344039562,
        "compression_ratio": 1.2758620689655173,
        "end": 4904,
        "id": 1303,
        "no_speech_prob": 0.05665022134780884,
        "seek": 488500,
        "start": 4898,
        "temperature": 0,
        "text": " Okay, let me try this again.",
        "tokens": [
          51014,
          1033,
          11,
          718,
          385,
          853,
          341,
          797,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.5200010344039562,
        "compression_ratio": 1.2758620689655173,
        "end": 4910,
        "id": 1304,
        "no_speech_prob": 0.05665022134780884,
        "seek": 488500,
        "start": 4904,
        "temperature": 0,
        "text": " So let's try, let's try this again.",
        "tokens": [
          51314,
          407,
          718,
          311,
          853,
          11,
          718,
          311,
          853,
          341,
          797,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21161627215008402,
        "compression_ratio": 1.5657142857142856,
        "end": 4918,
        "id": 1305,
        "no_speech_prob": 0.017441995441913605,
        "seek": 491000,
        "start": 4911,
        "temperature": 0,
        "text": " So let's try, let's try, now let's try lowering the learning rate.",
        "tokens": [
          50414,
          407,
          718,
          311,
          853,
          11,
          718,
          311,
          853,
          11,
          586,
          718,
          311,
          853,
          28124,
          264,
          2539,
          3314,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21161627215008402,
        "compression_ratio": 1.5657142857142856,
        "end": 4923,
        "id": 1306,
        "no_speech_prob": 0.017441995441913605,
        "seek": 491000,
        "start": 4918,
        "temperature": 0,
        "text": " That didn't really seem to fix it.",
        "tokens": [
          50764,
          663,
          994,
          380,
          534,
          1643,
          281,
          3191,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21161627215008402,
        "compression_ratio": 1.5657142857142856,
        "end": 4925,
        "id": 1307,
        "no_speech_prob": 0.017441995441913605,
        "seek": 491000,
        "start": 4923,
        "temperature": 0,
        "text": " It's really stuck here.",
        "tokens": [
          51014,
          467,
          311,
          534,
          5541,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21161627215008402,
        "compression_ratio": 1.5657142857142856,
        "end": 4928,
        "id": 1308,
        "no_speech_prob": 0.017441995441913605,
        "seek": 491000,
        "start": 4925,
        "temperature": 0,
        "text": " So one thing I could do is I could just like start it over.",
        "tokens": [
          51114,
          407,
          472,
          551,
          286,
          727,
          360,
          307,
          286,
          727,
          445,
          411,
          722,
          309,
          670,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21161627215008402,
        "compression_ratio": 1.5657142857142856,
        "end": 4931,
        "id": 1309,
        "no_speech_prob": 0.017441995441913605,
        "seek": 491000,
        "start": 4928,
        "temperature": 0,
        "text": " Like new neural network 2, 2, 1.",
        "tokens": [
          51264,
          1743,
          777,
          18161,
          3209,
          568,
          11,
          568,
          11,
          502,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21161627215008402,
        "compression_ratio": 1.5657142857142856,
        "end": 4936,
        "id": 1310,
        "no_speech_prob": 0.017441995441913605,
        "seek": 491000,
        "start": 4931,
        "temperature": 0,
        "text": " And now I've just started it over and it's still stuck.",
        "tokens": [
          51414,
          400,
          586,
          286,
          600,
          445,
          1409,
          309,
          670,
          293,
          309,
          311,
          920,
          5541,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4939,
        "id": 1311,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4937,
        "temperature": 0,
        "text": " Let's try it again.",
        "tokens": [
          50414,
          961,
          311,
          853,
          309,
          797,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4941,
        "id": 1312,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4939,
        "temperature": 0,
        "text": " Let's leave it at like 0.1.",
        "tokens": [
          50514,
          961,
          311,
          1856,
          309,
          412,
          411,
          1958,
          13,
          16,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4947,
        "id": 1313,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4941,
        "temperature": 0,
        "text": " So I could write this as a function to like restart it a bunch of times and just get lucky with the first weights.",
        "tokens": [
          50614,
          407,
          286,
          727,
          2464,
          341,
          382,
          257,
          2445,
          281,
          411,
          21022,
          309,
          257,
          3840,
          295,
          1413,
          293,
          445,
          483,
          6356,
          365,
          264,
          700,
          17443,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4950,
        "id": 1314,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4947,
        "temperature": 0,
        "text": " Another thing I could try though, just to see if this really helps.",
        "tokens": [
          50914,
          3996,
          551,
          286,
          727,
          853,
          1673,
          11,
          445,
          281,
          536,
          498,
          341,
          534,
          3665,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4956,
        "id": 1315,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4950,
        "temperature": 0,
        "text": " The thing is what I probably need to do is be more thoughtful about how the weights are initialized.",
        "tokens": [
          51064,
          440,
          551,
          307,
          437,
          286,
          1391,
          643,
          281,
          360,
          307,
          312,
          544,
          21566,
          466,
          577,
          264,
          17443,
          366,
          5883,
          1602,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4959,
        "id": 1316,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4956,
        "temperature": 0,
        "text": " Which is something I would probably want to build into the neural network library.",
        "tokens": [
          51364,
          3013,
          307,
          746,
          286,
          576,
          1391,
          528,
          281,
          1322,
          666,
          264,
          18161,
          3209,
          6405,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21859029134114583,
        "compression_ratio": 1.6236933797909407,
        "end": 4962,
        "id": 1317,
        "no_speech_prob": 0.14413557946681976,
        "seek": 493600,
        "start": 4959,
        "temperature": 0,
        "text": " Just out of curiosity, let's add four hidden nodes.",
        "tokens": [
          51514,
          1449,
          484,
          295,
          18769,
          11,
          718,
          311,
          909,
          1451,
          7633,
          13891,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21575116439604422,
        "compression_ratio": 1.5149700598802396,
        "end": 4968,
        "id": 1318,
        "no_speech_prob": 0.057490721344947815,
        "seek": 496200,
        "start": 4962,
        "temperature": 0,
        "text": " So do we make the network smarter by giving it more things to learn about, right?",
        "tokens": [
          50364,
          407,
          360,
          321,
          652,
          264,
          3209,
          20294,
          538,
          2902,
          309,
          544,
          721,
          281,
          1466,
          466,
          11,
          558,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.21575116439604422,
        "compression_ratio": 1.5149700598802396,
        "end": 4971,
        "id": 1319,
        "no_speech_prob": 0.057490721344947815,
        "seek": 496200,
        "start": 4968,
        "temperature": 0,
        "text": " So I'm adding in all of these.",
        "tokens": [
          50664,
          407,
          286,
          478,
          5127,
          294,
          439,
          295,
          613,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21575116439604422,
        "compression_ratio": 1.5149700598802396,
        "end": 4973,
        "id": 1320,
        "no_speech_prob": 0.057490721344947815,
        "seek": 496200,
        "start": 4971,
        "temperature": 0,
        "text": " Whoops, this goes to here.",
        "tokens": [
          50814,
          45263,
          11,
          341,
          1709,
          281,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21575116439604422,
        "compression_ratio": 1.5149700598802396,
        "end": 4975,
        "id": 1321,
        "no_speech_prob": 0.057490721344947815,
        "seek": 496200,
        "start": 4973,
        "temperature": 0,
        "text": " There are more connections.",
        "tokens": [
          50914,
          821,
          366,
          544,
          9271,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21575116439604422,
        "compression_ratio": 1.5149700598802396,
        "end": 4979,
        "id": 1322,
        "no_speech_prob": 0.057490721344947815,
        "seek": 496200,
        "start": 4975,
        "temperature": 0,
        "text": " More connections, more possible things for it to learn about.",
        "tokens": [
          51014,
          5048,
          9271,
          11,
          544,
          1944,
          721,
          337,
          309,
          281,
          1466,
          466,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21575116439604422,
        "compression_ratio": 1.5149700598802396,
        "end": 4983,
        "id": 1323,
        "no_speech_prob": 0.057490721344947815,
        "seek": 496200,
        "start": 4979,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51214,
          961,
          311,
          536,
          437,
          2314,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 4985,
        "id": 1324,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 4983,
        "temperature": 0,
        "text": " Ooh, look at this.",
        "tokens": [
          50364,
          7951,
          11,
          574,
          412,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 4987,
        "id": 1325,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 4985,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          50464,
          2053,
          412,
          300,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 4989,
        "id": 1326,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 4987,
        "temperature": 0,
        "text": " It's nice and curvy.",
        "tokens": [
          50564,
          467,
          311,
          1481,
          293,
          1262,
          11869,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 4991,
        "id": 1327,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 4989,
        "temperature": 0,
        "text": " It's sort of like learned it in a slightly different way.",
        "tokens": [
          50664,
          467,
          311,
          1333,
          295,
          411,
          3264,
          309,
          294,
          257,
          4748,
          819,
          636,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 4995,
        "id": 1328,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 4991,
        "temperature": 0,
        "text": " And I suspect that I'm going to have a lot harder time having it get stuck.",
        "tokens": [
          50764,
          400,
          286,
          9091,
          300,
          286,
          478,
          516,
          281,
          362,
          257,
          688,
          6081,
          565,
          1419,
          309,
          483,
          5541,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 5001,
        "id": 1329,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 4995,
        "temperature": 0,
        "text": " Now, you can see that there's multiple quote unquote correct solutions to how the space looks.",
        "tokens": [
          50964,
          823,
          11,
          291,
          393,
          536,
          300,
          456,
          311,
          3866,
          6513,
          37557,
          3006,
          6547,
          281,
          577,
          264,
          1901,
          1542,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 5004,
        "id": 1330,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 5001,
        "temperature": 0,
        "text": " But it's really able to figure it out.",
        "tokens": [
          51264,
          583,
          309,
          311,
          534,
          1075,
          281,
          2573,
          309,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 5008,
        "id": 1331,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 5004,
        "temperature": 0,
        "text": " Now, that's really the end of this video.",
        "tokens": [
          51414,
          823,
          11,
          300,
          311,
          534,
          264,
          917,
          295,
          341,
          960,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.28544223022460935,
        "compression_ratio": 1.6356877323420074,
        "end": 5012,
        "id": 1332,
        "no_speech_prob": 0.01854603737592697,
        "seek": 498300,
        "start": 5008,
        "temperature": 0,
        "text": " The point of this mostly was just to show you how to build a neural network.",
        "tokens": [
          51614,
          440,
          935,
          295,
          341,
          5240,
          390,
          445,
          281,
          855,
          291,
          577,
          281,
          1322,
          257,
          18161,
          3209,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5015,
        "id": 1333,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5012,
        "temperature": 0,
        "text": " The point of this mostly was just to test the neural network library.",
        "tokens": [
          50364,
          440,
          935,
          295,
          341,
          5240,
          390,
          445,
          281,
          1500,
          264,
          18161,
          3209,
          6405,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5018,
        "id": 1334,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5015,
        "temperature": 0,
        "text": " So it works.",
        "tokens": [
          50514,
          407,
          309,
          1985,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5019,
        "id": 1335,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5018,
        "temperature": 0,
        "text": " I can use it.",
        "tokens": [
          50664,
          286,
          393,
          764,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5021,
        "id": 1336,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5019,
        "temperature": 0,
        "text": " I can give it data to learn.",
        "tokens": [
          50714,
          286,
          393,
          976,
          309,
          1412,
          281,
          1466,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5023,
        "id": 1337,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5021,
        "temperature": 0,
        "text": " I can try it with other data.",
        "tokens": [
          50814,
          286,
          393,
          853,
          309,
          365,
          661,
          1412,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5025,
        "id": 1338,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5023,
        "temperature": 0,
        "text": " I can visualize its result.",
        "tokens": [
          50914,
          286,
          393,
          23273,
          1080,
          1874,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5026,
        "id": 1339,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5025,
        "temperature": 0,
        "text": " Now, so here's the thing.",
        "tokens": [
          51014,
          823,
          11,
          370,
          510,
          311,
          264,
          551,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5027,
        "id": 1340,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5026,
        "temperature": 0,
        "text": " You're watching this video.",
        "tokens": [
          51064,
          509,
          434,
          1976,
          341,
          960,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5028,
        "id": 1341,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5027,
        "temperature": 0,
        "text": " What should you do next?",
        "tokens": [
          51114,
          708,
          820,
          291,
          360,
          958,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5035,
        "id": 1342,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5028,
        "temperature": 0,
        "text": " Well, first of all, I'm going to do another challenge, which is the kind of classic hello world neural network machine learning example,",
        "tokens": [
          51164,
          1042,
          11,
          700,
          295,
          439,
          11,
          286,
          478,
          516,
          281,
          360,
          1071,
          3430,
          11,
          597,
          307,
          264,
          733,
          295,
          7230,
          7751,
          1002,
          18161,
          3209,
          3479,
          2539,
          1365,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5037,
        "id": 1343,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5035,
        "temperature": 0,
        "text": " which is to recognize handwritten digits.",
        "tokens": [
          51514,
          597,
          307,
          281,
          5521,
          1011,
          26859,
          27011,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17948274283573545,
        "compression_ratio": 1.6666666666666667,
        "end": 5041,
        "id": 1344,
        "no_speech_prob": 0.18950210511684418,
        "seek": 501200,
        "start": 5037,
        "temperature": 0,
        "text": " And there's a well-known test set called MNIST that I will use.",
        "tokens": [
          51614,
          400,
          456,
          311,
          257,
          731,
          12,
          6861,
          1500,
          992,
          1219,
          376,
          45,
          19756,
          300,
          286,
          486,
          764,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18635669350624084,
        "compression_ratio": 1.7173913043478262,
        "end": 5046,
        "id": 1345,
        "no_speech_prob": 0.0019267058232799172,
        "seek": 504100,
        "start": 5041,
        "temperature": 0,
        "text": " I kind of don't want to, but I think it's worth me just doing that, just to do it.",
        "tokens": [
          50364,
          286,
          733,
          295,
          500,
          380,
          528,
          281,
          11,
          457,
          286,
          519,
          309,
          311,
          3163,
          385,
          445,
          884,
          300,
          11,
          445,
          281,
          360,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18635669350624084,
        "compression_ratio": 1.7173913043478262,
        "end": 5048,
        "id": 1346,
        "no_speech_prob": 0.0019267058232799172,
        "seek": 504100,
        "start": 5046,
        "temperature": 0,
        "text": " But that will be a more interesting problem.",
        "tokens": [
          50614,
          583,
          300,
          486,
          312,
          257,
          544,
          1880,
          1154,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18635669350624084,
        "compression_ratio": 1.7173913043478262,
        "end": 5054,
        "id": 1347,
        "no_speech_prob": 0.0019267058232799172,
        "seek": 504100,
        "start": 5048,
        "temperature": 0,
        "text": " And then we can even make it so that if I draw a digit, can the neural network detect what digit it is?",
        "tokens": [
          50714,
          400,
          550,
          321,
          393,
          754,
          652,
          309,
          370,
          300,
          498,
          286,
          2642,
          257,
          14293,
          11,
          393,
          264,
          18161,
          3209,
          5531,
          437,
          14293,
          309,
          307,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18635669350624084,
        "compression_ratio": 1.7173913043478262,
        "end": 5056,
        "id": 1348,
        "no_speech_prob": 0.0019267058232799172,
        "seek": 504100,
        "start": 5054,
        "temperature": 0,
        "text": " So anyway, so that's coming.",
        "tokens": [
          51014,
          407,
          4033,
          11,
          370,
          300,
          311,
          1348,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18635669350624084,
        "compression_ratio": 1.7173913043478262,
        "end": 5064,
        "id": 1349,
        "no_speech_prob": 0.0019267058232799172,
        "seek": 504100,
        "start": 5056,
        "temperature": 0,
        "text": " But could you, one, come up with your own data set, try to train the neural network with your own data set, and then how does it perform?",
        "tokens": [
          51114,
          583,
          727,
          291,
          11,
          472,
          11,
          808,
          493,
          365,
          428,
          1065,
          1412,
          992,
          11,
          853,
          281,
          3847,
          264,
          18161,
          3209,
          365,
          428,
          1065,
          1412,
          992,
          11,
          293,
          550,
          577,
          775,
          309,
          2042,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.18635669350624084,
        "compression_ratio": 1.7173913043478262,
        "end": 5069,
        "id": 1350,
        "no_speech_prob": 0.0019267058232799172,
        "seek": 504100,
        "start": 5064,
        "temperature": 0,
        "text": " You also might think about visualizing this output using color in some way.",
        "tokens": [
          51514,
          509,
          611,
          1062,
          519,
          466,
          5056,
          3319,
          341,
          5598,
          1228,
          2017,
          294,
          512,
          636,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19317969337838595,
        "compression_ratio": 1.6521739130434783,
        "end": 5075,
        "id": 1351,
        "no_speech_prob": 0.017711540684103966,
        "seek": 506900,
        "start": 5069,
        "temperature": 0,
        "text": " You know, you could use 3D, as I showed you with this processing example, which is no longer open.",
        "tokens": [
          50364,
          509,
          458,
          11,
          291,
          727,
          764,
          805,
          35,
          11,
          382,
          286,
          4712,
          291,
          365,
          341,
          9007,
          1365,
          11,
          597,
          307,
          572,
          2854,
          1269,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19317969337838595,
        "compression_ratio": 1.6521739130434783,
        "end": 5084,
        "id": 1352,
        "no_speech_prob": 0.017711540684103966,
        "seek": 506900,
        "start": 5075,
        "temperature": 0,
        "text": " So you could try a variety of different ways of visualizing this and maybe, or animating it or changing the way you build an interface to it.",
        "tokens": [
          50664,
          407,
          291,
          727,
          853,
          257,
          5673,
          295,
          819,
          2098,
          295,
          5056,
          3319,
          341,
          293,
          1310,
          11,
          420,
          2383,
          990,
          309,
          420,
          4473,
          264,
          636,
          291,
          1322,
          364,
          9226,
          281,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19317969337838595,
        "compression_ratio": 1.6521739130434783,
        "end": 5085,
        "id": 1353,
        "no_speech_prob": 0.017711540684103966,
        "seek": 506900,
        "start": 5084,
        "temperature": 0,
        "text": " There's so many possibilities.",
        "tokens": [
          51114,
          821,
          311,
          370,
          867,
          12178,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19317969337838595,
        "compression_ratio": 1.6521739130434783,
        "end": 5087,
        "id": 1354,
        "no_speech_prob": 0.017711540684103966,
        "seek": 506900,
        "start": 5085,
        "temperature": 0,
        "text": " So I encourage you to explore it.",
        "tokens": [
          51164,
          407,
          286,
          5373,
          291,
          281,
          6839,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19317969337838595,
        "compression_ratio": 1.6521739130434783,
        "end": 5094,
        "id": 1355,
        "no_speech_prob": 0.017711540684103966,
        "seek": 506900,
        "start": 5087,
        "temperature": 0,
        "text": " I encourage you to dig in also to the neural network library code if you want to see how that works, and check out those other videos as well.",
        "tokens": [
          51264,
          286,
          5373,
          291,
          281,
          2528,
          294,
          611,
          281,
          264,
          18161,
          3209,
          6405,
          3089,
          498,
          291,
          528,
          281,
          536,
          577,
          300,
          1985,
          11,
          293,
          1520,
          484,
          729,
          661,
          2145,
          382,
          731,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19317969337838595,
        "compression_ratio": 1.6521739130434783,
        "end": 5097,
        "id": 1356,
        "no_speech_prob": 0.017711540684103966,
        "seek": 506900,
        "start": 5094,
        "temperature": 0,
        "text": " So thanks for watching this coding challenge.",
        "tokens": [
          51614,
          407,
          3231,
          337,
          1976,
          341,
          17720,
          3430,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5098,
        "id": 1357,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5097,
        "temperature": 0,
        "text": " I think that's it.",
        "tokens": [
          50364,
          286,
          519,
          300,
          311,
          309,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5099,
        "id": 1358,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5098,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50414,
          663,
          311,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5100,
        "id": 1359,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5099,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50464,
          663,
          311,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5101,
        "id": 1360,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5100,
        "temperature": 0,
        "text": " I'm done.",
        "tokens": [
          50514,
          286,
          478,
          1096,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5112,
        "id": 1361,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5101,
        "temperature": 0,
        "text": " I'm sorry.",
        "tokens": [
          50564,
          286,
          478,
          2597,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5115,
        "id": 1362,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5112,
        "temperature": 0,
        "text": " It's interesting how, like, what kind of weird results we can get.",
        "tokens": [
          51114,
          467,
          311,
          1880,
          577,
          11,
          411,
          11,
          437,
          733,
          295,
          3657,
          3542,
          321,
          393,
          483,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5121,
        "id": 1363,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5115,
        "temperature": 0,
        "text": " Oh, try playing around with the slider now.",
        "tokens": [
          51264,
          876,
          11,
          853,
          2433,
          926,
          365,
          264,
          26046,
          586,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1613337066438463,
        "compression_ratio": 1.437956204379562,
        "end": 5122,
        "id": 1364,
        "no_speech_prob": 0.4415948987007141,
        "seek": 509700,
        "start": 5121,
        "temperature": 0,
        "text": " I should have done that.",
        "tokens": [
          51564,
          286,
          820,
          362,
          1096,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23362639143660263,
        "compression_ratio": 1.2767857142857142,
        "end": 5136,
        "id": 1365,
        "no_speech_prob": 0.5812378525733948,
        "seek": 512200,
        "start": 5123,
        "temperature": 0,
        "text": " So actually, one thing I should do is I should really have done this.",
        "tokens": [
          50414,
          407,
          767,
          11,
          472,
          551,
          286,
          820,
          360,
          307,
          286,
          820,
          534,
          362,
          1096,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23362639143660263,
        "compression_ratio": 1.2767857142857142,
        "end": 5144,
        "id": 1366,
        "no_speech_prob": 0.5812378525733948,
        "seek": 512200,
        "start": 5136,
        "temperature": 0,
        "text": " Because it's more interesting to watch it figure it out slowly over time.",
        "tokens": [
          51064,
          1436,
          309,
          311,
          544,
          1880,
          281,
          1159,
          309,
          2573,
          309,
          484,
          5692,
          670,
          565,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.262004554271698,
        "compression_ratio": 0.8636363636363636,
        "end": 5147,
        "id": 1367,
        "no_speech_prob": 0.8242342472076416,
        "seek": 514400,
        "start": 5144,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50364,
          1079,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.262004554271698,
        "compression_ratio": 0.8636363636363636,
        "end": 5160,
        "id": 1368,
        "no_speech_prob": 0.8242342472076416,
        "seek": 514400,
        "start": 5147,
        "temperature": 0,
        "text": " This is not as exciting to watch.",
        "tokens": [
          50514,
          639,
          307,
          406,
          382,
          4670,
          281,
          1159,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.29996977533612934,
        "compression_ratio": 1.3228346456692914,
        "end": 5175,
        "id": 1369,
        "no_speech_prob": 0.0474206916987896,
        "seek": 516000,
        "start": 5161,
        "temperature": 0,
        "text": " I'm going to try just with 10.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          853,
          445,
          365,
          1266,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.29996977533612934,
        "compression_ratio": 1.3228346456692914,
        "end": 5176,
        "id": 1370,
        "no_speech_prob": 0.0474206916987896,
        "seek": 516000,
        "start": 5175,
        "temperature": 0,
        "text": " Probably too slow to watch.",
        "tokens": [
          51114,
          9210,
          886,
          2964,
          281,
          1159,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.29996977533612934,
        "compression_ratio": 1.3228346456692914,
        "end": 5179,
        "id": 1371,
        "no_speech_prob": 0.0474206916987896,
        "seek": 516000,
        "start": 5176,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51164,
          865,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.29996977533612934,
        "compression_ratio": 1.3228346456692914,
        "end": 5187,
        "id": 1372,
        "no_speech_prob": 0.0474206916987896,
        "seek": 516000,
        "start": 5179,
        "temperature": 0,
        "text": " I'm just trying to, what's the sweet spot of, like, being able to slow it down but to also, like, yeah.",
        "tokens": [
          51314,
          286,
          478,
          445,
          1382,
          281,
          11,
          437,
          311,
          264,
          3844,
          4008,
          295,
          11,
          411,
          11,
          885,
          1075,
          281,
          2964,
          309,
          760,
          457,
          281,
          611,
          11,
          411,
          11,
          1338,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5189,
        "id": 1373,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5187,
        "temperature": 0,
        "text": " So this is probably better, 100.",
        "tokens": [
          50364,
          407,
          341,
          307,
          1391,
          1101,
          11,
          2319,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5196,
        "id": 1374,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5189,
        "temperature": 0,
        "text": " Because you can kind of see it learning more slowly over time.",
        "tokens": [
          50464,
          1436,
          291,
          393,
          733,
          295,
          536,
          309,
          2539,
          544,
          5692,
          670,
          565,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5206,
        "id": 1375,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5196,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5207,
        "id": 1376,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5206,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5209,
        "id": 1377,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5207,
        "temperature": 0,
        "text": " So I think I'm finished for today.",
        "tokens": [
          51364,
          407,
          286,
          519,
          286,
          478,
          4335,
          337,
          965,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5211,
        "id": 1378,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5209,
        "temperature": 0,
        "text": " It's 4 o'clock.",
        "tokens": [
          51464,
          467,
          311,
          1017,
          277,
          6,
          9023,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19208187987838965,
        "compression_ratio": 1.264516129032258,
        "end": 5213,
        "id": 1379,
        "no_speech_prob": 0.1710493564605713,
        "seek": 518700,
        "start": 5211,
        "temperature": 0,
        "text": " Oh, it's because of the sigmoid.",
        "tokens": [
          51564,
          876,
          11,
          309,
          311,
          570,
          295,
          264,
          4556,
          3280,
          327,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5216,
        "id": 1380,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5214,
        "temperature": 0,
        "text": " I forgot.",
        "tokens": [
          50414,
          286,
          5298,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5221,
        "id": 1381,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5216,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50514,
          865,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5222,
        "id": 1382,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5221,
        "temperature": 0,
        "text": " Yeah, that's interesting.",
        "tokens": [
          50764,
          865,
          11,
          300,
          311,
          1880,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5228,
        "id": 1383,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5222,
        "temperature": 0,
        "text": " Right, there's no correct answer for this center spot, really.",
        "tokens": [
          50814,
          1779,
          11,
          456,
          311,
          572,
          3006,
          1867,
          337,
          341,
          3056,
          4008,
          11,
          534,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5231,
        "id": 1384,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5228,
        "temperature": 0,
        "text": " And so it can, yeah.",
        "tokens": [
          51114,
          400,
          370,
          309,
          393,
          11,
          1338,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5237,
        "id": 1385,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5231,
        "temperature": 0,
        "text": " It would be interesting to just actually run this with a different activation function and to put that into the library.",
        "tokens": [
          51264,
          467,
          576,
          312,
          1880,
          281,
          445,
          767,
          1190,
          341,
          365,
          257,
          819,
          24433,
          2445,
          293,
          281,
          829,
          300,
          666,
          264,
          6405,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2213875099464699,
        "compression_ratio": 1.5078534031413613,
        "end": 5240,
        "id": 1386,
        "no_speech_prob": 0.4726477563381195,
        "seek": 521300,
        "start": 5237,
        "temperature": 0,
        "text": " But I'll have to come back to that later.",
        "tokens": [
          51564,
          583,
          286,
          603,
          362,
          281,
          808,
          646,
          281,
          300,
          1780,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5241,
        "id": 1387,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5240,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5243,
        "id": 1388,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5241,
        "temperature": 0,
        "text": " I don't know if this was better than the time that I did this before.",
        "tokens": [
          50414,
          286,
          500,
          380,
          458,
          498,
          341,
          390,
          1101,
          813,
          264,
          565,
          300,
          286,
          630,
          341,
          949,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5248,
        "id": 1389,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5243,
        "temperature": 0,
        "text": " It probably took longer.",
        "tokens": [
          50514,
          467,
          1391,
          1890,
          2854,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5255,
        "id": 1390,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5248,
        "temperature": 0,
        "text": " But, yeah, make it slow and play with the learning rate.",
        "tokens": [
          50764,
          583,
          11,
          1338,
          11,
          652,
          309,
          2964,
          293,
          862,
          365,
          264,
          2539,
          3314,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5256,
        "id": 1391,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5255,
        "temperature": 0,
        "text": " That's kind of interesting.",
        "tokens": [
          51114,
          663,
          311,
          733,
          295,
          1880,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5260,
        "id": 1392,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5256,
        "temperature": 0,
        "text": " That's an interesting idea.",
        "tokens": [
          51164,
          663,
          311,
          364,
          1880,
          1558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5261,
        "id": 1393,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5260,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51364,
          1057,
          558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5262,
        "id": 1394,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5261,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51414,
          407,
          718,
          311,
          360,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5267,
        "id": 1395,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5262,
        "temperature": 0,
        "text": " Let's make it slow like 10.",
        "tokens": [
          51464,
          961,
          311,
          652,
          309,
          2964,
          411,
          1266,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18603758017222086,
        "compression_ratio": 1.5736842105263158,
        "end": 5269,
        "id": 1396,
        "no_speech_prob": 0.005469178780913353,
        "seek": 524000,
        "start": 5267,
        "temperature": 0,
        "text": " Let's up that learning rate.",
        "tokens": [
          51714,
          961,
          311,
          493,
          300,
          2539,
          3314,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5270,
        "id": 1397,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5269,
        "temperature": 0,
        "text": " It's making big jumps.",
        "tokens": [
          50364,
          467,
          311,
          1455,
          955,
          16704,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5272,
        "id": 1398,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5270,
        "temperature": 0,
        "text": " They're too big.",
        "tokens": [
          50414,
          814,
          434,
          886,
          955,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5275,
        "id": 1399,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5272,
        "temperature": 0,
        "text": " And now I can lower it to refine.",
        "tokens": [
          50514,
          400,
          586,
          286,
          393,
          3126,
          309,
          281,
          33906,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5280,
        "id": 1400,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5275,
        "temperature": 0,
        "text": " Yeah, that's kind of interesting.",
        "tokens": [
          50664,
          865,
          11,
          300,
          311,
          733,
          295,
          1880,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5285,
        "id": 1401,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5280,
        "temperature": 0,
        "text": " Yeah, so playing with the learning rate really does make a difference.",
        "tokens": [
          50914,
          865,
          11,
          370,
          2433,
          365,
          264,
          2539,
          3314,
          534,
          775,
          652,
          257,
          2649,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5289,
        "id": 1402,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5285,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5290,
        "id": 1403,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5289,
        "temperature": 0,
        "text": " So I'm here.",
        "tokens": [
          51364,
          407,
          286,
          478,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19945467334904082,
        "compression_ratio": 1.3625,
        "end": 5292,
        "id": 1404,
        "no_speech_prob": 0.00734558142721653,
        "seek": 526900,
        "start": 5290,
        "temperature": 0,
        "text": " I'm just about done.",
        "tokens": [
          51414,
          286,
          478,
          445,
          466,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22047776721772694,
        "compression_ratio": 1.5532786885245902,
        "end": 5299,
        "id": 1405,
        "no_speech_prob": 0.6722363829612732,
        "seek": 529200,
        "start": 5293,
        "temperature": 0,
        "text": " But I do have a few minutes to take some questions.",
        "tokens": [
          50414,
          583,
          286,
          360,
          362,
          257,
          1326,
          2077,
          281,
          747,
          512,
          1651,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22047776721772694,
        "compression_ratio": 1.5532786885245902,
        "end": 5300,
        "id": 1406,
        "no_speech_prob": 0.6722363829612732,
        "seek": 529200,
        "start": 5299,
        "temperature": 0,
        "text": " It was really good.",
        "tokens": [
          50714,
          467,
          390,
          534,
          665,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22047776721772694,
        "compression_ratio": 1.5532786885245902,
        "end": 5302,
        "id": 1407,
        "no_speech_prob": 0.6722363829612732,
        "seek": 529200,
        "start": 5300,
        "temperature": 0,
        "text": " Okay, thanks, KB.",
        "tokens": [
          50764,
          1033,
          11,
          3231,
          11,
          591,
          33,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22047776721772694,
        "compression_ratio": 1.5532786885245902,
        "end": 5310,
        "id": 1408,
        "no_speech_prob": 0.6722363829612732,
        "seek": 529200,
        "start": 5302,
        "temperature": 0,
        "text": " I just felt like I needed some space from when I made the library because I was in my own head of, like, what did I say before, what did I didn't.",
        "tokens": [
          50864,
          286,
          445,
          2762,
          411,
          286,
          2978,
          512,
          1901,
          490,
          562,
          286,
          1027,
          264,
          6405,
          570,
          286,
          390,
          294,
          452,
          1065,
          1378,
          295,
          11,
          411,
          11,
          437,
          630,
          286,
          584,
          949,
          11,
          437,
          630,
          286,
          994,
          380,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22047776721772694,
        "compression_ratio": 1.5532786885245902,
        "end": 5314,
        "id": 1409,
        "no_speech_prob": 0.6722363829612732,
        "seek": 529200,
        "start": 5310,
        "temperature": 0,
        "text": " So this, I hoped, would kind of give an introduction.",
        "tokens": [
          51264,
          407,
          341,
          11,
          286,
          19737,
          11,
          576,
          733,
          295,
          976,
          364,
          9339,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22047776721772694,
        "compression_ratio": 1.5532786885245902,
        "end": 5319,
        "id": 1410,
        "no_speech_prob": 0.6722363829612732,
        "seek": 529200,
        "start": 5314,
        "temperature": 0,
        "text": " My goal for this was that you could watch it without having watched that other playlist.",
        "tokens": [
          51464,
          1222,
          3387,
          337,
          341,
          390,
          300,
          291,
          727,
          1159,
          309,
          1553,
          1419,
          6337,
          300,
          661,
          16788,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17921085357666017,
        "compression_ratio": 1.3448275862068966,
        "end": 5322,
        "id": 1411,
        "no_speech_prob": 0.07807634770870209,
        "seek": 531900,
        "start": 5319,
        "temperature": 0,
        "text": " But you could get more from watching the other playlist.",
        "tokens": [
          50364,
          583,
          291,
          727,
          483,
          544,
          490,
          1976,
          264,
          661,
          16788,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17921085357666017,
        "compression_ratio": 1.3448275862068966,
        "end": 5326,
        "id": 1412,
        "no_speech_prob": 0.07807634770870209,
        "seek": 531900,
        "start": 5322,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50514,
          286,
          500,
          380,
          458,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17921085357666017,
        "compression_ratio": 1.3448275862068966,
        "end": 5328,
        "id": 1413,
        "no_speech_prob": 0.07807634770870209,
        "seek": 531900,
        "start": 5326,
        "temperature": 0,
        "text": " I can add a slider for the iterations.",
        "tokens": [
          50714,
          286,
          393,
          909,
          257,
          26046,
          337,
          264,
          36540,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17921085357666017,
        "compression_ratio": 1.3448275862068966,
        "end": 5330,
        "id": 1414,
        "no_speech_prob": 0.07807634770870209,
        "seek": 531900,
        "start": 5328,
        "temperature": 0,
        "text": " That's a smart idea.",
        "tokens": [
          50814,
          663,
          311,
          257,
          4069,
          1558,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17921085357666017,
        "compression_ratio": 1.3448275862068966,
        "end": 5345,
        "id": 1415,
        "no_speech_prob": 0.07807634770870209,
        "seek": 531900,
        "start": 5330,
        "temperature": 0,
        "text": " That's a very smart idea.",
        "tokens": [
          50914,
          663,
          311,
          257,
          588,
          4069,
          1558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21231660610292016,
        "compression_ratio": 1.4342857142857144,
        "end": 5351,
        "id": 1416,
        "no_speech_prob": 0.5735990405082703,
        "seek": 534500,
        "start": 5346,
        "temperature": 0,
        "text": " So let me talk for a little bit about what I want to do on Friday.",
        "tokens": [
          50414,
          407,
          718,
          385,
          751,
          337,
          257,
          707,
          857,
          466,
          437,
          286,
          528,
          281,
          360,
          322,
          6984,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21231660610292016,
        "compression_ratio": 1.4342857142857144,
        "end": 5354,
        "id": 1417,
        "no_speech_prob": 0.5735990405082703,
        "seek": 534500,
        "start": 5351,
        "temperature": 0,
        "text": " I'm so tempted to do some of it right now.",
        "tokens": [
          50664,
          286,
          478,
          370,
          29941,
          281,
          360,
          512,
          295,
          309,
          558,
          586,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21231660610292016,
        "compression_ratio": 1.4342857142857144,
        "end": 5358,
        "id": 1418,
        "no_speech_prob": 0.5735990405082703,
        "seek": 534500,
        "start": 5354,
        "temperature": 0,
        "text": " But I think I will do it on Friday.",
        "tokens": [
          50814,
          583,
          286,
          519,
          286,
          486,
          360,
          309,
          322,
          6984,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21231660610292016,
        "compression_ratio": 1.4342857142857144,
        "end": 5361,
        "id": 1419,
        "no_speech_prob": 0.5735990405082703,
        "seek": 534500,
        "start": 5358,
        "temperature": 0,
        "text": " Let's, so here, actually, let's go.",
        "tokens": [
          51014,
          961,
          311,
          11,
          370,
          510,
          11,
          767,
          11,
          718,
          311,
          352,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21231660610292016,
        "compression_ratio": 1.4342857142857144,
        "end": 5362,
        "id": 1420,
        "no_speech_prob": 0.5735990405082703,
        "seek": 534500,
        "start": 5361,
        "temperature": 0,
        "text": " This is exciting.",
        "tokens": [
          51164,
          639,
          307,
          4670,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21231660610292016,
        "compression_ratio": 1.4342857142857144,
        "end": 5369,
        "id": 1421,
        "no_speech_prob": 0.5735990405082703,
        "seek": 534500,
        "start": 5362,
        "temperature": 0,
        "text": " Let's do a live adding to the Coding Train website.",
        "tokens": [
          51214,
          961,
          311,
          360,
          257,
          1621,
          5127,
          281,
          264,
          383,
          8616,
          28029,
          3144,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22865760210648323,
        "compression_ratio": 1.5446428571428572,
        "end": 5376,
        "id": 1422,
        "no_speech_prob": 0.5735349059104919,
        "seek": 536900,
        "start": 5370,
        "temperature": 0,
        "text": " So I think if we go in here under strings, we can see these are now, there's so many more that need to get added here.",
        "tokens": [
          50414,
          407,
          286,
          519,
          498,
          321,
          352,
          294,
          510,
          833,
          13985,
          11,
          321,
          393,
          536,
          613,
          366,
          586,
          11,
          456,
          311,
          370,
          867,
          544,
          300,
          643,
          281,
          483,
          3869,
          510,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22865760210648323,
        "compression_ratio": 1.5446428571428572,
        "end": 5381,
        "id": 1423,
        "no_speech_prob": 0.5735349059104919,
        "seek": 536900,
        "start": 5376,
        "temperature": 0,
        "text": " These are the markdown files for all of the live streams.",
        "tokens": [
          50714,
          1981,
          366,
          264,
          1491,
          5093,
          7098,
          337,
          439,
          295,
          264,
          1621,
          15842,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22865760210648323,
        "compression_ratio": 1.5446428571428572,
        "end": 5387,
        "id": 1424,
        "no_speech_prob": 0.5735349059104919,
        "seek": 536900,
        "start": 5381,
        "temperature": 0,
        "text": " And so the live stream this Friday would be one, well, today is what?",
        "tokens": [
          50964,
          400,
          370,
          264,
          1621,
          4309,
          341,
          6984,
          576,
          312,
          472,
          11,
          731,
          11,
          965,
          307,
          437,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.22865760210648323,
        "compression_ratio": 1.5446428571428572,
        "end": 5391,
        "id": 1425,
        "no_speech_prob": 0.5735349059104919,
        "seek": 536900,
        "start": 5387,
        "temperature": 0,
        "text": " Today, okay, so let me go to my channel.",
        "tokens": [
          51264,
          2692,
          11,
          1392,
          11,
          370,
          718,
          385,
          352,
          281,
          452,
          2269,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22865760210648323,
        "compression_ratio": 1.5446428571428572,
        "end": 5395,
        "id": 1426,
        "no_speech_prob": 0.5735349059104919,
        "seek": 536900,
        "start": 5391,
        "temperature": 0,
        "text": " No, I don't want to go to YouTube home.",
        "tokens": [
          51464,
          883,
          11,
          286,
          500,
          380,
          528,
          281,
          352,
          281,
          3088,
          1280,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22865760210648323,
        "compression_ratio": 1.5446428571428572,
        "end": 5396,
        "id": 1427,
        "no_speech_prob": 0.5735349059104919,
        "seek": 536900,
        "start": 5395,
        "temperature": 0,
        "text": " Coding Train live.",
        "tokens": [
          51664,
          383,
          8616,
          28029,
          1621,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20830075765393444,
        "compression_ratio": 1.665137614678899,
        "end": 5405,
        "id": 1428,
        "no_speech_prob": 0.4034726917743683,
        "seek": 539600,
        "start": 5396,
        "temperature": 0,
        "text": " What, by the way, this is so interesting to see what, like, things I should watch based on, because this is not my personal YouTube account.",
        "tokens": [
          50364,
          708,
          11,
          538,
          264,
          636,
          11,
          341,
          307,
          370,
          1880,
          281,
          536,
          437,
          11,
          411,
          11,
          721,
          286,
          820,
          1159,
          2361,
          322,
          11,
          570,
          341,
          307,
          406,
          452,
          2973,
          3088,
          2696,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20830075765393444,
        "compression_ratio": 1.665137614678899,
        "end": 5409,
        "id": 1429,
        "no_speech_prob": 0.4034726917743683,
        "seek": 539600,
        "start": 5405,
        "temperature": 0,
        "text": " This is like a random YouTube account that I set up just for live streaming.",
        "tokens": [
          50814,
          639,
          307,
          411,
          257,
          4974,
          3088,
          2696,
          300,
          286,
          992,
          493,
          445,
          337,
          1621,
          11791,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20830075765393444,
        "compression_ratio": 1.665137614678899,
        "end": 5412,
        "id": 1430,
        "no_speech_prob": 0.4034726917743683,
        "seek": 539600,
        "start": 5409,
        "temperature": 0,
        "text": " I don't know why I think I should watch this football video.",
        "tokens": [
          51014,
          286,
          500,
          380,
          458,
          983,
          286,
          519,
          286,
          820,
          1159,
          341,
          7346,
          960,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20830075765393444,
        "compression_ratio": 1.665137614678899,
        "end": 5415,
        "id": 1431,
        "no_speech_prob": 0.4034726917743683,
        "seek": 539600,
        "start": 5412,
        "temperature": 0,
        "text": " But what I want to do is go to the Coding Train.",
        "tokens": [
          51164,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          352,
          281,
          264,
          383,
          8616,
          28029,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20830075765393444,
        "compression_ratio": 1.665137614678899,
        "end": 5417,
        "id": 1432,
        "no_speech_prob": 0.4034726917743683,
        "seek": 539600,
        "start": 5415,
        "temperature": 0,
        "text": " I'm subscribed to the Coding Train.",
        "tokens": [
          51314,
          286,
          478,
          16665,
          281,
          264,
          383,
          8616,
          28029,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5423,
        "id": 1433,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5418,
        "temperature": 0,
        "text": " And hold on.",
        "tokens": [
          50414,
          400,
          1797,
          322,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5429,
        "id": 1434,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5423,
        "temperature": 0,
        "text": " Oh, interesting.",
        "tokens": [
          50664,
          876,
          11,
          1880,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5430,
        "id": 1435,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5429,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5436,
        "id": 1436,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5430,
        "temperature": 0,
        "text": " Sorry, I had some important messages, but I will get back to those in a minute.",
        "tokens": [
          51014,
          4919,
          11,
          286,
          632,
          512,
          1021,
          7897,
          11,
          457,
          286,
          486,
          483,
          646,
          281,
          729,
          294,
          257,
          3456,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5438,
        "id": 1437,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5436,
        "temperature": 0,
        "text": " I shouldn't be looking at my messages while I'm live streaming.",
        "tokens": [
          51314,
          286,
          4659,
          380,
          312,
          1237,
          412,
          452,
          7897,
          1339,
          286,
          478,
          1621,
          11791,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5442,
        "id": 1438,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5438,
        "temperature": 0,
        "text": " I'm looking for playlists.",
        "tokens": [
          51414,
          286,
          478,
          1237,
          337,
          862,
          36693,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19363709767659507,
        "compression_ratio": 1.3953488372093024,
        "end": 5445,
        "id": 1439,
        "no_speech_prob": 0.4072311818599701,
        "seek": 541700,
        "start": 5442,
        "temperature": 0,
        "text": " And actually, I can just do this.",
        "tokens": [
          51614,
          400,
          767,
          11,
          286,
          393,
          445,
          360,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5449,
        "id": 1440,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5445,
        "temperature": 0,
        "text": " The last live stream was number 118.",
        "tokens": [
          50364,
          440,
          1036,
          1621,
          4309,
          390,
          1230,
          2975,
          23,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5451,
        "id": 1441,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5449,
        "temperature": 0,
        "text": " So today is 119.",
        "tokens": [
          50564,
          407,
          965,
          307,
          2975,
          24,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5455,
        "id": 1442,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5451,
        "temperature": 0,
        "text": " And this Friday, I don't know what time I'm going to do it this Friday.",
        "tokens": [
          50664,
          400,
          341,
          6984,
          11,
          286,
          500,
          380,
          458,
          437,
          565,
          286,
          478,
          516,
          281,
          360,
          309,
          341,
          6984,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5457,
        "id": 1443,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5455,
        "temperature": 0,
        "text": " Probably in the morning, actually.",
        "tokens": [
          50864,
          9210,
          294,
          264,
          2446,
          11,
          767,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5458,
        "id": 1444,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5457,
        "temperature": 0,
        "text": " This Friday.",
        "tokens": [
          50964,
          639,
          6984,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5460,
        "id": 1445,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5458,
        "temperature": 0,
        "text": " So if I create a new file.",
        "tokens": [
          51014,
          407,
          498,
          286,
          1884,
          257,
          777,
          3991,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5462,
        "id": 1446,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5460,
        "temperature": 0,
        "text": " Create new file.",
        "tokens": [
          51114,
          20248,
          777,
          3991,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5465,
        "id": 1447,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5462,
        "temperature": 0,
        "text": " 119.",
        "tokens": [
          51214,
          2975,
          24,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21080245094737787,
        "compression_ratio": 1.4615384615384615,
        "end": 5471,
        "id": 1448,
        "no_speech_prob": 0.12251268327236176,
        "seek": 544500,
        "start": 5465,
        "temperature": 0,
        "text": " Upcoming live stream.md.",
        "tokens": [
          51364,
          5858,
          6590,
          1621,
          4309,
          13,
          76,
          67,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.221946382522583,
        "compression_ratio": 1.5447154471544715,
        "end": 5478,
        "id": 1449,
        "no_speech_prob": 0.061866629868745804,
        "seek": 547100,
        "start": 5472,
        "temperature": 0,
        "text": " Create a scheduling Fridays live stream.",
        "tokens": [
          50414,
          20248,
          257,
          29055,
          46306,
          1621,
          4309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.221946382522583,
        "compression_ratio": 1.5447154471544715,
        "end": 5481,
        "id": 1450,
        "no_speech_prob": 0.061866629868745804,
        "seek": 547100,
        "start": 5478,
        "temperature": 0,
        "text": " And I'm going to make that new file.",
        "tokens": [
          50714,
          400,
          286,
          478,
          516,
          281,
          652,
          300,
          777,
          3991,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.221946382522583,
        "compression_ratio": 1.5447154471544715,
        "end": 5487,
        "id": 1451,
        "no_speech_prob": 0.061866629868745804,
        "seek": 547100,
        "start": 5481,
        "temperature": 0,
        "text": " Then I'm going to go here.",
        "tokens": [
          50864,
          1396,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.221946382522583,
        "compression_ratio": 1.5447154471544715,
        "end": 5494,
        "id": 1452,
        "no_speech_prob": 0.061866629868745804,
        "seek": 547100,
        "start": 5487,
        "temperature": 0,
        "text": " And I am going to go look at another one.",
        "tokens": [
          51164,
          400,
          286,
          669,
          516,
          281,
          352,
          574,
          412,
          1071,
          472,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.221946382522583,
        "compression_ratio": 1.5447154471544715,
        "end": 5500,
        "id": 1453,
        "no_speech_prob": 0.061866629868745804,
        "seek": 547100,
        "start": 5494,
        "temperature": 0,
        "text": " I'm going to look at this one called Walks.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          574,
          412,
          341,
          472,
          1219,
          10818,
          82,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21689886575216774,
        "compression_ratio": 1.6506024096385543,
        "end": 5505,
        "id": 1454,
        "no_speech_prob": 0.0994587242603302,
        "seek": 550000,
        "start": 5501,
        "temperature": 0,
        "text": " And I'm going to look at how it's going to do this.",
        "tokens": [
          50414,
          400,
          286,
          478,
          516,
          281,
          574,
          412,
          577,
          309,
          311,
          220,
          8102,
          281,
          360,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21689886575216774,
        "compression_ratio": 1.6506024096385543,
        "end": 5510,
        "id": 1455,
        "no_speech_prob": 0.0994587242603302,
        "seek": 550000,
        "start": 5505,
        "temperature": 0,
        "text": " Because that's actually, this is no longer an upcoming live stream.",
        "tokens": [
          50614,
          1436,
          300,
          311,
          767,
          11,
          341,
          307,
          572,
          2854,
          364,
          11500,
          1621,
          4309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21689886575216774,
        "compression_ratio": 1.6506024096385543,
        "end": 5512,
        "id": 1456,
        "no_speech_prob": 0.0994587242603302,
        "seek": 550000,
        "start": 5510,
        "temperature": 0,
        "text": " But I'm going to grab this.",
        "tokens": [
          50864,
          583,
          286,
          478,
          516,
          281,
          4444,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21689886575216774,
        "compression_ratio": 1.6506024096385543,
        "end": 5515,
        "id": 1457,
        "no_speech_prob": 0.0994587242603302,
        "seek": 550000,
        "start": 5512,
        "temperature": 0,
        "text": " And I'm going to edit this file.",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          8129,
          341,
          3991,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21689886575216774,
        "compression_ratio": 1.6506024096385543,
        "end": 5517,
        "id": 1458,
        "no_speech_prob": 0.0994587242603302,
        "seek": 550000,
        "start": 5515,
        "temperature": 0,
        "text": " And I'm going to paste this in.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          9163,
          341,
          294,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21689886575216774,
        "compression_ratio": 1.6506024096385543,
        "end": 5524,
        "id": 1459,
        "no_speech_prob": 0.0994587242603302,
        "seek": 550000,
        "start": 5517,
        "temperature": 0,
        "text": " So now, the date for this Friday, today is the 7th, 8th, 9th.",
        "tokens": [
          51214,
          407,
          586,
          11,
          264,
          4002,
          337,
          341,
          6984,
          11,
          965,
          307,
          264,
          1614,
          392,
          11,
          1649,
          392,
          11,
          1722,
          392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5528,
        "id": 1460,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5525,
        "temperature": 0,
        "text": " To 9.",
        "tokens": [
          50414,
          1407,
          1722,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5531,
        "id": 1461,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5528,
        "temperature": 0,
        "text": " And the topics will be.",
        "tokens": [
          50564,
          400,
          264,
          8378,
          486,
          312,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5536,
        "id": 1462,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5531,
        "temperature": 0,
        "text": " So this Friday, what I want to do is MNIST coding challenge.",
        "tokens": [
          50714,
          407,
          341,
          6984,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          376,
          45,
          19756,
          17720,
          3430,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5541,
        "id": 1463,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5536,
        "temperature": 0,
        "text": " Pendulum.",
        "tokens": [
          50964,
          38048,
          11560,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5544,
        "id": 1464,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5541,
        "temperature": 0,
        "text": " Pendulum coding challenge.",
        "tokens": [
          51214,
          38048,
          11560,
          17720,
          3430,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5548,
        "id": 1465,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5544,
        "temperature": 0,
        "text": " Spring coding challenge.",
        "tokens": [
          51364,
          14013,
          17720,
          3430,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2974429963127015,
        "compression_ratio": 1.4210526315789473,
        "end": 5551,
        "id": 1466,
        "no_speech_prob": 0.26281556487083435,
        "seek": 552400,
        "start": 5548,
        "temperature": 0,
        "text": " What I mean by spring is Hook's Law.",
        "tokens": [
          51564,
          708,
          286,
          914,
          538,
          5587,
          307,
          33132,
          311,
          7744,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5558,
        "id": 1467,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5552,
        "temperature": 0,
        "text": " And double pendulum coding challenge.",
        "tokens": [
          50414,
          400,
          3834,
          44103,
          17720,
          3430,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5561,
        "id": 1468,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5558,
        "temperature": 0,
        "text": " Now there might have been something else.",
        "tokens": [
          50714,
          823,
          456,
          1062,
          362,
          668,
          746,
          1646,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5564,
        "id": 1469,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5561,
        "temperature": 0,
        "text": " So I'm kind of doing double duty here.",
        "tokens": [
          50864,
          407,
          286,
          478,
          733,
          295,
          884,
          3834,
          9776,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5566,
        "id": 1470,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5564,
        "temperature": 0,
        "text": " In that I'm trying to push the neural network stuff further.",
        "tokens": [
          51014,
          682,
          300,
          286,
          478,
          1382,
          281,
          2944,
          264,
          18161,
          3209,
          1507,
          3052,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5568,
        "id": 1471,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5566,
        "temperature": 0,
        "text": " Machine learning stuff.",
        "tokens": [
          51114,
          22155,
          2539,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5572,
        "id": 1472,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5568,
        "temperature": 0,
        "text": " But I also want to.",
        "tokens": [
          51214,
          583,
          286,
          611,
          528,
          281,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5576,
        "id": 1473,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5572,
        "temperature": 0,
        "text": " This week in my course at ITP that I'm actually teaching.",
        "tokens": [
          51414,
          639,
          1243,
          294,
          452,
          1164,
          412,
          6783,
          47,
          300,
          286,
          478,
          767,
          4571,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18682966561153017,
        "compression_ratio": 1.5213270142180095,
        "end": 5578,
        "id": 1474,
        "no_speech_prob": 0.007460367865860462,
        "seek": 555100,
        "start": 5576,
        "temperature": 0,
        "text": " This week was about oscillating motion.",
        "tokens": [
          51614,
          639,
          1243,
          390,
          466,
          18225,
          990,
          5394,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5581,
        "id": 1475,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5578,
        "temperature": 0,
        "text": " So I wanted to look at springs and pendulums.",
        "tokens": [
          50364,
          407,
          286,
          1415,
          281,
          574,
          412,
          24647,
          293,
          12179,
          425,
          8099,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5584,
        "id": 1476,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5581,
        "temperature": 0,
        "text": " And I've always wanted to program the double pendulum.",
        "tokens": [
          50514,
          400,
          286,
          600,
          1009,
          1415,
          281,
          1461,
          264,
          3834,
          44103,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5587,
        "id": 1477,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5584,
        "temperature": 0,
        "text": " But I feel like it's weird to do the double pendulum challenge.",
        "tokens": [
          50664,
          583,
          286,
          841,
          411,
          309,
          311,
          3657,
          281,
          360,
          264,
          3834,
          44103,
          3430,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5589,
        "id": 1478,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5587,
        "temperature": 0,
        "text": " Without having done the pendulum coding challenge.",
        "tokens": [
          50814,
          9129,
          1419,
          1096,
          264,
          44103,
          17720,
          3430,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5591,
        "id": 1479,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5589,
        "temperature": 0,
        "text": " Let's just make sure I haven't done these videos already.",
        "tokens": [
          50914,
          961,
          311,
          445,
          652,
          988,
          286,
          2378,
          380,
          1096,
          613,
          2145,
          1217,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5595,
        "id": 1480,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5591,
        "temperature": 0,
        "text": " So one way to figure that out is.",
        "tokens": [
          51014,
          407,
          472,
          636,
          281,
          2573,
          300,
          484,
          307,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5598,
        "id": 1481,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5595,
        "temperature": 0,
        "text": " Shiftman pendulum.",
        "tokens": [
          51214,
          28304,
          1601,
          44103,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5600,
        "id": 1482,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5598,
        "temperature": 0,
        "text": " Now I know I have a video about a pendulum.",
        "tokens": [
          51364,
          823,
          286,
          458,
          286,
          362,
          257,
          960,
          466,
          257,
          44103,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5603,
        "id": 1483,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5600,
        "temperature": 0,
        "text": " But I think in this video, which is two years old.",
        "tokens": [
          51464,
          583,
          286,
          519,
          294,
          341,
          960,
          11,
          597,
          307,
          732,
          924,
          1331,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5605,
        "id": 1484,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5603,
        "temperature": 0,
        "text": " First of all, it's in processing.",
        "tokens": [
          51614,
          2386,
          295,
          439,
          11,
          309,
          311,
          294,
          9007,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20276655870325425,
        "compression_ratio": 1.75,
        "end": 5607,
        "id": 1485,
        "no_speech_prob": 0.07476017624139786,
        "seek": 557800,
        "start": 5605,
        "temperature": 0,
        "text": " I don't have any gray hair.",
        "tokens": [
          51714,
          286,
          500,
          380,
          362,
          604,
          10855,
          2578,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5614,
        "id": 1486,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5608,
        "temperature": 0,
        "text": " And I'm pretty sure I don't actually code the pendulum from scratch.",
        "tokens": [
          50414,
          400,
          286,
          478,
          1238,
          988,
          286,
          500,
          380,
          767,
          3089,
          264,
          44103,
          490,
          8459,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5616,
        "id": 1487,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5614,
        "temperature": 0,
        "text": " I'm just talking through an example.",
        "tokens": [
          50714,
          286,
          478,
          445,
          1417,
          807,
          364,
          1365,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5621,
        "id": 1488,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5616,
        "temperature": 0,
        "text": " So I don't see anything else about a pendulum.",
        "tokens": [
          50814,
          407,
          286,
          500,
          380,
          536,
          1340,
          1646,
          466,
          257,
          44103,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5623,
        "id": 1489,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5621,
        "temperature": 0,
        "text": " So that's good.",
        "tokens": [
          51064,
          407,
          300,
          311,
          665,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5625,
        "id": 1490,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5623,
        "temperature": 0,
        "text": " What about springs?",
        "tokens": [
          51164,
          708,
          466,
          24647,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5628,
        "id": 1491,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5625,
        "temperature": 0,
        "text": " Springs, toxic libs, simple harmonic motion.",
        "tokens": [
          51264,
          33065,
          11,
          12786,
          287,
          897,
          82,
          11,
          2199,
          32270,
          5394,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5630,
        "id": 1492,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5628,
        "temperature": 0,
        "text": " But again, these are all the old ones.",
        "tokens": [
          51414,
          583,
          797,
          11,
          613,
          366,
          439,
          264,
          1331,
          2306,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5633,
        "id": 1493,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5630,
        "temperature": 0,
        "text": " Oh, I do have a guest tutorial.",
        "tokens": [
          51514,
          876,
          11,
          286,
          360,
          362,
          257,
          8341,
          7073,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18943973579029044,
        "compression_ratio": 1.5426008968609866,
        "end": 5636,
        "id": 1494,
        "no_speech_prob": 0.0061926948837935925,
        "seek": 560700,
        "start": 5633,
        "temperature": 0,
        "text": " With Val Head about a spring animation.",
        "tokens": [
          51664,
          2022,
          7188,
          11398,
          466,
          257,
          5587,
          9603,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5637,
        "id": 1495,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5636,
        "temperature": 0,
        "text": " Oh, wonderful.",
        "tokens": [
          50364,
          876,
          11,
          3715,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5638,
        "id": 1496,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5637,
        "temperature": 0,
        "text": " And that's great.",
        "tokens": [
          50414,
          400,
          300,
          311,
          869,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5640,
        "id": 1497,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5638,
        "temperature": 0,
        "text": " So this you should check out.",
        "tokens": [
          50464,
          407,
          341,
          291,
          820,
          1520,
          484,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5641,
        "id": 1498,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5640,
        "temperature": 0,
        "text": " Maybe I won't do that.",
        "tokens": [
          50564,
          2704,
          286,
          1582,
          380,
          360,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5643,
        "id": 1499,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5641,
        "temperature": 0,
        "text": " Because I'll just refer to.",
        "tokens": [
          50614,
          1436,
          286,
          603,
          445,
          2864,
          281,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5646,
        "id": 1500,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5643,
        "temperature": 0,
        "text": " I'll look at that and see if it's doing the same thing that I want to do.",
        "tokens": [
          50714,
          286,
          603,
          574,
          412,
          300,
          293,
          536,
          498,
          309,
          311,
          884,
          264,
          912,
          551,
          300,
          286,
          528,
          281,
          360,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5650,
        "id": 1501,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5646,
        "temperature": 0,
        "text": " And then.",
        "tokens": [
          50864,
          400,
          550,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5653,
        "id": 1502,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5650,
        "temperature": 0,
        "text": " Oh, I remember I used toxic libs for some stuff.",
        "tokens": [
          51064,
          876,
          11,
          286,
          1604,
          286,
          1143,
          12786,
          375,
          929,
          337,
          512,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5654,
        "id": 1503,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5653,
        "temperature": 0,
        "text": " So I have this.",
        "tokens": [
          51214,
          407,
          286,
          362,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5655,
        "id": 1504,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5654,
        "temperature": 0,
        "text": " Pendulum simulation.",
        "tokens": [
          51264,
          38048,
          11560,
          16575,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5657,
        "id": 1505,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5655,
        "temperature": 0,
        "text": " So I think that's kind of my plan.",
        "tokens": [
          51314,
          407,
          286,
          519,
          300,
          311,
          733,
          295,
          452,
          1393,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5659,
        "id": 1506,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5657,
        "temperature": 0,
        "text": " I'll probably let the spring go.",
        "tokens": [
          51414,
          286,
          603,
          1391,
          718,
          264,
          5587,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5661,
        "id": 1507,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5659,
        "temperature": 0,
        "text": " And focus just on the pendulum stuff.",
        "tokens": [
          51514,
          400,
          1879,
          445,
          322,
          264,
          44103,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5663,
        "id": 1508,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5661,
        "temperature": 0,
        "text": " So now.",
        "tokens": [
          51614,
          407,
          586,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5664,
        "id": 1509,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5663,
        "temperature": 0,
        "text": " Wait a second.",
        "tokens": [
          51714,
          3802,
          257,
          1150,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1741653860431828,
        "compression_ratio": 1.66147859922179,
        "end": 5665,
        "id": 1510,
        "no_speech_prob": 0.00769503740593791,
        "seek": 563600,
        "start": 5664,
        "temperature": 0,
        "text": " Wait a second.",
        "tokens": [
          51764,
          3802,
          257,
          1150,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5668,
        "id": 1511,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5665,
        "temperature": 0,
        "text": " The reason why I was doing this.",
        "tokens": [
          50364,
          440,
          1778,
          983,
          286,
          390,
          884,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5671,
        "id": 1512,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5668,
        "temperature": 0,
        "text": " This doesn't look right.",
        "tokens": [
          50514,
          639,
          1177,
          380,
          574,
          558,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5673,
        "id": 1513,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5671,
        "temperature": 0,
        "text": " Could this possibly be right?",
        "tokens": [
          50664,
          7497,
          341,
          6264,
          312,
          558,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5675,
        "id": 1514,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5673,
        "temperature": 0,
        "text": " Well, if I did this correctly.",
        "tokens": [
          50764,
          1042,
          11,
          498,
          286,
          630,
          341,
          8944,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5684,
        "id": 1515,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5675,
        "temperature": 0,
        "text": " Now if I go to thecodingtrain.com.",
        "tokens": [
          50864,
          823,
          498,
          286,
          352,
          281,
          264,
          66,
          8616,
          83,
          7146,
          13,
          1112,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5688,
        "id": 1516,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5684,
        "temperature": 0,
        "text": " I'm going to check my email to make sure I didn't get a build error.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          1520,
          452,
          3796,
          281,
          652,
          988,
          286,
          994,
          380,
          483,
          257,
          1322,
          6713,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16706724520082827,
        "compression_ratio": 1.4226190476190477,
        "end": 5691,
        "id": 1517,
        "no_speech_prob": 0.002934925025328994,
        "seek": 566500,
        "start": 5688,
        "temperature": 0,
        "text": " I don't see one.",
        "tokens": [
          51514,
          286,
          500,
          380,
          536,
          472,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5694,
        "id": 1518,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5691,
        "temperature": 0,
        "text": " If I now go to streams.",
        "tokens": [
          50364,
          759,
          286,
          586,
          352,
          281,
          15842,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5698,
        "id": 1519,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5694,
        "temperature": 0,
        "text": " And go to the bottom.",
        "tokens": [
          50514,
          400,
          352,
          281,
          264,
          2767,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5700,
        "id": 1520,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5698,
        "temperature": 0,
        "text": " So I probably did something wrong.",
        "tokens": [
          50714,
          407,
          286,
          1391,
          630,
          746,
          2085,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5702,
        "id": 1521,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5700,
        "temperature": 0,
        "text": " Is one.",
        "tokens": [
          50814,
          1119,
          472,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5703,
        "id": 1522,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5702,
        "temperature": 0,
        "text": " I might have used a bad.",
        "tokens": [
          50914,
          286,
          1062,
          362,
          1143,
          257,
          1578,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5705,
        "id": 1523,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5703,
        "temperature": 0,
        "text": " So let's look at one that's actually showing up.",
        "tokens": [
          50964,
          407,
          718,
          311,
          574,
          412,
          472,
          300,
          311,
          767,
          4099,
          493,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5710,
        "id": 1524,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5705,
        "temperature": 0,
        "text": " So let's look at 104.",
        "tokens": [
          51064,
          407,
          718,
          311,
          574,
          412,
          47757,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5712,
        "id": 1525,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5710,
        "temperature": 0,
        "text": " 104.",
        "tokens": [
          51314,
          47757,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5713,
        "id": 1526,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5712,
        "temperature": 0,
        "text": " Let's go to edit.",
        "tokens": [
          51414,
          961,
          311,
          352,
          281,
          8129,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5714,
        "id": 1527,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5713,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51464,
          876,
          11,
          1338,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5716,
        "id": 1528,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5714,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51514,
          876,
          11,
          574,
          412,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5717,
        "id": 1529,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5716,
        "temperature": 0,
        "text": " No, this is right.",
        "tokens": [
          51614,
          883,
          11,
          341,
          307,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5718,
        "id": 1530,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5717,
        "temperature": 0,
        "text": " Let's look at this.",
        "tokens": [
          51664,
          961,
          311,
          574,
          412,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14956863995256095,
        "compression_ratio": 1.639344262295082,
        "end": 5720,
        "id": 1531,
        "no_speech_prob": 0.30733442306518555,
        "seek": 569100,
        "start": 5718,
        "temperature": 0,
        "text": " So this one's showing up.",
        "tokens": [
          51714,
          407,
          341,
          472,
          311,
          4099,
          493,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5722,
        "id": 1532,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5720,
        "temperature": 0,
        "text": " I'm just going to paste this in.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          9163,
          341,
          294,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5725,
        "id": 1533,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5722,
        "temperature": 0,
        "text": " I think I did something wrong.",
        "tokens": [
          50464,
          286,
          519,
          286,
          630,
          746,
          2085,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5727,
        "id": 1534,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5725,
        "temperature": 0,
        "text": " Topics.",
        "tokens": [
          50614,
          8840,
          1167,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5728,
        "id": 1535,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5727,
        "temperature": 0,
        "text": " Oh, wait.",
        "tokens": [
          50714,
          876,
          11,
          1699,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5730,
        "id": 1536,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5728,
        "temperature": 0,
        "text": " I know what the problem is.",
        "tokens": [
          50764,
          286,
          458,
          437,
          264,
          1154,
          307,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5733,
        "id": 1537,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5730,
        "temperature": 0,
        "text": " Topics.",
        "tokens": [
          50864,
          8840,
          1167,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5735,
        "id": 1538,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5733,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51014,
          865,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5736,
        "id": 1539,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5735,
        "temperature": 0,
        "text": " I think.",
        "tokens": [
          51114,
          286,
          519,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5739,
        "id": 1540,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5736,
        "temperature": 0,
        "text": " If I look at the format here.",
        "tokens": [
          51164,
          759,
          286,
          574,
          412,
          264,
          7877,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5740,
        "id": 1541,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5739,
        "temperature": 0,
        "text": " Title.",
        "tokens": [
          51314,
          26768,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5744,
        "id": 1542,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5740,
        "temperature": 0,
        "text": " This should be under here.",
        "tokens": [
          51364,
          639,
          820,
          312,
          833,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15211805804022427,
        "compression_ratio": 1.4870129870129871,
        "end": 5748,
        "id": 1543,
        "no_speech_prob": 0.029311763122677803,
        "seek": 572000,
        "start": 5744,
        "temperature": 0,
        "text": " And this should just say topics.",
        "tokens": [
          51564,
          400,
          341,
          820,
          445,
          584,
          8378,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5750,
        "id": 1544,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5749,
        "temperature": 0,
        "text": " And maybe it's.",
        "tokens": [
          50414,
          400,
          1310,
          309,
          311,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5754,
        "id": 1545,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5750,
        "temperature": 0,
        "text": " I want to do this.",
        "tokens": [
          50464,
          286,
          528,
          281,
          360,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5756,
        "id": 1546,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5754,
        "temperature": 0,
        "text": " So maybe I want it to be like this.",
        "tokens": [
          50664,
          407,
          1310,
          286,
          528,
          309,
          281,
          312,
          411,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5760,
        "id": 1547,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5756,
        "temperature": 0,
        "text": " Oh, is the date format wrong?",
        "tokens": [
          50764,
          876,
          11,
          307,
          264,
          4002,
          7877,
          2085,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5761,
        "id": 1548,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5760,
        "temperature": 0,
        "text": " I have an extra line break at the top.",
        "tokens": [
          50964,
          286,
          362,
          364,
          2857,
          1622,
          1821,
          412,
          264,
          1192,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5763,
        "id": 1549,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5761,
        "temperature": 0,
        "text": " Is that the only problem?",
        "tokens": [
          51014,
          1119,
          300,
          264,
          787,
          1154,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5770,
        "id": 1550,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5763,
        "temperature": 0,
        "text": " But let's use this format.",
        "tokens": [
          51114,
          583,
          718,
          311,
          764,
          341,
          7877,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5775,
        "id": 1551,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5770,
        "temperature": 0,
        "text": " Let's use this format.",
        "tokens": [
          51464,
          961,
          311,
          764,
          341,
          7877,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15351053031094103,
        "compression_ratio": 1.6267605633802817,
        "end": 5777,
        "id": 1552,
        "no_speech_prob": 0.01542343758046627,
        "seek": 574800,
        "start": 5775,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          51714,
          961,
          311,
          853,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5778,
        "id": 1553,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5777,
        "temperature": 0,
        "text": " And then I can.",
        "tokens": [
          50364,
          400,
          550,
          286,
          393,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5781,
        "id": 1554,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5778,
        "temperature": 0,
        "text": " There's no video ID yet.",
        "tokens": [
          50414,
          821,
          311,
          572,
          960,
          7348,
          1939,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5782,
        "id": 1555,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5781,
        "temperature": 0,
        "text": " Oh, and this should say, by the way.",
        "tokens": [
          50564,
          876,
          11,
          293,
          341,
          820,
          584,
          11,
          538,
          264,
          636,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5783,
        "id": 1556,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5782,
        "temperature": 0,
        "text": " I want this to say.",
        "tokens": [
          50614,
          286,
          528,
          341,
          281,
          584,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5784,
        "id": 1557,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5783,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          50664,
          876,
          11,
          291,
          458,
          437,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5788,
        "id": 1558,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5784,
        "temperature": 0,
        "text": " I wouldn't be surprised if this requires this.",
        "tokens": [
          50714,
          286,
          2759,
          380,
          312,
          6100,
          498,
          341,
          7029,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5790,
        "id": 1559,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5788,
        "temperature": 0,
        "text": " February 9th.",
        "tokens": [
          50914,
          8711,
          1722,
          392,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5791,
        "id": 1560,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5790,
        "temperature": 0,
        "text": " Yep, that's right.",
        "tokens": [
          51014,
          7010,
          11,
          300,
          311,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5793,
        "id": 1561,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5791,
        "temperature": 0,
        "text": " 4 p.m.",
        "tokens": [
          51064,
          1017,
          280,
          13,
          76,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5798,
        "id": 1562,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5793,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          51164,
          961,
          311,
          853,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5803,
        "id": 1563,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5798,
        "temperature": 0,
        "text": " And then here.",
        "tokens": [
          51414,
          400,
          550,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19512865494708626,
        "compression_ratio": 1.4034090909090908,
        "end": 5805,
        "id": 1564,
        "no_speech_prob": 0.08033977448940277,
        "seek": 577700,
        "start": 5803,
        "temperature": 0,
        "text": " Live stream.",
        "tokens": [
          51664,
          10385,
          4309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5807,
        "id": 1565,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5805,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5810,
        "id": 1566,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5807,
        "temperature": 0,
        "text": " More neural networks.",
        "tokens": [
          50464,
          5048,
          18161,
          9590,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5813,
        "id": 1567,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5810,
        "temperature": 0,
        "text": " And also pendulums.",
        "tokens": [
          50614,
          400,
          611,
          12179,
          425,
          8099,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5814,
        "id": 1568,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5813,
        "temperature": 0,
        "text": " Let's just put that there.",
        "tokens": [
          50764,
          961,
          311,
          445,
          829,
          300,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5815,
        "id": 1569,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5814,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5818,
        "id": 1570,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5815,
        "temperature": 0,
        "text": " Let's look at this.",
        "tokens": [
          50864,
          961,
          311,
          574,
          412,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5819,
        "id": 1571,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5818,
        "temperature": 0,
        "text": " How are we doing here?",
        "tokens": [
          51014,
          1012,
          366,
          321,
          884,
          510,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5823,
        "id": 1572,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5819,
        "temperature": 0,
        "text": " Is this possibly correct?",
        "tokens": [
          51064,
          1119,
          341,
          6264,
          3006,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5826,
        "id": 1573,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5823,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          51264,
          961,
          311,
          853,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5828,
        "id": 1574,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5826,
        "temperature": 0,
        "text": " Let's.",
        "tokens": [
          51414,
          961,
          311,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2447288663763749,
        "compression_ratio": 1.401360544217687,
        "end": 5832,
        "id": 1575,
        "no_speech_prob": 0.06278650462627411,
        "seek": 580500,
        "start": 5828,
        "temperature": 0,
        "text": " Does correcting live stream page.",
        "tokens": [
          51514,
          4402,
          47032,
          1621,
          4309,
          3028,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2362626856023615,
        "compression_ratio": 1.2461538461538462,
        "end": 5835,
        "id": 1576,
        "no_speech_prob": 0.08151537925004959,
        "seek": 583200,
        "start": 5833,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          50414,
          961,
          311,
          360,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2362626856023615,
        "compression_ratio": 1.2461538461538462,
        "end": 5836,
        "id": 1577,
        "no_speech_prob": 0.08151537925004959,
        "seek": 583200,
        "start": 5835,
        "temperature": 0,
        "text": " This looks better.",
        "tokens": [
          50514,
          639,
          1542,
          1101,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2362626856023615,
        "compression_ratio": 1.2461538461538462,
        "end": 5839,
        "id": 1578,
        "no_speech_prob": 0.08151537925004959,
        "seek": 583200,
        "start": 5836,
        "temperature": 0,
        "text": " Like, it formatted it.",
        "tokens": [
          50564,
          1743,
          11,
          309,
          1254,
          32509,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2362626856023615,
        "compression_ratio": 1.2461538461538462,
        "end": 5845,
        "id": 1579,
        "no_speech_prob": 0.08151537925004959,
        "seek": 583200,
        "start": 5839,
        "temperature": 0,
        "text": " And so now we have to wait for the page to build.",
        "tokens": [
          50714,
          400,
          370,
          586,
          321,
          362,
          281,
          1699,
          337,
          264,
          3028,
          281,
          1322,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2362626856023615,
        "compression_ratio": 1.2461538461538462,
        "end": 5853,
        "id": 1580,
        "no_speech_prob": 0.08151537925004959,
        "seek": 583200,
        "start": 5845,
        "temperature": 0,
        "text": " So I will take some questions.",
        "tokens": [
          51014,
          407,
          286,
          486,
          747,
          512,
          1651,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2362626856023615,
        "compression_ratio": 1.2461538461538462,
        "end": 5854,
        "id": 1581,
        "no_speech_prob": 0.08151537925004959,
        "seek": 583200,
        "start": 5853,
        "temperature": 0,
        "text": " Maybe indent the topics.",
        "tokens": [
          51414,
          2704,
          44494,
          264,
          8378,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.25770779045260683,
        "compression_ratio": 1.297709923664122,
        "end": 5869,
        "id": 1582,
        "no_speech_prob": 0.08631407469511032,
        "seek": 585400,
        "start": 5855,
        "temperature": 0,
        "text": " Check if there's a plug-in for your editor.",
        "tokens": [
          50414,
          6881,
          498,
          456,
          311,
          257,
          5452,
          12,
          259,
          337,
          428,
          9839,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25770779045260683,
        "compression_ratio": 1.297709923664122,
        "end": 5875,
        "id": 1583,
        "no_speech_prob": 0.08631407469511032,
        "seek": 585400,
        "start": 5869,
        "temperature": 0,
        "text": " Does it show up on the home page?",
        "tokens": [
          51114,
          4402,
          309,
          855,
          493,
          322,
          264,
          1280,
          3028,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.25770779045260683,
        "compression_ratio": 1.297709923664122,
        "end": 5881,
        "id": 1584,
        "no_speech_prob": 0.08631407469511032,
        "seek": 585400,
        "start": 5875,
        "temperature": 0,
        "text": " I think one of the ideas was to have the upcoming, next upcoming live stream always be here.",
        "tokens": [
          51414,
          286,
          519,
          472,
          295,
          264,
          3487,
          390,
          281,
          362,
          264,
          11500,
          11,
          958,
          11500,
          1621,
          4309,
          1009,
          312,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23712005615234374,
        "compression_ratio": 1.3783783783783783,
        "end": 5884,
        "id": 1585,
        "no_speech_prob": 0.06852847337722778,
        "seek": 588100,
        "start": 5881,
        "temperature": 0,
        "text": " Latest videos.",
        "tokens": [
          50364,
          7354,
          377,
          2145,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.23712005615234374,
        "compression_ratio": 1.3783783783783783,
        "end": 5887,
        "id": 1586,
        "no_speech_prob": 0.06852847337722778,
        "seek": 588100,
        "start": 5884,
        "temperature": 0,
        "text": " By the way, also, these are the links now.",
        "tokens": [
          50514,
          3146,
          264,
          636,
          11,
          611,
          11,
          613,
          366,
          264,
          6123,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23712005615234374,
        "compression_ratio": 1.3783783783783783,
        "end": 5894,
        "id": 1587,
        "no_speech_prob": 0.06852847337722778,
        "seek": 588100,
        "start": 5887,
        "temperature": 0,
        "text": " So the Patreon link, merchandise link, and then link to the Amazon shop is here.",
        "tokens": [
          50664,
          407,
          264,
          15692,
          2113,
          11,
          34485,
          2113,
          11,
          293,
          550,
          2113,
          281,
          264,
          6795,
          3945,
          307,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23712005615234374,
        "compression_ratio": 1.3783783783783783,
        "end": 5902,
        "id": 1588,
        "no_speech_prob": 0.06852847337722778,
        "seek": 588100,
        "start": 5894,
        "temperature": 0,
        "text": " Let's go back to streams.",
        "tokens": [
          51014,
          961,
          311,
          352,
          646,
          281,
          15842,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23712005615234374,
        "compression_ratio": 1.3783783783783783,
        "end": 5903,
        "id": 1589,
        "no_speech_prob": 0.06852847337722778,
        "seek": 588100,
        "start": 5902,
        "temperature": 0,
        "text": " I'm sure it's just me screwing this up.",
        "tokens": [
          51414,
          286,
          478,
          988,
          309,
          311,
          445,
          385,
          5630,
          278,
          341,
          493,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2811400430244312,
        "compression_ratio": 1.3486842105263157,
        "end": 5912,
        "id": 1590,
        "no_speech_prob": 0.16666178405284882,
        "seek": 590300,
        "start": 5904,
        "temperature": 0,
        "text": " It's also possible that, because GitHub pages can take, so here.",
        "tokens": [
          50414,
          467,
          311,
          611,
          1944,
          300,
          11,
          570,
          23331,
          7183,
          393,
          747,
          11,
          370,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2811400430244312,
        "compression_ratio": 1.3486842105263157,
        "end": 5917,
        "id": 1591,
        "no_speech_prob": 0.16666178405284882,
        "seek": 590300,
        "start": 5912,
        "temperature": 0,
        "text": " Let's be a little bit more thoughtful about this.",
        "tokens": [
          50814,
          961,
          311,
          312,
          257,
          707,
          857,
          544,
          21566,
          466,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2811400430244312,
        "compression_ratio": 1.3486842105263157,
        "end": 5919,
        "id": 1592,
        "no_speech_prob": 0.16666178405284882,
        "seek": 590300,
        "start": 5917,
        "temperature": 0,
        "text": " Let's actually clone the repo.",
        "tokens": [
          51064,
          961,
          311,
          767,
          26506,
          264,
          49040,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2811400430244312,
        "compression_ratio": 1.3486842105263157,
        "end": 5930,
        "id": 1593,
        "no_speech_prob": 0.16666178405284882,
        "seek": 590300,
        "start": 5919,
        "temperature": 0,
        "text": " So those of you who are wondering, how does this even work?",
        "tokens": [
          51164,
          407,
          729,
          295,
          291,
          567,
          366,
          6359,
          11,
          577,
          775,
          341,
          754,
          589,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5933,
        "id": 1594,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5930,
        "temperature": 0,
        "text": " Let's go, let's clone.",
        "tokens": [
          50364,
          961,
          311,
          352,
          11,
          718,
          311,
          26506,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5939,
        "id": 1595,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5933,
        "temperature": 0,
        "text": " Now, this is probably going to be a very long clone.",
        "tokens": [
          50514,
          823,
          11,
          341,
          307,
          1391,
          516,
          281,
          312,
          257,
          588,
          938,
          26506,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5942,
        "id": 1596,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5939,
        "temperature": 0,
        "text": " So let's just get the repo to the desktop.",
        "tokens": [
          50814,
          407,
          718,
          311,
          445,
          483,
          264,
          49040,
          281,
          264,
          14502,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5943,
        "id": 1597,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5942,
        "temperature": 0,
        "text": " This is going to take a little while.",
        "tokens": [
          50964,
          639,
          307,
          516,
          281,
          747,
          257,
          707,
          1339,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5944,
        "id": 1598,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5943,
        "temperature": 0,
        "text": " We'll have a pretty fast.",
        "tokens": [
          51014,
          492,
          603,
          362,
          257,
          1238,
          2370,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5947,
        "id": 1599,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5944,
        "temperature": 0,
        "text": " Oh, it's working for me.",
        "tokens": [
          51064,
          876,
          11,
          309,
          311,
          1364,
          337,
          385,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5952,
        "id": 1600,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5947,
        "temperature": 0,
        "text": " I was going to just try running Jekyll locally.",
        "tokens": [
          51214,
          286,
          390,
          516,
          281,
          445,
          853,
          2614,
          508,
          916,
          34353,
          16143,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5954,
        "id": 1601,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5952,
        "temperature": 0,
        "text": " Oh, maybe it's caching.",
        "tokens": [
          51464,
          876,
          11,
          1310,
          309,
          311,
          269,
          2834,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19549893397910922,
        "compression_ratio": 1.5303030303030303,
        "end": 5959,
        "id": 1602,
        "no_speech_prob": 0.13114391267299652,
        "seek": 593000,
        "start": 5954,
        "temperature": 0,
        "text": " Let me force a refresh.",
        "tokens": [
          51564,
          961,
          385,
          3464,
          257,
          15134,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5960,
        "id": 1603,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5959,
        "temperature": 0,
        "text": " Is it on the home page?",
        "tokens": [
          50364,
          1119,
          309,
          322,
          264,
          1280,
          3028,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5962,
        "id": 1604,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5960,
        "temperature": 0,
        "text": " By the way, there's also one thing I'm just realizing now.",
        "tokens": [
          50414,
          3146,
          264,
          636,
          11,
          456,
          311,
          611,
          472,
          551,
          286,
          478,
          445,
          16734,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5964,
        "id": 1605,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5962,
        "temperature": 0,
        "text": " There's no link back to the front page.",
        "tokens": [
          50514,
          821,
          311,
          572,
          2113,
          646,
          281,
          264,
          1868,
          3028,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5966,
        "id": 1606,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5964,
        "temperature": 0,
        "text": " Well, maybe if I click here it is, yes.",
        "tokens": [
          50614,
          1042,
          11,
          1310,
          498,
          286,
          2052,
          510,
          309,
          307,
          11,
          2086,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5968,
        "id": 1607,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5966,
        "temperature": 0,
        "text": " Oh, there we go.",
        "tokens": [
          50714,
          876,
          11,
          456,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5969,
        "id": 1608,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5968,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          50814,
          2053,
          412,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5970,
        "id": 1609,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5969,
        "temperature": 0,
        "text": " Upcoming live stream.",
        "tokens": [
          50864,
          5858,
          6590,
          1621,
          4309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5973,
        "id": 1610,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5970,
        "temperature": 0,
        "text": " Ah, that's why I probably want to put it.",
        "tokens": [
          50914,
          2438,
          11,
          300,
          311,
          983,
          286,
          1391,
          528,
          281,
          829,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5974,
        "id": 1611,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5973,
        "temperature": 0,
        "text": " Okay, there we go.",
        "tokens": [
          51064,
          1033,
          11,
          456,
          321,
          352,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5975,
        "id": 1612,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5974,
        "temperature": 0,
        "text": " Look, there it is.",
        "tokens": [
          51114,
          2053,
          11,
          456,
          309,
          307,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5979,
        "id": 1613,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5975,
        "temperature": 0,
        "text": " So now, whenever I schedule one, the upcoming live stream should be there.",
        "tokens": [
          51164,
          407,
          586,
          11,
          5699,
          286,
          7567,
          472,
          11,
          264,
          11500,
          1621,
          4309,
          820,
          312,
          456,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5981,
        "id": 1614,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5979,
        "temperature": 0,
        "text": " Now, it has the wrong time.",
        "tokens": [
          51364,
          823,
          11,
          309,
          575,
          264,
          2085,
          565,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5983,
        "id": 1615,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5981,
        "temperature": 0,
        "text": " I'm not sure why.",
        "tokens": [
          51464,
          286,
          478,
          406,
          988,
          983,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16090620924162385,
        "compression_ratio": 1.6417910447761195,
        "end": 5984,
        "id": 1616,
        "no_speech_prob": 0.034617189317941666,
        "seek": 595900,
        "start": 5983,
        "temperature": 0,
        "text": " I thought I fixed that.",
        "tokens": [
          51564,
          286,
          1194,
          286,
          6806,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 5993,
        "id": 1617,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 5984,
        "temperature": 0,
        "text": " Let's go back to streams.",
        "tokens": [
          50364,
          961,
          311,
          352,
          646,
          281,
          15842,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 5994,
        "id": 1618,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 5993,
        "temperature": 0,
        "text": " Let me do this locally.",
        "tokens": [
          50814,
          961,
          385,
          360,
          341,
          16143,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 5995,
        "id": 1619,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 5994,
        "temperature": 0,
        "text": " Let's go through this.",
        "tokens": [
          50864,
          961,
          311,
          352,
          807,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 5997,
        "id": 1620,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 5995,
        "temperature": 0,
        "text": " Okay, I've got it.",
        "tokens": [
          50914,
          1033,
          11,
          286,
          600,
          658,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 5999,
        "id": 1621,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 5997,
        "temperature": 0,
        "text": " So I've cloned the repo.",
        "tokens": [
          51014,
          407,
          286,
          600,
          596,
          19009,
          264,
          49040,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 6006,
        "id": 1622,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 5999,
        "temperature": 0,
        "text": " If you want to work on it and understand and contribute to it locally, if I go now to Rainbow Code.",
        "tokens": [
          51114,
          759,
          291,
          528,
          281,
          589,
          322,
          309,
          293,
          1223,
          293,
          10586,
          281,
          309,
          16143,
          11,
          498,
          286,
          352,
          586,
          281,
          29477,
          15549,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 6011,
        "id": 1623,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 6006,
        "temperature": 0,
        "text": " Now, I have no idea if Jekyll is installed.",
        "tokens": [
          51464,
          823,
          11,
          286,
          362,
          572,
          1558,
          498,
          508,
          916,
          34353,
          307,
          8899,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1413325648153982,
        "compression_ratio": 1.453125,
        "end": 6013,
        "id": 1624,
        "no_speech_prob": 0.16666875779628754,
        "seek": 598400,
        "start": 6011,
        "temperature": 0,
        "text": " It is, apparently.",
        "tokens": [
          51714,
          467,
          307,
          11,
          7970,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21124627418124797,
        "compression_ratio": 1.5285714285714285,
        "end": 6016,
        "id": 1625,
        "no_speech_prob": 0.005220029968768358,
        "seek": 601300,
        "start": 6013,
        "temperature": 0,
        "text": " Of course, it just gave me a bunch of errors.",
        "tokens": [
          50364,
          2720,
          1164,
          11,
          309,
          445,
          2729,
          385,
          257,
          3840,
          295,
          13603,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21124627418124797,
        "compression_ratio": 1.5285714285714285,
        "end": 6024,
        "id": 1626,
        "no_speech_prob": 0.005220029968768358,
        "seek": 601300,
        "start": 6016,
        "temperature": 0,
        "text": " So let's, this is, the problem is I have, I've never used Jekyll or Ruby on this log into this computer.",
        "tokens": [
          50514,
          407,
          718,
          311,
          11,
          341,
          307,
          11,
          264,
          1154,
          307,
          286,
          362,
          11,
          286,
          600,
          1128,
          1143,
          508,
          916,
          34353,
          420,
          19907,
          322,
          341,
          3565,
          666,
          341,
          3820,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21124627418124797,
        "compression_ratio": 1.5285714285714285,
        "end": 6029,
        "id": 1627,
        "no_speech_prob": 0.005220029968768358,
        "seek": 601300,
        "start": 6024,
        "temperature": 0,
        "text": " So I hesitate to go get this all working right now, but let's just.",
        "tokens": [
          50914,
          407,
          286,
          20842,
          281,
          352,
          483,
          341,
          439,
          1364,
          558,
          586,
          11,
          457,
          718,
          311,
          445,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21124627418124797,
        "compression_ratio": 1.5285714285714285,
        "end": 6035,
        "id": 1628,
        "no_speech_prob": 0.005220029968768358,
        "seek": 601300,
        "start": 6029,
        "temperature": 0,
        "text": " Jekyll is a framework for building static websites, and I'm going to just do this.",
        "tokens": [
          51164,
          508,
          916,
          34353,
          307,
          257,
          8388,
          337,
          2390,
          13437,
          12891,
          11,
          293,
          286,
          478,
          516,
          281,
          445,
          360,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21124627418124797,
        "compression_ratio": 1.5285714285714285,
        "end": 6039,
        "id": 1629,
        "no_speech_prob": 0.005220029968768358,
        "seek": 601300,
        "start": 6035,
        "temperature": 0,
        "text": " Let's see if I can.",
        "tokens": [
          51464,
          961,
          311,
          536,
          498,
          286,
          393,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.28708140746406885,
        "compression_ratio": 0.8771929824561403,
        "end": 6042,
        "id": 1630,
        "no_speech_prob": 0.11278023570775986,
        "seek": 603900,
        "start": 6040,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50414,
          865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.28708140746406885,
        "compression_ratio": 0.8771929824561403,
        "end": 6048,
        "id": 1631,
        "no_speech_prob": 0.11278023570775986,
        "seek": 603900,
        "start": 6042,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50514,
          1057,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.28708140746406885,
        "compression_ratio": 0.8771929824561403,
        "end": 6064,
        "id": 1632,
        "no_speech_prob": 0.11278023570775986,
        "seek": 603900,
        "start": 6048,
        "temperature": 0,
        "text": " Yeah, so I've got to update Ruby.",
        "tokens": [
          50814,
          865,
          11,
          370,
          286,
          600,
          658,
          281,
          5623,
          19907,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19318806683575665,
        "compression_ratio": 1.5032258064516129,
        "end": 6070,
        "id": 1633,
        "no_speech_prob": 0.5116418600082397,
        "seek": 606400,
        "start": 6064,
        "temperature": 0,
        "text": " The guest tutorial is, okay.",
        "tokens": [
          50364,
          440,
          8341,
          7073,
          307,
          11,
          1392,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19318806683575665,
        "compression_ratio": 1.5032258064516129,
        "end": 6072,
        "id": 1634,
        "no_speech_prob": 0.5116418600082397,
        "seek": 606400,
        "start": 6070,
        "temperature": 0,
        "text": " I'm trying to decide if this is worth doing right now.",
        "tokens": [
          50664,
          286,
          478,
          1382,
          281,
          4536,
          498,
          341,
          307,
          3163,
          884,
          558,
          586,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19318806683575665,
        "compression_ratio": 1.5032258064516129,
        "end": 6076,
        "id": 1635,
        "no_speech_prob": 0.5116418600082397,
        "seek": 606400,
        "start": 6072,
        "temperature": 0,
        "text": " So let, yeah, let's, let me, do I have, so one thing that I use is RVM.",
        "tokens": [
          50764,
          407,
          718,
          11,
          1338,
          11,
          718,
          311,
          11,
          718,
          385,
          11,
          360,
          286,
          362,
          11,
          370,
          472,
          551,
          300,
          286,
          764,
          307,
          28314,
          44,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19318806683575665,
        "compression_ratio": 1.5032258064516129,
        "end": 6079,
        "id": 1636,
        "no_speech_prob": 0.5116418600082397,
        "seek": 606400,
        "start": 6076,
        "temperature": 0,
        "text": " So let's use RVM.",
        "tokens": [
          50964,
          407,
          718,
          311,
          764,
          28314,
          44,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19318806683575665,
        "compression_ratio": 1.5032258064516129,
        "end": 6090,
        "id": 1637,
        "no_speech_prob": 0.5116418600082397,
        "seek": 606400,
        "start": 6079,
        "temperature": 0,
        "text": " So I'm going to grab RVM, which should let me do this here.",
        "tokens": [
          51114,
          407,
          286,
          478,
          516,
          281,
          4444,
          28314,
          44,
          11,
          597,
          820,
          718,
          385,
          360,
          341,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16492203510168826,
        "compression_ratio": 1.3597122302158273,
        "end": 6095,
        "id": 1638,
        "no_speech_prob": 0.029309263452887535,
        "seek": 609000,
        "start": 6090,
        "temperature": 0,
        "text": " RVM is Ruby Version Manager.",
        "tokens": [
          50364,
          28314,
          44,
          307,
          19907,
          35965,
          13821,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16492203510168826,
        "compression_ratio": 1.3597122302158273,
        "end": 6100,
        "id": 1639,
        "no_speech_prob": 0.029309263452887535,
        "seek": 609000,
        "start": 6095,
        "temperature": 0,
        "text": " So this should allow me to manage the versions of Ruby I have.",
        "tokens": [
          50614,
          407,
          341,
          820,
          2089,
          385,
          281,
          3067,
          264,
          9606,
          295,
          19907,
          286,
          362,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16492203510168826,
        "compression_ratio": 1.3597122302158273,
        "end": 6107,
        "id": 1640,
        "no_speech_prob": 0.029309263452887535,
        "seek": 609000,
        "start": 6100,
        "temperature": 0,
        "text": " To start using RVM, you need to run sort, yeah, so I need to do this.",
        "tokens": [
          50864,
          1407,
          722,
          1228,
          28314,
          44,
          11,
          291,
          643,
          281,
          1190,
          1333,
          11,
          1338,
          11,
          370,
          286,
          643,
          281,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16492203510168826,
        "compression_ratio": 1.3597122302158273,
        "end": 6110,
        "id": 1641,
        "no_speech_prob": 0.029309263452887535,
        "seek": 609000,
        "start": 6107,
        "temperature": 0,
        "text": " So it's running.",
        "tokens": [
          51214,
          407,
          309,
          311,
          2614,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16492203510168826,
        "compression_ratio": 1.3597122302158273,
        "end": 6111,
        "id": 1642,
        "no_speech_prob": 0.029309263452887535,
        "seek": 609000,
        "start": 6110,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16492203510168826,
        "compression_ratio": 1.3597122302158273,
        "end": 6113,
        "id": 1643,
        "no_speech_prob": 0.029309263452887535,
        "seek": 609000,
        "start": 6111,
        "temperature": 0,
        "text": " RVM.",
        "tokens": [
          51414,
          28314,
          44,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1689565552605523,
        "compression_ratio": 1.5810055865921788,
        "end": 6123,
        "id": 1644,
        "no_speech_prob": 0.14604708552360535,
        "seek": 611300,
        "start": 6113,
        "temperature": 0,
        "text": " So I think to install with a certain version of Ruby, what I want to do,",
        "tokens": [
          50364,
          407,
          286,
          519,
          281,
          3625,
          365,
          257,
          1629,
          3037,
          295,
          19907,
          11,
          437,
          286,
          528,
          281,
          360,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.1689565552605523,
        "compression_ratio": 1.5810055865921788,
        "end": 6127,
        "id": 1645,
        "no_speech_prob": 0.14604708552360535,
        "seek": 611300,
        "start": 6123,
        "temperature": 0,
        "text": " I really don't know what I'm doing here, by the way, is document,",
        "tokens": [
          50864,
          286,
          534,
          500,
          380,
          458,
          437,
          286,
          478,
          884,
          510,
          11,
          538,
          264,
          636,
          11,
          307,
          4166,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1689565552605523,
        "compression_ratio": 1.5810055865921788,
        "end": 6130,
        "id": 1646,
        "no_speech_prob": 0.14604708552360535,
        "seek": 611300,
        "start": 6127,
        "temperature": 0,
        "text": " I just want the installation.",
        "tokens": [
          51064,
          286,
          445,
          528,
          264,
          13260,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1689565552605523,
        "compression_ratio": 1.5810055865921788,
        "end": 6132,
        "id": 1647,
        "no_speech_prob": 0.14604708552360535,
        "seek": 611300,
        "start": 6130,
        "temperature": 0,
        "text": " Yeah, I've installed it.",
        "tokens": [
          51214,
          865,
          11,
          286,
          600,
          8899,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1689565552605523,
        "compression_ratio": 1.5810055865921788,
        "end": 6137,
        "id": 1648,
        "no_speech_prob": 0.14604708552360535,
        "seek": 611300,
        "start": 6132,
        "temperature": 0,
        "text": " I just want like a, how do I install which version I'm using?",
        "tokens": [
          51314,
          286,
          445,
          528,
          411,
          257,
          11,
          577,
          360,
          286,
          3625,
          597,
          3037,
          286,
          478,
          1228,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1689565552605523,
        "compression_ratio": 1.5810055865921788,
        "end": 6140,
        "id": 1649,
        "no_speech_prob": 0.14604708552360535,
        "seek": 611300,
        "start": 6137,
        "temperature": 0,
        "text": " RVM, RVM list, RVM install.",
        "tokens": [
          51564,
          28314,
          44,
          11,
          28314,
          44,
          1329,
          11,
          28314,
          44,
          3625,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6141,
        "id": 1650,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6140,
        "temperature": 0,
        "text": " RVM install.",
        "tokens": [
          50364,
          28314,
          44,
          3625,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6142,
        "id": 1651,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6141,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6143,
        "id": 1652,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6142,
        "temperature": 0,
        "text": " RVM install.",
        "tokens": [
          50464,
          28314,
          44,
          3625,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6147,
        "id": 1653,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6143,
        "temperature": 0,
        "text": " And then what did it say on Jekyll I need to be using?",
        "tokens": [
          50514,
          400,
          550,
          437,
          630,
          309,
          584,
          322,
          508,
          916,
          34353,
          286,
          643,
          281,
          312,
          1228,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6150,
        "id": 1654,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6147,
        "temperature": 0,
        "text": " Which Ruby?",
        "tokens": [
          50714,
          3013,
          19907,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6152,
        "id": 1655,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6150,
        "temperature": 0,
        "text": " Jekyll.",
        "tokens": [
          50864,
          508,
          916,
          34353,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6158,
        "id": 1656,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6152,
        "temperature": 0,
        "text": " It's probably going to be an error because our, what did it say?",
        "tokens": [
          50964,
          467,
          311,
          1391,
          516,
          281,
          312,
          364,
          6713,
          570,
          527,
          11,
          437,
          630,
          309,
          584,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6164,
        "id": 1657,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6158,
        "temperature": 0,
        "text": " I can't believe I'm doing this on a live stream.",
        "tokens": [
          51264,
          286,
          393,
          380,
          1697,
          286,
          478,
          884,
          341,
          322,
          257,
          1621,
          4309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6165,
        "id": 1658,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6164,
        "temperature": 0,
        "text": " What did it say?",
        "tokens": [
          51564,
          708,
          630,
          309,
          584,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6167,
        "id": 1659,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6165,
        "temperature": 0,
        "text": " Requires Ruby 2.2.5.",
        "tokens": [
          51614,
          42029,
          3145,
          19907,
          568,
          13,
          17,
          13,
          20,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6168,
        "id": 1660,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6167,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51714,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1538801105744248,
        "compression_ratio": 1.5026737967914439,
        "end": 6169,
        "id": 1661,
        "no_speech_prob": 0.022285688668489456,
        "seek": 614000,
        "start": 6168,
        "temperature": 0,
        "text": " Let's quit that.",
        "tokens": [
          51764,
          961,
          311,
          10366,
          300,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6172,
        "id": 1662,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6169,
        "temperature": 0,
        "text": " RVM install this.",
        "tokens": [
          50364,
          28314,
          44,
          3625,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6176,
        "id": 1663,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6172,
        "temperature": 0,
        "text": " So now I'm installing Ruby 2.2.5.",
        "tokens": [
          50514,
          407,
          586,
          286,
          478,
          20762,
          19907,
          568,
          13,
          17,
          13,
          20,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6180,
        "id": 1664,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6176,
        "temperature": 0,
        "text": " Checking requirements, error is not, oh, right.",
        "tokens": [
          50714,
          6881,
          278,
          7728,
          11,
          6713,
          307,
          406,
          11,
          1954,
          11,
          558,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6182,
        "id": 1665,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6180,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          50914,
          876,
          11,
          452,
          8387,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6184,
        "id": 1666,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6182,
        "temperature": 0,
        "text": " Brew doctor.",
        "tokens": [
          51014,
          42906,
          4631,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6187,
        "id": 1667,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6184,
        "temperature": 0,
        "text": " Yeah, doctor, doctor.",
        "tokens": [
          51114,
          865,
          11,
          4631,
          11,
          4631,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6189,
        "id": 1668,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6187,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51264,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6191,
        "id": 1669,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6189,
        "temperature": 0,
        "text": " Oh, permission denied.",
        "tokens": [
          51364,
          876,
          11,
          11226,
          17774,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19745258048728662,
        "compression_ratio": 1.3773584905660377,
        "end": 6193,
        "id": 1670,
        "no_speech_prob": 0.06953561305999756,
        "seek": 616900,
        "start": 6191,
        "temperature": 0,
        "text": " Pseudo brew doctor.",
        "tokens": [
          51464,
          430,
          405,
          6207,
          34619,
          4631,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6196,
        "id": 1671,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6194,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50414,
          639,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6198,
        "id": 1672,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6196,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6200,
        "id": 1673,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6198,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6202,
        "id": 1674,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6200,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6208,
        "id": 1675,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6202,
        "temperature": 0,
        "text": " How about pseudo RVM install 2.2.5?",
        "tokens": [
          50814,
          1012,
          466,
          35899,
          28314,
          44,
          3625,
          568,
          13,
          17,
          13,
          20,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6210,
        "id": 1676,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6208,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          51114,
          876,
          11,
          3237,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6212,
        "id": 1677,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6210,
        "temperature": 0,
        "text": " Really?",
        "tokens": [
          51214,
          4083,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6214,
        "id": 1678,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6212,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          51314,
          876,
          11,
          1392,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.32724744932992117,
        "compression_ratio": 1.2333333333333334,
        "end": 6218,
        "id": 1679,
        "no_speech_prob": 0.07055262476205826,
        "seek": 619300,
        "start": 6214,
        "temperature": 0,
        "text": " Let's install home brew.",
        "tokens": [
          51414,
          961,
          311,
          3625,
          1280,
          34619,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20836209315879672,
        "compression_ratio": 1.1851851851851851,
        "end": 6223,
        "id": 1680,
        "no_speech_prob": 0.028435122221708298,
        "seek": 621800,
        "start": 6218,
        "temperature": 0,
        "text": " Let's install home brew.",
        "tokens": [
          50364,
          961,
          311,
          3625,
          1280,
          34619,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20836209315879672,
        "compression_ratio": 1.1851851851851851,
        "end": 6225,
        "id": 1681,
        "no_speech_prob": 0.028435122221708298,
        "seek": 621800,
        "start": 6223,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50614,
          3153,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20836209315879672,
        "compression_ratio": 1.1851851851851851,
        "end": 6232,
        "id": 1682,
        "no_speech_prob": 0.028435122221708298,
        "seek": 621800,
        "start": 6225,
        "temperature": 0,
        "text": " I didn't realize that, okay.",
        "tokens": [
          50714,
          286,
          994,
          380,
          4325,
          300,
          11,
          1392,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20836209315879672,
        "compression_ratio": 1.1851851851851851,
        "end": 6236,
        "id": 1683,
        "no_speech_prob": 0.028435122221708298,
        "seek": 621800,
        "start": 6232,
        "temperature": 0,
        "text": " Failed.",
        "tokens": [
          51064,
          479,
          24731,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20836209315879672,
        "compression_ratio": 1.1851851851851851,
        "end": 6243,
        "id": 1684,
        "no_speech_prob": 0.028435122221708298,
        "seek": 621800,
        "start": 6236,
        "temperature": 0,
        "text": " Don't run this as root.",
        "tokens": [
          51264,
          1468,
          380,
          1190,
          341,
          382,
          5593,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20836209315879672,
        "compression_ratio": 1.1851851851851851,
        "end": 6247,
        "id": 1685,
        "no_speech_prob": 0.028435122221708298,
        "seek": 621800,
        "start": 6243,
        "temperature": 0,
        "text": " Wow, what is going on in this log in?",
        "tokens": [
          51614,
          3153,
          11,
          437,
          307,
          516,
          322,
          294,
          341,
          3565,
          294,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6252,
        "id": 1686,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6247,
        "temperature": 0,
        "text": " Could not set, could not permission denied.",
        "tokens": [
          50364,
          7497,
          406,
          992,
          11,
          727,
          406,
          11226,
          17774,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6256,
        "id": 1687,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6252,
        "temperature": 0,
        "text": " Can I get rid of home brew?",
        "tokens": [
          50614,
          1664,
          286,
          483,
          3973,
          295,
          1280,
          34619,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6258,
        "id": 1688,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6256,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50814,
          3153,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6261,
        "id": 1689,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6258,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50914,
          3153,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6263,
        "id": 1690,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6261,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51064,
          876,
          11,
          452,
          8387,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6265,
        "id": 1691,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6263,
        "temperature": 0,
        "text": " I can't believe this is where I am right now.",
        "tokens": [
          51164,
          286,
          393,
          380,
          1697,
          341,
          307,
          689,
          286,
          669,
          558,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6266,
        "id": 1692,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6265,
        "temperature": 0,
        "text": " What was I trying to do?",
        "tokens": [
          51264,
          708,
          390,
          286,
          1382,
          281,
          360,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6267,
        "id": 1693,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6266,
        "temperature": 0,
        "text": " I don't even remember what I was trying to do.",
        "tokens": [
          51314,
          286,
          500,
          380,
          754,
          1604,
          437,
          286,
          390,
          1382,
          281,
          360,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6269,
        "id": 1694,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6267,
        "temperature": 0,
        "text": " I was trying to show you how to run Jekyll.",
        "tokens": [
          51364,
          286,
          390,
          1382,
          281,
          855,
          291,
          577,
          281,
          1190,
          508,
          916,
          34353,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18982098766208924,
        "compression_ratio": 1.5108695652173914,
        "end": 6275,
        "id": 1695,
        "no_speech_prob": 0.017711404711008072,
        "seek": 624700,
        "start": 6269,
        "temperature": 0,
        "text": " I could just log.",
        "tokens": [
          51464,
          286,
          727,
          445,
          3565,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6277,
        "id": 1696,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6275,
        "temperature": 0,
        "text": " I've been in this situation so many times.",
        "tokens": [
          50364,
          286,
          600,
          668,
          294,
          341,
          2590,
          370,
          867,
          1413,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6279,
        "id": 1697,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6277,
        "temperature": 0,
        "text": " Could not lock config file.",
        "tokens": [
          50464,
          7497,
          406,
          4017,
          6662,
          3991,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6281,
        "id": 1698,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6279,
        "temperature": 0,
        "text": " Permission denied.",
        "tokens": [
          50564,
          41006,
          3106,
          17774,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6283,
        "id": 1699,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6281,
        "temperature": 0,
        "text": " Am I?",
        "tokens": [
          50664,
          2012,
          286,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6285,
        "id": 1700,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6283,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50764,
          1057,
          558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6295,
        "id": 1701,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6285,
        "temperature": 0,
        "text": " Let's go down this rabbit hole for ten more minutes, then I'm out of here.",
        "tokens": [
          50864,
          961,
          311,
          352,
          760,
          341,
          19509,
          5458,
          337,
          2064,
          544,
          2077,
          11,
          550,
          286,
          478,
          484,
          295,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.27972518073187935,
        "compression_ratio": 1.272108843537415,
        "end": 6297,
        "id": 1702,
        "no_speech_prob": 0.021943746134638786,
        "seek": 627500,
        "start": 6295,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.5015466087742856,
        "compression_ratio": 0.8958333333333334,
        "end": 6316,
        "id": 1703,
        "no_speech_prob": 0.41860365867614746,
        "seek": 629700,
        "start": 6298,
        "temperature": 0,
        "text": " Oh, maybe if I just use iterm, I'd be fine.",
        "tokens": [
          50414,
          876,
          11,
          1310,
          498,
          286,
          445,
          764,
          309,
          966,
          11,
          286,
          1116,
          312,
          2489,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20602387967317,
        "compression_ratio": 1.2222222222222223,
        "end": 6332,
        "id": 1704,
        "no_speech_prob": 0.3737924098968506,
        "seek": 631600,
        "start": 6317,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          50414,
          961,
          311,
          853,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20602387967317,
        "compression_ratio": 1.2222222222222223,
        "end": 6336,
        "id": 1705,
        "no_speech_prob": 0.3737924098968506,
        "seek": 631600,
        "start": 6332,
        "temperature": 0,
        "text": " Yeah, that's the same thing I was running before.",
        "tokens": [
          51164,
          865,
          11,
          300,
          311,
          264,
          912,
          551,
          286,
          390,
          2614,
          949,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20602387967317,
        "compression_ratio": 1.2222222222222223,
        "end": 6339,
        "id": 1706,
        "no_speech_prob": 0.3737924098968506,
        "seek": 631600,
        "start": 6336,
        "temperature": 0,
        "text": " Create an access token.",
        "tokens": [
          51364,
          20248,
          364,
          2105,
          14862,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20602387967317,
        "compression_ratio": 1.2222222222222223,
        "end": 6340,
        "id": 1707,
        "no_speech_prob": 0.3737924098968506,
        "seek": 631600,
        "start": 6339,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          51514,
          3153,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20602387967317,
        "compression_ratio": 1.2222222222222223,
        "end": 6343,
        "id": 1708,
        "no_speech_prob": 0.3737924098968506,
        "seek": 631600,
        "start": 6340,
        "temperature": 0,
        "text": " Oh, someone probably wrote in the comments here.",
        "tokens": [
          51564,
          876,
          11,
          1580,
          1391,
          4114,
          294,
          264,
          3053,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19440377200091327,
        "compression_ratio": 1.26890756302521,
        "end": 6344,
        "id": 1709,
        "no_speech_prob": 0.16663922369480133,
        "seek": 634300,
        "start": 6343,
        "temperature": 0,
        "text": " What's the error that I'm getting again?",
        "tokens": [
          50364,
          708,
          311,
          264,
          6713,
          300,
          286,
          478,
          1242,
          797,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.19440377200091327,
        "compression_ratio": 1.26890756302521,
        "end": 6348,
        "id": 1710,
        "no_speech_prob": 0.16663922369480133,
        "seek": 634300,
        "start": 6344,
        "temperature": 0,
        "text": " Permission denied.",
        "tokens": [
          50414,
          41006,
          3106,
          17774,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19440377200091327,
        "compression_ratio": 1.26890756302521,
        "end": 6356,
        "id": 1711,
        "no_speech_prob": 0.16663922369480133,
        "seek": 634300,
        "start": 6348,
        "temperature": 0,
        "text": " What did I do wrong?",
        "tokens": [
          50614,
          708,
          630,
          286,
          360,
          2085,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.19440377200091327,
        "compression_ratio": 1.26890756302521,
        "end": 6357,
        "id": 1712,
        "no_speech_prob": 0.16663922369480133,
        "seek": 634300,
        "start": 6356,
        "temperature": 0,
        "text": " I kind of want to uninstall.",
        "tokens": [
          51014,
          286,
          733,
          295,
          528,
          281,
          517,
          40166,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19440377200091327,
        "compression_ratio": 1.26890756302521,
        "end": 6364,
        "id": 1713,
        "no_speech_prob": 0.16663922369480133,
        "seek": 634300,
        "start": 6357,
        "temperature": 0,
        "text": " Okay, how do I uninstall home brew?",
        "tokens": [
          51064,
          1033,
          11,
          577,
          360,
          286,
          517,
          40166,
          1280,
          34619,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.19440377200091327,
        "compression_ratio": 1.26890756302521,
        "end": 6369,
        "id": 1714,
        "no_speech_prob": 0.16663922369480133,
        "seek": 634300,
        "start": 6364,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6373,
        "id": 1715,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6370,
        "temperature": 0,
        "text": " Let's uninstall.",
        "tokens": [
          50414,
          961,
          311,
          517,
          40166,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6377,
        "id": 1716,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6373,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          50564,
          961,
          311,
          360,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6379,
        "id": 1717,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6377,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50764,
          45263,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6384,
        "id": 1718,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6379,
        "temperature": 0,
        "text": " Yes, yes.",
        "tokens": [
          50864,
          1079,
          11,
          2086,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6388,
        "id": 1719,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6384,
        "temperature": 0,
        "text": " Permission denied.",
        "tokens": [
          51114,
          41006,
          3106,
          17774,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6389,
        "id": 1720,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6388,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51314,
          876,
          11,
          452,
          8387,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2715894848692651,
        "compression_ratio": 1.5777777777777777,
        "end": 6397,
        "id": 1721,
        "no_speech_prob": 0.290833979845047,
        "seek": 636900,
        "start": 6389,
        "temperature": 0,
        "text": " Permission denied, permission denied, permission denied.",
        "tokens": [
          51364,
          41006,
          3106,
          17774,
          11,
          11226,
          17774,
          11,
          11226,
          17774,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6403,
        "id": 1722,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6397,
        "temperature": 0,
        "text": " This is loads of fun.",
        "tokens": [
          50364,
          639,
          307,
          12668,
          295,
          1019,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6405,
        "id": 1723,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6403,
        "temperature": 0,
        "text": " All right, brew update.",
        "tokens": [
          50664,
          1057,
          558,
          11,
          34619,
          5623,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6407,
        "id": 1724,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6405,
        "temperature": 0,
        "text": " Oh, yay.",
        "tokens": [
          50764,
          876,
          11,
          23986,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6408,
        "id": 1725,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6407,
        "temperature": 0,
        "text": " Okay, I don't have it anymore.",
        "tokens": [
          50864,
          1033,
          11,
          286,
          500,
          380,
          362,
          309,
          3602,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6410,
        "id": 1726,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6408,
        "temperature": 0,
        "text": " That's good.",
        "tokens": [
          50914,
          663,
          311,
          665,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6411,
        "id": 1727,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6410,
        "temperature": 0,
        "text": " Brew cleanup.",
        "tokens": [
          51014,
          42906,
          40991,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6413,
        "id": 1728,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6411,
        "temperature": 0,
        "text": " Oh, yeah, I don't have it anymore.",
        "tokens": [
          51064,
          876,
          11,
          1338,
          11,
          286,
          500,
          380,
          362,
          309,
          3602,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6415,
        "id": 1729,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6413,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2823723624734318,
        "compression_ratio": 1.3781512605042017,
        "end": 6426,
        "id": 1730,
        "no_speech_prob": 0.040838632732629776,
        "seek": 639700,
        "start": 6415,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51264,
          1057,
          558,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2688351313273112,
        "compression_ratio": 0.9178082191780822,
        "end": 6429,
        "id": 1731,
        "no_speech_prob": 0.032098326832056046,
        "seek": 642600,
        "start": 6427,
        "temperature": 0,
        "text": " Oh, yay.",
        "tokens": [
          50414,
          876,
          11,
          23986,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2688351313273112,
        "compression_ratio": 0.9178082191780822,
        "end": 6435,
        "id": 1732,
        "no_speech_prob": 0.032098326832056046,
        "seek": 642600,
        "start": 6429,
        "temperature": 0,
        "text": " Okay, we're in business now.",
        "tokens": [
          50514,
          1033,
          11,
          321,
          434,
          294,
          1606,
          586,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2688351313273112,
        "compression_ratio": 0.9178082191780822,
        "end": 6442,
        "id": 1733,
        "no_speech_prob": 0.032098326832056046,
        "seek": 642600,
        "start": 6435,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          50814,
          2492,
          322,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2688351313273112,
        "compression_ratio": 0.9178082191780822,
        "end": 6449,
        "id": 1734,
        "no_speech_prob": 0.032098326832056046,
        "seek": 642600,
        "start": 6442,
        "temperature": 0,
        "text": " Why was this denied?",
        "tokens": [
          51164,
          1545,
          390,
          341,
          17774,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.33636483550071716,
        "compression_ratio": 0.9565217391304348,
        "end": 6461,
        "id": 1735,
        "no_speech_prob": 0.8962482810020447,
        "seek": 644900,
        "start": 6450,
        "temperature": 0,
        "text": " Oops, no, no, no.",
        "tokens": [
          50414,
          21726,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.33636483550071716,
        "compression_ratio": 0.9565217391304348,
        "end": 6478,
        "id": 1736,
        "no_speech_prob": 0.8962482810020447,
        "seek": 644900,
        "start": 6461,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50964,
          1545,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.22665799004690987,
        "compression_ratio": 1.1170212765957446,
        "end": 6492,
        "id": 1737,
        "no_speech_prob": 0.15197718143463135,
        "seek": 647800,
        "start": 6478,
        "temperature": 0,
        "text": " Oh, yeah, this is definitely going to do it.",
        "tokens": [
          50364,
          876,
          11,
          1338,
          11,
          341,
          307,
          2138,
          516,
          281,
          360,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22665799004690987,
        "compression_ratio": 1.1170212765957446,
        "end": 6497,
        "id": 1738,
        "no_speech_prob": 0.15197718143463135,
        "seek": 647800,
        "start": 6492,
        "temperature": 0,
        "text": " This is the solution to all my problems.",
        "tokens": [
          51064,
          639,
          307,
          264,
          3827,
          281,
          439,
          452,
          2740,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22665799004690987,
        "compression_ratio": 1.1170212765957446,
        "end": 6498,
        "id": 1739,
        "no_speech_prob": 0.15197718143463135,
        "seek": 647800,
        "start": 6497,
        "temperature": 0,
        "text": " Yeah, can you hear?",
        "tokens": [
          51314,
          865,
          11,
          393,
          291,
          1568,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.21004689258077872,
        "compression_ratio": 0.896551724137931,
        "end": 6516,
        "id": 1740,
        "no_speech_prob": 0.3072858154773712,
        "seek": 649800,
        "start": 6499,
        "temperature": 0,
        "text": " It's not installed yet.",
        "tokens": [
          50414,
          467,
          311,
          406,
          8899,
          1939,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21004689258077872,
        "compression_ratio": 0.896551724137931,
        "end": 6519,
        "id": 1741,
        "no_speech_prob": 0.3072858154773712,
        "seek": 649800,
        "start": 6516,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          51264,
          865,
          11,
          1392,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21004689258077872,
        "compression_ratio": 0.896551724137931,
        "end": 6525,
        "id": 1742,
        "no_speech_prob": 0.3072858154773712,
        "seek": 649800,
        "start": 6519,
        "temperature": 0,
        "text": " Oh, my goodness.",
        "tokens": [
          51414,
          876,
          11,
          452,
          8387,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6529,
        "id": 1743,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6525,
        "temperature": 0,
        "text": " Well, if I got rid of home brew, can I use RVM now?",
        "tokens": [
          50364,
          1042,
          11,
          498,
          286,
          658,
          3973,
          295,
          1280,
          34619,
          11,
          393,
          286,
          764,
          28314,
          44,
          586,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6531,
        "id": 1744,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6529,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50564,
          865,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6533,
        "id": 1745,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6531,
        "temperature": 0,
        "text": " Does it need home brew?",
        "tokens": [
          50664,
          4402,
          309,
          643,
          1280,
          34619,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6538,
        "id": 1746,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6533,
        "temperature": 0,
        "text": " RVM install 2.2.5, that's all I wanted to do.",
        "tokens": [
          50764,
          28314,
          44,
          3625,
          568,
          13,
          17,
          13,
          20,
          11,
          300,
          311,
          439,
          286,
          1415,
          281,
          360,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6541,
        "id": 1747,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6538,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51014,
          876,
          11,
          574,
          412,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6549,
        "id": 1748,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6541,
        "temperature": 0,
        "text": " About to install home brew.",
        "tokens": [
          51164,
          7769,
          281,
          3625,
          1280,
          34619,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15400039986388325,
        "compression_ratio": 1.318840579710145,
        "end": 6553,
        "id": 1749,
        "no_speech_prob": 0.2043122798204422,
        "seek": 652500,
        "start": 6549,
        "temperature": 0,
        "text": " Restart.",
        "tokens": [
          51564,
          13094,
          446,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.32350892287034255,
        "compression_ratio": 1.2578125,
        "end": 6556,
        "id": 1750,
        "no_speech_prob": 0.06096974387764931,
        "seek": 655300,
        "start": 6553,
        "temperature": 0,
        "text": " It's totally not going to work, but all right.",
        "tokens": [
          50364,
          467,
          311,
          3879,
          406,
          516,
          281,
          589,
          11,
          457,
          439,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.32350892287034255,
        "compression_ratio": 1.2578125,
        "end": 6559,
        "id": 1751,
        "no_speech_prob": 0.06096974387764931,
        "seek": 655300,
        "start": 6556,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          50514,
          876,
          11,
          574,
          412,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.32350892287034255,
        "compression_ratio": 1.2578125,
        "end": 6575,
        "id": 1752,
        "no_speech_prob": 0.06096974387764931,
        "seek": 655300,
        "start": 6559,
        "temperature": 0,
        "text": " This is promising.",
        "tokens": [
          50664,
          639,
          307,
          20257,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.32350892287034255,
        "compression_ratio": 1.2578125,
        "end": 6578,
        "id": 1753,
        "no_speech_prob": 0.06096974387764931,
        "seek": 655300,
        "start": 6575,
        "temperature": 0,
        "text": " It would be nice to have Jekyll working because if I own Jekyll another time,",
        "tokens": [
          51464,
          467,
          576,
          312,
          1481,
          281,
          362,
          508,
          916,
          34353,
          1364,
          570,
          498,
          286,
          1065,
          508,
          916,
          34353,
          1071,
          565,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.41007741292317706,
        "compression_ratio": 1.3434343434343434,
        "end": 6581,
        "id": 1754,
        "no_speech_prob": 0.10374030470848083,
        "seek": 657800,
        "start": 6579,
        "temperature": 0,
        "text": " I'm going to be confused.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          312,
          9019,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.41007741292317706,
        "compression_ratio": 1.3434343434343434,
        "end": 6595,
        "id": 1755,
        "no_speech_prob": 0.10374030470848083,
        "seek": 657800,
        "start": 6581,
        "temperature": 0,
        "text": " Woo, woo.",
        "tokens": [
          50514,
          10468,
          11,
          21657,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.41007741292317706,
        "compression_ratio": 1.3434343434343434,
        "end": 6596,
        "id": 1756,
        "no_speech_prob": 0.10374030470848083,
        "seek": 657800,
        "start": 6595,
        "temperature": 0,
        "text": " Oh, it's pouring it.",
        "tokens": [
          51214,
          876,
          11,
          309,
          311,
          20450,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.41007741292317706,
        "compression_ratio": 1.3434343434343434,
        "end": 6598,
        "id": 1757,
        "no_speech_prob": 0.10374030470848083,
        "seek": 657800,
        "start": 6596,
        "temperature": 0,
        "text": " Oh, pouring it.",
        "tokens": [
          51264,
          876,
          11,
          20450,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.41007741292317706,
        "compression_ratio": 1.3434343434343434,
        "end": 6600,
        "id": 1758,
        "no_speech_prob": 0.10374030470848083,
        "seek": 657800,
        "start": 6598,
        "temperature": 0,
        "text": " Let me just pour.",
        "tokens": [
          51364,
          961,
          385,
          445,
          2016,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.41007741292317706,
        "compression_ratio": 1.3434343434343434,
        "end": 6602,
        "id": 1759,
        "no_speech_prob": 0.10374030470848083,
        "seek": 657800,
        "start": 6600,
        "temperature": 0,
        "text": " I'm going to pour a little bit of that on.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          2016,
          257,
          707,
          857,
          295,
          300,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.530895016410134,
        "compression_ratio": 1.037037037037037,
        "end": 6605,
        "id": 1760,
        "no_speech_prob": 0.9363423585891724,
        "seek": 660200,
        "start": 6602,
        "temperature": 0,
        "text": " It's coming out, coming out.",
        "tokens": [
          50414,
          467,
          311,
          1348,
          484,
          11,
          1348,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3785021901130676,
        "compression_ratio": 0.5789473684210527,
        "end": 6655,
        "id": 1761,
        "no_speech_prob": 0.05581936240196228,
        "seek": 663200,
        "start": 6633,
        "temperature": 0,
        "text": " Extracting.",
        "tokens": [
          50414,
          9881,
          1897,
          278,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3958159593435434,
        "compression_ratio": 0.8222222222222222,
        "end": 6657,
        "id": 1762,
        "no_speech_prob": 0.7820858955383301,
        "seek": 665500,
        "start": 6655,
        "temperature": 0,
        "text": " Do you guys mind if I check my email?",
        "tokens": [
          50414,
          1144,
          291,
          1074,
          1575,
          498,
          286,
          1520,
          452,
          3796,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.4066005119910607,
        "compression_ratio": 0.84,
        "end": 6699,
        "id": 1763,
        "no_speech_prob": 0.3700580894947052,
        "seek": 668500,
        "start": 6686,
        "temperature": 0,
        "text": " I was totally just reading my email there.",
        "tokens": [
          50414,
          286,
          390,
          3879,
          445,
          3760,
          452,
          3796,
          456,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2600455100719745,
        "compression_ratio": 0.8333333333333334,
        "end": 6726,
        "id": 1764,
        "no_speech_prob": 0.4412427544593811,
        "seek": 669900,
        "start": 6700,
        "temperature": 0,
        "text": " I forgot that I was even live streaming.",
        "tokens": [
          50414,
          286,
          5298,
          300,
          286,
          390,
          754,
          1621,
          11791,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21804071426391602,
        "compression_ratio": 0.9166666666666666,
        "end": 6730,
        "id": 1765,
        "no_speech_prob": 0.1112113669514656,
        "seek": 672600,
        "start": 6727,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21804071426391602,
        "compression_ratio": 0.9166666666666666,
        "end": 6734,
        "id": 1766,
        "no_speech_prob": 0.1112113669514656,
        "seek": 672600,
        "start": 6730,
        "temperature": 0,
        "text": " Wow.",
        "tokens": [
          50564,
          3153,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21804071426391602,
        "compression_ratio": 0.9166666666666666,
        "end": 6755,
        "id": 1767,
        "no_speech_prob": 0.1112113669514656,
        "seek": 672600,
        "start": 6734,
        "temperature": 0,
        "text": " As MPJ would say, this is authentic programmer waiting.",
        "tokens": [
          50764,
          1018,
          220,
          12224,
          41,
          576,
          584,
          11,
          341,
          307,
          12466,
          32116,
          3806,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6760,
        "id": 1768,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6755,
        "temperature": 0,
        "text": " I wish I had some coffee.",
        "tokens": [
          50364,
          286,
          3172,
          286,
          632,
          512,
          4982,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6766,
        "id": 1769,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6760,
        "temperature": 0,
        "text": " Coffee would be so good right now.",
        "tokens": [
          50614,
          25481,
          576,
          312,
          370,
          665,
          558,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6768,
        "id": 1770,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6766,
        "temperature": 0,
        "text": " Okay, I finished.",
        "tokens": [
          50914,
          1033,
          11,
          286,
          4335,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6770,
        "id": 1771,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6768,
        "temperature": 0,
        "text": " I don't even know what I'm doing anymore.",
        "tokens": [
          51014,
          286,
          500,
          380,
          754,
          458,
          437,
          286,
          478,
          884,
          3602,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6775,
        "id": 1772,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6770,
        "temperature": 0,
        "text": " So now RVM use, I think I say 2.",
        "tokens": [
          51114,
          407,
          586,
          28314,
          44,
          764,
          11,
          286,
          519,
          286,
          584,
          568,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6778,
        "id": 1773,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6775,
        "temperature": 0,
        "text": " If I wanted to like, I want to use that version.",
        "tokens": [
          51364,
          759,
          286,
          1415,
          281,
          411,
          11,
          286,
          528,
          281,
          764,
          300,
          3037,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6780,
        "id": 1774,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6778,
        "temperature": 0,
        "text": " Now I'm using that version.",
        "tokens": [
          51514,
          823,
          286,
          478,
          1228,
          300,
          3037,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23088708084620788,
        "compression_ratio": 1.4853801169590644,
        "end": 6782,
        "id": 1775,
        "no_speech_prob": 0.16023826599121094,
        "seek": 675500,
        "start": 6780,
        "temperature": 0,
        "text": " Okay, good, good, good.",
        "tokens": [
          51614,
          1033,
          11,
          665,
          11,
          665,
          11,
          665,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2605738162994385,
        "compression_ratio": 1.0389610389610389,
        "end": 6786,
        "id": 1776,
        "no_speech_prob": 0.4646156430244446,
        "seek": 678200,
        "start": 6782,
        "temperature": 0,
        "text": " Now let's go back to Jekyll.",
        "tokens": [
          50364,
          823,
          718,
          311,
          352,
          646,
          281,
          508,
          916,
          34353,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2605738162994385,
        "compression_ratio": 1.0389610389610389,
        "end": 6791,
        "id": 1777,
        "no_speech_prob": 0.4646156430244446,
        "seek": 678200,
        "start": 6786,
        "temperature": 0,
        "text": " I should be able to say gem install Jekyll bundler.",
        "tokens": [
          50564,
          286,
          820,
          312,
          1075,
          281,
          584,
          7173,
          3625,
          508,
          916,
          34353,
          13882,
          1918,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.5355639457702637,
        "compression_ratio": 0.3333333333333333,
        "end": 6794,
        "id": 1778,
        "no_speech_prob": 0.8419978022575378,
        "seek": 679100,
        "start": 6791,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50414,
          400,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21159846442086355,
        "compression_ratio": 1.2109375,
        "end": 6824,
        "id": 1779,
        "no_speech_prob": 0.22262929379940033,
        "seek": 682100,
        "start": 6822,
        "temperature": 0,
        "text": " Ruby 2.2.5 is old.",
        "tokens": [
          50414,
          19907,
          568,
          13,
          17,
          13,
          20,
          307,
          1331,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21159846442086355,
        "compression_ratio": 1.2109375,
        "end": 6834,
        "id": 1780,
        "no_speech_prob": 0.22262929379940033,
        "seek": 682100,
        "start": 6824,
        "temperature": 0,
        "text": " Should I be using a more current one?",
        "tokens": [
          50514,
          6454,
          286,
          312,
          1228,
          257,
          544,
          2190,
          472,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.21159846442086355,
        "compression_ratio": 1.2109375,
        "end": 6840,
        "id": 1781,
        "no_speech_prob": 0.22262929379940033,
        "seek": 682100,
        "start": 6834,
        "temperature": 0,
        "text": " Well, why did I say 2.2.5?",
        "tokens": [
          51014,
          1042,
          11,
          983,
          630,
          286,
          584,
          568,
          13,
          17,
          13,
          20,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.21159846442086355,
        "compression_ratio": 1.2109375,
        "end": 6846,
        "id": 1782,
        "no_speech_prob": 0.22262929379940033,
        "seek": 682100,
        "start": 6840,
        "temperature": 0,
        "text": " Wow, I probably have no room left on this computer's hard drive either.",
        "tokens": [
          51314,
          3153,
          11,
          286,
          1391,
          362,
          572,
          1808,
          1411,
          322,
          341,
          3820,
          311,
          1152,
          3332,
          2139,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2653177160965769,
        "compression_ratio": 1.2950819672131149,
        "end": 6861,
        "id": 1783,
        "no_speech_prob": 0.2364460527896881,
        "seek": 684600,
        "start": 6847,
        "temperature": 0,
        "text": " I'm expecting this just to like.",
        "tokens": [
          50414,
          286,
          478,
          9650,
          341,
          445,
          281,
          411,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2653177160965769,
        "compression_ratio": 1.2950819672131149,
        "end": 6863,
        "id": 1784,
        "no_speech_prob": 0.2364460527896881,
        "seek": 684600,
        "start": 6861,
        "temperature": 0,
        "text": " Oh, it was the minimum.",
        "tokens": [
          51114,
          876,
          11,
          309,
          390,
          264,
          7285,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2653177160965769,
        "compression_ratio": 1.2950819672131149,
        "end": 6865,
        "id": 1785,
        "no_speech_prob": 0.2364460527896881,
        "seek": 684600,
        "start": 6863,
        "temperature": 0,
        "text": " Should I really go and install it?",
        "tokens": [
          51214,
          6454,
          286,
          534,
          352,
          293,
          3625,
          309,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.2653177160965769,
        "compression_ratio": 1.2950819672131149,
        "end": 6867,
        "id": 1786,
        "no_speech_prob": 0.2364460527896881,
        "seek": 684600,
        "start": 6865,
        "temperature": 0,
        "text": " That was the minimum.",
        "tokens": [
          51314,
          663,
          390,
          264,
          7285,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2653177160965769,
        "compression_ratio": 1.2950819672131149,
        "end": 6869,
        "id": 1787,
        "no_speech_prob": 0.2364460527896881,
        "seek": 684600,
        "start": 6867,
        "temperature": 0,
        "text": " Oh, wait, okay.",
        "tokens": [
          51414,
          876,
          11,
          1699,
          11,
          1392,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2653177160965769,
        "compression_ratio": 1.2950819672131149,
        "end": 6871,
        "id": 1788,
        "no_speech_prob": 0.2364460527896881,
        "seek": 684600,
        "start": 6869,
        "temperature": 0,
        "text": " Well, let's see if it works.",
        "tokens": [
          51514,
          1042,
          11,
          718,
          311,
          536,
          498,
          309,
          1985,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2096789829314701,
        "compression_ratio": 1.3642384105960266,
        "end": 6877,
        "id": 1789,
        "no_speech_prob": 0.09670040756464005,
        "seek": 687100,
        "start": 6871,
        "temperature": 0,
        "text": " Does it finish now?",
        "tokens": [
          50364,
          4402,
          309,
          2413,
          586,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2096789829314701,
        "compression_ratio": 1.3642384105960266,
        "end": 6882,
        "id": 1790,
        "no_speech_prob": 0.09670040756464005,
        "seek": 687100,
        "start": 6877,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2096789829314701,
        "compression_ratio": 1.3642384105960266,
        "end": 6886,
        "id": 1791,
        "no_speech_prob": 0.09670040756464005,
        "seek": 687100,
        "start": 6882,
        "temperature": 0,
        "text": " And what was it called?",
        "tokens": [
          50914,
          400,
          437,
          390,
          309,
          1219,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.2096789829314701,
        "compression_ratio": 1.3642384105960266,
        "end": 6893,
        "id": 1792,
        "no_speech_prob": 0.09670040756464005,
        "seek": 687100,
        "start": 6886,
        "temperature": 0,
        "text": " So, okay, so what I should be able to do now is say bundle exec Jekyll serve.",
        "tokens": [
          51114,
          407,
          11,
          1392,
          11,
          370,
          437,
          286,
          820,
          312,
          1075,
          281,
          360,
          586,
          307,
          584,
          24438,
          4454,
          508,
          916,
          34353,
          4596,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2096789829314701,
        "compression_ratio": 1.3642384105960266,
        "end": 6899,
        "id": 1793,
        "no_speech_prob": 0.09670040756464005,
        "seek": 687100,
        "start": 6893,
        "temperature": 0,
        "text": " So if I am in this repository, this is now the coding train website repository",
        "tokens": [
          51464,
          407,
          498,
          286,
          669,
          294,
          341,
          25841,
          11,
          341,
          307,
          586,
          264,
          17720,
          3847,
          3144,
          25841,
          51764
        ]
      },
      {
        "avg_logprob": -0.19383659768611827,
        "compression_ratio": 1.2612612612612613,
        "end": 6901,
        "id": 1794,
        "no_speech_prob": 0.4414924681186676,
        "seek": 689900,
        "start": 6899,
        "temperature": 0,
        "text": " cloned locally to this computer.",
        "tokens": [
          50364,
          596,
          19009,
          16143,
          281,
          341,
          3820,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19383659768611827,
        "compression_ratio": 1.2612612612612613,
        "end": 6905,
        "id": 1795,
        "no_speech_prob": 0.4414924681186676,
        "seek": 689900,
        "start": 6901,
        "temperature": 0,
        "text": " If I say bundle exec Jekyll serve.",
        "tokens": [
          50464,
          759,
          286,
          584,
          24438,
          4454,
          508,
          916,
          34353,
          4596,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19383659768611827,
        "compression_ratio": 1.2612612612612613,
        "end": 6906,
        "id": 1796,
        "no_speech_prob": 0.4414924681186676,
        "seek": 689900,
        "start": 6905,
        "temperature": 0,
        "text": " Oh, bundle install.",
        "tokens": [
          50664,
          876,
          11,
          24438,
          3625,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19383659768611827,
        "compression_ratio": 1.2612612612612613,
        "end": 6907,
        "id": 1797,
        "no_speech_prob": 0.4414924681186676,
        "seek": 689900,
        "start": 6906,
        "temperature": 0,
        "text": " I have to install all the gems.",
        "tokens": [
          50714,
          286,
          362,
          281,
          3625,
          439,
          264,
          29296,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19383659768611827,
        "compression_ratio": 1.2612612612612613,
        "end": 6911,
        "id": 1798,
        "no_speech_prob": 0.4414924681186676,
        "seek": 689900,
        "start": 6907,
        "temperature": 0,
        "text": " I forgot about that.",
        "tokens": [
          50764,
          286,
          5298,
          466,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.4313705563545227,
        "compression_ratio": 0.6521739130434783,
        "end": 6914,
        "id": 1799,
        "no_speech_prob": 0.7449517846107483,
        "seek": 691100,
        "start": 6911,
        "temperature": 0,
        "text": " And we're back.",
        "tokens": [
          50414,
          400,
          321,
          434,
          646,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.9460168838500976,
        "compression_ratio": 0.38461538461538464,
        "end": 6950,
        "id": 1800,
        "no_speech_prob": 0.919916570186615,
        "seek": 694100,
        "start": 6941,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2375551928644595,
        "compression_ratio": 1.1262135922330097,
        "end": 6973,
        "id": 1801,
        "no_speech_prob": 0.1347261369228363,
        "seek": 697100,
        "start": 6972,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          50414,
          2305,
          669,
          286,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2375551928644595,
        "compression_ratio": 1.1262135922330097,
        "end": 6979,
        "id": 1802,
        "no_speech_prob": 0.1347261369228363,
        "seek": 697100,
        "start": 6973,
        "temperature": 0,
        "text": " What year is it?",
        "tokens": [
          50464,
          708,
          1064,
          307,
          309,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2375551928644595,
        "compression_ratio": 1.1262135922330097,
        "end": 6985,
        "id": 1803,
        "no_speech_prob": 0.1347261369228363,
        "seek": 697100,
        "start": 6979,
        "temperature": 0,
        "text": " Am I still installing Nokogiri?",
        "tokens": [
          50764,
          2012,
          286,
          920,
          20762,
          37400,
          664,
          12988,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2375551928644595,
        "compression_ratio": 1.1262135922330097,
        "end": 6995,
        "id": 1804,
        "no_speech_prob": 0.1347261369228363,
        "seek": 697100,
        "start": 6985,
        "temperature": 0,
        "text": " Control L.",
        "tokens": [
          51064,
          12912,
          441,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2375551928644595,
        "compression_ratio": 1.1262135922330097,
        "end": 6996,
        "id": 1805,
        "no_speech_prob": 0.1347261369228363,
        "seek": 697100,
        "start": 6995,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51564,
          821,
          321,
          352,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2375551928644595,
        "compression_ratio": 1.1262135922330097,
        "end": 6998,
        "id": 1806,
        "no_speech_prob": 0.1347261369228363,
        "seek": 697100,
        "start": 6996,
        "temperature": 0,
        "text": " Control L, thank you very much.",
        "tokens": [
          51614,
          12912,
          441,
          11,
          1309,
          291,
          588,
          709,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7011,
        "id": 1807,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 6999,
        "temperature": 0,
        "text": " Let's try this again.",
        "tokens": [
          50414,
          961,
          311,
          853,
          341,
          797,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7012,
        "id": 1808,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7011,
        "temperature": 0,
        "text": " Amazing.",
        "tokens": [
          51014,
          14165,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7014,
        "id": 1809,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7012,
        "temperature": 0,
        "text": " Amazing.",
        "tokens": [
          51064,
          14165,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7018,
        "id": 1810,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7014,
        "temperature": 0,
        "text": " Amazing.",
        "tokens": [
          51164,
          14165,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7020,
        "id": 1811,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7018,
        "temperature": 0,
        "text": " It still hasn't built yet though.",
        "tokens": [
          51364,
          467,
          920,
          6132,
          380,
          3094,
          1939,
          1673,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7023,
        "id": 1812,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7020,
        "temperature": 0,
        "text": " It's a big site with a lot of stuff.",
        "tokens": [
          51464,
          467,
          311,
          257,
          955,
          3621,
          365,
          257,
          688,
          295,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7025,
        "id": 1813,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7023,
        "temperature": 0,
        "text": " Very soon it will have built.",
        "tokens": [
          51614,
          4372,
          2321,
          309,
          486,
          362,
          3094,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18141058286031086,
        "compression_ratio": 1.361344537815126,
        "end": 7026,
        "id": 1814,
        "no_speech_prob": 0.08754904568195343,
        "seek": 699800,
        "start": 7025,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51714,
          821,
          321,
          352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7028,
        "id": 1815,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7026,
        "temperature": 0,
        "text": " So the server is now running.",
        "tokens": [
          50364,
          407,
          264,
          7154,
          307,
          586,
          2614,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7030,
        "id": 1816,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7028,
        "temperature": 0,
        "text": " So I can now grab this.",
        "tokens": [
          50464,
          407,
          286,
          393,
          586,
          4444,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7033,
        "id": 1817,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7030,
        "temperature": 0,
        "text": " And I can go to the browser.",
        "tokens": [
          50564,
          400,
          286,
          393,
          352,
          281,
          264,
          11185,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7036,
        "id": 1818,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7033,
        "temperature": 0,
        "text": " And we can see here is the coding train website.",
        "tokens": [
          50714,
          400,
          321,
          393,
          536,
          510,
          307,
          264,
          17720,
          3847,
          3144,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7040,
        "id": 1819,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7036,
        "temperature": 0,
        "text": " And now here is the card which now has the upcoming live stream.",
        "tokens": [
          50864,
          400,
          586,
          510,
          307,
          264,
          2920,
          597,
          586,
          575,
          264,
          11500,
          1621,
          4309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7045,
        "id": 1820,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7040,
        "temperature": 0,
        "text": " So now what I can do is I can be a bit more diligent about this.",
        "tokens": [
          51064,
          407,
          586,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          312,
          257,
          857,
          544,
          50251,
          466,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7048,
        "id": 1821,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7045,
        "temperature": 0,
        "text": " And I can actually just try editing all this stuff locally.",
        "tokens": [
          51314,
          400,
          286,
          393,
          767,
          445,
          853,
          10000,
          439,
          341,
          1507,
          16143,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18081355977941443,
        "compression_ratio": 1.8086124401913874,
        "end": 7054,
        "id": 1822,
        "no_speech_prob": 0.39217546582221985,
        "seek": 702600,
        "start": 7048,
        "temperature": 0,
        "text": " So I want to go to streams and upcoming live stream 119.",
        "tokens": [
          51464,
          407,
          286,
          528,
          281,
          352,
          281,
          15842,
          293,
          11500,
          1621,
          4309,
          2975,
          24,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7056,
        "id": 1823,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7054,
        "temperature": 0,
        "text": " And actually what I want to do, let's see.",
        "tokens": [
          50364,
          400,
          767,
          437,
          286,
          528,
          281,
          360,
          11,
          718,
          311,
          536,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7059,
        "id": 1824,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7056,
        "temperature": 0,
        "text": " I'm going to actually take this out.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          767,
          747,
          341,
          484,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7060,
        "id": 1825,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7059,
        "temperature": 0,
        "text": " Put this here.",
        "tokens": [
          50614,
          4935,
          341,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7073,
        "id": 1826,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7060,
        "temperature": 0,
        "text": " And when I hit save, right, we should see that I hit save.",
        "tokens": [
          50664,
          400,
          562,
          286,
          2045,
          3155,
          11,
          558,
          11,
          321,
          820,
          536,
          300,
          286,
          2045,
          3155,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7078,
        "id": 1827,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7073,
        "temperature": 0,
        "text": " It is now going to regenerate because I hit save.",
        "tokens": [
          51314,
          467,
          307,
          586,
          516,
          281,
          26358,
          473,
          570,
          286,
          2045,
          3155,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7080,
        "id": 1828,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7078,
        "temperature": 0,
        "text": " So it's regenerating the site.",
        "tokens": [
          51564,
          407,
          309,
          311,
          26358,
          990,
          264,
          3621,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17719976586031627,
        "compression_ratio": 1.5864197530864197,
        "end": 7083,
        "id": 1829,
        "no_speech_prob": 0.44927793741226196,
        "seek": 705400,
        "start": 7080,
        "temperature": 0,
        "text": " It's not finished yet.",
        "tokens": [
          51664,
          467,
          311,
          406,
          4335,
          1939,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7084,
        "id": 1830,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7083,
        "temperature": 0,
        "text": " And it's done.",
        "tokens": [
          50364,
          400,
          309,
          311,
          1096,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7085,
        "id": 1831,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7084,
        "temperature": 0,
        "text": " It took 11 seconds.",
        "tokens": [
          50414,
          467,
          1890,
          2975,
          3949,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7087,
        "id": 1832,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7085,
        "temperature": 0,
        "text": " And I should be able to refresh now.",
        "tokens": [
          50464,
          400,
          286,
          820,
          312,
          1075,
          281,
          15134,
          586,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7088,
        "id": 1833,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7087,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50564,
          400,
          456,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7090,
        "id": 1834,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7088,
        "temperature": 0,
        "text": " So now you can see, oops, that's there.",
        "tokens": [
          50614,
          407,
          586,
          291,
          393,
          536,
          11,
          34166,
          11,
          300,
          311,
          456,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7091,
        "id": 1835,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7090,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50714,
          1545,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7093,
        "id": 1836,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7091,
        "temperature": 0,
        "text": " Oh, I forgot that I left this stuff in here.",
        "tokens": [
          50764,
          876,
          11,
          286,
          5298,
          300,
          286,
          1411,
          341,
          1507,
          294,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7096,
        "id": 1837,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7093,
        "temperature": 0,
        "text": " So I can get rid of this now.",
        "tokens": [
          50864,
          407,
          286,
          393,
          483,
          3973,
          295,
          341,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7098,
        "id": 1838,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7096,
        "temperature": 0,
        "text": " It was just that line break at the top.",
        "tokens": [
          51014,
          467,
          390,
          445,
          300,
          1622,
          1821,
          412,
          264,
          1192,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7101,
        "id": 1839,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7098,
        "temperature": 0,
        "text": " The whole problem stemmed from the fact that I had that, by the way.",
        "tokens": [
          51114,
          440,
          1379,
          1154,
          12312,
          1912,
          490,
          264,
          1186,
          300,
          286,
          632,
          300,
          11,
          538,
          264,
          636,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7102,
        "id": 1840,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7101,
        "temperature": 0,
        "text": " So now I can do this.",
        "tokens": [
          51264,
          407,
          586,
          286,
          393,
          360,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7107,
        "id": 1841,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7102,
        "temperature": 0,
        "text": " You can see, actually, you can see the syntax highlighting completely disappeared.",
        "tokens": [
          51314,
          509,
          393,
          536,
          11,
          767,
          11,
          291,
          393,
          536,
          264,
          28431,
          26551,
          2584,
          13954,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18886716742264598,
        "compression_ratio": 1.6385135135135136,
        "end": 7112,
        "id": 1842,
        "no_speech_prob": 0.02033124677836895,
        "seek": 708300,
        "start": 7107,
        "temperature": 0,
        "text": " This is YAML which stands for YAML markup language apparently.",
        "tokens": [
          51564,
          639,
          307,
          398,
          2865,
          43,
          597,
          7382,
          337,
          398,
          2865,
          43,
          1491,
          1010,
          2856,
          7970,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7116,
        "id": 1843,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7113,
        "temperature": 0,
        "text": " And our young adult markup language maybe.",
        "tokens": [
          50414,
          400,
          527,
          2037,
          5075,
          1491,
          1010,
          2856,
          1310,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7118,
        "id": 1844,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7116,
        "temperature": 0,
        "text": " I'm not sure what it stands for.",
        "tokens": [
          50564,
          286,
          478,
          406,
          988,
          437,
          309,
          7382,
          337,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7120,
        "id": 1845,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7118,
        "temperature": 0,
        "text": " What else could YAB?",
        "tokens": [
          50664,
          708,
          1646,
          727,
          398,
          13868,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7127,
        "id": 1846,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7123,
        "temperature": 0,
        "text": " Okay, so now we can see this is hopefully now live stream.",
        "tokens": [
          50914,
          1033,
          11,
          370,
          586,
          321,
          393,
          536,
          341,
          307,
          4696,
          586,
          1621,
          4309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7130,
        "id": 1847,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7127,
        "temperature": 0,
        "text": " It still says 4 p.m. because I want this to be 10 a.m.",
        "tokens": [
          51114,
          467,
          920,
          1619,
          1017,
          280,
          13,
          76,
          13,
          570,
          286,
          528,
          341,
          281,
          312,
          1266,
          257,
          13,
          76,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7134,
        "id": 1848,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7130,
        "temperature": 0,
        "text": " Although now I'm wondering, actually, based on my schedule,",
        "tokens": [
          51264,
          5780,
          586,
          286,
          478,
          6359,
          11,
          767,
          11,
          2361,
          322,
          452,
          7567,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7139,
        "id": 1849,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7134,
        "temperature": 0,
        "text": " I thought I saw something in my email about something that had to happen on Friday morning.",
        "tokens": [
          51464,
          286,
          1194,
          286,
          1866,
          746,
          294,
          452,
          3796,
          466,
          746,
          300,
          632,
          281,
          1051,
          322,
          6984,
          2446,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2079258475984846,
        "compression_ratio": 1.4844961240310077,
        "end": 7141,
        "id": 1850,
        "no_speech_prob": 0.08386781066656113,
        "seek": 711200,
        "start": 7139,
        "temperature": 0,
        "text": " So let me look back.",
        "tokens": [
          51714,
          407,
          718,
          385,
          574,
          646,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7145,
        "id": 1851,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7141,
        "temperature": 0,
        "text": " So that might change it, but I'll put it there for now.",
        "tokens": [
          50364,
          407,
          300,
          1062,
          1319,
          309,
          11,
          457,
          286,
          603,
          829,
          309,
          456,
          337,
          586,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7147,
        "id": 1852,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7145,
        "temperature": 0,
        "text": " So and then I can come back here.",
        "tokens": [
          50564,
          407,
          293,
          550,
          286,
          393,
          808,
          646,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7149,
        "id": 1853,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7147,
        "temperature": 0,
        "text": " We can see here it is.",
        "tokens": [
          50664,
          492,
          393,
          536,
          510,
          309,
          307,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7151,
        "id": 1854,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7149,
        "temperature": 0,
        "text": " The upcoming live stream is here.",
        "tokens": [
          50764,
          440,
          11500,
          1621,
          4309,
          307,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7152,
        "id": 1855,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7151,
        "temperature": 0,
        "text": " So you can always check.",
        "tokens": [
          50864,
          407,
          291,
          393,
          1009,
          1520,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7157,
        "id": 1856,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7152,
        "temperature": 0,
        "text": " If I've done my job, you can check the website for the next upcoming live stream.",
        "tokens": [
          50914,
          759,
          286,
          600,
          1096,
          452,
          1691,
          11,
          291,
          393,
          1520,
          264,
          3144,
          337,
          264,
          958,
          11500,
          1621,
          4309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7160,
        "id": 1857,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7157,
        "temperature": 0,
        "text": " And this link should take you to.",
        "tokens": [
          51164,
          400,
          341,
          2113,
          820,
          747,
          291,
          281,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7165,
        "id": 1858,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7162,
        "temperature": 0,
        "text": " And actually it took you here.",
        "tokens": [
          51414,
          400,
          767,
          309,
          1890,
          291,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21381718904069327,
        "compression_ratio": 1.645320197044335,
        "end": 7166,
        "id": 1859,
        "no_speech_prob": 0.0009398896945640445,
        "seek": 714100,
        "start": 7165,
        "temperature": 0,
        "text": " And there I am.",
        "tokens": [
          51564,
          400,
          456,
          286,
          669,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7169,
        "id": 1860,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7166,
        "temperature": 0,
        "text": " But actually it should take you to.",
        "tokens": [
          50364,
          583,
          767,
          309,
          820,
          747,
          291,
          281,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7172,
        "id": 1861,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7169,
        "temperature": 0,
        "text": " Now this should be the URL.",
        "tokens": [
          50514,
          823,
          341,
          820,
          312,
          264,
          12905,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7175,
        "id": 1862,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7173,
        "temperature": 0,
        "text": " Because I have a new.",
        "tokens": [
          50714,
          1436,
          286,
          362,
          257,
          777,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7179,
        "id": 1863,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7175,
        "temperature": 0,
        "text": " I got this new checkmark URL thingy from YouTube.",
        "tokens": [
          50814,
          286,
          658,
          341,
          777,
          1520,
          5638,
          12905,
          551,
          88,
          490,
          3088,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7181,
        "id": 1864,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7180,
        "temperature": 0,
        "text": " And so.",
        "tokens": [
          51064,
          400,
          370,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7185,
        "id": 1865,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7183,
        "temperature": 0,
        "text": " So let's see if we can find where that is.",
        "tokens": [
          51214,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          915,
          689,
          300,
          307,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7188,
        "id": 1866,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7185,
        "temperature": 0,
        "text": " Where in this repo is user slash Shiffman?",
        "tokens": [
          51314,
          2305,
          294,
          341,
          49040,
          307,
          4195,
          17330,
          1160,
          3661,
          1601,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.22821666576244212,
        "compression_ratio": 1.3920454545454546,
        "end": 7192,
        "id": 1867,
        "no_speech_prob": 0.04885370656847954,
        "seek": 716600,
        "start": 7190,
        "temperature": 0,
        "text": " Lots of places.",
        "tokens": [
          51564,
          15908,
          295,
          3190,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7194,
        "id": 1868,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7193,
        "temperature": 0,
        "text": " Video card.",
        "tokens": [
          50414,
          9777,
          2920,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7196,
        "id": 1869,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7194,
        "temperature": 0,
        "text": " It's in the includes.",
        "tokens": [
          50464,
          467,
          311,
          294,
          264,
          5974,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7199,
        "id": 1870,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7196,
        "temperature": 0,
        "text": " Now I don't want it to show.",
        "tokens": [
          50564,
          823,
          286,
          500,
          380,
          528,
          309,
          281,
          855,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7201,
        "id": 1871,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7199,
        "temperature": 0,
        "text": " Oh no, but I don't want.",
        "tokens": [
          50714,
          876,
          572,
          11,
          457,
          286,
          500,
          380,
          528,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7202,
        "id": 1872,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7201,
        "temperature": 0,
        "text": " Where did it render the site?",
        "tokens": [
          50814,
          2305,
          630,
          309,
          15529,
          264,
          3621,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7203,
        "id": 1873,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7202,
        "temperature": 0,
        "text": " Oh, that's hidden.",
        "tokens": [
          50864,
          876,
          11,
          300,
          311,
          7633,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7204,
        "id": 1874,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7203,
        "temperature": 0,
        "text": " Okay, it's already.",
        "tokens": [
          50914,
          1033,
          11,
          309,
          311,
          1217,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7207,
        "id": 1875,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7204,
        "temperature": 0,
        "text": " So I think I want.",
        "tokens": [
          50964,
          407,
          286,
          519,
          286,
          528,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7208,
        "id": 1876,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7207,
        "temperature": 0,
        "text": " Dare I.",
        "tokens": [
          51114,
          42320,
          286,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7210,
        "id": 1877,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7208,
        "temperature": 0,
        "text": " First of all, let's do this.",
        "tokens": [
          51164,
          2386,
          295,
          439,
          11,
          718,
          311,
          360,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7216,
        "id": 1878,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7214,
        "temperature": 0,
        "text": " So let's add this commit.",
        "tokens": [
          51464,
          407,
          718,
          311,
          909,
          341,
          5599,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17737262688794184,
        "compression_ratio": 1.4860335195530727,
        "end": 7220,
        "id": 1879,
        "no_speech_prob": 0.0006070485687814653,
        "seek": 719200,
        "start": 7218,
        "temperature": 0,
        "text": " So this is new live stream.",
        "tokens": [
          51664,
          407,
          341,
          307,
          777,
          1621,
          4309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7225,
        "id": 1880,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7223,
        "temperature": 0,
        "text": " So I've committed that.",
        "tokens": [
          50414,
          407,
          286,
          600,
          7784,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7226,
        "id": 1881,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7225,
        "temperature": 0,
        "text": " Now what I'm going to do.",
        "tokens": [
          50514,
          823,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7228,
        "id": 1882,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7226,
        "temperature": 0,
        "text": " For probably against my better judgment.",
        "tokens": [
          50564,
          1171,
          1391,
          1970,
          452,
          1101,
          12216,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7230,
        "id": 1883,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7228,
        "temperature": 0,
        "text": " Is just replace this with.",
        "tokens": [
          50664,
          1119,
          445,
          7406,
          341,
          365,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7235,
        "id": 1884,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7232,
        "temperature": 0,
        "text": " Now is it silly to put capitals in the URL?",
        "tokens": [
          50864,
          823,
          307,
          309,
          11774,
          281,
          829,
          1410,
          11118,
          294,
          264,
          12905,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7237,
        "id": 1885,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7235,
        "temperature": 0,
        "text": " I don't like how that looks.",
        "tokens": [
          51014,
          286,
          500,
          380,
          411,
          577,
          300,
          1542,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7240,
        "id": 1886,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7237,
        "temperature": 0,
        "text": " Let me just make sure it works.",
        "tokens": [
          51114,
          961,
          385,
          445,
          652,
          988,
          309,
          1985,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7241,
        "id": 1887,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7240,
        "temperature": 0,
        "text": " If I go to.",
        "tokens": [
          51264,
          759,
          286,
          352,
          281,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7245,
        "id": 1888,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7242,
        "temperature": 0,
        "text": " YouTube.com.",
        "tokens": [
          51364,
          3088,
          13,
          1112,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7248,
        "id": 1889,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7245,
        "temperature": 0,
        "text": " The coding train live.",
        "tokens": [
          51514,
          440,
          17720,
          3847,
          1621,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1971487064951474,
        "compression_ratio": 1.4158415841584158,
        "end": 7250,
        "id": 1890,
        "no_speech_prob": 0.0004802797921001911,
        "seek": 722200,
        "start": 7248,
        "temperature": 0,
        "text": " Does that work?",
        "tokens": [
          51664,
          4402,
          300,
          589,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7254,
        "id": 1891,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7251,
        "temperature": 0,
        "text": " Yeah, I feel like I'd rather have it be lowercase.",
        "tokens": [
          50414,
          865,
          11,
          286,
          841,
          411,
          286,
          1116,
          2831,
          362,
          309,
          312,
          3126,
          9765,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7256,
        "id": 1892,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7254,
        "temperature": 0,
        "text": " The capitals kind of freak me out.",
        "tokens": [
          50564,
          440,
          1410,
          11118,
          733,
          295,
          21853,
          385,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7258,
        "id": 1893,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7256,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50664,
          407,
          718,
          311,
          360,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7261,
        "id": 1894,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7259,
        "temperature": 0,
        "text": " So let's change this to.",
        "tokens": [
          50814,
          407,
          718,
          311,
          1319,
          341,
          281,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7265,
        "id": 1895,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7261,
        "temperature": 0,
        "text": " This should be the coding train.",
        "tokens": [
          50914,
          639,
          820,
          312,
          264,
          17720,
          3847,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7268,
        "id": 1896,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7265,
        "temperature": 0,
        "text": " I'm going to change that everywhere it appears.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          1319,
          300,
          5315,
          309,
          7038,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7271,
        "id": 1897,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7269,
        "temperature": 0,
        "text": " Yeah, 11 times all over the place.",
        "tokens": [
          51314,
          865,
          11,
          2975,
          1413,
          439,
          670,
          264,
          1081,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7273,
        "id": 1898,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7271,
        "temperature": 0,
        "text": " How bad could that be?",
        "tokens": [
          51414,
          1012,
          1578,
          727,
          300,
          312,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7276,
        "id": 1899,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7274,
        "temperature": 0,
        "text": " Did I do it?",
        "tokens": [
          51564,
          2589,
          286,
          360,
          309,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1940360406432489,
        "compression_ratio": 1.4527363184079602,
        "end": 7278,
        "id": 1900,
        "no_speech_prob": 0.00015597359742969275,
        "seek": 725000,
        "start": 7276,
        "temperature": 0,
        "text": " Okay, done.",
        "tokens": [
          51664,
          1033,
          11,
          1096,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7280,
        "id": 1901,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7278,
        "temperature": 0,
        "text": " Let's do git status.",
        "tokens": [
          50364,
          961,
          311,
          360,
          18331,
          6558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7283,
        "id": 1902,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7280,
        "temperature": 0,
        "text": " So it got changed in a whole bunch of places.",
        "tokens": [
          50464,
          407,
          309,
          658,
          3105,
          294,
          257,
          1379,
          3840,
          295,
          3190,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7285,
        "id": 1903,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7283,
        "temperature": 0,
        "text": " Which makes sense, I guess.",
        "tokens": [
          50614,
          3013,
          1669,
          2020,
          11,
          286,
          2041,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7295,
        "id": 1904,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7293,
        "temperature": 0,
        "text": " What's in this folder here?",
        "tokens": [
          51114,
          708,
          311,
          294,
          341,
          10820,
          510,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7297,
        "id": 1905,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7295,
        "temperature": 0,
        "text": " Oh, that's the includes in the layouts.",
        "tokens": [
          51214,
          876,
          11,
          300,
          311,
          264,
          5974,
          294,
          264,
          46100,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7298,
        "id": 1906,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7297,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          51314,
          1033,
          11,
          869,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7300,
        "id": 1907,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7298,
        "temperature": 0,
        "text": " Git commit updating.",
        "tokens": [
          51364,
          16939,
          5599,
          25113,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7302,
        "id": 1908,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7300,
        "temperature": 0,
        "text": " To new Jekyll.",
        "tokens": [
          51464,
          1407,
          777,
          508,
          916,
          34353,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4032145000639416,
        "compression_ratio": 1.3555555555555556,
        "end": 7304,
        "id": 1909,
        "no_speech_prob": 0.0028444440104067326,
        "seek": 727800,
        "start": 7302,
        "temperature": 0,
        "text": " I mean, sorry, new command line.",
        "tokens": [
          51564,
          286,
          914,
          11,
          2597,
          11,
          777,
          5622,
          1622,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7306,
        "id": 1910,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7304,
        "temperature": 0,
        "text": " To new Jekyll.",
        "tokens": [
          50364,
          1407,
          777,
          508,
          916,
          34353,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7309,
        "id": 1911,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7306,
        "temperature": 0,
        "text": " I mean, sorry, new coding train URL.",
        "tokens": [
          50464,
          286,
          914,
          11,
          2597,
          11,
          777,
          17720,
          3847,
          12905,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7313,
        "id": 1912,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7311,
        "temperature": 0,
        "text": " And is the website still working?",
        "tokens": [
          50714,
          400,
          307,
          264,
          3144,
          920,
          1364,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7316,
        "id": 1913,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7314,
        "temperature": 0,
        "text": " This takes me to coding train live.",
        "tokens": [
          50864,
          639,
          2516,
          385,
          281,
          17720,
          3847,
          1621,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7318,
        "id": 1914,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7316,
        "temperature": 0,
        "text": " Subscribe on YouTube.",
        "tokens": [
          50964,
          10611,
          322,
          3088,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7319,
        "id": 1915,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7318,
        "temperature": 0,
        "text": " Oh, that's interesting.",
        "tokens": [
          51064,
          876,
          11,
          300,
          311,
          1880,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7322,
        "id": 1916,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7319,
        "temperature": 0,
        "text": " This somehow is still going to.",
        "tokens": [
          51114,
          639,
          6063,
          307,
          920,
          516,
          281,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7327,
        "id": 1917,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7324,
        "temperature": 0,
        "text": " And this should be a button that automatically subscribes you.",
        "tokens": [
          51364,
          400,
          341,
          820,
          312,
          257,
          2960,
          300,
          6772,
          2325,
          6446,
          291,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7328,
        "id": 1918,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7327,
        "temperature": 0,
        "text": " That's not.",
        "tokens": [
          51514,
          663,
          311,
          406,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7330,
        "id": 1919,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7329,
        "temperature": 0,
        "text": " This should really be.",
        "tokens": [
          51614,
          639,
          820,
          534,
          312,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19025216643343268,
        "compression_ratio": 1.6080402010050252,
        "end": 7332,
        "id": 1920,
        "no_speech_prob": 0.020331349223852158,
        "seek": 730400,
        "start": 7331,
        "temperature": 0,
        "text": " This should subscribe.",
        "tokens": [
          51714,
          639,
          820,
          3022,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7335,
        "id": 1921,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7332,
        "temperature": 0,
        "text": " There's a way to have the button automatically subscribe you to the channel.",
        "tokens": [
          50364,
          821,
          311,
          257,
          636,
          281,
          362,
          264,
          2960,
          6772,
          3022,
          291,
          281,
          264,
          2269,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7337,
        "id": 1922,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7335,
        "temperature": 0,
        "text": " Which this is not doing.",
        "tokens": [
          50514,
          3013,
          341,
          307,
          406,
          884,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7339,
        "id": 1923,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7337,
        "temperature": 0,
        "text": " So where is this showing up?",
        "tokens": [
          50614,
          407,
          689,
          307,
          341,
          4099,
          493,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7340,
        "id": 1924,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7339,
        "temperature": 0,
        "text": " Learn to code.",
        "tokens": [
          50714,
          17216,
          281,
          3089,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7342,
        "id": 1925,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7340,
        "temperature": 0,
        "text": " Where is this content?",
        "tokens": [
          50764,
          2305,
          307,
          341,
          2701,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7344,
        "id": 1926,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7342,
        "temperature": 0,
        "text": " Is it on.",
        "tokens": [
          50864,
          1119,
          309,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7349,
        "id": 1927,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7347,
        "temperature": 0,
        "text": " Landing page?",
        "tokens": [
          51114,
          49458,
          3028,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7350,
        "id": 1928,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7349,
        "temperature": 0,
        "text": " Learn to.",
        "tokens": [
          51214,
          17216,
          281,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7352,
        "id": 1929,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7350,
        "temperature": 0,
        "text": " Yeah, there it is.",
        "tokens": [
          51264,
          865,
          11,
          456,
          309,
          307,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7354,
        "id": 1930,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7352,
        "temperature": 0,
        "text": " Oh, site links YouTube.",
        "tokens": [
          51364,
          876,
          11,
          3621,
          6123,
          3088,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7356,
        "id": 1931,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7354,
        "temperature": 0,
        "text": " Ah, okay.",
        "tokens": [
          51464,
          2438,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7358,
        "id": 1932,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7356,
        "temperature": 0,
        "text": " So this is a special case though.",
        "tokens": [
          51564,
          407,
          341,
          307,
          257,
          2121,
          1389,
          1673,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1865361293899679,
        "compression_ratio": 1.5586854460093897,
        "end": 7360,
        "id": 1933,
        "no_speech_prob": 0.005468981806188822,
        "seek": 733200,
        "start": 7358,
        "temperature": 0,
        "text": " Because this should be a subscribe button.",
        "tokens": [
          51664,
          1436,
          341,
          820,
          312,
          257,
          3022,
          2960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7362,
        "id": 1934,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7360,
        "temperature": 0,
        "text": " YouTube channel.",
        "tokens": [
          50364,
          3088,
          2269,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7364,
        "id": 1935,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7362,
        "temperature": 0,
        "text": " I've lost the chat here.",
        "tokens": [
          50464,
          286,
          600,
          2731,
          264,
          5081,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7368,
        "id": 1936,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7367,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50714,
          876,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7370,
        "id": 1937,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7369,
        "temperature": 0,
        "text": " Oh, well.",
        "tokens": [
          50814,
          876,
          11,
          731,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7372,
        "id": 1938,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7370,
        "temperature": 0,
        "text": " Uh-oh, am I going to have double slash?",
        "tokens": [
          50864,
          4019,
          12,
          1445,
          11,
          669,
          286,
          516,
          281,
          362,
          3834,
          17330,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7374,
        "id": 1939,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7372,
        "temperature": 0,
        "text": " Double forward slash.",
        "tokens": [
          50964,
          16633,
          2128,
          17330,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7378,
        "id": 1940,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7374,
        "temperature": 0,
        "text": " 56 new messages since I stopped looking at the chat.",
        "tokens": [
          51064,
          19687,
          777,
          7897,
          1670,
          286,
          5936,
          1237,
          412,
          264,
          5081,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7381,
        "id": 1941,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7379,
        "temperature": 0,
        "text": " Double forward slash.",
        "tokens": [
          51314,
          16633,
          2128,
          17330,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7382,
        "id": 1942,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7381,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          51414,
          1033,
          11,
          1797,
          322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7384,
        "id": 1943,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7382,
        "temperature": 0,
        "text": " Let's search for.",
        "tokens": [
          51464,
          961,
          311,
          3164,
          337,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7386,
        "id": 1944,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7384,
        "temperature": 0,
        "text": " Let's search for.",
        "tokens": [
          51564,
          961,
          311,
          3164,
          337,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1849360880644425,
        "compression_ratio": 1.544378698224852,
        "end": 7388,
        "id": 1945,
        "no_speech_prob": 0.00628947326913476,
        "seek": 736000,
        "start": 7387,
        "temperature": 0,
        "text": " The coding train.",
        "tokens": [
          51714,
          440,
          17720,
          3847,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7390,
        "id": 1946,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7388,
        "temperature": 0,
        "text": " Maybe you guys can't see what I'm doing.",
        "tokens": [
          50364,
          2704,
          291,
          1074,
          393,
          380,
          536,
          437,
          286,
          478,
          884,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7392,
        "id": 1947,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7390,
        "temperature": 0,
        "text": " Let's search for the coding train double slash.",
        "tokens": [
          50464,
          961,
          311,
          3164,
          337,
          264,
          17720,
          3847,
          3834,
          17330,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7396,
        "id": 1948,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7395,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          50714,
          876,
          11,
          1338,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7397,
        "id": 1949,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7396,
        "temperature": 0,
        "text": " Everywhere.",
        "tokens": [
          50764,
          37322,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7400,
        "id": 1950,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7399,
        "temperature": 0,
        "text": " Whoa, it also.",
        "tokens": [
          50914,
          7521,
          11,
          309,
          611,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7401,
        "id": 1951,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7400,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          50964,
          876,
          11,
          1338,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7403,
        "id": 1952,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7401,
        "temperature": 0,
        "text": " Coding train double slash, double slash, double slash.",
        "tokens": [
          51014,
          383,
          8616,
          3847,
          3834,
          17330,
          11,
          3834,
          17330,
          11,
          3834,
          17330,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7405,
        "id": 1953,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7403,
        "temperature": 0,
        "text": " So let's fix that first of all.",
        "tokens": [
          51114,
          407,
          718,
          311,
          3191,
          300,
          700,
          295,
          439,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7406,
        "id": 1954,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7405,
        "temperature": 0,
        "text": " Replace all.",
        "tokens": [
          51214,
          1300,
          6742,
          439,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7410,
        "id": 1955,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7408,
        "temperature": 0,
        "text": " Git add.",
        "tokens": [
          51364,
          16939,
          909,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7411,
        "id": 1956,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7410,
        "temperature": 0,
        "text": " Git commit.",
        "tokens": [
          51464,
          16939,
          5599,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16981244824596287,
        "compression_ratio": 1.670731707317073,
        "end": 7414,
        "id": 1957,
        "no_speech_prob": 0.04023103788495064,
        "seek": 738800,
        "start": 7412,
        "temperature": 0,
        "text": " Fix double slash.",
        "tokens": [
          51564,
          25538,
          3834,
          17330,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7418,
        "id": 1958,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7415,
        "temperature": 0,
        "text": " And this might not be the proper way to do it.",
        "tokens": [
          50414,
          400,
          341,
          1062,
          406,
          312,
          264,
          2296,
          636,
          281,
          360,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7421,
        "id": 1959,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7418,
        "temperature": 0,
        "text": " But somebody in the chat just gave me the subscribe.",
        "tokens": [
          50564,
          583,
          2618,
          294,
          264,
          5081,
          445,
          2729,
          385,
          264,
          3022,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7423,
        "id": 1960,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7421,
        "temperature": 0,
        "text": " So I think.",
        "tokens": [
          50714,
          407,
          286,
          519,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7424,
        "id": 1961,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7423,
        "temperature": 0,
        "text": " Let's try this.",
        "tokens": [
          50814,
          961,
          311,
          853,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7426,
        "id": 1962,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7424,
        "temperature": 0,
        "text": " Let's go to.",
        "tokens": [
          50864,
          961,
          311,
          352,
          281,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7428,
        "id": 1963,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7427,
        "temperature": 0,
        "text": " Let's.",
        "tokens": [
          51014,
          961,
          311,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7429,
        "id": 1964,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7428,
        "temperature": 0,
        "text": " Okay, let's.",
        "tokens": [
          51064,
          1033,
          11,
          718,
          311,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7432,
        "id": 1965,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7431,
        "temperature": 0,
        "text": " Go to here.",
        "tokens": [
          51214,
          1037,
          281,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7435,
        "id": 1966,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7434,
        "temperature": 0,
        "text": " Still took me there.",
        "tokens": [
          51364,
          8291,
          1890,
          385,
          456,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7436,
        "id": 1967,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7435,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51414,
          663,
          311,
          2489,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7437,
        "id": 1968,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7436,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51464,
          663,
          311,
          3657,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7440,
        "id": 1969,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7438,
        "temperature": 0,
        "text": " Wait, where is that coming from?",
        "tokens": [
          51564,
          3802,
          11,
          689,
          307,
          300,
          1348,
          490,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.15731870780870752,
        "compression_ratio": 1.4754098360655739,
        "end": 7441,
        "id": 1970,
        "no_speech_prob": 0.004331312142312527,
        "seek": 741400,
        "start": 7440,
        "temperature": 0,
        "text": " Then if it says.",
        "tokens": [
          51664,
          1396,
          498,
          309,
          1619,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7444,
        "id": 1971,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7442,
        "temperature": 0,
        "text": " Hold on, hold on.",
        "tokens": [
          50414,
          6962,
          322,
          11,
          1797,
          322,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7447,
        "id": 1972,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7444,
        "temperature": 0,
        "text": " I'm talking to the people in the room next door.",
        "tokens": [
          50514,
          286,
          478,
          1417,
          281,
          264,
          561,
          294,
          264,
          1808,
          958,
          2853,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7449,
        "id": 1973,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7448,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50714,
          639,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7451,
        "id": 1974,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7449,
        "temperature": 0,
        "text": " Why is this still going to user slash shiftman?",
        "tokens": [
          50764,
          1545,
          307,
          341,
          920,
          516,
          281,
          4195,
          17330,
          5513,
          1601,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7452,
        "id": 1975,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7451,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          50864,
          1033,
          11,
          1797,
          322,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7453,
        "id": 1976,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7452,
        "temperature": 0,
        "text": " We got to figure this out.",
        "tokens": [
          50914,
          492,
          658,
          281,
          2573,
          341,
          484,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7455,
        "id": 1977,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7454,
        "temperature": 0,
        "text": " So landing page.",
        "tokens": [
          51014,
          407,
          11202,
          3028,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7460,
        "id": 1978,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7457,
        "temperature": 0,
        "text": " This is pulling this from site dot links dot YouTube.",
        "tokens": [
          51164,
          639,
          307,
          8407,
          341,
          490,
          3621,
          5893,
          6123,
          5893,
          3088,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7462,
        "id": 1979,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7460,
        "temperature": 0,
        "text": " So that must be in config.",
        "tokens": [
          51314,
          407,
          300,
          1633,
          312,
          294,
          6662,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7464,
        "id": 1980,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7463,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51464,
          1779,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7468,
        "id": 1981,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7466,
        "temperature": 0,
        "text": " But it's site dot links.",
        "tokens": [
          51614,
          583,
          309,
          311,
          3621,
          5893,
          6123,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2301865693564727,
        "compression_ratio": 1.558252427184466,
        "end": 7470,
        "id": 1982,
        "no_speech_prob": 0.0008830270962789655,
        "seek": 744100,
        "start": 7468,
        "temperature": 0,
        "text": " Why didn't that not rebuild?",
        "tokens": [
          51714,
          1545,
          994,
          380,
          300,
          406,
          16877,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7472,
        "id": 1983,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7470,
        "temperature": 0,
        "text": " I guess that doesn't rebuild.",
        "tokens": [
          50364,
          286,
          2041,
          300,
          1177,
          380,
          16877,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7476,
        "id": 1984,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7474,
        "temperature": 0,
        "text": " Let's rebuild the whole site.",
        "tokens": [
          50564,
          961,
          311,
          16877,
          264,
          1379,
          3621,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7484,
        "id": 1985,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7482,
        "temperature": 0,
        "text": " So I'm rebuilding the site.",
        "tokens": [
          50964,
          407,
          286,
          478,
          36717,
          264,
          3621,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7486,
        "id": 1986,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7484,
        "temperature": 0,
        "text": " I apparently have a wrong video number.",
        "tokens": [
          51064,
          286,
          7970,
          362,
          257,
          2085,
          960,
          1230,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7488,
        "id": 1987,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7486,
        "temperature": 0,
        "text": " 119 and 116.",
        "tokens": [
          51164,
          2975,
          24,
          293,
          2975,
          21,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7490,
        "id": 1988,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7489,
        "temperature": 0,
        "text": " Yeah, I haven't pushed the site live yet.",
        "tokens": [
          51314,
          865,
          11,
          286,
          2378,
          380,
          9152,
          264,
          3621,
          1621,
          1939,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7491,
        "id": 1989,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7490,
        "temperature": 0,
        "text": " That's correct.",
        "tokens": [
          51364,
          663,
          311,
          3006,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7497,
        "id": 1990,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7495,
        "temperature": 0,
        "text": " Okay, so let's see if that.",
        "tokens": [
          51614,
          1033,
          11,
          370,
          718,
          311,
          536,
          498,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16938464234514936,
        "compression_ratio": 1.3801169590643274,
        "end": 7499,
        "id": 1991,
        "no_speech_prob": 0.00008480883116135374,
        "seek": 747000,
        "start": 7498,
        "temperature": 0,
        "text": " Fixed it.",
        "tokens": [
          51764,
          25538,
          292,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7502,
        "id": 1992,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7500,
        "temperature": 0,
        "text": " Yes, this is now going to the coding train.",
        "tokens": [
          50364,
          1079,
          11,
          341,
          307,
          586,
          516,
          281,
          264,
          17720,
          3847,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7507,
        "id": 1993,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7503,
        "temperature": 0,
        "text": " And so what I want is to have it on landing page.",
        "tokens": [
          50514,
          400,
          370,
          437,
          286,
          528,
          307,
          281,
          362,
          309,
          322,
          11202,
          3028,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7510,
        "id": 1994,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7508,
        "temperature": 0,
        "text": " B and then it's question mark.",
        "tokens": [
          50764,
          363,
          293,
          550,
          309,
          311,
          1168,
          1491,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7517,
        "id": 1995,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7512,
        "temperature": 0,
        "text": " Sub confirmation equals one sub underscore confirmation equals one.",
        "tokens": [
          50964,
          8511,
          21871,
          6915,
          472,
          1422,
          37556,
          21871,
          6915,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7520,
        "id": 1996,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7518,
        "temperature": 0,
        "text": " Pretty sure that's going to subscribe me.",
        "tokens": [
          51264,
          10693,
          988,
          300,
          311,
          516,
          281,
          3022,
          385,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7522,
        "id": 1997,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7521,
        "temperature": 0,
        "text": " So this hasn't.",
        "tokens": [
          51414,
          407,
          341,
          6132,
          380,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7523,
        "id": 1998,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7522,
        "temperature": 0,
        "text": " I'm going to go here.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1944635155495633,
        "compression_ratio": 1.6557377049180328,
        "end": 7526,
        "id": 1999,
        "no_speech_prob": 0.0004442046629264951,
        "seek": 750000,
        "start": 7524,
        "temperature": 0,
        "text": " And I am going to unsubscribe.",
        "tokens": [
          51564,
          400,
          286,
          669,
          516,
          281,
          2693,
          9493,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21630584276639497,
        "compression_ratio": 1.3577235772357723,
        "end": 7529,
        "id": 2000,
        "no_speech_prob": 0.0335858054459095,
        "seek": 752600,
        "start": 7526,
        "temperature": 0,
        "text": " I am unsubscribing from the coding train.",
        "tokens": [
          50364,
          286,
          669,
          2693,
          5432,
          39541,
          490,
          264,
          17720,
          3847,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21630584276639497,
        "compression_ratio": 1.3577235772357723,
        "end": 7533,
        "id": 2001,
        "no_speech_prob": 0.0335858054459095,
        "seek": 752600,
        "start": 7532,
        "temperature": 0,
        "text": " Unsubscribe.",
        "tokens": [
          50664,
          25017,
          9493,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21630584276639497,
        "compression_ratio": 1.3577235772357723,
        "end": 7536,
        "id": 2002,
        "no_speech_prob": 0.0335858054459095,
        "seek": 752600,
        "start": 7534,
        "temperature": 0,
        "text": " Now we will go back to the website.",
        "tokens": [
          50764,
          823,
          321,
          486,
          352,
          646,
          281,
          264,
          3144,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21630584276639497,
        "compression_ratio": 1.3577235772357723,
        "end": 7541,
        "id": 2003,
        "no_speech_prob": 0.0335858054459095,
        "seek": 752600,
        "start": 7539,
        "temperature": 0,
        "text": " And I'm going to click on this link.",
        "tokens": [
          51014,
          400,
          286,
          478,
          516,
          281,
          2052,
          322,
          341,
          2113,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21630584276639497,
        "compression_ratio": 1.3577235772357723,
        "end": 7546,
        "id": 2004,
        "no_speech_prob": 0.0335858054459095,
        "seek": 752600,
        "start": 7543,
        "temperature": 0,
        "text": " And are you sure you want to subscribe?",
        "tokens": [
          51214,
          400,
          366,
          291,
          988,
          291,
          528,
          281,
          3022,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7558,
        "id": 2005,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7556,
        "temperature": 0,
        "text": " Okay, now I have subscribed.",
        "tokens": [
          50364,
          1033,
          11,
          586,
          286,
          362,
          16665,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7561,
        "id": 2006,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7559,
        "temperature": 0,
        "text": " I'm back up to my subscription number.",
        "tokens": [
          50514,
          286,
          478,
          646,
          493,
          281,
          452,
          17231,
          1230,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7562,
        "id": 2007,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7561,
        "temperature": 0,
        "text": " So that's good.",
        "tokens": [
          50614,
          407,
          300,
          311,
          665,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7563,
        "id": 2008,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7562,
        "temperature": 0,
        "text": " So I did that.",
        "tokens": [
          50664,
          407,
          286,
          630,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7564,
        "id": 2009,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7563,
        "temperature": 0,
        "text": " So.",
        "tokens": [
          50714,
          407,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7573,
        "id": 2010,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7570,
        "temperature": 0,
        "text": " Add automatic subscription link.",
        "tokens": [
          51064,
          5349,
          12509,
          17231,
          2113,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7576,
        "id": 2011,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7574,
        "temperature": 0,
        "text": " Okay, now what was the other thing?",
        "tokens": [
          51264,
          1033,
          11,
          586,
          437,
          390,
          264,
          661,
          551,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7578,
        "id": 2012,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7576,
        "temperature": 0,
        "text": " Somebody was telling me I had the video numbers wrong.",
        "tokens": [
          51364,
          13463,
          390,
          3585,
          385,
          286,
          632,
          264,
          960,
          3547,
          2085,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7580,
        "id": 2013,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7578,
        "temperature": 0,
        "text": " I'm going to go back to the website.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          264,
          3144,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4369620072214227,
        "compression_ratio": 1.6216216216216217,
        "end": 7583,
        "id": 2014,
        "no_speech_prob": 0.021945053711533546,
        "seek": 755600,
        "start": 7581,
        "temperature": 0,
        "text": " And I'm going to click on this link.",
        "tokens": [
          51614,
          400,
          286,
          478,
          516,
          281,
          2052,
          322,
          341,
          2113,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7584,
        "id": 2015,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7583,
        "temperature": 0,
        "text": " Now what was the other thing?",
        "tokens": [
          50364,
          823,
          437,
          390,
          264,
          661,
          551,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7586,
        "id": 2016,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7584,
        "temperature": 0,
        "text": " Somebody was telling me I had the video numbers wrong.",
        "tokens": [
          50414,
          13463,
          390,
          3585,
          385,
          286,
          632,
          264,
          960,
          3547,
          2085,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7589,
        "id": 2017,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7588,
        "temperature": 0,
        "text": " Oh, interesting.",
        "tokens": [
          50614,
          876,
          11,
          1880,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7591,
        "id": 2018,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7589,
        "temperature": 0,
        "text": " I don't have to unsubscribe to get that.",
        "tokens": [
          50664,
          286,
          500,
          380,
          362,
          281,
          2693,
          9493,
          281,
          483,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7592,
        "id": 2019,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7591,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7597,
        "id": 2020,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7593,
        "temperature": 0,
        "text": " So what was it that somebody was saying that I have the video numbers wrong?",
        "tokens": [
          50864,
          407,
          437,
          390,
          309,
          300,
          2618,
          390,
          1566,
          300,
          286,
          362,
          264,
          960,
          3547,
          2085,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7598,
        "id": 2021,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7597,
        "temperature": 0,
        "text": " Let me look back.",
        "tokens": [
          51064,
          961,
          385,
          574,
          646,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7599,
        "id": 2022,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7598,
        "temperature": 0,
        "text": " The reason why.",
        "tokens": [
          51114,
          440,
          1778,
          983,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7601,
        "id": 2023,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7600,
        "temperature": 0,
        "text": " Yes, here's the thing.",
        "tokens": [
          51214,
          1079,
          11,
          510,
          311,
          264,
          551,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7606,
        "id": 2024,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7604,
        "temperature": 0,
        "text": " Oh, 118 is already more neural networks.",
        "tokens": [
          51414,
          876,
          11,
          2975,
          23,
          307,
          1217,
          544,
          18161,
          9590,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7608,
        "id": 2025,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7607,
        "temperature": 0,
        "text": " Oh, I'm totally wrong.",
        "tokens": [
          51564,
          876,
          11,
          286,
          478,
          3879,
          2085,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17061749333920687,
        "compression_ratio": 1.6069868995633187,
        "end": 7612,
        "id": 2026,
        "no_speech_prob": 0.0014103318098932505,
        "seek": 758300,
        "start": 7609,
        "temperature": 0,
        "text": " Because today is 119.",
        "tokens": [
          51664,
          1436,
          965,
          307,
          2975,
          24,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7615,
        "id": 2027,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7613,
        "temperature": 0,
        "text": " And also, why is 116?",
        "tokens": [
          50364,
          400,
          611,
          11,
          983,
          307,
          2975,
          21,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7616,
        "id": 2028,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7615,
        "temperature": 0,
        "text": " What's?",
        "tokens": [
          50464,
          708,
          311,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7618,
        "id": 2029,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7617,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          50564,
          286,
          478,
          370,
          9019,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7619,
        "id": 2030,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7618,
        "temperature": 0,
        "text": " But let me go to the...",
        "tokens": [
          50614,
          583,
          718,
          385,
          352,
          281,
          264,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7621,
        "id": 2031,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7620,
        "temperature": 0,
        "text": " Let me look at the website here.",
        "tokens": [
          50714,
          961,
          385,
          574,
          412,
          264,
          3144,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7623,
        "id": 2032,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7622,
        "temperature": 0,
        "text": " Oh, it says 116 there.",
        "tokens": [
          50814,
          876,
          11,
          309,
          1619,
          2975,
          21,
          456,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7625,
        "id": 2033,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7623,
        "temperature": 0,
        "text": " Yes, yes, I see.",
        "tokens": [
          50864,
          1079,
          11,
          2086,
          11,
          286,
          536,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7629,
        "id": 2034,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7625,
        "temperature": 0,
        "text": " And actually, it shouldn't even be 119.",
        "tokens": [
          50964,
          400,
          767,
          11,
          309,
          4659,
          380,
          754,
          312,
          2975,
          24,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7631,
        "id": 2035,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7630,
        "temperature": 0,
        "text": " Because...",
        "tokens": [
          51214,
          1436,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7635,
        "id": 2036,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7634,
        "temperature": 0,
        "text": " It should be 120.",
        "tokens": [
          51414,
          467,
          820,
          312,
          10411,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20942564805348715,
        "compression_ratio": 1.396551724137931,
        "end": 7637,
        "id": 2037,
        "no_speech_prob": 0.00028682861011475325,
        "seek": 761300,
        "start": 7636,
        "temperature": 0,
        "text": " And so let me rename the file.",
        "tokens": [
          51514,
          400,
          370,
          718,
          385,
          36741,
          264,
          3991,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.44873770545510683,
        "compression_ratio": 1.4324324324324325,
        "end": 7647,
        "id": 2038,
        "no_speech_prob": 0.011865704320371151,
        "seek": 763700,
        "start": 7637,
        "temperature": 0,
        "text": " It should be 120 because if the last one that is on YouTube is in fact 118,",
        "tokens": [
          50364,
          467,
          820,
          312,
          10411,
          570,
          498,
          264,
          1036,
          472,
          300,
          307,
          322,
          3088,
          307,
          294,
          1186,
          2975,
          23,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.44873770545510683,
        "compression_ratio": 1.4324324324324325,
        "end": 7653,
        "id": 2039,
        "no_speech_prob": 0.011865704320371151,
        "seek": 763700,
        "start": 7647,
        "temperature": 0,
        "text": " that means today right now is 119 and Friday is 120.",
        "tokens": [
          50864,
          300,
          1355,
          965,
          558,
          586,
          307,
          2975,
          24,
          293,
          6984,
          307,
          10411,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.44873770545510683,
        "compression_ratio": 1.4324324324324325,
        "end": 7657,
        "id": 2040,
        "no_speech_prob": 0.011865704320371151,
        "seek": 763700,
        "start": 7654,
        "temperature": 0,
        "text": " So I change it to 120.",
        "tokens": [
          51214,
          407,
          286,
          1319,
          309,
          281,
          10411,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.44873770545510683,
        "compression_ratio": 1.4324324324324325,
        "end": 7661,
        "id": 2041,
        "no_speech_prob": 0.011865704320371151,
        "seek": 763700,
        "start": 7659,
        "temperature": 0,
        "text": " And let me do git status.",
        "tokens": [
          51464,
          400,
          718,
          385,
          360,
          18331,
          6558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.44873770545510683,
        "compression_ratio": 1.4324324324324325,
        "end": 7664,
        "id": 2042,
        "no_speech_prob": 0.011865704320371151,
        "seek": 763700,
        "start": 7662,
        "temperature": 0,
        "text": " And I'm going to change it to 120.",
        "tokens": [
          51614,
          400,
          286,
          478,
          516,
          281,
          1319,
          309,
          281,
          10411,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7666,
        "id": 2043,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7664,
        "temperature": 0,
        "text": " And let me do git status.",
        "tokens": [
          50364,
          400,
          718,
          385,
          360,
          18331,
          6558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7672,
        "id": 2044,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7669,
        "temperature": 0,
        "text": " So I'm going to do git add dash A.",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          360,
          18331,
          909,
          8240,
          316,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7675,
        "id": 2045,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7673,
        "temperature": 0,
        "text": " I did that dash capital A.",
        "tokens": [
          50814,
          286,
          630,
          300,
          8240,
          4238,
          316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7677,
        "id": 2046,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7675,
        "temperature": 0,
        "text": " I don't know if it needs to be capital because I deleted the file.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          498,
          309,
          2203,
          281,
          312,
          4238,
          570,
          286,
          22981,
          264,
          3991,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7681,
        "id": 2047,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7677,
        "temperature": 0,
        "text": " And so I want to make sure that delete gets added as well.",
        "tokens": [
          51014,
          400,
          370,
          286,
          528,
          281,
          652,
          988,
          300,
          12097,
          2170,
          3869,
          382,
          731,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7684,
        "id": 2048,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7682,
        "temperature": 0,
        "text": " Friday is 120.",
        "tokens": [
          51264,
          6984,
          307,
          10411,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20271895913516774,
        "compression_ratio": 1.497175141242938,
        "end": 7687,
        "id": 2049,
        "no_speech_prob": 0.0020187583286315203,
        "seek": 766400,
        "start": 7685,
        "temperature": 0,
        "text": " And then, why not add one for today?",
        "tokens": [
          51414,
          400,
          550,
          11,
          983,
          406,
          909,
          472,
          337,
          965,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7688,
        "id": 2050,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7687,
        "temperature": 0,
        "text": " If I do...",
        "tokens": [
          50364,
          759,
          286,
          360,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7690,
        "id": 2051,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7688,
        "temperature": 0,
        "text": " I'm not going to add one for today.",
        "tokens": [
          50414,
          286,
          478,
          406,
          516,
          281,
          909,
          472,
          337,
          965,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7691,
        "id": 2052,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7690,
        "temperature": 0,
        "text": " So this is the thing.",
        "tokens": [
          50514,
          407,
          341,
          307,
          264,
          551,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7693,
        "id": 2053,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7691,
        "temperature": 0,
        "text": " Anybody watching this video wants to help.",
        "tokens": [
          50564,
          19082,
          1976,
          341,
          960,
          2738,
          281,
          854,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7695,
        "id": 2054,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7694,
        "temperature": 0,
        "text": " There are...",
        "tokens": [
          50714,
          821,
          366,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7696,
        "id": 2055,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7695,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50764,
          2053,
          412,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7697,
        "id": 2056,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7696,
        "temperature": 0,
        "text": " A live stream could be...",
        "tokens": [
          50814,
          316,
          1621,
          4309,
          727,
          312,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7700,
        "id": 2057,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7697,
        "temperature": 0,
        "text": " The markdown file could be added for all of...",
        "tokens": [
          50864,
          440,
          1491,
          5093,
          3991,
          727,
          312,
          3869,
          337,
          439,
          295,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7703,
        "id": 2058,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7700,
        "temperature": 0,
        "text": " You know, it only starts here at about 104.",
        "tokens": [
          51014,
          509,
          458,
          11,
          309,
          787,
          3719,
          510,
          412,
          466,
          47757,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7706,
        "id": 2059,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7704,
        "temperature": 0,
        "text": " Coding challenges, I think...",
        "tokens": [
          51214,
          383,
          8616,
          4759,
          11,
          286,
          519,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7707,
        "id": 2060,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7706,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51314,
          45263,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7711,
        "id": 2061,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7707,
        "temperature": 0,
        "text": " I think I only have a markdown file for every coding challenge.",
        "tokens": [
          51364,
          286,
          519,
          286,
          787,
          362,
          257,
          1491,
          5093,
          3991,
          337,
          633,
          17720,
          3430,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7713,
        "id": 2062,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7712,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51614,
          286,
          500,
          380,
          458,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3261698768252418,
        "compression_ratio": 1.610878661087866,
        "end": 7714,
        "id": 2063,
        "no_speech_prob": 0.0007436812156811357,
        "seek": 768700,
        "start": 7713,
        "temperature": 0,
        "text": " I'm not sure.",
        "tokens": [
          51664,
          286,
          478,
          406,
          988,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21617771100394334,
        "compression_ratio": 1.6989247311827957,
        "end": 7716,
        "id": 2064,
        "no_speech_prob": 0.29732537269592285,
        "seek": 771400,
        "start": 7714,
        "temperature": 0,
        "text": " I have a markdown file for every coding challenge?",
        "tokens": [
          50364,
          286,
          362,
          257,
          1491,
          5093,
          3991,
          337,
          633,
          17720,
          3430,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.21617771100394334,
        "compression_ratio": 1.6989247311827957,
        "end": 7720,
        "id": 2065,
        "no_speech_prob": 0.29732537269592285,
        "seek": 771400,
        "start": 7717,
        "temperature": 0,
        "text": " Looks like I have a markdown file for every coding challenge.",
        "tokens": [
          50514,
          10027,
          411,
          286,
          362,
          257,
          1491,
          5093,
          3991,
          337,
          633,
          17720,
          3430,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21617771100394334,
        "compression_ratio": 1.6989247311827957,
        "end": 7725,
        "id": 2066,
        "no_speech_prob": 0.29732537269592285,
        "seek": 771400,
        "start": 7720,
        "temperature": 0,
        "text": " But I'm missing so many markdown files for the courses and tutorials.",
        "tokens": [
          50664,
          583,
          286,
          478,
          5361,
          370,
          867,
          1491,
          5093,
          7098,
          337,
          264,
          7712,
          293,
          17616,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21617771100394334,
        "compression_ratio": 1.6989247311827957,
        "end": 7727,
        "id": 2067,
        "no_speech_prob": 0.29732537269592285,
        "seek": 771400,
        "start": 7725,
        "temperature": 0,
        "text": " And also, just generally speaking...",
        "tokens": [
          50914,
          400,
          611,
          11,
          445,
          5101,
          4124,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.21617771100394334,
        "compression_ratio": 1.6989247311827957,
        "end": 7742,
        "id": 2068,
        "no_speech_prob": 0.29732537269592285,
        "seek": 771400,
        "start": 7731,
        "temperature": 0,
        "text": " If you have ideas for how this site can be more navigable, visually pleasing, make more sense...",
        "tokens": [
          51214,
          759,
          291,
          362,
          3487,
          337,
          577,
          341,
          3621,
          393,
          312,
          544,
          7407,
          712,
          11,
          19622,
          32798,
          11,
          652,
          544,
          2020,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7744,
        "id": 2069,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7743,
        "temperature": 0,
        "text": " You can clone it.",
        "tokens": [
          50414,
          509,
          393,
          26506,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7746,
        "id": 2070,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7744,
        "temperature": 0,
        "text": " You can run Jekyll locally like I did.",
        "tokens": [
          50464,
          509,
          393,
          1190,
          508,
          916,
          34353,
          16143,
          411,
          286,
          630,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7747,
        "id": 2071,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7746,
        "temperature": 0,
        "text": " You can make changes to it.",
        "tokens": [
          50564,
          509,
          393,
          652,
          2962,
          281,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7751,
        "id": 2072,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7747,
        "temperature": 0,
        "text": " It's all HTML, CSS, markdown, and some weird Jekyll stuff.",
        "tokens": [
          50614,
          467,
          311,
          439,
          17995,
          11,
          24387,
          11,
          1491,
          5093,
          11,
          293,
          512,
          3657,
          508,
          916,
          34353,
          1507,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7753,
        "id": 2073,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7751,
        "temperature": 0,
        "text": " But play with it.",
        "tokens": [
          50814,
          583,
          862,
          365,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7754,
        "id": 2074,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7753,
        "temperature": 0,
        "text": " Make fixes.",
        "tokens": [
          50914,
          4387,
          32539,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7755,
        "id": 2075,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7754,
        "temperature": 0,
        "text": " Make changes.",
        "tokens": [
          50964,
          4387,
          2962,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7756,
        "id": 2076,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7755,
        "temperature": 0,
        "text": " I could use some unit tests for it.",
        "tokens": [
          51014,
          286,
          727,
          764,
          512,
          4985,
          6921,
          337,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7760,
        "id": 2077,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7756,
        "temperature": 0,
        "text": " One thing would be good to have a unit test that checks to make sure the Jekyll build is right.",
        "tokens": [
          51064,
          1485,
          551,
          576,
          312,
          665,
          281,
          362,
          257,
          4985,
          1500,
          300,
          13834,
          281,
          652,
          988,
          264,
          508,
          916,
          34353,
          1322,
          307,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7762,
        "id": 2078,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7761,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51314,
          1079,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7764,
        "id": 2079,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7763,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51414,
          400,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.18632166172430767,
        "compression_ratio": 1.5913043478260869,
        "end": 7767,
        "id": 2080,
        "no_speech_prob": 0.004069065675139427,
        "seek": 774200,
        "start": 7766,
        "temperature": 0,
        "text": " Yeah, I would love help with that.",
        "tokens": [
          51564,
          865,
          11,
          286,
          576,
          959,
          854,
          365,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7771,
        "id": 2081,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7767,
        "temperature": 0,
        "text": " But right now, I at least have successfully scheduled this Friday's live stream.",
        "tokens": [
          50364,
          583,
          558,
          586,
          11,
          286,
          412,
          1935,
          362,
          10727,
          15678,
          341,
          6984,
          311,
          1621,
          4309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7775,
        "id": 2082,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7771,
        "temperature": 0,
        "text": " Now, one thing I should say is this is my speculation.",
        "tokens": [
          50564,
          823,
          11,
          472,
          551,
          286,
          820,
          584,
          307,
          341,
          307,
          452,
          27696,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7779,
        "id": 2083,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7776,
        "temperature": 0,
        "text": " I might change it to the afternoon, but I will try to update this if I do.",
        "tokens": [
          50814,
          286,
          1062,
          1319,
          309,
          281,
          264,
          6499,
          11,
          457,
          286,
          486,
          853,
          281,
          5623,
          341,
          498,
          286,
          360,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7785,
        "id": 2084,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7779,
        "temperature": 0,
        "text": " But this at least now is going to be a system for me being able to alert people of when the next live stream is.",
        "tokens": [
          50964,
          583,
          341,
          412,
          1935,
          586,
          307,
          516,
          281,
          312,
          257,
          1185,
          337,
          385,
          885,
          1075,
          281,
          9615,
          561,
          295,
          562,
          264,
          958,
          1621,
          4309,
          307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7789,
        "id": 2085,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7786,
        "temperature": 0,
        "text": " It kind of lets us see the latest videos and all this stuff.",
        "tokens": [
          51314,
          467,
          733,
          295,
          6653,
          505,
          536,
          264,
          6792,
          2145,
          293,
          439,
          341,
          1507,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7791,
        "id": 2086,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7790,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51514,
          1057,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24104983747498063,
        "compression_ratio": 1.6420664206642066,
        "end": 7794,
        "id": 2087,
        "no_speech_prob": 0.14996671676635742,
        "seek": 776700,
        "start": 7792,
        "temperature": 0,
        "text": " I think that's all I've got to say for right now.",
        "tokens": [
          51614,
          286,
          519,
          300,
          311,
          439,
          286,
          600,
          658,
          281,
          584,
          337,
          558,
          586,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7796,
        "id": 2088,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7794,
        "temperature": 0,
        "text": " Oh, let me push it live to the site.",
        "tokens": [
          50364,
          876,
          11,
          718,
          385,
          2944,
          309,
          1621,
          281,
          264,
          3621,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7801,
        "id": 2089,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7799,
        "temperature": 0,
        "text": " So, I've now pushed this live.",
        "tokens": [
          50614,
          407,
          11,
          286,
          600,
          586,
          9152,
          341,
          1621,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7805,
        "id": 2090,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7801,
        "temperature": 0,
        "text": " So, you should now see this if I go to the codingtrain.com.",
        "tokens": [
          50714,
          407,
          11,
          291,
          820,
          586,
          536,
          341,
          498,
          286,
          352,
          281,
          264,
          17720,
          83,
          7146,
          13,
          1112,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7810,
        "id": 2091,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7805,
        "temperature": 0,
        "text": " Now, you don't see it right now because these Jekyll builds can take a little while.",
        "tokens": [
          50914,
          823,
          11,
          291,
          500,
          380,
          536,
          309,
          558,
          586,
          570,
          613,
          508,
          916,
          34353,
          15182,
          393,
          747,
          257,
          707,
          1339,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7812,
        "id": 2092,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7811,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7819,
        "id": 2093,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7817,
        "temperature": 0,
        "text": " Four coding challenge Friday or one of them?",
        "tokens": [
          51514,
          7451,
          17720,
          3430,
          6984,
          420,
          472,
          295,
          552,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.20860446229272958,
        "compression_ratio": 1.4951923076923077,
        "end": 7821,
        "id": 2094,
        "no_speech_prob": 0.019121374934911728,
        "seek": 779400,
        "start": 7819,
        "temperature": 0,
        "text": " Well, certainly my goal is to do all four.",
        "tokens": [
          51614,
          1042,
          11,
          3297,
          452,
          3387,
          307,
          281,
          360,
          439,
          1451,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7826,
        "id": 2095,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7821,
        "temperature": 0,
        "text": " I wouldn't be surprised if I only got to one or two or three, but my goal is to do all four.",
        "tokens": [
          50364,
          286,
          2759,
          380,
          312,
          6100,
          498,
          286,
          787,
          658,
          281,
          472,
          420,
          732,
          420,
          1045,
          11,
          457,
          452,
          3387,
          307,
          281,
          360,
          439,
          1451,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7831,
        "id": 2096,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7830,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7834,
        "id": 2097,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7831,
        "temperature": 0,
        "text": " So, I'm done for today.",
        "tokens": [
          50864,
          407,
          11,
          286,
          478,
          1096,
          337,
          965,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7840,
        "id": 2098,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7837,
        "temperature": 0,
        "text": " I will happily take a few last questions.",
        "tokens": [
          51164,
          286,
          486,
          19909,
          747,
          257,
          1326,
          1036,
          1651,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7843,
        "id": 2099,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7841,
        "temperature": 0,
        "text": " For a sigmoid, oh, it's 4.45.",
        "tokens": [
          51364,
          1171,
          257,
          4556,
          3280,
          327,
          11,
          1954,
          11,
          309,
          311,
          1017,
          13,
          8465,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7844,
        "id": 2100,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7843,
        "temperature": 0,
        "text": " I really got to go.",
        "tokens": [
          51464,
          286,
          534,
          658,
          281,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2043089769324478,
        "compression_ratio": 1.4666666666666666,
        "end": 7848,
        "id": 2101,
        "no_speech_prob": 0.05581482872366905,
        "seek": 782100,
        "start": 7844,
        "temperature": 0,
        "text": " For a sigmoid, should the outputs be negative one, one instead of zero?",
        "tokens": [
          51514,
          1171,
          257,
          4556,
          3280,
          327,
          11,
          820,
          264,
          23930,
          312,
          3671,
          472,
          11,
          472,
          2602,
          295,
          4018,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7851,
        "id": 2102,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7848,
        "temperature": 0,
        "text": " For a sigmoid, should the outputs be negative one, one instead of zero, one?",
        "tokens": [
          50364,
          1171,
          257,
          4556,
          3280,
          327,
          11,
          820,
          264,
          23930,
          312,
          3671,
          472,
          11,
          472,
          2602,
          295,
          4018,
          11,
          472,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7852,
        "id": 2103,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7851,
        "temperature": 0,
        "text": " Just thinking.",
        "tokens": [
          50514,
          1449,
          1953,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7857,
        "id": 2104,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7852,
        "temperature": 0,
        "text": " No, the sigmoid function squashes any number to a range between zero and one.",
        "tokens": [
          50564,
          883,
          11,
          264,
          4556,
          3280,
          327,
          2445,
          2339,
          12808,
          604,
          1230,
          281,
          257,
          3613,
          1296,
          4018,
          293,
          472,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7860,
        "id": 2105,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7858,
        "temperature": 0,
        "text": " There's a function called tanh or hypertangent.",
        "tokens": [
          50864,
          821,
          311,
          257,
          2445,
          1219,
          7603,
          71,
          420,
          9848,
          83,
          656,
          317,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7863,
        "id": 2106,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7860,
        "temperature": 0,
        "text": " That's another activation function that is used with neural networks.",
        "tokens": [
          50964,
          663,
          311,
          1071,
          24433,
          2445,
          300,
          307,
          1143,
          365,
          18161,
          9590,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7866,
        "id": 2107,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7864,
        "temperature": 0,
        "text": " That gives you an output between negative one and one.",
        "tokens": [
          51164,
          663,
          2709,
          291,
          364,
          5598,
          1296,
          3671,
          472,
          293,
          472,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7869,
        "id": 2108,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7866,
        "temperature": 0,
        "text": " But sigmoid gives you an output between zero and one.",
        "tokens": [
          51264,
          583,
          4556,
          3280,
          327,
          2709,
          291,
          364,
          5598,
          1296,
          4018,
          293,
          472,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20710715082765535,
        "compression_ratio": 1.8778625954198473,
        "end": 7876,
        "id": 2109,
        "no_speech_prob": 0.3378414809703827,
        "seek": 784800,
        "start": 7869,
        "temperature": 0,
        "text": " And the activation function that's used most commonly now is called relu or I like to say relu.",
        "tokens": [
          51414,
          400,
          264,
          24433,
          2445,
          300,
          311,
          1143,
          881,
          12719,
          586,
          307,
          1219,
          1039,
          84,
          420,
          286,
          411,
          281,
          584,
          1039,
          84,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19091154399671054,
        "compression_ratio": 1.4895397489539748,
        "end": 7881,
        "id": 2110,
        "no_speech_prob": 0.004263942129909992,
        "seek": 787600,
        "start": 7876,
        "temperature": 0,
        "text": " And that actually just gives you a number between zero and infinity.",
        "tokens": [
          50364,
          400,
          300,
          767,
          445,
          2709,
          291,
          257,
          1230,
          1296,
          4018,
          293,
          13202,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19091154399671054,
        "compression_ratio": 1.4895397489539748,
        "end": 7882,
        "id": 2111,
        "no_speech_prob": 0.004263942129909992,
        "seek": 787600,
        "start": 7881,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19091154399671054,
        "compression_ratio": 1.4895397489539748,
        "end": 7890,
        "id": 2112,
        "no_speech_prob": 0.004263942129909992,
        "seek": 787600,
        "start": 7884,
        "temperature": 0,
        "text": " Do you have plans of teaching JS for embedded devices like Esprino.js or Puck.js?",
        "tokens": [
          50764,
          1144,
          291,
          362,
          5482,
          295,
          4571,
          33063,
          337,
          16741,
          5759,
          411,
          2313,
          1424,
          2982,
          13,
          25530,
          420,
          430,
          1134,
          13,
          25530,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.19091154399671054,
        "compression_ratio": 1.4895397489539748,
        "end": 7896,
        "id": 2113,
        "no_speech_prob": 0.004263942129909992,
        "seek": 787600,
        "start": 7891,
        "temperature": 0,
        "text": " I don't have any plans, but that sounds like a great idea.",
        "tokens": [
          51114,
          286,
          500,
          380,
          362,
          604,
          5482,
          11,
          457,
          300,
          3263,
          411,
          257,
          869,
          1558,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19091154399671054,
        "compression_ratio": 1.4895397489539748,
        "end": 7899,
        "id": 2114,
        "no_speech_prob": 0.004263942129909992,
        "seek": 787600,
        "start": 7896,
        "temperature": 0,
        "text": " That would probably be a good territory for a guest tutorial.",
        "tokens": [
          51364,
          663,
          576,
          1391,
          312,
          257,
          665,
          11360,
          337,
          257,
          8341,
          7073,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19091154399671054,
        "compression_ratio": 1.4895397489539748,
        "end": 7904,
        "id": 2115,
        "no_speech_prob": 0.004263942129909992,
        "seek": 787600,
        "start": 7899,
        "temperature": 0,
        "text": " Hopefully, I can get a little more handle on my schedule and have more guests.",
        "tokens": [
          51514,
          10429,
          11,
          286,
          393,
          483,
          257,
          707,
          544,
          4813,
          322,
          452,
          7567,
          293,
          362,
          544,
          9804,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21010272447452988,
        "compression_ratio": 1.627906976744186,
        "end": 7909,
        "id": 2116,
        "no_speech_prob": 0.001956951804459095,
        "seek": 790400,
        "start": 7905,
        "temperature": 0,
        "text": " Are you going to carry on with neural networks, convolution, etc.?",
        "tokens": [
          50414,
          2014,
          291,
          516,
          281,
          3985,
          322,
          365,
          18161,
          9590,
          11,
          45216,
          11,
          5183,
          41401,
          50614
        ]
      },
      {
        "avg_logprob": -0.21010272447452988,
        "compression_ratio": 1.627906976744186,
        "end": 7913,
        "id": 2117,
        "no_speech_prob": 0.001956951804459095,
        "seek": 790400,
        "start": 7909,
        "temperature": 0,
        "text": " Yes, I'm going to keep neural networking and carrying on.",
        "tokens": [
          50614,
          1079,
          11,
          286,
          478,
          516,
          281,
          1066,
          18161,
          17985,
          293,
          9792,
          322,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21010272447452988,
        "compression_ratio": 1.627906976744186,
        "end": 7918,
        "id": 2118,
        "no_speech_prob": 0.001956951804459095,
        "seek": 790400,
        "start": 7917,
        "temperature": 0,
        "text": " But I'm not sure.",
        "tokens": [
          51014,
          583,
          286,
          478,
          406,
          988,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21010272447452988,
        "compression_ratio": 1.627906976744186,
        "end": 7928,
        "id": 2119,
        "no_speech_prob": 0.001956951804459095,
        "seek": 790400,
        "start": 7918,
        "temperature": 0,
        "text": " I don't think that I'm going to continue to build every style and flavor and architecture of neural network into this toy JavaScript library.",
        "tokens": [
          51064,
          286,
          500,
          380,
          519,
          300,
          286,
          478,
          516,
          281,
          2354,
          281,
          1322,
          633,
          3758,
          293,
          6813,
          293,
          9482,
          295,
          18161,
          3209,
          666,
          341,
          12058,
          15778,
          6405,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21010272447452988,
        "compression_ratio": 1.627906976744186,
        "end": 7931,
        "id": 2120,
        "no_speech_prob": 0.001956951804459095,
        "seek": 790400,
        "start": 7928,
        "temperature": 0,
        "text": " This I really meant to do like the sort of first beginning steps.",
        "tokens": [
          51564,
          639,
          286,
          534,
          4140,
          281,
          360,
          411,
          264,
          1333,
          295,
          700,
          2863,
          4439,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7939,
        "id": 2121,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7931,
        "temperature": 0,
        "text": " And then if I do stuff with say a convolutional neural network, I'll do that with deeplearn.js and possibly this ml5.js library.",
        "tokens": [
          50364,
          400,
          550,
          498,
          286,
          360,
          1507,
          365,
          584,
          257,
          45216,
          304,
          18161,
          3209,
          11,
          286,
          603,
          360,
          300,
          365,
          2452,
          306,
          1083,
          13,
          25530,
          293,
          6264,
          341,
          23271,
          20,
          13,
          25530,
          6405,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7948,
        "id": 2122,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7945,
        "temperature": 0,
        "text": " When are you going to add splitting to the game Agario?",
        "tokens": [
          51064,
          1133,
          366,
          291,
          516,
          281,
          909,
          30348,
          281,
          264,
          1216,
          2725,
          4912,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7950,
        "id": 2123,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7949,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51264,
          286,
          500,
          380,
          458,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7951,
        "id": 2124,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7950,
        "temperature": 0,
        "text": " Probably not for a while.",
        "tokens": [
          51314,
          9210,
          406,
          337,
          257,
          1339,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7955,
        "id": 2125,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7951,
        "temperature": 0,
        "text": " But people have really requested that I follow up on that challenge.",
        "tokens": [
          51364,
          583,
          561,
          362,
          534,
          16436,
          300,
          286,
          1524,
          493,
          322,
          300,
          3430,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7958,
        "id": 2126,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7955,
        "temperature": 0,
        "text": " Are you interested in a coding train app?",
        "tokens": [
          51564,
          2014,
          291,
          3102,
          294,
          257,
          17720,
          3847,
          724,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.20737913465991462,
        "compression_ratio": 1.5044247787610618,
        "end": 7960,
        "id": 2127,
        "no_speech_prob": 0.12587380409240723,
        "seek": 793100,
        "start": 7959,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51764,
          1079,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22093410282344608,
        "compression_ratio": 1.6008064516129032,
        "end": 7965,
        "id": 2128,
        "no_speech_prob": 0.013409832492470741,
        "seek": 796000,
        "start": 7961,
        "temperature": 0,
        "text": " The budget that I have for this channel is small.",
        "tokens": [
          50414,
          440,
          4706,
          300,
          286,
          362,
          337,
          341,
          2269,
          307,
          1359,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22093410282344608,
        "compression_ratio": 1.6008064516129032,
        "end": 7972,
        "id": 2129,
        "no_speech_prob": 0.013409832492470741,
        "seek": 796000,
        "start": 7967,
        "temperature": 0,
        "text": " And I do use the Patreon funds for video editing and other production and design services.",
        "tokens": [
          50714,
          400,
          286,
          360,
          764,
          264,
          15692,
          8271,
          337,
          960,
          10000,
          293,
          661,
          4265,
          293,
          1715,
          3328,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22093410282344608,
        "compression_ratio": 1.6008064516129032,
        "end": 7977,
        "id": 2130,
        "no_speech_prob": 0.013409832492470741,
        "seek": 796000,
        "start": 7972,
        "temperature": 0,
        "text": " An app could be something that I would potentially want to invest some funds in having somebody develop.",
        "tokens": [
          50964,
          1107,
          724,
          727,
          312,
          746,
          300,
          286,
          576,
          7263,
          528,
          281,
          1963,
          512,
          8271,
          294,
          1419,
          2618,
          1499,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22093410282344608,
        "compression_ratio": 1.6008064516129032,
        "end": 7983,
        "id": 2131,
        "no_speech_prob": 0.013409832492470741,
        "seek": 796000,
        "start": 7977,
        "temperature": 0,
        "text": " But I also wouldn't be opposed to having a community built app that somebody works on for volunteer.",
        "tokens": [
          51214,
          583,
          286,
          611,
          2759,
          380,
          312,
          8851,
          281,
          1419,
          257,
          1768,
          3094,
          724,
          300,
          2618,
          1985,
          322,
          337,
          13835,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22093410282344608,
        "compression_ratio": 1.6008064516129032,
        "end": 7985,
        "id": 2132,
        "no_speech_prob": 0.013409832492470741,
        "seek": 796000,
        "start": 7983,
        "temperature": 0,
        "text": " If you're interested in that, please get in touch.",
        "tokens": [
          51514,
          759,
          291,
          434,
          3102,
          294,
          300,
          11,
          1767,
          483,
          294,
          2557,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 7991,
        "id": 2133,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 7986,
        "temperature": 0,
        "text": " The website is kind of right now living in this sort of volunteer place.",
        "tokens": [
          50414,
          440,
          3144,
          307,
          733,
          295,
          558,
          586,
          2647,
          294,
          341,
          1333,
          295,
          13835,
          1081,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 7993,
        "id": 2134,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 7991,
        "temperature": 0,
        "text": " But I'm not opposed to...",
        "tokens": [
          50664,
          583,
          286,
          478,
          406,
          8851,
          281,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 7996,
        "id": 2135,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 7995,
        "temperature": 0,
        "text": " I don't know what I'm saying here.",
        "tokens": [
          50864,
          286,
          500,
          380,
          458,
          437,
          286,
          478,
          1566,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 7997,
        "id": 2136,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 7996,
        "temperature": 0,
        "text": " But yeah, I'm not opposed to an app.",
        "tokens": [
          50914,
          583,
          1338,
          11,
          286,
          478,
          406,
          8851,
          281,
          364,
          724,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 7998,
        "id": 2137,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 7997,
        "temperature": 0,
        "text": " That would be interesting.",
        "tokens": [
          50964,
          663,
          576,
          312,
          1880,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 8001,
        "id": 2138,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 8000,
        "temperature": 0,
        "text": " Can you teach us Python?",
        "tokens": [
          51114,
          1664,
          291,
          2924,
          505,
          15329,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 8004,
        "id": 2139,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 8002,
        "temperature": 0,
        "text": " No, I don't really know Python.",
        "tokens": [
          51214,
          883,
          11,
          286,
          500,
          380,
          534,
          458,
          15329,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 8010,
        "id": 2140,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 8004,
        "temperature": 0,
        "text": " I was planning to do Python because I was going to use Python for all this neural networking machine learning stuff.",
        "tokens": [
          51314,
          286,
          390,
          5038,
          281,
          360,
          15329,
          570,
          286,
          390,
          516,
          281,
          764,
          15329,
          337,
          439,
          341,
          18161,
          17985,
          3479,
          2539,
          1507,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21468438940533138,
        "compression_ratio": 1.628352490421456,
        "end": 8013,
        "id": 2141,
        "no_speech_prob": 0.17325522005558014,
        "seek": 798500,
        "start": 8010,
        "temperature": 0,
        "text": " And then use a Flask server to talk to my JavaScript.",
        "tokens": [
          51614,
          400,
          550,
          764,
          257,
          3235,
          3863,
          7154,
          281,
          751,
          281,
          452,
          15778,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8017,
        "id": 2142,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8013,
        "temperature": 0,
        "text": " And then it descended from the Google.",
        "tokens": [
          50364,
          400,
          550,
          309,
          41311,
          490,
          264,
          3329,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8019,
        "id": 2143,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8018,
        "temperature": 0,
        "text": " DeepLearn.js came out.",
        "tokens": [
          50614,
          14895,
          11020,
          1083,
          13,
          25530,
          1361,
          484,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8023,
        "id": 2144,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8019,
        "temperature": 0,
        "text": " And that's really shifted my thinking into kind of really staying within the browser for this stuff.",
        "tokens": [
          50664,
          400,
          300,
          311,
          534,
          18892,
          452,
          1953,
          666,
          733,
          295,
          534,
          7939,
          1951,
          264,
          11185,
          337,
          341,
          1507,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8026,
        "id": 2145,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8023,
        "temperature": 0,
        "text": " But I do hope to add Node and maybe Electron to some of the stuff that I'm doing.",
        "tokens": [
          50864,
          583,
          286,
          360,
          1454,
          281,
          909,
          38640,
          293,
          1310,
          12575,
          2044,
          281,
          512,
          295,
          264,
          1507,
          300,
          286,
          478,
          884,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8029,
        "id": 2146,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8026,
        "temperature": 0,
        "text": " But Python I would probably want to have some guests for.",
        "tokens": [
          51014,
          583,
          15329,
          286,
          576,
          1391,
          528,
          281,
          362,
          512,
          9804,
          337,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8032,
        "id": 2147,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8030,
        "temperature": 0,
        "text": " Coding train app coding challenge.",
        "tokens": [
          51214,
          383,
          8616,
          3847,
          724,
          17720,
          3430,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8033,
        "id": 2148,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8032,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8034,
        "id": 2149,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8033,
        "temperature": 0,
        "text": " Oh, the song ended.",
        "tokens": [
          51364,
          876,
          11,
          264,
          2153,
          4590,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8036,
        "id": 2150,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8034,
        "temperature": 0,
        "text": " Okay, thank you everybody for watching.",
        "tokens": [
          51414,
          1033,
          11,
          1309,
          291,
          2201,
          337,
          1976,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8037,
        "id": 2151,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8036,
        "temperature": 0,
        "text": " This was a bonus live stream.",
        "tokens": [
          51514,
          639,
          390,
          257,
          10882,
          1621,
          4309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1797969567514684,
        "compression_ratio": 1.6213592233009708,
        "end": 8041,
        "id": 2152,
        "no_speech_prob": 0.015419482253491879,
        "seek": 801300,
        "start": 8037,
        "temperature": 0,
        "text": " I think that XOR was an improvement over my previous XOR challenge.",
        "tokens": [
          51564,
          286,
          519,
          300,
          1783,
          2483,
          390,
          364,
          10444,
          670,
          452,
          3894,
          1783,
          2483,
          3430,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20100170135498047,
        "compression_ratio": 1.6219512195121952,
        "end": 8048,
        "id": 2153,
        "no_speech_prob": 0.07052991539239883,
        "seek": 804100,
        "start": 8041,
        "temperature": 0,
        "text": " But I will let the wonderful Math Blanks, Mathieu, let me know what he thinks.",
        "tokens": [
          50364,
          583,
          286,
          486,
          718,
          264,
          3715,
          15776,
          2177,
          14592,
          11,
          15776,
          19347,
          11,
          718,
          385,
          458,
          437,
          415,
          7309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20100170135498047,
        "compression_ratio": 1.6219512195121952,
        "end": 8056,
        "id": 2154,
        "no_speech_prob": 0.07052991539239883,
        "seek": 804100,
        "start": 8048,
        "temperature": 0,
        "text": " And so tomorrow will come out the video series on unit testing and continuous integration with CircleCI.",
        "tokens": [
          50714,
          400,
          370,
          4153,
          486,
          808,
          484,
          264,
          960,
          2638,
          322,
          4985,
          4997,
          293,
          10957,
          10980,
          365,
          29381,
          25240,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20100170135498047,
        "compression_ratio": 1.6219512195121952,
        "end": 8059,
        "id": 2155,
        "no_speech_prob": 0.07052991539239883,
        "seek": 804100,
        "start": 8056,
        "temperature": 0,
        "text": " Thank you to CircleCI for sponsoring those videos.",
        "tokens": [
          51114,
          1044,
          291,
          281,
          29381,
          25240,
          337,
          30311,
          729,
          2145,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20100170135498047,
        "compression_ratio": 1.6219512195121952,
        "end": 8062,
        "id": 2156,
        "no_speech_prob": 0.07052991539239883,
        "seek": 804100,
        "start": 8060,
        "temperature": 0,
        "text": " I really like doing sponsored content.",
        "tokens": [
          51314,
          286,
          534,
          411,
          884,
          16621,
          2701,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20100170135498047,
        "compression_ratio": 1.6219512195121952,
        "end": 8066,
        "id": 2157,
        "no_speech_prob": 0.07052991539239883,
        "seek": 804100,
        "start": 8062,
        "temperature": 0,
        "text": " It's a good way to make what I do more possible.",
        "tokens": [
          51414,
          467,
          311,
          257,
          665,
          636,
          281,
          652,
          437,
          286,
          360,
          544,
          1944,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20100170135498047,
        "compression_ratio": 1.6219512195121952,
        "end": 8069,
        "id": 2158,
        "no_speech_prob": 0.07052991539239883,
        "seek": 804100,
        "start": 8066,
        "temperature": 0,
        "text": " So if you're interested in sponsoring content, you can get in touch with me.",
        "tokens": [
          51614,
          407,
          498,
          291,
          434,
          3102,
          294,
          30311,
          2701,
          11,
          291,
          393,
          483,
          294,
          2557,
          365,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8071,
        "id": 2159,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8069,
        "temperature": 0,
        "text": " Okay, thanks everybody.",
        "tokens": [
          50364,
          1033,
          11,
          3231,
          2201,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8073,
        "id": 2160,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8071,
        "temperature": 0,
        "text": " And Tetris.",
        "tokens": [
          50464,
          400,
          31580,
          5714,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8074,
        "id": 2161,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8073,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50564,
          407,
          510,
          311,
          264,
          551,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8076,
        "id": 2162,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8074,
        "temperature": 0,
        "text": " I need an idea.",
        "tokens": [
          50614,
          286,
          643,
          364,
          1558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8078,
        "id": 2163,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8076,
        "temperature": 0,
        "text": " If I go to coding challenges.",
        "tokens": [
          50714,
          759,
          286,
          352,
          281,
          17720,
          4759,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8081,
        "id": 2164,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8078,
        "temperature": 0,
        "text": " Snakes and Ladders was 91.",
        "tokens": [
          50814,
          9264,
          3419,
          293,
          12106,
          15633,
          390,
          31064,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8083,
        "id": 2165,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8081,
        "temperature": 0,
        "text": " So that XOR was 92.",
        "tokens": [
          50964,
          407,
          300,
          1783,
          2483,
          390,
          28225,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8085,
        "id": 2166,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8083,
        "temperature": 0,
        "text": " I'm getting close to coding challenge 100.",
        "tokens": [
          51064,
          286,
          478,
          1242,
          1998,
          281,
          17720,
          3430,
          2319,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8087,
        "id": 2167,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8085,
        "temperature": 0,
        "text": " I need a really good idea for that.",
        "tokens": [
          51164,
          286,
          643,
          257,
          534,
          665,
          1558,
          337,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16750019529591437,
        "compression_ratio": 1.5195530726256983,
        "end": 8091,
        "id": 2168,
        "no_speech_prob": 0.08507861942052841,
        "seek": 806900,
        "start": 8087,
        "temperature": 0,
        "text": " And Tetris is kind of on possibility there.",
        "tokens": [
          51264,
          400,
          31580,
          5714,
          307,
          733,
          295,
          322,
          7959,
          456,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2005280052743307,
        "compression_ratio": 1.5432692307692308,
        "end": 8100,
        "id": 2169,
        "no_speech_prob": 0.6294103860855103,
        "seek": 809100,
        "start": 8091,
        "temperature": 0,
        "text": " So if you have ideas for what's the perfect coding challenge to synthesize everything that I ever have done on this channel, let me know.",
        "tokens": [
          50364,
          407,
          498,
          291,
          362,
          3487,
          337,
          437,
          311,
          264,
          2176,
          17720,
          3430,
          281,
          26617,
          1125,
          1203,
          300,
          286,
          1562,
          362,
          1096,
          322,
          341,
          2269,
          11,
          718,
          385,
          458,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2005280052743307,
        "compression_ratio": 1.5432692307692308,
        "end": 8102,
        "id": 2170,
        "no_speech_prob": 0.6294103860855103,
        "seek": 809100,
        "start": 8100,
        "temperature": 0,
        "text": " Okay, goodbye everybody.",
        "tokens": [
          50814,
          1033,
          11,
          12084,
          2201,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2005280052743307,
        "compression_ratio": 1.5432692307692308,
        "end": 8104,
        "id": 2171,
        "no_speech_prob": 0.6294103860855103,
        "seek": 809100,
        "start": 8102,
        "temperature": 0,
        "text": " I will see you hopefully on Friday.",
        "tokens": [
          50914,
          286,
          486,
          536,
          291,
          4696,
          322,
          6984,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2005280052743307,
        "compression_ratio": 1.5432692307692308,
        "end": 8108,
        "id": 2172,
        "no_speech_prob": 0.6294103860855103,
        "seek": 809100,
        "start": 8104,
        "temperature": 0,
        "text": " And if for some reason Friday doesn't work out, I won't feel guilty because I did a bonus stream this week.",
        "tokens": [
          51014,
          400,
          498,
          337,
          512,
          1778,
          6984,
          1177,
          380,
          589,
          484,
          11,
          286,
          1582,
          380,
          841,
          12341,
          570,
          286,
          630,
          257,
          10882,
          4309,
          341,
          1243,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2005280052743307,
        "compression_ratio": 1.5432692307692308,
        "end": 8110,
        "id": 2173,
        "no_speech_prob": 0.6294103860855103,
        "seek": 809100,
        "start": 8108,
        "temperature": 0,
        "text": " Okay, goodbye.",
        "tokens": [
          51214,
          1033,
          11,
          12084,
          13,
          51314
        ]
      }
    ],
    "transcription": " Good afternoon and welcome to a special extra bonus live stream. As you know, I typically, well I don't know if you know this, but if you're watching or if you watched before, I typically live stream on Fridays. I'm sorry, this music is just so catchy, can't stop enjoying it. It's gonna be over soon. I try to time it where I come in right when there's about 10 to 15 seconds left so the music can trail off to the end. But it was at like 35 seconds, so now I'm just kind of waiting for it to end. Okay, it's over now. So here I am. I had something get cancelled today that I typically often have to do on Wednesday afternoons. I have been aspiring for a while to do more often shorter live streams than less frequent longer live streams. As much as some people might enjoy the three or four hours at a time of live streaming on a Friday, I do find that the content somewhat suffers, especially towards the end. And if I can find little pockets of time to record a video, to do a tutorial, to update something. And so today actually I was thinking, oh I have this extra bit of time, what I'm gonna do is I'm gonna sit at my computer and go through a bunch of pull requests on the toy neural network library that I built last Friday. And then I thought, eh, I might as well just live stream that because I've got some questions around that and I can talk about it. I don't see anybody saying that they are listening. Oh, they are. Okay, for a second there I thought, did I just totally not hit the start streaming button? The other thing was, is I've had this cold and I was kind of sick on a little bit last Friday and much more over the weekend and Monday and I thought, oh I'm all the way better now. And then all of a sudden I'm talking and realizing, eh, there's still a little bit of scratchiness there. So I will be here, it's about 2.30 my time, Eastern time now in New York City. I will probably live stream for one hour, possibly a little bit longer, but this is gonna be a shorter live stream. And I have two plans, I have two plans for today. One is, let me just open this up here, a web browser, is to use a web browser. And I'm going to go to this GitHub repository. This is the CodingTrainToyNeuralNetwork-JS GitHub repository. I have actually now, oh, a couple of things. One is, you can now go to, I have arrived finally. You can now go to YouTube.com slash TheCodingTrain and it will take you directly to this channel of which you are watching. And there you will see a check mark, because I am verified. It is me, a verified person. Check, check, I am here, I am truly here. And if you're wondering if it's true, it says it right there, that it's me, that says it's me. So I have been releasing these, and in fact let me find the playlist for it. Because I think that will be most useful. Here we go. Oops, don't play the video. Just go here. So this is the playlist, starting off just with an introductory video to the idea of neural networks. I built a simple perceptron, I talk about a multilayer perceptron, then I do a bunch of matrix math things. Then I look at the feedforward algorithm, and then I continue looking at that. And then, as you know, I struggled massively through the backpropagation training process, but I did five videos and finished that off. So that's, everything in all of those videos has now gone into this neural network JavaScript library. So, and I've been getting some lovely pull requests, and so I want to look through some of these and merge them. So that's item number one. And I will mention, in case you're wondering, oh, so much stuff to talk about. I will also mention that if you are looking for the code in the state exactly as is when I finished that part five, that I am putting here under courses, nature of code, 10.18, toy neural network. So that's in my, the repo that has all of the code for all of the videos. And so this is kind of like a frozen state of the code as it stands at the end of that particular video. And then I will allow this repository to grow and improve. And one of the reasons why I'm doing this project is I intend to start using two other frameworks. So I've mentioned before, deeplearn.js is a project from the Google Big Picture group, Google pair initiative, people and AI research. It is a, you know, one way you might think of it is a TensorFlow, but in the browser. So this is a library that I intend to use in further tutorials as I get further along down this road. And in fact, related to that is a project that is being worked on at ITP, itp.nyu.github.io.ml5-js. This is another repository URL that you might take a peek at. This is now a high level JavaScript library for machine learning. So this is a library that's built on top of deeplearn.js to make using deeplearn.js a bit easier for beginners, specifically beginners who might be learning to code with p5.js. And so for example, there's some nice examples here. Here is an example of simple image classification using a pre-trained model. I will talk about eventually what all these things are. And you can see here the code is simple in that you can just say, you can ask the model to predict what it thinks about an image. You can look at the results and update what's on the page with the results. So there's a lot of stuff like this that you can start to look at. You can look under experiments, which are some things that people have built with this. But this library is, you know, less than two months old. So this is a brand new thing, and I will be doing many more videos with this library. So part of the reason why I'm building my own kind of toy version of a machine learning library is just to really understand how all the pieces work, so that when I start to use other libraries and frameworks, I can have a kind of language to speak about them and, I don't know, some experience. So anyway, so did I say I'd be streaming until 2.30? I did, yeah. I meant an hour or so. So it's 2.30 now, until 3.30 or so. Okay, so that's two things I want to mention. And then on Friday, I did the XOR coding challenge. And I thought I would just, for some reason, I don't know why, I just felt like I wanted to do it again. Because a couple things. One is I got some interesting comments. One thing that I think would be really useful to demonstrate is if I manipulate, like, okay, well, what if I use four hidden nodes instead of two hidden nodes? And I just didn't have that as part of the tutorial, which I think would be really useful. But also, I felt like I wanted to have some distance from the library. I just was at the end of, like, hours and hours and hours of doing the backpropagation. And I really want that video to kind of stand alone in its own way and be disconnected from that. So I thought maybe I would try it again and see what happens. Okay, let's see. So now, what do I want? While I'm here, let me mention a couple other things. This repository, coding train slash rainbow code, which ostensibly, if you're not looking very closely, is just a repository that has all the source code from all of my video tutorials. Right? You can say, like, oh, look, I want to find code for one of the coding challenges or one of the p5.js courses or the node sockets playlist or code that was one of the Q&A videos. I don't know, tutorials, courses. There still could be some work done on organization here. But you'll start to notice, oh, what is this underscore, underscore, underscore? There's all this stuff. Landing page. And then all of a sudden there's readme.md and contributing.md. Oh. So this repository, thanks in large part to many contributors, but most notably Neils Webb, has turned into the repository which is also the coding train website. Now, I will open this up a bit wider. So this is the new coding train website, a sort of work in progress. And each video now has its, if it's put into the website, has its own page. So, for example, the latest video is here, snakes and ladders part three. And this would obviously take me directly to the video on YouTube. But if I click on this link here, it will take me to a page which has the video in bed. It has a link to run the example in the browser. So here's the example running in the browser. It has a link, this link will download the code, a little description here. And then, ah, a place for community contributions. But there aren't any yet. But you can add your own by looking at this guide. So you can submit a pull request to add yours. There's links that were discussed, links to the other parts of the video. So this is an attempt to create a more navigable version, a more navigable system, for finding and looking through all the videos separate from the YouTube interface, as well as aggregating and collecting community contributions and relevant links and source code and that sort of thing. So I think this website, as remarkable and amazing and beautiful as it is, it's just like tremendous that Niels Webb was able to just put this all together. It runs on something called Jekyll, which is a static site-generated templating engine that works well with GitHub Pages. I think it could still use work in visual design, and it's missing a lot of content. So I encourage any of you who are interested in kind of learning to participate in an open-source project, here's one for you. If you want to make a design contribution or add some content that's missing, let me know. Let me know at Shiffman on Twitter. You can read, hopefully, the documentation that's in the GitHub repository. I would love to have people help with that. All right. Is he sick? Right? Yes. Yeah, I thought my cold was gone, and that's why I felt comfortable. I feel so much better, but I think the congestion is still lingering in my throat. So I don't know. Oh, I have a—hold on. Let me just check here. Okay, okay, okay. All right. Just looking at some messages here. Let me go back to the live channel. What I'm looking at over here, by the way, is a Slack channel. I often get the question, oh, how can I ask a question or get help? So, of course, I would always recommend that you use— a forum that goes well with a lot of my videos is forum.processing.org. You can get in contact with me on Twitter, but I also have a Patreon. And if you join the Patreon at patreon.com slash codingtrain, that's where you'll get an invitation to the Slack channel, which I participate in. But honestly, the thing about the Slack channel that's great, the idea was like, oh, I could help people with their code if they sign up and subscribe. But there's so many people already now in the Slack channel who know way more than I do and are much more helpful. So it's kind of built itself into a nice community there. Okay. I'll take a couple questions from the chat. Ricardo asks, have you ever thought about going full-time YouTuber? Actually, I have thought about it. Some ways I might be interested in doing it, just so I can say full-time YouTuber. It sounds like a weird thing, like a crazy thing to say. I do have a full-time job that I love. I live in New York City, which is a very expensive and complicated place to live. And the job where I have is at a program called ITP at NYU. In fact, that's where I'm recording these videos. So while I fantasize and think about it sometimes, I don't know if it's realistic for me at this point. And I wouldn't want to give up the wonderful in-person community and teaching stuff that I'm able to do through working here. But it's an interesting question. Ben Anderson asks, could you explain to me the basic premise of neural networks? So that's where I would recommend starting with this neural networks playlist. So in theory, I don't remember at all what's in this video. I made it quite a while ago. But it does say introduction to neural networks. And I believe I do cover in that video the basic premise of neural networks. And I will rehash that again when I start doing the XOR coding challenge. And I also would recommend the 3Blue1Brown neural network channel. Yes, moving upstate and becoming a hermit is an excellent idea, was the suggestion for how I could become a full-time YouTuber. And dye my hair green. Okay, ah, this cold. This is not, this is not, I've been silent I guess all day and didn't realize. Okay. So I'm looking at the chat. There's a class going in behind this wall. And they're watching a movie right now. I can almost hear what it is. What's the chance you can hear it if I put my microphone up to the wall? I probably just made a horrible scratching sound as I put the microphone on the wall. All right. So let's get set here. Okay, so the first thing that I want to do is I want to look through the pull requests here. And let's think about, let's do this backwards. So I'm going to look at the oldest pull request and move up and see which of these I can merge. Now one thing you'll notice is they all have a green check mark. And that green check mark is because I added unit testing. Testing to make sure the code does what it should be doing before it can be merged. So let's see. Use matrix constructor to, okay. So tidied up the construct, this is from Phila Turner. Tidied up the constructor a little bit. Plus I've never done a pull request before. Amazing. Could this possibly be Phil A. Turner's first pull request that we are hopefully going to merge? Okay, then I wrote apologies, can you resolve the conflicts? I love this change, but since I haven't explained Phil in a video yet, I wonder if it will be confusing. I'm just here reading my comment. Or maybe this means I better just get to explaining it. Conflicts are resolved. And I'm noting another issue that I discussed this in. But let's take a look at the code changes here. Under files change. Excuse me. Ah, so first of all, this is a wonderful little addition here, but I'll come back to that. So look, this is the change. This is my ugly long-winded way of creating the two-dimensional array to store all the values in a matrix. And now instead, and shouldn't this say, should this say new array? Or is it okay to say, oh no, it's array.phil.map, array.phil.0. So it passed the test, so I can assume that, I think this looks pretty good to me. But let's, just so I have this on record here, if you haven't seen Phil before. Where is Phil? Now, if you haven't seen Phil before, JavaScript array functions. Alka in the patron group is saying it's fine, it's ugly either way. So the array object has a whole bunch of functions built into it like fill, find, filter, map, reduce. And I really should make a list of, let's make a list of these. Let's go to rainbow topics under issues. And let me look at array, let's see if there, I think I have one that's talking about arrays. Like array higher order functions in JavaScript. So I definitely should do this. Okay, let's, making a list of functions to cover. So I am going to add a fill here. So by the way, in GitHub at issue, if you do, you might not be aware of this, if you put this notation, this will leave a checkbox. And if I put this notation, it will leave a checkbox that's checked. But I haven't made it yet. So I know I want to cover fill, I know I want to cover map, I know I want to cover reduce. And probably filter, right? These are some array functions that I want to eventually cover. So maybe in the chat, if there's some that would be important. So I am now going to, where am I? Merge this pull request. Whoops, not this one. Where is it? Ah, here we are. I'm going to go back to conversation. And I'm going to say merging this live on air and noting to make a video about fill here. Okay, comment. And here we go. Okay, I kid you not. I'm in the middle floor, which is the film school here at NYU. And so they're always watching movies, I think, in the classroom next to me. So I can hear the soundtrack. I don't know if you can hear that. That was totally a train going by. It was like a very loud train going by. I'm here with you people in the next room. We are one on the train. All right, here we go, merging. Confirming. All right, thank you, thank you. That was a merge. That was a pull request merged. Alka is mentioning sort. I've actually talked about sort in a video. I don't remember which one. But I have a very distinct memory of using sort. But it would be worth mentioning or covering in that context as well. Thank you for that. All right, so we got one pull request done. Now, use ES6 exported import functions. Okay, this I'm not ready for yet. There's a nice discussion here. It's also out of date. But let me see if I can update it. That should be fine because I merged that other pull request. It's going to run the tests again. Let's look at the files changed here. Yeah, so this is using ES6 modules. And I feel like I'm not ready for that yet. But I really should add that soon. It will fix the whole testing stuff. So maybe I need to do a video about that and understand that better. Because it's got the export here. And it needs this like babble thing. So I could be talked into this. But this I don't feel ready for. Even though I'm super thankful for this wonderful thoughtful pull requests. Okay, so now updated to-do list. Oh yeah, this was a... Oh yeah, this was somebody who added and fixed up the to-do list that was in my nn.js file that I just put in the comments. And I guess I've done all these things now. Except for the MNIST coding challenge. I'm going to redo the XOR coding challenge today. But I did make a comment about this one. Which is I thought this might be better in say the readme. So I'm going to... I'm going to merge this right now. Because why not merge? Merge this for now. Merge this for now. But maybe someone will pull request a new place for the to-do list. Now interestingly enough, I cannot merge it. Why is this there? It's because it's got to run the tests again. And it's probably waiting. Let's see, show all checks. Oh, it passed. So what test has it not run yet? That it won't... Interesting. So I'll come back. I'm not sure why this one won't allow me to merge it. By the way, if you're wondering what's going on with why this merge button is not available. I did a whole video tutorial series about unit testing and continuous integration. And there's a live stream which already is online and archived. But the actual edited videos are prepared but haven't been released yet. Those will start coming out tomorrow morning. Okay. Alright. Yeah, me, I am, so me is... Yeah, so if I were doing this properly, I would probably want to check a bunch of these things locally. But I'm just living on the edge. I'm doing this just through the GitHub interface. But I could pull the branch and have it local, test it out, run the test myself. And I really don't understand why this one is not merging. But I'm going to come back to here. Updating transposed tests. So this is a pull request that came in about the transposed test. And I added some comments and requested those changes. Those changes have not come in yet. So I'm going to leave this one alone. Added more transposed tests. And let's see if I can, let's run this update. So it's running the tests. Now there's some music playing in the other room. Alright, we got to wait for the test to finish. I could go on to a different pull request. But I like just waiting. I like to see it just like... By the way, we could see the test, I think under details. Yep. Let's watch the test going. Here it is. It's running it. Oops. Sorry. Oh, they all passed. All the tests passed. So it should now... Say the test passed. Yep. Alright. Let's look at what this code was. So this looks like it's adding a test for transpose. It's checking a 1x1 matrix. Then it's checking a 2x3 to 3x2. Checking a 3x2 to 3x3. Checking a 3x3 to 3x3. Checking a 3x3 to 3x3. Checking a 3x3 to 3x3. Checking a 3x2 to 2x3. This looks good. Checking a 1x5. This is nice. I love this test. Okay. Great. I think this looks good to me. We need tests for the tests. And again, I should look this over more carefully. But you know, this is just an open source project for fun. I'm so appreciative. Merge. And then... Confirm merge. And we have merged this pull request. Thank you to Mikhail Sousa. Who submitted that pull request that is now merged. Okay. Now, map improvements. Oh, this one I'm excited about. Map improvements and using map instead of two nested for loops. Oh, another reason why I want to redo the XOR challenge is I was playing with the learning rate and it wasn't working the whole time because I had the wrong variable name. And this pull request is going to help us with that. So, I am now going to go to map improvements. So, let's do this. Let me look at this one. Okay. So, made map pass the row and column to the callback function. So, this is really useful. I have a map function in the library, which I could pull up. And the map function expects a callback function that it applies to every element. And sometimes you want to know the column and row or the row and column indices. And I didn't implement that. So, this implements that. And then it also has a lot of use of the ES6 arrow notation. So, I wasn't sure about merging this just yet. But now that I have the original source code backed up, let's take a look at this. So, first of all, let's run the tests again because I'm sure it's... Oh, we've got conflicts now. Oh, so sad. So, unfortunately, there's some conflicts here because some of the other merges changed the same. So, you get a merge conflict. And I need to do a whole video about this. I have this on my list in my GitHub series. You need to do a merge... Oh, all right. Let's do a video about it right now. This is great. This is going to now be a tutorial that will go in my GitHub list. All right. We're going to resolve this live. I have a new sponsor. You know I've always sponsored by water. But this was... I don't usually like to destroy the earth. I have to stand over here and drink my earth-destroying water. All right. All right. Hello, surprise! It's a video about Git and GitHub. And this video is about resolving merge conflicts. So, I probably should be doing this video in my poem repository, which I use for all of my intro to Git and GitHub videos. But I happen to be here streaming live and working on this neural network library that I've been building in a bunch of other video tutorials. So, if you just watch those Git and GitHub videos, all about using a poem to sort of demonstrate how Git and GitHub works, there will be some aspects of this that are confusing. But hopefully this will be helpful anyway. And I can always double back and make another video if this one doesn't work. But let's just try it. So, what is a merge conflict, first of all? So, a merge conflict is when you have, let's say, this is a file. And in this case, it's my file called matrix.js. So, I have a file called matrix.js, and it has code in it. Now, I had two people, two separate people of the internet, happen to be working on this file. So, we'll call one person A and one person B. Now, any text file has lines in it. So, even if it were a poem, it would have lines of the poem. If it's a source code file, it has lines of the source code. So, we can think of the lines as like 1, 2, 3, 4, 5, 6. Now, if person A makes a change and submits a pull request, meaning, hey, hey, you, the library, please pull my changes, right? I want to push my changes to you, but I'm asking, requesting that you pull my changes. If this person just made changes to lines 5 and 6, and this person just made, and this person's doing the same thing, but made changes to lines 2 and 3, the git system is smart enough to figure out how to pull both of these things in with no conflicts, because there are no conflicts. If I want to accept changes to lines 2 and 3, I can accept those at the same time, one before the other, simultaneously, you can't really do it simultaneously, as lines 5 and 6. However, if right here, person B makes a change to line 4, and person A also makes a change to line 4, then we have what's known as a conflict. And typically, what will happen, and what just happened to me right now, is I merged this one. I merged this one, wasn't thinking about it, it was done, it's finished, and it worked fine, it merged with no problems. But now when I went to merge this one, I got a message saying, resolve conflicts. Now, there are a variety of ways you can resolve conflicts, and I think that I've, in some of my previous tutorials, looked at working with git command line locally, and I could have the text file there, but what I'm going to do is see if I can resolve the conflict just through the github interface itself. So let's take a look at how that works. Now, once again, this isn't the best scenario, and I might come back and do a follow-up, because it would be nice to see a trivial example where I can really know what the changes are, but I'm just going to look and see, there's a whole discussion here, and we can see these are the files. These are the files that have conflicts in them. Matrix.js and Matrix.test.js. So hopefully you can continue to watch this, even if you don't understand what the code in those files is doing. I'm going to look and see what the conflicts are. Oh, this is definitely going to go down the internet tubes really quickly. So I'm going to click this Resolve Conflicts button, and now it's, ooh, look at this. Ooh, okay, alright. Oh, I'm in Matrix.js. Hmm, okay, I have to figure out what's going on here. So we can see, ah, look, this is where the conflict is. Oh, look, I think I know how to resolve this. Okay, so this is where the conflict is. Now, what is it telling me here? Map improvements, master, equals, equals, equals, equals, greater than, greater than, greater than, greater than. So what this is showing me is, this is showing me through kind of like a visual interface of the text file that there are two proposed ways that this code could run. One of the files had it this way, and one of the files had it this way. In fact, the current master has it this way, but the one that I'm trying to merge has it this way. And why does this one have it this way? This is the thing that I changed. I want it this. So it's up to me. Now, there's no right or wrong answer here. As the kind of proprietor of this GitHub repository, I've got to decide if both pull requests worked on, worked on, sorry, if both pull requests worked on the same line, I have to pick one. Which one do I want? And I want, I'm going to take this one at the bottom. So I'm going to delete, delete this, and I'm going to delete this. Whoops! What did I just do? I'm going to delete this. Now, if only I knew how to use a computer. I'm going to delete this. And now, are there any other conflicts? Please be, no other conflicts. Oh, I'm so lucky. I'm going to now say, mark as resolved. Now, one thing you can do if you're the proprietor of a GitHub repository is you could just write to the person submitting the pull request, I'm so sorry, but some conflicts arose. I love your pull request. Do you think you could refactor it? Because you could leave this up to the contributor, certainly. But I'm here, live on the internet. I mean, maybe I'm not live anymore. I'm recorded. And so there we go. Oh, no. Okay, ah, so now I have this other file. Let's look at this. I might just quit while I'm ahead here, but let's see if I can look at this other file. So this code might look very strange to you. This is something called unit testing. And actually, related to this video series, I have a video series that I will link to in this video's description about how you can run automated tests that make sure a change in your code doesn't actually break your code. That's what this is doing here. So there's map improvements. That's the pull request. And master. You know what? I think this is a very trivial change. It looks to me like this was just added at the end, and there was a line break or something that caused a merge conflict. So this looks like something that I could actually just completely delete here and then delete here. And this is just some new stuff that got added to the end as part of this pull request. There was an extra line break or something, so GitHub detected a conflict, but it really was not a conflict. So now I can go and I can click mark as resolved. And look at this. Commit merge. So here's the thing. Where am I right now? So I resolved all the conflicts. Do I want to do this? I think this button, if I'm right, is not actually I'm looking at the chat to see if anybody's complaining about what I've done. It's not actually merging the pull request. I think this is the committing the resolution of the conflicts to the pull request. Let's find out. It's a green button. When I see a green button, it just makes me want to click it. Click. So I think the pull request is still going to be live and active. Boy, it's taking a while. Yes. All it did was fix the conflicts. Where can I find that that was done here? Yes, that was this. So this is me. Now there's a little note that I merged branch master into map improvements. That's basically saying there were conflicts between master and map improvements. This pull request was map improvements. And there was me merging them together and resolving the conflicts. And now I can actually go ahead. The conflicts are resolved, and I can merge the pull request. Nothing exciting is going to happen. It really should. Confetti should explode. Confirm. But I can make something happen. Yay. Okay. So that was a video about resolving merge conflicts through the GitHub interface, the sort of basic gist of it. Perhaps I missed something important, and I will certainly make a follow-up video. So let me know what I missed, what questions you have in the comments. And thanks for watching this video about merging or resolving conflicts, merging them with a pull request, something, something, GitHub. I don't know. Search engine optimized keywords. Throw them in there. Okay. Bye-bye. All right. What's wrong with the – is the mic – is the mic performing poorly right now? Am I having sound issues? Because if it is, I would like to fix those. No sound issues. Okay, great. All right. So now that we did that, where am I? Add neural network. Oh, look, I love how live while I'm streaming new pull requests are being opened. Thank you, Adam Morris, for that. That's fantastic. Okay. Add a neural network learning rate setter. Thank you to Arsanguinetti. You know, I really just need to work on pronouncing people's names. Let's look at this. Okay. Oh, oh. So is this actually, dare I say, using – oh, so this adds a setter. I probably do want – oh, no, a setter. Yeah. So this – is this actually using this thing that I don't really know about, which is ES6 getters and setters? Do I have a Rainbow Topics issue keeping track of that? I kind of want to talk about that at some point soon. Where is my – hold on. Sorry. I dripped some water on the track pad. Then I pressed some buttons by accident. Rainbow Topics, where is that? So ES6. Prototype, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah. Getter. Nope. So we need to do ES6 getters and setters. I need to do a video on that at some point. Okay. So now we're back here. So I think this looks good to me. There's some – so this can happen a lot, which is unfortunate. It looks like in this pull request some extra white space was added here, like either a tab or some spaces, which made Git think that these two lines are different. This is a little bit of noise that if I were a real stickler, I would kind of want to not be in here. But I'm not a stickler, as you can tell from me just merging stuff. And so now I'm going to say I'm going to update the branch. I'm going to write thank you. It's going to be running its checks. Let's watch the checks run. It's running NPM install right now. And now it's running the tests. Perfect timing. Wow, half an hour has passed. 3.15, boy. I take way longer to do anything than I think. Okay. So now I think I've finished. Yep, merge. Okay, that has been merged. Back to the pull requests. Update readme link to – okay, let's do this. I think this is exactly what I think. Oh, yeah, perfect. So this is great. This is a nice link to – this is a nice link that if anyone is looking for the original source code with the video, they can find it. And by the way, if anybody else wants to do this pull request, if you can go to this repo and add a link from here back to here, that would be awesome. It might already be there. So let's merge this one. Tests are still running. Looks like it's finished now. Merge pull requests. There we go. Oh, I didn't – okay, we'll merge the pull requests. One more to go now. Create a to-do list. Oh, out of date. Let's update it and let's take a look at it. Okay. We use semver for versioning. We do? I never even heard of that. That's something I have to learn about. Semver for versioning. So this is like some noise, some line break noise that got added in here by accident. This is now the to-do list. And they got removed from here, which is great. I will say that most of this to-do list is done. So probably what I would do – but I'm just going to – I'll do this change myself. This is – and this page is out of date. Refresh. I'm going to merge this. And there's some music playing in the room next door that you guys can't hear, but I can hear. I'm going to go here now to the read me. I'm going to click edit. And where's the to-do list? Where did that to-do list end up? It wasn't in the read me? Oh, yeah. That's so funny. I looked at that pull request and just assumed it went here. Where did that pull request go? Closed. Create to-do list. Oh, separate to-do.md file. Okay, there we go. Obviously. I'm going to go here. I'm going to edit this. This – whatever this is was done. This was done. I mean, this to-do list is almost silly now, but this was done. This was not really done. Different activation functions. XOR coding challenge. Oh, this is not done. This is not done. And I'll add some other things. Add support for multiple layers, multiple hidden layers. And I'll actually change this to support for different activation functions. This is something I would like to do with this library. And these could be issues, but combine with ml5 slash deep learn js. Okay. So let's add this. And I'm going to make a pull request. This repo is so protected that even if I'm just editing one of the markdown files and I am the administrator of the repo, I cannot merge this change into master without these tests running. So we'll see if these tests run. Okay. They ran. They passed. I'm going to merge. All right. We're in good shape now. We are now able to do some coding. And I really wish I had not closed the playlist because I'm going to need that. Or this. So now let me open up terminal. Let's go here. Open. Come on. Come find your window. There you are. Examples. XOR. So one thing I'm going to do is, yeah, I'm going to leave this here. It's fine. Git status. Git pull origin. Oh, I'm standing in front of this. So I want to get all those changes now to have them locally. Oh, what did I change here? There's nothing there. Okay. And then what I want to do, ah, I should do that iterm tutorial now, shouldn't I? And then let's just run the tests locally to make sure everything is kind of going well. Okay. There's 20 tests now. They all passed. That's awesome. And let's open this up in Atom. Let's run a local server. Let's go to the browser. Now, this is the example I made before. I'm going to completely wipe this example and start over. So let's do that. Okay. Please hold. I need to tie my shoe, drink some water, and blow my nose. Oh, I'm out of tissue. Oh, no, I have another one. I will mute myself right now. I'm not sure why I have this extra jacket on. Remove that. Let's do the job for today. Okay. Here we go. Okay. It's all quiet now. I think it's time to read just a few random numbers to get warmed up. To relax, go into a sleepy slumbered state of neural network training. 38,271. 54,967. 58,046. I really need progressives. 22,950. This is actually how I read now, or I do this. 22,950. 97,533. 61,932. 5,199. 65,968. 69,784. 25,659. 74,954. 11,139. 32,340. Okay. Yeah, I know I said I was going to leave at 3.30, but I like to say I'm going to leave like way earlier than I absolutely need to leave because, as you know, I never, as much as, I barely ever start on time, let alone finish on time. All right. Energy, people, energy, places, places. We're about to get started with the coding challenge. Why is my, I'm getting a notification on my Fitbit from Slack that someone said zzzz. Okay. By the way, I am committed to somehow, most likely through the magic of artificial intelligence, if I ever hit 1 million subscribers, I will read all 1 million random digits in a video. Again, though, I have a feeling that it's going to end up being a computer generated me reading all of them because the amount of time it would take is absurd. I would love to do something, I could do something that takes like five or six hours, some kind of marathon thing, but I think it would take me a week without sleeping, which is very unrealistic and not good for my health. Okay. So, I'm looking at the chat. Let's see, I don't know how many viewers I've lost. Hopefully a lot. Oh, I've been looking for this for the longest time. It's a sleeve. By the way, for this computer that goes here, this is going to blow your minds. Whoa, look at my magic sleeve that doesn't fall down. Magic trick. I'm like a regular internet video magician. Watch this. I am hiding from you. Okay. Amazing what a little green paper will do. Okay. It would be great if I could warn you about a mistake by making your watch notify you. If you're at the whiteboard, it's impossible to get your attention. Yes. So, the thing is, I will actually get in Slack, if you at shift in me, it will notify my phone, which will often, I usually turn it off. I usually turn notifications off, but I did just have them on just now because I forgot about that. And so, I can get, oh look, Simon sent me a nice picture of how getters and setters work. I could potentially, Alka, get a notification today. You could try that if I really mess something up. Now, I'm going to, I have a totally different way I'm going to do this video right now. Okay. Hold on a second. Okay. Let's give this some time here and see if this will work itself out. I'm just waiting for the neural network to learn. I'm going to use this as a visual, visual aid, visual reference. All right. That's good enough. Okay. Hello. Welcome to a coding challenge. In this coding challenge, I'm going to make a version of this. Wait a second. Do you guys see? Is there like a smudge? Hold on. Is that just like, where is that smudge from? Oh, weird. That's just like an artifact on my screen. That was so weird. Did you see that? Oh my goodness. All right. Starting over. Hello. Welcome to a coding challenge. In this coding challenge, I am going to, this is going to sound really weird, solve XOR with a neural network. Now, why would anyone want to do this? Why would I want to do this? Well, what this is actually, this is a video in which I'm going to test a neural network library I've been building in JavaScript. And in fact, if you want to follow along with that process of building it, there is a giant playlist here starting with 10.1, introduction to neural networks, and I start building that library actually around, oops, don't play the video, around 10.4. So this video is a standalone video where I'm going to make use of that library in a coding challenge. You don't have to have watched all those, but if you want the background with a bit more to go deeper in how the internal mechanics of this neural network that I'm going to use works, I would refer you to those videos. Now, what is this crazy weird visualization going on over here? So let's, I'm going to come back to it in a second, but let's come over to the whiteboard. So this is an example, a very beginning basic rather trivial example of machine learning. And what do I mean by that? I mean, I'm going to draw a circle here, and I'm going to write ML, short for machine learning. And you can think of this as a place where there exists some machine learning recipe, some algorithm. You might have heard of k-nearest neighbor or neural network, fill in the blank, support vector machines. So fill in the blank with your machine learning algorithm there. With a machine learning algorithm, something goes into it, data. How you collect your data, how you're thoughtful about that, what the data is, how you quote unquote normalize your data. So there's so many questions, ethical questions, scientific questions that go into this piece. I am not covering that piece in this video, but there needs to be some data, something that I want to analyze or learn with. That's the data portion. And then, that data goes into the magical machine learning recipe, and out comes some output. Now what that output could be, it could be a piece of music that I've generated. It could be a classification of an image. It could be the price of a house that I'm trying to predict based on some data. So there's so much possibility here, and this output doesn't have to be a single thing, but can be multiple things. The input obviously, the data can be multiple things. This is the idea of machine learning. Now, I spent all this time building what is mostly like a toy neural network library. It's written in JavaScript, there's nothing about it that's optimized, but just to kind of understand the pieces of how it works. So what I want to do is have my recipe be in there, be a neural network. And I want to create some scenario where I have some training data. So what I'm going to do, this is going to be a demonstration also of the machine learning process called supervised learning. Supervised learning. Meaning, I am the supervisor, and I am going to teach this machine learning recipe to produce output, that appropriate output for a given input. Now, if I just know all the answers, why would I even do this? Well, likely there's a scenario, machine learning is going to be used with a scenario where I have a lot of labeled data. I have a known data set that I can use to train this system, so that if I give it some unknown data, it will give me an output, a relevant output. Classic example of this, of course, is I have a whole bunch of images. I'm going to say, here's a bunch of, I'm going to tell the recipe, here's a bunch of cats, here's a bunch of dogs, now here's a new... Here's a bunch of cats, here's a bunch of dogs, now here's a new image, which one is it? And along with this process, we will typically have training data. This is labeled data for which we know the answer. We will have testing data. This is data that we know the labels for, but we aren't using in the training set, so that we can see, is it working? Does it actually give us good outcomes with unknown data? And then, of course, we have the actual unknown new data that we want to use. Okay, so what's the scenario that I'm going to use? The trivial, almost rather ridiculous example that I'm going to use in this video is the XOR. XOR stands for exclusive OR. It's a Boolean operation that resolves to true only if... So you can think of true and if true XOR true is actually false. I didn't finish my sentence. It resolves to true only if one of the two Boolean expressions is true. So false XOR false also is false. And if you go back to my video that's linked here about the perceptron, you'll see that this is a special problem because a single simple perceptron, a single neuron machine learning system cannot solve this problem. It is not linearly separable. The solution space is not a space where you can just draw a line and see all the categories of one on one side and all the categories of the other on the other side. So you can dive into that deeper but this is where a neural network that involves a hidden layer can be used as the machine learning recipe. So what I mean by this is I need my training set. My training set is going to be 0 0 0 1 1 0 1 1. I only have four elements in my training set and each one of these is labeled. This is labeled with a 0. This is labeled with a 1. This is labeled with a 1 and this is labeled with a 0. This is the known data. Again, this is a sort of trivial. You could build a circuit. Imagine what it would take to build a circuit with two switches and the LED only lights up if one switch is on. If they're both on it doesn't light up. If they're both off it doesn't light up. Think about how you might build that. That's essentially the going that that diagram of that circuit is essentially what we want the neural network to look like. So the way that it's going to look and let me erase this here is we can see here in my labeled data set that there are two inputs and one output. So the neural network structure has to have two inputs and one output. I'm going to send in X1 and X2. These are true and true, true and false, false or true and somehow out of this I should get a Y. I should get a true or false. So how you architect and structural a neural network system this is something that I've gone into much more depth in the other videos. But the key to this problem is having what's known as a hidden layer. So the inputs come in here. I want to look at the output here but these neurons are going to exist in between. So everything this is also what's known as a fully connected network. So as the inputs come here they both go into this hidden layer. Some math happens. This is the math that I go over in a previous video. It has to do with multiplying by weights. These are all weighted connections. Then those go into this output layer and we get the answer. And then there is a training process. We say try it with this. Internally in the training process what it does is if I give it 0, 0 with a 0 and it outputs a 1. It's like I tell it hey you got that wrong. Adjust all those weights to try to see if you can get it more correct. So what we're going to do is over and over again to train it to see if we can then later. We don't have a separate training and testing set in this scenario. We're just going to say I'm going to train it and see if you can start producing the correct answers for all of these numbers. Okay. That's the background for XOR. Now I'm actually going to go and write the code to do all of this and hope that it works. Okay. So how's it going here? I just want to see did I miss anything kind of crucial there? I'm going to go and do the code part now. All right. Sounds pretty good to me. Okay. Ringing endorsement. Okay. So you might recall that I started the video. I had this thing up here. So this is actually an example that I made in the processing Java based programming environment. I probably like almost eight years ago at this point. So it's not using the same code base but it's actually solved the XOR problem. And what's interesting about this and I'm going to come back to the whiteboard just for one more moment here. Let me find some room here. If I draw a plane and I consider this to be 0, 0 and this to be 1, 1. So this is 1, 0 and this is 0, 1. Right. Notice that if I take this idea of XOR and map it to here, I've got false here, false here, true here and true here. And by the way, what did I write at 1 there? 2 here and true here. This, by the way, is why it's not linearly separable. You can't draw a line. I can draw two lines like this or I can draw two lines like this. You're going to see that result happen actually as I start to program this. I hope if it works. But what this idea of a plane, this is a plane that's describing the whole solution space for the problem. And if you come back over here, you'll see. Look at that. Those corners, if I bring this over closer to me, I can try to point to it. These corners are the true corners. I need more practice. And these corners are the false corners. And this plane is all the other solutions. Now this is a 3D rendering. It's doing some fancy stuff. I'm going to create a simpler version of this. So let's just actually start doing that. So what you're going to need first of all is if you're writing this code along with me, you're going to need to have the toy neural network JS library. It has really just two files that you need. It has neural network.js and nn.js and matrix.js. You can ignore this. This is for testing. That's something I cover in some other videos that you could probably find. And you'll see that in my index.html file, I am referencing those two JavaScript files. I've got like a weird path thing going on, but when I publish the code, I'll publish it all as one thing. Okay. So now I need to go over to sketch.js. Let's do some stuff here. Let's write a setup function. Let's write a draw function. Let's say let. I'm going to have a neural network variable. I'm going to say create canvas 400, 400. Let's draw a background of zero. And let's go to the browser and see. There we go. There it is. Step one. Now what I want to do is create a neural network. And I've written out how I want to create it. I want two inputs, two hidden neurons, and one output. So the neural network library, the toy library that I've built, expects those as arguments to the constructor. So I can say neural network equals a new neural network with two inputs, two hidden neurons, and one output neuron. Now I should mention that modern so-called deep learning systems often have many, many, many hidden layers. Hundreds of hidden nodes. Big, massive networks. This is a very small, simple one. The library only supports networks with these two layers. If you consider the input, you could say three. But really these were the layers. The hidden and the output plus the inputs, three things. Okay. Now what do I need to do? I need my training data. So I'm going to say let training equal, and I want to have it be in an array. And each element of the array, I want it to be an object. And it's going to have the inputs, which would be like this, and the outputs. Now even though I only have one output, right, one output, outputs can be an array. They're often referred to as a vector. So a list of numbers. But in this case, 00 gives me just a single output. I have single outputs, but I'm going to put the array, the library expects an array. So I have that. Inputs out 00. I have 01, and 00 gives me a 0, not a 1. I have 01, which gives me a 1. I have 10, which gives me a 1. And then I also have, what's the last one? 11, which should give me a 0. So this is my training data. Now ordinarily this data might be in a spreadsheet, it might come from an API, it might be in a JSON file. But I'm just hard coding the training data directly into my program just to demonstrate the idea. Now what do I want to do? Well, in the draw function, what I want to do is, and now, if you look at how machine learning algorithms work, typically you'll see something called, you'll have a batch training process, where you give it a large batch of data, and then you adjust the weights and do the training in another batch. I'm going to do everything just one at a time. And the way I'm going to do that is with a function called train that's in the neural network library. So if I say neural network train, this expects two arguments. What it expects is to say, train the neural network with this input and this expected output. And so the easy thing here that I could do is, what it should look like is something like this. Train it with 0, 0 and with 1. So this is what I'm saying. These inputs should produce this output. Train yourself on that. But I have that all stored in an array. What I'm going to do is I'm going to say data equals random training. And what did I call that up here? I called it training. I just called it training. Let's call it training underscore data. Training underscore data. So the random function in p5 will pull a random element from that array, and it will put it here in data. So then I can just say train it with these inputs and expect these outputs. It's only one output, but outputs. So this is the process. This is the training process. Of course, all of the work to adjust the weights of the neural network is in the library, and you can go, stop saying this, refer to those videos that go through that process. Okay, we've got that. Now I am going to, let's just run this and see if I get any errors. Ah, syntax error. Sketch.js line four. Oh, look at this. Horrible. My JavaScript object syntax is just completely off. These are not semicolons. You guys have all, everyone watching has been screaming at the screen. Take two. Oh. Oh, I have semicolons here. These should be commas. My syntax is completely wrong. If you're watching this, you were probably screaming at me or saying very nicely and sweetly to the computer, excuse me, excuse me, it's not semicolon. Okay. There we go. Now let's run again. All right, it's running, it's training. I think it's working. Is it working? So now here's the thing. It's doing its thing. Let's actually see if it's working because one thing I can do right now is I can just test the output here in the console itself. What is this weird graphics artifact going on here? I'm going to ignore that. I'm going to say nn predict. So the predict function is a function in the neural network library that doesn't take the inputs and a labeled output. It just says here's some inputs, tell me what you think, tell me what the output is. So if I give it 00, shouldn't I get 1.0? Oh, that's not good,.49, that's not good..51, oh, it's doing a little better, got a little higher, that's closer to 1..51, oh no,.49 again. So this is the thing. I have programmed this in such a way that first of all it needs to run these data points in thousands or possibly hundreds of thousands of times to be able to train itself. And also this is a problem that with only two hidden nodes it can kind of get stuck, right? It gets stuck in this sort of in-between state. I was trying to think of how to, I didn't want to cover the getting stuck thing. Let me just go again and hope that it's a time that it doesn't get stuck. So this will get edited. I do want to cover the getting stuck thing because I think there's some things we can do by adjusting the learning rate and mucking around with it, but I just didn't want that to happen right now. So I'm going to just run it again. It's running, it's running. So what I can do is right here in the console just to test it I can type nn. and there's a function called predict. And what predict expects in the neural network library is the input data with no output because it's not labeled training data, it's just input data. So let's see if we can get results that make sense. It hasn't trained for very long and I don't know, but let's see. Let's just try it. Predict 0, 0. 0.45. That's not right. So I should be seeing 0.1, right? It's changing. 0.43. So my guess here is that we really need it to just train a lot more. What I'm going to do is just for right now is I'm going to say in the draw loop itself I'm going to say i equals 0, i is less than 1,000. I'm going to have it do every time through draw 1,000 of these training points. So this will hopefully get us there a little faster. And I can look at this now. We can see, ah, ooh. Now that's wrong, right? Oh, no, that's correct. I should be getting false. Yeah. So that's right. I got it backwards for a second. I shouldn't be getting true. I should be getting false. 0, 0. So let's try 1, 0 and I've got something that's close to 1. So you can see that this worked. Okay. So the library is working. But let's say I want to visualize it. Okay. I want to visualize it. I want to see it working. I want to see it animating as it works. So one way I could do that is I could basically let's create some variables like resolution. I'm going to make a grid of 10 by 10 pixels. So the columns is the width of the canvas divided by the resolution. And the rows is the height of the canvas divided by the resolution. Then I am going to say x equals 0. I'm going to use i. i equals 0. i is less than the number of columns, i++. And I'm going to say j equals 0. It's less than the number of rows. I'm going to do a nice little nested loop here just to now I'm going to say fill random 255. And I'm going to say rectangle i times resolution, j times resolution. Resolution. I should have picked a less long variable name. Resolution. So what this should do is this is a nice little nested loop to just draw a grid of rectangles, 10 by 10. And a little warning, this will be kind of flashy. So you can see all of these elements are flashing out with a random color. But I don't want a random color. What I want to do is I want to create some inputs. So I'm going to say let x1 equal i divided by columns, right, from 0 to 1. Let x2 equals j divided by rows. And the inputs then is an array x1, x2. So what I want to do is I want to create a scenario. Let me just say no loop here so this stops. I want to create a scenario where I am inputting in 0, 0 here. And at this corner 1, 0. And 1, 1 and 0, 1 down here and all the numbers in between, right. So now and then I, what I can do is I can say let y equal neural network predict. And this should be an equals here. It's this particular predict, those inputs. And then fill y times 255. So I should get a brightness value out that's between, I should get a y value that's between 0 and 1. And I should get that, a brightness value. I can multiply by 255 to get a brightness value. Okay, let's run this. Boom. So we can see now and let's be a little more thoughtful about this and say no stroke. And I'm going to refresh it. And very quickly, ah, so this, I'm so glad this happened. So here's the thing. It worked for me a bunch of times. But actually here you can see it's totally getting stuck. Let's refresh it again. And that got stuck in a slightly different way. Let me hit refresh again. Whoa, it's just like going around the horn and getting stuck in every possible way. Now it worked. So here's the thing. Remember how I said a neural network is an interconnected set of nodes with each connection being a weight. So there's a couple important factors here. One is those weights are initialized randomly. And there are thoughtful ways that you can initialize those weights. But I kind of think if you initialize them in a certain way, the problem is there's multiple solutions here. So there's one solution here where there's white all the way along this way. And if I refresh this a bunch of times, you'll see there's another solution where there's black all the way down through the middle. Because honestly the only thing that's correct is what's in the corners. So I've run this a bunch of times. Isn't this the opposite of what we got before? I can't remember. So there's a bunch of different solutions here. And it sometimes can get stuck in that middle. So one thing I might be able to do is play with something called the learning rate. So there is a variable in the library called learning rate. And I could say neural network learning rate equals. There's a set function, but I think... Time out here. Just pause for a second. Does somebody who is watching this know if this has this set learning rate... Does this mean I should... Maybe this isn't using this getter setter in the ES6 way. Does this mean I should call a function called set learning rate? Or does this mean I'm supposed to do the thing where I can actually say learning rate equals and it kind of automatically calls this function? I'm waiting for somebody to weigh in. So I should call set learning rate the way that it's written. Is there some fancy getter setter thing you can do? That's not an ES6 setter. Okay. So someday it might be an ES6 setter, but it's not going to be right now. No setter. Okay. Should I make it a setter? Like should the library have a setter? Would that be like a good thing to do? This is me just waiting for the internet to tell me which to do. I mean, I don't really need to be getting into this right now. Right. It's only really useful if I want to get the learning rate. Okay. Okay. Let's not worry about that right now. So I forgot the library actually has a function called set learning rate. And so what I can do is I can set this to some value. Now what should that learning rate be? The learning rate is like how big are these steps? How big are these adjustments? And so maybe what I'll do here is I will create a LR slider for learning rate slider. And I'm going to say LR slider equals create slider. And so I'm going to have learning rates that go between 0 and 0.5. That's probably a ridiculous range with an incremental step of 0.1 and an incremental step of 0.01. So this is a P5 DOM function create slider that creates an HTML5 slider, puts it on the page. And so now I could just say LR underscore slider dot value. So this should, if I'm right, always set the learning rate according to this. So let's see if I put it up here and I say neural network learning rate, it's 0.5. And if I go down to here, it is 0. Now I shouldn't let it be 0, right? So the lowest the learning rate should be is probably 0.01. So let's see if we can get it stuck. Now of course I'm going to hit refresh. Okay, it's stuck. Let's see if just like allowing it to take bigger steps one way or the other will sort of fix the problem. It's still really stuck. Interesting. Now I guess what I could do is if it's stuck, I could reset the neural network. So neural network, is there a function in the neural network library to randomize the weights again? Let me go from where I stopped with the slider. No, that doesn't really work. Well, one thing I could do is I could kind of like re-randomize the weights. I could like, that could be something I don't know. Oh, the learning rate is only being applied after a thousand. No, but it'll come back. Because once it doesn't get, that's a good point in the chat to be saying it's learning rate is only being applied after a thousand iterations. But it just has to wait for that 1,000. It's not like, then it's back again. The reason why it gets stuck is because there's two possible solutions. I was going to add four hidden nodes and I think that will help it. But I'm trying to think of, I can't remember what I put into the neural network library. I guess to reset it. Okay, I have an idea now. Okay, let me try this again. So let's try, let's try this again. So let's try, let's try, now let's try lowering the learning rate. That didn't really seem to fix it. It's really stuck here. So one thing I could do is I could just like start it over. Like new neural network 2, 2, 1. And now I've just started it over and it's still stuck. Let's try it again. Let's leave it at like 0.1. So I could write this as a function to like restart it a bunch of times and just get lucky with the first weights. Another thing I could try though, just to see if this really helps. The thing is what I probably need to do is be more thoughtful about how the weights are initialized. Which is something I would probably want to build into the neural network library. Just out of curiosity, let's add four hidden nodes. So do we make the network smarter by giving it more things to learn about, right? So I'm adding in all of these. Whoops, this goes to here. There are more connections. More connections, more possible things for it to learn about. Let's see what happens. Ooh, look at this. Look at that. It's nice and curvy. It's sort of like learned it in a slightly different way. And I suspect that I'm going to have a lot harder time having it get stuck. Now, you can see that there's multiple quote unquote correct solutions to how the space looks. But it's really able to figure it out. Now, that's really the end of this video. The point of this mostly was just to show you how to build a neural network. The point of this mostly was just to test the neural network library. So it works. I can use it. I can give it data to learn. I can try it with other data. I can visualize its result. Now, so here's the thing. You're watching this video. What should you do next? Well, first of all, I'm going to do another challenge, which is the kind of classic hello world neural network machine learning example, which is to recognize handwritten digits. And there's a well-known test set called MNIST that I will use. I kind of don't want to, but I think it's worth me just doing that, just to do it. But that will be a more interesting problem. And then we can even make it so that if I draw a digit, can the neural network detect what digit it is? So anyway, so that's coming. But could you, one, come up with your own data set, try to train the neural network with your own data set, and then how does it perform? You also might think about visualizing this output using color in some way. You know, you could use 3D, as I showed you with this processing example, which is no longer open. So you could try a variety of different ways of visualizing this and maybe, or animating it or changing the way you build an interface to it. There's so many possibilities. So I encourage you to explore it. I encourage you to dig in also to the neural network library code if you want to see how that works, and check out those other videos as well. So thanks for watching this coding challenge. I think that's it. That's it. That's it. I'm done. I'm sorry. It's interesting how, like, what kind of weird results we can get. Oh, try playing around with the slider now. I should have done that. So actually, one thing I should do is I should really have done this. Because it's more interesting to watch it figure it out slowly over time. Yes. This is not as exciting to watch. I'm going to try just with 10. Probably too slow to watch. Yeah. I'm just trying to, what's the sweet spot of, like, being able to slow it down but to also, like, yeah. So this is probably better, 100. Because you can kind of see it learning more slowly over time. Okay. All right. So I think I'm finished for today. It's 4 o'clock. Oh, it's because of the sigmoid. I forgot. Yeah. Yeah, that's interesting. Right, there's no correct answer for this center spot, really. And so it can, yeah. It would be interesting to just actually run this with a different activation function and to put that into the library. But I'll have to come back to that later. Okay. I don't know if this was better than the time that I did this before. It probably took longer. But, yeah, make it slow and play with the learning rate. That's kind of interesting. That's an interesting idea. All right. So let's do that. Let's make it slow like 10. Let's up that learning rate. It's making big jumps. They're too big. And now I can lower it to refine. Yeah, that's kind of interesting. Yeah, so playing with the learning rate really does make a difference. Okay. So I'm here. I'm just about done. But I do have a few minutes to take some questions. It was really good. Okay, thanks, KB. I just felt like I needed some space from when I made the library because I was in my own head of, like, what did I say before, what did I didn't. So this, I hoped, would kind of give an introduction. My goal for this was that you could watch it without having watched that other playlist. But you could get more from watching the other playlist. I don't know. I can add a slider for the iterations. That's a smart idea. That's a very smart idea. So let me talk for a little bit about what I want to do on Friday. I'm so tempted to do some of it right now. But I think I will do it on Friday. Let's, so here, actually, let's go. This is exciting. Let's do a live adding to the Coding Train website. So I think if we go in here under strings, we can see these are now, there's so many more that need to get added here. These are the markdown files for all of the live streams. And so the live stream this Friday would be one, well, today is what? Today, okay, so let me go to my channel. No, I don't want to go to YouTube home. Coding Train live. What, by the way, this is so interesting to see what, like, things I should watch based on, because this is not my personal YouTube account. This is like a random YouTube account that I set up just for live streaming. I don't know why I think I should watch this football video. But what I want to do is go to the Coding Train. I'm subscribed to the Coding Train. And hold on. Oh, interesting. Okay. Sorry, I had some important messages, but I will get back to those in a minute. I shouldn't be looking at my messages while I'm live streaming. I'm looking for playlists. And actually, I can just do this. The last live stream was number 118. So today is 119. And this Friday, I don't know what time I'm going to do it this Friday. Probably in the morning, actually. This Friday. So if I create a new file. Create new file. 119. Upcoming live stream.md. Create a scheduling Fridays live stream. And I'm going to make that new file. Then I'm going to go here. And I am going to go look at another one. I'm going to look at this one called Walks. And I'm going to look at how it's going to do this. Because that's actually, this is no longer an upcoming live stream. But I'm going to grab this. And I'm going to edit this file. And I'm going to paste this in. So now, the date for this Friday, today is the 7th, 8th, 9th. To 9. And the topics will be. So this Friday, what I want to do is MNIST coding challenge. Pendulum. Pendulum coding challenge. Spring coding challenge. What I mean by spring is Hook's Law. And double pendulum coding challenge. Now there might have been something else. So I'm kind of doing double duty here. In that I'm trying to push the neural network stuff further. Machine learning stuff. But I also want to. This week in my course at ITP that I'm actually teaching. This week was about oscillating motion. So I wanted to look at springs and pendulums. And I've always wanted to program the double pendulum. But I feel like it's weird to do the double pendulum challenge. Without having done the pendulum coding challenge. Let's just make sure I haven't done these videos already. So one way to figure that out is. Shiftman pendulum. Now I know I have a video about a pendulum. But I think in this video, which is two years old. First of all, it's in processing. I don't have any gray hair. And I'm pretty sure I don't actually code the pendulum from scratch. I'm just talking through an example. So I don't see anything else about a pendulum. So that's good. What about springs? Springs, toxic libs, simple harmonic motion. But again, these are all the old ones. Oh, I do have a guest tutorial. With Val Head about a spring animation. Oh, wonderful. And that's great. So this you should check out. Maybe I won't do that. Because I'll just refer to. I'll look at that and see if it's doing the same thing that I want to do. And then. Oh, I remember I used toxic libs for some stuff. So I have this. Pendulum simulation. So I think that's kind of my plan. I'll probably let the spring go. And focus just on the pendulum stuff. So now. Wait a second. Wait a second. The reason why I was doing this. This doesn't look right. Could this possibly be right? Well, if I did this correctly. Now if I go to thecodingtrain.com. I'm going to check my email to make sure I didn't get a build error. I don't see one. If I now go to streams. And go to the bottom. So I probably did something wrong. Is one. I might have used a bad. So let's look at one that's actually showing up. So let's look at 104. 104. Let's go to edit. Oh, yeah. Oh, look at this. No, this is right. Let's look at this. So this one's showing up. I'm just going to paste this in. I think I did something wrong. Topics. Oh, wait. I know what the problem is. Topics. Yeah. I think. If I look at the format here. Title. This should be under here. And this should just say topics. And maybe it's. I want to do this. So maybe I want it to be like this. Oh, is the date format wrong? I have an extra line break at the top. Is that the only problem? But let's use this format. Let's use this format. Let's try this. And then I can. There's no video ID yet. Oh, and this should say, by the way. I want this to say. Oh, you know what? I wouldn't be surprised if this requires this. February 9th. Yep, that's right. 4 p.m. Let's try this. And then here. Live stream. Okay. More neural networks. And also pendulums. Let's just put that there. Okay. Let's look at this. How are we doing here? Is this possibly correct? Let's try this. Let's. Does correcting live stream page. Let's do this. This looks better. Like, it formatted it. And so now we have to wait for the page to build. So I will take some questions. Maybe indent the topics. Check if there's a plug-in for your editor. Does it show up on the home page? I think one of the ideas was to have the upcoming, next upcoming live stream always be here. Latest videos. By the way, also, these are the links now. So the Patreon link, merchandise link, and then link to the Amazon shop is here. Let's go back to streams. I'm sure it's just me screwing this up. It's also possible that, because GitHub pages can take, so here. Let's be a little bit more thoughtful about this. Let's actually clone the repo. So those of you who are wondering, how does this even work? Let's go, let's clone. Now, this is probably going to be a very long clone. So let's just get the repo to the desktop. This is going to take a little while. We'll have a pretty fast. Oh, it's working for me. I was going to just try running Jekyll locally. Oh, maybe it's caching. Let me force a refresh. Is it on the home page? By the way, there's also one thing I'm just realizing now. There's no link back to the front page. Well, maybe if I click here it is, yes. Oh, there we go. Look at that. Upcoming live stream. Ah, that's why I probably want to put it. Okay, there we go. Look, there it is. So now, whenever I schedule one, the upcoming live stream should be there. Now, it has the wrong time. I'm not sure why. I thought I fixed that. Let's go back to streams. Let me do this locally. Let's go through this. Okay, I've got it. So I've cloned the repo. If you want to work on it and understand and contribute to it locally, if I go now to Rainbow Code. Now, I have no idea if Jekyll is installed. It is, apparently. Of course, it just gave me a bunch of errors. So let's, this is, the problem is I have, I've never used Jekyll or Ruby on this log into this computer. So I hesitate to go get this all working right now, but let's just. Jekyll is a framework for building static websites, and I'm going to just do this. Let's see if I can. Yeah. All right. Yeah, so I've got to update Ruby. The guest tutorial is, okay. I'm trying to decide if this is worth doing right now. So let, yeah, let's, let me, do I have, so one thing that I use is RVM. So let's use RVM. So I'm going to grab RVM, which should let me do this here. RVM is Ruby Version Manager. So this should allow me to manage the versions of Ruby I have. To start using RVM, you need to run sort, yeah, so I need to do this. So it's running. Okay. RVM. So I think to install with a certain version of Ruby, what I want to do, I really don't know what I'm doing here, by the way, is document, I just want the installation. Yeah, I've installed it. I just want like a, how do I install which version I'm using? RVM, RVM list, RVM install. RVM install. Okay. RVM install. And then what did it say on Jekyll I need to be using? Which Ruby? Jekyll. It's probably going to be an error because our, what did it say? I can't believe I'm doing this on a live stream. What did it say? Requires Ruby 2.2.5. Okay. Let's quit that. RVM install this. So now I'm installing Ruby 2.2.5. Checking requirements, error is not, oh, right. Oh, my goodness. Brew doctor. Yeah, doctor, doctor. Let's see if this works. Oh, permission denied. Pseudo brew doctor. This. Okay. Okay. Okay. How about pseudo RVM install 2.2.5? Oh, boy. Really? Oh, okay. Let's install home brew. Let's install home brew. Wow. I didn't realize that, okay. Failed. Don't run this as root. Wow, what is going on in this log in? Could not set, could not permission denied. Can I get rid of home brew? Wow. Wow. Oh, my goodness. I can't believe this is where I am right now. What was I trying to do? I don't even remember what I was trying to do. I was trying to show you how to run Jekyll. I could just log. I've been in this situation so many times. Could not lock config file. Permission denied. Am I? All right. Let's go down this rabbit hole for ten more minutes, then I'm out of here. Okay. Oh, maybe if I just use iterm, I'd be fine. Let's try this. Yeah, that's the same thing I was running before. Create an access token. Wow. Oh, someone probably wrote in the comments here. What's the error that I'm getting again? Permission denied. What did I do wrong? I kind of want to uninstall. Okay, how do I uninstall home brew? Okay. Let's uninstall. Let's do this. Whoops. Yes, yes. Permission denied. Oh, my goodness. Permission denied, permission denied, permission denied. This is loads of fun. All right, brew update. Oh, yay. Okay, I don't have it anymore. That's good. Brew cleanup. Oh, yeah, I don't have it anymore. Okay. All right. Oh, yay. Okay, we're in business now. Come on. Why was this denied? Oops, no, no, no. Why? Oh, yeah, this is definitely going to do it. This is the solution to all my problems. Yeah, can you hear? It's not installed yet. Yeah, okay. Oh, my goodness. Well, if I got rid of home brew, can I use RVM now? Yeah. Does it need home brew? RVM install 2.2.5, that's all I wanted to do. Oh, look at this. About to install home brew. Restart. It's totally not going to work, but all right. Oh, look at this. This is promising. It would be nice to have Jekyll working because if I own Jekyll another time, I'm going to be confused. Woo, woo. Oh, it's pouring it. Oh, pouring it. Let me just pour. I'm going to pour a little bit of that on. It's coming out, coming out. Extracting. Do you guys mind if I check my email? I was totally just reading my email there. I forgot that I was even live streaming. Okay. Wow. As MPJ would say, this is authentic programmer waiting. I wish I had some coffee. Coffee would be so good right now. Okay, I finished. I don't even know what I'm doing anymore. So now RVM use, I think I say 2. If I wanted to like, I want to use that version. Now I'm using that version. Okay, good, good, good. Now let's go back to Jekyll. I should be able to say gem install Jekyll bundler. And. Ruby 2.2.5 is old. Should I be using a more current one? Well, why did I say 2.2.5? Wow, I probably have no room left on this computer's hard drive either. I'm expecting this just to like. Oh, it was the minimum. Should I really go and install it? That was the minimum. Oh, wait, okay. Well, let's see if it works. Does it finish now? Okay. And what was it called? So, okay, so what I should be able to do now is say bundle exec Jekyll serve. So if I am in this repository, this is now the coding train website repository cloned locally to this computer. If I say bundle exec Jekyll serve. Oh, bundle install. I have to install all the gems. I forgot about that. And we're back. Okay. Where am I? What year is it? Am I still installing Nokogiri? Control L. There we go. Control L, thank you very much. Let's try this again. Amazing. Amazing. Amazing. It still hasn't built yet though. It's a big site with a lot of stuff. Very soon it will have built. There we go. So the server is now running. So I can now grab this. And I can go to the browser. And we can see here is the coding train website. And now here is the card which now has the upcoming live stream. So now what I can do is I can be a bit more diligent about this. And I can actually just try editing all this stuff locally. So I want to go to streams and upcoming live stream 119. And actually what I want to do, let's see. I'm going to actually take this out. Put this here. And when I hit save, right, we should see that I hit save. It is now going to regenerate because I hit save. So it's regenerating the site. It's not finished yet. And it's done. It took 11 seconds. And I should be able to refresh now. And there we go. So now you can see, oops, that's there. Why? Oh, I forgot that I left this stuff in here. So I can get rid of this now. It was just that line break at the top. The whole problem stemmed from the fact that I had that, by the way. So now I can do this. You can see, actually, you can see the syntax highlighting completely disappeared. This is YAML which stands for YAML markup language apparently. And our young adult markup language maybe. I'm not sure what it stands for. What else could YAB? Okay, so now we can see this is hopefully now live stream. It still says 4 p.m. because I want this to be 10 a.m. Although now I'm wondering, actually, based on my schedule, I thought I saw something in my email about something that had to happen on Friday morning. So let me look back. So that might change it, but I'll put it there for now. So and then I can come back here. We can see here it is. The upcoming live stream is here. So you can always check. If I've done my job, you can check the website for the next upcoming live stream. And this link should take you to. And actually it took you here. And there I am. But actually it should take you to. Now this should be the URL. Because I have a new. I got this new checkmark URL thingy from YouTube. And so. So let's see if we can find where that is. Where in this repo is user slash Shiffman? Lots of places. Video card. It's in the includes. Now I don't want it to show. Oh no, but I don't want. Where did it render the site? Oh, that's hidden. Okay, it's already. So I think I want. Dare I. First of all, let's do this. So let's add this commit. So this is new live stream. So I've committed that. Now what I'm going to do. For probably against my better judgment. Is just replace this with. Now is it silly to put capitals in the URL? I don't like how that looks. Let me just make sure it works. If I go to. YouTube.com. The coding train live. Does that work? Yeah, I feel like I'd rather have it be lowercase. The capitals kind of freak me out. So let's do that. So let's change this to. This should be the coding train. I'm going to change that everywhere it appears. Yeah, 11 times all over the place. How bad could that be? Did I do it? Okay, done. Let's do git status. So it got changed in a whole bunch of places. Which makes sense, I guess. What's in this folder here? Oh, that's the includes in the layouts. Okay, great. Git commit updating. To new Jekyll. I mean, sorry, new command line. To new Jekyll. I mean, sorry, new coding train URL. And is the website still working? This takes me to coding train live. Subscribe on YouTube. Oh, that's interesting. This somehow is still going to. And this should be a button that automatically subscribes you. That's not. This should really be. This should subscribe. There's a way to have the button automatically subscribe you to the channel. Which this is not doing. So where is this showing up? Learn to code. Where is this content? Is it on. Landing page? Learn to. Yeah, there it is. Oh, site links YouTube. Ah, okay. So this is a special case though. Because this should be a subscribe button. YouTube channel. I've lost the chat here. Oh. Oh, well. Uh-oh, am I going to have double slash? Double forward slash. 56 new messages since I stopped looking at the chat. Double forward slash. Okay, hold on. Let's search for. Let's search for. The coding train. Maybe you guys can't see what I'm doing. Let's search for the coding train double slash. Oh, yeah. Everywhere. Whoa, it also. Oh, yeah. Coding train double slash, double slash, double slash. So let's fix that first of all. Replace all. Git add. Git commit. Fix double slash. And this might not be the proper way to do it. But somebody in the chat just gave me the subscribe. So I think. Let's try this. Let's go to. Let's. Okay, let's. Go to here. Still took me there. That's fine. That's weird. Wait, where is that coming from? Then if it says. Hold on, hold on. I'm talking to the people in the room next door. This. Why is this still going to user slash shiftman? Okay, hold on. We got to figure this out. So landing page. This is pulling this from site dot links dot YouTube. So that must be in config. Right? But it's site dot links. Why didn't that not rebuild? I guess that doesn't rebuild. Let's rebuild the whole site. So I'm rebuilding the site. I apparently have a wrong video number. 119 and 116. Yeah, I haven't pushed the site live yet. That's correct. Okay, so let's see if that. Fixed it. Yes, this is now going to the coding train. And so what I want is to have it on landing page. B and then it's question mark. Sub confirmation equals one sub underscore confirmation equals one. Pretty sure that's going to subscribe me. So this hasn't. I'm going to go here. And I am going to unsubscribe. I am unsubscribing from the coding train. Unsubscribe. Now we will go back to the website. And I'm going to click on this link. And are you sure you want to subscribe? Okay, now I have subscribed. I'm back up to my subscription number. So that's good. So I did that. So. Add automatic subscription link. Okay, now what was the other thing? Somebody was telling me I had the video numbers wrong. I'm going to go back to the website. And I'm going to click on this link. Now what was the other thing? Somebody was telling me I had the video numbers wrong. Oh, interesting. I don't have to unsubscribe to get that. Okay. So what was it that somebody was saying that I have the video numbers wrong? Let me look back. The reason why. Yes, here's the thing. Oh, 118 is already more neural networks. Oh, I'm totally wrong. Because today is 119. And also, why is 116? What's? I'm so confused. But let me go to the... Let me look at the website here. Oh, it says 116 there. Yes, yes, I see. And actually, it shouldn't even be 119. Because... It should be 120. And so let me rename the file. It should be 120 because if the last one that is on YouTube is in fact 118, that means today right now is 119 and Friday is 120. So I change it to 120. And let me do git status. And I'm going to change it to 120. And let me do git status. So I'm going to do git add dash A. I did that dash capital A. I don't know if it needs to be capital because I deleted the file. And so I want to make sure that delete gets added as well. Friday is 120. And then, why not add one for today? If I do... I'm not going to add one for today. So this is the thing. Anybody watching this video wants to help. There are... Look at this. A live stream could be... The markdown file could be added for all of... You know, it only starts here at about 104. Coding challenges, I think... Whoops. I think I only have a markdown file for every coding challenge. I don't know. I'm not sure. I have a markdown file for every coding challenge? Looks like I have a markdown file for every coding challenge. But I'm missing so many markdown files for the courses and tutorials. And also, just generally speaking... If you have ideas for how this site can be more navigable, visually pleasing, make more sense... You can clone it. You can run Jekyll locally like I did. You can make changes to it. It's all HTML, CSS, markdown, and some weird Jekyll stuff. But play with it. Make fixes. Make changes. I could use some unit tests for it. One thing would be good to have a unit test that checks to make sure the Jekyll build is right. Yes. And... Yeah, I would love help with that. But right now, I at least have successfully scheduled this Friday's live stream. Now, one thing I should say is this is my speculation. I might change it to the afternoon, but I will try to update this if I do. But this at least now is going to be a system for me being able to alert people of when the next live stream is. It kind of lets us see the latest videos and all this stuff. All right. I think that's all I've got to say for right now. Oh, let me push it live to the site. So, I've now pushed this live. So, you should now see this if I go to the codingtrain.com. Now, you don't see it right now because these Jekyll builds can take a little while. All right. Four coding challenge Friday or one of them? Well, certainly my goal is to do all four. I wouldn't be surprised if I only got to one or two or three, but my goal is to do all four. Okay. So, I'm done for today. I will happily take a few last questions. For a sigmoid, oh, it's 4.45. I really got to go. For a sigmoid, should the outputs be negative one, one instead of zero? For a sigmoid, should the outputs be negative one, one instead of zero, one? Just thinking. No, the sigmoid function squashes any number to a range between zero and one. There's a function called tanh or hypertangent. That's another activation function that is used with neural networks. That gives you an output between negative one and one. But sigmoid gives you an output between zero and one. And the activation function that's used most commonly now is called relu or I like to say relu. And that actually just gives you a number between zero and infinity. Okay. Do you have plans of teaching JS for embedded devices like Esprino.js or Puck.js? I don't have any plans, but that sounds like a great idea. That would probably be a good territory for a guest tutorial. Hopefully, I can get a little more handle on my schedule and have more guests. Are you going to carry on with neural networks, convolution, etc.? Yes, I'm going to keep neural networking and carrying on. But I'm not sure. I don't think that I'm going to continue to build every style and flavor and architecture of neural network into this toy JavaScript library. This I really meant to do like the sort of first beginning steps. And then if I do stuff with say a convolutional neural network, I'll do that with deeplearn.js and possibly this ml5.js library. When are you going to add splitting to the game Agario? I don't know. Probably not for a while. But people have really requested that I follow up on that challenge. Are you interested in a coding train app? Yes. The budget that I have for this channel is small. And I do use the Patreon funds for video editing and other production and design services. An app could be something that I would potentially want to invest some funds in having somebody develop. But I also wouldn't be opposed to having a community built app that somebody works on for volunteer. If you're interested in that, please get in touch. The website is kind of right now living in this sort of volunteer place. But I'm not opposed to... I don't know what I'm saying here. But yeah, I'm not opposed to an app. That would be interesting. Can you teach us Python? No, I don't really know Python. I was planning to do Python because I was going to use Python for all this neural networking machine learning stuff. And then use a Flask server to talk to my JavaScript. And then it descended from the Google. DeepLearn.js came out. And that's really shifted my thinking into kind of really staying within the browser for this stuff. But I do hope to add Node and maybe Electron to some of the stuff that I'm doing. But Python I would probably want to have some guests for. Coding train app coding challenge. Okay. Oh, the song ended. Okay, thank you everybody for watching. This was a bonus live stream. I think that XOR was an improvement over my previous XOR challenge. But I will let the wonderful Math Blanks, Mathieu, let me know what he thinks. And so tomorrow will come out the video series on unit testing and continuous integration with CircleCI. Thank you to CircleCI for sponsoring those videos. I really like doing sponsored content. It's a good way to make what I do more possible. So if you're interested in sponsoring content, you can get in touch with me. Okay, thanks everybody. And Tetris. So here's the thing. I need an idea. If I go to coding challenges. Snakes and Ladders was 91. So that XOR was 92. I'm getting close to coding challenge 100. I need a really good idea for that. And Tetris is kind of on possibility there. So if you have ideas for what's the perfect coding challenge to synthesize everything that I ever have done on this channel, let me know. Okay, goodbye everybody. I will see you hopefully on Friday. And if for some reason Friday doesn't work out, I won't feel guilty because I did a bonus stream this week. Okay, goodbye.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:50:00.748509Z",
  "started_at": "2023-09-26T21:54:04.513103Z",
  "completed_at": "2023-09-26T22:17:32.252969Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=f9vaiHoq-Fk",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1407.739866
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/csgckgzbcxexrw6faut35xuosu/cancel",
    "get": "https://api.replicate.com/v1/predictions/csgckgzbcxexrw6faut35xuosu"
  }
}