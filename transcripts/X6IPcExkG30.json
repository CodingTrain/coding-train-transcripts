{
  "id": "jewgjjbbamj4s45fw7vtn6ar5u",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/X6IPcExkG30.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/964833 [00:00<?, ?frames/s]\n  0%|          | 3000/964833 [00:02<15:45, 1016.98frames/s]\n  1%|          | 5900/964833 [00:07<21:27, 744.58frames/s] \n  1%|          | 8900/964833 [00:11<20:32, 775.63frames/s]\n  1%|          | 11800/964833 [00:17<26:00, 610.80frames/s]\n  1%|▏         | 14300/964833 [00:23<28:55, 547.75frames/s]\n  2%|▏         | 17000/964833 [00:29<31:05, 507.96frames/s]\n  2%|▏         | 19900/964833 [00:36<33:22, 471.83frames/s]\n  2%|▏         | 22800/964833 [00:43<34:21, 456.86frames/s]\n  3%|▎         | 25300/964833 [00:48<34:32, 453.36frames/s]\n  3%|▎         | 28000/964833 [00:54<33:46, 462.23frames/s]\n  3%|▎         | 30800/964833 [00:59<32:47, 474.77frames/s]\n  3%|▎         | 33500/964833 [01:05<33:21, 465.40frames/s]\n  4%|▍         | 36200/964833 [01:11<33:40, 459.49frames/s]\n  4%|▍         | 39100/964833 [01:18<33:51, 455.66frames/s]\n  4%|▍         | 41700/964833 [01:24<34:30, 445.87frames/s]\n  5%|▍         | 44300/964833 [01:29<33:41, 455.40frames/s]\n  5%|▍         | 47000/964833 [01:36<34:13, 446.92frames/s]\n  5%|▌         | 49800/964833 [01:40<30:23, 501.68frames/s]\n  5%|▌         | 52400/964833 [01:43<27:23, 555.06frames/s]\n  6%|▌         | 55100/964833 [01:48<27:19, 555.03frames/s]\n  6%|▌         | 57500/964833 [01:53<27:47, 544.18frames/s]\n  6%|▋         | 60400/964833 [01:58<28:18, 532.53frames/s]\n  7%|▋         | 63300/964833 [02:04<28:05, 534.84frames/s]\n  7%|▋         | 65700/964833 [02:08<27:49, 538.71frames/s]\n  7%|▋         | 68300/964833 [02:11<24:57, 598.51frames/s]\n  7%|▋         | 71100/964833 [02:18<27:34, 540.14frames/s]\n  8%|▊         | 74000/964833 [02:24<29:29, 503.35frames/s]\n  8%|▊         | 76600/964833 [02:31<31:12, 474.38frames/s]\n  8%|▊         | 79300/964833 [02:36<30:38, 481.76frames/s]\n  8%|▊         | 81400/964833 [02:41<31:07, 473.01frames/s]\n  9%|▊         | 84300/964833 [02:46<30:09, 486.73frames/s]\n  9%|▉         | 87200/964833 [02:52<29:15, 499.83frames/s]\n  9%|▉         | 89900/964833 [02:56<27:51, 523.43frames/s]\n 10%|▉         | 92800/964833 [03:00<25:24, 571.85frames/s]\n 10%|▉         | 95200/964833 [03:04<25:19, 572.39frames/s]\n 10%|█         | 98100/964833 [03:08<23:29, 615.12frames/s]\n 10%|█         | 100500/964833 [03:12<23:02, 625.27frames/s]\n 11%|█         | 103400/964833 [03:16<21:32, 666.27frames/s]\n 11%|█         | 106300/964833 [03:20<21:34, 663.22frames/s]\n 11%|█▏        | 109000/964833 [03:24<20:21, 700.79frames/s]\n 11%|█▏        | 110700/964833 [03:26<20:36, 690.93frames/s]\n 12%|█▏        | 112900/964833 [03:29<19:30, 727.84frames/s]\n 12%|█▏        | 115800/964833 [03:33<20:19, 696.00frames/s]\n 12%|█▏        | 118600/964833 [03:41<25:24, 555.08frames/s]\n 13%|█▎        | 121500/964833 [03:44<22:14, 631.92frames/s]\n 13%|█▎        | 124200/964833 [03:47<20:41, 676.92frames/s]\n 13%|█▎        | 126900/964833 [03:52<21:22, 653.49frames/s]\n 13%|█▎        | 128800/964833 [03:55<22:09, 628.66frames/s]\n 14%|█▎        | 131500/964833 [03:59<21:15, 653.41frames/s]\n 14%|█▍        | 134400/964833 [04:02<19:41, 702.83frames/s]\n 14%|█▍        | 137400/964833 [04:05<17:42, 778.46frames/s]\n 14%|█▍        | 139900/964833 [04:07<15:24, 891.89frames/s]\n 15%|█▍        | 142400/964833 [04:12<18:39, 734.66frames/s]\n 15%|█▌        | 145000/964833 [04:15<18:12, 750.62frames/s]\n 15%|█▌        | 147900/964833 [04:21<21:20, 638.21frames/s]\n 16%|█▌        | 150100/964833 [04:26<22:44, 597.18frames/s]\n 16%|█▌        | 152800/964833 [04:30<22:52, 591.51frames/s]\n 16%|█▌        | 155200/964833 [04:35<23:29, 574.35frames/s]\n 16%|█▋        | 158100/964833 [04:40<24:01, 559.60frames/s]\n 17%|█▋        | 161000/964833 [04:46<24:43, 541.71frames/s]\n 17%|█▋        | 163700/964833 [04:52<26:00, 513.47frames/s]\n 17%|█▋        | 166400/964833 [04:56<24:28, 543.83frames/s]\n 18%|█▊        | 169300/964833 [04:59<21:22, 620.39frames/s]\n 18%|█▊        | 171300/964833 [05:02<20:54, 632.55frames/s]\n 18%|█▊        | 174200/964833 [05:08<21:54, 601.46frames/s]\n 18%|█▊        | 177000/964833 [05:14<25:10, 521.62frames/s]\n 19%|█▊        | 179600/964833 [05:19<24:12, 540.67frames/s]\n 19%|█▉        | 182000/964833 [05:24<25:27, 512.61frames/s]\n 19%|█▉        | 184800/964833 [05:29<24:50, 523.27frames/s]\n 19%|█▉        | 187400/964833 [05:33<22:20, 580.16frames/s]\n 20%|█▉        | 190300/964833 [05:37<21:44, 593.54frames/s]\n 20%|██        | 193100/964833 [05:43<23:31, 546.68frames/s]\n 20%|██        | 195300/964833 [05:48<24:15, 528.72frames/s]\n 21%|██        | 198200/964833 [05:55<26:55, 474.62frames/s]\n 21%|██        | 201100/964833 [06:02<27:38, 460.59frames/s]\n 21%|██        | 203900/964833 [06:08<28:08, 450.66frames/s]\n 21%|██▏       | 206500/964833 [06:14<27:19, 462.55frames/s]\n 22%|██▏       | 209300/964833 [06:19<26:44, 470.85frames/s]\n 22%|██▏       | 211600/964833 [06:24<26:19, 476.99frames/s]\n 22%|██▏       | 214400/964833 [06:29<25:28, 490.83frames/s]\n 22%|██▏       | 217000/964833 [06:34<24:08, 516.21frames/s]\n 23%|██▎       | 219500/964833 [06:39<23:50, 521.09frames/s]\n 23%|██▎       | 221800/964833 [06:42<22:03, 561.33frames/s]\n 23%|██▎       | 224700/964833 [06:47<22:24, 550.42frames/s]\n 24%|██▎       | 227300/964833 [06:54<25:38, 479.23frames/s]\n 24%|██▍       | 229900/964833 [06:58<23:36, 518.96frames/s]\n 24%|██▍       | 232700/964833 [07:03<21:48, 559.40frames/s]\n 24%|██▍       | 235600/964833 [07:08<21:57, 553.52frames/s]\n 25%|██▍       | 238300/964833 [07:12<20:49, 581.30frames/s]\n 25%|██▍       | 241100/964833 [07:18<22:00, 548.22frames/s]\n 25%|██▌       | 243900/964833 [07:24<23:28, 511.70frames/s]\n 26%|██▌       | 246800/964833 [07:30<23:59, 498.69frames/s]\n 26%|██▌       | 249200/964833 [07:35<23:35, 505.63frames/s]\n 26%|██▌       | 251900/964833 [07:40<23:25, 507.41frames/s]\n 26%|██▋       | 254500/964833 [07:46<24:32, 482.26frames/s]\n 27%|██▋       | 257300/964833 [07:52<24:05, 489.33frames/s]\n 27%|██▋       | 260200/964833 [08:00<26:34, 442.04frames/s]\n 27%|██▋       | 263000/964833 [08:06<26:29, 441.48frames/s]\n 28%|██▊       | 265900/964833 [08:13<26:27, 440.21frames/s]\n 28%|██▊       | 268800/964833 [08:20<27:06, 427.89frames/s]\n 28%|██▊       | 271500/964833 [08:25<25:38, 450.73frames/s]\n 28%|██▊       | 274400/964833 [08:32<25:56, 443.56frames/s]\n 29%|██▊       | 277300/964833 [08:37<24:40, 464.33frames/s]\n 29%|██▉       | 280100/964833 [08:45<26:10, 435.91frames/s]\n 29%|██▉       | 282900/964833 [08:48<22:10, 512.72frames/s]\n 30%|██▉       | 285600/964833 [08:51<19:46, 572.70frames/s]\n 30%|██▉       | 288500/964833 [08:56<18:50, 598.06frames/s]\n 30%|███       | 291300/964833 [09:03<21:59, 510.33frames/s]\n 30%|███       | 294200/964833 [09:10<23:52, 468.00frames/s]\n 31%|███       | 297000/964833 [09:15<21:56, 507.24frames/s]\n 31%|███       | 299600/964833 [09:17<18:24, 602.13frames/s]\n 31%|███▏      | 302300/964833 [09:23<20:03, 550.31frames/s]\n 32%|███▏      | 305200/964833 [09:30<22:15, 494.09frames/s]\n 32%|███▏      | 308100/964833 [09:38<24:13, 451.77frames/s]\n 32%|███▏      | 311000/964833 [09:44<24:16, 448.78frames/s]\n 33%|███▎      | 313900/964833 [09:52<25:01, 433.38frames/s]\n 33%|███▎      | 316500/964833 [09:58<24:54, 433.83frames/s]\n 33%|███▎      | 319400/964833 [10:05<26:01, 413.47frames/s]\n 33%|███▎      | 322300/964833 [10:12<25:08, 425.86frames/s]\n 34%|███▎      | 325100/964833 [10:17<23:28, 454.05frames/s]\n 34%|███▍      | 327700/964833 [10:22<23:10, 458.07frames/s]\n 34%|███▍      | 330600/964833 [10:30<24:08, 437.88frames/s]\n 35%|███▍      | 333400/964833 [10:37<24:32, 428.85frames/s]\n 35%|███▍      | 336200/964833 [10:42<23:21, 448.39frames/s]\n 35%|███▌      | 339100/964833 [10:49<23:39, 440.68frames/s]\n 35%|███▌      | 342000/964833 [10:55<23:04, 449.76frames/s]\n 36%|███▌      | 344900/964833 [11:01<22:26, 460.33frames/s]\n 36%|███▌      | 347700/964833 [11:06<20:50, 493.70frames/s]\n 36%|███▋      | 350600/964833 [11:12<20:39, 495.35frames/s]\n 37%|███▋      | 353300/964833 [11:17<20:17, 502.09frames/s]\n 37%|███▋      | 356000/964833 [11:22<20:18, 499.59frames/s]\n 37%|███▋      | 358600/964833 [11:28<20:39, 488.93frames/s]\n 37%|███▋      | 361000/964833 [11:32<19:43, 510.33frames/s]\n 38%|███▊      | 363900/964833 [11:38<19:35, 511.17frames/s]\n 38%|███▊      | 366700/964833 [11:42<18:36, 535.74frames/s]\n 38%|███▊      | 369500/964833 [11:48<19:31, 508.30frames/s]\n 39%|███▊      | 372100/964833 [11:54<19:34, 504.66frames/s]\n 39%|███▉      | 374900/964833 [12:00<20:50, 471.78frames/s]\n 39%|███▉      | 377200/964833 [12:04<19:42, 497.09frames/s]\n 39%|███▉      | 379600/964833 [12:08<18:44, 520.53frames/s]\n 40%|███▉      | 382000/964833 [12:12<16:58, 572.48frames/s]\n 40%|███▉      | 384700/964833 [12:17<17:38, 548.03frames/s]\n 40%|████      | 387400/964833 [12:23<18:28, 520.93frames/s]\n 40%|████      | 390200/964833 [12:28<18:35, 515.32frames/s]\n 41%|████      | 393100/964833 [12:34<19:00, 501.36frames/s]\n 41%|████      | 396000/964833 [12:39<18:09, 522.28frames/s]\n 41%|████▏     | 398400/964833 [12:45<18:53, 499.83frames/s]\n 42%|████▏     | 401100/964833 [12:50<18:38, 503.89frames/s]\n 42%|████▏     | 404000/964833 [12:56<18:38, 501.40frames/s]\n 42%|████▏     | 406600/964833 [13:01<18:18, 508.06frames/s]\n 42%|████▏     | 409500/964833 [13:07<18:36, 497.34frames/s]\n 43%|████▎     | 412000/964833 [13:13<19:07, 481.75frames/s]\n 43%|████▎     | 414400/964833 [13:17<18:56, 484.13frames/s]\n 43%|████▎     | 417200/964833 [13:24<19:12, 475.30frames/s]\n 44%|████▎     | 419800/964833 [13:29<19:07, 475.18frames/s]\n 44%|████▍     | 422300/964833 [13:34<18:15, 495.21frames/s]\n 44%|████▍     | 425100/964833 [13:40<19:01, 472.73frames/s]\n 44%|████▍     | 427800/964833 [13:46<18:42, 478.41frames/s]\n 45%|████▍     | 430300/964833 [13:51<19:14, 462.85frames/s]\n 45%|████▍     | 433100/964833 [13:57<18:27, 480.12frames/s]\n 45%|████▌     | 435400/964833 [14:02<19:07, 461.25frames/s]\n 45%|████▌     | 438000/964833 [14:05<16:21, 536.70frames/s]\n 46%|████▌     | 440400/964833 [14:08<14:09, 617.04frames/s]\n 46%|████▌     | 441600/964833 [14:09<13:28, 646.88frames/s]\n 46%|████▌     | 444400/964833 [14:12<12:16, 706.86frames/s]\n 46%|████▋     | 446700/964833 [14:17<13:51, 623.13frames/s]\n 47%|████▋     | 449500/964833 [14:22<13:59, 613.73frames/s]\n 47%|████▋     | 452400/964833 [14:27<14:04, 606.92frames/s]\n 47%|████▋     | 455100/964833 [14:30<12:43, 667.93frames/s]\n 47%|████▋     | 457800/964833 [14:32<11:00, 768.07frames/s]\n 48%|████▊     | 460500/964833 [14:35<10:19, 814.19frames/s]\n 48%|████▊     | 462700/964833 [14:38<10:29, 797.86frames/s]\n 48%|████▊     | 465400/964833 [14:41<09:36, 865.67frames/s]\n 49%|████▊     | 468100/964833 [14:44<09:52, 838.99frames/s]\n 49%|████▉     | 470700/964833 [14:47<09:31, 865.21frames/s]\n 49%|████▉     | 473500/964833 [14:50<09:03, 904.05frames/s]\n 49%|████▉     | 476200/964833 [14:55<11:06, 732.90frames/s]\n 50%|████▉     | 478900/964833 [15:00<12:24, 652.34frames/s]\n 50%|████▉     | 481300/964833 [15:05<13:47, 584.46frames/s]\n 50%|█████     | 484100/964833 [15:08<11:49, 678.04frames/s]\n 50%|█████     | 487000/964833 [15:13<12:31, 635.65frames/s]\n 51%|█████     | 489800/964833 [15:18<12:37, 627.30frames/s]\n 51%|█████     | 492400/964833 [15:23<13:46, 571.34frames/s]\n 51%|█████▏    | 495300/964833 [15:27<12:56, 604.81frames/s]\n 52%|█████▏    | 497300/964833 [15:31<12:54, 603.94frames/s]\n 52%|█████▏    | 500000/964833 [15:33<10:56, 708.21frames/s]\n 52%|█████▏    | 501100/964833 [15:35<11:16, 685.77frames/s]\n 52%|█████▏    | 504000/964833 [15:39<10:49, 709.67frames/s]\n 52%|█████▏    | 506500/964833 [15:44<12:21, 618.36frames/s]\n 53%|█████▎    | 509100/964833 [15:49<12:49, 591.95frames/s]\n 53%|█████▎    | 511400/964833 [15:54<13:39, 553.34frames/s]\n 53%|█████▎    | 513300/964833 [15:57<13:33, 555.23frames/s]\n 53%|█████▎    | 516100/964833 [16:01<12:20, 606.16frames/s]\n 54%|█████▍    | 518800/964833 [16:07<13:46, 539.69frames/s]\n 54%|█████▍    | 520900/964833 [16:12<14:51, 498.17frames/s]\n 54%|█████▍    | 523500/964833 [16:18<15:09, 485.16frames/s]\n 54%|█████▍    | 525800/964833 [16:23<15:07, 483.67frames/s]\n 55%|█████▍    | 528500/964833 [16:28<14:41, 494.84frames/s]\n 55%|█████▌    | 531400/964833 [16:34<15:07, 477.47frames/s]\n 55%|█████▌    | 534200/964833 [16:41<15:21, 467.19frames/s]\n 56%|█████▌    | 537000/964833 [16:46<15:00, 475.37frames/s]\n 56%|█████▌    | 539900/964833 [16:53<15:18, 462.61frames/s]\n 56%|█████▋    | 542800/964833 [16:59<15:06, 465.34frames/s]\n 57%|█████▋    | 545400/964833 [17:04<14:31, 481.35frames/s]\n 57%|█████▋    | 548200/964833 [17:09<13:39, 508.46frames/s]\n 57%|█████▋    | 550700/964833 [17:13<13:14, 521.44frames/s]\n 57%|█████▋    | 553400/964833 [17:21<14:47, 463.77frames/s]\n 58%|█████▊    | 556200/964833 [17:26<14:16, 477.23frames/s]\n 58%|█████▊    | 558400/964833 [17:31<14:17, 473.77frames/s]\n 58%|█████▊    | 560700/964833 [17:35<13:37, 494.20frames/s]\n 58%|█████▊    | 563200/964833 [17:39<12:42, 526.41frames/s]\n 59%|█████▊    | 565800/964833 [17:45<13:40, 486.35frames/s]\n 59%|█████▉    | 568000/964833 [17:49<12:50, 515.30frames/s]\n 59%|█████▉    | 570600/964833 [17:54<12:31, 524.78frames/s]\n 59%|█████▉    | 573500/964833 [17:59<12:11, 535.01frames/s]\n 60%|█████▉    | 576100/964833 [18:05<12:52, 503.04frames/s]\n 60%|██████    | 578900/964833 [18:10<12:34, 511.38frames/s]\n 60%|██████    | 581900/964833 [18:14<11:32, 552.67frames/s]\n 61%|██████    | 584700/964833 [18:20<11:41, 541.51frames/s]\n 61%|██████    | 587500/964833 [18:24<11:08, 564.40frames/s]\n 61%|██████    | 590500/964833 [18:30<11:02, 565.41frames/s]\n 61%|██████▏   | 593200/964833 [18:34<10:58, 564.64frames/s]\n 62%|██████▏   | 595900/964833 [18:40<11:35, 530.50frames/s]\n 62%|██████▏   | 598600/964833 [18:45<11:20, 537.82frames/s]\n 62%|██████▏   | 601400/964833 [18:50<10:49, 559.41frames/s]\n 63%|██████▎   | 604200/964833 [18:54<10:03, 597.68frames/s]\n 63%|██████▎   | 607200/964833 [18:58<09:36, 620.29frames/s]\n 63%|██████▎   | 610200/964833 [19:01<08:21, 707.09frames/s]\n 64%|██████▎   | 613200/964833 [19:04<07:32, 776.89frames/s]\n 64%|██████▍   | 615100/964833 [19:07<08:10, 713.42frames/s]\n 64%|██████▍   | 617600/964833 [19:10<07:46, 743.87frames/s]\n 64%|██████▍   | 620600/964833 [19:14<07:07, 805.22frames/s]\n 65%|██████▍   | 622900/964833 [19:15<06:25, 886.70frames/s]\n 65%|██████▍   | 625900/964833 [19:19<06:42, 842.68frames/s]\n 65%|██████▌   | 628900/964833 [19:22<06:01, 929.17frames/s]\n 65%|██████▌   | 631900/964833 [19:25<05:45, 964.28frames/s]\n 66%|██████▌   | 634700/964833 [19:29<06:25, 856.28frames/s]\n 66%|██████▌   | 637700/964833 [19:33<06:45, 807.65frames/s]\n 66%|██████▋   | 640300/964833 [19:37<07:00, 772.14frames/s]\n 67%|██████▋   | 643100/964833 [19:39<06:23, 839.17frames/s]\n 67%|██████▋   | 645900/964833 [19:43<06:17, 845.49frames/s]\n 67%|██████▋   | 648700/964833 [19:48<07:21, 715.52frames/s]\n 68%|██████▊   | 651700/964833 [19:51<06:50, 762.66frames/s]\n 68%|██████▊   | 654700/964833 [19:55<06:28, 798.29frames/s]\n 68%|██████▊   | 657500/964833 [20:01<07:59, 640.98frames/s]\n 68%|██████▊   | 660300/964833 [20:05<07:50, 647.55frames/s]\n 69%|██████▊   | 663300/964833 [20:09<07:11, 698.00frames/s]\n 69%|██████▉   | 666100/964833 [20:15<08:12, 606.32frames/s]\n 69%|██████▉   | 668700/964833 [20:20<08:16, 596.31frames/s]\n 70%|██████▉   | 671500/964833 [20:26<08:52, 551.06frames/s]\n 70%|██████▉   | 674300/964833 [20:33<09:49, 493.20frames/s]\n 70%|███████   | 677100/964833 [20:38<09:46, 490.33frames/s]\n 70%|███████   | 679900/964833 [20:45<09:53, 480.13frames/s]\n 71%|███████   | 682700/964833 [20:51<10:08, 463.85frames/s]\n 71%|███████   | 685500/964833 [20:56<09:39, 482.05frames/s]\n 71%|███████▏  | 688300/964833 [21:04<10:33, 436.74frames/s]\n 72%|███████▏  | 691100/964833 [21:10<10:05, 452.00frames/s]\n 72%|███████▏  | 693900/964833 [21:17<10:24, 433.91frames/s]\n 72%|███████▏  | 696700/964833 [21:23<10:05, 443.04frames/s]\n 72%|███████▏  | 699500/964833 [21:28<09:12, 480.51frames/s]\n 73%|███████▎  | 702300/964833 [21:34<09:10, 476.69frames/s]\n 73%|███████▎  | 705100/964833 [21:40<09:22, 461.96frames/s]\n 73%|███████▎  | 707900/964833 [21:47<09:30, 450.55frames/s]\n 74%|███████▎  | 710700/964833 [21:53<09:16, 456.64frames/s]\n 74%|███████▍  | 713500/964833 [21:59<09:27, 442.73frames/s]\n 74%|███████▍  | 716300/964833 [22:05<09:08, 452.84frames/s]\n 75%|███████▍  | 719100/964833 [22:12<09:17, 440.63frames/s]\n 75%|███████▍  | 721900/964833 [22:19<09:27, 428.11frames/s]\n 75%|███████▌  | 724700/964833 [22:27<09:49, 407.37frames/s]\n 75%|███████▌  | 724700/964833 [22:46<09:49, 407.37frames/s]\n 75%|███████▌  | 727524/964833 [23:20<29:12, 135.40frames/s]\n 76%|███████▌  | 730524/964833 [23:24<21:40, 180.12frames/s]\n 76%|███████▌  | 733524/964833 [23:25<15:04, 255.65frames/s]\n 76%|███████▌  | 733524/964833 [23:36<15:04, 255.65frames/s]\n 76%|███████▋  | 736444/964833 [23:51<20:35, 184.83frames/s]\n 77%|███████▋  | 739344/964833 [23:56<16:00, 234.74frames/s]\n 77%|███████▋  | 742344/964833 [23:58<11:49, 313.67frames/s]\n 77%|███████▋  | 744844/964833 [24:01<09:53, 370.86frames/s]\n 77%|███████▋  | 747544/964833 [24:05<08:19, 434.67frames/s]\n 78%|███████▊  | 750344/964833 [24:11<08:06, 440.45frames/s]\n 78%|███████▊  | 752944/964833 [24:16<07:46, 453.74frames/s]\n 78%|███████▊  | 755844/964833 [24:22<07:23, 471.07frames/s]\n 79%|███████▊  | 758144/964833 [24:25<06:33, 525.31frames/s]\n 79%|███████▉  | 760944/964833 [24:29<06:02, 562.23frames/s]\n 79%|███████▉  | 763844/964833 [24:35<06:12, 540.16frames/s]\n 79%|███████▉  | 766544/964833 [24:40<06:14, 529.11frames/s]\n 80%|███████▉  | 769244/964833 [24:46<06:11, 526.61frames/s]\n 80%|████████  | 772044/964833 [24:52<06:28, 496.20frames/s]\n 80%|████████  | 774744/964833 [24:58<06:27, 490.94frames/s]\n 81%|████████  | 777544/964833 [25:03<06:10, 505.66frames/s]\n 81%|████████  | 780344/964833 [25:09<06:23, 480.95frames/s]\n 81%|████████  | 783044/964833 [25:15<06:22, 475.71frames/s]\n 81%|████████▏ | 785844/964833 [25:20<06:03, 493.01frames/s]\n 82%|████████▏ | 787944/964833 [25:26<06:35, 446.78frames/s]\n 82%|████████▏ | 790644/964833 [25:33<06:34, 441.36frames/s]\n 82%|████████▏ | 793544/964833 [25:38<06:12, 460.38frames/s]\n 83%|████████▎ | 796444/964833 [25:43<05:45, 487.28frames/s]\n 83%|████████▎ | 799344/964833 [25:48<05:16, 523.11frames/s]\n 83%|████████▎ | 802244/964833 [25:55<05:26, 497.41frames/s]\n 83%|████████▎ | 805044/964833 [26:00<05:19, 500.68frames/s]\n 84%|████████▎ | 807944/964833 [26:06<05:22, 486.26frames/s]\n 84%|████████▍ | 810644/964833 [26:11<05:01, 511.49frames/s]\n 84%|████████▍ | 813444/964833 [26:17<05:07, 492.91frames/s]\n 85%|████████▍ | 816344/964833 [26:23<05:06, 484.77frames/s]\n 85%|████████▍ | 819244/964833 [26:29<04:54, 494.94frames/s]\n 85%|████████▌ | 822044/964833 [26:34<04:41, 507.46frames/s]\n 85%|████████▌ | 824744/964833 [26:39<04:21, 535.34frames/s]\n 86%|████████▌ | 827144/964833 [26:44<04:28, 513.40frames/s]\n 86%|████████▌ | 829344/964833 [26:47<04:03, 557.33frames/s]\n 86%|████████▌ | 831844/964833 [26:50<03:34, 619.49frames/s]\n 87%|████████▋ | 834644/964833 [26:53<03:12, 675.21frames/s]\n 87%|████████▋ | 837444/964833 [26:57<03:03, 695.95frames/s]\n 87%|████████▋ | 840144/964833 [26:59<02:35, 801.54frames/s]\n 87%|████████▋ | 842944/964833 [27:03<02:37, 771.84frames/s]\n 88%|████████▊ | 845744/964833 [27:07<02:36, 762.07frames/s]\n 88%|████████▊ | 848444/964833 [27:11<02:37, 740.38frames/s]\n 88%|████████▊ | 850744/964833 [27:13<02:23, 796.85frames/s]\n 88%|████████▊ | 852544/964833 [27:14<02:07, 884.10frames/s]\n 89%|████████▊ | 855044/964833 [27:17<02:00, 910.56frames/s]\n 89%|████████▉ | 857844/964833 [27:20<01:56, 918.74frames/s]\n 89%|████████▉ | 860344/964833 [27:23<01:54, 910.22frames/s]\n 89%|████████▉ | 863244/964833 [27:27<02:08, 791.26frames/s]\n 90%|████████▉ | 866144/964833 [27:34<02:34, 640.28frames/s]\n 90%|█████████ | 868744/964833 [27:37<02:28, 646.71frames/s]\n 90%|█████████ | 871544/964833 [27:43<02:34, 605.16frames/s]\n 91%|█████████ | 874344/964833 [27:48<02:37, 574.56frames/s]\n 91%|█████████ | 877244/964833 [27:55<02:45, 530.84frames/s]\n 91%|█████████ | 880044/964833 [28:00<02:45, 512.92frames/s]\n 92%|█████████▏| 882944/964833 [28:07<02:45, 494.68frames/s]\n 92%|█████████▏| 885544/964833 [28:12<02:39, 497.21frames/s]\n 92%|█████████▏| 888344/964833 [28:17<02:32, 503.10frames/s]\n 92%|█████████▏| 891244/964833 [28:24<02:35, 472.98frames/s]\n 93%|█████████▎| 893944/964833 [28:31<02:39, 443.06frames/s]\n 93%|█████████▎| 896644/964833 [28:37<02:33, 443.31frames/s]\n 93%|█████████▎| 896644/964833 [28:56<02:33, 443.31frames/s]\n 93%|█████████▎| 899644/964833 [29:12<05:37, 193.34frames/s]\n 93%|█████████▎| 899644/964833 [29:26<05:37, 193.34frames/s]\n 94%|█████████▎| 902644/964833 [29:41<06:49, 151.70frames/s]\n 94%|█████████▍| 905644/964833 [29:41<04:33, 216.74frames/s]\n 94%|█████████▍| 908044/964833 [29:45<03:35, 263.70frames/s]\n 94%|█████████▍| 910244/964833 [29:49<02:57, 307.97frames/s]\n 95%|█████████▍| 912944/964833 [29:53<02:21, 365.58frames/s]\n 95%|█████████▍| 915244/964833 [29:57<02:01, 408.45frames/s]\n 95%|█████████▌| 916944/964833 [29:58<01:40, 478.63frames/s]\n 95%|█████████▌| 919044/964833 [30:00<01:20, 567.45frames/s]\n 96%|█████████▌| 921544/964833 [30:05<01:18, 549.96frames/s]\n 96%|█████████▌| 924044/964833 [30:11<01:23, 491.41frames/s]\n 96%|█████████▌| 926944/964833 [30:17<01:16, 497.54frames/s]\n 96%|█████████▋| 929844/964833 [30:23<01:12, 479.82frames/s]\n 97%|█████████▋| 932644/964833 [30:30<01:09, 462.93frames/s]\n 97%|█████████▋| 935244/964833 [30:35<01:03, 466.28frames/s]\n 97%|█████████▋| 938144/964833 [30:42<00:57, 463.18frames/s]\n 98%|█████████▊| 941044/964833 [30:47<00:49, 477.11frames/s]\n 98%|█████████▊| 943444/964833 [30:53<00:45, 465.85frames/s]\n 98%|█████████▊| 945944/964833 [30:57<00:38, 495.48frames/s]\n 98%|█████████▊| 948544/964833 [31:01<00:30, 531.04frames/s]\n 99%|█████████▊| 950644/964833 [31:05<00:27, 518.22frames/s]\n 99%|█████████▊| 952744/964833 [31:09<00:23, 519.88frames/s]\n 99%|█████████▉| 955444/964833 [31:15<00:18, 514.70frames/s]\n 99%|█████████▉| 958244/964833 [31:21<00:13, 480.11frames/s]\n100%|█████████▉| 960744/964833 [31:27<00:08, 484.67frames/s]\n100%|█████████▉| 961833/964833 [31:27<00:05, 535.80frames/s]\n100%|█████████▉| 961833/964833 [31:27<00:05, 509.48frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.3737053706728179,
        "compression_ratio": 1.4933333333333334,
        "end": 14,
        "id": 0,
        "no_speech_prob": 0.2888355255126953,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Did you think that learning coding would be really rough?",
        "tokens": [
          50364,
          2589,
          291,
          519,
          300,
          2539,
          17720,
          576,
          312,
          534,
          5903,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.3737053706728179,
        "compression_ratio": 1.4933333333333334,
        "end": 17,
        "id": 1,
        "no_speech_prob": 0.2888355255126953,
        "seek": 0,
        "start": 14,
        "temperature": 0,
        "text": " Throw your hands up in the air and say enough's enough!",
        "tokens": [
          51064,
          22228,
          428,
          2377,
          493,
          294,
          264,
          1988,
          293,
          584,
          1547,
          311,
          1547,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.3737053706728179,
        "compression_ratio": 1.4933333333333334,
        "end": 20,
        "id": 2,
        "no_speech_prob": 0.2888355255126953,
        "seek": 0,
        "start": 17,
        "temperature": 0,
        "text": " Do you want to learn to code and make some awesome stuff?",
        "tokens": [
          51214,
          1144,
          291,
          528,
          281,
          1466,
          281,
          3089,
          293,
          652,
          512,
          3476,
          1507,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.3737053706728179,
        "compression_ratio": 1.4933333333333334,
        "end": 24,
        "id": 3,
        "no_speech_prob": 0.2888355255126953,
        "seek": 0,
        "start": 20,
        "temperature": 0,
        "text": " Learn that anyone can when you're coding with Danon!",
        "tokens": [
          51364,
          17216,
          300,
          2878,
          393,
          562,
          291,
          434,
          17720,
          365,
          3394,
          266,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 36,
        "id": 4,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 30,
        "temperature": 0,
        "text": " Whether you're a pro or this is all brand new,",
        "tokens": [
          50364,
          8503,
          291,
          434,
          257,
          447,
          420,
          341,
          307,
          439,
          3360,
          777,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 39,
        "id": 5,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 36,
        "temperature": 0,
        "text": " Learn the overarching concepts and some fun stuff too!",
        "tokens": [
          50664,
          17216,
          264,
          45501,
          10392,
          293,
          512,
          1019,
          1507,
          886,
          0,
          50814
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 46,
        "id": 6,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 39,
        "temperature": 0,
        "text": " And with Dan as your guide, come along for the ride on!",
        "tokens": [
          50814,
          400,
          365,
          3394,
          382,
          428,
          5934,
          11,
          808,
          2051,
          337,
          264,
          5077,
          322,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 49,
        "id": 7,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 46,
        "temperature": 0,
        "text": " Make a crazy pixel mirror to reflect your face,",
        "tokens": [
          51164,
          4387,
          257,
          3219,
          19261,
          8013,
          281,
          5031,
          428,
          1851,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 52,
        "id": 8,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 49,
        "temperature": 0,
        "text": " You can make a jump to light speed into outer space,",
        "tokens": [
          51314,
          509,
          393,
          652,
          257,
          3012,
          281,
          1442,
          3073,
          666,
          10847,
          1901,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 55,
        "id": 9,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 52,
        "temperature": 0,
        "text": " You can generate a maze that can go on for days,",
        "tokens": [
          51464,
          509,
          393,
          8460,
          257,
          33032,
          300,
          393,
          352,
          322,
          337,
          1708,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21598054944854422,
        "compression_ratio": 1.617117117117117,
        "end": 59,
        "id": 10,
        "no_speech_prob": 0.04022926092147827,
        "seek": 3000,
        "start": 55,
        "temperature": 0,
        "text": " You can make your own terrain and some purple rain,",
        "tokens": [
          51614,
          509,
          393,
          652,
          428,
          1065,
          17674,
          293,
          512,
          9656,
          4830,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.21828475365271935,
        "compression_ratio": 1.5454545454545454,
        "end": 62,
        "id": 11,
        "no_speech_prob": 0.011156701482832432,
        "seek": 5900,
        "start": 59,
        "temperature": 0,
        "text": " You can make a retro game to see how it's done,",
        "tokens": [
          50364,
          509,
          393,
          652,
          257,
          18820,
          1216,
          281,
          536,
          577,
          309,
          311,
          1096,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.21828475365271935,
        "compression_ratio": 1.5454545454545454,
        "end": 65,
        "id": 12,
        "no_speech_prob": 0.011156701482832432,
        "seek": 5900,
        "start": 62,
        "temperature": 0,
        "text": " And then tweak a piece to make it yours for everyone!",
        "tokens": [
          50514,
          400,
          550,
          29879,
          257,
          2522,
          281,
          652,
          309,
          6342,
          337,
          1518,
          0,
          50664
        ]
      },
      {
        "avg_logprob": -0.21828475365271935,
        "compression_ratio": 1.5454545454545454,
        "end": 68,
        "id": 13,
        "no_speech_prob": 0.011156701482832432,
        "seek": 5900,
        "start": 65,
        "temperature": 0,
        "text": " Make some fractally trees or twitter bots if you please,",
        "tokens": [
          50664,
          4387,
          512,
          17948,
          379,
          5852,
          420,
          21439,
          35410,
          498,
          291,
          1767,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.21828475365271935,
        "compression_ratio": 1.5454545454545454,
        "end": 72,
        "id": 14,
        "no_speech_prob": 0.011156701482832432,
        "seek": 5900,
        "start": 68,
        "temperature": 0,
        "text": " And when the seeds are a-sown, you can make them your own!",
        "tokens": [
          50814,
          400,
          562,
          264,
          9203,
          366,
          257,
          12,
          82,
          648,
          11,
          291,
          393,
          652,
          552,
          428,
          1065,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.21828475365271935,
        "compression_ratio": 1.5454545454545454,
        "end": 82,
        "id": 15,
        "no_speech_prob": 0.011156701482832432,
        "seek": 5900,
        "start": 78,
        "temperature": 0,
        "text": " Write the colors of code, you can follow the road too!",
        "tokens": [
          51314,
          23499,
          264,
          4577,
          295,
          3089,
          11,
          291,
          393,
          1524,
          264,
          3060,
          886,
          0,
          51514
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 91,
        "id": 16,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 89,
        "temperature": 0,
        "text": " Hello, welcome! I think I am live.",
        "tokens": [
          50364,
          2425,
          11,
          2928,
          0,
          286,
          519,
          286,
          669,
          1621,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 97,
        "id": 17,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 91,
        "temperature": 0,
        "text": " I'm using a... this is Dan, welcome to my YouTube live stream of undefined name.",
        "tokens": [
          50464,
          286,
          478,
          1228,
          257,
          485,
          341,
          307,
          3394,
          11,
          2928,
          281,
          452,
          3088,
          1621,
          4309,
          295,
          674,
          5666,
          2001,
          1315,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 100,
        "id": 18,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 97,
        "temperature": 0,
        "text": " I would like to know first off...",
        "tokens": [
          50764,
          286,
          576,
          411,
          281,
          458,
          700,
          766,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 104,
        "id": 19,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 100,
        "temperature": 0,
        "text": " First of all, I'd like to know first off if the audio is okay if you hear static.",
        "tokens": [
          50914,
          2386,
          295,
          439,
          11,
          286,
          1116,
          411,
          281,
          458,
          700,
          766,
          498,
          264,
          6278,
          307,
          1392,
          498,
          291,
          1568,
          13437,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 107,
        "id": 20,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 104,
        "temperature": 0,
        "text": " Because last week this particular microphone that I'm using right now",
        "tokens": [
          51114,
          1436,
          1036,
          1243,
          341,
          1729,
          10952,
          300,
          286,
          478,
          1228,
          558,
          586,
          51264
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 109,
        "id": 21,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 107,
        "temperature": 0,
        "text": " was having static issues.",
        "tokens": [
          51264,
          390,
          1419,
          13437,
          2663,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 113,
        "id": 22,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 109,
        "temperature": 0,
        "text": " But I decided maybe if it just rested for a week and I put it on again,",
        "tokens": [
          51364,
          583,
          286,
          3047,
          1310,
          498,
          309,
          445,
          43090,
          337,
          257,
          1243,
          293,
          286,
          829,
          309,
          322,
          797,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 115,
        "id": 23,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 113,
        "temperature": 0,
        "text": " that there wouldn't be any static.",
        "tokens": [
          51564,
          300,
          456,
          2759,
          380,
          312,
          604,
          13437,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.27400850727610343,
        "compression_ratio": 1.7142857142857142,
        "end": 118,
        "id": 24,
        "no_speech_prob": 0.6906949281692505,
        "seek": 8900,
        "start": 115,
        "temperature": 0,
        "text": " So I'm going to check the chat and see the other thing...",
        "tokens": [
          51664,
          407,
          286,
          478,
          516,
          281,
          1520,
          264,
          5081,
          293,
          536,
          264,
          661,
          551,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 120,
        "id": 25,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 118,
        "temperature": 0,
        "text": " Ah! The other thing I have to say is I...",
        "tokens": [
          50364,
          2438,
          0,
          440,
          661,
          551,
          286,
          362,
          281,
          584,
          307,
          286,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 125,
        "id": 26,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 120,
        "temperature": 0,
        "text": " Normally when I come down here, I'm live from the school for poetic computation,",
        "tokens": [
          50464,
          17424,
          562,
          286,
          808,
          760,
          510,
          11,
          286,
          478,
          1621,
          490,
          264,
          1395,
          337,
          41080,
          24903,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 129,
        "id": 27,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 125,
        "temperature": 0,
        "text": " Normally when I get ready to come to a live stream,",
        "tokens": [
          50714,
          17424,
          562,
          286,
          483,
          1919,
          281,
          808,
          281,
          257,
          1621,
          4309,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 131,
        "id": 28,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 129,
        "temperature": 0,
        "text": " I bring three devices with me.",
        "tokens": [
          50914,
          286,
          1565,
          1045,
          5759,
          365,
          385,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 133,
        "id": 29,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 131,
        "temperature": 0,
        "text": " I bring two laptops and a tablet,",
        "tokens": [
          51014,
          286,
          1565,
          732,
          27642,
          293,
          257,
          14136,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 137,
        "id": 30,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 133,
        "temperature": 0,
        "text": " because I have like the chat on one, and I have a soundboard on the other,",
        "tokens": [
          51114,
          570,
          286,
          362,
          411,
          264,
          5081,
          322,
          472,
          11,
          293,
          286,
          362,
          257,
          1626,
          3787,
          322,
          264,
          661,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 139,
        "id": 31,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 137,
        "temperature": 0,
        "text": " and then I have the computer I'm using to code,",
        "tokens": [
          51314,
          293,
          550,
          286,
          362,
          264,
          3820,
          286,
          478,
          1228,
          281,
          3089,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2505552485837775,
        "compression_ratio": 1.697674418604651,
        "end": 143,
        "id": 32,
        "no_speech_prob": 0.008443210273981094,
        "seek": 11800,
        "start": 139,
        "temperature": 0,
        "text": " and I completely just this morning forgot everything but my regular laptop.",
        "tokens": [
          51414,
          293,
          286,
          2584,
          445,
          341,
          2446,
          5298,
          1203,
          457,
          452,
          3890,
          10732,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 149,
        "id": 33,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 143,
        "temperature": 0,
        "text": " So I do have the streaming computer which I am now running...",
        "tokens": [
          50364,
          407,
          286,
          360,
          362,
          264,
          11791,
          3820,
          597,
          286,
          669,
          586,
          2614,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 151,
        "id": 34,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 149,
        "temperature": 0,
        "text": " I'm kind of... which usually I just use as a monitor,",
        "tokens": [
          50664,
          286,
          478,
          733,
          295,
          485,
          597,
          2673,
          286,
          445,
          764,
          382,
          257,
          6002,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 153,
        "id": 35,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 151,
        "temperature": 0,
        "text": " but I'm actually looking at the chat on that.",
        "tokens": [
          50764,
          457,
          286,
          478,
          767,
          1237,
          412,
          264,
          5081,
          322,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 155,
        "id": 36,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 153,
        "temperature": 0,
        "text": " So when I'm looking this direction,",
        "tokens": [
          50864,
          407,
          562,
          286,
          478,
          1237,
          341,
          3513,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 159,
        "id": 37,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 155,
        "temperature": 0,
        "text": " it looks like I'm referring to this beautiful rainbow over here,",
        "tokens": [
          50964,
          309,
          1542,
          411,
          286,
          478,
          13761,
          281,
          341,
          2238,
          18526,
          670,
          510,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 161,
        "id": 38,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 159,
        "temperature": 0,
        "text": " but really I am looking at your chat,",
        "tokens": [
          51164,
          457,
          534,
          286,
          669,
          1237,
          412,
          428,
          5081,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 164,
        "id": 39,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 161,
        "temperature": 0,
        "text": " which for example it says it's a little bit too quiet,",
        "tokens": [
          51264,
          597,
          337,
          1365,
          309,
          1619,
          309,
          311,
          257,
          707,
          857,
          886,
          5677,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 167,
        "id": 40,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 164,
        "temperature": 0,
        "text": " or sometimes I do read the messages, sometimes I don't.",
        "tokens": [
          51414,
          420,
          2171,
          286,
          360,
          1401,
          264,
          7897,
          11,
          2171,
          286,
          500,
          380,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 168,
        "id": 41,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 167,
        "temperature": 0,
        "text": " There's a discussion.",
        "tokens": [
          51564,
          821,
          311,
          257,
          5017,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20584431985267124,
        "compression_ratio": 1.7056737588652482,
        "end": 170,
        "id": 42,
        "no_speech_prob": 0.0780227929353714,
        "seek": 14300,
        "start": 168,
        "temperature": 0,
        "text": " Okay, good news for you is that I can easily...",
        "tokens": [
          51614,
          1033,
          11,
          665,
          2583,
          337,
          291,
          307,
          300,
          286,
          393,
          3612,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 172,
        "id": 43,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 170,
        "temperature": 0,
        "text": " I have a mixing board.",
        "tokens": [
          50364,
          286,
          362,
          257,
          11983,
          3150,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 174,
        "id": 44,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 172,
        "temperature": 0,
        "text": " It's very exciting.",
        "tokens": [
          50464,
          467,
          311,
          588,
          4670,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 176,
        "id": 45,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 174,
        "temperature": 0,
        "text": " I can turn the volume up a tiny bit, which I'm going to do.",
        "tokens": [
          50564,
          286,
          393,
          1261,
          264,
          5523,
          493,
          257,
          5870,
          857,
          11,
          597,
          286,
          478,
          516,
          281,
          360,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 178,
        "id": 46,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 176,
        "temperature": 0,
        "text": " I'm a little bit low to do this,",
        "tokens": [
          50664,
          286,
          478,
          257,
          707,
          857,
          2295,
          281,
          360,
          341,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 181,
        "id": 47,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 178,
        "temperature": 0,
        "text": " because last week there were some peaking issues,",
        "tokens": [
          50764,
          570,
          1036,
          1243,
          456,
          645,
          512,
          520,
          2456,
          2663,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 184,
        "id": 48,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 181,
        "temperature": 0,
        "text": " where as I talked the volume peaked,",
        "tokens": [
          50914,
          689,
          382,
          286,
          2825,
          264,
          5523,
          520,
          7301,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 187,
        "id": 49,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 184,
        "temperature": 0,
        "text": " but I can see where the bar is going is not going too high.",
        "tokens": [
          51064,
          457,
          286,
          393,
          536,
          689,
          264,
          2159,
          307,
          516,
          307,
          406,
          516,
          886,
          1090,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 189,
        "id": 50,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 187,
        "temperature": 0,
        "text": " So I think... I don't see any red lights over here,",
        "tokens": [
          51214,
          407,
          286,
          519,
          485,
          286,
          500,
          380,
          536,
          604,
          2182,
          5811,
          670,
          510,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 190,
        "id": 51,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 189,
        "temperature": 0,
        "text": " so I think I'm okay.",
        "tokens": [
          51314,
          370,
          286,
          519,
          286,
          478,
          1392,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 193,
        "id": 52,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 190,
        "temperature": 0,
        "text": " I'm also... I have to admit which...",
        "tokens": [
          51364,
          286,
          478,
          611,
          485,
          286,
          362,
          281,
          9796,
          597,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 197,
        "id": 53,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 193,
        "temperature": 0,
        "text": " Last spring when I started doing the weekly live streams,",
        "tokens": [
          51514,
          5264,
          5587,
          562,
          286,
          1409,
          884,
          264,
          12460,
          1621,
          15842,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.1938130460827556,
        "compression_ratio": 1.7615658362989324,
        "end": 199,
        "id": 54,
        "no_speech_prob": 0.2657439112663269,
        "seek": 17000,
        "start": 197,
        "temperature": 0,
        "text": " and last spring I was doing it twice a week,",
        "tokens": [
          51714,
          293,
          1036,
          5587,
          286,
          390,
          884,
          309,
          6091,
          257,
          1243,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 202,
        "id": 55,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 199,
        "temperature": 0,
        "text": " I was kind of excited about it, I'm energetic about it,",
        "tokens": [
          50364,
          286,
          390,
          733,
          295,
          2919,
          466,
          309,
          11,
          286,
          478,
          24935,
          466,
          309,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 205,
        "id": 56,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 202,
        "temperature": 0,
        "text": " which I still am, but I was sort of curious how this would go,",
        "tokens": [
          50514,
          597,
          286,
          920,
          669,
          11,
          457,
          286,
          390,
          1333,
          295,
          6369,
          577,
          341,
          576,
          352,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 210,
        "id": 57,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 205,
        "temperature": 0,
        "text": " teaching full time at ITP at NYU and doing this YouTube channel.",
        "tokens": [
          50664,
          4571,
          1577,
          565,
          412,
          6783,
          47,
          412,
          42682,
          293,
          884,
          341,
          3088,
          2269,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 212,
        "id": 58,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 210,
        "temperature": 0,
        "text": " And I think it's been going pretty well,",
        "tokens": [
          50914,
          400,
          286,
          519,
          309,
          311,
          668,
          516,
          1238,
          731,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 214,
        "id": 59,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 212,
        "temperature": 0,
        "text": " but this week I'm starting to feel the crunch,",
        "tokens": [
          51014,
          457,
          341,
          1243,
          286,
          478,
          2891,
          281,
          841,
          264,
          13386,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 217,
        "id": 60,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 214,
        "temperature": 0,
        "text": " and I'm just like overloaded with things to do,",
        "tokens": [
          51114,
          293,
          286,
          478,
          445,
          411,
          28777,
          292,
          365,
          721,
          281,
          360,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 218,
        "id": 61,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 217,
        "temperature": 0,
        "text": " and I'm like not prepared,",
        "tokens": [
          51264,
          293,
          286,
          478,
          411,
          406,
          4927,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 220,
        "id": 62,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 218,
        "temperature": 0,
        "text": " and I wasn't even sure if I'd have time to do this today,",
        "tokens": [
          51314,
          293,
          286,
          2067,
          380,
          754,
          988,
          498,
          286,
          1116,
          362,
          565,
          281,
          360,
          341,
          965,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 223,
        "id": 63,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 220,
        "temperature": 0,
        "text": " which is why I didn't send out an announcement to like an hour in advance.",
        "tokens": [
          51414,
          597,
          307,
          983,
          286,
          994,
          380,
          2845,
          484,
          364,
          12847,
          281,
          411,
          364,
          1773,
          294,
          7295,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18577736976162698,
        "compression_ratio": 1.6719242902208202,
        "end": 228,
        "id": 64,
        "no_speech_prob": 0.00818660482764244,
        "seek": 19900,
        "start": 223,
        "temperature": 0,
        "text": " So hopefully schedule-wise things will start to...",
        "tokens": [
          51564,
          407,
          4696,
          7567,
          12,
          3711,
          721,
          486,
          722,
          281,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 230,
        "id": 65,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 228,
        "temperature": 0,
        "text": " There will be ebbs and flows,",
        "tokens": [
          50364,
          821,
          486,
          312,
          308,
          65,
          929,
          293,
          12867,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 234,
        "id": 66,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 230,
        "temperature": 0,
        "text": " and so maybe I'll catch up and do a couple extra live streams in January,",
        "tokens": [
          50464,
          293,
          370,
          1310,
          286,
          603,
          3745,
          493,
          293,
          360,
          257,
          1916,
          2857,
          1621,
          15842,
          294,
          7061,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 237,
        "id": 67,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 234,
        "temperature": 0,
        "text": " for example, if I miss some in November and December,",
        "tokens": [
          50664,
          337,
          1365,
          11,
          498,
          286,
          1713,
          512,
          294,
          7674,
          293,
          7687,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 241,
        "id": 68,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 237,
        "temperature": 0,
        "text": " but I can tell already that the next couple months is only getting busier and busier.",
        "tokens": [
          50814,
          457,
          286,
          393,
          980,
          1217,
          300,
          264,
          958,
          1916,
          2493,
          307,
          787,
          1242,
          1255,
          811,
          293,
          1255,
          811,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 246,
        "id": 69,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 241,
        "temperature": 0,
        "text": " But first, a big thank you to...",
        "tokens": [
          51014,
          583,
          700,
          11,
          257,
          955,
          1309,
          291,
          281,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 249,
        "id": 70,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 246,
        "temperature": 0,
        "text": " Ah, okay, so lots of people are asking questions about the name.",
        "tokens": [
          51264,
          2438,
          11,
          1392,
          11,
          370,
          3195,
          295,
          561,
          366,
          3365,
          1651,
          466,
          264,
          1315,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 252,
        "id": 71,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 249,
        "temperature": 0,
        "text": " I did talk about this on the live stream last week,",
        "tokens": [
          51414,
          286,
          630,
          751,
          466,
          341,
          322,
          264,
          1621,
          4309,
          1036,
          1243,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.17999510037696967,
        "compression_ratio": 1.5902255639097744,
        "end": 253,
        "id": 72,
        "no_speech_prob": 0.003075162647292018,
        "seek": 22800,
        "start": 252,
        "temperature": 0,
        "text": " I will just mention it again.",
        "tokens": [
          51564,
          286,
          486,
          445,
          2152,
          309,
          797,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 258,
        "id": 73,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 253,
        "temperature": 0,
        "text": " Unfortunately, due to a trademark issue with Reading Rainbow,",
        "tokens": [
          50364,
          8590,
          11,
          3462,
          281,
          257,
          31361,
          2734,
          365,
          29766,
          29477,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 263,
        "id": 74,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 258,
        "temperature": 0,
        "text": " who has been nothing but nice and generous with me in their support and discussion about this,",
        "tokens": [
          50614,
          567,
          575,
          668,
          1825,
          457,
          1481,
          293,
          14537,
          365,
          385,
          294,
          641,
          1406,
          293,
          5017,
          466,
          341,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 267,
        "id": 75,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 263,
        "temperature": 0,
        "text": " but it looks like based on all the advice and research that I've done",
        "tokens": [
          50864,
          457,
          309,
          1542,
          411,
          2361,
          322,
          439,
          264,
          5192,
          293,
          2132,
          300,
          286,
          600,
          1096,
          51064
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 270,
        "id": 76,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 267,
        "temperature": 0,
        "text": " that it is a legitimate trademark conflict,",
        "tokens": [
          51064,
          300,
          309,
          307,
          257,
          17956,
          31361,
          6596,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 273,
        "id": 77,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 270,
        "temperature": 0,
        "text": " Reading Rainbow and the previous name of this channel,",
        "tokens": [
          51214,
          29766,
          29477,
          293,
          264,
          3894,
          1315,
          295,
          341,
          2269,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 276,
        "id": 78,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 273,
        "temperature": 0,
        "text": " which I guess I'm avoiding saying.",
        "tokens": [
          51364,
          597,
          286,
          2041,
          286,
          478,
          20220,
          1566,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 278,
        "id": 79,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 276,
        "temperature": 0,
        "text": " So I'm looking, I'm in the market for a new name.",
        "tokens": [
          51514,
          407,
          286,
          478,
          1237,
          11,
          286,
          478,
          294,
          264,
          2142,
          337,
          257,
          777,
          1315,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17621191557463226,
        "compression_ratio": 1.6716981132075472,
        "end": 280,
        "id": 80,
        "no_speech_prob": 0.36638447642326355,
        "seek": 25300,
        "start": 278,
        "temperature": 0,
        "text": " However, I still have a rainbow.",
        "tokens": [
          51614,
          2908,
          11,
          286,
          920,
          362,
          257,
          18526,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 284,
        "id": 81,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 280,
        "temperature": 0,
        "text": " I don't know, you guys can all tweet at LeVar Burton if you want to register your...",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          11,
          291,
          1074,
          393,
          439,
          15258,
          412,
          1456,
          53,
          289,
          46011,
          498,
          291,
          528,
          281,
          7280,
          428,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 286,
        "id": 82,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 284,
        "temperature": 0,
        "text": " But you should only tweet with love,",
        "tokens": [
          50564,
          583,
          291,
          820,
          787,
          15258,
          365,
          959,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 290,
        "id": 83,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 286,
        "temperature": 0,
        "text": " because Reading Rainbow is a wonderful, wonderful kids program and show,",
        "tokens": [
          50664,
          570,
          29766,
          29477,
          307,
          257,
          3715,
          11,
          3715,
          2301,
          1461,
          293,
          855,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 294,
        "id": 84,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 290,
        "temperature": 0,
        "text": " and I believe they have an app now about learning to read.",
        "tokens": [
          50864,
          293,
          286,
          1697,
          436,
          362,
          364,
          724,
          586,
          466,
          2539,
          281,
          1401,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 299,
        "id": 85,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 294,
        "temperature": 0,
        "text": " So I don't want to spend too much time talking about the name of this channel,",
        "tokens": [
          51064,
          407,
          286,
          500,
          380,
          528,
          281,
          3496,
          886,
          709,
          565,
          1417,
          466,
          264,
          1315,
          295,
          341,
          2269,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 302,
        "id": 86,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 299,
        "temperature": 0,
        "text": " because primarily I think the point of this channel is...",
        "tokens": [
          51314,
          570,
          10029,
          286,
          519,
          264,
          935,
          295,
          341,
          2269,
          307,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 305,
        "id": 87,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 302,
        "temperature": 0,
        "text": " I was going to say rainbows,",
        "tokens": [
          51464,
          286,
          390,
          516,
          281,
          584,
          4830,
          21118,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.2133586565653483,
        "compression_ratio": 1.6989247311827957,
        "end": 308,
        "id": 88,
        "no_speech_prob": 0.07914421707391739,
        "seek": 28000,
        "start": 305,
        "temperature": 0,
        "text": " but is friendly and accessible tutorials about coding.",
        "tokens": [
          51614,
          457,
          307,
          9208,
          293,
          9515,
          17616,
          466,
          17720,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 314,
        "id": 89,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 308,
        "temperature": 0,
        "text": " I would also like for the viewers of this channel to see a lot of different faces and voices,",
        "tokens": [
          50364,
          286,
          576,
          611,
          411,
          337,
          264,
          8499,
          295,
          341,
          2269,
          281,
          536,
          257,
          688,
          295,
          819,
          8475,
          293,
          9802,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 317,
        "id": 90,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 314,
        "temperature": 0,
        "text": " talk and demonstrate stuff about coding.",
        "tokens": [
          50664,
          751,
          293,
          11698,
          1507,
          466,
          17720,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 320,
        "id": 91,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 317,
        "temperature": 0,
        "text": " So each week I'm also hoping to have a guest now,",
        "tokens": [
          50814,
          407,
          1184,
          1243,
          286,
          478,
          611,
          7159,
          281,
          362,
          257,
          8341,
          586,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 321,
        "id": 92,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 320,
        "temperature": 0,
        "text": " and I have a guest coming.",
        "tokens": [
          50964,
          293,
          286,
          362,
          257,
          8341,
          1348,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 324,
        "id": 93,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 321,
        "temperature": 0,
        "text": " I probably won't live stream it later today in the studio.",
        "tokens": [
          51014,
          286,
          1391,
          1582,
          380,
          1621,
          4309,
          309,
          1780,
          965,
          294,
          264,
          6811,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 325,
        "id": 94,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 324,
        "temperature": 0,
        "text": " So if you subscribe to the channel,",
        "tokens": [
          51164,
          407,
          498,
          291,
          3022,
          281,
          264,
          2269,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 328,
        "id": 95,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 325,
        "temperature": 0,
        "text": " you'll see a video with a guest tutorial coming sometime soon.",
        "tokens": [
          51214,
          291,
          603,
          536,
          257,
          960,
          365,
          257,
          8341,
          7073,
          1348,
          15053,
          2321,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 331,
        "id": 96,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 328,
        "temperature": 0,
        "text": " I would love to partner with Reading Rainbow.",
        "tokens": [
          51364,
          286,
          576,
          959,
          281,
          4975,
          365,
          29766,
          29477,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 333,
        "id": 97,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 331,
        "temperature": 0,
        "text": " I don't think that that's an option for me,",
        "tokens": [
          51514,
          286,
          500,
          380,
          519,
          300,
          300,
          311,
          364,
          3614,
          337,
          385,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.16449267263630873,
        "compression_ratio": 1.7108843537414966,
        "end": 335,
        "id": 98,
        "no_speech_prob": 0.08262196183204651,
        "seek": 30800,
        "start": 333,
        "temperature": 0,
        "text": " although that would certainly be wonderful.",
        "tokens": [
          51614,
          4878,
          300,
          576,
          3297,
          312,
          3715,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 338,
        "id": 99,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 336,
        "temperature": 0,
        "text": " One name that I have that I actually really like,",
        "tokens": [
          50414,
          1485,
          1315,
          300,
          286,
          362,
          300,
          286,
          767,
          534,
          411,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 340,
        "id": 100,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 338,
        "temperature": 0,
        "text": " but a lot of people don't like,",
        "tokens": [
          50514,
          457,
          257,
          688,
          295,
          561,
          500,
          380,
          411,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 341,
        "id": 101,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 340,
        "temperature": 0,
        "text": " so I recognize that in fact.",
        "tokens": [
          50614,
          370,
          286,
          5521,
          300,
          294,
          1186,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 344,
        "id": 102,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 341,
        "temperature": 0,
        "text": " I'm thinking of kind of kids show style names,",
        "tokens": [
          50664,
          286,
          478,
          1953,
          295,
          733,
          295,
          2301,
          855,
          3758,
          5288,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 346,
        "id": 103,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 344,
        "temperature": 0,
        "text": " even though this is not a kids show,",
        "tokens": [
          50814,
          754,
          1673,
          341,
          307,
          406,
          257,
          2301,
          855,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 351,
        "id": 104,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 346,
        "temperature": 0,
        "text": " but my sort of aesthetic and attitude and things that I love",
        "tokens": [
          50914,
          457,
          452,
          1333,
          295,
          20092,
          293,
          10157,
          293,
          721,
          300,
          286,
          959,
          51164
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 356,
        "id": 105,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 351,
        "temperature": 0,
        "text": " are kind of in the realm of Reading Rainbow, Mr. Rogers' Neighborhood,",
        "tokens": [
          51164,
          366,
          733,
          295,
          294,
          264,
          15355,
          295,
          29766,
          29477,
          11,
          2221,
          13,
          29877,
          6,
          47729,
          3809,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 357,
        "id": 106,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 356,
        "temperature": 0,
        "text": " things like that.",
        "tokens": [
          51414,
          721,
          411,
          300,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 358,
        "id": 107,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 357,
        "temperature": 0,
        "text": " So I was thinking of...",
        "tokens": [
          51464,
          407,
          286,
          390,
          1953,
          295,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 360,
        "id": 108,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 358,
        "temperature": 0,
        "text": " Actually it was suggested on Twitter.",
        "tokens": [
          51514,
          5135,
          309,
          390,
          10945,
          322,
          5794,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 361,
        "id": 109,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 360,
        "temperature": 0,
        "text": " I have to look up who suggested this.",
        "tokens": [
          51614,
          286,
          362,
          281,
          574,
          493,
          567,
          10945,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2085459286108949,
        "compression_ratio": 1.7238805970149254,
        "end": 362,
        "id": 110,
        "no_speech_prob": 0.12244395911693573,
        "seek": 33500,
        "start": 361,
        "temperature": 0,
        "text": " The Coding Train.",
        "tokens": [
          51664,
          440,
          383,
          8616,
          28029,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 363,
        "id": 111,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 362,
        "temperature": 0,
        "text": " The reason why now,",
        "tokens": [
          50364,
          440,
          1778,
          983,
          586,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 365,
        "id": 112,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 363,
        "temperature": 0,
        "text": " before you get too upset about that as a name,",
        "tokens": [
          50414,
          949,
          291,
          483,
          886,
          8340,
          466,
          300,
          382,
          257,
          1315,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 368,
        "id": 113,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 365,
        "temperature": 0,
        "text": " picture this, a train coming in,",
        "tokens": [
          50514,
          3036,
          341,
          11,
          257,
          3847,
          1348,
          294,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 372,
        "id": 114,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 368,
        "temperature": 0,
        "text": " a steam train with rainbows coming out of the steam engine,",
        "tokens": [
          50664,
          257,
          11952,
          3847,
          365,
          4830,
          21118,
          1348,
          484,
          295,
          264,
          11952,
          2848,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 373,
        "id": 115,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 372,
        "temperature": 0,
        "text": " and in the back, in the train,",
        "tokens": [
          50864,
          293,
          294,
          264,
          646,
          11,
          294,
          264,
          3847,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 377,
        "id": 116,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 373,
        "temperature": 0,
        "text": " riding along a horde of unicorns and other people or something.",
        "tokens": [
          50914,
          9546,
          2051,
          257,
          276,
          15127,
          295,
          28122,
          82,
          293,
          661,
          561,
          420,
          746,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 379,
        "id": 117,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 377,
        "temperature": 0,
        "text": " So that's sort of what I'm thinking.",
        "tokens": [
          51114,
          407,
          300,
          311,
          1333,
          295,
          437,
          286,
          478,
          1953,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 383,
        "id": 118,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 379,
        "temperature": 0,
        "text": " The Joy of Coding is also something that I've been thinking about.",
        "tokens": [
          51214,
          440,
          15571,
          295,
          383,
          8616,
          307,
          611,
          746,
          300,
          286,
          600,
          668,
          1953,
          466,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 386,
        "id": 119,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 383,
        "temperature": 0,
        "text": " Choo-choo all aboard the coding train.",
        "tokens": [
          51414,
          761,
          1986,
          12,
          339,
          1986,
          439,
          27488,
          264,
          17720,
          3847,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 389,
        "id": 120,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 388,
        "temperature": 0,
        "text": " Can't you imagine, you know, something...",
        "tokens": [
          51664,
          1664,
          380,
          291,
          3811,
          11,
          291,
          458,
          11,
          746,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.2187909335954815,
        "compression_ratio": 1.7601476014760147,
        "end": 391,
        "id": 121,
        "no_speech_prob": 0.3485386073589325,
        "seek": 36200,
        "start": 389,
        "temperature": 0,
        "text": " Anyway, so I don't want to get too...",
        "tokens": [
          51714,
          5684,
          11,
          370,
          286,
          500,
          380,
          528,
          281,
          483,
          886,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 392,
        "id": 122,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 391,
        "temperature": 0,
        "text": " I did do a Markov chain.",
        "tokens": [
          50364,
          286,
          630,
          360,
          257,
          3934,
          5179,
          5021,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 394,
        "id": 123,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 392,
        "temperature": 0,
        "text": " Oh, I haven't released all my videos yet.",
        "tokens": [
          50414,
          876,
          11,
          286,
          2378,
          380,
          4736,
          439,
          452,
          2145,
          1939,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 395,
        "id": 124,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 394,
        "temperature": 0,
        "text": " I'm so behind on everything.",
        "tokens": [
          50514,
          286,
          478,
          370,
          2261,
          322,
          1203,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 397,
        "id": 125,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 395,
        "temperature": 0,
        "text": " I did a Markov chain tutorial last week,",
        "tokens": [
          50564,
          286,
          630,
          257,
          3934,
          5179,
          5021,
          7073,
          1036,
          1243,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 402,
        "id": 126,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 397,
        "temperature": 0,
        "text": " which is an algorithm that can be used to generate text randomly",
        "tokens": [
          50664,
          597,
          307,
          364,
          9284,
          300,
          393,
          312,
          1143,
          281,
          8460,
          2487,
          16979,
          50914
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 403,
        "id": 127,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 402,
        "temperature": 0,
        "text": " based on other text.",
        "tokens": [
          50914,
          2361,
          322,
          661,
          2487,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 404,
        "id": 128,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 403,
        "temperature": 0,
        "text": " I tried to generate a name for the channel.",
        "tokens": [
          50964,
          286,
          3031,
          281,
          8460,
          257,
          1315,
          337,
          264,
          2269,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 406,
        "id": 129,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 404,
        "temperature": 0,
        "text": " I was not able to do that.",
        "tokens": [
          51014,
          286,
          390,
          406,
          1075,
          281,
          360,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 408,
        "id": 130,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 406,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 410,
        "id": 131,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 408,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 413,
        "id": 132,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 412,
        "temperature": 0,
        "text": " So if you have strong...",
        "tokens": [
          51414,
          407,
          498,
          291,
          362,
          2068,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 414,
        "id": 133,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 413,
        "temperature": 0,
        "text": " I'm looking over here at the chat.",
        "tokens": [
          51464,
          286,
          478,
          1237,
          670,
          510,
          412,
          264,
          5081,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16523841797836183,
        "compression_ratio": 1.6970954356846473,
        "end": 417,
        "id": 134,
        "no_speech_prob": 0.022973721846938133,
        "seek": 39100,
        "start": 414,
        "temperature": 0,
        "text": " If you have strong opinions about the name,",
        "tokens": [
          51514,
          759,
          291,
          362,
          2068,
          11819,
          466,
          264,
          1315,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 420,
        "id": 135,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 417,
        "temperature": 0,
        "text": " I kind of almost feel like I might take it easy for a while",
        "tokens": [
          50364,
          286,
          733,
          295,
          1920,
          841,
          411,
          286,
          1062,
          747,
          309,
          1858,
          337,
          257,
          1339,
          50514
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 423,
        "id": 136,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 420,
        "temperature": 0,
        "text": " and just kind of leave the channel as undefined,",
        "tokens": [
          50514,
          293,
          445,
          733,
          295,
          1856,
          264,
          2269,
          382,
          674,
          5666,
          2001,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 425,
        "id": 137,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 423,
        "temperature": 0,
        "text": " which in many ways is a very appropriate name,",
        "tokens": [
          50664,
          597,
          294,
          867,
          2098,
          307,
          257,
          588,
          6854,
          1315,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 430,
        "id": 138,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 425,
        "temperature": 0,
        "text": " and return to hopefully launch in 2017 with a new name",
        "tokens": [
          50764,
          293,
          2736,
          281,
          4696,
          4025,
          294,
          6591,
          365,
          257,
          777,
          1315,
          51014
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 433,
        "id": 139,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 430,
        "temperature": 0,
        "text": " if it takes me a month or two to kind of get that all settled.",
        "tokens": [
          51014,
          498,
          309,
          2516,
          385,
          257,
          1618,
          420,
          732,
          281,
          733,
          295,
          483,
          300,
          439,
          14819,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 435,
        "id": 140,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 433,
        "temperature": 0,
        "text": " Markov train.",
        "tokens": [
          51164,
          3934,
          5179,
          3847,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 437,
        "id": 141,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 435,
        "temperature": 0,
        "text": " Yes, I like that.",
        "tokens": [
          51264,
          1079,
          11,
          286,
          411,
          300,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 439,
        "id": 142,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 437,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 441,
        "id": 143,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 439,
        "temperature": 0,
        "text": " No, the stream is not ending soon.",
        "tokens": [
          51464,
          883,
          11,
          264,
          4309,
          307,
          406,
          8121,
          2321,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17045617318368173,
        "compression_ratio": 1.5333333333333334,
        "end": 443,
        "id": 144,
        "no_speech_prob": 0.08266482502222061,
        "seek": 41700,
        "start": 441,
        "temperature": 0,
        "text": " We have just started.",
        "tokens": [
          51564,
          492,
          362,
          445,
          1409,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 449,
        "id": 145,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 443,
        "temperature": 0,
        "text": " So today's topic, beyond me just really wanting to take a nap.",
        "tokens": [
          50364,
          407,
          965,
          311,
          4829,
          11,
          4399,
          385,
          445,
          534,
          7935,
          281,
          747,
          257,
          9296,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 453,
        "id": 146,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 449,
        "temperature": 0,
        "text": " Have you ever had that feeling where you just want to take a nap?",
        "tokens": [
          50664,
          3560,
          291,
          1562,
          632,
          300,
          2633,
          689,
          291,
          445,
          528,
          281,
          747,
          257,
          9296,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 454,
        "id": 147,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 453,
        "temperature": 0,
        "text": " It's the afternoon.",
        "tokens": [
          50864,
          467,
          311,
          264,
          6499,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 455,
        "id": 148,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 454,
        "temperature": 0,
        "text": " You're tired.",
        "tokens": [
          50914,
          509,
          434,
          5868,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 456,
        "id": 149,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 455,
        "temperature": 0,
        "text": " It's been a long day already.",
        "tokens": [
          50964,
          467,
          311,
          668,
          257,
          938,
          786,
          1217,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 458,
        "id": 150,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 456,
        "temperature": 0,
        "text": " You already taught a three-hour class.",
        "tokens": [
          51014,
          509,
          1217,
          5928,
          257,
          1045,
          12,
          18048,
          1508,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 460,
        "id": 151,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 458,
        "temperature": 0,
        "text": " Morning.",
        "tokens": [
          51114,
          17967,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 464,
        "id": 152,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 460,
        "temperature": 0,
        "text": " It's cold, which I think the one good thing about it being cold in New York City now",
        "tokens": [
          51214,
          467,
          311,
          3554,
          11,
          597,
          286,
          519,
          264,
          472,
          665,
          551,
          466,
          309,
          885,
          3554,
          294,
          1873,
          3609,
          4392,
          586,
          51414
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 467,
        "id": 153,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 464,
        "temperature": 0,
        "text": " is that this room used to get so hot with the lights,",
        "tokens": [
          51414,
          307,
          300,
          341,
          1808,
          1143,
          281,
          483,
          370,
          2368,
          365,
          264,
          5811,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.2250569123488206,
        "compression_ratio": 1.6380597014925373,
        "end": 470,
        "id": 154,
        "no_speech_prob": 0.04208359867334366,
        "seek": 44300,
        "start": 467,
        "temperature": 0,
        "text": " but it's cold, so I'm waiting for the lights to warm me up.",
        "tokens": [
          51564,
          457,
          309,
          311,
          3554,
          11,
          370,
          286,
          478,
          3806,
          337,
          264,
          5811,
          281,
          4561,
          385,
          493,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 473,
        "id": 155,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 471,
        "temperature": 0,
        "text": " Okay, so this.coding.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          341,
          13,
          66,
          8616,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 474,
        "id": 156,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 473,
        "temperature": 0,
        "text": " Yes, of course this.",
        "tokens": [
          50514,
          1079,
          11,
          295,
          1164,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 480,
        "id": 157,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 474,
        "temperature": 0,
        "text": " And the other thing is I forgot my soundboard, but I have a backup soundboard.",
        "tokens": [
          50564,
          400,
          264,
          661,
          551,
          307,
          286,
          5298,
          452,
          1626,
          3787,
          11,
          457,
          286,
          362,
          257,
          14807,
          1626,
          3787,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 482,
        "id": 158,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 480,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          50864,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 487,
        "id": 159,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 484,
        "temperature": 0,
        "text": " Can you guys hear the this.song?",
        "tokens": [
          51064,
          1664,
          291,
          1074,
          1568,
          264,
          341,
          13,
          38762,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 489,
        "id": 160,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 487,
        "temperature": 0,
        "text": " Let me know if you can hear it.",
        "tokens": [
          51214,
          961,
          385,
          458,
          498,
          291,
          393,
          1568,
          309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24669918382024192,
        "compression_ratio": 1.4702380952380953,
        "end": 498,
        "id": 161,
        "no_speech_prob": 0.019122924655675888,
        "seek": 47000,
        "start": 496,
        "temperature": 0,
        "text": " And I can't see my monitor anymore.",
        "tokens": [
          51664,
          400,
          286,
          393,
          380,
          536,
          452,
          6002,
          3602,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 500,
        "id": 162,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 498,
        "temperature": 0,
        "text": " Oh, I turned my camera off.",
        "tokens": [
          50364,
          876,
          11,
          286,
          3574,
          452,
          2799,
          766,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 505,
        "id": 163,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 504,
        "temperature": 0,
        "text": " Too quiet.",
        "tokens": [
          50664,
          11395,
          5677,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 506,
        "id": 164,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 505,
        "temperature": 0,
        "text": " You can hear it, but it's quiet.",
        "tokens": [
          50714,
          509,
          393,
          1568,
          309,
          11,
          457,
          309,
          311,
          5677,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 508,
        "id": 165,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 506,
        "temperature": 0,
        "text": " All right, let me work on that.",
        "tokens": [
          50764,
          1057,
          558,
          11,
          718,
          385,
          589,
          322,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 510,
        "id": 166,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 508,
        "temperature": 0,
        "text": " That's an easy fix.",
        "tokens": [
          50864,
          663,
          311,
          364,
          1858,
          3191,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 517,
        "id": 167,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 513,
        "temperature": 0,
        "text": " I believe that's coming from this, this.",
        "tokens": [
          51114,
          286,
          1697,
          300,
          311,
          1348,
          490,
          341,
          11,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1415950664575549,
        "compression_ratio": 1.3286713286713288,
        "end": 524,
        "id": 168,
        "no_speech_prob": 0.00015843537403270602,
        "seek": 49800,
        "start": 522,
        "temperature": 0,
        "text": " Is that a lot louder now?",
        "tokens": [
          51564,
          1119,
          300,
          257,
          688,
          22717,
          586,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 529,
        "id": 169,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 525,
        "temperature": 0,
        "text": " All right, I'm not going to worry too much about the sound",
        "tokens": [
          50414,
          1057,
          558,
          11,
          286,
          478,
          406,
          516,
          281,
          3292,
          886,
          709,
          466,
          264,
          1626,
          50614
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 537,
        "id": 170,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 529,
        "temperature": 0,
        "text": " because that's not really the point of today here.",
        "tokens": [
          50614,
          570,
          300,
          311,
          406,
          534,
          264,
          935,
          295,
          965,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 538,
        "id": 171,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 537,
        "temperature": 0,
        "text": " Let me come back.",
        "tokens": [
          51014,
          961,
          385,
          808,
          646,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 539,
        "id": 172,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 538,
        "temperature": 0,
        "text": " Wrong screen.",
        "tokens": [
          51064,
          28150,
          2568,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 542,
        "id": 173,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 539,
        "temperature": 0,
        "text": " See, I'm really a mess without still a bit quiet.",
        "tokens": [
          51114,
          3008,
          11,
          286,
          478,
          534,
          257,
          2082,
          1553,
          920,
          257,
          857,
          5677,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 543,
        "id": 174,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 542,
        "temperature": 0,
        "text": " I could have made it louder still.",
        "tokens": [
          51264,
          286,
          727,
          362,
          1027,
          309,
          22717,
          920,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 546,
        "id": 175,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 543,
        "temperature": 0,
        "text": " If I need to play that song later, I will make it louder.",
        "tokens": [
          51314,
          759,
          286,
          643,
          281,
          862,
          300,
          2153,
          1780,
          11,
          286,
          486,
          652,
          309,
          22717,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19385478075812845,
        "compression_ratio": 1.5462555066079295,
        "end": 551,
        "id": 176,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 52400,
        "start": 546,
        "temperature": 0,
        "text": " Okay, so I'm all out of whack still without my multiple computers.",
        "tokens": [
          51464,
          1033,
          11,
          370,
          286,
          478,
          439,
          484,
          295,
          42877,
          920,
          1553,
          452,
          3866,
          10807,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 557,
        "id": 177,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 552,
        "temperature": 0,
        "text": " Okay, so let's get started.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          718,
          311,
          483,
          1409,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 561,
        "id": 178,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 560,
        "temperature": 0,
        "text": " I'm completely unprepared.",
        "tokens": [
          50814,
          286,
          478,
          2584,
          19237,
          45573,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 565,
        "id": 179,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 561,
        "temperature": 0,
        "text": " I mean, I'm not unprepared in terms of thinking about and having,",
        "tokens": [
          50864,
          286,
          914,
          11,
          286,
          478,
          406,
          19237,
          45573,
          294,
          2115,
          295,
          1953,
          466,
          293,
          1419,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 568,
        "id": 180,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 565,
        "temperature": 0,
        "text": " but I'm completely unprepared in terms of what's on my screen here.",
        "tokens": [
          51064,
          457,
          286,
          478,
          2584,
          19237,
          45573,
          294,
          2115,
          295,
          437,
          311,
          322,
          452,
          2568,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 571,
        "id": 181,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 568,
        "temperature": 0,
        "text": " So I've got to get set up a little bit, and I'll talk you through what's going on.",
        "tokens": [
          51214,
          407,
          286,
          600,
          658,
          281,
          483,
          992,
          493,
          257,
          707,
          857,
          11,
          293,
          286,
          603,
          751,
          291,
          807,
          437,
          311,
          516,
          322,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 573,
        "id": 182,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 571,
        "temperature": 0,
        "text": " So here we are.",
        "tokens": [
          51364,
          407,
          510,
          321,
          366,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23633341445136316,
        "compression_ratio": 1.6354166666666667,
        "end": 575,
        "id": 183,
        "no_speech_prob": 0.0004108439025003463,
        "seek": 55100,
        "start": 573,
        "temperature": 0,
        "text": " What I am doing this fall.",
        "tokens": [
          51464,
          708,
          286,
          669,
          884,
          341,
          2100,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 581,
        "id": 184,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 575,
        "temperature": 0,
        "text": " So first of all, you can still actually go to this website,",
        "tokens": [
          50364,
          407,
          700,
          295,
          439,
          11,
          291,
          393,
          920,
          767,
          352,
          281,
          341,
          3144,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 584,
        "id": 185,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 581,
        "temperature": 0,
        "text": " which it's codingrainbow.com.",
        "tokens": [
          50664,
          597,
          309,
          311,
          17720,
          7146,
          8202,
          13,
          1112,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 586,
        "id": 186,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 584,
        "temperature": 0,
        "text": " At some point, I will change that URL.",
        "tokens": [
          50814,
          1711,
          512,
          935,
          11,
          286,
          486,
          1319,
          300,
          12905,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 592,
        "id": 187,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 586,
        "temperature": 0,
        "text": " And if you're interested, I would encourage you to subscribe to the channel.",
        "tokens": [
          50914,
          400,
          498,
          291,
          434,
          3102,
          11,
          286,
          576,
          5373,
          291,
          281,
          3022,
          281,
          264,
          2269,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 595,
        "id": 188,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 592,
        "temperature": 0,
        "text": " You can become a patron on Patreon if you're so inclined.",
        "tokens": [
          51214,
          509,
          393,
          1813,
          257,
          21843,
          322,
          15692,
          498,
          291,
          434,
          370,
          28173,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 600,
        "id": 189,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 595,
        "temperature": 0,
        "text": " And also, I do send out emails once a week about scheduling of when I'm going to do these live streams",
        "tokens": [
          51364,
          400,
          611,
          11,
          286,
          360,
          2845,
          484,
          12524,
          1564,
          257,
          1243,
          466,
          29055,
          295,
          562,
          286,
          478,
          516,
          281,
          360,
          613,
          1621,
          15842,
          51614
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 602,
        "id": 190,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 600,
        "temperature": 0,
        "text": " if you want to get an email update.",
        "tokens": [
          51614,
          498,
          291,
          528,
          281,
          483,
          364,
          3796,
          5623,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19294473947572313,
        "compression_ratio": 1.5978260869565217,
        "end": 604,
        "id": 191,
        "no_speech_prob": 0.037887465208768845,
        "seek": 57500,
        "start": 602,
        "temperature": 0,
        "text": " So let me mention those things to you.",
        "tokens": [
          51714,
          407,
          718,
          385,
          2152,
          729,
          721,
          281,
          291,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 612,
        "id": 192,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 604,
        "temperature": 0,
        "text": " Now, what I've been using this fall for in the live stream is I'm teaching a class at itp.nyu.edu.",
        "tokens": [
          50364,
          823,
          11,
          437,
          286,
          600,
          668,
          1228,
          341,
          2100,
          337,
          294,
          264,
          1621,
          4309,
          307,
          286,
          478,
          4571,
          257,
          1508,
          412,
          309,
          79,
          13,
          1634,
          84,
          13,
          22938,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 614,
        "id": 193,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 612,
        "temperature": 0,
        "text": " The class is called Programming from A to Z.",
        "tokens": [
          50764,
          440,
          1508,
          307,
          1219,
          8338,
          2810,
          490,
          316,
          281,
          1176,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 619,
        "id": 194,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 614,
        "temperature": 0,
        "text": " You can see here a variety of topics that I have already explored.",
        "tokens": [
          50864,
          509,
          393,
          536,
          510,
          257,
          5673,
          295,
          8378,
          300,
          286,
          362,
          1217,
          24016,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 622,
        "id": 195,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 619,
        "temperature": 0,
        "text": " I made a set of videos on regular expressions.",
        "tokens": [
          51114,
          286,
          1027,
          257,
          992,
          295,
          2145,
          322,
          3890,
          15277,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 626,
        "id": 196,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 622,
        "temperature": 0,
        "text": " I looked at using different JavaScript libraries around text.",
        "tokens": [
          51264,
          286,
          2956,
          412,
          1228,
          819,
          15778,
          15148,
          926,
          2487,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 630,
        "id": 197,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 626,
        "temperature": 0,
        "text": " I haven't actually done videos about server-side programming with Node yet,",
        "tokens": [
          51464,
          286,
          2378,
          380,
          767,
          1096,
          2145,
          466,
          7154,
          12,
          1812,
          9410,
          365,
          38640,
          1939,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.15724830289857578,
        "compression_ratio": 1.5588235294117647,
        "end": 633,
        "id": 198,
        "no_speech_prob": 0.018830634653568268,
        "seek": 60400,
        "start": 630,
        "temperature": 0,
        "text": " but there's a page of notes.",
        "tokens": [
          51664,
          457,
          456,
          311,
          257,
          3028,
          295,
          5570,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17568450969654126,
        "compression_ratio": 1.5702127659574467,
        "end": 635,
        "id": 199,
        "no_speech_prob": 0.005910858977586031,
        "seek": 63300,
        "start": 633,
        "temperature": 0,
        "text": " I have a bunch of videos about Twitter bots.",
        "tokens": [
          50364,
          286,
          362,
          257,
          3840,
          295,
          2145,
          466,
          5794,
          35410,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17568450969654126,
        "compression_ratio": 1.5702127659574467,
        "end": 639,
        "id": 200,
        "no_speech_prob": 0.005910858977586031,
        "seek": 63300,
        "start": 635,
        "temperature": 0,
        "text": " I don't know why I can't get this to scroll correctly.",
        "tokens": [
          50464,
          286,
          500,
          380,
          458,
          983,
          286,
          393,
          380,
          483,
          341,
          281,
          11369,
          8944,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17568450969654126,
        "compression_ratio": 1.5702127659574467,
        "end": 644,
        "id": 201,
        "no_speech_prob": 0.005910858977586031,
        "seek": 63300,
        "start": 639,
        "temperature": 0,
        "text": " And more recently, I did a session on text analysis,",
        "tokens": [
          50664,
          400,
          544,
          3938,
          11,
          286,
          630,
          257,
          5481,
          322,
          2487,
          5215,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17568450969654126,
        "compression_ratio": 1.5702127659574467,
        "end": 649,
        "id": 202,
        "no_speech_prob": 0.005910858977586031,
        "seek": 63300,
        "start": 644,
        "temperature": 0,
        "text": " looking at word counting and what types of applications you can create",
        "tokens": [
          50914,
          1237,
          412,
          1349,
          13251,
          293,
          437,
          3467,
          295,
          5821,
          291,
          393,
          1884,
          51164
        ]
      },
      {
        "avg_logprob": -0.17568450969654126,
        "compression_ratio": 1.5702127659574467,
        "end": 652,
        "id": 203,
        "no_speech_prob": 0.005910858977586031,
        "seek": 63300,
        "start": 649,
        "temperature": 0,
        "text": " from just counting the frequency of words in a document.",
        "tokens": [
          51164,
          490,
          445,
          13251,
          264,
          7893,
          295,
          2283,
          294,
          257,
          4166,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17568450969654126,
        "compression_ratio": 1.5702127659574467,
        "end": 657,
        "id": 204,
        "no_speech_prob": 0.005910858977586031,
        "seek": 63300,
        "start": 652,
        "temperature": 0,
        "text": " And then last week, I looked at a particular algorithm, highly related to word counting,",
        "tokens": [
          51314,
          400,
          550,
          1036,
          1243,
          11,
          286,
          2956,
          412,
          257,
          1729,
          9284,
          11,
          5405,
          4077,
          281,
          1349,
          13251,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.2938659191131592,
        "compression_ratio": 1.8333333333333333,
        "end": 659,
        "id": 205,
        "no_speech_prob": 0.087557353079319,
        "seek": 65700,
        "start": 657,
        "temperature": 0,
        "text": " which involved...",
        "tokens": [
          50364,
          597,
          3288,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2938659191131592,
        "compression_ratio": 1.8333333333333333,
        "end": 664,
        "id": 206,
        "no_speech_prob": 0.087557353079319,
        "seek": 65700,
        "start": 659,
        "temperature": 0,
        "text": " which involved...",
        "tokens": [
          50464,
          597,
          3288,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.2938659191131592,
        "compression_ratio": 1.8333333333333333,
        "end": 668,
        "id": 207,
        "no_speech_prob": 0.087557353079319,
        "seek": 65700,
        "start": 664,
        "temperature": 0,
        "text": " looking at too many screens at once...",
        "tokens": [
          50714,
          1237,
          412,
          886,
          867,
          11171,
          412,
          1564,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.2938659191131592,
        "compression_ratio": 1.8333333333333333,
        "end": 671,
        "id": 208,
        "no_speech_prob": 0.087557353079319,
        "seek": 65700,
        "start": 668,
        "temperature": 0,
        "text": " which involved looking at the sequence of words or characters",
        "tokens": [
          50914,
          597,
          3288,
          1237,
          412,
          264,
          8310,
          295,
          2283,
          420,
          4342,
          51064
        ]
      },
      {
        "avg_logprob": -0.2938659191131592,
        "compression_ratio": 1.8333333333333333,
        "end": 679,
        "id": 209,
        "no_speech_prob": 0.087557353079319,
        "seek": 65700,
        "start": 671,
        "temperature": 0,
        "text": " and the probabilities of those sequences occurring in the context of a Markov chain,",
        "tokens": [
          51064,
          293,
          264,
          33783,
          295,
          729,
          22978,
          18386,
          294,
          264,
          4319,
          295,
          257,
          3934,
          5179,
          5021,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2938659191131592,
        "compression_ratio": 1.8333333333333333,
        "end": 683,
        "id": 210,
        "no_speech_prob": 0.087557353079319,
        "seek": 65700,
        "start": 679,
        "temperature": 0,
        "text": " a Markov chain being a sequence of states,",
        "tokens": [
          51464,
          257,
          3934,
          5179,
          5021,
          885,
          257,
          8310,
          295,
          4368,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 687,
        "id": 211,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 684,
        "temperature": 0,
        "text": " and the states in this case being either characters or words,",
        "tokens": [
          50414,
          293,
          264,
          4368,
          294,
          341,
          1389,
          885,
          2139,
          4342,
          420,
          2283,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 692,
        "id": 212,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 687,
        "temperature": 0,
        "text": " and then evaluating a text based on all of the ways that the characters appear next to each other",
        "tokens": [
          50564,
          293,
          550,
          27479,
          257,
          2487,
          2361,
          322,
          439,
          295,
          264,
          2098,
          300,
          264,
          4342,
          4204,
          958,
          281,
          1184,
          661,
          50814
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 693,
        "id": 213,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 692,
        "temperature": 0,
        "text": " and generating new text from that.",
        "tokens": [
          50814,
          293,
          17746,
          777,
          2487,
          490,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 696,
        "id": 214,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 693,
        "temperature": 0,
        "text": " So if you're interested in that, those are the videos from last week.",
        "tokens": [
          50864,
          407,
          498,
          291,
          434,
          3102,
          294,
          300,
          11,
          729,
          366,
          264,
          2145,
          490,
          1036,
          1243,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 700,
        "id": 215,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 696,
        "temperature": 0,
        "text": " And there's actually even one or two more that I didn't release.",
        "tokens": [
          51014,
          400,
          456,
          311,
          767,
          754,
          472,
          420,
          732,
          544,
          300,
          286,
          994,
          380,
          4374,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 702,
        "id": 216,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 700,
        "temperature": 0,
        "text": " So one thing I should say, by the way, for those of you...",
        "tokens": [
          51214,
          407,
          472,
          551,
          286,
          820,
          584,
          11,
          538,
          264,
          636,
          11,
          337,
          729,
          295,
          291,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 704,
        "id": 217,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 702,
        "temperature": 0,
        "text": " here's a little secret.",
        "tokens": [
          51314,
          510,
          311,
          257,
          707,
          4054,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 709,
        "id": 218,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 706,
        "temperature": 0,
        "text": " For... you know, I release videos in multiple ways.",
        "tokens": [
          51514,
          1171,
          485,
          291,
          458,
          11,
          286,
          4374,
          2145,
          294,
          3866,
          2098,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22111773490905762,
        "compression_ratio": 1.7432432432432432,
        "end": 711,
        "id": 219,
        "no_speech_prob": 0.12937131524085999,
        "seek": 68300,
        "start": 709,
        "temperature": 0,
        "text": " And let me just go to my channel here for a second.",
        "tokens": [
          51664,
          400,
          718,
          385,
          445,
          352,
          281,
          452,
          2269,
          510,
          337,
          257,
          1150,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 717,
        "id": 220,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 711,
        "temperature": 0,
        "text": " So for example, if you go here, the most recent thing that's happening right now is Coding Rainbow Live,",
        "tokens": [
          50364,
          407,
          337,
          1365,
          11,
          498,
          291,
          352,
          510,
          11,
          264,
          881,
          5162,
          551,
          300,
          311,
          2737,
          558,
          586,
          307,
          383,
          8616,
          29477,
          10385,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 718,
        "id": 221,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 717,
        "temperature": 0,
        "text": " which you can see there.",
        "tokens": [
          50664,
          597,
          291,
          393,
          536,
          456,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 725,
        "id": 222,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 718,
        "temperature": 0,
        "text": " But you can see here that I also... the most recent video that I published is Coding Challenge 42.1 Markov Chains.",
        "tokens": [
          50714,
          583,
          291,
          393,
          536,
          510,
          300,
          286,
          611,
          485,
          264,
          881,
          5162,
          960,
          300,
          286,
          6572,
          307,
          383,
          8616,
          17517,
          14034,
          13,
          16,
          3934,
          5179,
          761,
          2315,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 728,
        "id": 223,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 725,
        "temperature": 0,
        "text": " So once a day, and I just forgot to do it this morning,",
        "tokens": [
          51064,
          407,
          1564,
          257,
          786,
          11,
          293,
          286,
          445,
          5298,
          281,
          360,
          309,
          341,
          2446,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 730,
        "id": 224,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 728,
        "temperature": 0,
        "text": " I usually have a backlog of videos that I've made.",
        "tokens": [
          51214,
          286,
          2673,
          362,
          257,
          47364,
          295,
          2145,
          300,
          286,
          600,
          1027,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 734,
        "id": 225,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 730,
        "temperature": 0,
        "text": " So once a day, I try to release a new one, meaning make it public.",
        "tokens": [
          51314,
          407,
          1564,
          257,
          786,
          11,
          286,
          853,
          281,
          4374,
          257,
          777,
          472,
          11,
          3620,
          652,
          309,
          1908,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16838173766236206,
        "compression_ratio": 1.8159722222222223,
        "end": 740,
        "id": 226,
        "no_speech_prob": 0.005384540650993586,
        "seek": 71100,
        "start": 734,
        "temperature": 0,
        "text": " But I usually have a lot of videos that are on my channel that I haven't released yet that are unlisted.",
        "tokens": [
          51514,
          583,
          286,
          2673,
          362,
          257,
          688,
          295,
          2145,
          300,
          366,
          322,
          452,
          2269,
          300,
          286,
          2378,
          380,
          4736,
          1939,
          300,
          366,
          517,
          34890,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 742,
        "id": 227,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 740,
        "temperature": 0,
        "text": " And you can always find those by going to the playlists.",
        "tokens": [
          50364,
          400,
          291,
          393,
          1009,
          915,
          729,
          538,
          516,
          281,
          264,
          862,
          36693,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 750,
        "id": 228,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 742,
        "temperature": 0,
        "text": " So if I went to, for example, session 6 playlist, you'll see that even though this is the most recent video that has been released,",
        "tokens": [
          50464,
          407,
          498,
          286,
          1437,
          281,
          11,
          337,
          1365,
          11,
          5481,
          1386,
          16788,
          11,
          291,
          603,
          536,
          300,
          754,
          1673,
          341,
          307,
          264,
          881,
          5162,
          960,
          300,
          575,
          668,
          4736,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 756,
        "id": 229,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 750,
        "temperature": 0,
        "text": " there's also the second part to that there, and a video about kind of a homework assignment that's there as well.",
        "tokens": [
          50864,
          456,
          311,
          611,
          264,
          1150,
          644,
          281,
          300,
          456,
          11,
          293,
          257,
          960,
          466,
          733,
          295,
          257,
          14578,
          15187,
          300,
          311,
          456,
          382,
          731,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 757,
        "id": 230,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 756,
        "temperature": 0,
        "text": " So I'm just mentioning that.",
        "tokens": [
          51164,
          407,
          286,
          478,
          445,
          18315,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 762,
        "id": 231,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 757,
        "temperature": 0,
        "text": " If you're ever, like, poking around the playlist, you'll often find additional videos that haven't been released yet.",
        "tokens": [
          51214,
          759,
          291,
          434,
          1562,
          11,
          411,
          11,
          42684,
          926,
          264,
          16788,
          11,
          291,
          603,
          2049,
          915,
          4497,
          2145,
          300,
          2378,
          380,
          668,
          4736,
          1939,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 764,
        "id": 232,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 762,
        "temperature": 0,
        "text": " You can always tweet me at Shiffman about that.",
        "tokens": [
          51464,
          509,
          393,
          1009,
          15258,
          385,
          412,
          1160,
          3661,
          1601,
          466,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2043614247265984,
        "compression_ratio": 1.7777777777777777,
        "end": 766,
        "id": 233,
        "no_speech_prob": 0.008984621614217758,
        "seek": 74000,
        "start": 764,
        "temperature": 0,
        "text": " So what's the topic for today?",
        "tokens": [
          51564,
          407,
          437,
          311,
          264,
          4829,
          337,
          965,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 771,
        "id": 234,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 766,
        "temperature": 0,
        "text": " Because the last topic on this list is Ngrams and Markov Chains.",
        "tokens": [
          50364,
          1436,
          264,
          1036,
          4829,
          322,
          341,
          1329,
          307,
          426,
          1342,
          82,
          293,
          3934,
          5179,
          761,
          2315,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 775,
        "id": 235,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 771,
        "temperature": 0,
        "text": " So if there's no topic after it, then what can I possibly talk about?",
        "tokens": [
          50614,
          407,
          498,
          456,
          311,
          572,
          4829,
          934,
          309,
          11,
          550,
          437,
          393,
          286,
          6264,
          751,
          466,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 778,
        "id": 236,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 775,
        "temperature": 0,
        "text": " Well, I have something to talk about, which is grammars.",
        "tokens": [
          50814,
          1042,
          11,
          286,
          362,
          746,
          281,
          751,
          466,
          11,
          597,
          307,
          17570,
          685,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 787,
        "id": 237,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 778,
        "temperature": 0,
        "text": " Today's topic is looking at what a grammar is, how you can define a grammar in code, encode a grammar,",
        "tokens": [
          50964,
          2692,
          311,
          4829,
          307,
          1237,
          412,
          437,
          257,
          22317,
          307,
          11,
          577,
          291,
          393,
          6964,
          257,
          22317,
          294,
          3089,
          11,
          2058,
          1429,
          257,
          22317,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 790,
        "id": 238,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 787,
        "temperature": 0,
        "text": " and how you can generate text based on that grammar.",
        "tokens": [
          51414,
          293,
          577,
          291,
          393,
          8460,
          2487,
          2361,
          322,
          300,
          22317,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 792,
        "id": 239,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 790,
        "temperature": 0,
        "text": " And there's a variety of things.",
        "tokens": [
          51564,
          400,
          456,
          311,
          257,
          5673,
          295,
          721,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16171162588554516,
        "compression_ratio": 1.6612244897959183,
        "end": 793,
        "id": 240,
        "no_speech_prob": 0.2538363039493561,
        "seek": 76600,
        "start": 792,
        "temperature": 0,
        "text": " My glasses are very dirty.",
        "tokens": [
          51664,
          1222,
          10812,
          366,
          588,
          9360,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17267940521240235,
        "compression_ratio": 1.578512396694215,
        "end": 796,
        "id": 241,
        "no_speech_prob": 0.2094249278306961,
        "seek": 79300,
        "start": 793,
        "temperature": 0,
        "text": " There's a variety of applications of this and things that we can look at.",
        "tokens": [
          50364,
          821,
          311,
          257,
          5673,
          295,
          5821,
          295,
          341,
          293,
          721,
          300,
          321,
          393,
          574,
          412,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17267940521240235,
        "compression_ratio": 1.578512396694215,
        "end": 799,
        "id": 242,
        "no_speech_prob": 0.2094249278306961,
        "seek": 79300,
        "start": 796,
        "temperature": 0,
        "text": " And in particular, I want to look at something called Tracery.",
        "tokens": [
          50514,
          400,
          294,
          1729,
          11,
          286,
          528,
          281,
          574,
          412,
          746,
          1219,
          1765,
          326,
          2109,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17267940521240235,
        "compression_ratio": 1.578512396694215,
        "end": 806,
        "id": 243,
        "no_speech_prob": 0.2094249278306961,
        "seek": 79300,
        "start": 799,
        "temperature": 0,
        "text": " Tracery is an engine for generating text from grammar, and it's by Kate Compton, GalaxyKate on Twitter.",
        "tokens": [
          50664,
          1765,
          326,
          2109,
          307,
          364,
          2848,
          337,
          17746,
          2487,
          490,
          22317,
          11,
          293,
          309,
          311,
          538,
          16251,
          2432,
          21987,
          11,
          13520,
          42,
          473,
          322,
          5794,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17267940521240235,
        "compression_ratio": 1.578512396694215,
        "end": 811,
        "id": 244,
        "no_speech_prob": 0.2094249278306961,
        "seek": 79300,
        "start": 806,
        "temperature": 0,
        "text": " And it's a really easy, powerful entry point into text generation in JavaScript using grammars.",
        "tokens": [
          51014,
          400,
          309,
          311,
          257,
          534,
          1858,
          11,
          4005,
          8729,
          935,
          666,
          2487,
          5125,
          294,
          15778,
          1228,
          17570,
          685,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17267940521240235,
        "compression_ratio": 1.578512396694215,
        "end": 814,
        "id": 245,
        "no_speech_prob": 0.2094249278306961,
        "seek": 79300,
        "start": 811,
        "temperature": 0,
        "text": " So that's kind of going to be the main topic.",
        "tokens": [
          51264,
          407,
          300,
          311,
          733,
          295,
          516,
          281,
          312,
          264,
          2135,
          4829,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 823,
        "id": 246,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 814,
        "temperature": 0,
        "text": " I am looking at the chat for a moment to see if there is anything.",
        "tokens": [
          50364,
          286,
          669,
          1237,
          412,
          264,
          5081,
          337,
          257,
          1623,
          281,
          536,
          498,
          456,
          307,
          1340,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 825,
        "id": 247,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 823,
        "temperature": 0,
        "text": " Dun, dun, dun.",
        "tokens": [
          50814,
          11959,
          11,
          10234,
          11,
          10234,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 826,
        "id": 248,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 825,
        "temperature": 0,
        "text": " Grammar.",
        "tokens": [
          50914,
          22130,
          6209,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 831,
        "id": 249,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 826,
        "temperature": 0,
        "text": " It doesn't look like there's any questions I need to answer at the moment.",
        "tokens": [
          50964,
          467,
          1177,
          380,
          574,
          411,
          456,
          311,
          604,
          1651,
          286,
          643,
          281,
          1867,
          412,
          264,
          1623,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 833,
        "id": 250,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 831,
        "temperature": 0,
        "text": " So every once in a while, I try to take a peek at the chat.",
        "tokens": [
          51214,
          407,
          633,
          1564,
          294,
          257,
          1339,
          11,
          286,
          853,
          281,
          747,
          257,
          19604,
          412,
          264,
          5081,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 839,
        "id": 251,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 833,
        "temperature": 0,
        "text": " And once I do, I've got – this isn't going to be – I'll probably be here for at least an hour now.",
        "tokens": [
          51314,
          400,
          1564,
          286,
          360,
          11,
          286,
          600,
          658,
          220,
          5815,
          341,
          1943,
          380,
          516,
          281,
          312,
          1662,
          286,
          603,
          1391,
          312,
          510,
          337,
          412,
          1935,
          364,
          1773,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20837451616923014,
        "compression_ratio": 1.6062992125984252,
        "end": 843,
        "id": 252,
        "no_speech_prob": 0.6856528520584106,
        "seek": 81400,
        "start": 839,
        "temperature": 0,
        "text": " And I want to walk through a few different examples and make a couple examples.",
        "tokens": [
          51614,
          400,
          286,
          528,
          281,
          1792,
          807,
          257,
          1326,
          819,
          5110,
          293,
          652,
          257,
          1916,
          5110,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 850,
        "id": 253,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 843,
        "temperature": 0,
        "text": " And then I've lost my train of thought.",
        "tokens": [
          50364,
          400,
          550,
          286,
          600,
          2731,
          452,
          3847,
          295,
          1194,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 851,
        "id": 254,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 850,
        "temperature": 0,
        "text": " And then I will be gone.",
        "tokens": [
          50714,
          400,
          550,
          286,
          486,
          312,
          2780,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 855,
        "id": 255,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 851,
        "temperature": 0,
        "text": " But once I finish these few examples, I'll stick around for maybe – I'll try to leave like 15 minutes",
        "tokens": [
          50764,
          583,
          1564,
          286,
          2413,
          613,
          1326,
          5110,
          11,
          286,
          603,
          2897,
          926,
          337,
          1310,
          1662,
          286,
          603,
          853,
          281,
          1856,
          411,
          2119,
          2077,
          50964
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 858,
        "id": 256,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 855,
        "temperature": 0,
        "text": " or even a half an hour at the end for just questions.",
        "tokens": [
          50964,
          420,
          754,
          257,
          1922,
          364,
          1773,
          412,
          264,
          917,
          337,
          445,
          1651,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 863,
        "id": 257,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 858,
        "temperature": 0,
        "text": " And I can answer questions or make quick and dirty little examples of things that you guys are wondering about.",
        "tokens": [
          51114,
          400,
          286,
          393,
          1867,
          1651,
          420,
          652,
          1702,
          293,
          9360,
          707,
          5110,
          295,
          721,
          300,
          291,
          1074,
          366,
          6359,
          466,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 866,
        "id": 258,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 863,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21338924179729232,
        "compression_ratio": 1.6035714285714286,
        "end": 872,
        "id": 259,
        "no_speech_prob": 0.003222414292395115,
        "seek": 84300,
        "start": 866,
        "temperature": 0,
        "text": " I know everyone's like, I woke up this morning and I heard there was going to be a live stream about coding.",
        "tokens": [
          51514,
          286,
          458,
          1518,
          311,
          411,
          11,
          286,
          12852,
          493,
          341,
          2446,
          293,
          286,
          2198,
          456,
          390,
          516,
          281,
          312,
          257,
          1621,
          4309,
          466,
          17720,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 875,
        "id": 260,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 872,
        "temperature": 0,
        "text": " And I found out it was about grammar.",
        "tokens": [
          50364,
          400,
          286,
          1352,
          484,
          309,
          390,
          466,
          22317,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 877,
        "id": 261,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 875,
        "temperature": 0,
        "text": " Well, that's what it is.",
        "tokens": [
          50514,
          1042,
          11,
          300,
          311,
          437,
          309,
          307,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 878,
        "id": 262,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 877,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 884,
        "id": 263,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 878,
        "temperature": 0,
        "text": " So let me – let's see if I can get the – some music going for you guys.",
        "tokens": [
          50664,
          407,
          718,
          385,
          1662,
          718,
          311,
          536,
          498,
          286,
          393,
          483,
          264,
          1662,
          512,
          1318,
          516,
          337,
          291,
          1074,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 887,
        "id": 264,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 884,
        "temperature": 0,
        "text": " I have a little – I don't know what this music is.",
        "tokens": [
          50964,
          286,
          362,
          257,
          707,
          1662,
          286,
          500,
          380,
          458,
          437,
          341,
          1318,
          307,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 890,
        "id": 265,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 887,
        "temperature": 0,
        "text": " A little music in the background.",
        "tokens": [
          51114,
          316,
          707,
          1318,
          294,
          264,
          3678,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 892,
        "id": 266,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 890,
        "temperature": 0,
        "text": " And let me get set up here.",
        "tokens": [
          51264,
          400,
          718,
          385,
          483,
          992,
          493,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1869609230443051,
        "compression_ratio": 1.4591836734693877,
        "end": 899,
        "id": 267,
        "no_speech_prob": 0.01590563729405403,
        "seek": 87200,
        "start": 892,
        "temperature": 0,
        "text": " So I'm going to my Finder.",
        "tokens": [
          51364,
          407,
          286,
          478,
          516,
          281,
          452,
          479,
          5669,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 901,
        "id": 268,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 899,
        "temperature": 0,
        "text": " Wait, week six.",
        "tokens": [
          50364,
          3802,
          11,
          1243,
          2309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 904,
        "id": 269,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 901,
        "temperature": 0,
        "text": " This is session seven technically.",
        "tokens": [
          50464,
          639,
          307,
          5481,
          3407,
          12120,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 908,
        "id": 270,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 904,
        "temperature": 0,
        "text": " You should really call it session, not week.",
        "tokens": [
          50614,
          509,
          820,
          534,
          818,
          309,
          5481,
          11,
          406,
          1243,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 911,
        "id": 271,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 908,
        "temperature": 0,
        "text": " Let's rename all these.",
        "tokens": [
          50814,
          961,
          311,
          36741,
          439,
          613,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 914,
        "id": 272,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 911,
        "temperature": 0,
        "text": " How about riveting things to watch on YouTube?",
        "tokens": [
          50964,
          1012,
          466,
          28745,
          9880,
          721,
          281,
          1159,
          322,
          3088,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 919,
        "id": 273,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 914,
        "temperature": 0,
        "text": " Watching somebody rename six folders.",
        "tokens": [
          51114,
          28482,
          2618,
          36741,
          2309,
          31082,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 924,
        "id": 274,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 919,
        "temperature": 0,
        "text": " And I seem to have lost my ability to count.",
        "tokens": [
          51364,
          400,
          286,
          1643,
          281,
          362,
          2731,
          452,
          3485,
          281,
          1207,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 926,
        "id": 275,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 924,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          51614,
          876,
          11,
          3237,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23245947701590403,
        "compression_ratio": 1.4314720812182742,
        "end": 928,
        "id": 276,
        "no_speech_prob": 0.08509586751461029,
        "seek": 89900,
        "start": 926,
        "temperature": 0,
        "text": " Oh, what just happened?",
        "tokens": [
          51714,
          876,
          11,
          437,
          445,
          2011,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 929,
        "id": 277,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 928,
        "temperature": 0,
        "text": " Everything went awry.",
        "tokens": [
          50364,
          5471,
          1437,
          1714,
          627,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 930,
        "id": 278,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 929,
        "temperature": 0,
        "text": " One, two, three.",
        "tokens": [
          50414,
          1485,
          11,
          732,
          11,
          1045,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 932,
        "id": 279,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 930,
        "temperature": 0,
        "text": " I'll have to fix this later.",
        "tokens": [
          50464,
          286,
          603,
          362,
          281,
          3191,
          341,
          1780,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 937,
        "id": 280,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 932,
        "temperature": 0,
        "text": " All I care is that this is section seven.",
        "tokens": [
          50564,
          1057,
          286,
          1127,
          307,
          300,
          341,
          307,
          3541,
          3407,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 939,
        "id": 281,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 937,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 941,
        "id": 282,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 939,
        "temperature": 0,
        "text": " I'm so tired today.",
        "tokens": [
          50914,
          286,
          478,
          370,
          5868,
          965,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 942,
        "id": 283,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 941,
        "temperature": 0,
        "text": " Hope I can do this.",
        "tokens": [
          51014,
          6483,
          286,
          393,
          360,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 945,
        "id": 284,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 942,
        "temperature": 0,
        "text": " Let's go in here.",
        "tokens": [
          51064,
          961,
          311,
          352,
          294,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18105788614558077,
        "compression_ratio": 1.4058823529411764,
        "end": 952,
        "id": 285,
        "no_speech_prob": 0.004609527066349983,
        "seek": 92800,
        "start": 945,
        "temperature": 0,
        "text": " Let's do our first example, I think, going to be tracery grammar.",
        "tokens": [
          51214,
          961,
          311,
          360,
          527,
          700,
          1365,
          11,
          286,
          519,
          11,
          516,
          281,
          312,
          504,
          326,
          2109,
          22317,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 960,
        "id": 286,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 953,
        "temperature": 0,
        "text": " And what I need to do is open up terminal.",
        "tokens": [
          50414,
          400,
          437,
          286,
          643,
          281,
          360,
          307,
          1269,
          493,
          14709,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 962,
        "id": 287,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 960,
        "temperature": 0,
        "text": " Oh, I better see if I have any good markers here.",
        "tokens": [
          50764,
          876,
          11,
          286,
          1101,
          536,
          498,
          286,
          362,
          604,
          665,
          19175,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 965,
        "id": 288,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 962,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 966,
        "id": 289,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 965,
        "temperature": 0,
        "text": " Desktop.",
        "tokens": [
          51014,
          49044,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 968,
        "id": 290,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 966,
        "temperature": 0,
        "text": " I'm going to the desktop.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          264,
          14502,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 970,
        "id": 291,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 968,
        "temperature": 0,
        "text": " And A to Z.",
        "tokens": [
          51164,
          400,
          316,
          281,
          1176,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 976,
        "id": 292,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 970,
        "temperature": 0,
        "text": " Maybe our coding – oh, I've got to change the name of that folder.",
        "tokens": [
          51264,
          2704,
          527,
          17720,
          1662,
          1954,
          11,
          286,
          600,
          658,
          281,
          1319,
          264,
          1315,
          295,
          300,
          10820,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2240124884105864,
        "compression_ratio": 1.3898305084745763,
        "end": 981,
        "id": 293,
        "no_speech_prob": 0.03789149224758148,
        "seek": 95200,
        "start": 976,
        "temperature": 0,
        "text": " I'm going to run a server here.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          1190,
          257,
          7154,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 985,
        "id": 294,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 981,
        "temperature": 0,
        "text": " And I'm going to open this up in Atom.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          1269,
          341,
          493,
          294,
          1711,
          298,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 987,
        "id": 295,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 985,
        "temperature": 0,
        "text": " Minimize this.",
        "tokens": [
          50564,
          2829,
          43890,
          341,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 992,
        "id": 296,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 987,
        "temperature": 0,
        "text": " And let's look at this tracery grammar example that I will make at some point.",
        "tokens": [
          50664,
          400,
          718,
          311,
          574,
          412,
          341,
          504,
          326,
          2109,
          22317,
          1365,
          300,
          286,
          486,
          652,
          412,
          512,
          935,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 995,
        "id": 297,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 992,
        "temperature": 0,
        "text": " Function setup.",
        "tokens": [
          50914,
          11166,
          882,
          8657,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 998,
        "id": 298,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 995,
        "temperature": 0,
        "text": " And hello, function draw.",
        "tokens": [
          51064,
          400,
          7751,
          11,
          2445,
          2642,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 999,
        "id": 299,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 998,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1719175890872353,
        "compression_ratio": 1.3841463414634145,
        "end": 1005,
        "id": 300,
        "no_speech_prob": 0.08509449660778046,
        "seek": 98100,
        "start": 999,
        "temperature": 0,
        "text": " So now if I go here and I go to session seven,",
        "tokens": [
          51264,
          407,
          586,
          498,
          286,
          352,
          510,
          293,
          286,
          352,
          281,
          5481,
          3407,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1011,
        "id": 301,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1005,
        "temperature": 0,
        "text": " I should have a nice little browser window and JavaScript console.",
        "tokens": [
          50364,
          286,
          820,
          362,
          257,
          1481,
          707,
          11185,
          4910,
          293,
          15778,
          11076,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1014,
        "id": 302,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1011,
        "temperature": 0,
        "text": " Let's just put something here to make sure everything is working.",
        "tokens": [
          50664,
          961,
          311,
          445,
          829,
          746,
          510,
          281,
          652,
          988,
          1203,
          307,
          1364,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1017,
        "id": 303,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1014,
        "temperature": 0,
        "text": " No canvas.",
        "tokens": [
          50814,
          883,
          16267,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1022,
        "id": 304,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1017,
        "temperature": 0,
        "text": " And what was I going to say here?",
        "tokens": [
          50964,
          400,
          437,
          390,
          286,
          516,
          281,
          584,
          510,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1030,
        "id": 305,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1022,
        "temperature": 0,
        "text": " No canvas and console log unicorn.",
        "tokens": [
          51214,
          883,
          16267,
          293,
          11076,
          3565,
          28122,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1031,
        "id": 306,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1030,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1032,
        "id": 307,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1031,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51664,
          821,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1033,
        "id": 308,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1032,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51714,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20123185739888774,
        "compression_ratio": 1.4857142857142858,
        "end": 1034,
        "id": 309,
        "no_speech_prob": 0.2877497971057892,
        "seek": 100500,
        "start": 1033,
        "temperature": 0,
        "text": " So things are working.",
        "tokens": [
          51764,
          407,
          721,
          366,
          1364,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17580292814521378,
        "compression_ratio": 1.6650717703349283,
        "end": 1038,
        "id": 310,
        "no_speech_prob": 0.33108818531036377,
        "seek": 103400,
        "start": 1034,
        "temperature": 0,
        "text": " I have a code example ready to go.",
        "tokens": [
          50364,
          286,
          362,
          257,
          3089,
          1365,
          1919,
          281,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17580292814521378,
        "compression_ratio": 1.6650717703349283,
        "end": 1043,
        "id": 311,
        "no_speech_prob": 0.33108818531036377,
        "seek": 103400,
        "start": 1038,
        "temperature": 0,
        "text": " And I have got a code example ready to go.",
        "tokens": [
          50564,
          400,
          286,
          362,
          658,
          257,
          3089,
          1365,
          1919,
          281,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17580292814521378,
        "compression_ratio": 1.6650717703349283,
        "end": 1050,
        "id": 312,
        "no_speech_prob": 0.33108818531036377,
        "seek": 103400,
        "start": 1043,
        "temperature": 0,
        "text": " Now, some things I want to get up and running in the browser with is I want to make sure I have a window open to tracery.",
        "tokens": [
          50814,
          823,
          11,
          512,
          721,
          286,
          528,
          281,
          483,
          493,
          293,
          2614,
          294,
          264,
          11185,
          365,
          307,
          286,
          528,
          281,
          652,
          988,
          286,
          362,
          257,
          4910,
          1269,
          281,
          504,
          326,
          2109,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17580292814521378,
        "compression_ratio": 1.6650717703349283,
        "end": 1060,
        "id": 313,
        "no_speech_prob": 0.33108818531036377,
        "seek": 103400,
        "start": 1050,
        "temperature": 0,
        "text": " So this is the GitHub repository for tracery by Kate Compton, Galaxy Kate on GitHub and on Twitter.",
        "tokens": [
          51164,
          407,
          341,
          307,
          264,
          23331,
          25841,
          337,
          504,
          326,
          2109,
          538,
          16251,
          2432,
          21987,
          11,
          13520,
          16251,
          322,
          23331,
          293,
          322,
          5794,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17580292814521378,
        "compression_ratio": 1.6650717703349283,
        "end": 1063,
        "id": 314,
        "no_speech_prob": 0.33108818531036377,
        "seek": 103400,
        "start": 1060,
        "temperature": 0,
        "text": " Story grammar generation library for JavaScript.",
        "tokens": [
          51664,
          14484,
          22317,
          5125,
          6405,
          337,
          15778,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18938497936024384,
        "compression_ratio": 1.5165562913907285,
        "end": 1077,
        "id": 315,
        "no_speech_prob": 0.02517841011285782,
        "seek": 106300,
        "start": 1063,
        "temperature": 0,
        "text": " Another thing I want to do is I want to make sure I want to have my let's see here.",
        "tokens": [
          50364,
          3996,
          551,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          652,
          988,
          286,
          528,
          281,
          362,
          452,
          718,
          311,
          536,
          510,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18938497936024384,
        "compression_ratio": 1.5165562913907285,
        "end": 1082,
        "id": 316,
        "no_speech_prob": 0.02517841011285782,
        "seek": 106300,
        "start": 1077,
        "temperature": 0,
        "text": " I want to go I have some pre-made examples that I might want to refer to.",
        "tokens": [
          51064,
          286,
          528,
          281,
          352,
          286,
          362,
          512,
          659,
          12,
          10341,
          5110,
          300,
          286,
          1062,
          528,
          281,
          2864,
          281,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18938497936024384,
        "compression_ratio": 1.5165562913907285,
        "end": 1088,
        "id": 317,
        "no_speech_prob": 0.02517841011285782,
        "seek": 106300,
        "start": 1082,
        "temperature": 0,
        "text": " So I better clone my GitHub repo for the course.",
        "tokens": [
          51314,
          407,
          286,
          1101,
          26506,
          452,
          23331,
          49040,
          337,
          264,
          1164,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18938497936024384,
        "compression_ratio": 1.5165562913907285,
        "end": 1090,
        "id": 318,
        "no_speech_prob": 0.02517841011285782,
        "seek": 106300,
        "start": 1088,
        "temperature": 0,
        "text": " Can I find that clone?",
        "tokens": [
          51614,
          1664,
          286,
          915,
          300,
          26506,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.2434396553039551,
        "compression_ratio": 1.3153153153153154,
        "end": 1096,
        "id": 319,
        "no_speech_prob": 0.8395713567733765,
        "seek": 109000,
        "start": 1090,
        "temperature": 0,
        "text": " So I can grab this and I can say git clone.",
        "tokens": [
          50364,
          407,
          286,
          393,
          4444,
          341,
          293,
          286,
          393,
          584,
          18331,
          26506,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2434396553039551,
        "compression_ratio": 1.3153153153153154,
        "end": 1097,
        "id": 320,
        "no_speech_prob": 0.8395713567733765,
        "seek": 109000,
        "start": 1096,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          50664,
          876,
          11,
          1338,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2434396553039551,
        "compression_ratio": 1.3153153153153154,
        "end": 1104,
        "id": 321,
        "no_speech_prob": 0.8395713567733765,
        "seek": 109000,
        "start": 1097,
        "temperature": 0,
        "text": " So let's just do this because I'm not logged in as myself.",
        "tokens": [
          50714,
          407,
          718,
          311,
          445,
          360,
          341,
          570,
          286,
          478,
          406,
          27231,
          294,
          382,
          2059,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2434396553039551,
        "compression_ratio": 1.3153153153153154,
        "end": 1107,
        "id": 322,
        "no_speech_prob": 0.8395713567733765,
        "seek": 109000,
        "start": 1104,
        "temperature": 0,
        "text": " So let me grab all of this stuff.",
        "tokens": [
          51064,
          407,
          718,
          385,
          4444,
          439,
          295,
          341,
          1507,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19317434310913087,
        "compression_ratio": 1.3571428571428572,
        "end": 1120,
        "id": 323,
        "no_speech_prob": 0.21463559567928314,
        "seek": 110700,
        "start": 1107,
        "temperature": 0,
        "text": " And then I'm also going to run a server from this directory.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          611,
          516,
          281,
          1190,
          257,
          7154,
          490,
          341,
          21120,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19317434310913087,
        "compression_ratio": 1.3571428571428572,
        "end": 1123,
        "id": 324,
        "no_speech_prob": 0.21463559567928314,
        "seek": 110700,
        "start": 1120,
        "temperature": 0,
        "text": " So that should be running now.",
        "tokens": [
          51014,
          407,
          300,
          820,
          312,
          2614,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19317434310913087,
        "compression_ratio": 1.3571428571428572,
        "end": 1129,
        "id": 325,
        "no_speech_prob": 0.21463559567928314,
        "seek": 110700,
        "start": 1123,
        "temperature": 0,
        "text": " This is the stuff that I really would like to make a habit of doing before I start live streaming.",
        "tokens": [
          51164,
          639,
          307,
          264,
          1507,
          300,
          286,
          534,
          576,
          411,
          281,
          652,
          257,
          7164,
          295,
          884,
          949,
          286,
          722,
          1621,
          11791,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1132,
        "id": 326,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1130,
        "temperature": 0,
        "text": " So now we can look.",
        "tokens": [
          50414,
          407,
          586,
          321,
          393,
          574,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1140,
        "id": 327,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1132,
        "temperature": 0,
        "text": " These are a bunch of pre-existing examples that I will cover and discuss here in this session as well.",
        "tokens": [
          50514,
          1981,
          366,
          257,
          3840,
          295,
          659,
          12,
          36447,
          5110,
          300,
          286,
          486,
          2060,
          293,
          2248,
          510,
          294,
          341,
          5481,
          382,
          731,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1142,
        "id": 328,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1140,
        "temperature": 0,
        "text": " And let's see.",
        "tokens": [
          50914,
          400,
          718,
          311,
          536,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1149,
        "id": 329,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1142,
        "temperature": 0,
        "text": " In particular, I want to maybe and I want to also have these available for me here.",
        "tokens": [
          51014,
          682,
          1729,
          11,
          286,
          528,
          281,
          1310,
          293,
          286,
          528,
          281,
          611,
          362,
          613,
          2435,
          337,
          385,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1151,
        "id": 330,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1149,
        "temperature": 0,
        "text": " Add project folder.",
        "tokens": [
          51364,
          5349,
          1716,
          10820,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1154,
        "id": 331,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1151,
        "temperature": 0,
        "text": " Use the F16.",
        "tokens": [
          51464,
          8278,
          264,
          479,
          6866,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1155,
        "id": 332,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1154,
        "temperature": 0,
        "text": " You know what?",
        "tokens": [
          51614,
          509,
          458,
          437,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2500714262326558,
        "compression_ratio": 1.4454545454545455,
        "end": 1158,
        "id": 333,
        "no_speech_prob": 0.7850723266601562,
        "seek": 112900,
        "start": 1155,
        "temperature": 0,
        "text": " I think I'm just going to I hesitate to do this.",
        "tokens": [
          51664,
          286,
          519,
          286,
          478,
          445,
          516,
          281,
          286,
          20842,
          281,
          360,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1159,
        "id": 334,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1158,
        "temperature": 0,
        "text": " I'm just going to add this week 8.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          909,
          341,
          1243,
          1649,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1160,
        "id": 335,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1159,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1161,
        "id": 336,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1160,
        "temperature": 0,
        "text": " So now I have my code.",
        "tokens": [
          50464,
          407,
          586,
          286,
          362,
          452,
          3089,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1164,
        "id": 337,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1161,
        "temperature": 0,
        "text": " I have my pre-made examples.",
        "tokens": [
          50514,
          286,
          362,
          452,
          659,
          12,
          10341,
          5110,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1166,
        "id": 338,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1164,
        "temperature": 0,
        "text": " I really, by the way, think of this like a cooking show.",
        "tokens": [
          50664,
          286,
          534,
          11,
          538,
          264,
          636,
          11,
          519,
          295,
          341,
          411,
          257,
          6361,
          855,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1171,
        "id": 339,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1166,
        "temperature": 0,
        "text": " And so I have thought like the joy of coding, like the joy of cooking kind of works in that sense.",
        "tokens": [
          50764,
          400,
          370,
          286,
          362,
          1194,
          411,
          264,
          6258,
          295,
          17720,
          11,
          411,
          264,
          6258,
          295,
          6361,
          733,
          295,
          1985,
          294,
          300,
          2020,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1177,
        "id": 340,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1171,
        "temperature": 0,
        "text": " But there are other good like cooking show kind of style names that might be something to think of.",
        "tokens": [
          51014,
          583,
          456,
          366,
          661,
          665,
          411,
          6361,
          855,
          733,
          295,
          3758,
          5288,
          300,
          1062,
          312,
          746,
          281,
          519,
          295,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1178,
        "id": 341,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1177,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1179,
        "id": 342,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1178,
        "temperature": 0,
        "text": " So it's funny.",
        "tokens": [
          51364,
          407,
          309,
          311,
          4074,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1180,
        "id": 343,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1179,
        "temperature": 0,
        "text": " I have this like preview of the chat.",
        "tokens": [
          51414,
          286,
          362,
          341,
          411,
          14281,
          295,
          264,
          5081,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1182,
        "id": 344,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1180,
        "temperature": 0,
        "text": " I can only see like half of it.",
        "tokens": [
          51464,
          286,
          393,
          787,
          536,
          411,
          1922,
          295,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1183,
        "id": 345,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1182,
        "temperature": 0,
        "text": " So it's a little confusing to look at.",
        "tokens": [
          51564,
          407,
          309,
          311,
          257,
          707,
          13181,
          281,
          574,
          412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1184,
        "id": 346,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1183,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17011132630162268,
        "compression_ratio": 1.8436363636363637,
        "end": 1186,
        "id": 347,
        "no_speech_prob": 0.0284341499209404,
        "seek": 115800,
        "start": 1184,
        "temperature": 0,
        "text": " So now what do I need?",
        "tokens": [
          51664,
          407,
          586,
          437,
          360,
          286,
          643,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.19926237337517017,
        "compression_ratio": 1.4722222222222223,
        "end": 1192,
        "id": 348,
        "no_speech_prob": 0.1520194411277771,
        "seek": 118600,
        "start": 1186,
        "temperature": 0,
        "text": " So one thing I want to also do.",
        "tokens": [
          50364,
          407,
          472,
          551,
          286,
          528,
          281,
          611,
          360,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19926237337517017,
        "compression_ratio": 1.4722222222222223,
        "end": 1197,
        "id": 349,
        "no_speech_prob": 0.1520194411277771,
        "seek": 118600,
        "start": 1192,
        "temperature": 0,
        "text": " I hate to do this.",
        "tokens": [
          50664,
          286,
          4700,
          281,
          360,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19926237337517017,
        "compression_ratio": 1.4722222222222223,
        "end": 1207,
        "id": 350,
        "no_speech_prob": 0.1520194411277771,
        "seek": 118600,
        "start": 1197,
        "temperature": 0,
        "text": " So this is a some links and references that I would like to refer to.",
        "tokens": [
          50914,
          407,
          341,
          307,
          257,
          512,
          6123,
          293,
          15400,
          300,
          286,
          576,
          411,
          281,
          2864,
          281,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19926237337517017,
        "compression_ratio": 1.4722222222222223,
        "end": 1214,
        "id": 351,
        "no_speech_prob": 0.1520194411277771,
        "seek": 118600,
        "start": 1207,
        "temperature": 0,
        "text": " I think these will be on my new page of notes that I just haven't made yet.",
        "tokens": [
          51414,
          286,
          519,
          613,
          486,
          312,
          322,
          452,
          777,
          3028,
          295,
          5570,
          300,
          286,
          445,
          2378,
          380,
          1027,
          1939,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19926237337517017,
        "compression_ratio": 1.4722222222222223,
        "end": 1215,
        "id": 352,
        "no_speech_prob": 0.1520194411277771,
        "seek": 118600,
        "start": 1214,
        "temperature": 0,
        "text": " This is useful.",
        "tokens": [
          51764,
          639,
          307,
          4420,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24728693681604721,
        "compression_ratio": 1.50625,
        "end": 1224,
        "id": 353,
        "no_speech_prob": 0.06187307834625244,
        "seek": 121500,
        "start": 1215,
        "temperature": 0,
        "text": " This one was really good, I think.",
        "tokens": [
          50364,
          639,
          472,
          390,
          534,
          665,
          11,
          286,
          519,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24728693681604721,
        "compression_ratio": 1.50625,
        "end": 1227,
        "id": 354,
        "no_speech_prob": 0.06187307834625244,
        "seek": 121500,
        "start": 1224,
        "temperature": 0,
        "text": " I think.",
        "tokens": [
          50814,
          286,
          519,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24728693681604721,
        "compression_ratio": 1.50625,
        "end": 1228,
        "id": 355,
        "no_speech_prob": 0.06187307834625244,
        "seek": 121500,
        "start": 1227,
        "temperature": 0,
        "text": " Interesting, interesting, interesting.",
        "tokens": [
          50964,
          14711,
          11,
          1880,
          11,
          1880,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24728693681604721,
        "compression_ratio": 1.50625,
        "end": 1234,
        "id": 356,
        "no_speech_prob": 0.06187307834625244,
        "seek": 121500,
        "start": 1228,
        "temperature": 0,
        "text": " So I'm looking for what links might be the most illustrative, although I will most likely just diagram myself on the whiteboard.",
        "tokens": [
          51014,
          407,
          286,
          478,
          1237,
          337,
          437,
          6123,
          1062,
          312,
          264,
          881,
          8490,
          30457,
          11,
          4878,
          286,
          486,
          881,
          3700,
          445,
          10686,
          2059,
          322,
          264,
          2418,
          3787,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24728693681604721,
        "compression_ratio": 1.50625,
        "end": 1239,
        "id": 357,
        "no_speech_prob": 0.06187307834625244,
        "seek": 121500,
        "start": 1234,
        "temperature": 0,
        "text": " Let's look at this one.",
        "tokens": [
          51314,
          961,
          311,
          574,
          412,
          341,
          472,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24728693681604721,
        "compression_ratio": 1.50625,
        "end": 1242,
        "id": 358,
        "no_speech_prob": 0.06187307834625244,
        "seek": 121500,
        "start": 1239,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51564,
          865,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1246,
        "id": 359,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1242,
        "temperature": 0,
        "text": " So this is interesting as it relates to the grammar for programming.",
        "tokens": [
          50364,
          407,
          341,
          307,
          1880,
          382,
          309,
          16155,
          281,
          264,
          22317,
          337,
          9410,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1251,
        "id": 360,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1246,
        "temperature": 0,
        "text": " So I will have that available.",
        "tokens": [
          50564,
          407,
          286,
          486,
          362,
          300,
          2435,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1252,
        "id": 361,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1251,
        "temperature": 0,
        "text": " And okay.",
        "tokens": [
          50814,
          400,
          1392,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1256,
        "id": 362,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1252,
        "temperature": 0,
        "text": " So that's good.",
        "tokens": [
          50864,
          407,
          300,
          311,
          665,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1260,
        "id": 363,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1256,
        "temperature": 0,
        "text": " And where are my these are my notes here.",
        "tokens": [
          51064,
          400,
          689,
          366,
          452,
          613,
          366,
          452,
          5570,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1262,
        "id": 364,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1260,
        "temperature": 0,
        "text": " If I see anything useful here.",
        "tokens": [
          51264,
          759,
          286,
          536,
          1340,
          4420,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1264,
        "id": 365,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1262,
        "temperature": 0,
        "text": " And then also I'm almost there.",
        "tokens": [
          51364,
          400,
          550,
          611,
          286,
          478,
          1920,
          456,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1266,
        "id": 366,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1264,
        "temperature": 0,
        "text": " I'm almost ready.",
        "tokens": [
          51464,
          286,
          478,
          1920,
          1919,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1268,
        "id": 367,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1266,
        "temperature": 0,
        "text": " Example grammars.",
        "tokens": [
          51564,
          24755,
          781,
          17570,
          685,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.26135892453400983,
        "compression_ratio": 1.5978260869565217,
        "end": 1269,
        "id": 368,
        "no_speech_prob": 0.34855303168296814,
        "seek": 124200,
        "start": 1268,
        "temperature": 0,
        "text": " Did I look at that already?",
        "tokens": [
          51664,
          2589,
          286,
          574,
          412,
          300,
          1217,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1275,
        "id": 369,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1269,
        "temperature": 0,
        "text": " And then I want to look at Chomsky hierarchy.",
        "tokens": [
          50364,
          400,
          550,
          286,
          528,
          281,
          574,
          412,
          761,
          4785,
          4133,
          22333,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1276,
        "id": 370,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1275,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50664,
          2053,
          412,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1281,
        "id": 371,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1276,
        "temperature": 0,
        "text": " Have this page available to us as well.",
        "tokens": [
          50714,
          3560,
          341,
          3028,
          2435,
          281,
          505,
          382,
          731,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1282,
        "id": 372,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1281,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1285,
        "id": 373,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1282,
        "temperature": 0,
        "text": " So I've got this.",
        "tokens": [
          51014,
          407,
          286,
          600,
          658,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1286,
        "id": 374,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1285,
        "temperature": 0,
        "text": " I don't need I've got this.",
        "tokens": [
          51164,
          286,
          500,
          380,
          643,
          286,
          600,
          658,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1287,
        "id": 375,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1286,
        "temperature": 0,
        "text": " I've got this.",
        "tokens": [
          51214,
          286,
          600,
          658,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18132335117885046,
        "compression_ratio": 1.5210084033613445,
        "end": 1288,
        "id": 376,
        "no_speech_prob": 0.6037554740905762,
        "seek": 126900,
        "start": 1287,
        "temperature": 0,
        "text": " I've got this.",
        "tokens": [
          51264,
          286,
          600,
          658,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2105142134654371,
        "compression_ratio": 1.5168539325842696,
        "end": 1303,
        "id": 377,
        "no_speech_prob": 0.3885275721549988,
        "seek": 128800,
        "start": 1289,
        "temperature": 0,
        "text": " So I think I first want to do is the first video, the first sort of chunk of information that I will start with.",
        "tokens": [
          50414,
          407,
          286,
          519,
          286,
          700,
          528,
          281,
          360,
          307,
          264,
          700,
          960,
          11,
          264,
          700,
          1333,
          295,
          16635,
          295,
          1589,
          300,
          286,
          486,
          722,
          365,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2105142134654371,
        "compression_ratio": 1.5168539325842696,
        "end": 1307,
        "id": 378,
        "no_speech_prob": 0.3885275721549988,
        "seek": 128800,
        "start": 1303,
        "temperature": 0,
        "text": " Let me see if I have a marker and an eraser that works.",
        "tokens": [
          51114,
          961,
          385,
          536,
          498,
          286,
          362,
          257,
          15247,
          293,
          364,
          46018,
          300,
          1985,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2105142134654371,
        "compression_ratio": 1.5168539325842696,
        "end": 1311,
        "id": 379,
        "no_speech_prob": 0.3885275721549988,
        "seek": 128800,
        "start": 1307,
        "temperature": 0,
        "text": " Definitely have an eraser here.",
        "tokens": [
          51314,
          12151,
          362,
          364,
          46018,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2105142134654371,
        "compression_ratio": 1.5168539325842696,
        "end": 1313,
        "id": 380,
        "no_speech_prob": 0.3885275721549988,
        "seek": 128800,
        "start": 1311,
        "temperature": 0,
        "text": " Let's see how this goes.",
        "tokens": [
          51514,
          961,
          311,
          536,
          577,
          341,
          1709,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2105142134654371,
        "compression_ratio": 1.5168539325842696,
        "end": 1314,
        "id": 381,
        "no_speech_prob": 0.3885275721549988,
        "seek": 128800,
        "start": 1313,
        "temperature": 0,
        "text": " That's pretty good.",
        "tokens": [
          51614,
          663,
          311,
          1238,
          665,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2105142134654371,
        "compression_ratio": 1.5168539325842696,
        "end": 1315,
        "id": 382,
        "no_speech_prob": 0.3885275721549988,
        "seek": 128800,
        "start": 1314,
        "temperature": 0,
        "text": " How's the focus on that?",
        "tokens": [
          51664,
          1012,
          311,
          264,
          1879,
          322,
          300,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1317,
        "id": 383,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1315,
        "temperature": 0,
        "text": " Let me come see.",
        "tokens": [
          50364,
          961,
          385,
          808,
          536,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1319,
        "id": 384,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1317,
        "temperature": 0,
        "text": " Looks pretty good to me, I think.",
        "tokens": [
          50464,
          10027,
          1238,
          665,
          281,
          385,
          11,
          286,
          519,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1323,
        "id": 385,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1319,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50564,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1324,
        "id": 386,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1323,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1328,
        "id": 387,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1324,
        "temperature": 0,
        "text": " Here we are.",
        "tokens": [
          50814,
          1692,
          321,
          366,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1332,
        "id": 388,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1328,
        "temperature": 0,
        "text": " So.",
        "tokens": [
          51014,
          407,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1333,
        "id": 389,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1332,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1336,
        "id": 390,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1333,
        "temperature": 0,
        "text": " So I'm trying to think of what a good opening screen is.",
        "tokens": [
          51264,
          407,
          286,
          478,
          1382,
          281,
          519,
          295,
          437,
          257,
          665,
          5193,
          2568,
          307,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1341,
        "id": 391,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1336,
        "temperature": 0,
        "text": " This isn't the worst.",
        "tokens": [
          51414,
          639,
          1943,
          380,
          264,
          5855,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22691006727621588,
        "compression_ratio": 1.3622047244094488,
        "end": 1344,
        "id": 392,
        "no_speech_prob": 0.028432758525013924,
        "seek": 131500,
        "start": 1341,
        "temperature": 0,
        "text": " I think.",
        "tokens": [
          51664,
          286,
          519,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1347,
        "id": 393,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1344,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1348,
        "id": 394,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1347,
        "temperature": 0,
        "text": " Everybody hold on.",
        "tokens": [
          50514,
          7646,
          1797,
          322,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1349,
        "id": 395,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1348,
        "temperature": 0,
        "text": " I'll be right back.",
        "tokens": [
          50564,
          286,
          603,
          312,
          558,
          646,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1351,
        "id": 396,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1349,
        "temperature": 0,
        "text": " Just give me a second.",
        "tokens": [
          50614,
          1449,
          976,
          385,
          257,
          1150,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1354,
        "id": 397,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1351,
        "temperature": 0,
        "text": " I'm losing my things are going.",
        "tokens": [
          50714,
          286,
          478,
          7027,
          452,
          721,
          366,
          516,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1356,
        "id": 398,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1354,
        "temperature": 0,
        "text": " Things are beeping in weird places on different screens.",
        "tokens": [
          50864,
          9514,
          366,
          34800,
          294,
          3657,
          3190,
          322,
          819,
          11171,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1357,
        "id": 399,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1356,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2060608041697535,
        "compression_ratio": 1.2954545454545454,
        "end": 1358,
        "id": 400,
        "no_speech_prob": 0.0526144914329052,
        "seek": 134400,
        "start": 1357,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51014,
          6962,
          322,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.25235820585681545,
        "compression_ratio": 0.9866666666666667,
        "end": 1387,
        "id": 401,
        "no_speech_prob": 0.032579902559518814,
        "seek": 137400,
        "start": 1375,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25235820585681545,
        "compression_ratio": 0.9866666666666667,
        "end": 1389,
        "id": 402,
        "no_speech_prob": 0.032579902559518814,
        "seek": 137400,
        "start": 1387,
        "temperature": 0,
        "text": " I am back.",
        "tokens": [
          51014,
          286,
          669,
          646,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25235820585681545,
        "compression_ratio": 0.9866666666666667,
        "end": 1390,
        "id": 403,
        "no_speech_prob": 0.032579902559518814,
        "seek": 137400,
        "start": 1389,
        "temperature": 0,
        "text": " So I'm going to get started.",
        "tokens": [
          51114,
          407,
          286,
          478,
          516,
          281,
          483,
          1409,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25235820585681545,
        "compression_ratio": 0.9866666666666667,
        "end": 1399,
        "id": 404,
        "no_speech_prob": 0.032579902559518814,
        "seek": 137400,
        "start": 1390,
        "temperature": 0,
        "text": " So let me cycle the cameras.",
        "tokens": [
          51164,
          407,
          718,
          385,
          6586,
          264,
          8622,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2519983537126296,
        "compression_ratio": 1.668,
        "end": 1403,
        "id": 405,
        "no_speech_prob": 0.5075486302375793,
        "seek": 139900,
        "start": 1400,
        "temperature": 0,
        "text": " And this will be this first like five or ten minute little video.",
        "tokens": [
          50414,
          400,
          341,
          486,
          312,
          341,
          700,
          411,
          1732,
          420,
          2064,
          3456,
          707,
          960,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2519983537126296,
        "compression_ratio": 1.668,
        "end": 1407,
        "id": 406,
        "no_speech_prob": 0.5075486302375793,
        "seek": 139900,
        "start": 1403,
        "temperature": 0,
        "text": " So for those of you who might be watching this for the first time, this is a live session.",
        "tokens": [
          50564,
          407,
          337,
          729,
          295,
          291,
          567,
          1062,
          312,
          1976,
          341,
          337,
          264,
          700,
          565,
          11,
          341,
          307,
          257,
          1621,
          5481,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2519983537126296,
        "compression_ratio": 1.668,
        "end": 1410,
        "id": 407,
        "no_speech_prob": 0.5075486302375793,
        "seek": 139900,
        "start": 1407,
        "temperature": 0,
        "text": " It lasts somewhere between one and two hours.",
        "tokens": [
          50764,
          467,
          20669,
          4079,
          1296,
          472,
          293,
          732,
          2496,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2519983537126296,
        "compression_ratio": 1.668,
        "end": 1416,
        "id": 408,
        "no_speech_prob": 0.5075486302375793,
        "seek": 139900,
        "start": 1410,
        "temperature": 0,
        "text": " And then after, excuse me, after the session is over, with the help of Mathieu,",
        "tokens": [
          50914,
          400,
          550,
          934,
          11,
          8960,
          385,
          11,
          934,
          264,
          5481,
          307,
          670,
          11,
          365,
          264,
          854,
          295,
          15776,
          19347,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2519983537126296,
        "compression_ratio": 1.668,
        "end": 1422,
        "id": 409,
        "no_speech_prob": 0.5075486302375793,
        "seek": 139900,
        "start": 1416,
        "temperature": 0,
        "text": " I take certain sections of the live stream out and edit those together for some shorter tutorial videos",
        "tokens": [
          51214,
          286,
          747,
          1629,
          10863,
          295,
          264,
          1621,
          4309,
          484,
          293,
          8129,
          729,
          1214,
          337,
          512,
          11639,
          7073,
          2145,
          51514
        ]
      },
      {
        "avg_logprob": -0.2519983537126296,
        "compression_ratio": 1.668,
        "end": 1424,
        "id": 410,
        "no_speech_prob": 0.5075486302375793,
        "seek": 139900,
        "start": 1422,
        "temperature": 0,
        "text": " which get uploaded separately.",
        "tokens": [
          51514,
          597,
          483,
          17135,
          14759,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1431,
        "id": 411,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1424,
        "temperature": 0,
        "text": " But always the live session is also available if you want to watch the full archive of the live session",
        "tokens": [
          50364,
          583,
          1009,
          264,
          1621,
          5481,
          307,
          611,
          2435,
          498,
          291,
          528,
          281,
          1159,
          264,
          1577,
          23507,
          295,
          264,
          1621,
          5481,
          50714
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1435,
        "id": 412,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1431,
        "temperature": 0,
        "text": " with all the extra me needing to take a break kind of stuff.",
        "tokens": [
          50714,
          365,
          439,
          264,
          2857,
          385,
          18006,
          281,
          747,
          257,
          1821,
          733,
          295,
          1507,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1436,
        "id": 413,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1435,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1441,
        "id": 414,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1436,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50964,
          1692,
          321,
          352,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1446,
        "id": 415,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1441,
        "temperature": 0,
        "text": " So grammars.",
        "tokens": [
          51214,
          407,
          17570,
          685,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1447,
        "id": 416,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1446,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23719897414698746,
        "compression_ratio": 1.4797297297297298,
        "end": 1450,
        "id": 417,
        "no_speech_prob": 0.01363616157323122,
        "seek": 142400,
        "start": 1447,
        "temperature": 0,
        "text": " So session seven.",
        "tokens": [
          51514,
          407,
          5481,
          3407,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1453,
        "id": 418,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1451,
        "temperature": 0,
        "text": " Darth Taurus asked what goofiness did I miss?",
        "tokens": [
          50414,
          40696,
          314,
          40913,
          2351,
          437,
          30356,
          1324,
          630,
          286,
          1713,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1458,
        "id": 419,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1453,
        "temperature": 0,
        "text": " There's not a lot of, let me answer some of these questions for a second.",
        "tokens": [
          50514,
          821,
          311,
          406,
          257,
          688,
          295,
          11,
          718,
          385,
          1867,
          512,
          295,
          613,
          1651,
          337,
          257,
          1150,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1463,
        "id": 420,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1458,
        "temperature": 0,
        "text": " There hasn't been a lot of goofiness yet because I'm having like a low energy day.",
        "tokens": [
          50764,
          821,
          6132,
          380,
          668,
          257,
          688,
          295,
          30356,
          1324,
          1939,
          570,
          286,
          478,
          1419,
          411,
          257,
          2295,
          2281,
          786,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1468,
        "id": 421,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1463,
        "temperature": 0,
        "text": " Why LeVay asked what is the end result you're trying to get with all the text analysis topics?",
        "tokens": [
          51014,
          1545,
          1456,
          53,
          320,
          2351,
          437,
          307,
          264,
          917,
          1874,
          291,
          434,
          1382,
          281,
          483,
          365,
          439,
          264,
          2487,
          5215,
          8378,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1470,
        "id": 422,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1468,
        "temperature": 0,
        "text": " What's the true goal you're striving for?",
        "tokens": [
          51264,
          708,
          311,
          264,
          2074,
          3387,
          291,
          434,
          36582,
          337,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1472,
        "id": 423,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1470,
        "temperature": 0,
        "text": " Well, this is a great question.",
        "tokens": [
          51364,
          1042,
          11,
          341,
          307,
          257,
          869,
          1168,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23157645398237575,
        "compression_ratio": 1.6326530612244898,
        "end": 1479,
        "id": 424,
        "no_speech_prob": 0.4881690442562103,
        "seek": 145000,
        "start": 1472,
        "temperature": 0,
        "text": " And I like to think that I covered or talked about this in the introduction to programming from A to Z video",
        "tokens": [
          51464,
          400,
          286,
          411,
          281,
          519,
          300,
          286,
          5343,
          420,
          2825,
          466,
          341,
          294,
          264,
          9339,
          281,
          9410,
          490,
          316,
          281,
          1176,
          960,
          51814
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1481,
        "id": 425,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1479,
        "temperature": 0,
        "text": " about the sort of course as a whole.",
        "tokens": [
          50364,
          466,
          264,
          1333,
          295,
          1164,
          382,
          257,
          1379,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1489,
        "id": 426,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1481,
        "temperature": 0,
        "text": " And I think for me one of the things that I'm interested in is I would say like coding for blank.",
        "tokens": [
          50464,
          400,
          286,
          519,
          337,
          385,
          472,
          295,
          264,
          721,
          300,
          286,
          478,
          3102,
          294,
          307,
          286,
          576,
          584,
          411,
          17720,
          337,
          8247,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1491,
        "id": 427,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1489,
        "temperature": 0,
        "text": " So what is your field of interest?",
        "tokens": [
          50864,
          407,
          437,
          307,
          428,
          2519,
          295,
          1179,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1494,
        "id": 428,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1491,
        "temperature": 0,
        "text": " What is it that you work on?",
        "tokens": [
          50964,
          708,
          307,
          309,
          300,
          291,
          589,
          322,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1496,
        "id": 429,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1494,
        "temperature": 0,
        "text": " What's your job?",
        "tokens": [
          51114,
          708,
          311,
          428,
          1691,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1497,
        "id": 430,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1496,
        "temperature": 0,
        "text": " What are you studying?",
        "tokens": [
          51214,
          708,
          366,
          291,
          7601,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1498,
        "id": 431,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1497,
        "temperature": 0,
        "text": " What's your hobby?",
        "tokens": [
          51264,
          708,
          311,
          428,
          18240,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.16063950087997939,
        "compression_ratio": 1.627659574468085,
        "end": 1501,
        "id": 432,
        "no_speech_prob": 0.004755137953907251,
        "seek": 147900,
        "start": 1498,
        "temperature": 0,
        "text": " And what does computation or coding add to that?",
        "tokens": [
          51314,
          400,
          437,
          775,
          24903,
          420,
          17720,
          909,
          281,
          300,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.21051758834996173,
        "compression_ratio": 1.6774193548387097,
        "end": 1513,
        "id": 433,
        "no_speech_prob": 0.3592269718647003,
        "seek": 150100,
        "start": 1501,
        "temperature": 0,
        "text": " And I think something that one possible blank is language, writing, the humanities to put it like a broad kind of stroke over everything.",
        "tokens": [
          50364,
          400,
          286,
          519,
          746,
          300,
          472,
          1944,
          8247,
          307,
          2856,
          11,
          3579,
          11,
          264,
          36140,
          281,
          829,
          309,
          411,
          257,
          4152,
          733,
          295,
          12403,
          670,
          1203,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21051758834996173,
        "compression_ratio": 1.6774193548387097,
        "end": 1521,
        "id": 434,
        "no_speech_prob": 0.3592269718647003,
        "seek": 150100,
        "start": 1513,
        "temperature": 0,
        "text": " And so in particular in creative coding so to speak with tools like processing or P5.js or open frameworks,",
        "tokens": [
          50964,
          400,
          370,
          294,
          1729,
          294,
          5880,
          17720,
          370,
          281,
          1710,
          365,
          3873,
          411,
          9007,
          420,
          430,
          20,
          13,
          25530,
          420,
          1269,
          29834,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.21051758834996173,
        "compression_ratio": 1.6774193548387097,
        "end": 1523,
        "id": 435,
        "no_speech_prob": 0.3592269718647003,
        "seek": 150100,
        "start": 1521,
        "temperature": 0,
        "text": " there's a lot of focus on graphics programming.",
        "tokens": [
          51364,
          456,
          311,
          257,
          688,
          295,
          1879,
          322,
          11837,
          9410,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21051758834996173,
        "compression_ratio": 1.6774193548387097,
        "end": 1525,
        "id": 436,
        "no_speech_prob": 0.3592269718647003,
        "seek": 150100,
        "start": 1523,
        "temperature": 0,
        "text": " And there's a lot of wonderful things you can do.",
        "tokens": [
          51464,
          400,
          456,
          311,
          257,
          688,
          295,
          3715,
          721,
          291,
          393,
          360,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21051758834996173,
        "compression_ratio": 1.6774193548387097,
        "end": 1528,
        "id": 437,
        "no_speech_prob": 0.3592269718647003,
        "seek": 150100,
        "start": 1525,
        "temperature": 0,
        "text": " And I will come back to focusing on algorithms for graphics programming.",
        "tokens": [
          51564,
          400,
          286,
          486,
          808,
          646,
          281,
          8416,
          322,
          14642,
          337,
          11837,
          9410,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18268031262336892,
        "compression_ratio": 1.6452830188679246,
        "end": 1532,
        "id": 438,
        "no_speech_prob": 0.20177406072616577,
        "seek": 152800,
        "start": 1528,
        "temperature": 0,
        "text": " But here I'm asking the question what types of creative experiments,",
        "tokens": [
          50364,
          583,
          510,
          286,
          478,
          3365,
          264,
          1168,
          437,
          3467,
          295,
          5880,
          12050,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.18268031262336892,
        "compression_ratio": 1.6452830188679246,
        "end": 1539,
        "id": 439,
        "no_speech_prob": 0.20177406072616577,
        "seek": 152800,
        "start": 1532,
        "temperature": 0,
        "text": " what types of new possibilities can you discover if you're working with algorithms whose purpose is to read text and generate text?",
        "tokens": [
          50564,
          437,
          3467,
          295,
          777,
          12178,
          393,
          291,
          4411,
          498,
          291,
          434,
          1364,
          365,
          14642,
          6104,
          4334,
          307,
          281,
          1401,
          2487,
          293,
          8460,
          2487,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.18268031262336892,
        "compression_ratio": 1.6452830188679246,
        "end": 1544,
        "id": 440,
        "no_speech_prob": 0.20177406072616577,
        "seek": 152800,
        "start": 1539,
        "temperature": 0,
        "text": " And there are a lot of classic applications of this like sentiment analysis,",
        "tokens": [
          50914,
          400,
          456,
          366,
          257,
          688,
          295,
          7230,
          5821,
          295,
          341,
          411,
          16149,
          5215,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18268031262336892,
        "compression_ratio": 1.6452830188679246,
        "end": 1547,
        "id": 441,
        "no_speech_prob": 0.20177406072616577,
        "seek": 152800,
        "start": 1544,
        "temperature": 0,
        "text": " reading in a text, determining whether it's positive or negative.",
        "tokens": [
          51164,
          3760,
          294,
          257,
          2487,
          11,
          23751,
          1968,
          309,
          311,
          3353,
          420,
          3671,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18268031262336892,
        "compression_ratio": 1.6452830188679246,
        "end": 1552,
        "id": 442,
        "no_speech_prob": 0.20177406072616577,
        "seek": 152800,
        "start": 1547,
        "temperature": 0,
        "text": " There's lots of academic papers and lots of research and companies using this sort of stuff.",
        "tokens": [
          51314,
          821,
          311,
          3195,
          295,
          7778,
          10577,
          293,
          3195,
          295,
          2132,
          293,
          3431,
          1228,
          341,
          1333,
          295,
          1507,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1560,
        "id": 443,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1552,
        "temperature": 0,
        "text": " And for me I'm looking forward to provide a set of explanations and simple tutorials for some of the basic concepts around working with algorithms,",
        "tokens": [
          50364,
          400,
          337,
          385,
          286,
          478,
          1237,
          2128,
          281,
          2893,
          257,
          992,
          295,
          28708,
          293,
          2199,
          17616,
          337,
          512,
          295,
          264,
          3875,
          10392,
          926,
          1364,
          365,
          14642,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1567,
        "id": 444,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1560,
        "temperature": 0,
        "text": " programming, and text and see what the viewers, you folks watching, what creative outcomes you might have that are things that I can't think of.",
        "tokens": [
          50764,
          9410,
          11,
          293,
          2487,
          293,
          536,
          437,
          264,
          8499,
          11,
          291,
          4024,
          1976,
          11,
          437,
          5880,
          10070,
          291,
          1062,
          362,
          300,
          366,
          721,
          300,
          286,
          393,
          380,
          519,
          295,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1570,
        "id": 445,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1567,
        "temperature": 0,
        "text": " And so that to me is sort of the plan here.",
        "tokens": [
          51114,
          400,
          370,
          300,
          281,
          385,
          307,
          1333,
          295,
          264,
          1393,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1572,
        "id": 446,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1570,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1577,
        "id": 447,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1572,
        "temperature": 0,
        "text": " So yes, this van beers us.",
        "tokens": [
          51364,
          407,
          2086,
          11,
          341,
          3161,
          34159,
          505,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1579,
        "id": 448,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1577,
        "temperature": 0,
        "text": " Are we looking at stuff people sent in today?",
        "tokens": [
          51614,
          2014,
          321,
          1237,
          412,
          1507,
          561,
          2279,
          294,
          965,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.22261487520658052,
        "compression_ratio": 1.6436363636363636,
        "end": 1581,
        "id": 449,
        "no_speech_prob": 0.08880104124546051,
        "seek": 155200,
        "start": 1579,
        "temperature": 0,
        "text": " And I don't know why I can't get it.",
        "tokens": [
          51714,
          400,
          286,
          500,
          380,
          458,
          983,
          286,
          393,
          380,
          483,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1897568903049501,
        "compression_ratio": 1.7142857142857142,
        "end": 1589,
        "id": 450,
        "no_speech_prob": 0.05106988921761513,
        "seek": 158100,
        "start": 1581,
        "temperature": 0,
        "text": " I'm having, as you guys have mentioned a few times, I'm having a lot of trouble keeping up with everything just in the last couple weeks.",
        "tokens": [
          50364,
          286,
          478,
          1419,
          11,
          382,
          291,
          1074,
          362,
          2835,
          257,
          1326,
          1413,
          11,
          286,
          478,
          1419,
          257,
          688,
          295,
          5253,
          5145,
          493,
          365,
          1203,
          445,
          294,
          264,
          1036,
          1916,
          3259,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1897568903049501,
        "compression_ratio": 1.7142857142857142,
        "end": 1592,
        "id": 451,
        "no_speech_prob": 0.05106988921761513,
        "seek": 158100,
        "start": 1589,
        "temperature": 0,
        "text": " So I need to do a better job.",
        "tokens": [
          50764,
          407,
          286,
          643,
          281,
          360,
          257,
          1101,
          1691,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1897568903049501,
        "compression_ratio": 1.7142857142857142,
        "end": 1595,
        "id": 452,
        "no_speech_prob": 0.05106988921761513,
        "seek": 158100,
        "start": 1592,
        "temperature": 0,
        "text": " I have a Slack channel for the patrons of the channel.",
        "tokens": [
          50914,
          286,
          362,
          257,
          37211,
          2269,
          337,
          264,
          27559,
          295,
          264,
          2269,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1897568903049501,
        "compression_ratio": 1.7142857142857142,
        "end": 1603,
        "id": 453,
        "no_speech_prob": 0.05106988921761513,
        "seek": 158100,
        "start": 1595,
        "temperature": 0,
        "text": " And there is where people post things they're working on, share work, and we have discussion and feedback and help around those things.",
        "tokens": [
          51064,
          400,
          456,
          307,
          689,
          561,
          2183,
          721,
          436,
          434,
          1364,
          322,
          11,
          2073,
          589,
          11,
          293,
          321,
          362,
          5017,
          293,
          5824,
          293,
          854,
          926,
          729,
          721,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1897568903049501,
        "compression_ratio": 1.7142857142857142,
        "end": 1607,
        "id": 454,
        "no_speech_prob": 0.05106988921761513,
        "seek": 158100,
        "start": 1603,
        "temperature": 0,
        "text": " And I usually try to pull a few to share in the live stream.",
        "tokens": [
          51464,
          400,
          286,
          2673,
          853,
          281,
          2235,
          257,
          1326,
          281,
          2073,
          294,
          264,
          1621,
          4309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1897568903049501,
        "compression_ratio": 1.7142857142857142,
        "end": 1610,
        "id": 455,
        "no_speech_prob": 0.05106988921761513,
        "seek": 158100,
        "start": 1607,
        "temperature": 0,
        "text": " And I said last week I didn't do it.",
        "tokens": [
          51664,
          400,
          286,
          848,
          1036,
          1243,
          286,
          994,
          380,
          360,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1612,
        "id": 456,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1610,
        "temperature": 0,
        "text": " I said I would next week.",
        "tokens": [
          50364,
          286,
          848,
          286,
          576,
          958,
          1243,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1614,
        "id": 457,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1612,
        "temperature": 0,
        "text": " And this week I didn't do it again.",
        "tokens": [
          50464,
          400,
          341,
          1243,
          286,
          994,
          380,
          360,
          309,
          797,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1619,
        "id": 458,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1614,
        "temperature": 0,
        "text": " So I'm going to try to get do a better job of sort of keeping up with this sort of thing.",
        "tokens": [
          50564,
          407,
          286,
          478,
          516,
          281,
          853,
          281,
          483,
          220,
          2595,
          257,
          1101,
          1691,
          295,
          1333,
          295,
          5145,
          493,
          365,
          341,
          1333,
          295,
          551,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1628,
        "id": 459,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1619,
        "temperature": 0,
        "text": " So if you are a patron and you're on Slack, feel free to remind me about this, especially if you have something that you'd like me to share to get feedback with on the channel.",
        "tokens": [
          50814,
          407,
          498,
          291,
          366,
          257,
          21843,
          293,
          291,
          434,
          322,
          37211,
          11,
          841,
          1737,
          281,
          4160,
          385,
          466,
          341,
          11,
          2318,
          498,
          291,
          362,
          746,
          300,
          291,
          1116,
          411,
          385,
          281,
          2073,
          281,
          483,
          5824,
          365,
          322,
          264,
          2269,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1631,
        "id": 460,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1628,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1634,
        "id": 461,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1631,
        "temperature": 0,
        "text": " So I want to talk about grammars.",
        "tokens": [
          51414,
          407,
          286,
          528,
          281,
          751,
          466,
          17570,
          685,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1635,
        "id": 462,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1634,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1636,
        "id": 463,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1635,
        "temperature": 0,
        "text": " Drop the marker.",
        "tokens": [
          51614,
          17675,
          264,
          15247,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1811272939046224,
        "compression_ratio": 1.6270491803278688,
        "end": 1637,
        "id": 464,
        "no_speech_prob": 0.01262441836297512,
        "seek": 161000,
        "start": 1636,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51664,
          865,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1645,
        "id": 465,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1638,
        "temperature": 0,
        "text": " It's like a, you know, some people have like a nice teddy stuffed animal or something as a comfort object.",
        "tokens": [
          50414,
          467,
          311,
          411,
          257,
          11,
          291,
          458,
          11,
          512,
          561,
          362,
          411,
          257,
          1481,
          45116,
          24092,
          5496,
          420,
          746,
          382,
          257,
          3400,
          2657,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1647,
        "id": 466,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1645,
        "temperature": 0,
        "text": " I have a whiteboard marker.",
        "tokens": [
          50764,
          286,
          362,
          257,
          2418,
          3787,
          15247,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1648,
        "id": 467,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1647,
        "temperature": 0,
        "text": " Put it down over here.",
        "tokens": [
          50864,
          4935,
          309,
          760,
          670,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1650,
        "id": 468,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1648,
        "temperature": 0,
        "text": " I'm going to use it in a second to draw on that whiteboard.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          764,
          309,
          294,
          257,
          1150,
          281,
          2642,
          322,
          300,
          2418,
          3787,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1651,
        "id": 469,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1650,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1654,
        "id": 470,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1651,
        "temperature": 0,
        "text": " So here we go.",
        "tokens": [
          51064,
          407,
          510,
          321,
          352,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19649535285101996,
        "compression_ratio": 1.473170731707317,
        "end": 1664,
        "id": 471,
        "no_speech_prob": 0.0035935782361775637,
        "seek": 163700,
        "start": 1654,
        "temperature": 0,
        "text": " This will be an introduction to context-free grammars and such.",
        "tokens": [
          51214,
          639,
          486,
          312,
          364,
          9339,
          281,
          4319,
          12,
          10792,
          17570,
          685,
          293,
          1270,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1665,
        "id": 472,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1664,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1669,
        "id": 473,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1665,
        "temperature": 0,
        "text": " So I'm just looking at this.",
        "tokens": [
          50414,
          407,
          286,
          478,
          445,
          1237,
          412,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1676,
        "id": 474,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1669,
        "temperature": 0,
        "text": " Yeah, I'm looking at this page and trying to remember some of these URLs.",
        "tokens": [
          50614,
          865,
          11,
          286,
          478,
          1237,
          412,
          341,
          3028,
          293,
          1382,
          281,
          1604,
          512,
          295,
          613,
          43267,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1677,
        "id": 475,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1676,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1679,
        "id": 476,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1677,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1685,
        "id": 477,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1679,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1691,
        "id": 478,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1685,
        "temperature": 0,
        "text": " Hello and welcome to session seven from a session.",
        "tokens": [
          51414,
          2425,
          293,
          2928,
          281,
          5481,
          3407,
          490,
          257,
          5481,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23433240743783804,
        "compression_ratio": 1.4222222222222223,
        "end": 1693,
        "id": 479,
        "no_speech_prob": 0.08151555061340332,
        "seek": 166400,
        "start": 1691,
        "temperature": 0,
        "text": " One more time.",
        "tokens": [
          51714,
          1485,
          544,
          565,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2293448766072591,
        "compression_ratio": 1.4444444444444444,
        "end": 1698,
        "id": 480,
        "no_speech_prob": 0.021286534145474434,
        "seek": 169300,
        "start": 1693,
        "temperature": 0,
        "text": " This is my free Mulligan start over thing.",
        "tokens": [
          50364,
          639,
          307,
          452,
          1737,
          41621,
          9552,
          722,
          670,
          551,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2293448766072591,
        "compression_ratio": 1.4444444444444444,
        "end": 1701,
        "id": 481,
        "no_speech_prob": 0.021286534145474434,
        "seek": 169300,
        "start": 1698,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2293448766072591,
        "compression_ratio": 1.4444444444444444,
        "end": 1705,
        "id": 482,
        "no_speech_prob": 0.021286534145474434,
        "seek": 169300,
        "start": 1701,
        "temperature": 0,
        "text": " Hello, welcome to session seven of programming from A to Z.",
        "tokens": [
          50764,
          2425,
          11,
          2928,
          281,
          5481,
          3407,
          295,
          9410,
          490,
          316,
          281,
          1176,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2293448766072591,
        "compression_ratio": 1.4444444444444444,
        "end": 1713,
        "id": 483,
        "no_speech_prob": 0.021286534145474434,
        "seek": 169300,
        "start": 1705,
        "temperature": 0,
        "text": " The topic for session seven is grammars and what I mean specifically a certain kind of grammar called a context-free grammar.",
        "tokens": [
          50964,
          440,
          4829,
          337,
          5481,
          3407,
          307,
          17570,
          685,
          293,
          437,
          286,
          914,
          4682,
          257,
          1629,
          733,
          295,
          22317,
          1219,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22445798127547553,
        "compression_ratio": 1.77007299270073,
        "end": 1728,
        "id": 484,
        "no_speech_prob": 0.4648165702819824,
        "seek": 171300,
        "start": 1713,
        "temperature": 0,
        "text": " So in this introductory video, I want to just kind of talk, give a brief overview of what grammars are, what the various, what a context-free grammar is and how that fits into that sort of larger concept of a grammar, so to speak.",
        "tokens": [
          50364,
          407,
          294,
          341,
          39048,
          960,
          11,
          286,
          528,
          281,
          445,
          733,
          295,
          751,
          11,
          976,
          257,
          5353,
          12492,
          295,
          437,
          17570,
          685,
          366,
          11,
          437,
          264,
          3683,
          11,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          293,
          577,
          300,
          9001,
          666,
          300,
          1333,
          295,
          4833,
          3410,
          295,
          257,
          22317,
          11,
          370,
          281,
          1710,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22445798127547553,
        "compression_ratio": 1.77007299270073,
        "end": 1733,
        "id": 485,
        "no_speech_prob": 0.4648165702819824,
        "seek": 171300,
        "start": 1728,
        "temperature": 0,
        "text": " And what are some tools that you can work with in JavaScript to generate text based on grammars?",
        "tokens": [
          51114,
          400,
          437,
          366,
          512,
          3873,
          300,
          291,
          393,
          589,
          365,
          294,
          15778,
          281,
          8460,
          2487,
          2361,
          322,
          17570,
          685,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.22445798127547553,
        "compression_ratio": 1.77007299270073,
        "end": 1742,
        "id": 486,
        "no_speech_prob": 0.4648165702819824,
        "seek": 171300,
        "start": 1733,
        "temperature": 0,
        "text": " And then I'm going to, this video is going to end and I'm going to launch right into some code examples of writing grammars and generating text with grammar.",
        "tokens": [
          51364,
          400,
          550,
          286,
          478,
          516,
          281,
          11,
          341,
          960,
          307,
          516,
          281,
          917,
          293,
          286,
          478,
          516,
          281,
          4025,
          558,
          666,
          512,
          3089,
          5110,
          295,
          3579,
          17570,
          685,
          293,
          17746,
          2487,
          365,
          22317,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1745,
        "id": 487,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1742,
        "temperature": 0,
        "text": " So hopefully this is going to be kind of a short video, just give you kind of an overview.",
        "tokens": [
          50364,
          407,
          4696,
          341,
          307,
          516,
          281,
          312,
          733,
          295,
          257,
          2099,
          960,
          11,
          445,
          976,
          291,
          733,
          295,
          364,
          12492,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1750,
        "id": 488,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1745,
        "temperature": 0,
        "text": " If you're not interested in the overview, skip to the next video and get right into the code of using and generating text with a grammar.",
        "tokens": [
          50514,
          759,
          291,
          434,
          406,
          3102,
          294,
          264,
          12492,
          11,
          10023,
          281,
          264,
          958,
          960,
          293,
          483,
          558,
          666,
          264,
          3089,
          295,
          1228,
          293,
          17746,
          2487,
          365,
          257,
          22317,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1751,
        "id": 489,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1750,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1757,
        "id": 490,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1751,
        "temperature": 0,
        "text": " So first of all, I have this Wikipedia page up behind me, which is from, which is the Chomsky hierarchy.",
        "tokens": [
          50814,
          407,
          700,
          295,
          439,
          11,
          286,
          362,
          341,
          28999,
          3028,
          493,
          2261,
          385,
          11,
          597,
          307,
          490,
          11,
          597,
          307,
          264,
          761,
          4785,
          4133,
          22333,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1762,
        "id": 491,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1757,
        "temperature": 0,
        "text": " So one way that I think is useful to think of a grammar, I lost this diagram that I wanted.",
        "tokens": [
          51114,
          407,
          472,
          636,
          300,
          286,
          519,
          307,
          4420,
          281,
          519,
          295,
          257,
          22317,
          11,
          286,
          2731,
          341,
          10686,
          300,
          286,
          1415,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1768,
        "id": 492,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1762,
        "temperature": 0,
        "text": " A grammar is really the structure and syntax of language or you might say the language of the languages of a language.",
        "tokens": [
          51364,
          316,
          22317,
          307,
          534,
          264,
          3877,
          293,
          28431,
          295,
          2856,
          420,
          291,
          1062,
          584,
          264,
          2856,
          295,
          264,
          8650,
          295,
          257,
          2856,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1769,
        "id": 493,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1768,
        "temperature": 0,
        "text": " That didn't make any sense.",
        "tokens": [
          51664,
          663,
          994,
          380,
          652,
          604,
          2020,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21356524149576822,
        "compression_ratio": 1.7889908256880733,
        "end": 1770,
        "id": 494,
        "no_speech_prob": 0.006903584115207195,
        "seek": 174200,
        "start": 1769,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51714,
          1779,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20708721286647921,
        "compression_ratio": 1.6027397260273972,
        "end": 1775,
        "id": 495,
        "no_speech_prob": 0.021613966673612595,
        "seek": 177000,
        "start": 1770,
        "temperature": 0,
        "text": " So how do you define how the pieces of a language, so to speak?",
        "tokens": [
          50364,
          407,
          577,
          360,
          291,
          6964,
          577,
          264,
          3755,
          295,
          257,
          2856,
          11,
          370,
          281,
          1710,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.20708721286647921,
        "compression_ratio": 1.6027397260273972,
        "end": 1786,
        "id": 496,
        "no_speech_prob": 0.021613966673612595,
        "seek": 177000,
        "start": 1775,
        "temperature": 0,
        "text": " So there are a variety of kinds of grammars and I'll include a link to Chomsky's kind of seminal paper about different types of grammars.",
        "tokens": [
          50614,
          407,
          456,
          366,
          257,
          5673,
          295,
          3685,
          295,
          17570,
          685,
          293,
          286,
          603,
          4090,
          257,
          2113,
          281,
          761,
          4785,
          4133,
          311,
          733,
          295,
          4361,
          2071,
          3035,
          466,
          819,
          3467,
          295,
          17570,
          685,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20708721286647921,
        "compression_ratio": 1.6027397260273972,
        "end": 1796,
        "id": 497,
        "no_speech_prob": 0.021613966673612595,
        "seek": 177000,
        "start": 1786,
        "temperature": 0,
        "text": " And you can see here this, these are, this is a set of different possible grammars, regular, context free, context sensitive, recursively enumerable.",
        "tokens": [
          51164,
          400,
          291,
          393,
          536,
          510,
          341,
          11,
          613,
          366,
          11,
          341,
          307,
          257,
          992,
          295,
          819,
          1944,
          17570,
          685,
          11,
          3890,
          11,
          4319,
          1737,
          11,
          4319,
          9477,
          11,
          20560,
          3413,
          465,
          15583,
          712,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1800,
        "id": 498,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1796,
        "temperature": 0,
        "text": " And context free is the grammar that I really want to focus on.",
        "tokens": [
          50364,
          400,
          4319,
          1737,
          307,
          264,
          22317,
          300,
          286,
          534,
          528,
          281,
          1879,
          322,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1805,
        "id": 499,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1800,
        "temperature": 0,
        "text": " And if I go, I have some other links that you can kind of look at that I'm going to put.",
        "tokens": [
          50564,
          400,
          498,
          286,
          352,
          11,
          286,
          362,
          512,
          661,
          6123,
          300,
          291,
          393,
          733,
          295,
          574,
          412,
          300,
          286,
          478,
          516,
          281,
          829,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1807,
        "id": 500,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1805,
        "temperature": 0,
        "text": " This is a great language.",
        "tokens": [
          50814,
          639,
          307,
          257,
          869,
          2856,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1811,
        "id": 501,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1807,
        "temperature": 0,
        "text": " This is obviously where I got that from, from this article, the grammar being the language of languages.",
        "tokens": [
          50914,
          639,
          307,
          2745,
          689,
          286,
          658,
          300,
          490,
          11,
          490,
          341,
          7222,
          11,
          264,
          22317,
          885,
          264,
          2856,
          295,
          8650,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1815,
        "id": 502,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1811,
        "temperature": 0,
        "text": " And you can see that there are a variety of different kinds of notation.",
        "tokens": [
          51114,
          400,
          291,
          393,
          536,
          300,
          456,
          366,
          257,
          5673,
          295,
          819,
          3685,
          295,
          24657,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1818,
        "id": 503,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1815,
        "temperature": 0,
        "text": " Backus now form is a kind of notation.",
        "tokens": [
          51314,
          5833,
          301,
          586,
          1254,
          307,
          257,
          733,
          295,
          24657,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2229034257971722,
        "compression_ratio": 1.7551020408163265,
        "end": 1820,
        "id": 504,
        "no_speech_prob": 0.06655872613191605,
        "seek": 179600,
        "start": 1818,
        "temperature": 0,
        "text": " It is sort of a syntax of grammar.",
        "tokens": [
          51464,
          467,
          307,
          1333,
          295,
          257,
          28431,
          295,
          22317,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2207150282683196,
        "compression_ratio": 1.6147186147186148,
        "end": 1826,
        "id": 505,
        "no_speech_prob": 0.5811092257499695,
        "seek": 182000,
        "start": 1820,
        "temperature": 0,
        "text": " So we're looking at this idea of grammars outside of programming in a way.",
        "tokens": [
          50364,
          407,
          321,
          434,
          1237,
          412,
          341,
          1558,
          295,
          17570,
          685,
          2380,
          295,
          9410,
          294,
          257,
          636,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2207150282683196,
        "compression_ratio": 1.6147186147186148,
        "end": 1832,
        "id": 506,
        "no_speech_prob": 0.5811092257499695,
        "seek": 182000,
        "start": 1826,
        "temperature": 0,
        "text": " And then what we want to do is pull the grammars into our code and figure out how we can, how we can mess around with them.",
        "tokens": [
          50664,
          400,
          550,
          437,
          321,
          528,
          281,
          360,
          307,
          2235,
          264,
          17570,
          685,
          666,
          527,
          3089,
          293,
          2573,
          484,
          577,
          321,
          393,
          11,
          577,
          321,
          393,
          2082,
          926,
          365,
          552,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2207150282683196,
        "compression_ratio": 1.6147186147186148,
        "end": 1836,
        "id": 507,
        "no_speech_prob": 0.5811092257499695,
        "seek": 182000,
        "start": 1832,
        "temperature": 0,
        "text": " I just want to like do this video over again.",
        "tokens": [
          50964,
          286,
          445,
          528,
          281,
          411,
          360,
          341,
          960,
          670,
          797,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2207150282683196,
        "compression_ratio": 1.6147186147186148,
        "end": 1838,
        "id": 508,
        "no_speech_prob": 0.5811092257499695,
        "seek": 182000,
        "start": 1836,
        "temperature": 0,
        "text": " Hooray for Backus now.",
        "tokens": [
          51164,
          3631,
          284,
          320,
          337,
          5833,
          301,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2207150282683196,
        "compression_ratio": 1.6147186147186148,
        "end": 1843,
        "id": 509,
        "no_speech_prob": 0.5811092257499695,
        "seek": 182000,
        "start": 1838,
        "temperature": 0,
        "text": " What's something there's, hold on.",
        "tokens": [
          51264,
          708,
          311,
          746,
          456,
          311,
          11,
          1797,
          322,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2207150282683196,
        "compression_ratio": 1.6147186147186148,
        "end": 1848,
        "id": 510,
        "no_speech_prob": 0.5811092257499695,
        "seek": 182000,
        "start": 1843,
        "temperature": 0,
        "text": " I just had to, I had to pause for a moment because I'm not feeling it.",
        "tokens": [
          51514,
          286,
          445,
          632,
          281,
          11,
          286,
          632,
          281,
          10465,
          337,
          257,
          1623,
          570,
          286,
          478,
          406,
          2633,
          309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25517668443567615,
        "compression_ratio": 1.3866666666666667,
        "end": 1850,
        "id": 511,
        "no_speech_prob": 0.03358684852719307,
        "seek": 184800,
        "start": 1848,
        "temperature": 0,
        "text": " I can't see the chat.",
        "tokens": [
          50364,
          286,
          393,
          380,
          536,
          264,
          5081,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.25517668443567615,
        "compression_ratio": 1.3866666666666667,
        "end": 1852,
        "id": 512,
        "no_speech_prob": 0.03358684852719307,
        "seek": 184800,
        "start": 1850,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50464,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.25517668443567615,
        "compression_ratio": 1.3866666666666667,
        "end": 1854,
        "id": 513,
        "no_speech_prob": 0.03358684852719307,
        "seek": 184800,
        "start": 1852,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50564,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25517668443567615,
        "compression_ratio": 1.3866666666666667,
        "end": 1857,
        "id": 514,
        "no_speech_prob": 0.03358684852719307,
        "seek": 184800,
        "start": 1854,
        "temperature": 0,
        "text": " Let me, if you guys will bear with me today.",
        "tokens": [
          50664,
          961,
          385,
          11,
          498,
          291,
          1074,
          486,
          6155,
          365,
          385,
          965,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25517668443567615,
        "compression_ratio": 1.3866666666666667,
        "end": 1863,
        "id": 515,
        "no_speech_prob": 0.03358684852719307,
        "seek": 184800,
        "start": 1857,
        "temperature": 0,
        "text": " I would like to do a take two here.",
        "tokens": [
          50814,
          286,
          576,
          411,
          281,
          360,
          257,
          747,
          732,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.25517668443567615,
        "compression_ratio": 1.3866666666666667,
        "end": 1874,
        "id": 516,
        "no_speech_prob": 0.03358684852719307,
        "seek": 184800,
        "start": 1863,
        "temperature": 0,
        "text": " Because I realized, and rather than, sorry, my preview screen is all messed up with the chat.",
        "tokens": [
          51114,
          1436,
          286,
          5334,
          11,
          293,
          2831,
          813,
          11,
          2597,
          11,
          452,
          14281,
          2568,
          307,
          439,
          16507,
          493,
          365,
          264,
          5081,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1881,
        "id": 517,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1874,
        "temperature": 0,
        "text": " Rather than edit together, I think I'm just going to start over.",
        "tokens": [
          50364,
          16571,
          813,
          8129,
          1214,
          11,
          286,
          519,
          286,
          478,
          445,
          516,
          281,
          722,
          670,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1889,
        "id": 518,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1881,
        "temperature": 0,
        "text": " Because I sort of forgot that I was pulling this idea of the language of languages from this.",
        "tokens": [
          50714,
          1436,
          286,
          1333,
          295,
          5298,
          300,
          286,
          390,
          8407,
          341,
          1558,
          295,
          264,
          2856,
          295,
          8650,
          490,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1891,
        "id": 519,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1889,
        "temperature": 0,
        "text": " And then I have the Chomsky hierarchy here.",
        "tokens": [
          51114,
          400,
          550,
          286,
          362,
          264,
          761,
          4785,
          4133,
          22333,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1893,
        "id": 520,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1891,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1895,
        "id": 521,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1893,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1897,
        "id": 522,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1895,
        "temperature": 0,
        "text": " So, yeah.",
        "tokens": [
          51414,
          407,
          11,
          1338,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1898,
        "id": 523,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1897,
        "temperature": 0,
        "text": " So, oh, wow.",
        "tokens": [
          51514,
          407,
          11,
          1954,
          11,
          6076,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1902,
        "id": 524,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1898,
        "temperature": 0,
        "text": " Somebody said that Nara was actually a professor at the university where they went.",
        "tokens": [
          51564,
          13463,
          848,
          300,
          426,
          2419,
          390,
          767,
          257,
          8304,
          412,
          264,
          5454,
          689,
          436,
          1437,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2360543915719697,
        "compression_ratio": 1.536697247706422,
        "end": 1903,
        "id": 525,
        "no_speech_prob": 0.08631627261638641,
        "seek": 187400,
        "start": 1902,
        "temperature": 0,
        "text": " That's great.",
        "tokens": [
          51764,
          663,
          311,
          869,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1904,
        "id": 526,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1903,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1905,
        "id": 527,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1904,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1906,
        "id": 528,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1905,
        "temperature": 0,
        "text": " So, I apologize for this.",
        "tokens": [
          50464,
          407,
          11,
          286,
          12328,
          337,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1907,
        "id": 529,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1906,
        "temperature": 0,
        "text": " I try never to do this.",
        "tokens": [
          50514,
          286,
          853,
          1128,
          281,
          360,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1909,
        "id": 530,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1907,
        "temperature": 0,
        "text": " But you guys got to cut me some slack today.",
        "tokens": [
          50564,
          583,
          291,
          1074,
          658,
          281,
          1723,
          385,
          512,
          29767,
          965,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1911,
        "id": 531,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1909,
        "temperature": 0,
        "text": " I almost didn't come.",
        "tokens": [
          50664,
          286,
          1920,
          994,
          380,
          808,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1912,
        "id": 532,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1911,
        "temperature": 0,
        "text": " I don't mean to complain.",
        "tokens": [
          50764,
          286,
          500,
          380,
          914,
          281,
          11024,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1914,
        "id": 533,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1912,
        "temperature": 0,
        "text": " This is awful.",
        "tokens": [
          50814,
          639,
          307,
          11232,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1917,
        "id": 534,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1914,
        "temperature": 0,
        "text": " Everyone's allowed to have a bad day.",
        "tokens": [
          50914,
          5198,
          311,
          4350,
          281,
          362,
          257,
          1578,
          786,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1918,
        "id": 535,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1917,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1924,
        "id": 536,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1918,
        "temperature": 0,
        "text": " So, here we go.",
        "tokens": [
          51114,
          407,
          11,
          510,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1926,
        "id": 537,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1924,
        "temperature": 0,
        "text": " One more time.",
        "tokens": [
          51414,
          1485,
          544,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1927,
        "id": 538,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1926,
        "temperature": 0,
        "text": " Let me cycle that camera.",
        "tokens": [
          51514,
          961,
          385,
          6586,
          300,
          2799,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1929,
        "id": 539,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1927,
        "temperature": 0,
        "text": " Oh, no, this is going to be so short.",
        "tokens": [
          51564,
          876,
          11,
          572,
          11,
          341,
          307,
          516,
          281,
          312,
          370,
          2099,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20569885778063127,
        "compression_ratio": 1.5394190871369295,
        "end": 1931,
        "id": 540,
        "no_speech_prob": 0.061873070895671844,
        "seek": 190300,
        "start": 1929,
        "temperature": 0,
        "text": " I want to just get into doing the stuff with the grammar.",
        "tokens": [
          51664,
          286,
          528,
          281,
          445,
          483,
          666,
          884,
          264,
          1507,
          365,
          264,
          22317,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1871605722527755,
        "compression_ratio": 1.6376146788990826,
        "end": 1932,
        "id": 541,
        "no_speech_prob": 0.21203932166099548,
        "seek": 193100,
        "start": 1931,
        "temperature": 0,
        "text": " So, I'm going to make this short.",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          652,
          341,
          2099,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1871605722527755,
        "compression_ratio": 1.6376146788990826,
        "end": 1934,
        "id": 542,
        "no_speech_prob": 0.21203932166099548,
        "seek": 193100,
        "start": 1932,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1871605722527755,
        "compression_ratio": 1.6376146788990826,
        "end": 1938,
        "id": 543,
        "no_speech_prob": 0.21203932166099548,
        "seek": 193100,
        "start": 1934,
        "temperature": 0,
        "text": " Hello, and welcome to session 7 of programming from A to Z.",
        "tokens": [
          50514,
          2425,
          11,
          293,
          2928,
          281,
          5481,
          1614,
          295,
          9410,
          490,
          316,
          281,
          1176,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1871605722527755,
        "compression_ratio": 1.6376146788990826,
        "end": 1944,
        "id": 544,
        "no_speech_prob": 0.21203932166099548,
        "seek": 193100,
        "start": 1938,
        "temperature": 0,
        "text": " And the topic for this session is generating text with something called a context-free grammar.",
        "tokens": [
          50714,
          400,
          264,
          4829,
          337,
          341,
          5481,
          307,
          17746,
          2487,
          365,
          746,
          1219,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1871605722527755,
        "compression_ratio": 1.6376146788990826,
        "end": 1949,
        "id": 545,
        "no_speech_prob": 0.21203932166099548,
        "seek": 193100,
        "start": 1944,
        "temperature": 0,
        "text": " So, what I want to do in this video is just talk a little bit about the broader topic of what a grammar is.",
        "tokens": [
          51014,
          407,
          11,
          437,
          286,
          528,
          281,
          360,
          294,
          341,
          960,
          307,
          445,
          751,
          257,
          707,
          857,
          466,
          264,
          13227,
          4829,
          295,
          437,
          257,
          22317,
          307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1871605722527755,
        "compression_ratio": 1.6376146788990826,
        "end": 1953,
        "id": 546,
        "no_speech_prob": 0.21203932166099548,
        "seek": 193100,
        "start": 1949,
        "temperature": 0,
        "text": " And then specifically what a context-free grammar is.",
        "tokens": [
          51264,
          400,
          550,
          4682,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1961,
        "id": 547,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1953,
        "temperature": 0,
        "text": " And look at some different and give you an overview of what code libraries and algorithms you might use to generate text with a context-free grammar.",
        "tokens": [
          50364,
          400,
          574,
          412,
          512,
          819,
          293,
          976,
          291,
          364,
          12492,
          295,
          437,
          3089,
          15148,
          293,
          14642,
          291,
          1062,
          764,
          281,
          8460,
          2487,
          365,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1968,
        "id": 548,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1961,
        "temperature": 0,
        "text": " And as soon as I'm done with that, I'm going to just move into the next video and actually start to implement a grammar to generate stories and text or poems or whatever.",
        "tokens": [
          50764,
          400,
          382,
          2321,
          382,
          286,
          478,
          1096,
          365,
          300,
          11,
          286,
          478,
          516,
          281,
          445,
          1286,
          666,
          264,
          958,
          960,
          293,
          767,
          722,
          281,
          4445,
          257,
          22317,
          281,
          8460,
          3676,
          293,
          2487,
          420,
          24014,
          420,
          2035,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1970,
        "id": 549,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1968,
        "temperature": 0,
        "text": " And you will see how you can do that.",
        "tokens": [
          51114,
          400,
          291,
          486,
          536,
          577,
          291,
          393,
          360,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1972,
        "id": 550,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1970,
        "temperature": 0,
        "text": " So, if you want to just jump to the code, you can skip to the next video.",
        "tokens": [
          51214,
          407,
          11,
          498,
          291,
          528,
          281,
          445,
          3012,
          281,
          264,
          3089,
          11,
          291,
          393,
          10023,
          281,
          264,
          958,
          960,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1974,
        "id": 551,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1972,
        "temperature": 0,
        "text": " But here I'll give you kind of an overview.",
        "tokens": [
          51314,
          583,
          510,
          286,
          603,
          976,
          291,
          733,
          295,
          364,
          12492,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1975,
        "id": 552,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1974,
        "temperature": 0,
        "text": " So, if you're interested in the topic.",
        "tokens": [
          51414,
          407,
          11,
          498,
          291,
          434,
          3102,
          294,
          264,
          4829,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1976,
        "id": 553,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1975,
        "temperature": 0,
        "text": " First of all, so what is a grammar?",
        "tokens": [
          51464,
          2386,
          295,
          439,
          11,
          370,
          437,
          307,
          257,
          22317,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.18582651150301568,
        "compression_ratio": 1.8540372670807452,
        "end": 1982,
        "id": 554,
        "no_speech_prob": 0.6333087682723999,
        "seek": 195300,
        "start": 1976,
        "temperature": 0,
        "text": " And this is a page about grammars by, by, by.",
        "tokens": [
          51514,
          400,
          341,
          307,
          257,
          3028,
          466,
          17570,
          685,
          538,
          11,
          538,
          11,
          538,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1984,
        "id": 555,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1982,
        "temperature": 0,
        "text": " I want to give reference to who this is by.",
        "tokens": [
          50364,
          286,
          528,
          281,
          976,
          6408,
          281,
          567,
          341,
          307,
          538,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1987,
        "id": 556,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1984,
        "temperature": 0,
        "text": " Matt, Matt Might on Twitter.",
        "tokens": [
          50464,
          7397,
          11,
          7397,
          23964,
          322,
          5794,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1988,
        "id": 557,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1987,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          50614,
          1033,
          11,
          1797,
          322,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1991,
        "id": 558,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1988,
        "temperature": 0,
        "text": " Matt, too, will edit this back in.",
        "tokens": [
          50664,
          7397,
          11,
          886,
          11,
          486,
          8129,
          341,
          646,
          294,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1994,
        "id": 559,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1991,
        "temperature": 0,
        "text": " This is a page about grammars by Matt Might on Twitter.",
        "tokens": [
          50814,
          639,
          307,
          257,
          3028,
          466,
          17570,
          685,
          538,
          7397,
          23964,
          322,
          5794,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1996,
        "id": 560,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1994,
        "temperature": 0,
        "text": " I find it a useful overview of grammars.",
        "tokens": [
          50964,
          286,
          915,
          309,
          257,
          4420,
          12492,
          295,
          17570,
          685,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 1998,
        "id": 561,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1996,
        "temperature": 0,
        "text": " I'll link to it in this video's description.",
        "tokens": [
          51064,
          286,
          603,
          2113,
          281,
          309,
          294,
          341,
          960,
          311,
          3855,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 2005,
        "id": 562,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 1998,
        "temperature": 0,
        "text": " And Matt Might makes the point which is grammar, you can think of it as the language of languages.",
        "tokens": [
          51164,
          400,
          7397,
          23964,
          1669,
          264,
          935,
          597,
          307,
          22317,
          11,
          291,
          393,
          519,
          295,
          309,
          382,
          264,
          2856,
          295,
          8650,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 2006,
        "id": 563,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 2005,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51514,
          1779,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 2007,
        "id": 564,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 2006,
        "temperature": 0,
        "text": " So, we have language.",
        "tokens": [
          51564,
          407,
          11,
          321,
          362,
          2856,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 2010,
        "id": 565,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 2007,
        "temperature": 0,
        "text": " But how do you describe the syntax and structure of a language?",
        "tokens": [
          51614,
          583,
          577,
          360,
          291,
          6786,
          264,
          28431,
          293,
          3877,
          295,
          257,
          2856,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.21327105435458096,
        "compression_ratio": 1.789090909090909,
        "end": 2011,
        "id": 566,
        "no_speech_prob": 0.039045173674821854,
        "seek": 198200,
        "start": 2010,
        "temperature": 0,
        "text": " What's the language for a language?",
        "tokens": [
          51764,
          708,
          311,
          264,
          2856,
          337,
          257,
          2856,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2012,
        "id": 567,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2011,
        "temperature": 0,
        "text": " And that's what a grammar is.",
        "tokens": [
          50364,
          400,
          300,
          311,
          437,
          257,
          22317,
          307,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2017,
        "id": 568,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2012,
        "temperature": 0,
        "text": " And if I were to scan through this page, there's, you know, different Bacchus Now form grammar.",
        "tokens": [
          50414,
          400,
          498,
          286,
          645,
          281,
          11049,
          807,
          341,
          3028,
          11,
          456,
          311,
          11,
          291,
          458,
          11,
          819,
          363,
          326,
          339,
          301,
          823,
          1254,
          22317,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2018,
        "id": 569,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2017,
        "temperature": 0,
        "text": " And Bacchus Now, extended Bacchus Now.",
        "tokens": [
          50664,
          400,
          363,
          326,
          339,
          301,
          823,
          11,
          10913,
          363,
          326,
          339,
          301,
          823,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2021,
        "id": 570,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2018,
        "temperature": 0,
        "text": " There's all these different syntax, syntaxes.",
        "tokens": [
          50714,
          821,
          311,
          439,
          613,
          819,
          28431,
          11,
          28431,
          279,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2023,
        "id": 571,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2021,
        "temperature": 0,
        "text": " How do you say, what's the plural syntax?",
        "tokens": [
          50864,
          1012,
          360,
          291,
          584,
          11,
          437,
          311,
          264,
          25377,
          28431,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2025,
        "id": 572,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2023,
        "temperature": 0,
        "text": " Somebody write in the comments for me.",
        "tokens": [
          50964,
          13463,
          2464,
          294,
          264,
          3053,
          337,
          385,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2029,
        "id": 573,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2025,
        "temperature": 0,
        "text": " And a variety of ways of expressing grammars for a language.",
        "tokens": [
          51064,
          400,
          257,
          5673,
          295,
          2098,
          295,
          22171,
          17570,
          685,
          337,
          257,
          2856,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2033,
        "id": 574,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2029,
        "temperature": 0,
        "text": " One thing I'll point out to you, whoops, is this is a grammar.",
        "tokens": [
          51264,
          1485,
          551,
          286,
          603,
          935,
          484,
          281,
          291,
          11,
          567,
          3370,
          11,
          307,
          341,
          307,
          257,
          22317,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23172263832359047,
        "compression_ratio": 1.7430555555555556,
        "end": 2039,
        "id": 575,
        "no_speech_prob": 0.040235765278339386,
        "seek": 201100,
        "start": 2033,
        "temperature": 0,
        "text": " Programming languages are made actually with this thing called a context-free grammar.",
        "tokens": [
          51464,
          8338,
          2810,
          8650,
          366,
          1027,
          767,
          365,
          341,
          551,
          1219,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2041,
        "id": 576,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2039,
        "temperature": 0,
        "text": " So, I haven't described what a context-free grammar is.",
        "tokens": [
          50364,
          407,
          11,
          286,
          2378,
          380,
          7619,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2046,
        "id": 577,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2041,
        "temperature": 0,
        "text": " But you can see here, this is a context-free grammar for C++ statements.",
        "tokens": [
          50464,
          583,
          291,
          393,
          536,
          510,
          11,
          341,
          307,
          257,
          4319,
          12,
          10792,
          22317,
          337,
          383,
          25472,
          12363,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2050,
        "id": 578,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2046,
        "temperature": 0,
        "text": " So, you can see what is a statement could be if expression and statement.",
        "tokens": [
          50714,
          407,
          11,
          291,
          393,
          536,
          437,
          307,
          257,
          5629,
          727,
          312,
          498,
          6114,
          293,
          5629,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2052,
        "id": 579,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2050,
        "temperature": 0,
        "text": " Or if expression statement else statement.",
        "tokens": [
          50914,
          1610,
          498,
          6114,
          5629,
          1646,
          5629,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2053,
        "id": 580,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2052,
        "temperature": 0,
        "text": " What is a statement?",
        "tokens": [
          51014,
          708,
          307,
          257,
          5629,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2056,
        "id": 581,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2053,
        "temperature": 0,
        "text": " A statement could be do statement while expression.",
        "tokens": [
          51064,
          316,
          5629,
          727,
          312,
          360,
          5629,
          1339,
          6114,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2062,
        "id": 582,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2056,
        "temperature": 0,
        "text": " So, this idea of fitting things in to a grammar, a defined structure.",
        "tokens": [
          51214,
          407,
          11,
          341,
          1558,
          295,
          15669,
          721,
          294,
          281,
          257,
          22317,
          11,
          257,
          7642,
          3877,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18285880770002091,
        "compression_ratio": 1.9255813953488372,
        "end": 2065,
        "id": 583,
        "no_speech_prob": 0.013636570423841476,
        "seek": 203900,
        "start": 2062,
        "temperature": 0,
        "text": " So, let's think of, okay.",
        "tokens": [
          51514,
          407,
          11,
          718,
          311,
          519,
          295,
          11,
          1392,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2069,
        "id": 584,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2065,
        "temperature": 0,
        "text": " And so, there are a variety of seminal work on grammars.",
        "tokens": [
          50364,
          400,
          370,
          11,
          456,
          366,
          257,
          5673,
          295,
          4361,
          2071,
          589,
          322,
          17570,
          685,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2073,
        "id": 585,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2069,
        "temperature": 0,
        "text": " You can read, I'll link to the paper by Noam Chomsky.",
        "tokens": [
          50564,
          509,
          393,
          1401,
          11,
          286,
          603,
          2113,
          281,
          264,
          3035,
          538,
          883,
          335,
          761,
          4785,
          4133,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2076,
        "id": 586,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2073,
        "temperature": 0,
        "text": " Where you can think of grammars divided into four categories.",
        "tokens": [
          50764,
          2305,
          291,
          393,
          519,
          295,
          17570,
          685,
          6666,
          666,
          1451,
          10479,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2081,
        "id": 587,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2076,
        "temperature": 0,
        "text": " So, there's this kind of unrestricted grammar, type 0, which is just basically everything.",
        "tokens": [
          50914,
          407,
          11,
          456,
          311,
          341,
          733,
          295,
          35103,
          3740,
          292,
          22317,
          11,
          2010,
          1958,
          11,
          597,
          307,
          445,
          1936,
          1203,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2085,
        "id": 588,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2081,
        "temperature": 0,
        "text": " English language is a highly sophisticated, complex grammar.",
        "tokens": [
          51164,
          3669,
          2856,
          307,
          257,
          5405,
          16950,
          11,
          3997,
          22317,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2091,
        "id": 589,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2085,
        "temperature": 0,
        "text": " But there are also context-sensitive grammars, which I think will actually make a lot more sense.",
        "tokens": [
          51364,
          583,
          456,
          366,
          611,
          4319,
          12,
          82,
          34465,
          17570,
          685,
          11,
          597,
          286,
          519,
          486,
          767,
          652,
          257,
          688,
          544,
          2020,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22765884091777186,
        "compression_ratio": 1.6433566433566433,
        "end": 2093,
        "id": 590,
        "no_speech_prob": 0.1037181094288826,
        "seek": 206500,
        "start": 2091,
        "temperature": 0,
        "text": " Once I describe what a context-free grammar is.",
        "tokens": [
          51664,
          3443,
          286,
          6786,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17917183467320033,
        "compression_ratio": 1.6877828054298643,
        "end": 2096,
        "id": 591,
        "no_speech_prob": 0.13113591074943542,
        "seek": 209300,
        "start": 2093,
        "temperature": 0,
        "text": " So, there's a bunch of different kinds of grammars.",
        "tokens": [
          50364,
          407,
          11,
          456,
          311,
          257,
          3840,
          295,
          819,
          3685,
          295,
          17570,
          685,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17917183467320033,
        "compression_ratio": 1.6877828054298643,
        "end": 2099,
        "id": 592,
        "no_speech_prob": 0.13113591074943542,
        "seek": 209300,
        "start": 2096,
        "temperature": 0,
        "text": " And I encourage you to explore this hierarchy of grammars.",
        "tokens": [
          50514,
          400,
          286,
          5373,
          291,
          281,
          6839,
          341,
          22333,
          295,
          17570,
          685,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17917183467320033,
        "compression_ratio": 1.6877828054298643,
        "end": 2103,
        "id": 593,
        "no_speech_prob": 0.13113591074943542,
        "seek": 209300,
        "start": 2099,
        "temperature": 0,
        "text": " And think more deeply about grammars beyond what I'm going to do in these videos.",
        "tokens": [
          50664,
          400,
          519,
          544,
          8760,
          466,
          17570,
          685,
          4399,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          613,
          2145,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17917183467320033,
        "compression_ratio": 1.6877828054298643,
        "end": 2112,
        "id": 594,
        "no_speech_prob": 0.13113591074943542,
        "seek": 209300,
        "start": 2103,
        "temperature": 0,
        "text": " But the classic grammar that can be used to create generative text is a context-free grammar.",
        "tokens": [
          50864,
          583,
          264,
          7230,
          22317,
          300,
          393,
          312,
          1143,
          281,
          1884,
          1337,
          1166,
          2487,
          307,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17917183467320033,
        "compression_ratio": 1.6877828054298643,
        "end": 2116,
        "id": 595,
        "no_speech_prob": 0.13113591074943542,
        "seek": 209300,
        "start": 2112,
        "temperature": 0,
        "text": " So, let me talk to you a little bit about, in general, what a context-free grammar is.",
        "tokens": [
          51314,
          407,
          11,
          718,
          385,
          751,
          281,
          291,
          257,
          707,
          857,
          466,
          11,
          294,
          2674,
          11,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2123,
        "id": 596,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2117,
        "temperature": 0,
        "text": " And then I'll show you some tools that allow you to generate with context-free grammars.",
        "tokens": [
          50414,
          400,
          550,
          286,
          603,
          855,
          291,
          512,
          3873,
          300,
          2089,
          291,
          281,
          8460,
          365,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2125,
        "id": 597,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2123,
        "temperature": 0,
        "text": " And then I'll just start to write in code.",
        "tokens": [
          50714,
          400,
          550,
          286,
          603,
          445,
          722,
          281,
          2464,
          294,
          3089,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2131,
        "id": 598,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2125,
        "temperature": 0,
        "text": " So, context-free grammar is made up by, I'm going to say, we can use different terms for these things.",
        "tokens": [
          50814,
          407,
          11,
          4319,
          12,
          10792,
          22317,
          307,
          1027,
          493,
          538,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          321,
          393,
          764,
          819,
          2115,
          337,
          613,
          721,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2132,
        "id": 599,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2131,
        "temperature": 0,
        "text": " But there's an alphabet.",
        "tokens": [
          51114,
          583,
          456,
          311,
          364,
          23339,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2136,
        "id": 600,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2132,
        "temperature": 0,
        "text": " Or there's a set of valid elements in the language.",
        "tokens": [
          51164,
          1610,
          456,
          311,
          257,
          992,
          295,
          7363,
          4959,
          294,
          264,
          2856,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2141,
        "id": 601,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2136,
        "temperature": 0,
        "text": " Like, you can only say, the, cat, meow, and puppy.",
        "tokens": [
          51364,
          1743,
          11,
          291,
          393,
          787,
          584,
          11,
          264,
          11,
          3857,
          11,
          45132,
          11,
          293,
          18196,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22876976676609206,
        "compression_ratio": 1.6556016597510372,
        "end": 2144,
        "id": 602,
        "no_speech_prob": 0.2658098042011261,
        "seek": 211600,
        "start": 2141,
        "temperature": 0,
        "text": " That's the alphabet of the language.",
        "tokens": [
          51614,
          663,
          311,
          264,
          23339,
          295,
          264,
          2856,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2145,
        "id": 603,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2144,
        "temperature": 0,
        "text": " It only has four possible words.",
        "tokens": [
          50364,
          467,
          787,
          575,
          1451,
          1944,
          2283,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2146,
        "id": 604,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2145,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50414,
          1779,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2154,
        "id": 605,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2146,
        "temperature": 0,
        "text": " There are also, in a grammar, some of these are what are known as terminal.",
        "tokens": [
          50464,
          821,
          366,
          611,
          11,
          294,
          257,
          22317,
          11,
          512,
          295,
          613,
          366,
          437,
          366,
          2570,
          382,
          14709,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2159,
        "id": 606,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2154,
        "temperature": 0,
        "text": " And some of these are known as non-terminal.",
        "tokens": [
          50864,
          400,
          512,
          295,
          613,
          366,
          2570,
          382,
          2107,
          12,
          7039,
          2071,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2164,
        "id": 607,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2159,
        "temperature": 0,
        "text": " So, the alphabet is terminal and non-terminal.",
        "tokens": [
          51114,
          407,
          11,
          264,
          23339,
          307,
          14709,
          293,
          2107,
          12,
          7039,
          2071,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2165,
        "id": 608,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2164,
        "temperature": 0,
        "text": " Now, this is probably a bad idea.",
        "tokens": [
          51364,
          823,
          11,
          341,
          307,
          1391,
          257,
          1578,
          1558,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17992121108034823,
        "compression_ratio": 1.6080402010050252,
        "end": 2170,
        "id": 609,
        "no_speech_prob": 0.027167879045009613,
        "seek": 214400,
        "start": 2165,
        "temperature": 0,
        "text": " But I'm going to just use, like, sort of generic characters for this alphabet.",
        "tokens": [
          51414,
          583,
          286,
          478,
          516,
          281,
          445,
          764,
          11,
          411,
          11,
          1333,
          295,
          19577,
          4342,
          337,
          341,
          23339,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2176,
        "id": 610,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2170,
        "temperature": 0,
        "text": " So, let's pretend that we have an alphabet which is A, B, and C.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          11865,
          300,
          321,
          362,
          364,
          23339,
          597,
          307,
          316,
          11,
          363,
          11,
          293,
          383,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2178,
        "id": 611,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2176,
        "temperature": 0,
        "text": " And those are, this is the alphabet.",
        "tokens": [
          50664,
          400,
          729,
          366,
          11,
          341,
          307,
          264,
          23339,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2183,
        "id": 612,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2178,
        "temperature": 0,
        "text": " And these are non-terminal characters.",
        "tokens": [
          50764,
          400,
          613,
          366,
          2107,
          12,
          7039,
          2071,
          4342,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2186,
        "id": 613,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2183,
        "temperature": 0,
        "text": " I don't know what I put these little quotes around them for, for no particular reason.",
        "tokens": [
          51014,
          286,
          500,
          380,
          458,
          437,
          286,
          829,
          613,
          707,
          19963,
          926,
          552,
          337,
          11,
          337,
          572,
          1729,
          1778,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2189,
        "id": 614,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2186,
        "temperature": 0,
        "text": " And then we also have terminal characters.",
        "tokens": [
          51164,
          400,
          550,
          321,
          611,
          362,
          14709,
          4342,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2193,
        "id": 615,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2189,
        "temperature": 0,
        "text": " And those will be D, E, and F.",
        "tokens": [
          51314,
          400,
          729,
          486,
          312,
          413,
          11,
          462,
          11,
          293,
          479,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2194,
        "id": 616,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2193,
        "temperature": 0,
        "text": " Okay?",
        "tokens": [
          51514,
          1033,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1662755106009689,
        "compression_ratio": 1.693069306930693,
        "end": 2195,
        "id": 617,
        "no_speech_prob": 0.09669633954763412,
        "seek": 217000,
        "start": 2194,
        "temperature": 0,
        "text": " So, these are terminal characters.",
        "tokens": [
          51564,
          407,
          11,
          613,
          366,
          14709,
          4342,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21714011105624112,
        "compression_ratio": 1.6346153846153846,
        "end": 2202,
        "id": 618,
        "no_speech_prob": 0.3775121569633484,
        "seek": 219500,
        "start": 2195,
        "temperature": 0,
        "text": " Now, the grammar will also have production rules.",
        "tokens": [
          50364,
          823,
          11,
          264,
          22317,
          486,
          611,
          362,
          4265,
          4474,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21714011105624112,
        "compression_ratio": 1.6346153846153846,
        "end": 2208,
        "id": 619,
        "no_speech_prob": 0.3775121569633484,
        "seek": 219500,
        "start": 2202,
        "temperature": 0,
        "text": " A production rule is a rule, and these are also referred to as, like, replacement rules.",
        "tokens": [
          50714,
          316,
          4265,
          4978,
          307,
          257,
          4978,
          11,
          293,
          613,
          366,
          611,
          10839,
          281,
          382,
          11,
          411,
          11,
          14419,
          4474,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21714011105624112,
        "compression_ratio": 1.6346153846153846,
        "end": 2218,
        "id": 620,
        "no_speech_prob": 0.3775121569633484,
        "seek": 219500,
        "start": 2208,
        "temperature": 0,
        "text": " So, a production rule is a rule by which, if you have a certain character, like A, what does that get replaced with?",
        "tokens": [
          51014,
          407,
          11,
          257,
          4265,
          4978,
          307,
          257,
          4978,
          538,
          597,
          11,
          498,
          291,
          362,
          257,
          1629,
          2517,
          11,
          411,
          316,
          11,
          437,
          775,
          300,
          483,
          10772,
          365,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2224,
        "id": 621,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2219,
        "temperature": 0,
        "text": " Let's say A gets replaced with B, D, E.",
        "tokens": [
          50414,
          961,
          311,
          584,
          316,
          2170,
          10772,
          365,
          363,
          11,
          413,
          11,
          462,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2229,
        "id": 622,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2224,
        "temperature": 0,
        "text": " And B gets replaced with A, F.",
        "tokens": [
          50664,
          400,
          363,
          2170,
          10772,
          365,
          316,
          11,
          479,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2234,
        "id": 623,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2229,
        "temperature": 0,
        "text": " And C gets replaced with A.",
        "tokens": [
          50914,
          400,
          383,
          2170,
          10772,
          365,
          316,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2238,
        "id": 624,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2234,
        "temperature": 0,
        "text": " So, this now could make up the entire grammar.",
        "tokens": [
          51164,
          407,
          11,
          341,
          586,
          727,
          652,
          493,
          264,
          2302,
          22317,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2239,
        "id": 625,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2238,
        "temperature": 0,
        "text": " And I kind of hate what I'm doing here.",
        "tokens": [
          51364,
          400,
          286,
          733,
          295,
          4700,
          437,
          286,
          478,
          884,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2240,
        "id": 626,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2239,
        "temperature": 0,
        "text": " And I'm doing it anyway.",
        "tokens": [
          51414,
          400,
          286,
          478,
          884,
          309,
          4033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2244,
        "id": 627,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2240,
        "temperature": 0,
        "text": " And I knew this morning when I was having the same discussion that I shouldn't do it this way.",
        "tokens": [
          51464,
          400,
          286,
          2586,
          341,
          2446,
          562,
          286,
          390,
          1419,
          264,
          912,
          5017,
          300,
          286,
          4659,
          380,
          360,
          309,
          341,
          636,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14139083393833093,
        "compression_ratio": 1.6902654867256637,
        "end": 2247,
        "id": 628,
        "no_speech_prob": 0.07585398107767105,
        "seek": 221800,
        "start": 2244,
        "temperature": 0,
        "text": " Because I think this makes so much more sense if I have content here, right?",
        "tokens": [
          51664,
          1436,
          286,
          519,
          341,
          1669,
          370,
          709,
          544,
          2020,
          498,
          286,
          362,
          2701,
          510,
          11,
          558,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2250,
        "id": 629,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2247,
        "temperature": 0,
        "text": " But let's look at it, let's just think about it in the abstract sense.",
        "tokens": [
          50364,
          583,
          718,
          311,
          574,
          412,
          309,
          11,
          718,
          311,
          445,
          519,
          466,
          309,
          294,
          264,
          12649,
          2020,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2259,
        "id": 630,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2250,
        "temperature": 0,
        "text": " And as I start to go through code examples, we'll get to, well, I think it might, if this is confusing to you, when I have some actual content, it might click in for you.",
        "tokens": [
          50514,
          400,
          382,
          286,
          722,
          281,
          352,
          807,
          3089,
          5110,
          11,
          321,
          603,
          483,
          281,
          11,
          731,
          11,
          286,
          519,
          309,
          1062,
          11,
          498,
          341,
          307,
          13181,
          281,
          291,
          11,
          562,
          286,
          362,
          512,
          3539,
          2701,
          11,
          309,
          1062,
          2052,
          294,
          337,
          291,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2260,
        "id": 631,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2259,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2262,
        "id": 632,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2260,
        "temperature": 0,
        "text": " So, these are the production rules.",
        "tokens": [
          51014,
          407,
          11,
          613,
          366,
          264,
          4265,
          4474,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2267,
        "id": 633,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2262,
        "temperature": 0,
        "text": " So, now what I need is, this is sometimes referred to as an axiom or maybe a starting sentence.",
        "tokens": [
          51114,
          407,
          11,
          586,
          437,
          286,
          643,
          307,
          11,
          341,
          307,
          2171,
          10839,
          281,
          382,
          364,
          6360,
          72,
          298,
          420,
          1310,
          257,
          2891,
          8174,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2270,
        "id": 634,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2267,
        "temperature": 0,
        "text": " But what I, I'm going to call it an axiom just to be formal here.",
        "tokens": [
          51364,
          583,
          437,
          286,
          11,
          286,
          478,
          516,
          281,
          818,
          309,
          364,
          6360,
          72,
          298,
          445,
          281,
          312,
          9860,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2271,
        "id": 635,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2270,
        "temperature": 0,
        "text": " What I need is an axiom.",
        "tokens": [
          51514,
          708,
          286,
          643,
          307,
          364,
          6360,
          72,
          298,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16516717274983725,
        "compression_ratio": 1.7222222222222223,
        "end": 2273,
        "id": 636,
        "no_speech_prob": 0.004468277562409639,
        "seek": 224700,
        "start": 2271,
        "temperature": 0,
        "text": " So, what do I start with?",
        "tokens": [
          51564,
          407,
          11,
          437,
          360,
          286,
          722,
          365,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2280,
        "id": 637,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2273,
        "temperature": 0,
        "text": " So, let's say I start with the axiom AC.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          584,
          286,
          722,
          365,
          264,
          6360,
          72,
          298,
          8157,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2286,
        "id": 638,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2280,
        "temperature": 0,
        "text": " So, what that means is I start with AC and then I start to go through my replacement rules.",
        "tokens": [
          50714,
          407,
          11,
          437,
          300,
          1355,
          307,
          286,
          722,
          365,
          8157,
          293,
          550,
          286,
          722,
          281,
          352,
          807,
          452,
          14419,
          4474,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2289,
        "id": 639,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2286,
        "temperature": 0,
        "text": " What am I doing here?",
        "tokens": [
          51014,
          708,
          669,
          286,
          884,
          510,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2291,
        "id": 640,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2289,
        "temperature": 0,
        "text": " A becomes BDE.",
        "tokens": [
          51164,
          316,
          3643,
          363,
          22296,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2294,
        "id": 641,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2291,
        "temperature": 0,
        "text": " So, this becomes BDE.",
        "tokens": [
          51264,
          407,
          11,
          341,
          3643,
          363,
          22296,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2296,
        "id": 642,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2294,
        "temperature": 0,
        "text": " And C becomes A.",
        "tokens": [
          51414,
          400,
          383,
          3643,
          316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1826986148033613,
        "compression_ratio": 1.4903225806451612,
        "end": 2299,
        "id": 643,
        "no_speech_prob": 0.05665166676044464,
        "seek": 227300,
        "start": 2296,
        "temperature": 0,
        "text": " Now, we do this again.",
        "tokens": [
          51514,
          823,
          11,
          321,
          360,
          341,
          797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2302,
        "id": 644,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2299,
        "temperature": 0,
        "text": " B becomes AF.",
        "tokens": [
          50364,
          363,
          3643,
          20389,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2306,
        "id": 645,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2302,
        "temperature": 0,
        "text": " And D is terminal, so D stays as D.",
        "tokens": [
          50514,
          400,
          413,
          307,
          14709,
          11,
          370,
          413,
          10834,
          382,
          413,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2308,
        "id": 646,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2306,
        "temperature": 0,
        "text": " E is terminal, so E stays as E.",
        "tokens": [
          50714,
          462,
          307,
          14709,
          11,
          370,
          462,
          10834,
          382,
          462,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2310,
        "id": 647,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2308,
        "temperature": 0,
        "text": " And A becomes what?",
        "tokens": [
          50814,
          400,
          316,
          3643,
          437,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2313,
        "id": 648,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2310,
        "temperature": 0,
        "text": " BDE.",
        "tokens": [
          50914,
          363,
          22296,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2315,
        "id": 649,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2313,
        "temperature": 0,
        "text": " So, I could keep going.",
        "tokens": [
          51064,
          407,
          11,
          286,
          727,
          1066,
          516,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1486272368320199,
        "compression_ratio": 1.5146198830409356,
        "end": 2327,
        "id": 650,
        "no_speech_prob": 0.16026104986667633,
        "seek": 229900,
        "start": 2315,
        "temperature": 0,
        "text": " Now, I didn't do this very smartly because my non-terminal characters all get replaced with something that is also non-terminal.",
        "tokens": [
          51164,
          823,
          11,
          286,
          994,
          380,
          360,
          341,
          588,
          4069,
          356,
          570,
          452,
          2107,
          12,
          7039,
          2071,
          4342,
          439,
          483,
          10772,
          365,
          746,
          300,
          307,
          611,
          2107,
          12,
          7039,
          2071,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17799369148586108,
        "compression_ratio": 1.6886446886446886,
        "end": 2331,
        "id": 651,
        "no_speech_prob": 0.05419479310512543,
        "seek": 232700,
        "start": 2327,
        "temperature": 0,
        "text": " So, this is kind of, this way, this is known as an expansion.",
        "tokens": [
          50364,
          407,
          11,
          341,
          307,
          733,
          295,
          11,
          341,
          636,
          11,
          341,
          307,
          2570,
          382,
          364,
          11260,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17799369148586108,
        "compression_ratio": 1.6886446886446886,
        "end": 2336,
        "id": 652,
        "no_speech_prob": 0.05419479310512543,
        "seek": 232700,
        "start": 2331,
        "temperature": 0,
        "text": " I'm expanding out the grammar by iteratively running these replacement rules over and over again.",
        "tokens": [
          50564,
          286,
          478,
          14702,
          484,
          264,
          22317,
          538,
          17138,
          19020,
          2614,
          613,
          14419,
          4474,
          670,
          293,
          670,
          797,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17799369148586108,
        "compression_ratio": 1.6886446886446886,
        "end": 2341,
        "id": 653,
        "no_speech_prob": 0.05419479310512543,
        "seek": 232700,
        "start": 2336,
        "temperature": 0,
        "text": " And when we write the code for this, you'll see this happens with this fancy thing called a recursive algorithm.",
        "tokens": [
          50814,
          400,
          562,
          321,
          2464,
          264,
          3089,
          337,
          341,
          11,
          291,
          603,
          536,
          341,
          2314,
          365,
          341,
          10247,
          551,
          1219,
          257,
          20560,
          488,
          9284,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17799369148586108,
        "compression_ratio": 1.6886446886446886,
        "end": 2348,
        "id": 654,
        "no_speech_prob": 0.05419479310512543,
        "seek": 232700,
        "start": 2341,
        "temperature": 0,
        "text": " But you can see here that this is going to go until infinity.",
        "tokens": [
          51064,
          583,
          291,
          393,
          536,
          510,
          300,
          341,
          307,
          516,
          281,
          352,
          1826,
          13202,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17799369148586108,
        "compression_ratio": 1.6886446886446886,
        "end": 2356,
        "id": 655,
        "no_speech_prob": 0.05419479310512543,
        "seek": 232700,
        "start": 2348,
        "temperature": 0,
        "text": " But if I were to do this in a slightly different way, for example, I'm going to show you a grammar created by Allison Parrish.",
        "tokens": [
          51414,
          583,
          498,
          286,
          645,
          281,
          360,
          341,
          294,
          257,
          4748,
          819,
          636,
          11,
          337,
          1365,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          257,
          22317,
          2942,
          538,
          32638,
          47890,
          742,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19361759895502134,
        "compression_ratio": 1.6028708133971292,
        "end": 2363,
        "id": 656,
        "no_speech_prob": 0.008847189135849476,
        "seek": 235600,
        "start": 2356,
        "temperature": 0,
        "text": " For a class that she teaches called Reading and Writing Electronic Text.",
        "tokens": [
          50364,
          1171,
          257,
          1508,
          300,
          750,
          16876,
          1219,
          29766,
          293,
          32774,
          46921,
          18643,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19361759895502134,
        "compression_ratio": 1.6028708133971292,
        "end": 2365,
        "id": 657,
        "no_speech_prob": 0.008847189135849476,
        "seek": 235600,
        "start": 2363,
        "temperature": 0,
        "text": " I encourage you to check out those examples.",
        "tokens": [
          50714,
          286,
          5373,
          291,
          281,
          1520,
          484,
          729,
          5110,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19361759895502134,
        "compression_ratio": 1.6028708133971292,
        "end": 2368,
        "id": 658,
        "no_speech_prob": 0.008847189135849476,
        "seek": 235600,
        "start": 2365,
        "temperature": 0,
        "text": " A lot of my code is ported from her code in Python.",
        "tokens": [
          50814,
          316,
          688,
          295,
          452,
          3089,
          307,
          2436,
          292,
          490,
          720,
          3089,
          294,
          15329,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19361759895502134,
        "compression_ratio": 1.6028708133971292,
        "end": 2375,
        "id": 659,
        "no_speech_prob": 0.008847189135849476,
        "seek": 235600,
        "start": 2368,
        "temperature": 0,
        "text": " And you can see here, here are the sets of production rules.",
        "tokens": [
          50964,
          400,
          291,
          393,
          536,
          510,
          11,
          510,
          366,
          264,
          6352,
          295,
          4265,
          4474,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19361759895502134,
        "compression_ratio": 1.6028708133971292,
        "end": 2379,
        "id": 660,
        "no_speech_prob": 0.008847189135849476,
        "seek": 235600,
        "start": 2375,
        "temperature": 0,
        "text": " Sentence becomes noun phrase, verb phrase.",
        "tokens": [
          51314,
          23652,
          655,
          3643,
          23307,
          9535,
          11,
          9595,
          9535,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19361759895502134,
        "compression_ratio": 1.6028708133971292,
        "end": 2383,
        "id": 661,
        "no_speech_prob": 0.008847189135849476,
        "seek": 235600,
        "start": 2379,
        "temperature": 0,
        "text": " Or a sentence becomes interjection, noun phrase, verb phrase.",
        "tokens": [
          51514,
          1610,
          257,
          8174,
          3643,
          46787,
          313,
          11,
          23307,
          9535,
          11,
          9595,
          9535,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2387,
        "id": 662,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2383,
        "temperature": 0,
        "text": " A noun phrase becomes determiner noun or determiner noun that verb phrase.",
        "tokens": [
          50364,
          316,
          23307,
          9535,
          3643,
          3618,
          4564,
          23307,
          420,
          3618,
          4564,
          23307,
          300,
          9595,
          9535,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2395,
        "id": 663,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2387,
        "temperature": 0,
        "text": " So, you can see these are all the possible, and these are all non-terminal elements of the grammar.",
        "tokens": [
          50564,
          407,
          11,
          291,
          393,
          536,
          613,
          366,
          439,
          264,
          1944,
          11,
          293,
          613,
          366,
          439,
          2107,
          12,
          7039,
          2071,
          4959,
          295,
          264,
          22317,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2399,
        "id": 664,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2395,
        "temperature": 0,
        "text": " And then here you can see, here are some terminal elements.",
        "tokens": [
          50964,
          400,
          550,
          510,
          291,
          393,
          536,
          11,
          510,
          366,
          512,
          14709,
          4959,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2403,
        "id": 665,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2399,
        "temperature": 0,
        "text": " For example, an interjection could be oh, or my, or wow, or damn.",
        "tokens": [
          51164,
          1171,
          1365,
          11,
          364,
          46787,
          313,
          727,
          312,
          1954,
          11,
          420,
          452,
          11,
          420,
          6076,
          11,
          420,
          8151,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2406,
        "id": 666,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2403,
        "temperature": 0,
        "text": " Sort of like a curse on my YouTube stream.",
        "tokens": [
          51364,
          26149,
          295,
          411,
          257,
          17139,
          322,
          452,
          3088,
          4309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2409,
        "id": 667,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2406,
        "temperature": 0,
        "text": " Did I just call it my YouTube stream? That's also a little bit weird.",
        "tokens": [
          51514,
          2589,
          286,
          445,
          818,
          309,
          452,
          3088,
          4309,
          30,
          663,
          311,
          611,
          257,
          707,
          857,
          3657,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2221781005859375,
        "compression_ratio": 1.7738095238095237,
        "end": 2411,
        "id": 668,
        "no_speech_prob": 0.07695694267749786,
        "seek": 238300,
        "start": 2409,
        "temperature": 0,
        "text": " Determiner is this, that, or the.",
        "tokens": [
          51664,
          4237,
          966,
          4564,
          307,
          341,
          11,
          300,
          11,
          420,
          264,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2414,
        "id": 669,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2411,
        "temperature": 0,
        "text": " So, if I were to just go to the example, I'm going to not bother looking at the code.",
        "tokens": [
          50364,
          407,
          11,
          498,
          286,
          645,
          281,
          445,
          352,
          281,
          264,
          1365,
          11,
          286,
          478,
          516,
          281,
          406,
          8677,
          1237,
          412,
          264,
          3089,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2420,
        "id": 670,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2414,
        "temperature": 0,
        "text": " But we can see here, if I go to week 8, context-free grammar reader.",
        "tokens": [
          50514,
          583,
          321,
          393,
          536,
          510,
          11,
          498,
          286,
          352,
          281,
          1243,
          1649,
          11,
          4319,
          12,
          10792,
          22317,
          15149,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2424,
        "id": 671,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2420,
        "temperature": 0,
        "text": " This example generates, is this the right one that I was looking at? Yes.",
        "tokens": [
          50814,
          639,
          1365,
          23815,
          11,
          307,
          341,
          264,
          558,
          472,
          300,
          286,
          390,
          1237,
          412,
          30,
          1079,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2427,
        "id": 672,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2424,
        "temperature": 0,
        "text": " This example generates sentences based on that grammar.",
        "tokens": [
          51014,
          639,
          1365,
          23815,
          16579,
          2361,
          322,
          300,
          22317,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2429,
        "id": 673,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2427,
        "temperature": 0,
        "text": " Let me move this a little bit over and zoom in here.",
        "tokens": [
          51164,
          961,
          385,
          1286,
          341,
          257,
          707,
          857,
          670,
          293,
          8863,
          294,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2432,
        "id": 674,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2429,
        "temperature": 0,
        "text": " And you can see, wow, the bald restaurant sneezes.",
        "tokens": [
          51264,
          400,
          291,
          393,
          536,
          11,
          6076,
          11,
          264,
          21096,
          6383,
          49299,
          279,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2435,
        "id": 675,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2432,
        "temperature": 0,
        "text": " My, the smug corsage computes that overstaffed corsage.",
        "tokens": [
          51414,
          1222,
          11,
          264,
          899,
          697,
          46511,
          609,
          715,
          1819,
          300,
          48834,
          2518,
          292,
          46511,
          609,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1830448930280922,
        "compression_ratio": 1.7402135231316727,
        "end": 2439,
        "id": 676,
        "no_speech_prob": 0.2719849944114685,
        "seek": 241100,
        "start": 2435,
        "temperature": 0,
        "text": " This corsage interprets the blue restaurant.",
        "tokens": [
          51564,
          639,
          46511,
          609,
          17489,
          1373,
          264,
          3344,
          6383,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2443,
        "id": 677,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2439,
        "temperature": 0,
        "text": " So, there's a lot of corsages in this particular generative system.",
        "tokens": [
          50364,
          407,
          11,
          456,
          311,
          257,
          688,
          295,
          46511,
          1660,
          294,
          341,
          1729,
          1337,
          1166,
          1185,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2449,
        "id": 678,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2443,
        "temperature": 0,
        "text": " So, it's interestingly enough, typically, what you might use a grammar for,",
        "tokens": [
          50564,
          407,
          11,
          309,
          311,
          25873,
          1547,
          11,
          5850,
          11,
          437,
          291,
          1062,
          764,
          257,
          22317,
          337,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2453,
        "id": 679,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2449,
        "temperature": 0,
        "text": " I'm over here now, and I kind of want to leave this because I think I want to refer to this later.",
        "tokens": [
          50864,
          286,
          478,
          670,
          510,
          586,
          11,
          293,
          286,
          733,
          295,
          528,
          281,
          1856,
          341,
          570,
          286,
          519,
          286,
          528,
          281,
          2864,
          281,
          341,
          1780,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2457,
        "id": 680,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2453,
        "temperature": 0,
        "text": " What you might use a grammar for is you have an existing sentence.",
        "tokens": [
          51064,
          708,
          291,
          1062,
          764,
          257,
          22317,
          337,
          307,
          291,
          362,
          364,
          6741,
          8174,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2459,
        "id": 681,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2457,
        "temperature": 0,
        "text": " Maybe you have a bit of code.",
        "tokens": [
          51264,
          2704,
          291,
          362,
          257,
          857,
          295,
          3089,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2463,
        "id": 682,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2459,
        "temperature": 0,
        "text": " Like, for example, what if I go to a code editor.",
        "tokens": [
          51364,
          1743,
          11,
          337,
          1365,
          11,
          437,
          498,
          286,
          352,
          281,
          257,
          3089,
          9839,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2466,
        "id": 683,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2463,
        "temperature": 0,
        "text": " I'm jumping around like a crazy person here.",
        "tokens": [
          51564,
          286,
          478,
          11233,
          926,
          411,
          257,
          3219,
          954,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16462574148536624,
        "compression_ratio": 1.6797153024911031,
        "end": 2468,
        "id": 684,
        "no_speech_prob": 0.00530175631865859,
        "seek": 243900,
        "start": 2466,
        "temperature": 0,
        "text": " Let's see if this works with CodePen.",
        "tokens": [
          51714,
          961,
          311,
          536,
          498,
          341,
          1985,
          365,
          15549,
          47,
          268,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2471,
        "id": 685,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2468,
        "temperature": 0,
        "text": " I'm going to go to CodePen, and I'm going to make a new pen,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          352,
          281,
          15549,
          47,
          268,
          11,
          293,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          3435,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2480,
        "id": 686,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2471,
        "temperature": 0,
        "text": " and I'm going to say something like, if for var i equals 0, let's make this bigger,",
        "tokens": [
          50514,
          293,
          286,
          478,
          516,
          281,
          584,
          746,
          411,
          11,
          498,
          337,
          1374,
          741,
          6915,
          1958,
          11,
          718,
          311,
          652,
          341,
          3801,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2485,
        "id": 687,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2480,
        "temperature": 0,
        "text": " i is less than i++.",
        "tokens": [
          50964,
          741,
          307,
          1570,
          813,
          741,
          25472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2488,
        "id": 688,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2485,
        "temperature": 0,
        "text": " Now, where's my JavaScript lintern?",
        "tokens": [
          51214,
          823,
          11,
          689,
          311,
          452,
          15778,
          287,
          5106,
          77,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2489,
        "id": 689,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2488,
        "temperature": 0,
        "text": " Ah, here we go. Here.",
        "tokens": [
          51364,
          2438,
          11,
          510,
          321,
          352,
          13,
          1692,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2491,
        "id": 690,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2489,
        "temperature": 0,
        "text": " Look at this, unexpected token.",
        "tokens": [
          51414,
          2053,
          412,
          341,
          11,
          13106,
          14862,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23117963473002115,
        "compression_ratio": 1.4702702702702704,
        "end": 2492,
        "id": 691,
        "no_speech_prob": 0.0025114358868449926,
        "seek": 246800,
        "start": 2491,
        "temperature": 0,
        "text": " So, look at this.",
        "tokens": [
          51514,
          407,
          11,
          574,
          412,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2500,
        "id": 692,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2492,
        "temperature": 0,
        "text": " How does the code environment understand that the semicolon is unexpected and shouldn't be there?",
        "tokens": [
          50364,
          1012,
          775,
          264,
          3089,
          2823,
          1223,
          300,
          264,
          27515,
          38780,
          307,
          13106,
          293,
          4659,
          380,
          312,
          456,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2504,
        "id": 693,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2500,
        "temperature": 0,
        "text": " So, normally, not normally, but one way of using a grammar,",
        "tokens": [
          50764,
          407,
          11,
          5646,
          11,
          406,
          5646,
          11,
          457,
          472,
          636,
          295,
          1228,
          257,
          22317,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2506,
        "id": 694,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2504,
        "temperature": 0,
        "text": " and in this case a context-free grammar,",
        "tokens": [
          50964,
          293,
          294,
          341,
          1389,
          257,
          4319,
          12,
          10792,
          22317,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2509,
        "id": 695,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2506,
        "temperature": 0,
        "text": " is to look at an existing sentence, like this block of code,",
        "tokens": [
          51064,
          307,
          281,
          574,
          412,
          364,
          6741,
          8174,
          11,
          411,
          341,
          3461,
          295,
          3089,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2512,
        "id": 696,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2509,
        "temperature": 0,
        "text": " and see if it fits, right?",
        "tokens": [
          51214,
          293,
          536,
          498,
          309,
          9001,
          11,
          558,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2513,
        "id": 697,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2512,
        "temperature": 0,
        "text": " The reverse.",
        "tokens": [
          51364,
          440,
          9943,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2516,
        "id": 698,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2513,
        "temperature": 0,
        "text": " See if it fits the structure of the grammar going in reverse.",
        "tokens": [
          51414,
          3008,
          498,
          309,
          9001,
          264,
          3877,
          295,
          264,
          22317,
          516,
          294,
          9943,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.203083172179105,
        "compression_ratio": 1.7008196721311475,
        "end": 2519,
        "id": 699,
        "no_speech_prob": 0.18009963631629944,
        "seek": 249200,
        "start": 2516,
        "temperature": 0,
        "text": " And if it doesn't, right, then there's an error like,",
        "tokens": [
          51564,
          400,
          498,
          309,
          1177,
          380,
          11,
          558,
          11,
          550,
          456,
          311,
          364,
          6713,
          411,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2521,
        "id": 700,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2519,
        "temperature": 0,
        "text": " oh, there's got to be something here.",
        "tokens": [
          50364,
          1954,
          11,
          456,
          311,
          658,
          281,
          312,
          746,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2524,
        "id": 701,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2521,
        "temperature": 0,
        "text": " Like, let's look at it without the parentheses.",
        "tokens": [
          50464,
          1743,
          11,
          718,
          311,
          574,
          412,
          309,
          1553,
          264,
          34153,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2527,
        "id": 702,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2524,
        "temperature": 0,
        "text": " We can see here, right, unexpected token.",
        "tokens": [
          50614,
          492,
          393,
          536,
          510,
          11,
          558,
          11,
          13106,
          14862,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2529,
        "id": 703,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2527,
        "temperature": 0,
        "text": " So, it's a lot of unexpected token.",
        "tokens": [
          50764,
          407,
          11,
          309,
          311,
          257,
          688,
          295,
          13106,
          14862,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2532,
        "id": 704,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2529,
        "temperature": 0,
        "text": " It's getting some new thing that doesn't fit, doesn't fit the grammar.",
        "tokens": [
          50864,
          467,
          311,
          1242,
          512,
          777,
          551,
          300,
          1177,
          380,
          3318,
          11,
          1177,
          380,
          3318,
          264,
          22317,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2536,
        "id": 705,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2532,
        "temperature": 0,
        "text": " So, this is one way that grammars are used to evaluate text,",
        "tokens": [
          51014,
          407,
          11,
          341,
          307,
          472,
          636,
          300,
          17570,
          685,
          366,
          1143,
          281,
          13059,
          2487,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2538,
        "id": 706,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2536,
        "temperature": 0,
        "text": " and that might be something you explore.",
        "tokens": [
          51214,
          293,
          300,
          1062,
          312,
          746,
          291,
          6839,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2541,
        "id": 707,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2538,
        "temperature": 0,
        "text": " But, what I'm exploring is the reverse, which is saying,",
        "tokens": [
          51314,
          583,
          11,
          437,
          286,
          478,
          12736,
          307,
          264,
          9943,
          11,
          597,
          307,
          1566,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20015062185434196,
        "compression_ratio": 1.7944664031620554,
        "end": 2545,
        "id": 708,
        "no_speech_prob": 0.239328995347023,
        "seek": 251900,
        "start": 2541,
        "temperature": 0,
        "text": " here is the grammar, start with a sentence, start with an s,",
        "tokens": [
          51464,
          510,
          307,
          264,
          22317,
          11,
          722,
          365,
          257,
          8174,
          11,
          722,
          365,
          364,
          262,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2550,
        "id": 709,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2546,
        "temperature": 0,
        "text": " turn that into either noun phrase, verb phrase, or interjection noun phrase,",
        "tokens": [
          50414,
          1261,
          300,
          666,
          2139,
          23307,
          9535,
          11,
          9595,
          9535,
          11,
          420,
          46787,
          313,
          23307,
          9535,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2552,
        "id": 710,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2550,
        "temperature": 0,
        "text": " verb phrase, and let's see what we get.",
        "tokens": [
          50614,
          9595,
          9535,
          11,
          293,
          718,
          311,
          536,
          437,
          321,
          483,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2555,
        "id": 711,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2552,
        "temperature": 0,
        "text": " Again, I showed this to you already, but let me make a new one.",
        "tokens": [
          50714,
          3764,
          11,
          286,
          4712,
          341,
          281,
          291,
          1217,
          11,
          457,
          718,
          385,
          652,
          257,
          777,
          472,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2560,
        "id": 712,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2555,
        "temperature": 0,
        "text": " And we can see that seagull, right, that is a noun phrase,",
        "tokens": [
          50864,
          400,
          321,
          393,
          536,
          300,
          369,
          559,
          858,
          11,
          558,
          11,
          300,
          307,
          257,
          23307,
          9535,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2566,
        "id": 713,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2560,
        "temperature": 0,
        "text": " determiner noun, that seagull, so I can see that that fits,",
        "tokens": [
          51114,
          3618,
          4564,
          23307,
          11,
          300,
          369,
          559,
          858,
          11,
          370,
          286,
          393,
          536,
          300,
          300,
          9001,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2571,
        "id": 714,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2566,
        "temperature": 0,
        "text": " that computes this, corsage, is a verb phrase, right,",
        "tokens": [
          51414,
          300,
          715,
          1819,
          341,
          11,
          46511,
          609,
          11,
          307,
          257,
          9595,
          9535,
          11,
          558,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.20724225448349776,
        "compression_ratio": 1.84037558685446,
        "end": 2573,
        "id": 715,
        "no_speech_prob": 0.34504538774490356,
        "seek": 254500,
        "start": 2571,
        "temperature": 0,
        "text": " which is, I probably ended up getting,",
        "tokens": [
          51664,
          597,
          307,
          11,
          286,
          1391,
          4590,
          493,
          1242,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2576,
        "id": 716,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2573,
        "temperature": 0,
        "text": " oh, you know what, that, it actually made the noun phrase,",
        "tokens": [
          50364,
          1954,
          11,
          291,
          458,
          437,
          11,
          300,
          11,
          309,
          767,
          1027,
          264,
          23307,
          9535,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2579,
        "id": 717,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2576,
        "temperature": 0,
        "text": " determiner noun, that, so you can see how this gets complicated, right?",
        "tokens": [
          50514,
          3618,
          4564,
          23307,
          11,
          300,
          11,
          370,
          291,
          393,
          536,
          577,
          341,
          2170,
          6179,
          11,
          558,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2581,
        "id": 718,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2579,
        "temperature": 0,
        "text": " I'm trying to, I could diagram and run it backwards,",
        "tokens": [
          50664,
          286,
          478,
          1382,
          281,
          11,
          286,
          727,
          10686,
          293,
          1190,
          309,
          12204,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2583,
        "id": 719,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2581,
        "temperature": 0,
        "text": " but the point is, I don't need to do that.",
        "tokens": [
          50764,
          457,
          264,
          935,
          307,
          11,
          286,
          500,
          380,
          643,
          281,
          360,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2585,
        "id": 720,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2583,
        "temperature": 0,
        "text": " All I need to do is write the grammar,",
        "tokens": [
          50864,
          1057,
          286,
          643,
          281,
          360,
          307,
          2464,
          264,
          22317,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2588,
        "id": 721,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2585,
        "temperature": 0,
        "text": " and then if I have a system that generates text, it happens.",
        "tokens": [
          50964,
          293,
          550,
          498,
          286,
          362,
          257,
          1185,
          300,
          23815,
          2487,
          11,
          309,
          2314,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2590,
        "id": 722,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2588,
        "temperature": 0,
        "text": " So, one of the nice things about working with this,",
        "tokens": [
          51114,
          407,
          11,
          472,
          295,
          264,
          1481,
          721,
          466,
          1364,
          365,
          341,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2593,
        "id": 723,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2590,
        "temperature": 0,
        "text": " and say you're going to do an exercise or try some playful experiment",
        "tokens": [
          51214,
          293,
          584,
          291,
          434,
          516,
          281,
          360,
          364,
          5380,
          420,
          853,
          512,
          30730,
          5120,
          51364
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2597,
        "id": 724,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2593,
        "temperature": 0,
        "text": " based on these videos that I'm making, is you can just write your grammar.",
        "tokens": [
          51364,
          2361,
          322,
          613,
          2145,
          300,
          286,
          478,
          1455,
          11,
          307,
          291,
          393,
          445,
          2464,
          428,
          22317,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2599,
        "id": 725,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2597,
        "temperature": 0,
        "text": " You don't need to write any code, potentially,",
        "tokens": [
          51564,
          509,
          500,
          380,
          643,
          281,
          2464,
          604,
          3089,
          11,
          7263,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1946367066482018,
        "compression_ratio": 1.75,
        "end": 2602,
        "id": 726,
        "no_speech_prob": 0.02556406706571579,
        "seek": 257300,
        "start": 2599,
        "temperature": 0,
        "text": " because there are a lot of existing systems that will read a grammar file",
        "tokens": [
          51664,
          570,
          456,
          366,
          257,
          688,
          295,
          6741,
          3652,
          300,
          486,
          1401,
          257,
          22317,
          3991,
          51814
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2604,
        "id": 727,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2602,
        "temperature": 0,
        "text": " and generate text based on it.",
        "tokens": [
          50364,
          293,
          8460,
          2487,
          2361,
          322,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2606,
        "id": 728,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2604,
        "temperature": 0,
        "text": " And so, let me give you an overview.",
        "tokens": [
          50464,
          400,
          370,
          11,
          718,
          385,
          976,
          291,
          364,
          12492,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2608,
        "id": 729,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2606,
        "temperature": 0,
        "text": " So, I'm going to show you three things.",
        "tokens": [
          50564,
          407,
          11,
          286,
          478,
          516,
          281,
          855,
          291,
          1045,
          721,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2612,
        "id": 730,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2608,
        "temperature": 0,
        "text": " The first thing I'm going to use is a grammar called Tracery,",
        "tokens": [
          50664,
          440,
          700,
          551,
          286,
          478,
          516,
          281,
          764,
          307,
          257,
          22317,
          1219,
          1765,
          326,
          2109,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2617,
        "id": 731,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2612,
        "temperature": 0,
        "text": " sorry, a story grammar generation system called Tracery for JavaScript,",
        "tokens": [
          50864,
          2597,
          11,
          257,
          1657,
          22317,
          5125,
          1185,
          1219,
          1765,
          326,
          2109,
          337,
          15778,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2621,
        "id": 732,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2617,
        "temperature": 0,
        "text": " written by Kate Compton at GalaxyKate here on GitHub,",
        "tokens": [
          51114,
          3720,
          538,
          16251,
          2432,
          21987,
          412,
          13520,
          42,
          473,
          510,
          322,
          23331,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2623,
        "id": 733,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2621,
        "temperature": 0,
        "text": " and you can see there's a syntax to it,",
        "tokens": [
          51314,
          293,
          291,
          393,
          536,
          456,
          311,
          257,
          28431,
          281,
          309,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2626,
        "id": 734,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2623,
        "temperature": 0,
        "text": " which I'll go over and talk about in the next video.",
        "tokens": [
          51414,
          597,
          286,
          603,
          352,
          670,
          293,
          751,
          466,
          294,
          264,
          958,
          960,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2628,
        "id": 735,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2626,
        "temperature": 0,
        "text": " There's some nice examples I'll just pull up.",
        "tokens": [
          51564,
          821,
          311,
          512,
          1481,
          5110,
          286,
          603,
          445,
          2235,
          493,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17871668759514303,
        "compression_ratio": 1.627177700348432,
        "end": 2630,
        "id": 736,
        "no_speech_prob": 0.036764755845069885,
        "seek": 260200,
        "start": 2628,
        "temperature": 0,
        "text": " This is one of my favorite ones.",
        "tokens": [
          51664,
          639,
          307,
          472,
          295,
          452,
          2954,
          2306,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2632,
        "id": 737,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2630,
        "temperature": 0,
        "text": " I don't know if this is going to...",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          516,
          281,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2635,
        "id": 738,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2632,
        "temperature": 0,
        "text": " This is called Interruption Junction.",
        "tokens": [
          50464,
          639,
          307,
          1219,
          5751,
          11266,
          8492,
          882,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2638,
        "id": 739,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2635,
        "temperature": 0,
        "text": " So, I don't... I encourage...",
        "tokens": [
          50614,
          407,
          11,
          286,
          500,
          380,
          485,
          286,
          5373,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2640,
        "id": 740,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2638,
        "temperature": 0,
        "text": " So, this is...",
        "tokens": [
          50764,
          407,
          11,
          341,
          307,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2642,
        "id": 741,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2640,
        "temperature": 0,
        "text": " Interruption Junction!",
        "tokens": [
          50864,
          5751,
          11266,
          8492,
          882,
          0,
          50964
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2644,
        "id": 742,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2642,
        "temperature": 0,
        "text": " I don't know if you guys can hear that, but...",
        "tokens": [
          50964,
          286,
          500,
          380,
          458,
          498,
          291,
          1074,
          393,
          1568,
          300,
          11,
          457,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2649,
        "id": 743,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2644,
        "temperature": 0,
        "text": " Oh, you can't, because I haven't piped the sound of this laptop in through the stream.",
        "tokens": [
          51064,
          876,
          11,
          291,
          393,
          380,
          11,
          570,
          286,
          2378,
          380,
          8489,
          292,
          264,
          1626,
          295,
          341,
          10732,
          294,
          807,
          264,
          4309,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2651,
        "id": 744,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2649,
        "temperature": 0,
        "text": " But I need to click, I need to click.",
        "tokens": [
          51314,
          583,
          286,
          643,
          281,
          2052,
          11,
          286,
          643,
          281,
          2052,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2654,
        "id": 745,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2651,
        "temperature": 0,
        "text": " So, you can see this is one of the things that's interesting",
        "tokens": [
          51414,
          407,
          11,
          291,
          393,
          536,
          341,
          307,
          472,
          295,
          264,
          721,
          300,
          311,
          1880,
          51564
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2656,
        "id": 746,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2654,
        "temperature": 0,
        "text": " about working with these generative systems,",
        "tokens": [
          51564,
          466,
          1364,
          365,
          613,
          1337,
          1166,
          3652,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21838482332901216,
        "compression_ratio": 1.7610294117647058,
        "end": 2659,
        "id": 747,
        "no_speech_prob": 0.06559644639492035,
        "seek": 263000,
        "start": 2656,
        "temperature": 0,
        "text": " whether you're doing a Markov chain or context-free grammar",
        "tokens": [
          51664,
          1968,
          291,
          434,
          884,
          257,
          3934,
          5179,
          5021,
          420,
          4319,
          12,
          10792,
          22317,
          51814
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2660,
        "id": 748,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2659,
        "temperature": 0,
        "text": " or combining them in some way,",
        "tokens": [
          50364,
          420,
          21928,
          552,
          294,
          512,
          636,
          11,
          50414
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2663,
        "id": 749,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2660,
        "temperature": 0,
        "text": " is really not just the algorithm and what it generates,",
        "tokens": [
          50414,
          307,
          534,
          406,
          445,
          264,
          9284,
          293,
          437,
          309,
          23815,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2666,
        "id": 750,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2663,
        "temperature": 0,
        "text": " but the context where you display those results.",
        "tokens": [
          50564,
          457,
          264,
          4319,
          689,
          291,
          4674,
          729,
          3542,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2670,
        "id": 751,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2666,
        "temperature": 0,
        "text": " And I think thinking about dialogue or an interactive animated story system,",
        "tokens": [
          50714,
          400,
          286,
          519,
          1953,
          466,
          10221,
          420,
          364,
          15141,
          18947,
          1657,
          1185,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2672,
        "id": 752,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2670,
        "temperature": 0,
        "text": " there's a lot of interesting possibilities there.",
        "tokens": [
          50914,
          456,
          311,
          257,
          688,
          295,
          1880,
          12178,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2674,
        "id": 753,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2672,
        "temperature": 0,
        "text": " And if you look through Tracery's...",
        "tokens": [
          51014,
          400,
          498,
          291,
          574,
          807,
          1765,
          326,
          2109,
          311,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2676,
        "id": 754,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2674,
        "temperature": 0,
        "text": " the GitHub repository for Tracery,",
        "tokens": [
          51114,
          264,
          23331,
          25841,
          337,
          1765,
          326,
          2109,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2678,
        "id": 755,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2676,
        "temperature": 0,
        "text": " you'll find a lot of links to a lot of fun and interesting projects",
        "tokens": [
          51214,
          291,
          603,
          915,
          257,
          688,
          295,
          6123,
          281,
          257,
          688,
          295,
          1019,
          293,
          1880,
          4455,
          51314
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2681,
        "id": 756,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2678,
        "temperature": 0,
        "text": " made with these kind of crazy grammars.",
        "tokens": [
          51314,
          1027,
          365,
          613,
          733,
          295,
          3219,
          17570,
          685,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2683,
        "id": 757,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2681,
        "temperature": 0,
        "text": " So, Tracery is the number...",
        "tokens": [
          51464,
          407,
          11,
          1765,
          326,
          2109,
          307,
          264,
          1230,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2685,
        "id": 758,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2683,
        "temperature": 0,
        "text": " It's the first video that I'm going to make after this one.",
        "tokens": [
          51564,
          467,
          311,
          264,
          700,
          960,
          300,
          286,
          478,
          516,
          281,
          652,
          934,
          341,
          472,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1708230792351489,
        "compression_ratio": 1.7342857142857142,
        "end": 2688,
        "id": 759,
        "no_speech_prob": 0.0016743759624660015,
        "seek": 265900,
        "start": 2685,
        "temperature": 0,
        "text": " We'll be showing you how to build and generate text with a Tracery grammar.",
        "tokens": [
          51664,
          492,
          603,
          312,
          4099,
          291,
          577,
          281,
          1322,
          293,
          8460,
          2487,
          365,
          257,
          1765,
          326,
          2109,
          22317,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2693,
        "id": 760,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2688,
        "temperature": 0,
        "text": " Another JavaScript library,",
        "tokens": [
          50364,
          3996,
          15778,
          6405,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2696,
        "id": 761,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2693,
        "temperature": 0,
        "text": " Rita.js, that I have mentioned before,",
        "tokens": [
          50614,
          32672,
          13,
          25530,
          11,
          300,
          286,
          362,
          2835,
          949,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2700,
        "id": 762,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2696,
        "temperature": 0,
        "text": " has a grammar object, right?",
        "tokens": [
          50764,
          575,
          257,
          22317,
          2657,
          11,
          558,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2702,
        "id": 763,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2700,
        "temperature": 0,
        "text": " It's called RIGrammar.",
        "tokens": [
          50964,
          467,
          311,
          1219,
          497,
          10489,
          2356,
          6209,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2704,
        "id": 764,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2702,
        "temperature": 0,
        "text": " You can add rules to it.",
        "tokens": [
          51064,
          509,
          393,
          909,
          4474,
          281,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2706,
        "id": 765,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2704,
        "temperature": 0,
        "text": " You can expand those grammars.",
        "tokens": [
          51164,
          509,
          393,
          5268,
          729,
          17570,
          685,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2708,
        "id": 766,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2706,
        "temperature": 0,
        "text": " You can check if there's a rule.",
        "tokens": [
          51264,
          509,
          393,
          1520,
          498,
          456,
          311,
          257,
          4978,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2709,
        "id": 767,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2708,
        "temperature": 0,
        "text": " You can load text into it.",
        "tokens": [
          51364,
          509,
          393,
          3677,
          2487,
          666,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2710,
        "id": 768,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2709,
        "temperature": 0,
        "text": " You can remove a rule, reset.",
        "tokens": [
          51414,
          509,
          393,
          4159,
          257,
          4978,
          11,
          14322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2713,
        "id": 769,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2710,
        "temperature": 0,
        "text": " So, you can see that this is essentially a JavaScript library",
        "tokens": [
          51464,
          407,
          11,
          291,
          393,
          536,
          300,
          341,
          307,
          4476,
          257,
          15778,
          6405,
          51614
        ]
      },
      {
        "avg_logprob": -0.1846651520047869,
        "compression_ratio": 1.7370892018779343,
        "end": 2715,
        "id": 770,
        "no_speech_prob": 0.0009697366622276604,
        "seek": 268800,
        "start": 2713,
        "temperature": 0,
        "text": " that allows you to generate those grammars.",
        "tokens": [
          51614,
          300,
          4045,
          291,
          281,
          8460,
          729,
          17570,
          685,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2718,
        "id": 771,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2715,
        "temperature": 0,
        "text": " Sorry, that allows you to generate text based on an existing grammar",
        "tokens": [
          50364,
          4919,
          11,
          300,
          4045,
          291,
          281,
          8460,
          2487,
          2361,
          322,
          364,
          6741,
          22317,
          50514
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2720,
        "id": 772,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2718,
        "temperature": 0,
        "text": " from a file, potentially.",
        "tokens": [
          50514,
          490,
          257,
          3991,
          11,
          7263,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2723,
        "id": 773,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2720,
        "temperature": 0,
        "text": " So, I'd encourage you to look at Tracery and the Rita library.",
        "tokens": [
          50614,
          407,
          11,
          286,
          1116,
          5373,
          291,
          281,
          574,
          412,
          1765,
          326,
          2109,
          293,
          264,
          32672,
          6405,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2726,
        "id": 774,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2723,
        "temperature": 0,
        "text": " Finally, I think for educational purposes,",
        "tokens": [
          50764,
          6288,
          11,
          286,
          519,
          337,
          10189,
          9932,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2730,
        "id": 775,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2726,
        "temperature": 0,
        "text": " and ultimately, if you really want to play around with this idea of grammars",
        "tokens": [
          50914,
          293,
          6284,
          11,
          498,
          291,
          534,
          528,
          281,
          862,
          926,
          365,
          341,
          1558,
          295,
          17570,
          685,
          51114
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2732,
        "id": 776,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2730,
        "temperature": 0,
        "text": " and context-free grammar, that is,",
        "tokens": [
          51114,
          293,
          4319,
          12,
          10792,
          22317,
          11,
          300,
          307,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2734,
        "id": 777,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2732,
        "temperature": 0,
        "text": " and customize it highly,",
        "tokens": [
          51214,
          293,
          19734,
          309,
          5405,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2736,
        "id": 778,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2734,
        "temperature": 0,
        "text": " you might want to write your own code",
        "tokens": [
          51314,
          291,
          1062,
          528,
          281,
          2464,
          428,
          1065,
          3089,
          51414
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2738,
        "id": 779,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2736,
        "temperature": 0,
        "text": " or at least play around with my example code and modify it.",
        "tokens": [
          51414,
          420,
          412,
          1935,
          862,
          926,
          365,
          452,
          1365,
          3089,
          293,
          16927,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2741,
        "id": 780,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2738,
        "temperature": 0,
        "text": " For example, what if, while the text is being generated,",
        "tokens": [
          51514,
          1171,
          1365,
          11,
          437,
          498,
          11,
          1339,
          264,
          2487,
          307,
          885,
          10833,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.19682134252016237,
        "compression_ratio": 1.7071651090342679,
        "end": 2744,
        "id": 781,
        "no_speech_prob": 0.05920333042740822,
        "seek": 271500,
        "start": 2741,
        "temperature": 0,
        "text": " you're querying an API to grab words from, say, Wordnik",
        "tokens": [
          51664,
          291,
          434,
          7083,
          1840,
          364,
          9362,
          281,
          4444,
          2283,
          490,
          11,
          584,
          11,
          8725,
          13123,
          51814
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2745,
        "id": 782,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2744,
        "temperature": 0,
        "text": " or something like that.",
        "tokens": [
          50364,
          420,
          746,
          411,
          300,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2749,
        "id": 783,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2745,
        "temperature": 0,
        "text": " You might be limited with using some of these existing libraries or frameworks,",
        "tokens": [
          50414,
          509,
          1062,
          312,
          5567,
          365,
          1228,
          512,
          295,
          613,
          6741,
          15148,
          420,
          29834,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2751,
        "id": 784,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2749,
        "temperature": 0,
        "text": " but if you've written all of the code yourself,",
        "tokens": [
          50614,
          457,
          498,
          291,
          600,
          3720,
          439,
          295,
          264,
          3089,
          1803,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2756,
        "id": 785,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2751,
        "temperature": 0,
        "text": " you can kind of add in sort of features that are more procedurally based",
        "tokens": [
          50714,
          291,
          393,
          733,
          295,
          909,
          294,
          1333,
          295,
          4122,
          300,
          366,
          544,
          6682,
          6512,
          2361,
          50964
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2758,
        "id": 786,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2756,
        "temperature": 0,
        "text": " inside of the algorithm itself as it's running.",
        "tokens": [
          50964,
          1854,
          295,
          264,
          9284,
          2564,
          382,
          309,
          311,
          2614,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2762,
        "id": 787,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2758,
        "temperature": 0,
        "text": " So, in that sense, the last thing that I'll do besides Tracery and Rita",
        "tokens": [
          51064,
          407,
          11,
          294,
          300,
          2020,
          11,
          264,
          1036,
          551,
          300,
          286,
          603,
          360,
          11868,
          1765,
          326,
          2109,
          293,
          32672,
          51264
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2770,
        "id": 788,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2762,
        "temperature": 0,
        "text": " is I will show you how to write your own grammar object.",
        "tokens": [
          51264,
          307,
          286,
          486,
          855,
          291,
          577,
          281,
          2464,
          428,
          1065,
          22317,
          2657,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18194430669148762,
        "compression_ratio": 1.6421052631578947,
        "end": 2773,
        "id": 789,
        "no_speech_prob": 0.0024343463592231274,
        "seek": 274400,
        "start": 2770,
        "temperature": 0,
        "text": " And so, I have an example that makes a context-free grammar object",
        "tokens": [
          51664,
          400,
          370,
          11,
          286,
          362,
          364,
          1365,
          300,
          1669,
          257,
          4319,
          12,
          10792,
          22317,
          2657,
          51814
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2776,
        "id": 790,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2773,
        "temperature": 0,
        "text": " and that you can simply just add rules to it,",
        "tokens": [
          50364,
          293,
          300,
          291,
          393,
          2935,
          445,
          909,
          4474,
          281,
          309,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2779,
        "id": 791,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2776,
        "temperature": 0,
        "text": " whether it's coming from a file or whether it's just directly in the code.",
        "tokens": [
          50514,
          1968,
          309,
          311,
          1348,
          490,
          257,
          3991,
          420,
          1968,
          309,
          311,
          445,
          3838,
          294,
          264,
          3089,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2781,
        "id": 792,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2779,
        "temperature": 0,
        "text": " So, those are the things I'm going to show you.",
        "tokens": [
          50664,
          407,
          11,
          729,
          366,
          264,
          721,
          286,
          478,
          516,
          281,
          855,
          291,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2784,
        "id": 793,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2781,
        "temperature": 0,
        "text": " I'm going to make probably two or three or four little video tutorials",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          652,
          1391,
          732,
          420,
          1045,
          420,
          1451,
          707,
          960,
          17616,
          50914
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2786,
        "id": 794,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2784,
        "temperature": 0,
        "text": " all about context-free grammars.",
        "tokens": [
          50914,
          439,
          466,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2788,
        "id": 795,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2786,
        "temperature": 0,
        "text": " Somewhere in there, I'll try to make sure I mention the whole idea",
        "tokens": [
          51014,
          34500,
          294,
          456,
          11,
          286,
          603,
          853,
          281,
          652,
          988,
          286,
          2152,
          264,
          1379,
          1558,
          51114
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2790,
        "id": 796,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2788,
        "temperature": 0,
        "text": " of a context-sensitive grammar,",
        "tokens": [
          51114,
          295,
          257,
          4319,
          12,
          82,
          34465,
          22317,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2793,
        "id": 797,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2790,
        "temperature": 0,
        "text": " but I think it'll make more sense once we start looking at the nitty-gritty.",
        "tokens": [
          51214,
          457,
          286,
          519,
          309,
          603,
          652,
          544,
          2020,
          1564,
          321,
          722,
          1237,
          412,
          264,
          297,
          10016,
          12,
          861,
          10016,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2796,
        "id": 798,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2793,
        "temperature": 0,
        "text": " Okay? So, I hope you enjoyed this brief overview.",
        "tokens": [
          51364,
          1033,
          30,
          407,
          11,
          286,
          1454,
          291,
          4626,
          341,
          5353,
          12492,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2798,
        "id": 799,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2796,
        "temperature": 0,
        "text": " Check some of the links in this video's description",
        "tokens": [
          51514,
          6881,
          512,
          295,
          264,
          6123,
          294,
          341,
          960,
          311,
          3855,
          51614
        ]
      },
      {
        "avg_logprob": -0.1686084888599537,
        "compression_ratio": 1.7365439093484418,
        "end": 2801,
        "id": 800,
        "no_speech_prob": 0.03788616880774498,
        "seek": 277300,
        "start": 2798,
        "temperature": 0,
        "text": " for more reading and materials about the background and theory",
        "tokens": [
          51614,
          337,
          544,
          3760,
          293,
          5319,
          466,
          264,
          3678,
          293,
          5261,
          51764
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2803,
        "id": 801,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2801,
        "temperature": 0,
        "text": " of using grammars with text,",
        "tokens": [
          50364,
          295,
          1228,
          17570,
          685,
          365,
          2487,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2807,
        "id": 802,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2803,
        "temperature": 0,
        "text": " and hopefully I'll see you in some of the actual coding tutorial videos next.",
        "tokens": [
          50464,
          293,
          4696,
          286,
          603,
          536,
          291,
          294,
          512,
          295,
          264,
          3539,
          17720,
          7073,
          2145,
          958,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2809,
        "id": 803,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2807,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2813,
        "id": 804,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2809,
        "temperature": 0,
        "text": " So, all right.",
        "tokens": [
          50764,
          407,
          11,
          439,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2818,
        "id": 805,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2813,
        "temperature": 0,
        "text": " Hopefully that was something useful.",
        "tokens": [
          50964,
          10429,
          300,
          390,
          746,
          4420,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2821,
        "id": 806,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2818,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51214,
          400,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.2664751786452073,
        "compression_ratio": 1.3509933774834437,
        "end": 2829,
        "id": 807,
        "no_speech_prob": 0.04467586427927017,
        "seek": 280100,
        "start": 2821,
        "temperature": 0,
        "text": " Next, I am going to use Tracery.",
        "tokens": [
          51364,
          3087,
          11,
          286,
          669,
          516,
          281,
          764,
          1765,
          326,
          2109,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2832,
        "id": 808,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2829,
        "temperature": 0,
        "text": " So, while you guys are catching up to me,",
        "tokens": [
          50364,
          407,
          11,
          1339,
          291,
          1074,
          366,
          16124,
          493,
          281,
          385,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2834,
        "id": 809,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2832,
        "temperature": 0,
        "text": " because you'll never catch up to me,",
        "tokens": [
          50514,
          570,
          291,
          603,
          1128,
          3745,
          493,
          281,
          385,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2844,
        "id": 810,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2834,
        "temperature": 0,
        "text": " I'm going to close a bunch of windows here.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          1998,
          257,
          3840,
          295,
          9309,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2846,
        "id": 811,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2844,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51114,
          400,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2851,
        "id": 812,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2846,
        "temperature": 0,
        "text": " I'm back to here.",
        "tokens": [
          51214,
          286,
          478,
          646,
          281,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2854,
        "id": 813,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2851,
        "temperature": 0,
        "text": " And Tracery.",
        "tokens": [
          51464,
          400,
          1765,
          326,
          2109,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21329966458407315,
        "compression_ratio": 1.4435483870967742,
        "end": 2856,
        "id": 814,
        "no_speech_prob": 0.11278358846902847,
        "seek": 282900,
        "start": 2854,
        "temperature": 0,
        "text": " I'm here and here.",
        "tokens": [
          51614,
          286,
          478,
          510,
          293,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2864,
        "id": 815,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2857,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50414,
          407,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2866,
        "id": 816,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2864,
        "temperature": 0,
        "text": " So, let me open up my...",
        "tokens": [
          50764,
          407,
          11,
          718,
          385,
          1269,
          493,
          452,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2868,
        "id": 817,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2866,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50864,
          7521,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2871,
        "id": 818,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2868,
        "temperature": 0,
        "text": " What happened to the context-free grammar?",
        "tokens": [
          50964,
          708,
          2011,
          281,
          264,
          4319,
          12,
          10792,
          22317,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2872,
        "id": 819,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2871,
        "temperature": 0,
        "text": " I'm in the wrong place, aren't I?",
        "tokens": [
          51114,
          286,
          478,
          294,
          264,
          2085,
          1081,
          11,
          3212,
          380,
          286,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2874,
        "id": 820,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2872,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51164,
          876,
          11,
          1338,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2876,
        "id": 821,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2874,
        "temperature": 0,
        "text": " Oops. Sorry, everybody.",
        "tokens": [
          51264,
          21726,
          13,
          4919,
          11,
          2201,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2878,
        "id": 822,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2876,
        "temperature": 0,
        "text": " Confusion. There we go.",
        "tokens": [
          51364,
          11701,
          5704,
          13,
          821,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2881,
        "id": 823,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2878,
        "temperature": 0,
        "text": " Tracery.",
        "tokens": [
          51464,
          1765,
          326,
          2109,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18769457075330948,
        "compression_ratio": 1.3431952662721893,
        "end": 2885,
        "id": 824,
        "no_speech_prob": 0.042720116674900055,
        "seek": 285600,
        "start": 2881,
        "temperature": 0,
        "text": " So, okay. So, first of all, I will say this...",
        "tokens": [
          51614,
          407,
          11,
          1392,
          13,
          407,
          11,
          700,
          295,
          439,
          11,
          286,
          486,
          584,
          341,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2889,
        "id": 825,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2885,
        "temperature": 0,
        "text": " The reason I said you'll never catch up to me is because I...",
        "tokens": [
          50364,
          440,
          1778,
          286,
          848,
          291,
          603,
          1128,
          3745,
          493,
          281,
          385,
          307,
          570,
          286,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2892,
        "id": 826,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2889,
        "temperature": 0,
        "text": " The live stream has about a 15 to 20 second delay.",
        "tokens": [
          50564,
          440,
          1621,
          4309,
          575,
          466,
          257,
          2119,
          281,
          945,
          1150,
          8577,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2895,
        "id": 827,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2892,
        "temperature": 0,
        "text": " So, you will all catch up to me and bypass me, I hope, at some point.",
        "tokens": [
          50714,
          407,
          11,
          291,
          486,
          439,
          3745,
          493,
          281,
          385,
          293,
          24996,
          385,
          11,
          286,
          1454,
          11,
          412,
          512,
          935,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2897,
        "id": 828,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2895,
        "temperature": 0,
        "text": " And hopefully you will still continue to watch.",
        "tokens": [
          50864,
          400,
          4696,
          291,
          486,
          920,
          2354,
          281,
          1159,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2900,
        "id": 829,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2897,
        "temperature": 0,
        "text": " Or maybe you won't watch and you'll make your own YouTube live stream.",
        "tokens": [
          50964,
          1610,
          1310,
          291,
          1582,
          380,
          1159,
          293,
          291,
          603,
          652,
          428,
          1065,
          3088,
          1621,
          4309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2902,
        "id": 830,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2900,
        "temperature": 0,
        "text": " Okay. So, I'm...",
        "tokens": [
          51114,
          1033,
          13,
          407,
          11,
          286,
          478,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2904,
        "id": 831,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2902,
        "temperature": 0,
        "text": " I guess I'll mention this.",
        "tokens": [
          51214,
          286,
          2041,
          286,
          603,
          2152,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2905,
        "id": 832,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2904,
        "temperature": 0,
        "text": " I was going to describe what this is,",
        "tokens": [
          51314,
          286,
          390,
          516,
          281,
          6786,
          437,
          341,
          307,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2908,
        "id": 833,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2905,
        "temperature": 0,
        "text": " but I'm just going to start in doing the Tracery grammar.",
        "tokens": [
          51364,
          457,
          286,
          478,
          445,
          516,
          281,
          722,
          294,
          884,
          264,
          1765,
          326,
          2109,
          22317,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2910,
        "id": 834,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2908,
        "temperature": 0,
        "text": " Yes, emojis.",
        "tokens": [
          51514,
          1079,
          11,
          19611,
          40371,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.191688354701212,
        "compression_ratio": 1.6458333333333333,
        "end": 2913,
        "id": 835,
        "no_speech_prob": 0.01205303706228733,
        "seek": 288500,
        "start": 2910,
        "temperature": 0,
        "text": " Emojis are upon us.",
        "tokens": [
          51614,
          462,
          3280,
          40371,
          366,
          3564,
          505,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2914,
        "id": 836,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2913,
        "temperature": 0,
        "text": " I want to do a whole...",
        "tokens": [
          50364,
          286,
          528,
          281,
          360,
          257,
          1379,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2915,
        "id": 837,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2914,
        "temperature": 0,
        "text": " I want to do a whole...",
        "tokens": [
          50414,
          286,
          528,
          281,
          360,
          257,
          1379,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2916,
        "id": 838,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2915,
        "temperature": 0,
        "text": " I don't have an undefined...",
        "tokens": [
          50464,
          286,
          500,
          380,
          362,
          364,
          674,
          5666,
          2001,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2917,
        "id": 839,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2916,
        "temperature": 0,
        "text": " I don't have a name.",
        "tokens": [
          50514,
          286,
          500,
          380,
          362,
          257,
          1315,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2919,
        "id": 840,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2917,
        "temperature": 0,
        "text": " Undefined session all about emojis.",
        "tokens": [
          50564,
          2719,
          5666,
          2001,
          5481,
          439,
          466,
          19611,
          40371,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2922,
        "id": 841,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2919,
        "temperature": 0,
        "text": " So, one day we're going to do a whole afternoon that's just only about emojis",
        "tokens": [
          50664,
          407,
          11,
          472,
          786,
          321,
          434,
          516,
          281,
          360,
          257,
          1379,
          6499,
          300,
          311,
          445,
          787,
          466,
          19611,
          40371,
          50814
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2925,
        "id": 842,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2922,
        "temperature": 0,
        "text": " and programming with emojis.",
        "tokens": [
          50814,
          293,
          9410,
          365,
          19611,
          40371,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2927,
        "id": 843,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2925,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2929,
        "id": 844,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2927,
        "temperature": 0,
        "text": " I'm so glad when people say I just got the perfect idea",
        "tokens": [
          51064,
          286,
          478,
          370,
          5404,
          562,
          561,
          584,
          286,
          445,
          658,
          264,
          2176,
          1558,
          51164
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2931,
        "id": 845,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2929,
        "temperature": 0,
        "text": " because that's the point of doing this.",
        "tokens": [
          51164,
          570,
          300,
          311,
          264,
          935,
          295,
          884,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2933,
        "id": 846,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2931,
        "temperature": 0,
        "text": " I want you guys to have interesting ideas of things to make.",
        "tokens": [
          51264,
          286,
          528,
          291,
          1074,
          281,
          362,
          1880,
          3487,
          295,
          721,
          281,
          652,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2938,
        "id": 847,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2933,
        "temperature": 0,
        "text": " And please share them with me if you do.",
        "tokens": [
          51364,
          400,
          1767,
          2073,
          552,
          365,
          385,
          498,
          291,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2940,
        "id": 848,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2938,
        "temperature": 0,
        "text": " Okay. So...",
        "tokens": [
          51614,
          1033,
          13,
          407,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.16581446164614194,
        "compression_ratio": 1.8021978021978022,
        "end": 2942,
        "id": 849,
        "no_speech_prob": 0.00026529980823397636,
        "seek": 291300,
        "start": 2940,
        "temperature": 0,
        "text": " Wow, there are 138 people watching,",
        "tokens": [
          51714,
          3153,
          11,
          456,
          366,
          3705,
          23,
          561,
          1976,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2943,
        "id": 850,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2942,
        "temperature": 0,
        "text": " which is really exciting and nice.",
        "tokens": [
          50364,
          597,
          307,
          534,
          4670,
          293,
          1481,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2946,
        "id": 851,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2943,
        "temperature": 0,
        "text": " Thank you all for being here.",
        "tokens": [
          50414,
          1044,
          291,
          439,
          337,
          885,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2952,
        "id": 852,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2946,
        "temperature": 0,
        "text": " I'm feeling your energy and it's giving me a little bit of a spark.",
        "tokens": [
          50564,
          286,
          478,
          2633,
          428,
          2281,
          293,
          309,
          311,
          2902,
          385,
          257,
          707,
          857,
          295,
          257,
          9908,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2958,
        "id": 853,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2952,
        "temperature": 0,
        "text": " So, let me...",
        "tokens": [
          50864,
          407,
          11,
          718,
          385,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2959,
        "id": 854,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2958,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2960,
        "id": 855,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2959,
        "temperature": 0,
        "text": " So, what I've got this...",
        "tokens": [
          51214,
          407,
          11,
          437,
          286,
          600,
          658,
          341,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2961,
        "id": 856,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2960,
        "temperature": 0,
        "text": " Where's...",
        "tokens": [
          51264,
          2305,
          311,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2962,
        "id": 857,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2961,
        "temperature": 0,
        "text": " I've got the marker.",
        "tokens": [
          51314,
          286,
          600,
          658,
          264,
          15247,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2967,
        "id": 858,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2962,
        "temperature": 0,
        "text": " And I'm going to work with Tracery in this first video.",
        "tokens": [
          51364,
          400,
          286,
          478,
          516,
          281,
          589,
          365,
          1765,
          326,
          2109,
          294,
          341,
          700,
          960,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19219002825148562,
        "compression_ratio": 1.4945054945054945,
        "end": 2970,
        "id": 859,
        "no_speech_prob": 0.0017006993293762207,
        "seek": 294200,
        "start": 2967,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2597832997639974,
        "compression_ratio": 1.099009900990099,
        "end": 2971,
        "id": 860,
        "no_speech_prob": 0.017175814136862755,
        "seek": 297000,
        "start": 2970,
        "temperature": 0,
        "text": " This, by the way, is something I'm...",
        "tokens": [
          50364,
          639,
          11,
          538,
          264,
          636,
          11,
          307,
          746,
          286,
          478,
          485,
          50414
        ]
      },
      {
        "avg_logprob": -0.2597832997639974,
        "compression_ratio": 1.099009900990099,
        "end": 2973,
        "id": 861,
        "no_speech_prob": 0.017175814136862755,
        "seek": 297000,
        "start": 2971,
        "temperature": 0,
        "text": " I'll just talk about what this is in a second.",
        "tokens": [
          50414,
          286,
          603,
          445,
          751,
          466,
          437,
          341,
          307,
          294,
          257,
          1150,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2597832997639974,
        "compression_ratio": 1.099009900990099,
        "end": 2975,
        "id": 862,
        "no_speech_prob": 0.017175814136862755,
        "seek": 297000,
        "start": 2973,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2597832997639974,
        "compression_ratio": 1.099009900990099,
        "end": 2980,
        "id": 863,
        "no_speech_prob": 0.017175814136862755,
        "seek": 297000,
        "start": 2975,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50614,
          1692,
          321,
          352,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2597832997639974,
        "compression_ratio": 1.099009900990099,
        "end": 2996,
        "id": 864,
        "no_speech_prob": 0.017175814136862755,
        "seek": 297000,
        "start": 2980,
        "temperature": 0,
        "text": " Oh, boy.",
        "tokens": [
          50864,
          876,
          11,
          3237,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 2997,
        "id": 865,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 2996,
        "temperature": 0,
        "text": " Remember when I said here we go?",
        "tokens": [
          50364,
          5459,
          562,
          286,
          848,
          510,
          321,
          352,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3000,
        "id": 866,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 2997,
        "temperature": 0,
        "text": " Now I really mean it.",
        "tokens": [
          50414,
          823,
          286,
          534,
          914,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3001,
        "id": 867,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3000,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          50564,
          708,
          565,
          307,
          309,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3002,
        "id": 868,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3001,
        "temperature": 0,
        "text": " 2.50.",
        "tokens": [
          50614,
          568,
          13,
          2803,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3003,
        "id": 869,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3002,
        "temperature": 0,
        "text": " Oh, good.",
        "tokens": [
          50664,
          876,
          11,
          665,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3004,
        "id": 870,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3003,
        "temperature": 0,
        "text": " We're doing pretty well on time.",
        "tokens": [
          50714,
          492,
          434,
          884,
          1238,
          731,
          322,
          565,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3005,
        "id": 871,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3004,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50764,
          2425,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3006,
        "id": 872,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3005,
        "temperature": 0,
        "text": " Welcome to another video tutorial.",
        "tokens": [
          50814,
          4027,
          281,
          1071,
          960,
          7073,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3009,
        "id": 873,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3006,
        "temperature": 0,
        "text": " This is part of session 7, Programming from A to Z.",
        "tokens": [
          50864,
          639,
          307,
          644,
          295,
          5481,
          1614,
          11,
          8338,
          2810,
          490,
          316,
          281,
          1176,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3012,
        "id": 874,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3009,
        "temperature": 0,
        "text": " And all these videos are about grammar,",
        "tokens": [
          51014,
          400,
          439,
          613,
          2145,
          366,
          466,
          22317,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3014,
        "id": 875,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3012,
        "temperature": 0,
        "text": " specifically, context-free grammars.",
        "tokens": [
          51164,
          4682,
          11,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3019,
        "id": 876,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3014,
        "temperature": 0,
        "text": " So, today I want to talk about a particular grammar generation library",
        "tokens": [
          51264,
          407,
          11,
          965,
          286,
          528,
          281,
          751,
          466,
          257,
          1729,
          22317,
          5125,
          6405,
          51514
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3021,
        "id": 877,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3019,
        "temperature": 0,
        "text": " for JavaScript called Tracery.",
        "tokens": [
          51514,
          337,
          15778,
          1219,
          1765,
          326,
          2109,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2129549869271212,
        "compression_ratio": 1.5092936802973977,
        "end": 3023,
        "id": 878,
        "no_speech_prob": 0.4223214089870453,
        "seek": 299600,
        "start": 3021,
        "temperature": 0,
        "text": " Ah, Tracery.",
        "tokens": [
          51614,
          2438,
          11,
          1765,
          326,
          2109,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3026,
        "id": 879,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3023,
        "temperature": 0,
        "text": " Tracery is by Kate Compton, at GalaxyKate on GitHub.",
        "tokens": [
          50364,
          1765,
          326,
          2109,
          307,
          538,
          16251,
          2432,
          21987,
          11,
          412,
          13520,
          42,
          473,
          322,
          23331,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3028,
        "id": 880,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3026,
        "temperature": 0,
        "text": " It's a wonderful project.",
        "tokens": [
          50514,
          467,
          311,
          257,
          3715,
          1716,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3032,
        "id": 881,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3028,
        "temperature": 0,
        "text": " It allows you to be really creative with generating text, generating stories,",
        "tokens": [
          50614,
          467,
          4045,
          291,
          281,
          312,
          534,
          5880,
          365,
          17746,
          2487,
          11,
          17746,
          3676,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3037,
        "id": 882,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3032,
        "temperature": 0,
        "text": " making a Twitter bot, just by putting together a bunch of possibilities, in a way.",
        "tokens": [
          50814,
          1455,
          257,
          5794,
          10592,
          11,
          445,
          538,
          3372,
          1214,
          257,
          3840,
          295,
          12178,
          11,
          294,
          257,
          636,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3039,
        "id": 883,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3037,
        "temperature": 0,
        "text": " A grammar, so to speak.",
        "tokens": [
          51064,
          316,
          22317,
          11,
          370,
          281,
          1710,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3041,
        "id": 884,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3039,
        "temperature": 0,
        "text": " So, first I'm going to show you an example.",
        "tokens": [
          51164,
          407,
          11,
          700,
          286,
          478,
          516,
          281,
          855,
          291,
          364,
          1365,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3042,
        "id": 885,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3041,
        "temperature": 0,
        "text": " This is actually...",
        "tokens": [
          51264,
          639,
          307,
          767,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3045,
        "id": 886,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3042,
        "temperature": 0,
        "text": " This is called Once Upon a Time Stories.",
        "tokens": [
          51314,
          639,
          307,
          1219,
          3443,
          25184,
          257,
          6161,
          31797,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3048,
        "id": 887,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3045,
        "temperature": 0,
        "text": " It is by a 5-year-old and an 8-year-old who happen to be related to me.",
        "tokens": [
          51464,
          467,
          307,
          538,
          257,
          1025,
          12,
          5294,
          12,
          2641,
          293,
          364,
          1649,
          12,
          5294,
          12,
          2641,
          567,
          1051,
          281,
          312,
          4077,
          281,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3050,
        "id": 888,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3048,
        "temperature": 0,
        "text": " They're my children.",
        "tokens": [
          51614,
          814,
          434,
          452,
          2227,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1782307409471081,
        "compression_ratio": 1.6257668711656441,
        "end": 3052,
        "id": 889,
        "no_speech_prob": 0.40718090534210205,
        "seek": 302300,
        "start": 3050,
        "temperature": 0,
        "text": " And they didn't write the code for this, but they wrote the grammar.",
        "tokens": [
          51714,
          400,
          436,
          994,
          380,
          2464,
          264,
          3089,
          337,
          341,
          11,
          457,
          436,
          4114,
          264,
          22317,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3055,
        "id": 890,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3052,
        "temperature": 0,
        "text": " So, I'm going to just generate a story and read it to you.",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          445,
          8460,
          257,
          1657,
          293,
          1401,
          309,
          281,
          291,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3059,
        "id": 891,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3055,
        "temperature": 0,
        "text": " Once upon a time there was a princess, and that princess was very happy.",
        "tokens": [
          50514,
          3443,
          3564,
          257,
          565,
          456,
          390,
          257,
          14742,
          11,
          293,
          300,
          14742,
          390,
          588,
          2055,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3061,
        "id": 892,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3059,
        "temperature": 0,
        "text": " And the princess liked hamburgers.",
        "tokens": [
          50714,
          400,
          264,
          14742,
          4501,
          25172,
          5476,
          433,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3062,
        "id": 893,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3061,
        "temperature": 0,
        "text": " The princess was very jealous.",
        "tokens": [
          50814,
          440,
          14742,
          390,
          588,
          13805,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3067,
        "id": 894,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3062,
        "temperature": 0,
        "text": " Then the princess met a lovely, sad chupacabra, and she killed the chupacabra.",
        "tokens": [
          50864,
          1396,
          264,
          14742,
          1131,
          257,
          7496,
          11,
          4227,
          417,
          1010,
          326,
          455,
          424,
          11,
          293,
          750,
          4652,
          264,
          417,
          1010,
          326,
          455,
          424,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3068,
        "id": 895,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3067,
        "temperature": 0,
        "text": " Yahoo!",
        "tokens": [
          51114,
          41757,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3072,
        "id": 896,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3068,
        "temperature": 0,
        "text": " And then the princess ate the burrito, and she was so sunglasses,",
        "tokens": [
          51164,
          400,
          550,
          264,
          14742,
          8468,
          264,
          2779,
          17492,
          11,
          293,
          750,
          390,
          370,
          28675,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3075,
        "id": 897,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3072,
        "temperature": 0,
        "text": " and she was heart eyes too today.",
        "tokens": [
          51364,
          293,
          750,
          390,
          1917,
          2575,
          886,
          965,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3077,
        "id": 898,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3075,
        "temperature": 0,
        "text": " I don't know. Let's generate another one.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          13,
          961,
          311,
          8460,
          1071,
          472,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3078,
        "id": 899,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3077,
        "temperature": 0,
        "text": " Oh, here's a princess again.",
        "tokens": [
          51614,
          876,
          11,
          510,
          311,
          257,
          14742,
          797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3079,
        "id": 900,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3078,
        "temperature": 0,
        "text": " Ah, dragon. Okay.",
        "tokens": [
          51664,
          2438,
          11,
          12165,
          13,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1912435719996323,
        "compression_ratio": 1.9672727272727273,
        "end": 3081,
        "id": 901,
        "no_speech_prob": 0.005060045979917049,
        "seek": 305200,
        "start": 3079,
        "temperature": 0,
        "text": " Once upon a time there was a dragon, and that dragon was very angry.",
        "tokens": [
          51714,
          3443,
          3564,
          257,
          565,
          456,
          390,
          257,
          12165,
          11,
          293,
          300,
          12165,
          390,
          588,
          6884,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3083,
        "id": 902,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3081,
        "temperature": 0,
        "text": " And the dragon liked shrimp.",
        "tokens": [
          50364,
          400,
          264,
          12165,
          4501,
          15600,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3085,
        "id": 903,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3083,
        "temperature": 0,
        "text": " The dragon was very funny, and then the dragon met a...",
        "tokens": [
          50464,
          440,
          12165,
          390,
          588,
          4074,
          11,
          293,
          550,
          264,
          12165,
          1131,
          257,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3087,
        "id": 904,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3085,
        "temperature": 0,
        "text": " I better stop reading these.",
        "tokens": [
          50564,
          286,
          1101,
          1590,
          3760,
          613,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3090,
        "id": 905,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3087,
        "temperature": 0,
        "text": " We'll edit that down.",
        "tokens": [
          50664,
          492,
          603,
          8129,
          300,
          760,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3095,
        "id": 906,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3090,
        "temperature": 0,
        "text": " So, you can see this is one way of using a grammar like tracery to generate.",
        "tokens": [
          50814,
          407,
          11,
          291,
          393,
          536,
          341,
          307,
          472,
          636,
          295,
          1228,
          257,
          22317,
          411,
          504,
          326,
          2109,
          281,
          8460,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3098,
        "id": 907,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3095,
        "temperature": 0,
        "text": " And there's a little bit of color and emojis and stuff going on here,",
        "tokens": [
          51064,
          400,
          456,
          311,
          257,
          707,
          857,
          295,
          2017,
          293,
          19611,
          40371,
          293,
          1507,
          516,
          322,
          510,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3099,
        "id": 908,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3098,
        "temperature": 0,
        "text": " but to generate text.",
        "tokens": [
          51214,
          457,
          281,
          8460,
          2487,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3103,
        "id": 909,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3099,
        "temperature": 0,
        "text": " So, let me just look into the code for this for a second",
        "tokens": [
          51264,
          407,
          11,
          718,
          385,
          445,
          574,
          666,
          264,
          3089,
          337,
          341,
          337,
          257,
          1150,
          51464
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3106,
        "id": 910,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3103,
        "temperature": 0,
        "text": " so that I can point out to you what the grammar actually...",
        "tokens": [
          51464,
          370,
          300,
          286,
          393,
          935,
          484,
          281,
          291,
          437,
          264,
          22317,
          767,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3107,
        "id": 911,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3106,
        "temperature": 0,
        "text": " Oops, I'm in the wrong place.",
        "tokens": [
          51614,
          21726,
          11,
          286,
          478,
          294,
          264,
          2085,
          1081,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2129688262939453,
        "compression_ratio": 1.7464285714285714,
        "end": 3110,
        "id": 912,
        "no_speech_prob": 0.018546095117926598,
        "seek": 308100,
        "start": 3107,
        "temperature": 0,
        "text": " What the grammar actually looks like.",
        "tokens": [
          51664,
          708,
          264,
          22317,
          767,
          1542,
          411,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3113,
        "id": 913,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3111,
        "temperature": 0,
        "text": " So, this is what the grammar actually looks like.",
        "tokens": [
          50414,
          407,
          11,
          341,
          307,
          437,
          264,
          22317,
          767,
          1542,
          411,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3116,
        "id": 914,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3113,
        "temperature": 0,
        "text": " And the grammar is simply a JavaScript object.",
        "tokens": [
          50514,
          400,
          264,
          22317,
          307,
          2935,
          257,
          15778,
          2657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3120,
        "id": 915,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3116,
        "temperature": 0,
        "text": " And remember, if you watched my first video about context-free grammar,",
        "tokens": [
          50664,
          400,
          1604,
          11,
          498,
          291,
          6337,
          452,
          700,
          960,
          466,
          4319,
          12,
          10792,
          22317,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3122,
        "id": 916,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3120,
        "temperature": 0,
        "text": " everything is about production rules.",
        "tokens": [
          50864,
          1203,
          307,
          466,
          4265,
          4474,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3124,
        "id": 917,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3122,
        "temperature": 0,
        "text": " Take this and replace it with this.",
        "tokens": [
          50964,
          3664,
          341,
          293,
          7406,
          309,
          365,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3126,
        "id": 918,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3124,
        "temperature": 0,
        "text": " And if you have this, replace it with this.",
        "tokens": [
          51064,
          400,
          498,
          291,
          362,
          341,
          11,
          7406,
          309,
          365,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3127,
        "id": 919,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3126,
        "temperature": 0,
        "text": " And if you have this, replace it with this.",
        "tokens": [
          51164,
          400,
          498,
          291,
          362,
          341,
          11,
          7406,
          309,
          365,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3129,
        "id": 920,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3127,
        "temperature": 0,
        "text": " And you've got to start with something.",
        "tokens": [
          51214,
          400,
          291,
          600,
          658,
          281,
          722,
          365,
          746,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3132,
        "id": 921,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3129,
        "temperature": 0,
        "text": " So, if I come back to here, you're going to see here there is a start.",
        "tokens": [
          51314,
          407,
          11,
          498,
          286,
          808,
          646,
          281,
          510,
          11,
          291,
          434,
          516,
          281,
          536,
          510,
          456,
          307,
          257,
          722,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3134,
        "id": 922,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3132,
        "temperature": 0,
        "text": " Now, there's some strange syntax.",
        "tokens": [
          51464,
          823,
          11,
          456,
          311,
          512,
          5861,
          28431,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3137,
        "id": 923,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3134,
        "temperature": 0,
        "text": " There's a hash symbol and a bracket, colon and a character.",
        "tokens": [
          51564,
          821,
          311,
          257,
          22019,
          5986,
          293,
          257,
          16904,
          11,
          8255,
          293,
          257,
          2517,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16259477700397468,
        "compression_ratio": 1.965635738831615,
        "end": 3139,
        "id": 924,
        "no_speech_prob": 0.0019877376034855843,
        "seek": 311000,
        "start": 3137,
        "temperature": 0,
        "text": " There's a story. There's characters.",
        "tokens": [
          51714,
          821,
          311,
          257,
          1657,
          13,
          821,
          311,
          4342,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3141,
        "id": 925,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3139,
        "temperature": 0,
        "text": " But you can see there's a selection of food options,",
        "tokens": [
          50364,
          583,
          291,
          393,
          536,
          456,
          311,
          257,
          9450,
          295,
          1755,
          3956,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3144,
        "id": 926,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3141,
        "temperature": 0,
        "text": " a selection of monster options, that sort of thing.",
        "tokens": [
          50464,
          257,
          9450,
          295,
          10090,
          3956,
          11,
          300,
          1333,
          295,
          551,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3147,
        "id": 927,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3144,
        "temperature": 0,
        "text": " And I should point out to you one thing you'll notice, by the way,",
        "tokens": [
          50614,
          400,
          286,
          820,
          935,
          484,
          281,
          291,
          472,
          551,
          291,
          603,
          3449,
          11,
          538,
          264,
          636,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3149,
        "id": 928,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3147,
        "temperature": 0,
        "text": " is in JavaScript, if you want to have emojis,",
        "tokens": [
          50764,
          307,
          294,
          15778,
          11,
          498,
          291,
          528,
          281,
          362,
          19611,
          40371,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3151,
        "id": 929,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3149,
        "temperature": 0,
        "text": " you can just stick emojis in there.",
        "tokens": [
          50864,
          291,
          393,
          445,
          2897,
          19611,
          40371,
          294,
          456,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3153,
        "id": 930,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3151,
        "temperature": 0,
        "text": " They're read just as text like anything else.",
        "tokens": [
          50964,
          814,
          434,
          1401,
          445,
          382,
          2487,
          411,
          1340,
          1646,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3155,
        "id": 931,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3153,
        "temperature": 0,
        "text": " I mean, how they're interpreted and displayed",
        "tokens": [
          51064,
          286,
          914,
          11,
          577,
          436,
          434,
          26749,
          293,
          16372,
          51164
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3158,
        "id": 932,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3155,
        "temperature": 0,
        "text": " depends on what the environment you're living in.",
        "tokens": [
          51164,
          5946,
          322,
          437,
          264,
          2823,
          291,
          434,
          2647,
          294,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3163,
        "id": 933,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3158,
        "temperature": 0,
        "text": " But the Unicode characters themselves are there for you to use.",
        "tokens": [
          51314,
          583,
          264,
          1156,
          299,
          1429,
          4342,
          2969,
          366,
          456,
          337,
          291,
          281,
          764,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2122399696936974,
        "compression_ratio": 1.6643109540636043,
        "end": 3165,
        "id": 934,
        "no_speech_prob": 0.000579289102461189,
        "seek": 313900,
        "start": 3163,
        "temperature": 0,
        "text": " Okay. So...",
        "tokens": [
          51564,
          1033,
          13,
          407,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3169,
        "id": 935,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3166,
        "temperature": 0,
        "text": " Okay. So, let's make our own tracery grammar.",
        "tokens": [
          50414,
          1033,
          13,
          407,
          11,
          718,
          311,
          652,
          527,
          1065,
          504,
          326,
          2109,
          22317,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3171,
        "id": 936,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3169,
        "temperature": 0,
        "text": " And then we'll come back to this one.",
        "tokens": [
          50564,
          400,
          550,
          321,
          603,
          808,
          646,
          281,
          341,
          472,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3173,
        "id": 937,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3171,
        "temperature": 0,
        "text": " Okay. So, what am I doing here?",
        "tokens": [
          50664,
          1033,
          13,
          407,
          11,
          437,
          669,
          286,
          884,
          510,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3176,
        "id": 938,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3173,
        "temperature": 0,
        "text": " I want to go to my example, which is over here.",
        "tokens": [
          50764,
          286,
          528,
          281,
          352,
          281,
          452,
          1365,
          11,
          597,
          307,
          670,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3177,
        "id": 939,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3176,
        "temperature": 0,
        "text": " This is some blank code.",
        "tokens": [
          50914,
          639,
          307,
          512,
          8247,
          3089,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3179,
        "id": 940,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3177,
        "temperature": 0,
        "text": " I'm going to go here, make sure it's running.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          352,
          510,
          11,
          652,
          988,
          309,
          311,
          2614,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3182,
        "id": 941,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3179,
        "temperature": 0,
        "text": " Great. So, the first thing I need to do is get that tracery library.",
        "tokens": [
          51064,
          3769,
          13,
          407,
          11,
          264,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          483,
          300,
          504,
          326,
          2109,
          6405,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3186,
        "id": 942,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3182,
        "temperature": 0,
        "text": " And tracery as a library is just this JavaScript file, tracery.js.",
        "tokens": [
          51214,
          400,
          504,
          326,
          2109,
          382,
          257,
          6405,
          307,
          445,
          341,
          15778,
          3991,
          11,
          504,
          326,
          2109,
          13,
          25530,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3190,
        "id": 943,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3186,
        "temperature": 0,
        "text": " So, I'm going to grab this file.",
        "tokens": [
          51414,
          407,
          11,
          286,
          478,
          516,
          281,
          4444,
          341,
          3991,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3192,
        "id": 944,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3190,
        "temperature": 0,
        "text": " And I'm going to do something silly, which is just copy.",
        "tokens": [
          51614,
          400,
          286,
          478,
          516,
          281,
          360,
          746,
          11774,
          11,
          597,
          307,
          445,
          5055,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.13991170837765649,
        "compression_ratio": 1.8076923076923077,
        "end": 3194,
        "id": 945,
        "no_speech_prob": 0.01717562973499298,
        "seek": 316500,
        "start": 3192,
        "temperature": 0,
        "text": " I could download it, but I'm just going to copy-paste it",
        "tokens": [
          51714,
          286,
          727,
          5484,
          309,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          5055,
          12,
          79,
          9079,
          309,
          51814
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3198,
        "id": 946,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3194,
        "temperature": 0,
        "text": " into a new file, which I'm going to call...",
        "tokens": [
          50364,
          666,
          257,
          777,
          3991,
          11,
          597,
          286,
          478,
          516,
          281,
          818,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3200,
        "id": 947,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3198,
        "temperature": 0,
        "text": " I guess I could have done this not in the video.",
        "tokens": [
          50564,
          286,
          2041,
          286,
          727,
          362,
          1096,
          341,
          406,
          294,
          264,
          960,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3203,
        "id": 948,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3200,
        "temperature": 0,
        "text": " Tracery.js. I'm going to copy it there.",
        "tokens": [
          50664,
          1765,
          326,
          2109,
          13,
          25530,
          13,
          286,
          478,
          516,
          281,
          5055,
          309,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3207,
        "id": 949,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3203,
        "temperature": 0,
        "text": " And then I need to make sure if I'm using another JavaScript library",
        "tokens": [
          50814,
          400,
          550,
          286,
          643,
          281,
          652,
          988,
          498,
          286,
          478,
          1228,
          1071,
          15778,
          6405,
          51014
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3212,
        "id": 950,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3207,
        "temperature": 0,
        "text": " that I want to make sure that I also reference it in the index.html file.",
        "tokens": [
          51014,
          300,
          286,
          528,
          281,
          652,
          988,
          300,
          286,
          611,
          6408,
          309,
          294,
          264,
          8186,
          13,
          357,
          15480,
          3991,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3216,
        "id": 951,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3212,
        "temperature": 0,
        "text": " So, just like I'm using p5.dom, I want to use tracery.",
        "tokens": [
          51264,
          407,
          11,
          445,
          411,
          286,
          478,
          1228,
          280,
          20,
          13,
          4121,
          11,
          286,
          528,
          281,
          764,
          504,
          326,
          2109,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3221,
        "id": 952,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3216,
        "temperature": 0,
        "text": " Now, another thing, actually, by the way, is tracery is dependent on jQuery.",
        "tokens": [
          51464,
          823,
          11,
          1071,
          551,
          11,
          767,
          11,
          538,
          264,
          636,
          11,
          307,
          504,
          326,
          2109,
          307,
          12334,
          322,
          361,
          35550,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14027987888881138,
        "compression_ratio": 1.6984732824427482,
        "end": 3223,
        "id": 953,
        "no_speech_prob": 0.005219954997301102,
        "seek": 319400,
        "start": 3221,
        "temperature": 0,
        "text": " So, it uses jQuery behind the scenes.",
        "tokens": [
          51714,
          407,
          11,
          309,
          4960,
          361,
          35550,
          2261,
          264,
          8026,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3229,
        "id": 954,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3223,
        "temperature": 0,
        "text": " So, I also should make sure I download and grab jQuery.",
        "tokens": [
          50364,
          407,
          11,
          286,
          611,
          820,
          652,
          988,
          286,
          5484,
          293,
          4444,
          361,
          35550,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3232,
        "id": 955,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3229,
        "temperature": 0,
        "text": " You could fast-forward ahead 30 seconds if you want.",
        "tokens": [
          50664,
          509,
          727,
          2370,
          12,
          13305,
          2286,
          2217,
          3949,
          498,
          291,
          528,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3234,
        "id": 956,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3232,
        "temperature": 0,
        "text": " Or maybe this will get edited out.",
        "tokens": [
          50814,
          1610,
          1310,
          341,
          486,
          483,
          23016,
          484,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3236,
        "id": 957,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3234,
        "temperature": 0,
        "text": " jQuery CDN.",
        "tokens": [
          50914,
          361,
          35550,
          6743,
          45,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3240,
        "id": 958,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3236,
        "temperature": 0,
        "text": " And I'm going to go here.",
        "tokens": [
          51014,
          400,
          286,
          478,
          516,
          281,
          352,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3241,
        "id": 959,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3240,
        "temperature": 0,
        "text": " Let's just use this.",
        "tokens": [
          51214,
          961,
          311,
          445,
          764,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3244,
        "id": 960,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3241,
        "temperature": 0,
        "text": " And copy. Copy to clipboard.",
        "tokens": [
          51264,
          400,
          5055,
          13,
          25653,
          281,
          7353,
          3787,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3247,
        "id": 961,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3244,
        "temperature": 0,
        "text": " And I should be able to paste it in here.",
        "tokens": [
          51414,
          400,
          286,
          820,
          312,
          1075,
          281,
          9163,
          309,
          294,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3248,
        "id": 962,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3247,
        "temperature": 0,
        "text": " That didn't work.",
        "tokens": [
          51564,
          663,
          994,
          380,
          589,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3249,
        "id": 963,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3248,
        "temperature": 0,
        "text": " I'm having this trouble today.",
        "tokens": [
          51614,
          286,
          478,
          1419,
          341,
          5253,
          965,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1772365737379643,
        "compression_ratio": 1.4849785407725322,
        "end": 3251,
        "id": 964,
        "no_speech_prob": 0.0012255546171218157,
        "seek": 322300,
        "start": 3249,
        "temperature": 0,
        "text": " Why does this not work?",
        "tokens": [
          51664,
          1545,
          775,
          341,
          406,
          589,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3253,
        "id": 965,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3251,
        "temperature": 0,
        "text": " This is driving me crazy.",
        "tokens": [
          50364,
          639,
          307,
          4840,
          385,
          3219,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3255,
        "id": 966,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3253,
        "temperature": 0,
        "text": " Maybe this will get edited out.",
        "tokens": [
          50464,
          2704,
          341,
          486,
          483,
          23016,
          484,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3258,
        "id": 967,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3255,
        "temperature": 0,
        "text": " Normally, I say that and it doesn't actually get edited out.",
        "tokens": [
          50564,
          17424,
          11,
          286,
          584,
          300,
          293,
          309,
          1177,
          380,
          767,
          483,
          23016,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3260,
        "id": 968,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3258,
        "temperature": 0,
        "text": " But this is actually something that could get edited out,",
        "tokens": [
          50714,
          583,
          341,
          307,
          767,
          746,
          300,
          727,
          483,
          23016,
          484,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3264,
        "id": 969,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3260,
        "temperature": 0,
        "text": " especially because I'm doing ridiculous, unnecessary things.",
        "tokens": [
          50814,
          2318,
          570,
          286,
          478,
          884,
          11083,
          11,
          19350,
          721,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3265,
        "id": 970,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3264,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3270,
        "id": 971,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3265,
        "temperature": 0,
        "text": " So, if this does get edited out, I'm coming back in.",
        "tokens": [
          51064,
          407,
          11,
          498,
          341,
          775,
          483,
          23016,
          484,
          11,
          286,
          478,
          1348,
          646,
          294,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3272,
        "id": 972,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3270,
        "temperature": 0,
        "text": " So, I also have a reference to jQuery here.",
        "tokens": [
          51314,
          407,
          11,
          286,
          611,
          362,
          257,
          6408,
          281,
          361,
          35550,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3275,
        "id": 973,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3272,
        "temperature": 0,
        "text": " One thing I'll note, by the way, is that you can reference JavaScript libraries",
        "tokens": [
          51414,
          1485,
          551,
          286,
          603,
          3637,
          11,
          538,
          264,
          636,
          11,
          307,
          300,
          291,
          393,
          6408,
          15778,
          15148,
          51564
        ]
      },
      {
        "avg_logprob": -0.16005197635366897,
        "compression_ratio": 1.7038461538461538,
        "end": 3277,
        "id": 974,
        "no_speech_prob": 0.0053018429316580296,
        "seek": 325100,
        "start": 3275,
        "temperature": 0,
        "text": " either as local files.",
        "tokens": [
          51564,
          2139,
          382,
          2654,
          7098,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3282,
        "id": 975,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3277,
        "temperature": 0,
        "text": " Like I have a local copy of p5.dom.js here in my folder.",
        "tokens": [
          50364,
          1743,
          286,
          362,
          257,
          2654,
          5055,
          295,
          280,
          20,
          13,
          4121,
          13,
          25530,
          510,
          294,
          452,
          10820,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3285,
        "id": 976,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3282,
        "temperature": 0,
        "text": " But you can also reference libraries through something called a CDN",
        "tokens": [
          50614,
          583,
          291,
          393,
          611,
          6408,
          15148,
          807,
          746,
          1219,
          257,
          6743,
          45,
          50764
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3287,
        "id": 977,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3285,
        "temperature": 0,
        "text": " or content delivery network.",
        "tokens": [
          50764,
          420,
          2701,
          8982,
          3209,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3289,
        "id": 978,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3287,
        "temperature": 0,
        "text": " Meaning, if it's a really popular library,",
        "tokens": [
          50864,
          19948,
          11,
          498,
          309,
          311,
          257,
          534,
          3743,
          6405,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3291,
        "id": 979,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3289,
        "temperature": 0,
        "text": " somebody might have just hosted it somewhere.",
        "tokens": [
          50964,
          2618,
          1062,
          362,
          445,
          19204,
          309,
          4079,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3293,
        "id": 980,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3291,
        "temperature": 0,
        "text": " Instead of having to download it, I could just reference the URL.",
        "tokens": [
          51064,
          7156,
          295,
          1419,
          281,
          5484,
          309,
          11,
          286,
          727,
          445,
          6408,
          264,
          12905,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3295,
        "id": 981,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3293,
        "temperature": 0,
        "text": " And, you know, there's good reasons for doing one or the other.",
        "tokens": [
          51164,
          400,
          11,
          291,
          458,
          11,
          456,
          311,
          665,
          4112,
          337,
          884,
          472,
          420,
          264,
          661,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3297,
        "id": 982,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3295,
        "temperature": 0,
        "text": " And I'm kind of mixing and matching here.",
        "tokens": [
          51264,
          400,
          286,
          478,
          733,
          295,
          11983,
          293,
          14324,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3298,
        "id": 983,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3297,
        "temperature": 0,
        "text": " But I just want to get stuff working.",
        "tokens": [
          51364,
          583,
          286,
          445,
          528,
          281,
          483,
          1507,
          1364,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3302,
        "id": 984,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3298,
        "temperature": 0,
        "text": " So, now I should have the Tracery library and the jQuery library.",
        "tokens": [
          51414,
          407,
          11,
          586,
          286,
          820,
          362,
          264,
          1765,
          326,
          2109,
          6405,
          293,
          264,
          361,
          35550,
          6405,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3305,
        "id": 985,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3302,
        "temperature": 0,
        "text": " And I'm ready to start making stuff happen with Tracery.",
        "tokens": [
          51614,
          400,
          286,
          478,
          1919,
          281,
          722,
          1455,
          1507,
          1051,
          365,
          1765,
          326,
          2109,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17094301733170977,
        "compression_ratio": 1.664756446991404,
        "end": 3306,
        "id": 986,
        "no_speech_prob": 0.045350056141614914,
        "seek": 327700,
        "start": 3305,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51764,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3310,
        "id": 987,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3306,
        "temperature": 0,
        "text": " So, let me at least just go here back to my example.",
        "tokens": [
          50364,
          407,
          11,
          718,
          385,
          412,
          1935,
          445,
          352,
          510,
          646,
          281,
          452,
          1365,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3312,
        "id": 988,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3310,
        "temperature": 0,
        "text": " And wherever that is, I lost it.",
        "tokens": [
          50564,
          400,
          8660,
          300,
          307,
          11,
          286,
          2731,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3313,
        "id": 989,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3312,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          50664,
          1692,
          309,
          307,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3314,
        "id": 990,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3313,
        "temperature": 0,
        "text": " I'm going to hit refresh.",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3317,
        "id": 991,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3314,
        "temperature": 0,
        "text": " And I'm going to go back to my code.",
        "tokens": [
          50764,
          400,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          3089,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3319,
        "id": 992,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3317,
        "temperature": 0,
        "text": " And what I want to do is start writing the grammar.",
        "tokens": [
          50914,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          722,
          3579,
          264,
          22317,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3324,
        "id": 993,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3319,
        "temperature": 0,
        "text": " So, I'm going to make a variable called – and let's make it a story.",
        "tokens": [
          51014,
          407,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          1662,
          293,
          718,
          311,
          652,
          309,
          257,
          1657,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3328,
        "id": 994,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3324,
        "temperature": 0,
        "text": " And what I need is to have – now, Tracery, by default,",
        "tokens": [
          51264,
          400,
          437,
          286,
          643,
          307,
          281,
          362,
          1662,
          586,
          11,
          1765,
          326,
          2109,
          11,
          538,
          7576,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3330,
        "id": 995,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3328,
        "temperature": 0,
        "text": " looks for something called start.",
        "tokens": [
          51464,
          1542,
          337,
          746,
          1219,
          722,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3332,
        "id": 996,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3330,
        "temperature": 0,
        "text": " So, I'm going to – you don't have to name it start,",
        "tokens": [
          51564,
          407,
          11,
          286,
          478,
          516,
          281,
          1662,
          291,
          500,
          380,
          362,
          281,
          1315,
          309,
          722,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.14182972263645482,
        "compression_ratio": 1.7829457364341086,
        "end": 3334,
        "id": 997,
        "no_speech_prob": 0.0013885160442441702,
        "seek": 330600,
        "start": 3332,
        "temperature": 0,
        "text": " but I'm going to call it start.",
        "tokens": [
          51664,
          457,
          286,
          478,
          516,
          281,
          818,
          309,
          722,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3337,
        "id": 998,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3334,
        "temperature": 0,
        "text": " I'm going to say start is – and I'm going to need the chat, by the way,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          722,
          307,
          1662,
          293,
          286,
          478,
          516,
          281,
          643,
          264,
          5081,
          11,
          538,
          264,
          636,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3340,
        "id": 999,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3337,
        "temperature": 0,
        "text": " to start giving me ideas for story things.",
        "tokens": [
          50514,
          281,
          722,
          2902,
          385,
          3487,
          337,
          1657,
          721,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3343,
        "id": 1000,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3340,
        "temperature": 0,
        "text": " But I guess I'll just be making this up as I go right now.",
        "tokens": [
          50664,
          583,
          286,
          2041,
          286,
          603,
          445,
          312,
          1455,
          341,
          493,
          382,
          286,
          352,
          558,
          586,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3347,
        "id": 1001,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3343,
        "temperature": 0,
        "text": " It was a dark and stormy night.",
        "tokens": [
          50814,
          467,
          390,
          257,
          2877,
          293,
          7679,
          88,
          1818,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3352,
        "id": 1002,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3347,
        "temperature": 0,
        "text": " So, now, if I have this JavaScript object, which essentially holds the grammar,",
        "tokens": [
          51014,
          407,
          11,
          586,
          11,
          498,
          286,
          362,
          341,
          15778,
          2657,
          11,
          597,
          4476,
          9190,
          264,
          22317,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3357,
        "id": 1003,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3352,
        "temperature": 0,
        "text": " I should be able to make a variable called grammar.",
        "tokens": [
          51264,
          286,
          820,
          312,
          1075,
          281,
          652,
          257,
          7006,
          1219,
          22317,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3358,
        "id": 1004,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3357,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          51514,
          31973,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3359,
        "id": 1005,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3358,
        "temperature": 0,
        "text": " How do you spell grammar?",
        "tokens": [
          51564,
          1012,
          360,
          291,
          9827,
          22317,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.16169692287925913,
        "compression_ratio": 1.4941634241245136,
        "end": 3362,
        "id": 1006,
        "no_speech_prob": 0.13116905093193054,
        "seek": 333400,
        "start": 3359,
        "temperature": 0,
        "text": " E-R or A-R?",
        "tokens": [
          51614,
          462,
          12,
          49,
          420,
          316,
          12,
          49,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3367,
        "id": 1007,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3362,
        "temperature": 0,
        "text": " It's A-R, right?",
        "tokens": [
          50364,
          467,
          311,
          316,
          12,
          49,
          11,
          558,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3368,
        "id": 1008,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3367,
        "temperature": 0,
        "text": " Grammar, grammar.",
        "tokens": [
          50614,
          22130,
          6209,
          11,
          22317,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3369,
        "id": 1009,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3368,
        "temperature": 0,
        "text": " It's got – oh, E-R.",
        "tokens": [
          50664,
          467,
          311,
          658,
          1662,
          1954,
          11,
          462,
          12,
          49,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3371,
        "id": 1010,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3369,
        "temperature": 0,
        "text": " Ah, E-R, A-R.",
        "tokens": [
          50714,
          2438,
          11,
          462,
          12,
          49,
          11,
          316,
          12,
          49,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3373,
        "id": 1011,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3371,
        "temperature": 0,
        "text": " How do you spell grammar?",
        "tokens": [
          50814,
          1012,
          360,
          291,
          9827,
          22317,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3377,
        "id": 1012,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3373,
        "temperature": 0,
        "text": " How do you spell grammar?",
        "tokens": [
          50914,
          1012,
          360,
          291,
          9827,
          22317,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3379,
        "id": 1013,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3377,
        "temperature": 0,
        "text": " Is it like – is this like an English or American thing?",
        "tokens": [
          51114,
          1119,
          309,
          411,
          1662,
          307,
          341,
          411,
          364,
          3669,
          420,
          2665,
          551,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3381,
        "id": 1014,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3379,
        "temperature": 0,
        "text": " No, A-R, I think.",
        "tokens": [
          51214,
          883,
          11,
          316,
          12,
          49,
          11,
          286,
          519,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3383,
        "id": 1015,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3381,
        "temperature": 0,
        "text": " Which one is the correct spelling?",
        "tokens": [
          51314,
          3013,
          472,
          307,
          264,
          3006,
          22254,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3388,
        "id": 1016,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3383,
        "temperature": 0,
        "text": " I'm going to use A-R because I think it's A-R.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          764,
          316,
          12,
          49,
          570,
          286,
          519,
          309,
          311,
          316,
          12,
          49,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3389,
        "id": 1017,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3388,
        "temperature": 0,
        "text": " You can all tell me in the chat.",
        "tokens": [
          51664,
          509,
          393,
          439,
          980,
          385,
          294,
          264,
          5081,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3390,
        "id": 1018,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3389,
        "temperature": 0,
        "text": " Yeah, A-R, A-R, A-R.",
        "tokens": [
          51714,
          865,
          11,
          316,
          12,
          49,
          11,
          316,
          12,
          49,
          11,
          316,
          12,
          49,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.13859024563351194,
        "compression_ratio": 1.6761904761904762,
        "end": 3391,
        "id": 1019,
        "no_speech_prob": 0.020023226737976074,
        "seek": 336200,
        "start": 3390,
        "temperature": 0,
        "text": " Yeah, yeah, yeah.",
        "tokens": [
          51764,
          865,
          11,
          1338,
          11,
          1338,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3392,
        "id": 1020,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3391,
        "temperature": 0,
        "text": " That will get edited out.",
        "tokens": [
          50364,
          663,
          486,
          483,
          23016,
          484,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3394,
        "id": 1021,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3392,
        "temperature": 0,
        "text": " Oops, I misspelled grammar.",
        "tokens": [
          50414,
          21726,
          11,
          286,
          1713,
          33000,
          22317,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3395,
        "id": 1022,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3394,
        "temperature": 0,
        "text": " A-R.",
        "tokens": [
          50514,
          316,
          12,
          49,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3398,
        "id": 1023,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3395,
        "temperature": 0,
        "text": " Okay, so I'm going to have a variable called grammar.",
        "tokens": [
          50564,
          1033,
          11,
          370,
          286,
          478,
          516,
          281,
          362,
          257,
          7006,
          1219,
          22317,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3403,
        "id": 1024,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3398,
        "temperature": 0,
        "text": " And I'm going to say grammar equals tracery.",
        "tokens": [
          50714,
          400,
          286,
          478,
          516,
          281,
          584,
          22317,
          6915,
          504,
          326,
          2109,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3406,
        "id": 1025,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3403,
        "temperature": 0,
        "text": " I think create grammar story.",
        "tokens": [
          50964,
          286,
          519,
          1884,
          22317,
          1657,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3408,
        "id": 1026,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3406,
        "temperature": 0,
        "text": " Boy, I don't actually remember if that's correct.",
        "tokens": [
          51114,
          9486,
          11,
          286,
          500,
          380,
          767,
          1604,
          498,
          300,
          311,
          3006,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3410,
        "id": 1027,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3408,
        "temperature": 0,
        "text": " So, one of the things when you're working with a JavaScript library",
        "tokens": [
          51214,
          407,
          11,
          472,
          295,
          264,
          721,
          562,
          291,
          434,
          1364,
          365,
          257,
          15778,
          6405,
          51314
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3412,
        "id": 1028,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3410,
        "temperature": 0,
        "text": " is you've got to look at documentation.",
        "tokens": [
          51314,
          307,
          291,
          600,
          658,
          281,
          574,
          412,
          14333,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3417,
        "id": 1029,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3412,
        "temperature": 0,
        "text": " So, I'm going to just go back to the GitHub page for tracery",
        "tokens": [
          51414,
          407,
          11,
          286,
          478,
          516,
          281,
          445,
          352,
          646,
          281,
          264,
          23331,
          3028,
          337,
          504,
          326,
          2109,
          51664
        ]
      },
      {
        "avg_logprob": -0.19381967702306302,
        "compression_ratio": 1.6336996336996337,
        "end": 3420,
        "id": 1030,
        "no_speech_prob": 0.02368897944688797,
        "seek": 339100,
        "start": 3417,
        "temperature": 0,
        "text": " and just to like kind of remind myself.",
        "tokens": [
          51664,
          293,
          445,
          281,
          411,
          733,
          295,
          4160,
          2059,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3423,
        "id": 1031,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3420,
        "temperature": 0,
        "text": " Yes, tracery.creategrammar spellbook.",
        "tokens": [
          50364,
          1079,
          11,
          504,
          326,
          2109,
          13,
          14066,
          473,
          1342,
          6209,
          9827,
          2939,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3427,
        "id": 1032,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3423,
        "temperature": 0,
        "text": " By the way, if you're looking for an idea, certain things like a cooking recipe",
        "tokens": [
          50514,
          3146,
          264,
          636,
          11,
          498,
          291,
          434,
          1237,
          337,
          364,
          1558,
          11,
          1629,
          721,
          411,
          257,
          6361,
          6782,
          50714
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3431,
        "id": 1033,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3427,
        "temperature": 0,
        "text": " or a spellbook, there's a wonderful Twitter bot called ArtAssignmentBot.",
        "tokens": [
          50714,
          420,
          257,
          9827,
          2939,
          11,
          456,
          311,
          257,
          3715,
          5794,
          10592,
          1219,
          5735,
          20892,
          41134,
          33,
          310,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3433,
        "id": 1034,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3431,
        "temperature": 0,
        "text": " I don't know that it uses a grammar.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          300,
          309,
          4960,
          257,
          22317,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3438,
        "id": 1035,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3433,
        "temperature": 0,
        "text": " But these kinds of highly structured types of narrative scenarios",
        "tokens": [
          51014,
          583,
          613,
          3685,
          295,
          5405,
          18519,
          3467,
          295,
          9977,
          15077,
          51264
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3443,
        "id": 1036,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3438,
        "temperature": 0,
        "text": " can work really well to have a grammar generate different possibilities.",
        "tokens": [
          51264,
          393,
          589,
          534,
          731,
          281,
          362,
          257,
          22317,
          8460,
          819,
          12178,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3446,
        "id": 1037,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3443,
        "temperature": 0,
        "text": " I'll also show you at some point that you can use a grammar to generate,",
        "tokens": [
          51514,
          286,
          603,
          611,
          855,
          291,
          412,
          512,
          935,
          300,
          291,
          393,
          764,
          257,
          22317,
          281,
          8460,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.19442966372467752,
        "compression_ratio": 1.7094594594594594,
        "end": 3449,
        "id": 1038,
        "no_speech_prob": 0.0043993559665977955,
        "seek": 342000,
        "start": 3446,
        "temperature": 0,
        "text": " you know, haiku patterns or certain patterns or certain syllables.",
        "tokens": [
          51664,
          291,
          458,
          11,
          324,
          24320,
          8294,
          420,
          1629,
          8294,
          420,
          1629,
          45364,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3451,
        "id": 1039,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3449,
        "temperature": 0,
        "text": " It's another way to use a grammar.",
        "tokens": [
          50364,
          467,
          311,
          1071,
          636,
          281,
          764,
          257,
          22317,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3454,
        "id": 1040,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3451,
        "temperature": 0,
        "text": " Okay. So, tracery.creategrammar story. Perfect.",
        "tokens": [
          50464,
          1033,
          13,
          407,
          11,
          504,
          326,
          2109,
          13,
          14066,
          473,
          1342,
          6209,
          1657,
          13,
          10246,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3457,
        "id": 1041,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3454,
        "temperature": 0,
        "text": " Now, what I want to say is story.",
        "tokens": [
          50614,
          823,
          11,
          437,
          286,
          528,
          281,
          584,
          307,
          1657,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3460,
        "id": 1042,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3457,
        "temperature": 0,
        "text": " I guess I called it story.",
        "tokens": [
          50764,
          286,
          2041,
          286,
          1219,
          309,
          1657,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3464,
        "id": 1043,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3460,
        "temperature": 0,
        "text": " Result, I'll call it, equals tracery.",
        "tokens": [
          50914,
          5015,
          723,
          11,
          286,
          603,
          818,
          309,
          11,
          6915,
          504,
          326,
          2109,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3466,
        "id": 1044,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3464,
        "temperature": 0,
        "text": " And let's look here.",
        "tokens": [
          51114,
          400,
          718,
          311,
          574,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3475,
        "id": 1045,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3466,
        "temperature": 0,
        "text": " I believe it's get expansion or create flattened.",
        "tokens": [
          51214,
          286,
          1697,
          309,
          311,
          483,
          11260,
          420,
          1884,
          24183,
          292,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3476,
        "id": 1046,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3475,
        "temperature": 0,
        "text": " Pause.",
        "tokens": [
          51664,
          31973,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16703529357910157,
        "compression_ratio": 1.4736842105263157,
        "end": 3477,
        "id": 1047,
        "no_speech_prob": 0.002082959981635213,
        "seek": 344900,
        "start": 3476,
        "temperature": 0,
        "text": " Let me just look up.",
        "tokens": [
          51714,
          961,
          385,
          445,
          574,
          493,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3479,
        "id": 1048,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3477,
        "temperature": 0,
        "text": " There's a bunch of different ways of doing this.",
        "tokens": [
          50364,
          821,
          311,
          257,
          3840,
          295,
          819,
          2098,
          295,
          884,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3483,
        "id": 1049,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3479,
        "temperature": 0,
        "text": " And because this is actually...",
        "tokens": [
          50464,
          400,
          570,
          341,
          307,
          767,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3487,
        "id": 1050,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3483,
        "temperature": 0,
        "text": " Hold on. Time out. I'm going to edit this back.",
        "tokens": [
          50664,
          6962,
          322,
          13,
          6161,
          484,
          13,
          286,
          478,
          516,
          281,
          8129,
          341,
          646,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3489,
        "id": 1051,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3487,
        "temperature": 0,
        "text": " I'm going to go back from where I typed that.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          352,
          646,
          490,
          689,
          286,
          33941,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3491,
        "id": 1052,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3489,
        "temperature": 0,
        "text": " Sorry, Matthew. This is going to be a lot of editing, this one.",
        "tokens": [
          50964,
          4919,
          11,
          6789,
          3322,
          86,
          13,
          639,
          307,
          516,
          281,
          312,
          257,
          688,
          295,
          10000,
          11,
          341,
          472,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3492,
        "id": 1053,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3491,
        "temperature": 0,
        "text": " I apologize.",
        "tokens": [
          51064,
          286,
          12328,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3498,
        "id": 1054,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3492,
        "temperature": 0,
        "text": " I just want to look at how I did it in this one.",
        "tokens": [
          51114,
          286,
          445,
          528,
          281,
          574,
          412,
          577,
          286,
          630,
          309,
          294,
          341,
          472,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3501,
        "id": 1055,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3498,
        "temperature": 0,
        "text": " Flatten. That's what I thought. Grammar.flatten.",
        "tokens": [
          51414,
          3235,
          32733,
          13,
          663,
          311,
          437,
          286,
          1194,
          13,
          22130,
          6209,
          13,
          3423,
          32733,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20701376597086588,
        "compression_ratio": 1.6962025316455696,
        "end": 3506,
        "id": 1056,
        "no_speech_prob": 0.056650735437870026,
        "seek": 347700,
        "start": 3501,
        "temperature": 0,
        "text": " There's a bunch of different functions. Okay. Sorry.",
        "tokens": [
          51564,
          821,
          311,
          257,
          3840,
          295,
          819,
          6828,
          13,
          1033,
          13,
          4919,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3509,
        "id": 1057,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3506,
        "temperature": 0,
        "text": " So, now I want to look at the result.",
        "tokens": [
          50364,
          407,
          11,
          586,
          286,
          528,
          281,
          574,
          412,
          264,
          1874,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3514,
        "id": 1058,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3509,
        "temperature": 0,
        "text": " And I'll say var result equals grammar.flatten.",
        "tokens": [
          50514,
          400,
          286,
          603,
          584,
          1374,
          1874,
          6915,
          22317,
          13,
          3423,
          32733,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3518,
        "id": 1059,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3514,
        "temperature": 0,
        "text": " So, again, why the word flatten?",
        "tokens": [
          50764,
          407,
          11,
          797,
          11,
          983,
          264,
          1349,
          24183,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3521,
        "id": 1060,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3518,
        "temperature": 0,
        "text": " So, there's two words that involve generating text from a grammar.",
        "tokens": [
          50964,
          407,
          11,
          456,
          311,
          732,
          2283,
          300,
          9494,
          17746,
          2487,
          490,
          257,
          22317,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3523,
        "id": 1061,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3521,
        "temperature": 0,
        "text": " One is expansion and the other is flatten.",
        "tokens": [
          51114,
          1485,
          307,
          11260,
          293,
          264,
          661,
          307,
          24183,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3525,
        "id": 1062,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3523,
        "temperature": 0,
        "text": " So, this is the idea of an... Where am I here?",
        "tokens": [
          51214,
          407,
          11,
          341,
          307,
          264,
          1558,
          295,
          364,
          485,
          2305,
          669,
          286,
          510,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3527,
        "id": 1063,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3525,
        "temperature": 0,
        "text": " This is the idea of an expansion, right?",
        "tokens": [
          51314,
          639,
          307,
          264,
          1558,
          295,
          364,
          11260,
          11,
          558,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.19916439056396484,
        "compression_ratio": 1.6887966804979253,
        "end": 3533,
        "id": 1064,
        "no_speech_prob": 0.004468333441764116,
        "seek": 350600,
        "start": 3527,
        "temperature": 0,
        "text": " I'm expanding out from the sort of start and iteratively applying these replacement rules.",
        "tokens": [
          51414,
          286,
          478,
          14702,
          484,
          490,
          264,
          1333,
          295,
          722,
          293,
          17138,
          19020,
          9275,
          613,
          14419,
          4474,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3539,
        "id": 1065,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3533,
        "temperature": 0,
        "text": " Now, tracery behind the scenes or any grammar system is probably keeping track of the entire tree that's being generated.",
        "tokens": [
          50364,
          823,
          11,
          504,
          326,
          2109,
          2261,
          264,
          8026,
          420,
          604,
          22317,
          1185,
          307,
          1391,
          5145,
          2837,
          295,
          264,
          2302,
          4230,
          300,
          311,
          885,
          10833,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3541,
        "id": 1066,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3539,
        "temperature": 0,
        "text": " But all I want is the end result.",
        "tokens": [
          50664,
          583,
          439,
          286,
          528,
          307,
          264,
          917,
          1874,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3543,
        "id": 1067,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3541,
        "temperature": 0,
        "text": " So, I want to flatten it and get the end result.",
        "tokens": [
          50764,
          407,
          11,
          286,
          528,
          281,
          24183,
          309,
          293,
          483,
          264,
          917,
          1874,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3545,
        "id": 1068,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3543,
        "temperature": 0,
        "text": " And that's what's happening over here.",
        "tokens": [
          50864,
          400,
          300,
          311,
          437,
          311,
          2737,
          670,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3550,
        "id": 1069,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3545,
        "temperature": 0,
        "text": " So, I can say console.log result.",
        "tokens": [
          50964,
          407,
          11,
          286,
          393,
          584,
          11076,
          13,
          4987,
          1874,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3554,
        "id": 1070,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3550,
        "temperature": 0,
        "text": " And if I run this, come back to my example.",
        "tokens": [
          51214,
          400,
          498,
          286,
          1190,
          341,
          11,
          808,
          646,
          281,
          452,
          1365,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3556,
        "id": 1071,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3554,
        "temperature": 0,
        "text": " That didn't work.",
        "tokens": [
          51414,
          663,
          994,
          380,
          589,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3558,
        "id": 1072,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3556,
        "temperature": 0,
        "text": " Now, I thought it would automatically use start.",
        "tokens": [
          51514,
          823,
          11,
          286,
          1194,
          309,
          576,
          6772,
          764,
          722,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16170870247533767,
        "compression_ratio": 1.6047430830039526,
        "end": 3560,
        "id": 1073,
        "no_speech_prob": 0.037325918674468994,
        "seek": 353300,
        "start": 3558,
        "temperature": 0,
        "text": " Maybe it doesn't.",
        "tokens": [
          51614,
          2704,
          309,
          1177,
          380,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3563,
        "id": 1074,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3560,
        "temperature": 0,
        "text": " So, I'm going to add this in there.",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          516,
          281,
          909,
          341,
          294,
          456,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3565,
        "id": 1075,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3563,
        "temperature": 0,
        "text": " Oh, yeah. Okay.",
        "tokens": [
          50514,
          876,
          11,
          1338,
          13,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3568,
        "id": 1076,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3565,
        "temperature": 0,
        "text": " So, I had mistakenly... Oh, maybe it's origin.",
        "tokens": [
          50614,
          407,
          11,
          286,
          632,
          21333,
          356,
          485,
          876,
          11,
          1310,
          309,
          311,
          4957,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3572,
        "id": 1077,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3568,
        "temperature": 0,
        "text": " I think tracery uses the keyword origin as the automatic.",
        "tokens": [
          50764,
          286,
          519,
          504,
          326,
          2109,
          4960,
          264,
          20428,
          4957,
          382,
          264,
          12509,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3574,
        "id": 1078,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3572,
        "temperature": 0,
        "text": " And I just used start in my example.",
        "tokens": [
          50964,
          400,
          286,
          445,
          1143,
          722,
          294,
          452,
          1365,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3577,
        "id": 1079,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3574,
        "temperature": 0,
        "text": " So, let me... Nope.",
        "tokens": [
          51064,
          407,
          11,
          718,
          385,
          485,
          12172,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3579,
        "id": 1080,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3577,
        "temperature": 0,
        "text": " I imagined that too. Okay.",
        "tokens": [
          51214,
          286,
          16590,
          300,
          886,
          13,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3581,
        "id": 1081,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3579,
        "temperature": 0,
        "text": " So, I don't know. I thought we could look at the documentation later.",
        "tokens": [
          51314,
          407,
          11,
          286,
          500,
          380,
          458,
          13,
          286,
          1194,
          321,
          727,
          574,
          412,
          264,
          14333,
          1780,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3583,
        "id": 1082,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3581,
        "temperature": 0,
        "text": " Boy, this is going well.",
        "tokens": [
          51414,
          9486,
          11,
          341,
          307,
          516,
          731,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19698813704193616,
        "compression_ratio": 1.6008583690987124,
        "end": 3586,
        "id": 1083,
        "no_speech_prob": 0.06008410081267357,
        "seek": 356000,
        "start": 3583,
        "temperature": 0,
        "text": " But the point is it doesn't really...",
        "tokens": [
          51514,
          583,
          264,
          935,
          307,
          309,
          1177,
          380,
          534,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.23352445405105066,
        "compression_ratio": 1.535,
        "end": 3591,
        "id": 1084,
        "no_speech_prob": 0.008577210828661919,
        "seek": 358600,
        "start": 3586,
        "temperature": 0,
        "text": " Come back to me, code. Help.",
        "tokens": [
          50364,
          2492,
          646,
          281,
          385,
          11,
          3089,
          13,
          10773,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23352445405105066,
        "compression_ratio": 1.535,
        "end": 3594,
        "id": 1085,
        "no_speech_prob": 0.008577210828661919,
        "seek": 358600,
        "start": 3591,
        "temperature": 0,
        "text": " Let me make sure this is working again.",
        "tokens": [
          50614,
          961,
          385,
          652,
          988,
          341,
          307,
          1364,
          797,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23352445405105066,
        "compression_ratio": 1.535,
        "end": 3601,
        "id": 1086,
        "no_speech_prob": 0.008577210828661919,
        "seek": 358600,
        "start": 3594,
        "temperature": 0,
        "text": " Okay. The point is what I want is to give that axiom, that seed phrase start in...",
        "tokens": [
          50764,
          1033,
          13,
          440,
          935,
          307,
          437,
          286,
          528,
          307,
          281,
          976,
          300,
          6360,
          72,
          298,
          11,
          300,
          8871,
          9535,
          722,
          294,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.23352445405105066,
        "compression_ratio": 1.535,
        "end": 3603,
        "id": 1087,
        "no_speech_prob": 0.008577210828661919,
        "seek": 358600,
        "start": 3601,
        "temperature": 0,
        "text": " I want to pass that to the grammar.",
        "tokens": [
          51114,
          286,
          528,
          281,
          1320,
          300,
          281,
          264,
          22317,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23352445405105066,
        "compression_ratio": 1.535,
        "end": 3610,
        "id": 1088,
        "no_speech_prob": 0.008577210828661919,
        "seek": 358600,
        "start": 3603,
        "temperature": 0,
        "text": " And the grammar object, the tracery grammar object, is then going to expand it out based on all those production rules.",
        "tokens": [
          51214,
          400,
          264,
          22317,
          2657,
          11,
          264,
          504,
          326,
          2109,
          22317,
          2657,
          11,
          307,
          550,
          516,
          281,
          5268,
          309,
          484,
          2361,
          322,
          439,
          729,
          4265,
          4474,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3618,
        "id": 1089,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3610,
        "temperature": 0,
        "text": " Now, right now... And you'll notice that the syntax for tracery, specifically, is a non-terminal element.",
        "tokens": [
          50364,
          823,
          11,
          558,
          586,
          485,
          400,
          291,
          603,
          3449,
          300,
          264,
          28431,
          337,
          504,
          326,
          2109,
          11,
          4682,
          11,
          307,
          257,
          2107,
          12,
          7039,
          2071,
          4478,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3622,
        "id": 1090,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3618,
        "temperature": 0,
        "text": " It's wrapped in the pound or hash symbol.",
        "tokens": [
          50764,
          467,
          311,
          14226,
          294,
          264,
          12013,
          420,
          22019,
          5986,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3626,
        "id": 1091,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3622,
        "temperature": 0,
        "text": " So, this means please replace me as opposed to the word start.",
        "tokens": [
          50964,
          407,
          11,
          341,
          1355,
          1767,
          7406,
          385,
          382,
          8851,
          281,
          264,
          1349,
          722,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3635,
        "id": 1092,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3626,
        "temperature": 0,
        "text": " And so, if I did something like this, we would have a real problem because this would kind of generate to infinity.",
        "tokens": [
          51164,
          400,
          370,
          11,
          498,
          286,
          630,
          746,
          411,
          341,
          11,
          321,
          576,
          362,
          257,
          957,
          1154,
          570,
          341,
          576,
          733,
          295,
          8460,
          281,
          13202,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3636,
        "id": 1093,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3635,
        "temperature": 0,
        "text": " I almost want to run it to see what happens.",
        "tokens": [
          51614,
          286,
          1920,
          528,
          281,
          1190,
          309,
          281,
          536,
          437,
          2314,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3637,
        "id": 1094,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3636,
        "temperature": 0,
        "text": " I do. Let's just do it.",
        "tokens": [
          51664,
          286,
          360,
          13,
          961,
          311,
          445,
          360,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19649212419494125,
        "compression_ratio": 1.5818181818181818,
        "end": 3639,
        "id": 1095,
        "no_speech_prob": 0.04146023467183113,
        "seek": 361000,
        "start": 3637,
        "temperature": 0,
        "text": " What's the worst thing that can happen?",
        "tokens": [
          51714,
          708,
          311,
          264,
          5855,
          551,
          300,
          393,
          1051,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3641,
        "id": 1096,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3639,
        "temperature": 0,
        "text": " Maximum cost tag received.",
        "tokens": [
          50364,
          29076,
          449,
          2063,
          6162,
          4613,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3643,
        "id": 1097,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3641,
        "temperature": 0,
        "text": " So, you can see that this idea of replacing.",
        "tokens": [
          50464,
          407,
          11,
          291,
          393,
          536,
          300,
          341,
          1558,
          295,
          19139,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3648,
        "id": 1098,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3643,
        "temperature": 0,
        "text": " But what I can do is say it was an... And I can say adjective.",
        "tokens": [
          50564,
          583,
          437,
          286,
          393,
          360,
          307,
          584,
          309,
          390,
          364,
          485,
          400,
          286,
          393,
          584,
          44129,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3650,
        "id": 1099,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3648,
        "temperature": 0,
        "text": " And then I could add another rule.",
        "tokens": [
          50814,
          400,
          550,
          286,
          727,
          909,
          1071,
          4978,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3654,
        "id": 1100,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3650,
        "temperature": 0,
        "text": " Adjective, some possibilities are...",
        "tokens": [
          50914,
          1999,
          1020,
          488,
          11,
          512,
          12178,
          366,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3659,
        "id": 1101,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3654,
        "temperature": 0,
        "text": " It was a dark.",
        "tokens": [
          51114,
          467,
          390,
          257,
          2877,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3662,
        "id": 1102,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3659,
        "temperature": 0,
        "text": " Shout out your adjectives in the live chat that's going on right now.",
        "tokens": [
          51364,
          32749,
          484,
          428,
          29378,
          1539,
          294,
          264,
          1621,
          5081,
          300,
          311,
          516,
          322,
          558,
          586,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3665,
        "id": 1103,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3662,
        "temperature": 0,
        "text": " Dark.",
        "tokens": [
          51514,
          9563,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.26720798376834753,
        "compression_ratio": 1.5658536585365854,
        "end": 3667,
        "id": 1104,
        "no_speech_prob": 0.02800678461790085,
        "seek": 363900,
        "start": 3665,
        "temperature": 0,
        "text": " Sleepy, somebody wrote.",
        "tokens": [
          51664,
          19383,
          88,
          11,
          2618,
          4114,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3670,
        "id": 1105,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3667,
        "temperature": 0,
        "text": " It was a quiet.",
        "tokens": [
          50364,
          467,
          390,
          257,
          5677,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3676,
        "id": 1106,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3670,
        "temperature": 0,
        "text": " So, right. If I give all these adjectives now, now I have two non-terminal characters.",
        "tokens": [
          50514,
          407,
          11,
          558,
          13,
          759,
          286,
          976,
          439,
          613,
          29378,
          1539,
          586,
          11,
          586,
          286,
          362,
          732,
          2107,
          12,
          7039,
          2071,
          4342,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3678,
        "id": 1107,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3676,
        "temperature": 0,
        "text": " Elements, I should say. They're not characters.",
        "tokens": [
          50814,
          8024,
          1117,
          11,
          286,
          820,
          584,
          13,
          814,
          434,
          406,
          4342,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3680,
        "id": 1108,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3678,
        "temperature": 0,
        "text": " Start, which generates this sentence.",
        "tokens": [
          50914,
          6481,
          11,
          597,
          23815,
          341,
          8174,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3684,
        "id": 1109,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3680,
        "temperature": 0,
        "text": " Adjectives, which has three possibilities.",
        "tokens": [
          51014,
          1999,
          1020,
          1539,
          11,
          597,
          575,
          1045,
          12178,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3688,
        "id": 1110,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3684,
        "temperature": 0,
        "text": " And so, now if I run this, you can see it was a sleepy and stormy night.",
        "tokens": [
          51214,
          400,
          370,
          11,
          586,
          498,
          286,
          1190,
          341,
          11,
          291,
          393,
          536,
          309,
          390,
          257,
          24908,
          293,
          7679,
          88,
          1818,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3691,
        "id": 1111,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3688,
        "temperature": 0,
        "text": " It was a sleepy. It was a dark. It was a sleepy. It was a sleepy. It was a quiet.",
        "tokens": [
          51414,
          467,
          390,
          257,
          24908,
          13,
          467,
          390,
          257,
          2877,
          13,
          467,
          390,
          257,
          24908,
          13,
          467,
          390,
          257,
          24908,
          13,
          467,
          390,
          257,
          5677,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16255321359275876,
        "compression_ratio": 1.839662447257384,
        "end": 3695,
        "id": 1112,
        "no_speech_prob": 0.11123532056808472,
        "seek": 366700,
        "start": 3691,
        "temperature": 0,
        "text": " So, each time I refresh, I get a new possibility.",
        "tokens": [
          51564,
          407,
          11,
          1184,
          565,
          286,
          15134,
          11,
          286,
          483,
          257,
          777,
          7959,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22379841524011948,
        "compression_ratio": 1.6431372549019607,
        "end": 3701,
        "id": 1113,
        "no_speech_prob": 0.014727793633937836,
        "seek": 369500,
        "start": 3695,
        "temperature": 0,
        "text": " Okay. So, this is level one here of using a tracery grammar.",
        "tokens": [
          50364,
          1033,
          13,
          407,
          11,
          341,
          307,
          1496,
          472,
          510,
          295,
          1228,
          257,
          504,
          326,
          2109,
          22317,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22379841524011948,
        "compression_ratio": 1.6431372549019607,
        "end": 3704,
        "id": 1114,
        "no_speech_prob": 0.014727793633937836,
        "seek": 369500,
        "start": 3701,
        "temperature": 0,
        "text": " And even this is like plenty to play with.",
        "tokens": [
          50664,
          400,
          754,
          341,
          307,
          411,
          7140,
          281,
          862,
          365,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22379841524011948,
        "compression_ratio": 1.6431372549019607,
        "end": 3709,
        "id": 1115,
        "no_speech_prob": 0.014727793633937836,
        "seek": 369500,
        "start": 3704,
        "temperature": 0,
        "text": " One thing I should mention is that each one of these has a one out of three chance of being picked.",
        "tokens": [
          50814,
          1485,
          551,
          286,
          820,
          2152,
          307,
          300,
          1184,
          472,
          295,
          613,
          575,
          257,
          472,
          484,
          295,
          1045,
          2931,
          295,
          885,
          6183,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22379841524011948,
        "compression_ratio": 1.6431372549019607,
        "end": 3714,
        "id": 1116,
        "no_speech_prob": 0.014727793633937836,
        "seek": 369500,
        "start": 3709,
        "temperature": 0,
        "text": " And another reason why you might use a system or modify tracery...",
        "tokens": [
          51064,
          400,
          1071,
          1778,
          983,
          291,
          1062,
          764,
          257,
          1185,
          420,
          16927,
          504,
          326,
          2109,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.22379841524011948,
        "compression_ratio": 1.6431372549019607,
        "end": 3718,
        "id": 1117,
        "no_speech_prob": 0.014727793633937836,
        "seek": 369500,
        "start": 3714,
        "temperature": 0,
        "text": " Think about programming your own sort of grammar generation system from scratch.",
        "tokens": [
          51314,
          6557,
          466,
          9410,
          428,
          1065,
          1333,
          295,
          22317,
          5125,
          1185,
          490,
          8459,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22379841524011948,
        "compression_ratio": 1.6431372549019607,
        "end": 3721,
        "id": 1118,
        "no_speech_prob": 0.014727793633937836,
        "seek": 369500,
        "start": 3718,
        "temperature": 0,
        "text": " You might be interested in playing around with those probabilities.",
        "tokens": [
          51514,
          509,
          1062,
          312,
          3102,
          294,
          2433,
          926,
          365,
          729,
          33783,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3725,
        "id": 1119,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3721,
        "temperature": 0,
        "text": " What if it's 60... But, of course, I could do that also right here by just...",
        "tokens": [
          50364,
          708,
          498,
          309,
          311,
          4060,
          485,
          583,
          11,
          295,
          1164,
          11,
          286,
          727,
          360,
          300,
          611,
          558,
          510,
          538,
          445,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3729,
        "id": 1120,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3725,
        "temperature": 0,
        "text": " Now I've played with the probabilities that dark has a 50% chance of being picked,",
        "tokens": [
          50564,
          823,
          286,
          600,
          3737,
          365,
          264,
          33783,
          300,
          2877,
          575,
          257,
          2625,
          4,
          2931,
          295,
          885,
          6183,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3732,
        "id": 1121,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3729,
        "temperature": 0,
        "text": " whereas sleepy and quiet only have a 25% chance of being picked.",
        "tokens": [
          50764,
          9735,
          24908,
          293,
          5677,
          787,
          362,
          257,
          3552,
          4,
          2931,
          295,
          885,
          6183,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3735,
        "id": 1122,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3732,
        "temperature": 0,
        "text": " Okay. So, let's write a story with a character.",
        "tokens": [
          50914,
          1033,
          13,
          407,
          11,
          718,
          311,
          2464,
          257,
          1657,
          365,
          257,
          2517,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3738,
        "id": 1123,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3735,
        "temperature": 0,
        "text": " And what I'm going to do, actually, I'm going to do something different.",
        "tokens": [
          51064,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          767,
          11,
          286,
          478,
          516,
          281,
          360,
          746,
          819,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3740,
        "id": 1124,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3738,
        "temperature": 0,
        "text": " I'm going to say I'm going to have a story.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          584,
          286,
          478,
          516,
          281,
          362,
          257,
          1657,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3747,
        "id": 1125,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3740,
        "temperature": 0,
        "text": " And I'm going to just use the same kind of story that my children wrote last night,",
        "tokens": [
          51314,
          400,
          286,
          478,
          516,
          281,
          445,
          764,
          264,
          912,
          733,
          295,
          1657,
          300,
          452,
          2227,
          4114,
          1036,
          1818,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.21619340818222255,
        "compression_ratio": 1.7448979591836735,
        "end": 3749,
        "id": 1126,
        "no_speech_prob": 0.3665288984775543,
        "seek": 372100,
        "start": 3747,
        "temperature": 0,
        "text": " which is a... And I'll call it a hero.",
        "tokens": [
          51664,
          597,
          307,
          257,
          485,
          400,
          286,
          603,
          818,
          309,
          257,
          5316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17546729783754092,
        "compression_ratio": 1.4871794871794872,
        "end": 3755,
        "id": 1127,
        "no_speech_prob": 0.04958618804812431,
        "seek": 374900,
        "start": 3749,
        "temperature": 0,
        "text": " A hero fights the monster. Go, hero, go.",
        "tokens": [
          50364,
          316,
          5316,
          14512,
          264,
          10090,
          13,
          1037,
          11,
          5316,
          11,
          352,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17546729783754092,
        "compression_ratio": 1.4871794871794872,
        "end": 3761,
        "id": 1128,
        "no_speech_prob": 0.04958618804812431,
        "seek": 374900,
        "start": 3755,
        "temperature": 0,
        "text": " But what I want is for this hero to be picked.",
        "tokens": [
          50664,
          583,
          437,
          286,
          528,
          307,
          337,
          341,
          5316,
          281,
          312,
          6183,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17546729783754092,
        "compression_ratio": 1.4871794871794872,
        "end": 3766,
        "id": 1129,
        "no_speech_prob": 0.04958618804812431,
        "seek": 374900,
        "start": 3761,
        "temperature": 0,
        "text": " So, what I... And I'm running out of space here, so let me open this up a little bit.",
        "tokens": [
          50964,
          407,
          11,
          437,
          286,
          485,
          400,
          286,
          478,
          2614,
          484,
          295,
          1901,
          510,
          11,
          370,
          718,
          385,
          1269,
          341,
          493,
          257,
          707,
          857,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17546729783754092,
        "compression_ratio": 1.4871794871794872,
        "end": 3772,
        "id": 1130,
        "no_speech_prob": 0.04958618804812431,
        "seek": 374900,
        "start": 3766,
        "temperature": 0,
        "text": " What I want is... So, let me give some options for a hero.",
        "tokens": [
          51214,
          708,
          286,
          528,
          307,
          485,
          407,
          11,
          718,
          385,
          976,
          512,
          3956,
          337,
          257,
          5316,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.33021714137150693,
        "compression_ratio": 1.503030303030303,
        "end": 3782,
        "id": 1131,
        "no_speech_prob": 0.15404222905635834,
        "seek": 377200,
        "start": 3772,
        "temperature": 0,
        "text": " And I'm going to say dragon, fairy, amusing... The same... I don't know.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          584,
          12165,
          11,
          19104,
          11,
          47809,
          485,
          440,
          912,
          485,
          286,
          500,
          380,
          458,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.33021714137150693,
        "compression_ratio": 1.503030303030303,
        "end": 3785,
        "id": 1132,
        "no_speech_prob": 0.15404222905635834,
        "seek": 377200,
        "start": 3782,
        "temperature": 0,
        "text": " I don't know why that makes sense. Character... You know, I don't...",
        "tokens": [
          50864,
          286,
          500,
          380,
          458,
          983,
          300,
          1669,
          2020,
          13,
          36786,
          485,
          509,
          458,
          11,
          286,
          500,
          380,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.33021714137150693,
        "compression_ratio": 1.503030303030303,
        "end": 3791,
        "id": 1133,
        "no_speech_prob": 0.15404222905635834,
        "seek": 377200,
        "start": 3785,
        "temperature": 0,
        "text": " Let me just... Pause. Let me go back. Let me make this different.",
        "tokens": [
          51014,
          961,
          385,
          445,
          485,
          31973,
          13,
          961,
          385,
          352,
          646,
          13,
          961,
          385,
          652,
          341,
          819,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.33021714137150693,
        "compression_ratio": 1.503030303030303,
        "end": 3796,
        "id": 1134,
        "no_speech_prob": 0.15404222905635834,
        "seek": 377200,
        "start": 3791,
        "temperature": 0,
        "text": " Unicorn. Yes, unicorn. Okay, okay, okay.",
        "tokens": [
          51314,
          1156,
          23115,
          13,
          1079,
          11,
          28122,
          13,
          1033,
          11,
          1392,
          11,
          1392,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3081649405057313,
        "compression_ratio": 1.34375,
        "end": 3806,
        "id": 1135,
        "no_speech_prob": 0.0226285383105278,
        "seek": 379600,
        "start": 3797,
        "temperature": 0,
        "text": " Dragon. Unicorn. Rainbow. Etc.",
        "tokens": [
          50414,
          11517,
          13,
          1156,
          23115,
          13,
          29477,
          13,
          3790,
          66,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3081649405057313,
        "compression_ratio": 1.34375,
        "end": 3808,
        "id": 1136,
        "no_speech_prob": 0.0226285383105278,
        "seek": 379600,
        "start": 3806,
        "temperature": 0,
        "text": " Okay, so these are my possible heroes.",
        "tokens": [
          50864,
          1033,
          11,
          370,
          613,
          366,
          452,
          1944,
          12332,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3081649405057313,
        "compression_ratio": 1.34375,
        "end": 3810,
        "id": 1137,
        "no_speech_prob": 0.0226285383105278,
        "seek": 379600,
        "start": 3808,
        "temperature": 0,
        "text": " And I want the story... I lost the story.",
        "tokens": [
          50964,
          400,
          286,
          528,
          264,
          1657,
          485,
          286,
          2731,
          264,
          1657,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3081649405057313,
        "compression_ratio": 1.34375,
        "end": 3814,
        "id": 1138,
        "no_speech_prob": 0.0226285383105278,
        "seek": 379600,
        "start": 3810,
        "temperature": 0,
        "text": " I want to say story... Wait, hold on.",
        "tokens": [
          51064,
          286,
          528,
          281,
          584,
          1657,
          485,
          3802,
          11,
          1797,
          322,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3081649405057313,
        "compression_ratio": 1.34375,
        "end": 3820,
        "id": 1139,
        "no_speech_prob": 0.0226285383105278,
        "seek": 379600,
        "start": 3814,
        "temperature": 0,
        "text": " Ah! I have to go back.",
        "tokens": [
          51264,
          2438,
          0,
          286,
          362,
          281,
          352,
          646,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23696765565035635,
        "compression_ratio": 1.7142857142857142,
        "end": 3825,
        "id": 1140,
        "no_speech_prob": 0.2173157036304474,
        "seek": 382000,
        "start": 3820,
        "temperature": 0,
        "text": " Matt, you can cleverly edit, but I'm just going to go from dragon to unicorn.",
        "tokens": [
          50364,
          7397,
          11,
          291,
          393,
          13494,
          356,
          8129,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          352,
          490,
          12165,
          281,
          28122,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23696765565035635,
        "compression_ratio": 1.7142857142857142,
        "end": 3831,
        "id": 1141,
        "no_speech_prob": 0.2173157036304474,
        "seek": 382000,
        "start": 3825,
        "temperature": 0,
        "text": " Dragon, unicorn, rainbow. These are the possible heroes.",
        "tokens": [
          50614,
          11517,
          11,
          28122,
          11,
          18526,
          13,
          1981,
          366,
          264,
          1944,
          12332,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23696765565035635,
        "compression_ratio": 1.7142857142857142,
        "end": 3836,
        "id": 1142,
        "no_speech_prob": 0.2173157036304474,
        "seek": 382000,
        "start": 3831,
        "temperature": 0,
        "text": " Okay? So, the story is a hero fights the monster. Go, hero, go.",
        "tokens": [
          50914,
          1033,
          30,
          407,
          11,
          264,
          1657,
          307,
          257,
          5316,
          14512,
          264,
          10090,
          13,
          1037,
          11,
          5316,
          11,
          352,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23696765565035635,
        "compression_ratio": 1.7142857142857142,
        "end": 3841,
        "id": 1143,
        "no_speech_prob": 0.2173157036304474,
        "seek": 382000,
        "start": 3836,
        "temperature": 0,
        "text": " So, what I'm going to do now is I am going to change this to story.",
        "tokens": [
          51164,
          407,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          286,
          669,
          516,
          281,
          1319,
          341,
          281,
          1657,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23696765565035635,
        "compression_ratio": 1.7142857142857142,
        "end": 3845,
        "id": 1144,
        "no_speech_prob": 0.2173157036304474,
        "seek": 382000,
        "start": 3841,
        "temperature": 0,
        "text": " So, I want to flatten starting with story. And I'm going to hit refresh.",
        "tokens": [
          51414,
          407,
          11,
          286,
          528,
          281,
          24183,
          2891,
          365,
          1657,
          13,
          400,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23696765565035635,
        "compression_ratio": 1.7142857142857142,
        "end": 3847,
        "id": 1145,
        "no_speech_prob": 0.2173157036304474,
        "seek": 382000,
        "start": 3845,
        "temperature": 0,
        "text": " A dragon fights the monster. Go, dragon, go.",
        "tokens": [
          51614,
          316,
          12165,
          14512,
          264,
          10090,
          13,
          1037,
          11,
          12165,
          11,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3851,
        "id": 1146,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3847,
        "temperature": 0,
        "text": " So, that's good. A unicorn fights the monster. Go, unicorn, go.",
        "tokens": [
          50364,
          407,
          11,
          300,
          311,
          665,
          13,
          316,
          28122,
          14512,
          264,
          10090,
          13,
          1037,
          11,
          28122,
          11,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3853,
        "id": 1147,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3851,
        "temperature": 0,
        "text": " Well, this is kind of working by accident.",
        "tokens": [
          50564,
          1042,
          11,
          341,
          307,
          733,
          295,
          1364,
          538,
          6398,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3855,
        "id": 1148,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3853,
        "temperature": 0,
        "text": " A rainbow fights the monster. Go, dragon, go.",
        "tokens": [
          50664,
          316,
          18526,
          14512,
          264,
          10090,
          13,
          1037,
          11,
          12165,
          11,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3862,
        "id": 1149,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3855,
        "temperature": 0,
        "text": " So, you'll notice here what I haven't done is secured that I pick the same hero both times.",
        "tokens": [
          50764,
          407,
          11,
          291,
          603,
          3449,
          510,
          437,
          286,
          2378,
          380,
          1096,
          307,
          22905,
          300,
          286,
          1888,
          264,
          912,
          5316,
          1293,
          1413,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3865,
        "id": 1150,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3862,
        "temperature": 0,
        "text": " So, you know, in this sort of Mad Libs way of thinking about this,",
        "tokens": [
          51114,
          407,
          11,
          291,
          458,
          11,
          294,
          341,
          1333,
          295,
          5326,
          15834,
          82,
          636,
          295,
          1953,
          466,
          341,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3867,
        "id": 1151,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3865,
        "temperature": 0,
        "text": " sometimes I want to have a different adjective.",
        "tokens": [
          51264,
          2171,
          286,
          528,
          281,
          362,
          257,
          819,
          44129,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20990607698084945,
        "compression_ratio": 1.7295081967213115,
        "end": 3874,
        "id": 1152,
        "no_speech_prob": 0.22266945242881775,
        "seek": 384700,
        "start": 3867,
        "temperature": 0,
        "text": " So, I could say a adjective hero fights the adjective monster.",
        "tokens": [
          51364,
          407,
          11,
          286,
          727,
          584,
          257,
          44129,
          5316,
          14512,
          264,
          44129,
          10090,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18750735691615514,
        "compression_ratio": 1.759656652360515,
        "end": 3880,
        "id": 1153,
        "no_speech_prob": 0.13295406103134155,
        "seek": 387400,
        "start": 3875,
        "temperature": 0,
        "text": " And so, in this case, right, refresh, a sleepy unicorn fights the dark monster.",
        "tokens": [
          50414,
          400,
          370,
          11,
          294,
          341,
          1389,
          11,
          558,
          11,
          15134,
          11,
          257,
          24908,
          28122,
          14512,
          264,
          2877,
          10090,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18750735691615514,
        "compression_ratio": 1.759656652360515,
        "end": 3885,
        "id": 1154,
        "no_speech_prob": 0.13295406103134155,
        "seek": 387400,
        "start": 3880,
        "temperature": 0,
        "text": " Go, unicorn, go. A dark dragon fights the quiet monster. Go, unicorn, go.",
        "tokens": [
          50664,
          1037,
          11,
          28122,
          11,
          352,
          13,
          316,
          2877,
          12165,
          14512,
          264,
          5677,
          10090,
          13,
          1037,
          11,
          28122,
          11,
          352,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18750735691615514,
        "compression_ratio": 1.759656652360515,
        "end": 3891,
        "id": 1155,
        "no_speech_prob": 0.13295406103134155,
        "seek": 387400,
        "start": 3885,
        "temperature": 0,
        "text": " So, I do want a different adjective. I want a random adjective for the hero and the monster.",
        "tokens": [
          50914,
          407,
          11,
          286,
          360,
          528,
          257,
          819,
          44129,
          13,
          286,
          528,
          257,
          4974,
          44129,
          337,
          264,
          5316,
          293,
          264,
          10090,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18750735691615514,
        "compression_ratio": 1.759656652360515,
        "end": 3894,
        "id": 1156,
        "no_speech_prob": 0.13295406103134155,
        "seek": 387400,
        "start": 3891,
        "temperature": 0,
        "text": " But when I say hero, I want to get the same hero twice.",
        "tokens": [
          51214,
          583,
          562,
          286,
          584,
          5316,
          11,
          286,
          528,
          281,
          483,
          264,
          912,
          5316,
          6091,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18750735691615514,
        "compression_ratio": 1.759656652360515,
        "end": 3902,
        "id": 1157,
        "no_speech_prob": 0.13295406103134155,
        "seek": 387400,
        "start": 3894,
        "temperature": 0,
        "text": " So, one of the wonderful things that Tracery has is it has a mechanism for you to assign a production rule.",
        "tokens": [
          51364,
          407,
          11,
          472,
          295,
          264,
          3715,
          721,
          300,
          1765,
          326,
          2109,
          575,
          307,
          309,
          575,
          257,
          7513,
          337,
          291,
          281,
          6269,
          257,
          4265,
          4978,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3907,
        "id": 1158,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3902,
        "temperature": 0,
        "text": " Essentially, like, almost have like a variable that holds something that's picked in the grammar over time",
        "tokens": [
          50364,
          23596,
          11,
          411,
          11,
          1920,
          362,
          411,
          257,
          7006,
          300,
          9190,
          746,
          300,
          311,
          6183,
          294,
          264,
          22317,
          670,
          565,
          50614
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3910,
        "id": 1159,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3907,
        "temperature": 0,
        "text": " across the entire sentence, the story that's being generated.",
        "tokens": [
          50614,
          2108,
          264,
          2302,
          8174,
          11,
          264,
          1657,
          300,
          311,
          885,
          10833,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3915,
        "id": 1160,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3910,
        "temperature": 0,
        "text": " So, in that sense, what I can do here is I want to start with start.",
        "tokens": [
          50764,
          407,
          11,
          294,
          300,
          2020,
          11,
          437,
          286,
          393,
          360,
          510,
          307,
          286,
          528,
          281,
          722,
          365,
          722,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3920,
        "id": 1161,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3915,
        "temperature": 0,
        "text": " And what I want start to render, so to speak, to expand is the story.",
        "tokens": [
          51014,
          400,
          437,
          286,
          528,
          722,
          281,
          15529,
          11,
          370,
          281,
          1710,
          11,
          281,
          5268,
          307,
          264,
          1657,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3924,
        "id": 1162,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3920,
        "temperature": 0,
        "text": " So, start expands the story, which is this. So, this should be the same.",
        "tokens": [
          51264,
          407,
          11,
          722,
          33706,
          264,
          1657,
          11,
          597,
          307,
          341,
          13,
          407,
          11,
          341,
          820,
          312,
          264,
          912,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3927,
        "id": 1163,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3924,
        "temperature": 0,
        "text": " I'm just getting these little stories here.",
        "tokens": [
          51464,
          286,
          478,
          445,
          1242,
          613,
          707,
          3676,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20225445059842842,
        "compression_ratio": 1.795539033457249,
        "end": 3931,
        "id": 1164,
        "no_speech_prob": 0.00844547525048256,
        "seek": 390200,
        "start": 3927,
        "temperature": 0,
        "text": " And now, though, what I want to do is put in here bracket.",
        "tokens": [
          51614,
          400,
          586,
          11,
          1673,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          829,
          294,
          510,
          16904,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3935,
        "id": 1165,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3931,
        "temperature": 0,
        "text": " I'm going to assign hero.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          6269,
          5316,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3939,
        "id": 1166,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3935,
        "temperature": 0,
        "text": " And the hero actually is going to come from this list.",
        "tokens": [
          50564,
          400,
          264,
          5316,
          767,
          307,
          516,
          281,
          808,
          490,
          341,
          1329,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3941,
        "id": 1167,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3939,
        "temperature": 0,
        "text": " So, I need to give this list another name.",
        "tokens": [
          50764,
          407,
          11,
          286,
          643,
          281,
          976,
          341,
          1329,
          1071,
          1315,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3944,
        "id": 1168,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3941,
        "temperature": 0,
        "text": " This is, let's just call this characters.",
        "tokens": [
          50864,
          639,
          307,
          11,
          718,
          311,
          445,
          818,
          341,
          4342,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3948,
        "id": 1169,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3944,
        "temperature": 0,
        "text": " Hero, character.",
        "tokens": [
          51014,
          14731,
          11,
          2517,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3955,
        "id": 1170,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3948,
        "temperature": 0,
        "text": " So, what this does is it says, render the story with a character being picked as the hero.",
        "tokens": [
          51214,
          407,
          11,
          437,
          341,
          775,
          307,
          309,
          1619,
          11,
          15529,
          264,
          1657,
          365,
          257,
          2517,
          885,
          6183,
          382,
          264,
          5316,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21437225701673976,
        "compression_ratio": 1.7053571428571428,
        "end": 3960,
        "id": 1171,
        "no_speech_prob": 0.005220044869929552,
        "seek": 393100,
        "start": 3955,
        "temperature": 0,
        "text": " So, first it will pick dragon, unicorn, or rainbow, assign that to hero, and then use hero throughout there.",
        "tokens": [
          51564,
          407,
          11,
          700,
          309,
          486,
          1888,
          12165,
          11,
          28122,
          11,
          420,
          18526,
          11,
          6269,
          300,
          281,
          5316,
          11,
          293,
          550,
          764,
          5316,
          3710,
          456,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3965,
        "id": 1172,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3960,
        "temperature": 0,
        "text": " So, now as I render this, you can see a dark rainbow fights the sleepy monster.",
        "tokens": [
          50364,
          407,
          11,
          586,
          382,
          286,
          15529,
          341,
          11,
          291,
          393,
          536,
          257,
          2877,
          18526,
          14512,
          264,
          24908,
          10090,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3967,
        "id": 1173,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3965,
        "temperature": 0,
        "text": " Go, rainbow, go.",
        "tokens": [
          50614,
          1037,
          11,
          18526,
          11,
          352,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3970,
        "id": 1174,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3967,
        "temperature": 0,
        "text": " A dark unicorn fights the quiet monster.",
        "tokens": [
          50714,
          316,
          2877,
          28122,
          14512,
          264,
          5677,
          10090,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3971,
        "id": 1175,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3970,
        "temperature": 0,
        "text": " Go, unicorn, go.",
        "tokens": [
          50864,
          1037,
          11,
          28122,
          11,
          352,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3973,
        "id": 1176,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3971,
        "temperature": 0,
        "text": " So, this is basically it.",
        "tokens": [
          50914,
          407,
          11,
          341,
          307,
          1936,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3975,
        "id": 1177,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3973,
        "temperature": 0,
        "text": " This is how tracery works.",
        "tokens": [
          51014,
          639,
          307,
          577,
          504,
          326,
          2109,
          1985,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3979,
        "id": 1178,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3975,
        "temperature": 0,
        "text": " You know, I could keep going, and it would be sort of like an interesting experiment.",
        "tokens": [
          51114,
          509,
          458,
          11,
          286,
          727,
          1066,
          516,
          11,
          293,
          309,
          576,
          312,
          1333,
          295,
          411,
          364,
          1880,
          5120,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1722503425800695,
        "compression_ratio": 1.5943775100401607,
        "end": 3984,
        "id": 1179,
        "no_speech_prob": 0.006388161797076464,
        "seek": 396000,
        "start": 3979,
        "temperature": 0,
        "text": " Maybe what I'll do, actually, is we could create on GitHub some type of collaboratively edited grammar.",
        "tokens": [
          51314,
          2704,
          437,
          286,
          603,
          360,
          11,
          767,
          11,
          307,
          321,
          727,
          1884,
          322,
          23331,
          512,
          2010,
          295,
          16555,
          356,
          23016,
          22317,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 3992,
        "id": 1180,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 3985,
        "temperature": 0,
        "text": " If I publish this example, maybe I'll include a link to the grammar in this video's description if people want to contribute to it.",
        "tokens": [
          50414,
          759,
          286,
          11374,
          341,
          1365,
          11,
          1310,
          286,
          603,
          4090,
          257,
          2113,
          281,
          264,
          22317,
          294,
          341,
          960,
          311,
          3855,
          498,
          561,
          528,
          281,
          10586,
          281,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 3996,
        "id": 1181,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 3992,
        "temperature": 0,
        "text": " Because really the creativity now lies in how far can you go with this?",
        "tokens": [
          50764,
          1436,
          534,
          264,
          12915,
          586,
          9134,
          294,
          577,
          1400,
          393,
          291,
          352,
          365,
          341,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 3997,
        "id": 1182,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 3996,
        "temperature": 0,
        "text": " How long can you make this story?",
        "tokens": [
          50964,
          1012,
          938,
          393,
          291,
          652,
          341,
          1657,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 3999,
        "id": 1183,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 3997,
        "temperature": 0,
        "text": " What is the story?",
        "tokens": [
          51014,
          708,
          307,
          264,
          1657,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 4002,
        "id": 1184,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 3999,
        "temperature": 0,
        "text": " What types of other things might you assign and pick randomly or assign in advance?",
        "tokens": [
          51114,
          708,
          3467,
          295,
          661,
          721,
          1062,
          291,
          6269,
          293,
          1888,
          16979,
          420,
          6269,
          294,
          7295,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 4005,
        "id": 1185,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 4002,
        "temperature": 0,
        "text": " But I just want to show you one other thing.",
        "tokens": [
          51264,
          583,
          286,
          445,
          528,
          281,
          855,
          291,
          472,
          661,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20758890882830752,
        "compression_ratio": 1.6392156862745098,
        "end": 4011,
        "id": 1186,
        "no_speech_prob": 0.11278840899467468,
        "seek": 398400,
        "start": 4005,
        "temperature": 0,
        "text": " Tracery also includes modifiers.",
        "tokens": [
          51414,
          1765,
          326,
          2109,
          611,
          5974,
          1072,
          23463,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4020,
        "id": 1187,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4011,
        "temperature": 0,
        "text": " So, for example, if I put.s here,.s will pluralize whatever character is picked.",
        "tokens": [
          50364,
          407,
          11,
          337,
          1365,
          11,
          498,
          286,
          829,
          2411,
          82,
          510,
          11,
          2411,
          82,
          486,
          25377,
          1125,
          2035,
          2517,
          307,
          6183,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4022,
        "id": 1188,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4020,
        "temperature": 0,
        "text": " So, this isn't going to make a lot of sense.",
        "tokens": [
          50814,
          407,
          11,
          341,
          1943,
          380,
          516,
          281,
          652,
          257,
          688,
          295,
          2020,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4025,
        "id": 1189,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4022,
        "temperature": 0,
        "text": " But you can say, a sleepy dragons fights the sleepy monster.",
        "tokens": [
          50914,
          583,
          291,
          393,
          584,
          11,
          257,
          24908,
          27240,
          14512,
          264,
          24908,
          10090,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4027,
        "id": 1190,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4025,
        "temperature": 0,
        "text": " Go, dragon, go.",
        "tokens": [
          51064,
          1037,
          11,
          12165,
          11,
          352,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4033,
        "id": 1191,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4027,
        "temperature": 0,
        "text": " But the reason why this is a nice quality is I don't have to include a particular rule that's like plural character.",
        "tokens": [
          51164,
          583,
          264,
          1778,
          983,
          341,
          307,
          257,
          1481,
          3125,
          307,
          286,
          500,
          380,
          362,
          281,
          4090,
          257,
          1729,
          4978,
          300,
          311,
          411,
          25377,
          2517,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4038,
        "id": 1192,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4033,
        "temperature": 0,
        "text": " Or I don't have to include dragon, unicorn, rainbow, dragons, unicorns, rainbow.",
        "tokens": [
          51464,
          1610,
          286,
          500,
          380,
          362,
          281,
          4090,
          12165,
          11,
          28122,
          11,
          18526,
          11,
          27240,
          11,
          28122,
          82,
          11,
          18526,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17212080383300782,
        "compression_ratio": 1.703125,
        "end": 4040,
        "id": 1193,
        "no_speech_prob": 0.008061764761805534,
        "seek": 401100,
        "start": 4038,
        "temperature": 0,
        "text": " So, there are a bunch of modifiers.",
        "tokens": [
          51714,
          407,
          11,
          456,
          366,
          257,
          3840,
          295,
          1072,
          23463,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22294114862830894,
        "compression_ratio": 1.6451612903225807,
        "end": 4048,
        "id": 1194,
        "no_speech_prob": 0.039044834673404694,
        "seek": 404000,
        "start": 4040,
        "temperature": 0,
        "text": " I can also use, I believe,.capitalize is a modifier that's built into tracery which will capitalize the particular word.",
        "tokens": [
          50364,
          286,
          393,
          611,
          764,
          11,
          286,
          1697,
          11,
          2411,
          9485,
          1686,
          1125,
          307,
          257,
          38011,
          300,
          311,
          3094,
          666,
          504,
          326,
          2109,
          597,
          486,
          48114,
          264,
          1729,
          1349,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22294114862830894,
        "compression_ratio": 1.6451612903225807,
        "end": 4055,
        "id": 1195,
        "no_speech_prob": 0.039044834673404694,
        "seek": 404000,
        "start": 4048,
        "temperature": 0,
        "text": " So, if I'm picking that here and putting it at the beginning of the sentence, I can always make sure that the grammar generates in such a way that that word is capitalized.",
        "tokens": [
          50764,
          407,
          11,
          498,
          286,
          478,
          8867,
          300,
          510,
          293,
          3372,
          309,
          412,
          264,
          2863,
          295,
          264,
          8174,
          11,
          286,
          393,
          1009,
          652,
          988,
          300,
          264,
          22317,
          23815,
          294,
          1270,
          257,
          636,
          300,
          300,
          1349,
          307,
          4238,
          1602,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22294114862830894,
        "compression_ratio": 1.6451612903225807,
        "end": 4063,
        "id": 1196,
        "no_speech_prob": 0.039044834673404694,
        "seek": 404000,
        "start": 4055,
        "temperature": 0,
        "text": " And if you look through the documentation, I believe here we'll find also some...",
        "tokens": [
          51114,
          400,
          498,
          291,
          574,
          807,
          264,
          14333,
          11,
          286,
          1697,
          510,
          321,
          603,
          915,
          611,
          512,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.22294114862830894,
        "compression_ratio": 1.6451612903225807,
        "end": 4066,
        "id": 1197,
        "no_speech_prob": 0.039044834673404694,
        "seek": 404000,
        "start": 4063,
        "temperature": 0,
        "text": " There'll be a list of modifiers.",
        "tokens": [
          51514,
          821,
          603,
          312,
          257,
          1329,
          295,
          1072,
          23463,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22340639986733132,
        "compression_ratio": 1.7156862745098038,
        "end": 4073,
        "id": 1198,
        "no_speech_prob": 0.33102378249168396,
        "seek": 406600,
        "start": 4067,
        "temperature": 0,
        "text": " Okay. I also should mention here, by the way, one thing you might look at is under here there are many new examples of tracery in use.",
        "tokens": [
          50414,
          1033,
          13,
          286,
          611,
          820,
          2152,
          510,
          11,
          538,
          264,
          636,
          11,
          472,
          551,
          291,
          1062,
          574,
          412,
          307,
          833,
          510,
          456,
          366,
          867,
          777,
          5110,
          295,
          504,
          326,
          2109,
          294,
          764,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22340639986733132,
        "compression_ratio": 1.7156862745098038,
        "end": 4076,
        "id": 1199,
        "no_speech_prob": 0.33102378249168396,
        "seek": 406600,
        "start": 4073,
        "temperature": 0,
        "text": " And I also have an exciting new interactive tutorial.",
        "tokens": [
          50714,
          400,
          286,
          611,
          362,
          364,
          4670,
          777,
          15141,
          7073,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22340639986733132,
        "compression_ratio": 1.7156862745098038,
        "end": 4085,
        "id": 1200,
        "no_speech_prob": 0.33102378249168396,
        "seek": 406600,
        "start": 4076,
        "temperature": 0,
        "text": " So, I'd also encourage you to check out this tutorial which allows you to sort of type the grammars into these boxes and hit re-roll and see what kind of possibilities you can get.",
        "tokens": [
          50864,
          407,
          11,
          286,
          1116,
          611,
          5373,
          291,
          281,
          1520,
          484,
          341,
          7073,
          597,
          4045,
          291,
          281,
          1333,
          295,
          2010,
          264,
          17570,
          685,
          666,
          613,
          9002,
          293,
          2045,
          319,
          12,
          3970,
          293,
          536,
          437,
          733,
          295,
          12178,
          291,
          393,
          483,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22340639986733132,
        "compression_ratio": 1.7156862745098038,
        "end": 4091,
        "id": 1201,
        "no_speech_prob": 0.33102378249168396,
        "seek": 406600,
        "start": 4085,
        "temperature": 0,
        "text": " And the features are kind of explained through the various possibilities here.",
        "tokens": [
          51314,
          400,
          264,
          4122,
          366,
          733,
          295,
          8825,
          807,
          264,
          3683,
          12178,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22340639986733132,
        "compression_ratio": 1.7156862745098038,
        "end": 4095,
        "id": 1202,
        "no_speech_prob": 0.33102378249168396,
        "seek": 406600,
        "start": 4091,
        "temperature": 0,
        "text": " Okay. So, there's so much more here that I want to look into that I haven't.",
        "tokens": [
          51614,
          1033,
          13,
          407,
          11,
          456,
          311,
          370,
          709,
          544,
          510,
          300,
          286,
          528,
          281,
          574,
          666,
          300,
          286,
          2378,
          380,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17689351868211178,
        "compression_ratio": 1.633587786259542,
        "end": 4102,
        "id": 1203,
        "no_speech_prob": 0.11593979597091675,
        "seek": 409500,
        "start": 4095,
        "temperature": 0,
        "text": " So, maybe someday I'll come back and show you some other additional advanced, so to speak, features of the tracery library.",
        "tokens": [
          50364,
          407,
          11,
          1310,
          19412,
          286,
          603,
          808,
          646,
          293,
          855,
          291,
          512,
          661,
          4497,
          7339,
          11,
          370,
          281,
          1710,
          11,
          4122,
          295,
          264,
          504,
          326,
          2109,
          6405,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17689351868211178,
        "compression_ratio": 1.633587786259542,
        "end": 4104,
        "id": 1204,
        "no_speech_prob": 0.11593979597091675,
        "seek": 409500,
        "start": 4102,
        "temperature": 0,
        "text": " So, this example will be published for you.",
        "tokens": [
          50714,
          407,
          11,
          341,
          1365,
          486,
          312,
          6572,
          337,
          291,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17689351868211178,
        "compression_ratio": 1.633587786259542,
        "end": 4107,
        "id": 1205,
        "no_speech_prob": 0.11593979597091675,
        "seek": 409500,
        "start": 4104,
        "temperature": 0,
        "text": " I encourage you to write your own grammar.",
        "tokens": [
          50814,
          286,
          5373,
          291,
          281,
          2464,
          428,
          1065,
          22317,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17689351868211178,
        "compression_ratio": 1.633587786259542,
        "end": 4110,
        "id": 1206,
        "no_speech_prob": 0.11593979597091675,
        "seek": 409500,
        "start": 4107,
        "temperature": 0,
        "text": " Of course, you can use emojis as possibilities as you can see.",
        "tokens": [
          50964,
          2720,
          1164,
          11,
          291,
          393,
          764,
          19611,
          40371,
          382,
          12178,
          382,
          291,
          393,
          536,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17689351868211178,
        "compression_ratio": 1.633587786259542,
        "end": 4112,
        "id": 1207,
        "no_speech_prob": 0.11593979597091675,
        "seek": 409500,
        "start": 4110,
        "temperature": 0,
        "text": " And we can go back now, by the way.",
        "tokens": [
          51114,
          400,
          321,
          393,
          352,
          646,
          586,
          11,
          538,
          264,
          636,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17689351868211178,
        "compression_ratio": 1.633587786259542,
        "end": 4120,
        "id": 1208,
        "no_speech_prob": 0.11593979597091675,
        "seek": 409500,
        "start": 4112,
        "temperature": 0,
        "text": " I might as well go back just to return to the beginning of this video and show you now the code which we can see here.",
        "tokens": [
          51214,
          286,
          1062,
          382,
          731,
          352,
          646,
          445,
          281,
          2736,
          281,
          264,
          2863,
          295,
          341,
          960,
          293,
          855,
          291,
          586,
          264,
          3089,
          597,
          321,
          393,
          536,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24480669315044695,
        "compression_ratio": 1.8526785714285714,
        "end": 4123,
        "id": 1209,
        "no_speech_prob": 0.8457872867584229,
        "seek": 412000,
        "start": 4120,
        "temperature": 0,
        "text": " Now we can understand how this works.",
        "tokens": [
          50364,
          823,
          321,
          393,
          1223,
          577,
          341,
          1985,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.24480669315044695,
        "compression_ratio": 1.8526785714285714,
        "end": 4130,
        "id": 1210,
        "no_speech_prob": 0.8457872867584229,
        "seek": 412000,
        "start": 4123,
        "temperature": 0,
        "text": " That this story starts with a hero picked from a character, a villain picked from a list of monsters.",
        "tokens": [
          50514,
          663,
          341,
          1657,
          3719,
          365,
          257,
          5316,
          6183,
          490,
          257,
          2517,
          11,
          257,
          17906,
          6183,
          490,
          257,
          1329,
          295,
          15785,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24480669315044695,
        "compression_ratio": 1.8526785714285714,
        "end": 4134,
        "id": 1211,
        "no_speech_prob": 0.8457872867584229,
        "seek": 412000,
        "start": 4130,
        "temperature": 0,
        "text": " And then the story is once upon a time there was hero.a which means a hero.",
        "tokens": [
          50864,
          400,
          550,
          264,
          1657,
          307,
          1564,
          3564,
          257,
          565,
          456,
          390,
          5316,
          13,
          64,
          597,
          1355,
          257,
          5316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.24480669315044695,
        "compression_ratio": 1.8526785714285714,
        "end": 4136,
        "id": 1212,
        "no_speech_prob": 0.8457872867584229,
        "seek": 412000,
        "start": 4134,
        "temperature": 0,
        "text": " It's always going to modify it with a.",
        "tokens": [
          51064,
          467,
          311,
          1009,
          516,
          281,
          16927,
          309,
          365,
          257,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24480669315044695,
        "compression_ratio": 1.8526785714285714,
        "end": 4140,
        "id": 1213,
        "no_speech_prob": 0.8457872867584229,
        "seek": 412000,
        "start": 4136,
        "temperature": 0,
        "text": " And that hero was very adjective and the hero liked food and the hero was very adjective.",
        "tokens": [
          51164,
          400,
          300,
          5316,
          390,
          588,
          44129,
          293,
          264,
          5316,
          4501,
          1755,
          293,
          264,
          5316,
          390,
          588,
          44129,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.24480669315044695,
        "compression_ratio": 1.8526785714285714,
        "end": 4144,
        "id": 1214,
        "no_speech_prob": 0.8457872867584229,
        "seek": 412000,
        "start": 4140,
        "temperature": 0,
        "text": " And then the hero met an adjective villain and she killed the villain!",
        "tokens": [
          51364,
          400,
          550,
          264,
          5316,
          1131,
          364,
          44129,
          17906,
          293,
          750,
          4652,
          264,
          17906,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4150,
        "id": 1215,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4144,
        "temperature": 0,
        "text": " And the hero ate the food and she was so adjective that she adjective... that she was adjective to today.",
        "tokens": [
          50364,
          400,
          264,
          5316,
          8468,
          264,
          1755,
          293,
          750,
          390,
          370,
          44129,
          300,
          750,
          44129,
          485,
          300,
          750,
          390,
          44129,
          281,
          965,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4155,
        "id": 1216,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4150,
        "temperature": 0,
        "text": " And if I go back to this, we can generate one more story.",
        "tokens": [
          50664,
          400,
          498,
          286,
          352,
          646,
          281,
          341,
          11,
          321,
          393,
          8460,
          472,
          544,
          1657,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4156,
        "id": 1217,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4155,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50914,
          1044,
          291,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4162,
        "id": 1218,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4156,
        "temperature": 0,
        "text": " Once upon a time there was a bear and that bear was very funny and the bear liked ice cream and the bear was very pretty.",
        "tokens": [
          50964,
          3443,
          3564,
          257,
          565,
          456,
          390,
          257,
          6155,
          293,
          300,
          6155,
          390,
          588,
          4074,
          293,
          264,
          6155,
          4501,
          4435,
          4689,
          293,
          264,
          6155,
          390,
          588,
          1238,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4166,
        "id": 1219,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4162,
        "temperature": 0,
        "text": " Then the bear met a happy, lovely dinosaur and she killed the dinosaur.",
        "tokens": [
          51264,
          1396,
          264,
          6155,
          1131,
          257,
          2055,
          11,
          7496,
          23627,
          293,
          750,
          4652,
          264,
          23627,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4167,
        "id": 1220,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4166,
        "temperature": 0,
        "text": " Monkey face.",
        "tokens": [
          51464,
          34862,
          1851,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4170,
        "id": 1221,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4167,
        "temperature": 0,
        "text": " And then the bear ate the... acorn?",
        "tokens": [
          51514,
          400,
          550,
          264,
          6155,
          8468,
          264,
          485,
          696,
          1865,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4171,
        "id": 1222,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4170,
        "temperature": 0,
        "text": " Walnut?",
        "tokens": [
          51664,
          9707,
          18316,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.21800888416378997,
        "compression_ratio": 1.8125,
        "end": 4172,
        "id": 1223,
        "no_speech_prob": 0.7246248722076416,
        "seek": 414400,
        "start": 4171,
        "temperature": 0,
        "text": " I don't know what kind of nut that is.",
        "tokens": [
          51714,
          286,
          500,
          380,
          458,
          437,
          733,
          295,
          5393,
          300,
          307,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20802695598077336,
        "compression_ratio": 1.6468253968253967,
        "end": 4177,
        "id": 1224,
        "no_speech_prob": 0.6753610372543335,
        "seek": 417200,
        "start": 4172,
        "temperature": 0,
        "text": " And she was so smart and she was green heart jealous to today.",
        "tokens": [
          50364,
          400,
          750,
          390,
          370,
          4069,
          293,
          750,
          390,
          3092,
          1917,
          13805,
          281,
          965,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20802695598077336,
        "compression_ratio": 1.6468253968253967,
        "end": 4182,
        "id": 1225,
        "no_speech_prob": 0.6753610372543335,
        "seek": 417200,
        "start": 4177,
        "temperature": 0,
        "text": " Okay, so thanks for watching this video on Tracery.",
        "tokens": [
          50614,
          1033,
          11,
          370,
          3231,
          337,
          1976,
          341,
          960,
          322,
          1765,
          326,
          2109,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20802695598077336,
        "compression_ratio": 1.6468253968253967,
        "end": 4187,
        "id": 1226,
        "no_speech_prob": 0.6753610372543335,
        "seek": 417200,
        "start": 4182,
        "temperature": 0,
        "text": " If you make something with Tracery, please thank Galaxy Kate on Twitter I would say.",
        "tokens": [
          50864,
          759,
          291,
          652,
          746,
          365,
          1765,
          326,
          2109,
          11,
          1767,
          1309,
          13520,
          16251,
          322,
          5794,
          286,
          576,
          584,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20802695598077336,
        "compression_ratio": 1.6468253968253967,
        "end": 4190,
        "id": 1227,
        "no_speech_prob": 0.6753610372543335,
        "seek": 417200,
        "start": 4187,
        "temperature": 0,
        "text": " Or contribute to the Tracery project or support it in some way.",
        "tokens": [
          51114,
          1610,
          10586,
          281,
          264,
          1765,
          326,
          2109,
          1716,
          420,
          1406,
          309,
          294,
          512,
          636,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20802695598077336,
        "compression_ratio": 1.6468253968253967,
        "end": 4194,
        "id": 1228,
        "no_speech_prob": 0.6753610372543335,
        "seek": 417200,
        "start": 4190,
        "temperature": 0,
        "text": " And I look forward to hearing what you think and what you make.",
        "tokens": [
          51264,
          400,
          286,
          574,
          2128,
          281,
          4763,
          437,
          291,
          519,
          293,
          437,
          291,
          652,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20802695598077336,
        "compression_ratio": 1.6468253968253967,
        "end": 4198,
        "id": 1229,
        "no_speech_prob": 0.6753610372543335,
        "seek": 417200,
        "start": 4194,
        "temperature": 0,
        "text": " And in the next video I'm going to look at the Rita library with context free grammars.",
        "tokens": [
          51464,
          400,
          294,
          264,
          958,
          960,
          286,
          478,
          516,
          281,
          574,
          412,
          264,
          32672,
          6405,
          365,
          4319,
          1737,
          17570,
          685,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4202,
        "id": 1230,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4198,
        "temperature": 0,
        "text": " Oh, oh, before I leave, you can also use Tracery as a node package.",
        "tokens": [
          50364,
          876,
          11,
          1954,
          11,
          949,
          286,
          1856,
          11,
          291,
          393,
          611,
          764,
          1765,
          326,
          2109,
          382,
          257,
          9984,
          7372,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4203,
        "id": 1231,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4202,
        "temperature": 0,
        "text": " So maybe someday I'll return to that.",
        "tokens": [
          50564,
          407,
          1310,
          19412,
          286,
          603,
          2736,
          281,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4208,
        "id": 1232,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4203,
        "temperature": 0,
        "text": " But you can npm install Tracery and there's documentation for that on the Tracery GitHub as well.",
        "tokens": [
          50614,
          583,
          291,
          393,
          297,
          14395,
          3625,
          1765,
          326,
          2109,
          293,
          456,
          311,
          14333,
          337,
          300,
          322,
          264,
          1765,
          326,
          2109,
          23331,
          382,
          731,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4210,
        "id": 1233,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4208,
        "temperature": 0,
        "text": " Okay, thanks and see you in another video sometime.",
        "tokens": [
          50864,
          1033,
          11,
          3231,
          293,
          536,
          291,
          294,
          1071,
          960,
          15053,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4213,
        "id": 1234,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4210,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4221,
        "id": 1235,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4213,
        "temperature": 0,
        "text": " Okay, everybody.",
        "tokens": [
          51114,
          1033,
          11,
          2201,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2572266158237252,
        "compression_ratio": 1.566326530612245,
        "end": 4223,
        "id": 1236,
        "no_speech_prob": 0.23363295197486877,
        "seek": 419800,
        "start": 4221,
        "temperature": 0,
        "text": " I see everybody in the chat.",
        "tokens": [
          51514,
          286,
          536,
          2201,
          294,
          264,
          5081,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4227,
        "id": 1237,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4224,
        "temperature": 0,
        "text": " I think I'm... how's the sound and everything?",
        "tokens": [
          50414,
          286,
          519,
          286,
          478,
          485,
          577,
          311,
          264,
          1626,
          293,
          1203,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4228,
        "id": 1238,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4227,
        "temperature": 0,
        "text": " Am I finally better?",
        "tokens": [
          50564,
          2012,
          286,
          2721,
          1101,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4231,
        "id": 1239,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4228,
        "temperature": 0,
        "text": " You know, it's very nice of you guys to ask me.",
        "tokens": [
          50614,
          509,
          458,
          11,
          309,
          311,
          588,
          1481,
          295,
          291,
          1074,
          281,
          1029,
          385,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4233,
        "id": 1240,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4231,
        "temperature": 0,
        "text": " TwoTubers asked, are you finally better?",
        "tokens": [
          50764,
          4453,
          51,
          19581,
          2351,
          11,
          366,
          291,
          2721,
          1101,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4237,
        "id": 1241,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4233,
        "temperature": 0,
        "text": " You know, I was better and then I think I kind of caught something again.",
        "tokens": [
          50864,
          509,
          458,
          11,
          286,
          390,
          1101,
          293,
          550,
          286,
          519,
          286,
          733,
          295,
          5415,
          746,
          797,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4240,
        "id": 1242,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4237,
        "temperature": 0,
        "text": " So I'm a little bit of... I'm feeling a little bit under the weather again.",
        "tokens": [
          51064,
          407,
          286,
          478,
          257,
          707,
          857,
          295,
          485,
          286,
          478,
          2633,
          257,
          707,
          857,
          833,
          264,
          5503,
          797,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4242,
        "id": 1243,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4240,
        "temperature": 0,
        "text": " But, you know, I'm 94%.",
        "tokens": [
          51214,
          583,
          11,
          291,
          458,
          11,
          286,
          478,
          30849,
          6856,
          51314
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4246,
        "id": 1244,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4242,
        "temperature": 0,
        "text": " But it is a very busy week this week.",
        "tokens": [
          51314,
          583,
          309,
          307,
          257,
          588,
          5856,
          1243,
          341,
          1243,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4249,
        "id": 1245,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4246,
        "temperature": 0,
        "text": " So I'm a little run, a little haggard.",
        "tokens": [
          51514,
          407,
          286,
          478,
          257,
          707,
          1190,
          11,
          257,
          707,
          324,
          1615,
          515,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19998588281519272,
        "compression_ratio": 1.7541666666666667,
        "end": 4251,
        "id": 1246,
        "no_speech_prob": 0.8220169544219971,
        "seek": 422300,
        "start": 4249,
        "temperature": 0,
        "text": " But I'm okay.",
        "tokens": [
          51664,
          583,
          286,
          478,
          1392,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4253,
        "id": 1247,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4251,
        "temperature": 0,
        "text": " Don't worry too much about me.",
        "tokens": [
          50364,
          1468,
          380,
          3292,
          886,
          709,
          466,
          385,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4254,
        "id": 1248,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4253,
        "temperature": 0,
        "text": " Cut. Yes.",
        "tokens": [
          50464,
          9431,
          13,
          1079,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4256,
        "id": 1249,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4254,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4257,
        "id": 1250,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4256,
        "temperature": 0,
        "text": " Everything looks and sounds good.",
        "tokens": [
          50614,
          5471,
          1542,
          293,
          3263,
          665,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4259,
        "id": 1251,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4257,
        "temperature": 0,
        "text": " Thank you, Mathieu.",
        "tokens": [
          50664,
          1044,
          291,
          11,
          15776,
          19347,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4263,
        "id": 1252,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4259,
        "temperature": 0,
        "text": " Mathieu in the chat does a wonderful job.",
        "tokens": [
          50764,
          15776,
          19347,
          294,
          264,
          5081,
          775,
          257,
          3715,
          1691,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4271,
        "id": 1253,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4263,
        "temperature": 0,
        "text": " Mathieu was gracious enough to figure out a way to, like, blur out some of the stuff so we could at least keep this video.",
        "tokens": [
          50964,
          15776,
          19347,
          390,
          36113,
          1547,
          281,
          2573,
          484,
          257,
          636,
          281,
          11,
          411,
          11,
          14257,
          484,
          512,
          295,
          264,
          1507,
          370,
          321,
          727,
          412,
          1935,
          1066,
          341,
          960,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4273,
        "id": 1254,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4271,
        "temperature": 0,
        "text": " What was the name of that art project bot?",
        "tokens": [
          51364,
          708,
          390,
          264,
          1315,
          295,
          300,
          1523,
          1716,
          10592,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4274,
        "id": 1255,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4273,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51464,
          865,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4276,
        "id": 1256,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4274,
        "temperature": 0,
        "text": " Yeah, they took my weather, my rainbows.",
        "tokens": [
          51514,
          865,
          11,
          436,
          1890,
          452,
          5503,
          11,
          452,
          4830,
          21118,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1657451532654843,
        "compression_ratio": 1.5303643724696356,
        "end": 4278,
        "id": 1257,
        "no_speech_prob": 0.23648235201835632,
        "seek": 425100,
        "start": 4276,
        "temperature": 0,
        "text": " I'm under the weather.",
        "tokens": [
          51614,
          286,
          478,
          833,
          264,
          5503,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4280,
        "id": 1258,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4278,
        "temperature": 0,
        "text": " So let me show you guys.",
        "tokens": [
          50364,
          407,
          718,
          385,
          855,
          291,
          1074,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4283,
        "id": 1259,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4280,
        "temperature": 0,
        "text": " Art assignment bot is one of my favorite bots.",
        "tokens": [
          50464,
          5735,
          15187,
          10592,
          307,
          472,
          295,
          452,
          2954,
          35410,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4285,
        "id": 1260,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4283,
        "temperature": 0,
        "text": " I don't know who makes it.",
        "tokens": [
          50614,
          286,
          500,
          380,
          458,
          567,
          1669,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4287,
        "id": 1261,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4285,
        "temperature": 0,
        "text": " Oh, Jeffrey Thompson, it looks like.",
        "tokens": [
          50714,
          876,
          11,
          28721,
          23460,
          11,
          309,
          1542,
          411,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4288,
        "id": 1262,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4287,
        "temperature": 0,
        "text": " But this is a bot.",
        "tokens": [
          50814,
          583,
          341,
          307,
          257,
          10592,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4290,
        "id": 1263,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4288,
        "temperature": 0,
        "text": " I'll just read you a few.",
        "tokens": [
          50864,
          286,
          603,
          445,
          1401,
          291,
          257,
          1326,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4292,
        "id": 1264,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4290,
        "temperature": 0,
        "text": " Create a welded metal sculpture with sows.",
        "tokens": [
          50964,
          20248,
          257,
          49227,
          5760,
          22972,
          365,
          262,
          1509,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4294,
        "id": 1265,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4292,
        "temperature": 0,
        "text": " Due Tuesday, November 2nd.",
        "tokens": [
          51064,
          18980,
          10017,
          11,
          7674,
          568,
          273,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4295,
        "id": 1266,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4294,
        "temperature": 0,
        "text": " Produce an etching with readiness.",
        "tokens": [
          51164,
          11793,
          384,
          364,
          1030,
          17354,
          365,
          34954,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4298,
        "id": 1267,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4295,
        "temperature": 0,
        "text": " Due Sunday, October 25th, 2026.",
        "tokens": [
          51214,
          18980,
          7776,
          11,
          7617,
          3552,
          392,
          11,
          945,
          10880,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4301,
        "id": 1268,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4298,
        "temperature": 0,
        "text": " Create an intervention in the landscape using sub functions.",
        "tokens": [
          51364,
          20248,
          364,
          13176,
          294,
          264,
          9661,
          1228,
          1422,
          6828,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19800015581332572,
        "compression_ratio": 1.4777777777777779,
        "end": 4303,
        "id": 1269,
        "no_speech_prob": 0.02228313311934471,
        "seek": 427800,
        "start": 4301,
        "temperature": 0,
        "text": " Due in four seconds.",
        "tokens": [
          51514,
          18980,
          294,
          1451,
          3949,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4309,
        "id": 1270,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4303,
        "temperature": 0,
        "text": " So you can imagine how a bot like this might be made with a system like Tracery.",
        "tokens": [
          50364,
          407,
          291,
          393,
          3811,
          577,
          257,
          10592,
          411,
          341,
          1062,
          312,
          1027,
          365,
          257,
          1185,
          411,
          1765,
          326,
          2109,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4310,
        "id": 1271,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4309,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4313,
        "id": 1272,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4310,
        "temperature": 0,
        "text": " I should look at ulipo.org.",
        "tokens": [
          50714,
          286,
          820,
          574,
          412,
          20352,
          647,
          78,
          13,
          4646,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4315,
        "id": 1273,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4313,
        "temperature": 0,
        "text": " Oh, yes.",
        "tokens": [
          50864,
          876,
          11,
          2086,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4325,
        "id": 1274,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4315,
        "temperature": 0,
        "text": " Ulipo is a French collective of writers, I believe, as Code Cheetah in the chat mentions, from the 1950s, and does a lot of interesting work with generative text and different algorithms.",
        "tokens": [
          50964,
          24853,
          647,
          78,
          307,
          257,
          5522,
          12590,
          295,
          13491,
          11,
          286,
          1697,
          11,
          382,
          15549,
          3351,
          47947,
          294,
          264,
          5081,
          23844,
          11,
          490,
          264,
          18141,
          82,
          11,
          293,
          775,
          257,
          688,
          295,
          1880,
          589,
          365,
          1337,
          1166,
          2487,
          293,
          819,
          14642,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4327,
        "id": 1275,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4325,
        "temperature": 0,
        "text": " Can you update your Atom package?",
        "tokens": [
          51464,
          1664,
          291,
          5623,
          428,
          1711,
          298,
          7372,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.20836813259968714,
        "compression_ratio": 1.460377358490566,
        "end": 4331,
        "id": 1276,
        "no_speech_prob": 0.13657067716121674,
        "seek": 430300,
        "start": 4327,
        "temperature": 0,
        "text": " What do you mean by that, the real crazy?",
        "tokens": [
          51564,
          708,
          360,
          291,
          914,
          538,
          300,
          11,
          264,
          957,
          3219,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4335,
        "id": 1277,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4331,
        "temperature": 0,
        "text": " Is there some sort of message here that's saying, like, I need to update?",
        "tokens": [
          50364,
          1119,
          456,
          512,
          1333,
          295,
          3636,
          510,
          300,
          311,
          1566,
          11,
          411,
          11,
          286,
          643,
          281,
          5623,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4337,
        "id": 1278,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4335,
        "temperature": 0,
        "text": " Oh, yeah, one update.",
        "tokens": [
          50564,
          876,
          11,
          1338,
          11,
          472,
          5623,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4339,
        "id": 1279,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4337,
        "temperature": 0,
        "text": " I don't want to update right now.",
        "tokens": [
          50664,
          286,
          500,
          380,
          528,
          281,
          5623,
          558,
          586,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4340,
        "id": 1280,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4339,
        "temperature": 0,
        "text": " You're making me do it.",
        "tokens": [
          50764,
          509,
          434,
          1455,
          385,
          360,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4341,
        "id": 1281,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4340,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          50814,
          876,
          11,
          1392,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4342,
        "id": 1282,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4341,
        "temperature": 0,
        "text": " Sure, why not?",
        "tokens": [
          50864,
          4894,
          11,
          983,
          406,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4343,
        "id": 1283,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4342,
        "temperature": 0,
        "text": " Oh, this is dangerous.",
        "tokens": [
          50914,
          876,
          11,
          341,
          307,
          5795,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4344,
        "id": 1284,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4343,
        "temperature": 0,
        "text": " I'm updating!",
        "tokens": [
          50964,
          286,
          478,
          25113,
          0,
          51014
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4346,
        "id": 1285,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4344,
        "temperature": 0,
        "text": " It's happening.",
        "tokens": [
          51014,
          467,
          311,
          2737,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4347,
        "id": 1286,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4346,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4348,
        "id": 1287,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4347,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4350,
        "id": 1288,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4348,
        "temperature": 0,
        "text": " So let me think now.",
        "tokens": [
          51214,
          407,
          718,
          385,
          519,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18967230566616716,
        "compression_ratio": 1.5072463768115942,
        "end": 4354,
        "id": 1289,
        "no_speech_prob": 0.03567750006914139,
        "seek": 433100,
        "start": 4350,
        "temperature": 0,
        "text": " Let's look at context-free grammars in Rita.js.",
        "tokens": [
          51314,
          961,
          311,
          574,
          412,
          4319,
          12,
          10792,
          17570,
          685,
          294,
          32672,
          13,
          25530,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21001431147257488,
        "compression_ratio": 1.3862068965517242,
        "end": 4363,
        "id": 1290,
        "no_speech_prob": 0.46482181549072266,
        "seek": 435400,
        "start": 4355,
        "temperature": 0,
        "text": " And I actually so let me see if I can get set up for this.",
        "tokens": [
          50414,
          400,
          286,
          767,
          220,
          539,
          718,
          385,
          536,
          498,
          286,
          393,
          483,
          992,
          493,
          337,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21001431147257488,
        "compression_ratio": 1.3862068965517242,
        "end": 4369,
        "id": 1291,
        "no_speech_prob": 0.46482181549072266,
        "seek": 435400,
        "start": 4363,
        "temperature": 0,
        "text": " I'm kind of just making this stuff run in the console as opposed to generating anything on the page.",
        "tokens": [
          50814,
          286,
          478,
          733,
          295,
          445,
          1455,
          341,
          1507,
          1190,
          294,
          264,
          11076,
          382,
          8851,
          281,
          17746,
          1340,
          322,
          264,
          3028,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21001431147257488,
        "compression_ratio": 1.3862068965517242,
        "end": 4379,
        "id": 1292,
        "no_speech_prob": 0.46482181549072266,
        "seek": 435400,
        "start": 4369,
        "temperature": 0,
        "text": " So I'm going to make a new example.",
        "tokens": [
          51114,
          407,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          1365,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21001431147257488,
        "compression_ratio": 1.3862068965517242,
        "end": 4380,
        "id": 1293,
        "no_speech_prob": 0.46482181549072266,
        "seek": 435400,
        "start": 4379,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51614,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3308130832428628,
        "compression_ratio": 1.1702127659574468,
        "end": 4381,
        "id": 1294,
        "no_speech_prob": 0.44546595215797424,
        "seek": 438000,
        "start": 4380,
        "temperature": 0,
        "text": " So let's trace the grammar.",
        "tokens": [
          50364,
          407,
          718,
          311,
          13508,
          264,
          22317,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.3308130832428628,
        "compression_ratio": 1.1702127659574468,
        "end": 4394,
        "id": 1295,
        "no_speech_prob": 0.44546595215797424,
        "seek": 438000,
        "start": 4381,
        "temperature": 0,
        "text": " Let's do CFG Rita.",
        "tokens": [
          50414,
          961,
          311,
          360,
          21792,
          38,
          32672,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3308130832428628,
        "compression_ratio": 1.1702127659574468,
        "end": 4395,
        "id": 1296,
        "no_speech_prob": 0.44546595215797424,
        "seek": 438000,
        "start": 4394,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3308130832428628,
        "compression_ratio": 1.1702127659574468,
        "end": 4399,
        "id": 1297,
        "no_speech_prob": 0.44546595215797424,
        "seek": 438000,
        "start": 4395,
        "temperature": 0,
        "text": " So let's make this go back here.",
        "tokens": [
          51114,
          407,
          718,
          311,
          652,
          341,
          352,
          646,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3308130832428628,
        "compression_ratio": 1.1702127659574468,
        "end": 4402,
        "id": 1298,
        "no_speech_prob": 0.44546595215797424,
        "seek": 438000,
        "start": 4399,
        "temperature": 0,
        "text": " Session seven.",
        "tokens": [
          51314,
          318,
          4311,
          3407,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3308130832428628,
        "compression_ratio": 1.1702127659574468,
        "end": 4404,
        "id": 1299,
        "no_speech_prob": 0.44546595215797424,
        "seek": 438000,
        "start": 4402,
        "temperature": 0,
        "text": " CFG Rita.",
        "tokens": [
          51464,
          21792,
          38,
          32672,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20831659565801205,
        "compression_ratio": 0.9649122807017544,
        "end": 4412,
        "id": 1300,
        "no_speech_prob": 0.36653146147727966,
        "seek": 440400,
        "start": 4405,
        "temperature": 0,
        "text": " And then I'm going to go to where am I here?",
        "tokens": [
          50414,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          689,
          669,
          286,
          510,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.20831659565801205,
        "compression_ratio": 0.9649122807017544,
        "end": 4416,
        "id": 1301,
        "no_speech_prob": 0.36653146147727966,
        "seek": 440400,
        "start": 4412,
        "temperature": 0,
        "text": " Sketch.js.",
        "tokens": [
          50764,
          49245,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20774168042994257,
        "compression_ratio": 1.3681318681318682,
        "end": 4435,
        "id": 1302,
        "no_speech_prob": 0.7399893999099731,
        "seek": 441600,
        "start": 4416,
        "temperature": 0,
        "text": " I think what I will do here is I am going to just get the Rita library now.",
        "tokens": [
          50364,
          286,
          519,
          437,
          286,
          486,
          360,
          510,
          307,
          286,
          669,
          516,
          281,
          445,
          483,
          264,
          32672,
          6405,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20774168042994257,
        "compression_ratio": 1.3681318681318682,
        "end": 4441,
        "id": 1303,
        "no_speech_prob": 0.7399893999099731,
        "seek": 441600,
        "start": 4435,
        "temperature": 0,
        "text": " Ah, Coder for Life asks, hey, Daniel, are you going to talk about our briefly mentioned compilers?",
        "tokens": [
          51314,
          2438,
          11,
          383,
          19866,
          337,
          7720,
          8962,
          11,
          4177,
          11,
          8033,
          11,
          366,
          291,
          516,
          281,
          751,
          466,
          527,
          10515,
          2835,
          715,
          388,
          433,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.20774168042994257,
        "compression_ratio": 1.3681318681318682,
        "end": 4444,
        "id": 1304,
        "no_speech_prob": 0.7399893999099731,
        "seek": 441600,
        "start": 4441,
        "temperature": 0,
        "text": " We're talking about grammar and stuff which can be linked to syntax rules.",
        "tokens": [
          51614,
          492,
          434,
          1417,
          466,
          22317,
          293,
          1507,
          597,
          393,
          312,
          9408,
          281,
          28431,
          4474,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2181263542175293,
        "compression_ratio": 1.5696202531645569,
        "end": 4446,
        "id": 1305,
        "no_speech_prob": 0.1276434063911438,
        "seek": 444400,
        "start": 4444,
        "temperature": 0,
        "text": " You even brought up Bacchus now form and stuff.",
        "tokens": [
          50364,
          509,
          754,
          3038,
          493,
          363,
          326,
          339,
          301,
          586,
          1254,
          293,
          1507,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2181263542175293,
        "compression_ratio": 1.5696202531645569,
        "end": 4455,
        "id": 1306,
        "no_speech_prob": 0.1276434063911438,
        "seek": 444400,
        "start": 4446,
        "temperature": 0,
        "text": " Yes, I did reference it and I did briefly show a slide that showed a kind of syntax, a grammar for C++ expressions.",
        "tokens": [
          50464,
          1079,
          11,
          286,
          630,
          6408,
          309,
          293,
          286,
          630,
          10515,
          855,
          257,
          4137,
          300,
          4712,
          257,
          733,
          295,
          28431,
          11,
          257,
          22317,
          337,
          383,
          25472,
          15277,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2181263542175293,
        "compression_ratio": 1.5696202531645569,
        "end": 4461,
        "id": 1307,
        "no_speech_prob": 0.1276434063911438,
        "seek": 444400,
        "start": 4455,
        "temperature": 0,
        "text": " I'm trying, I think in the limited time I have today to stay in the sort of creative writing text generation side.",
        "tokens": [
          50914,
          286,
          478,
          1382,
          11,
          286,
          519,
          294,
          264,
          5567,
          565,
          286,
          362,
          965,
          281,
          1754,
          294,
          264,
          1333,
          295,
          5880,
          3579,
          2487,
          5125,
          1252,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2181263542175293,
        "compression_ratio": 1.5696202531645569,
        "end": 4465,
        "id": 1308,
        "no_speech_prob": 0.1276434063911438,
        "seek": 444400,
        "start": 4461,
        "temperature": 0,
        "text": " I don't have but I do think that is a rich and interesting topic.",
        "tokens": [
          51214,
          286,
          500,
          380,
          362,
          457,
          286,
          360,
          519,
          300,
          307,
          257,
          4593,
          293,
          1880,
          4829,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2181263542175293,
        "compression_ratio": 1.5696202531645569,
        "end": 4467,
        "id": 1309,
        "no_speech_prob": 0.1276434063911438,
        "seek": 444400,
        "start": 4465,
        "temperature": 0,
        "text": " I would love to explore it.",
        "tokens": [
          51414,
          286,
          576,
          959,
          281,
          6839,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4474,
        "id": 1310,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4467,
        "temperature": 0,
        "text": " So let me think about that if there is a way that I might be able to look at that a little more later today or come back another time if that becomes relevant as well.",
        "tokens": [
          50364,
          407,
          718,
          385,
          519,
          466,
          300,
          498,
          456,
          307,
          257,
          636,
          300,
          286,
          1062,
          312,
          1075,
          281,
          574,
          412,
          300,
          257,
          707,
          544,
          1780,
          965,
          420,
          808,
          646,
          1071,
          565,
          498,
          300,
          3643,
          7340,
          382,
          731,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4475,
        "id": 1311,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4474,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4477,
        "id": 1312,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4475,
        "temperature": 0,
        "text": " So Rita.js.",
        "tokens": [
          50764,
          407,
          32672,
          13,
          25530,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4481,
        "id": 1313,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4477,
        "temperature": 0,
        "text": " Let me go to distribution.",
        "tokens": [
          50864,
          961,
          385,
          352,
          281,
          7316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4488,
        "id": 1314,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4481,
        "temperature": 0,
        "text": " Actually, I can just go to releases here and download this.",
        "tokens": [
          51064,
          5135,
          11,
          286,
          393,
          445,
          352,
          281,
          16952,
          510,
          293,
          5484,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4490,
        "id": 1315,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4488,
        "temperature": 0,
        "text": " And I'm sure I have Rita.js somewhere anyway.",
        "tokens": [
          51414,
          400,
          286,
          478,
          988,
          286,
          362,
          32672,
          13,
          25530,
          4079,
          4033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23483906960000797,
        "compression_ratio": 1.6,
        "end": 4495,
        "id": 1316,
        "no_speech_prob": 0.4842197299003601,
        "seek": 446700,
        "start": 4490,
        "temperature": 0,
        "text": " But let me look for distribution.",
        "tokens": [
          51514,
          583,
          718,
          385,
          574,
          337,
          7316,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4496,
        "id": 1317,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4495,
        "temperature": 0,
        "text": " Distribution is the same thing.",
        "tokens": [
          50364,
          9840,
          30783,
          307,
          264,
          912,
          551,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4497,
        "id": 1318,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4496,
        "temperature": 0,
        "text": " Rita.",
        "tokens": [
          50414,
          32672,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4504,
        "id": 1319,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4497,
        "temperature": 0,
        "text": " So let me just use Rita full even though I might only need the smaller library for this.",
        "tokens": [
          50464,
          407,
          718,
          385,
          445,
          764,
          32672,
          1577,
          754,
          1673,
          286,
          1062,
          787,
          643,
          264,
          4356,
          6405,
          337,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4509,
        "id": 1320,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4504,
        "temperature": 0,
        "text": " So copy.",
        "tokens": [
          50814,
          407,
          5055,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4511,
        "id": 1321,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4509,
        "temperature": 0,
        "text": " A to Z session 7.",
        "tokens": [
          51064,
          316,
          281,
          1176,
          5481,
          1614,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4516,
        "id": 1322,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4511,
        "temperature": 0,
        "text": " Put this here under libraries.",
        "tokens": [
          51164,
          4935,
          341,
          510,
          833,
          15148,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4517,
        "id": 1323,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4516,
        "temperature": 0,
        "text": " And let me go back to the code.",
        "tokens": [
          51414,
          400,
          718,
          385,
          352,
          646,
          281,
          264,
          3089,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4521,
        "id": 1324,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4517,
        "temperature": 0,
        "text": " So I want to just get this set up in advance of doing the video.",
        "tokens": [
          51464,
          407,
          286,
          528,
          281,
          445,
          483,
          341,
          992,
          493,
          294,
          7295,
          295,
          884,
          264,
          960,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4523,
        "id": 1325,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4521,
        "temperature": 0,
        "text": " I don't need jQuery.",
        "tokens": [
          51664,
          286,
          500,
          380,
          643,
          361,
          35550,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2601391201927548,
        "compression_ratio": 1.5728155339805825,
        "end": 4524,
        "id": 1326,
        "no_speech_prob": 0.611185610294342,
        "seek": 449500,
        "start": 4523,
        "temperature": 0,
        "text": " I don't need tracery.",
        "tokens": [
          51764,
          286,
          500,
          380,
          643,
          504,
          326,
          2109,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2501806683010525,
        "compression_ratio": 1.3228346456692914,
        "end": 4529,
        "id": 1327,
        "no_speech_prob": 0.2877367436885834,
        "seek": 452400,
        "start": 4524,
        "temperature": 0,
        "text": " But I do need I don't know why I've done this differently.",
        "tokens": [
          50364,
          583,
          286,
          360,
          643,
          286,
          500,
          380,
          458,
          983,
          286,
          600,
          1096,
          341,
          7614,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2501806683010525,
        "compression_ratio": 1.3228346456692914,
        "end": 4534,
        "id": 1328,
        "no_speech_prob": 0.2877367436885834,
        "seek": 452400,
        "start": 4529,
        "temperature": 0,
        "text": " I do need Rita.",
        "tokens": [
          50614,
          286,
          360,
          643,
          32672,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2501806683010525,
        "compression_ratio": 1.3228346456692914,
        "end": 4536,
        "id": 1329,
        "no_speech_prob": 0.2877367436885834,
        "seek": 452400,
        "start": 4534,
        "temperature": 0,
        "text": " Rita-full.js.",
        "tokens": [
          50864,
          32672,
          12,
          32818,
          13,
          25530,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2501806683010525,
        "compression_ratio": 1.3228346456692914,
        "end": 4538,
        "id": 1330,
        "no_speech_prob": 0.2877367436885834,
        "seek": 452400,
        "start": 4536,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2501806683010525,
        "compression_ratio": 1.3228346456692914,
        "end": 4548,
        "id": 1331,
        "no_speech_prob": 0.2877367436885834,
        "seek": 452400,
        "start": 4538,
        "temperature": 0,
        "text": " So now what I want to do is I also want to get a grammar file.",
        "tokens": [
          51064,
          407,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          611,
          528,
          281,
          483,
          257,
          22317,
          3991,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2501806683010525,
        "compression_ratio": 1.3228346456692914,
        "end": 4551,
        "id": 1332,
        "no_speech_prob": 0.2877367436885834,
        "seek": 452400,
        "start": 4548,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51564,
          961,
          311,
          536,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23755043203180487,
        "compression_ratio": 1.191304347826087,
        "end": 4566,
        "id": 1333,
        "no_speech_prob": 0.17552955448627472,
        "seek": 455100,
        "start": 4551,
        "temperature": 0,
        "text": " And let me see if I have.",
        "tokens": [
          50364,
          400,
          718,
          385,
          536,
          498,
          286,
          362,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23755043203180487,
        "compression_ratio": 1.191304347826087,
        "end": 4572,
        "id": 1334,
        "no_speech_prob": 0.17552955448627472,
        "seek": 455100,
        "start": 4566,
        "temperature": 0,
        "text": " I guess I'll use this grammar file which comes from Alison Parrish.",
        "tokens": [
          51114,
          286,
          2041,
          286,
          603,
          764,
          341,
          22317,
          3991,
          597,
          1487,
          490,
          41001,
          47890,
          742,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23755043203180487,
        "compression_ratio": 1.191304347826087,
        "end": 4573,
        "id": 1335,
        "no_speech_prob": 0.17552955448627472,
        "seek": 455100,
        "start": 4572,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          51414,
          4919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23755043203180487,
        "compression_ratio": 1.191304347826087,
        "end": 4578,
        "id": 1336,
        "no_speech_prob": 0.17552955448627472,
        "seek": 455100,
        "start": 4573,
        "temperature": 0,
        "text": " I'm kind of like poking around here.",
        "tokens": [
          51464,
          286,
          478,
          733,
          295,
          411,
          42684,
          926,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24573418072291783,
        "compression_ratio": 1.2583333333333333,
        "end": 4588,
        "id": 1337,
        "no_speech_prob": 0.41104358434677124,
        "seek": 457800,
        "start": 4578,
        "temperature": 0,
        "text": " Let me see how this goes.",
        "tokens": [
          50364,
          961,
          385,
          536,
          577,
          341,
          1709,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24573418072291783,
        "compression_ratio": 1.2583333333333333,
        "end": 4591,
        "id": 1338,
        "no_speech_prob": 0.41104358434677124,
        "seek": 457800,
        "start": 4588,
        "temperature": 0,
        "text": " Test.grammar.",
        "tokens": [
          50864,
          9279,
          13,
          1342,
          6209,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24573418072291783,
        "compression_ratio": 1.2583333333333333,
        "end": 4594,
        "id": 1339,
        "no_speech_prob": 0.41104358434677124,
        "seek": 457800,
        "start": 4591,
        "temperature": 0,
        "text": " And save.",
        "tokens": [
          51014,
          400,
          3155,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.24573418072291783,
        "compression_ratio": 1.2583333333333333,
        "end": 4595,
        "id": 1340,
        "no_speech_prob": 0.41104358434677124,
        "seek": 457800,
        "start": 4594,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24573418072291783,
        "compression_ratio": 1.2583333333333333,
        "end": 4600,
        "id": 1341,
        "no_speech_prob": 0.41104358434677124,
        "seek": 457800,
        "start": 4595,
        "temperature": 0,
        "text": " So let's go to the other thing that I believe I have.",
        "tokens": [
          51214,
          407,
          718,
          311,
          352,
          281,
          264,
          661,
          551,
          300,
          286,
          1697,
          286,
          362,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24573418072291783,
        "compression_ratio": 1.2583333333333333,
        "end": 4605,
        "id": 1342,
        "no_speech_prob": 0.41104358434677124,
        "seek": 457800,
        "start": 4600,
        "temperature": 0,
        "text": " If I go to context free grammar Shiffman.",
        "tokens": [
          51464,
          759,
          286,
          352,
          281,
          4319,
          1737,
          22317,
          1160,
          3661,
          1601,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16458519434524796,
        "compression_ratio": 1.289855072463768,
        "end": 4614,
        "id": 1343,
        "no_speech_prob": 0.6001350283622742,
        "seek": 460500,
        "start": 4605,
        "temperature": 0,
        "text": " I believe that I have a link here to Daniel Howe's page which I will reference.",
        "tokens": [
          50364,
          286,
          1697,
          300,
          286,
          362,
          257,
          2113,
          510,
          281,
          8033,
          1012,
          68,
          311,
          3028,
          597,
          286,
          486,
          6408,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16458519434524796,
        "compression_ratio": 1.289855072463768,
        "end": 4615,
        "id": 1344,
        "no_speech_prob": 0.6001350283622742,
        "seek": 460500,
        "start": 4614,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16458519434524796,
        "compression_ratio": 1.289855072463768,
        "end": 4621,
        "id": 1345,
        "no_speech_prob": 0.6001350283622742,
        "seek": 460500,
        "start": 4615,
        "temperature": 0,
        "text": " And let me just see here if this.",
        "tokens": [
          50864,
          400,
          718,
          385,
          445,
          536,
          510,
          498,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16458519434524796,
        "compression_ratio": 1.289855072463768,
        "end": 4623,
        "id": 1346,
        "no_speech_prob": 0.6001350283622742,
        "seek": 460500,
        "start": 4621,
        "temperature": 0,
        "text": " Oh, this is a different format.",
        "tokens": [
          51164,
          876,
          11,
          341,
          307,
          257,
          819,
          7877,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16458519434524796,
        "compression_ratio": 1.289855072463768,
        "end": 4625,
        "id": 1347,
        "no_speech_prob": 0.6001350283622742,
        "seek": 460500,
        "start": 4623,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51264,
          14711,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16458519434524796,
        "compression_ratio": 1.289855072463768,
        "end": 4627,
        "id": 1348,
        "no_speech_prob": 0.6001350283622742,
        "seek": 460500,
        "start": 4625,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          51364,
          407,
          718,
          311,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23238878834004306,
        "compression_ratio": 1.2393162393162394,
        "end": 4635,
        "id": 1349,
        "no_speech_prob": 0.48042190074920654,
        "seek": 462700,
        "start": 4627,
        "temperature": 0,
        "text": " So Rita looks like it expects this format.",
        "tokens": [
          50364,
          407,
          32672,
          1542,
          411,
          309,
          33280,
          341,
          7877,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23238878834004306,
        "compression_ratio": 1.2393162393162394,
        "end": 4647,
        "id": 1350,
        "no_speech_prob": 0.48042190074920654,
        "seek": 462700,
        "start": 4635,
        "temperature": 0,
        "text": " So I'm going to paste this in.",
        "tokens": [
          50764,
          407,
          286,
          478,
          516,
          281,
          9163,
          341,
          294,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23238878834004306,
        "compression_ratio": 1.2393162393162394,
        "end": 4649,
        "id": 1351,
        "no_speech_prob": 0.48042190074920654,
        "seek": 462700,
        "start": 4647,
        "temperature": 0,
        "text": " Daniel has own property.",
        "tokens": [
          51364,
          8033,
          575,
          1065,
          4707,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23238878834004306,
        "compression_ratio": 1.2393162393162394,
        "end": 4651,
        "id": 1352,
        "no_speech_prob": 0.48042190074920654,
        "seek": 462700,
        "start": 4649,
        "temperature": 0,
        "text": " Daniel Howe.",
        "tokens": [
          51464,
          8033,
          1012,
          68,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23238878834004306,
        "compression_ratio": 1.2393162393162394,
        "end": 4652,
        "id": 1353,
        "no_speech_prob": 0.48042190074920654,
        "seek": 462700,
        "start": 4651,
        "temperature": 0,
        "text": " Auto complete.",
        "tokens": [
          51564,
          13738,
          3566,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23238878834004306,
        "compression_ratio": 1.2393162393162394,
        "end": 4654,
        "id": 1354,
        "no_speech_prob": 0.48042190074920654,
        "seek": 462700,
        "start": 4652,
        "temperature": 0,
        "text": " Adam, please stop.",
        "tokens": [
          51614,
          7938,
          11,
          1767,
          1590,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3194032941545759,
        "compression_ratio": 1.4228187919463087,
        "end": 4658,
        "id": 1355,
        "no_speech_prob": 0.7604967355728149,
        "seek": 465400,
        "start": 4654,
        "temperature": 0,
        "text": " And then let me just paste this URL in.",
        "tokens": [
          50364,
          400,
          550,
          718,
          385,
          445,
          9163,
          341,
          12905,
          294,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3194032941545759,
        "compression_ratio": 1.4228187919463087,
        "end": 4659,
        "id": 1356,
        "no_speech_prob": 0.7604967355728149,
        "seek": 465400,
        "start": 4658,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50564,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3194032941545759,
        "compression_ratio": 1.4228187919463087,
        "end": 4663,
        "id": 1357,
        "no_speech_prob": 0.7604967355728149,
        "seek": 465400,
        "start": 4659,
        "temperature": 0,
        "text": " So let's, oh, first of all, let me change this because you know me.",
        "tokens": [
          50614,
          407,
          718,
          311,
          11,
          1954,
          11,
          700,
          295,
          439,
          11,
          718,
          385,
          1319,
          341,
          570,
          291,
          458,
          385,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3194032941545759,
        "compression_ratio": 1.4228187919463087,
        "end": 4664,
        "id": 1358,
        "no_speech_prob": 0.7604967355728149,
        "seek": 465400,
        "start": 4663,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3194032941545759,
        "compression_ratio": 1.4228187919463087,
        "end": 4676,
        "id": 1359,
        "no_speech_prob": 0.7604967355728149,
        "seek": 465400,
        "start": 4664,
        "temperature": 0,
        "text": " So a, the rainbow, unicorn, and what is something that a rainbow and a unicorn does?",
        "tokens": [
          50864,
          407,
          257,
          11,
          264,
          18526,
          11,
          28122,
          11,
          293,
          437,
          307,
          746,
          300,
          257,
          18526,
          293,
          257,
          28122,
          775,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.3194032941545759,
        "compression_ratio": 1.4228187919463087,
        "end": 4681,
        "id": 1360,
        "no_speech_prob": 0.7604967355728149,
        "seek": 465400,
        "start": 4676,
        "temperature": 0,
        "text": " Dances.",
        "tokens": [
          51464,
          413,
          2676,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.37000666166606705,
        "compression_ratio": 1.459016393442623,
        "end": 4697,
        "id": 1361,
        "no_speech_prob": 0.2751014530658722,
        "seek": 468100,
        "start": 4682,
        "temperature": 0,
        "text": " Start, noun phrase, noun phrase, verb, noun phrase, a, the unicorn, rainbow, and dances.",
        "tokens": [
          50414,
          6481,
          11,
          23307,
          9535,
          11,
          23307,
          9535,
          11,
          9595,
          11,
          23307,
          9535,
          11,
          257,
          11,
          264,
          28122,
          11,
          18526,
          11,
          293,
          28322,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.37000666166606705,
        "compression_ratio": 1.459016393442623,
        "end": 4698,
        "id": 1362,
        "no_speech_prob": 0.2751014530658722,
        "seek": 468100,
        "start": 4697,
        "temperature": 0,
        "text": " So, okay.",
        "tokens": [
          51164,
          407,
          11,
          1392,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.37000666166606705,
        "compression_ratio": 1.459016393442623,
        "end": 4703,
        "id": 1363,
        "no_speech_prob": 0.2751014530658722,
        "seek": 468100,
        "start": 4698,
        "temperature": 0,
        "text": " So we're going to look at this.",
        "tokens": [
          51214,
          407,
          321,
          434,
          516,
          281,
          574,
          412,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.37000666166606705,
        "compression_ratio": 1.459016393442623,
        "end": 4707,
        "id": 1364,
        "no_speech_prob": 0.2751014530658722,
        "seek": 468100,
        "start": 4703,
        "temperature": 0,
        "text": " So I think if I just close everything out here.",
        "tokens": [
          51464,
          407,
          286,
          519,
          498,
          286,
          445,
          1998,
          1203,
          484,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4720,
        "id": 1365,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4707,
        "temperature": 0,
        "text": " I am now ready to look at Rita.js and context-free grammars.",
        "tokens": [
          50364,
          286,
          669,
          586,
          1919,
          281,
          574,
          412,
          32672,
          13,
          25530,
          293,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4723,
        "id": 1366,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4720,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51014,
          1692,
          321,
          352,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4726,
        "id": 1367,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4723,
        "temperature": 0,
        "text": " RI grammar.",
        "tokens": [
          51164,
          30474,
          22317,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4730,
        "id": 1368,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4726,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4731,
        "id": 1369,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4730,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51514,
          21726,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4733,
        "id": 1370,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4731,
        "temperature": 0,
        "text": " Back.",
        "tokens": [
          51564,
          5833,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4734,
        "id": 1371,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4733,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2218923568725586,
        "compression_ratio": 1.188034188034188,
        "end": 4735,
        "id": 1372,
        "no_speech_prob": 0.4186231195926666,
        "seek": 470700,
        "start": 4734,
        "temperature": 0,
        "text": " So how's everybody doing here?",
        "tokens": [
          51714,
          407,
          577,
          311,
          2201,
          884,
          510,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.19148070411344545,
        "compression_ratio": 1.55893536121673,
        "end": 4738,
        "id": 1373,
        "no_speech_prob": 0.6476671099662781,
        "seek": 473500,
        "start": 4735,
        "temperature": 0,
        "text": " Let's look.",
        "tokens": [
          50364,
          961,
          311,
          574,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19148070411344545,
        "compression_ratio": 1.55893536121673,
        "end": 4741,
        "id": 1374,
        "no_speech_prob": 0.6476671099662781,
        "seek": 473500,
        "start": 4738,
        "temperature": 0,
        "text": " Oh, there's some discussion about code editors.",
        "tokens": [
          50514,
          876,
          11,
          456,
          311,
          512,
          5017,
          466,
          3089,
          31446,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19148070411344545,
        "compression_ratio": 1.55893536121673,
        "end": 4747,
        "id": 1375,
        "no_speech_prob": 0.6476671099662781,
        "seek": 473500,
        "start": 4741,
        "temperature": 0,
        "text": " So by the way, there is a, for p5.js, which is a JavaScript framework that I do a lot of my teaching with,",
        "tokens": [
          50664,
          407,
          538,
          264,
          636,
          11,
          456,
          307,
          257,
          11,
          337,
          280,
          20,
          13,
          25530,
          11,
          597,
          307,
          257,
          15778,
          8388,
          300,
          286,
          360,
          257,
          688,
          295,
          452,
          4571,
          365,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.19148070411344545,
        "compression_ratio": 1.55893536121673,
        "end": 4753,
        "id": 1376,
        "no_speech_prob": 0.6476671099662781,
        "seek": 473500,
        "start": 4747,
        "temperature": 0,
        "text": " and I work on as part of the Processing Foundation, there is currently a downloadable desktop editor.",
        "tokens": [
          50964,
          293,
          286,
          589,
          322,
          382,
          644,
          295,
          264,
          31093,
          278,
          10335,
          11,
          456,
          307,
          4362,
          257,
          5484,
          712,
          14502,
          9839,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19148070411344545,
        "compression_ratio": 1.55893536121673,
        "end": 4759,
        "id": 1377,
        "no_speech_prob": 0.6476671099662781,
        "seek": 473500,
        "start": 4753,
        "temperature": 0,
        "text": " I'm choosing in this course to just use an editor like Atom or Sublime, a separate text editor,",
        "tokens": [
          51264,
          286,
          478,
          10875,
          294,
          341,
          1164,
          281,
          445,
          764,
          364,
          9839,
          411,
          1711,
          298,
          420,
          8511,
          40941,
          11,
          257,
          4994,
          2487,
          9839,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.19148070411344545,
        "compression_ratio": 1.55893536121673,
        "end": 4762,
        "id": 1378,
        "no_speech_prob": 0.6476671099662781,
        "seek": 473500,
        "start": 4759,
        "temperature": 0,
        "text": " and then run my own kind of local web server.",
        "tokens": [
          51564,
          293,
          550,
          1190,
          452,
          1065,
          733,
          295,
          2654,
          3670,
          7154,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4769,
        "id": 1379,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4762,
        "temperature": 0,
        "text": " I will mention that soon, hopefully in 2017, early 2017, there's going to be a release of a web editor.",
        "tokens": [
          50364,
          286,
          486,
          2152,
          300,
          2321,
          11,
          4696,
          294,
          6591,
          11,
          2440,
          6591,
          11,
          456,
          311,
          516,
          281,
          312,
          257,
          4374,
          295,
          257,
          3670,
          9839,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4777,
        "id": 1380,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4769,
        "temperature": 0,
        "text": " And I should also just mention, by the way, give a little plug to Sinan, the creator of Open Processing.",
        "tokens": [
          50714,
          400,
          286,
          820,
          611,
          445,
          2152,
          11,
          538,
          264,
          636,
          11,
          976,
          257,
          707,
          5452,
          281,
          11187,
          282,
          11,
          264,
          14181,
          295,
          7238,
          31093,
          278,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4782,
        "id": 1381,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4777,
        "temperature": 0,
        "text": " Open Processing just had a redesign, and it's really quite amazing.",
        "tokens": [
          51114,
          7238,
          31093,
          278,
          445,
          632,
          257,
          39853,
          11,
          293,
          309,
          311,
          534,
          1596,
          2243,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4786,
        "id": 1382,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4782,
        "temperature": 0,
        "text": " You can now create p5.js sketches in Open Processing.",
        "tokens": [
          51364,
          509,
          393,
          586,
          1884,
          280,
          20,
          13,
          25530,
          34547,
          294,
          7238,
          31093,
          278,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4787,
        "id": 1383,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4786,
        "temperature": 0,
        "text": " You can upload them.",
        "tokens": [
          51564,
          509,
          393,
          6580,
          552,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4788,
        "id": 1384,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4787,
        "temperature": 0,
        "text": " You can have an account.",
        "tokens": [
          51614,
          509,
          393,
          362,
          364,
          2696,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14752326692853654,
        "compression_ratio": 1.6569037656903767,
        "end": 4789,
        "id": 1385,
        "no_speech_prob": 0.0558178536593914,
        "seek": 476200,
        "start": 4788,
        "temperature": 0,
        "text": " You can share them.",
        "tokens": [
          51664,
          509,
          393,
          2073,
          552,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20927191218104932,
        "compression_ratio": 1.5582329317269077,
        "end": 4794,
        "id": 1386,
        "no_speech_prob": 0.34145084023475647,
        "seek": 478900,
        "start": 4789,
        "temperature": 0,
        "text": " It's a bit of a Flickr-style site for sharing JavaScript sketches,",
        "tokens": [
          50364,
          467,
          311,
          257,
          857,
          295,
          257,
          3235,
          618,
          81,
          12,
          15014,
          3621,
          337,
          5414,
          15778,
          34547,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20927191218104932,
        "compression_ratio": 1.5582329317269077,
        "end": 4798,
        "id": 1387,
        "no_speech_prob": 0.34145084023475647,
        "seek": 478900,
        "start": 4794,
        "temperature": 0,
        "text": " in particular made with Processing, Processing.js, or p5.js.",
        "tokens": [
          50614,
          294,
          1729,
          1027,
          365,
          31093,
          278,
          11,
          31093,
          278,
          13,
          25530,
          11,
          420,
          280,
          20,
          13,
          25530,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20927191218104932,
        "compression_ratio": 1.5582329317269077,
        "end": 4800,
        "id": 1388,
        "no_speech_prob": 0.34145084023475647,
        "seek": 478900,
        "start": 4798,
        "temperature": 0,
        "text": " So you should join.",
        "tokens": [
          50814,
          407,
          291,
          820,
          3917,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20927191218104932,
        "compression_ratio": 1.5582329317269077,
        "end": 4801,
        "id": 1389,
        "no_speech_prob": 0.34145084023475647,
        "seek": 478900,
        "start": 4800,
        "temperature": 0,
        "text": " You should sign up.",
        "tokens": [
          50914,
          509,
          820,
          1465,
          493,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20927191218104932,
        "compression_ratio": 1.5582329317269077,
        "end": 4807,
        "id": 1390,
        "no_speech_prob": 0.34145084023475647,
        "seek": 478900,
        "start": 4801,
        "temperature": 0,
        "text": " Tweet at Open Processing on Twitter and congratulate Sinan and all the work that went into this.",
        "tokens": [
          50964,
          314,
          10354,
          412,
          7238,
          31093,
          278,
          322,
          5794,
          293,
          24353,
          11187,
          282,
          293,
          439,
          264,
          589,
          300,
          1437,
          666,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20927191218104932,
        "compression_ratio": 1.5582329317269077,
        "end": 4813,
        "id": 1391,
        "no_speech_prob": 0.34145084023475647,
        "seek": 478900,
        "start": 4807,
        "temperature": 0,
        "text": " So I would also encourage you to, this is something that maybe I'll take a look at using it in a live stream at some point.",
        "tokens": [
          51264,
          407,
          286,
          576,
          611,
          5373,
          291,
          281,
          11,
          341,
          307,
          746,
          300,
          1310,
          286,
          603,
          747,
          257,
          574,
          412,
          1228,
          309,
          294,
          257,
          1621,
          4309,
          412,
          512,
          935,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4815,
        "id": 1392,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4813,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4822,
        "id": 1393,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4815,
        "temperature": 0,
        "text": " So let me come over here and see where I am.",
        "tokens": [
          50464,
          407,
          718,
          385,
          808,
          670,
          510,
          293,
          536,
          689,
          286,
          669,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4828,
        "id": 1394,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4822,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50814,
          3769,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4833,
        "id": 1395,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4828,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          51114,
          400,
          510,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4835,
        "id": 1396,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4833,
        "temperature": 0,
        "text": " Let me just look at this real quick.",
        "tokens": [
          51364,
          961,
          385,
          445,
          574,
          412,
          341,
          957,
          1702,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4839,
        "id": 1397,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4835,
        "temperature": 0,
        "text": " New grammar, expand.",
        "tokens": [
          51464,
          1873,
          22317,
          11,
          5268,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17860965009005564,
        "compression_ratio": 1.191304347826087,
        "end": 4841,
        "id": 1398,
        "no_speech_prob": 0.10966164618730545,
        "seek": 481300,
        "start": 4839,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4842,
        "id": 1399,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4841,
        "temperature": 0,
        "text": " Add rule.",
        "tokens": [
          50364,
          5349,
          4978,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4844,
        "id": 1400,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4842,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4846,
        "id": 1401,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4844,
        "temperature": 0,
        "text": " Okay, everybody.",
        "tokens": [
          50514,
          1033,
          11,
          2201,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4853,
        "id": 1402,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4846,
        "temperature": 0,
        "text": " So, okay.",
        "tokens": [
          50614,
          407,
          11,
          1392,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4857,
        "id": 1403,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4853,
        "temperature": 0,
        "text": " So an hour and 20 minutes in, there's 117 of you still watching, which is really amazing.",
        "tokens": [
          50964,
          407,
          364,
          1773,
          293,
          945,
          2077,
          294,
          11,
          456,
          311,
          2975,
          22,
          295,
          291,
          920,
          1976,
          11,
          597,
          307,
          534,
          2243,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4858,
        "id": 1404,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4857,
        "temperature": 0,
        "text": " I thank you.",
        "tokens": [
          51164,
          286,
          1309,
          291,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4859,
        "id": 1405,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4858,
        "temperature": 0,
        "text": " I appreciate you.",
        "tokens": [
          51214,
          286,
          4449,
          291,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4865,
        "id": 1406,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4859,
        "temperature": 0,
        "text": " And now we're going to look at context-free grammars in the Rita library.",
        "tokens": [
          51264,
          400,
          586,
          321,
          434,
          516,
          281,
          574,
          412,
          4319,
          12,
          10792,
          17570,
          685,
          294,
          264,
          32672,
          6405,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21025485258836013,
        "compression_ratio": 1.5458515283842795,
        "end": 4870,
        "id": 1407,
        "no_speech_prob": 0.0994572713971138,
        "seek": 484100,
        "start": 4865,
        "temperature": 0,
        "text": " And hopefully after this video I'm going to have time to build a little context-free grammar generator from scratch,",
        "tokens": [
          51564,
          400,
          4696,
          934,
          341,
          960,
          286,
          478,
          516,
          281,
          362,
          565,
          281,
          1322,
          257,
          707,
          4319,
          12,
          10792,
          22317,
          19265,
          490,
          8459,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4874,
        "id": 1408,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4870,
        "temperature": 0,
        "text": " if that interests you, which I think it might.",
        "tokens": [
          50364,
          498,
          300,
          8847,
          291,
          11,
          597,
          286,
          519,
          309,
          1062,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4875,
        "id": 1409,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4874,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50564,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4883,
        "id": 1410,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4875,
        "temperature": 0,
        "text": " So I'm going to get started now.",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          483,
          1409,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4886,
        "id": 1411,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4883,
        "temperature": 0,
        "text": " I'm going to do some jumping jacks.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          360,
          512,
          11233,
          7109,
          82,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4890,
        "id": 1412,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4886,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4893,
        "id": 1413,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4890,
        "temperature": 0,
        "text": " Hello and welcome to yet another video about context-free grammars.",
        "tokens": [
          51364,
          2425,
          293,
          2928,
          281,
          1939,
          1071,
          960,
          466,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4894,
        "id": 1414,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4893,
        "temperature": 0,
        "text": " Can you believe it?",
        "tokens": [
          51514,
          1664,
          291,
          1697,
          309,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4895,
        "id": 1415,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4894,
        "temperature": 0,
        "text": " This is my life.",
        "tokens": [
          51564,
          639,
          307,
          452,
          993,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19042831659317017,
        "compression_ratio": 1.5743589743589743,
        "end": 4898,
        "id": 1416,
        "no_speech_prob": 0.010818171314895153,
        "seek": 487000,
        "start": 4895,
        "temperature": 0,
        "text": " I'm making, this is like my third whole video about context-free grammars.",
        "tokens": [
          51614,
          286,
          478,
          1455,
          11,
          341,
          307,
          411,
          452,
          2636,
          1379,
          960,
          466,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1884693770573057,
        "compression_ratio": 1.664179104477612,
        "end": 4899,
        "id": 1417,
        "no_speech_prob": 0.0340985469520092,
        "seek": 489800,
        "start": 4898,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1884693770573057,
        "compression_ratio": 1.664179104477612,
        "end": 4907,
        "id": 1418,
        "no_speech_prob": 0.0340985469520092,
        "seek": 489800,
        "start": 4899,
        "temperature": 0,
        "text": " Now, in this video what I want to do is show you another JavaScript framework library for generating text using a context-free grammar.",
        "tokens": [
          50414,
          823,
          11,
          294,
          341,
          960,
          437,
          286,
          528,
          281,
          360,
          307,
          855,
          291,
          1071,
          15778,
          8388,
          6405,
          337,
          17746,
          2487,
          1228,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1884693770573057,
        "compression_ratio": 1.664179104477612,
        "end": 4911,
        "id": 1419,
        "no_speech_prob": 0.0340985469520092,
        "seek": 489800,
        "start": 4907,
        "temperature": 0,
        "text": " And the library this time that I want to show you, ah, I can't see myself in my preview screen.",
        "tokens": [
          50814,
          400,
          264,
          6405,
          341,
          565,
          300,
          286,
          528,
          281,
          855,
          291,
          11,
          3716,
          11,
          286,
          393,
          380,
          536,
          2059,
          294,
          452,
          14281,
          2568,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1884693770573057,
        "compression_ratio": 1.664179104477612,
        "end": 4913,
        "id": 1420,
        "no_speech_prob": 0.0340985469520092,
        "seek": 489800,
        "start": 4911,
        "temperature": 0,
        "text": " Let me fix this.",
        "tokens": [
          51014,
          961,
          385,
          3191,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1884693770573057,
        "compression_ratio": 1.664179104477612,
        "end": 4916,
        "id": 1421,
        "no_speech_prob": 0.0340985469520092,
        "seek": 489800,
        "start": 4913,
        "temperature": 0,
        "text": " Ah, over here, is called Rita.js.",
        "tokens": [
          51114,
          2438,
          11,
          670,
          510,
          11,
          307,
          1219,
          32672,
          13,
          25530,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1884693770573057,
        "compression_ratio": 1.664179104477612,
        "end": 4924,
        "id": 1422,
        "no_speech_prob": 0.0340985469520092,
        "seek": 489800,
        "start": 4916,
        "temperature": 0,
        "text": " Now, Rita, I introduced the Rita library in a previous video, which you'll find linked in this description, which it has a lot of features and functionality.",
        "tokens": [
          51264,
          823,
          11,
          32672,
          11,
          286,
          7268,
          264,
          32672,
          6405,
          294,
          257,
          3894,
          960,
          11,
          597,
          291,
          603,
          915,
          9408,
          294,
          341,
          3855,
          11,
          597,
          309,
          575,
          257,
          688,
          295,
          4122,
          293,
          14980,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21571811762723056,
        "compression_ratio": 1.5982142857142858,
        "end": 4930,
        "id": 1423,
        "no_speech_prob": 0.25088903307914734,
        "seek": 492400,
        "start": 4924,
        "temperature": 0,
        "text": " But one thing I didn't explore in my previous video was using the Rita grammar object.",
        "tokens": [
          50364,
          583,
          472,
          551,
          286,
          994,
          380,
          6839,
          294,
          452,
          3894,
          960,
          390,
          1228,
          264,
          32672,
          22317,
          2657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21571811762723056,
        "compression_ratio": 1.5982142857142858,
        "end": 4937,
        "id": 1424,
        "no_speech_prob": 0.25088903307914734,
        "seek": 492400,
        "start": 4930,
        "temperature": 0,
        "text": " So if you are wondering what a context-free grammar is, I encourage you to double back a couple videos where I kind of talk through the pieces.",
        "tokens": [
          50664,
          407,
          498,
          291,
          366,
          6359,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          11,
          286,
          5373,
          291,
          281,
          3834,
          646,
          257,
          1916,
          2145,
          689,
          286,
          733,
          295,
          751,
          807,
          264,
          3755,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21571811762723056,
        "compression_ratio": 1.5982142857142858,
        "end": 4953,
        "id": 1425,
        "no_speech_prob": 0.25088903307914734,
        "seek": 492400,
        "start": 4937,
        "temperature": 0,
        "text": " But just to remind you right here, in a sort of quick way, a context-free grammar is a system for generating text based on, ah,",
        "tokens": [
          51014,
          583,
          445,
          281,
          4160,
          291,
          558,
          510,
          11,
          294,
          257,
          1333,
          295,
          1702,
          636,
          11,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          257,
          1185,
          337,
          17746,
          2487,
          2361,
          322,
          11,
          3716,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.31507104985854206,
        "compression_ratio": 1.5957446808510638,
        "end": 4957,
        "id": 1426,
        "no_speech_prob": 0.10372021049261093,
        "seek": 495300,
        "start": 4953,
        "temperature": 0,
        "text": " I'm going to, I'm going to, ah, Matthew, you're going to, sorry, you're going to have to have a little edit point here.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          11,
          286,
          478,
          516,
          281,
          11,
          3716,
          11,
          6789,
          3322,
          86,
          11,
          291,
          434,
          516,
          281,
          11,
          2597,
          11,
          291,
          434,
          516,
          281,
          362,
          281,
          362,
          257,
          707,
          8129,
          935,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.31507104985854206,
        "compression_ratio": 1.5957446808510638,
        "end": 4973,
        "id": 1427,
        "no_speech_prob": 0.10372021049261093,
        "seek": 495300,
        "start": 4957,
        "temperature": 0,
        "text": " Um, I hate my, um, I hate my generic, like, nonsense characters because it would make so much more sense.",
        "tokens": [
          50564,
          3301,
          11,
          286,
          4700,
          452,
          11,
          1105,
          11,
          286,
          4700,
          452,
          19577,
          11,
          411,
          11,
          14925,
          4342,
          570,
          309,
          576,
          652,
          370,
          709,
          544,
          2020,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18597562262352477,
        "compression_ratio": 1.3153153153153154,
        "end": 5000,
        "id": 1428,
        "no_speech_prob": 0.18471591174602509,
        "seek": 497300,
        "start": 4973,
        "temperature": 0,
        "text": " I'm going to go back to where I say, ah, it would make so much more sense if I said, um, sentence is, and then if I said noun is, ah, there we go.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          689,
          286,
          584,
          11,
          3716,
          11,
          309,
          576,
          652,
          370,
          709,
          544,
          2020,
          498,
          286,
          848,
          11,
          1105,
          11,
          8174,
          307,
          11,
          293,
          550,
          498,
          286,
          848,
          23307,
          307,
          11,
          3716,
          11,
          456,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2514067257151884,
        "compression_ratio": 1.141304347826087,
        "end": 5009,
        "id": 1429,
        "no_speech_prob": 0.43393340706825256,
        "seek": 500000,
        "start": 5000,
        "temperature": 0,
        "text": " So, um, just redoing this diagram, even though it won't be in any video.",
        "tokens": [
          50364,
          407,
          11,
          1105,
          11,
          445,
          29956,
          278,
          341,
          10686,
          11,
          754,
          1673,
          309,
          1582,
          380,
          312,
          294,
          604,
          960,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2514067257151884,
        "compression_ratio": 1.141304347826087,
        "end": 5011,
        "id": 1430,
        "no_speech_prob": 0.43393340706825256,
        "seek": 500000,
        "start": 5009,
        "temperature": 0,
        "text": " Go back and redo my first video.",
        "tokens": [
          50814,
          1037,
          646,
          293,
          29956,
          452,
          700,
          960,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.25195488748671135,
        "compression_ratio": 1.673913043478261,
        "end": 5027,
        "id": 1431,
        "no_speech_prob": 0.25679996609687805,
        "seek": 501100,
        "start": 5011,
        "temperature": 0,
        "text": " So this becomes the noun, verb, and this becomes cat, and this becomes, you know, barks.",
        "tokens": [
          50364,
          407,
          341,
          3643,
          264,
          23307,
          11,
          9595,
          11,
          293,
          341,
          3643,
          3857,
          11,
          293,
          341,
          3643,
          11,
          291,
          458,
          11,
          16202,
          82,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.25195488748671135,
        "compression_ratio": 1.673913043478261,
        "end": 5032,
        "id": 1432,
        "no_speech_prob": 0.25679996609687805,
        "seek": 501100,
        "start": 5027,
        "temperature": 0,
        "text": " Okay, and then this is the flattened expansion.",
        "tokens": [
          51164,
          1033,
          11,
          293,
          550,
          341,
          307,
          264,
          24183,
          292,
          11260,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.25195488748671135,
        "compression_ratio": 1.673913043478261,
        "end": 5040,
        "id": 1433,
        "no_speech_prob": 0.25679996609687805,
        "seek": 501100,
        "start": 5032,
        "temperature": 0,
        "text": " Okay, I'm going to have to, there's going to be like a magic moment where this, if we edit this together, where this diagram just magically transforms into something else.",
        "tokens": [
          51414,
          1033,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          11,
          456,
          311,
          516,
          281,
          312,
          411,
          257,
          5585,
          1623,
          689,
          341,
          11,
          498,
          321,
          8129,
          341,
          1214,
          11,
          689,
          341,
          10686,
          445,
          39763,
          35592,
          666,
          746,
          1646,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5043,
        "id": 1434,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5040,
        "temperature": 0,
        "text": " Let me just, I'm just going to start this over.",
        "tokens": [
          50364,
          961,
          385,
          445,
          11,
          286,
          478,
          445,
          516,
          281,
          722,
          341,
          670,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5049,
        "id": 1435,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5043,
        "temperature": 0,
        "text": " Um, or I can start over from where I walk over to here.",
        "tokens": [
          50514,
          3301,
          11,
          420,
          286,
          393,
          722,
          670,
          490,
          689,
          286,
          1792,
          670,
          281,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5055,
        "id": 1436,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5049,
        "temperature": 0,
        "text": " Um, so I think I'll be able to do that.",
        "tokens": [
          50814,
          3301,
          11,
          370,
          286,
          519,
          286,
          603,
          312,
          1075,
          281,
          360,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5058,
        "id": 1437,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5055,
        "temperature": 0,
        "text": " Okay, uh, alright.",
        "tokens": [
          51114,
          1033,
          11,
          2232,
          11,
          5845,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5060,
        "id": 1438,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5058,
        "temperature": 0,
        "text": " Okay, so here we go.",
        "tokens": [
          51264,
          1033,
          11,
          370,
          510,
          321,
          352,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5062,
        "id": 1439,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5060,
        "temperature": 0,
        "text": " I'm going to, somehow this will get spliced together.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          11,
          6063,
          341,
          486,
          483,
          4732,
          4233,
          1214,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5063,
        "id": 1440,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5062,
        "temperature": 0,
        "text": " Matthew, you let me know if this is a disaster.",
        "tokens": [
          51464,
          12434,
          11,
          291,
          718,
          385,
          458,
          498,
          341,
          307,
          257,
          11293,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19628640271108086,
        "compression_ratio": 1.6105769230769231,
        "end": 5065,
        "id": 1441,
        "no_speech_prob": 0.2146705836057663,
        "seek": 504000,
        "start": 5063,
        "temperature": 0,
        "text": " I can always re-record the beginning of this too.",
        "tokens": [
          51514,
          286,
          393,
          1009,
          319,
          12,
          38500,
          264,
          2863,
          295,
          341,
          886,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5070,
        "id": 1442,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5066,
        "temperature": 0,
        "text": " In my, uh, one more time.",
        "tokens": [
          50414,
          682,
          452,
          11,
          2232,
          11,
          472,
          544,
          565,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5081,
        "id": 1443,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5070,
        "temperature": 0,
        "text": " In case you're wondering what a context-free grammar is, um, very, you can go back, double back a couple videos where I describe to you what it is.",
        "tokens": [
          50614,
          682,
          1389,
          291,
          434,
          6359,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          11,
          1105,
          11,
          588,
          11,
          291,
          393,
          352,
          646,
          11,
          3834,
          646,
          257,
          1916,
          2145,
          689,
          286,
          6786,
          281,
          291,
          437,
          309,
          307,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5083,
        "id": 1444,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5081,
        "temperature": 0,
        "text": " I think I better just start this whole video over.",
        "tokens": [
          51164,
          286,
          519,
          286,
          1101,
          445,
          722,
          341,
          1379,
          960,
          670,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5086,
        "id": 1445,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5083,
        "temperature": 0,
        "text": " Okay, it's fine.",
        "tokens": [
          51264,
          1033,
          11,
          309,
          311,
          2489,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5087,
        "id": 1446,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5086,
        "temperature": 0,
        "text": " Ready?",
        "tokens": [
          51414,
          9944,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5088,
        "id": 1447,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5087,
        "temperature": 0,
        "text": " Come on, everybody.",
        "tokens": [
          51464,
          2492,
          322,
          11,
          2201,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5089,
        "id": 1448,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5088,
        "temperature": 0,
        "text": " You're with me.",
        "tokens": [
          51514,
          509,
          434,
          365,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5090,
        "id": 1449,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5089,
        "temperature": 0,
        "text": " I'm with me.",
        "tokens": [
          51564,
          286,
          478,
          365,
          385,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.200163091270669,
        "compression_ratio": 1.4688995215311005,
        "end": 5091,
        "id": 1450,
        "no_speech_prob": 0.2628076374530792,
        "seek": 506500,
        "start": 5090,
        "temperature": 0,
        "text": " Let's go.",
        "tokens": [
          51614,
          961,
          311,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2557813233020259,
        "compression_ratio": 1.7024793388429753,
        "end": 5096,
        "id": 1451,
        "no_speech_prob": 0.34856483340263367,
        "seek": 509100,
        "start": 5092,
        "temperature": 0,
        "text": " Hello and welcome to yet another video about context-free grammars.",
        "tokens": [
          50414,
          2425,
          293,
          2928,
          281,
          1939,
          1071,
          960,
          466,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2557813233020259,
        "compression_ratio": 1.7024793388429753,
        "end": 5098,
        "id": 1452,
        "no_speech_prob": 0.34856483340263367,
        "seek": 509100,
        "start": 5096,
        "temperature": 0,
        "text": " That's right.",
        "tokens": [
          50614,
          663,
          311,
          558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2557813233020259,
        "compression_ratio": 1.7024793388429753,
        "end": 5102,
        "id": 1453,
        "no_speech_prob": 0.34856483340263367,
        "seek": 509100,
        "start": 5098,
        "temperature": 0,
        "text": " Video after video after video about grammar and programming, if you can believe that.",
        "tokens": [
          50714,
          9777,
          934,
          960,
          934,
          960,
          466,
          22317,
          293,
          9410,
          11,
          498,
          291,
          393,
          1697,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2557813233020259,
        "compression_ratio": 1.7024793388429753,
        "end": 5104,
        "id": 1454,
        "no_speech_prob": 0.34856483340263367,
        "seek": 509100,
        "start": 5102,
        "temperature": 0,
        "text": " So, um, here I am in this video.",
        "tokens": [
          50914,
          407,
          11,
          1105,
          11,
          510,
          286,
          669,
          294,
          341,
          960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2557813233020259,
        "compression_ratio": 1.7024793388429753,
        "end": 5114,
        "id": 1455,
        "no_speech_prob": 0.34856483340263367,
        "seek": 509100,
        "start": 5104,
        "temperature": 0,
        "text": " So in this video what I want to do is show you another, different JavaScript, uh, library that allows you, that will generate text based on a grammar, uh, for you automatically without you having to write the...",
        "tokens": [
          51014,
          407,
          294,
          341,
          960,
          437,
          286,
          528,
          281,
          360,
          307,
          855,
          291,
          1071,
          11,
          819,
          15778,
          11,
          2232,
          11,
          6405,
          300,
          4045,
          291,
          11,
          300,
          486,
          8460,
          2487,
          2361,
          322,
          257,
          22317,
          11,
          2232,
          11,
          337,
          291,
          6772,
          1553,
          291,
          1419,
          281,
          2464,
          264,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.27240118299211774,
        "compression_ratio": 1.4024390243902438,
        "end": 5119,
        "id": 1456,
        "no_speech_prob": 0.3380182981491089,
        "seek": 511400,
        "start": 5115,
        "temperature": 0,
        "text": " You know what I got tripped up on there?",
        "tokens": [
          50414,
          509,
          458,
          437,
          286,
          658,
          1376,
          3320,
          493,
          322,
          456,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.27240118299211774,
        "compression_ratio": 1.4024390243902438,
        "end": 5125,
        "id": 1457,
        "no_speech_prob": 0.3380182981491089,
        "seek": 511400,
        "start": 5119,
        "temperature": 0,
        "text": " Is I like, oh, I liked my weird little spontaneous joke about having made multiple...",
        "tokens": [
          50614,
          1119,
          286,
          411,
          11,
          1954,
          11,
          286,
          4501,
          452,
          3657,
          707,
          32744,
          7647,
          466,
          1419,
          1027,
          3866,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.27240118299211774,
        "compression_ratio": 1.4024390243902438,
        "end": 5128,
        "id": 1458,
        "no_speech_prob": 0.3380182981491089,
        "seek": 511400,
        "start": 5125,
        "temperature": 0,
        "text": " I'm just looking at the chat for no reason.",
        "tokens": [
          50914,
          286,
          478,
          445,
          1237,
          412,
          264,
          5081,
          337,
          572,
          1778,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.27240118299211774,
        "compression_ratio": 1.4024390243902438,
        "end": 5129,
        "id": 1459,
        "no_speech_prob": 0.3380182981491089,
        "seek": 511400,
        "start": 5128,
        "temperature": 0,
        "text": " Um, okay.",
        "tokens": [
          51064,
          3301,
          11,
          1392,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.27240118299211774,
        "compression_ratio": 1.4024390243902438,
        "end": 5133,
        "id": 1460,
        "no_speech_prob": 0.3380182981491089,
        "seek": 511400,
        "start": 5129,
        "temperature": 0,
        "text": " One more, one more, um, one more time, everybody.",
        "tokens": [
          51114,
          1485,
          544,
          11,
          472,
          544,
          11,
          1105,
          11,
          472,
          544,
          565,
          11,
          2201,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21299183519580697,
        "compression_ratio": 1.4910179640718564,
        "end": 5143,
        "id": 1461,
        "no_speech_prob": 0.04603036120533943,
        "seek": 513300,
        "start": 5133,
        "temperature": 0,
        "text": " Someday, I don't know.",
        "tokens": [
          50364,
          12297,
          16826,
          11,
          286,
          500,
          380,
          458,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21299183519580697,
        "compression_ratio": 1.4910179640718564,
        "end": 5147,
        "id": 1462,
        "no_speech_prob": 0.04603036120533943,
        "seek": 513300,
        "start": 5143,
        "temperature": 0,
        "text": " I'll have a more fluid way of doing this.",
        "tokens": [
          50864,
          286,
          603,
          362,
          257,
          544,
          9113,
          636,
          295,
          884,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21299183519580697,
        "compression_ratio": 1.4910179640718564,
        "end": 5151,
        "id": 1463,
        "no_speech_prob": 0.04603036120533943,
        "seek": 513300,
        "start": 5147,
        "temperature": 0,
        "text": " Hey, hello there.",
        "tokens": [
          51064,
          1911,
          11,
          7751,
          456,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21299183519580697,
        "compression_ratio": 1.4910179640718564,
        "end": 5156,
        "id": 1464,
        "no_speech_prob": 0.04603036120533943,
        "seek": 513300,
        "start": 5151,
        "temperature": 0,
        "text": " Welcome to another video about context-free grammars.",
        "tokens": [
          51264,
          4027,
          281,
          1071,
          960,
          466,
          4319,
          12,
          10792,
          17570,
          685,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21299183519580697,
        "compression_ratio": 1.4910179640718564,
        "end": 5157,
        "id": 1465,
        "no_speech_prob": 0.04603036120533943,
        "seek": 513300,
        "start": 5156,
        "temperature": 0,
        "text": " That's what I'm talking about.",
        "tokens": [
          51514,
          663,
          311,
          437,
          286,
          478,
          1417,
          466,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21299183519580697,
        "compression_ratio": 1.4910179640718564,
        "end": 5161,
        "id": 1466,
        "no_speech_prob": 0.04603036120533943,
        "seek": 513300,
        "start": 5157,
        "temperature": 0,
        "text": " So, um, I've already done, I've sort of explained what a context-free grammar is.",
        "tokens": [
          51564,
          407,
          11,
          1105,
          11,
          286,
          600,
          1217,
          1096,
          11,
          286,
          600,
          1333,
          295,
          8825,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22437834383836433,
        "compression_ratio": 1.73421926910299,
        "end": 5164,
        "id": 1467,
        "no_speech_prob": 0.4034454822540283,
        "seek": 516100,
        "start": 5161,
        "temperature": 0,
        "text": " I looked at a JavaScript frame, a library called Tracery.",
        "tokens": [
          50364,
          286,
          2956,
          412,
          257,
          15778,
          3920,
          11,
          257,
          6405,
          1219,
          1765,
          326,
          2109,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22437834383836433,
        "compression_ratio": 1.73421926910299,
        "end": 5174,
        "id": 1468,
        "no_speech_prob": 0.4034454822540283,
        "seek": 516100,
        "start": 5164,
        "temperature": 0,
        "text": " And in this video I want to look at yet another JavaScript library, uh, called Rita.js that has, uh, a functionality that allows you to generate text based on a grammar.",
        "tokens": [
          50514,
          400,
          294,
          341,
          960,
          286,
          528,
          281,
          574,
          412,
          1939,
          1071,
          15778,
          6405,
          11,
          2232,
          11,
          1219,
          32672,
          13,
          25530,
          300,
          575,
          11,
          2232,
          11,
          257,
          14980,
          300,
          4045,
          291,
          281,
          8460,
          2487,
          2361,
          322,
          257,
          22317,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22437834383836433,
        "compression_ratio": 1.73421926910299,
        "end": 5178,
        "id": 1469,
        "no_speech_prob": 0.4034454822540283,
        "seek": 516100,
        "start": 5174,
        "temperature": 0,
        "text": " Now, I, I previously made a video about the Rita.js library.",
        "tokens": [
          51014,
          823,
          11,
          286,
          11,
          286,
          8046,
          1027,
          257,
          960,
          466,
          264,
          32672,
          13,
          25530,
          6405,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22437834383836433,
        "compression_ratio": 1.73421926910299,
        "end": 5185,
        "id": 1470,
        "no_speech_prob": 0.4034454822540283,
        "seek": 516100,
        "start": 5178,
        "temperature": 0,
        "text": " I showed some other aspects of it, um, ways that you can generate and do and evaluate, actually analyze text with the Rita library.",
        "tokens": [
          51214,
          286,
          4712,
          512,
          661,
          7270,
          295,
          309,
          11,
          1105,
          11,
          2098,
          300,
          291,
          393,
          8460,
          293,
          360,
          293,
          13059,
          11,
          767,
          12477,
          2487,
          365,
          264,
          32672,
          6405,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22437834383836433,
        "compression_ratio": 1.73421926910299,
        "end": 5187,
        "id": 1471,
        "no_speech_prob": 0.4034454822540283,
        "seek": 516100,
        "start": 5185,
        "temperature": 0,
        "text": " And I'll make sure to link to that in this video's description.",
        "tokens": [
          51564,
          400,
          286,
          603,
          652,
          988,
          281,
          2113,
          281,
          300,
          294,
          341,
          960,
          311,
          3855,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22437834383836433,
        "compression_ratio": 1.73421926910299,
        "end": 5188,
        "id": 1472,
        "no_speech_prob": 0.4034454822540283,
        "seek": 516100,
        "start": 5187,
        "temperature": 0,
        "text": " So I encourage you to check that out.",
        "tokens": [
          51664,
          407,
          286,
          5373,
          291,
          281,
          1520,
          300,
          484,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20978685661598487,
        "compression_ratio": 1.7542372881355932,
        "end": 5194,
        "id": 1473,
        "no_speech_prob": 0.34152889251708984,
        "seek": 518800,
        "start": 5188,
        "temperature": 0,
        "text": " But an aspect that I did not look at is the R, the Rita grammar, the Ri grammar object.",
        "tokens": [
          50364,
          583,
          364,
          4171,
          300,
          286,
          630,
          406,
          574,
          412,
          307,
          264,
          497,
          11,
          264,
          32672,
          22317,
          11,
          264,
          33668,
          22317,
          2657,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20978685661598487,
        "compression_ratio": 1.7542372881355932,
        "end": 5197,
        "id": 1474,
        "no_speech_prob": 0.34152889251708984,
        "seek": 518800,
        "start": 5194,
        "temperature": 0,
        "text": " So how does the Ri grammar object work and what kinds of things can you do with it?",
        "tokens": [
          50664,
          407,
          577,
          775,
          264,
          33668,
          22317,
          2657,
          589,
          293,
          437,
          3685,
          295,
          721,
          393,
          291,
          360,
          365,
          309,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.20978685661598487,
        "compression_ratio": 1.7542372881355932,
        "end": 5203,
        "id": 1475,
        "no_speech_prob": 0.34152889251708984,
        "seek": 518800,
        "start": 5197,
        "temperature": 0,
        "text": " Okay, so first of all, um, the Ri grammar object is designed for use with a context-free grammar.",
        "tokens": [
          50814,
          1033,
          11,
          370,
          700,
          295,
          439,
          11,
          1105,
          11,
          264,
          33668,
          22317,
          2657,
          307,
          4761,
          337,
          764,
          365,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20978685661598487,
        "compression_ratio": 1.7542372881355932,
        "end": 5209,
        "id": 1476,
        "no_speech_prob": 0.34152889251708984,
        "seek": 518800,
        "start": 5203,
        "temperature": 0,
        "text": " Now, if you're wondering what a context-free grammar is, you can double back a couple videos where I maybe talk through it in a bit more detail.",
        "tokens": [
          51114,
          823,
          11,
          498,
          291,
          434,
          6359,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          11,
          291,
          393,
          3834,
          646,
          257,
          1916,
          2145,
          689,
          286,
          1310,
          751,
          807,
          309,
          294,
          257,
          857,
          544,
          2607,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18550319831912257,
        "compression_ratio": 1.6741573033707866,
        "end": 5218,
        "id": 1477,
        "no_speech_prob": 0.49992185831069946,
        "seek": 520900,
        "start": 5209,
        "temperature": 0,
        "text": " But just to remind you, if you're wondering, a context-free grammar is a, is a system that defines the structure of a particular language.",
        "tokens": [
          50364,
          583,
          445,
          281,
          4160,
          291,
          11,
          498,
          291,
          434,
          6359,
          11,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          257,
          11,
          307,
          257,
          1185,
          300,
          23122,
          264,
          3877,
          295,
          257,
          1729,
          2856,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18550319831912257,
        "compression_ratio": 1.6741573033707866,
        "end": 5221,
        "id": 1478,
        "no_speech_prob": 0.49992185831069946,
        "seek": 520900,
        "start": 5218,
        "temperature": 0,
        "text": " And in this sense, it could be a very small, tiny little language.",
        "tokens": [
          50814,
          400,
          294,
          341,
          2020,
          11,
          309,
          727,
          312,
          257,
          588,
          1359,
          11,
          5870,
          707,
          2856,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18550319831912257,
        "compression_ratio": 1.6741573033707866,
        "end": 5224,
        "id": 1479,
        "no_speech_prob": 0.49992185831069946,
        "seek": 520900,
        "start": 5221,
        "temperature": 0,
        "text": " Like, here's a language that has only these elements.",
        "tokens": [
          50964,
          1743,
          11,
          510,
          311,
          257,
          2856,
          300,
          575,
          787,
          613,
          4959,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18550319831912257,
        "compression_ratio": 1.6741573033707866,
        "end": 5229,
        "id": 1480,
        "no_speech_prob": 0.49992185831069946,
        "seek": 520900,
        "start": 5224,
        "temperature": 0,
        "text": " Sentence, nouns, verbs, and the cat, dog, meows, and barks.",
        "tokens": [
          51114,
          23652,
          655,
          11,
          48184,
          11,
          30051,
          11,
          293,
          264,
          3857,
          11,
          3000,
          11,
          385,
          1509,
          11,
          293,
          16202,
          82,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18550319831912257,
        "compression_ratio": 1.6741573033707866,
        "end": 5232,
        "id": 1481,
        "no_speech_prob": 0.49992185831069946,
        "seek": 520900,
        "start": 5229,
        "temperature": 0,
        "text": " So there are terminal and non-terminal characters.",
        "tokens": [
          51364,
          407,
          456,
          366,
          14709,
          293,
          2107,
          12,
          7039,
          2071,
          4342,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18550319831912257,
        "compression_ratio": 1.6741573033707866,
        "end": 5235,
        "id": 1482,
        "no_speech_prob": 0.49992185831069946,
        "seek": 520900,
        "start": 5232,
        "temperature": 0,
        "text": " These are non-terminal characters, meaning they get replaced with something.",
        "tokens": [
          51514,
          1981,
          366,
          2107,
          12,
          7039,
          2071,
          4342,
          11,
          3620,
          436,
          483,
          10772,
          365,
          746,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5239,
        "id": 1483,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5235,
        "temperature": 0,
        "text": " Sass, for sentence, gets replaced with the noun verb.",
        "tokens": [
          50364,
          318,
          640,
          11,
          337,
          8174,
          11,
          2170,
          10772,
          365,
          264,
          23307,
          9595,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5242,
        "id": 1484,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5239,
        "temperature": 0,
        "text": " Noun gets replaced with cat or dog.",
        "tokens": [
          50564,
          426,
          1733,
          2170,
          10772,
          365,
          3857,
          420,
          3000,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5244,
        "id": 1485,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5242,
        "temperature": 0,
        "text": " Verb gets replaced with meows or barks.",
        "tokens": [
          50714,
          27034,
          2170,
          10772,
          365,
          385,
          1509,
          420,
          16202,
          82,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5250,
        "id": 1486,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5244,
        "temperature": 0,
        "text": " So if I start with sentence, this gets expanded to the and v.",
        "tokens": [
          50814,
          407,
          498,
          286,
          722,
          365,
          8174,
          11,
          341,
          2170,
          14342,
          281,
          264,
          293,
          371,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5252,
        "id": 1487,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5250,
        "temperature": 0,
        "text": " The is terminal, so it stays as the.",
        "tokens": [
          51114,
          440,
          307,
          14709,
          11,
          370,
          309,
          10834,
          382,
          264,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5255,
        "id": 1488,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5252,
        "temperature": 0,
        "text": " N becomes flip a coin, cat or dog.",
        "tokens": [
          51214,
          426,
          3643,
          7929,
          257,
          11464,
          11,
          3857,
          420,
          3000,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5257,
        "id": 1489,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5255,
        "temperature": 0,
        "text": " V becomes flip a coin, cat or dog.",
        "tokens": [
          51364,
          691,
          3643,
          7929,
          257,
          11464,
          11,
          3857,
          420,
          3000,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16800912536016785,
        "compression_ratio": 1.867816091954023,
        "end": 5258,
        "id": 1490,
        "no_speech_prob": 0.3241786062717438,
        "seek": 523500,
        "start": 5257,
        "temperature": 0,
        "text": " And we get this expansion.",
        "tokens": [
          51464,
          400,
          321,
          483,
          341,
          11260,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21404952662331717,
        "compression_ratio": 1.6666666666666667,
        "end": 5270,
        "id": 1491,
        "no_speech_prob": 0.5076903104782104,
        "seek": 525800,
        "start": 5259,
        "temperature": 0,
        "text": " So certainly, the idea here is to design sophisticated and interesting grammars with all sorts of creative language in them to generate text with some purpose.",
        "tokens": [
          50414,
          407,
          3297,
          11,
          264,
          1558,
          510,
          307,
          281,
          1715,
          16950,
          293,
          1880,
          17570,
          685,
          365,
          439,
          7527,
          295,
          5880,
          2856,
          294,
          552,
          281,
          8460,
          2487,
          365,
          512,
          4334,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21404952662331717,
        "compression_ratio": 1.6666666666666667,
        "end": 5273,
        "id": 1492,
        "no_speech_prob": 0.5076903104782104,
        "seek": 525800,
        "start": 5270,
        "temperature": 0,
        "text": " Maybe you're making automatic Harry Potter spells.",
        "tokens": [
          50964,
          2704,
          291,
          434,
          1455,
          12509,
          9378,
          18115,
          25053,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21404952662331717,
        "compression_ratio": 1.6666666666666667,
        "end": 5276,
        "id": 1493,
        "no_speech_prob": 0.5076903104782104,
        "seek": 525800,
        "start": 5273,
        "temperature": 0,
        "text": " Or maybe you're making recipes that are going to randomly generate.",
        "tokens": [
          51114,
          1610,
          1310,
          291,
          434,
          1455,
          13035,
          300,
          366,
          516,
          281,
          16979,
          8460,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21404952662331717,
        "compression_ratio": 1.6666666666666667,
        "end": 5280,
        "id": 1494,
        "no_speech_prob": 0.5076903104782104,
        "seek": 525800,
        "start": 5276,
        "temperature": 0,
        "text": " You're going to cook some strange thing for dinner based on what your context-free grammar made you.",
        "tokens": [
          51264,
          509,
          434,
          516,
          281,
          2543,
          512,
          5861,
          551,
          337,
          6148,
          2361,
          322,
          437,
          428,
          4319,
          12,
          10792,
          22317,
          1027,
          291,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21404952662331717,
        "compression_ratio": 1.6666666666666667,
        "end": 5281,
        "id": 1495,
        "no_speech_prob": 0.5076903104782104,
        "seek": 525800,
        "start": 5280,
        "temperature": 0,
        "text": " Lots of possibilities there.",
        "tokens": [
          51464,
          15908,
          295,
          12178,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21404952662331717,
        "compression_ratio": 1.6666666666666667,
        "end": 5285,
        "id": 1496,
        "no_speech_prob": 0.5076903104782104,
        "seek": 525800,
        "start": 5281,
        "temperature": 0,
        "text": " But let's see if we can figure out how to make a simple grammar work with the Rita library.",
        "tokens": [
          51514,
          583,
          718,
          311,
          536,
          498,
          321,
          393,
          2573,
          484,
          577,
          281,
          652,
          257,
          2199,
          22317,
          589,
          365,
          264,
          32672,
          6405,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5290,
        "id": 1497,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5285,
        "temperature": 0,
        "text": " And then we'll also look at some other examples of grammars that you can generate with the Rita library.",
        "tokens": [
          50364,
          400,
          550,
          321,
          603,
          611,
          574,
          412,
          512,
          661,
          5110,
          295,
          17570,
          685,
          300,
          291,
          393,
          8460,
          365,
          264,
          32672,
          6405,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5291,
        "id": 1498,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5290,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5298,
        "id": 1499,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5291,
        "temperature": 0,
        "text": " So looking at this, the first thing you might notice is I need to say make a new Rita grammar object.",
        "tokens": [
          50664,
          407,
          1237,
          412,
          341,
          11,
          264,
          700,
          551,
          291,
          1062,
          3449,
          307,
          286,
          643,
          281,
          584,
          652,
          257,
          777,
          32672,
          22317,
          2657,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5300,
        "id": 1500,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5298,
        "temperature": 0,
        "text": " So let me go to code.",
        "tokens": [
          51014,
          407,
          718,
          385,
          352,
          281,
          3089,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5302,
        "id": 1501,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5300,
        "temperature": 0,
        "text": " And I'm going to say var.",
        "tokens": [
          51114,
          400,
          286,
          478,
          516,
          281,
          584,
          1374,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5305,
        "id": 1502,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5302,
        "temperature": 0,
        "text": " I'm going to call it RG, just like in the example.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          818,
          309,
          497,
          38,
          11,
          445,
          411,
          294,
          264,
          1365,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5307,
        "id": 1503,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5305,
        "temperature": 0,
        "text": " By the way, Rita is by Daniel Howe.",
        "tokens": [
          51364,
          3146,
          264,
          636,
          11,
          32672,
          307,
          538,
          8033,
          1012,
          68,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5310,
        "id": 1504,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5307,
        "temperature": 0,
        "text": " Thank you, Daniel Howe, for this wonderful generative text library.",
        "tokens": [
          51464,
          1044,
          291,
          11,
          8033,
          1012,
          68,
          11,
          337,
          341,
          3715,
          1337,
          1166,
          2487,
          6405,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1747821807861328,
        "compression_ratio": 1.6943521594684385,
        "end": 5314,
        "id": 1505,
        "no_speech_prob": 0.3701631426811218,
        "seek": 528500,
        "start": 5310,
        "temperature": 0,
        "text": " I encourage everybody watching to thank Daniel Howe and contribute to the development of Rita.",
        "tokens": [
          51614,
          286,
          5373,
          2201,
          1976,
          281,
          1309,
          8033,
          1012,
          68,
          293,
          10586,
          281,
          264,
          3250,
          295,
          32672,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5318,
        "id": 1506,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5314,
        "temperature": 0,
        "text": " RG equals new RI grammar.",
        "tokens": [
          50364,
          497,
          38,
          6915,
          777,
          30474,
          22317,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5321,
        "id": 1507,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5318,
        "temperature": 0,
        "text": " Now I'm going to leave the argument here empty.",
        "tokens": [
          50564,
          823,
          286,
          478,
          516,
          281,
          1856,
          264,
          6770,
          510,
          6707,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5326,
        "id": 1508,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5321,
        "temperature": 0,
        "text": " So ultimately, there's a lot of different ways that we might be able to create the grammar.",
        "tokens": [
          50714,
          407,
          6284,
          11,
          456,
          311,
          257,
          688,
          295,
          819,
          2098,
          300,
          321,
          1062,
          312,
          1075,
          281,
          1884,
          264,
          22317,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5330,
        "id": 1509,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5326,
        "temperature": 0,
        "text": " I could do it dynamically in code by just adding the rules, which is what I'm going to try to do right now.",
        "tokens": [
          50964,
          286,
          727,
          360,
          309,
          43492,
          294,
          3089,
          538,
          445,
          5127,
          264,
          4474,
          11,
          597,
          307,
          437,
          286,
          478,
          516,
          281,
          853,
          281,
          360,
          558,
          586,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5334,
        "id": 1510,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5330,
        "temperature": 0,
        "text": " Or I could load the grammar from a preexisting file.",
        "tokens": [
          51164,
          1610,
          286,
          727,
          3677,
          264,
          22317,
          490,
          257,
          659,
          36447,
          3991,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5335,
        "id": 1511,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5334,
        "temperature": 0,
        "text": " And I can mix and match, too.",
        "tokens": [
          51364,
          400,
          286,
          393,
          2890,
          293,
          2995,
          11,
          886,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5337,
        "id": 1512,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5335,
        "temperature": 0,
        "text": " But let's try to just dynamically generate it with code.",
        "tokens": [
          51414,
          583,
          718,
          311,
          853,
          281,
          445,
          43492,
          8460,
          309,
          365,
          3089,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18022788780322974,
        "compression_ratio": 1.6789297658862876,
        "end": 5342,
        "id": 1513,
        "no_speech_prob": 0.017176086083054543,
        "seek": 531400,
        "start": 5337,
        "temperature": 0,
        "text": " So the first thing I want to do, just looking at this, is see if I have an object there.",
        "tokens": [
          51514,
          407,
          264,
          700,
          551,
          286,
          528,
          281,
          360,
          11,
          445,
          1237,
          412,
          341,
          11,
          307,
          536,
          498,
          286,
          362,
          364,
          2657,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5344,
        "id": 1514,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5342,
        "temperature": 0,
        "text": " So you can see I have some Rita grammar object.",
        "tokens": [
          50364,
          407,
          291,
          393,
          536,
          286,
          362,
          512,
          32672,
          22317,
          2657,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5346,
        "id": 1515,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5344,
        "temperature": 0,
        "text": " It's got, like, some rules in it.",
        "tokens": [
          50464,
          467,
          311,
          658,
          11,
          411,
          11,
          512,
          4474,
          294,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5349,
        "id": 1516,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5346,
        "temperature": 0,
        "text": " Something's happening, but I can't do anything yet.",
        "tokens": [
          50564,
          6595,
          311,
          2737,
          11,
          457,
          286,
          393,
          380,
          360,
          1340,
          1939,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5353,
        "id": 1517,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5349,
        "temperature": 0,
        "text": " Now, if I go to here and I say, let me look at a result.",
        "tokens": [
          50714,
          823,
          11,
          498,
          286,
          352,
          281,
          510,
          293,
          286,
          584,
          11,
          718,
          385,
          574,
          412,
          257,
          1874,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5355,
        "id": 1518,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5353,
        "temperature": 0,
        "text": " Let me expand.",
        "tokens": [
          50914,
          961,
          385,
          5268,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5363,
        "id": 1519,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5355,
        "temperature": 0,
        "text": " Remember, an expansion is expanding from the sort of start of the grammar out and getting a sentence that fits that grammar.",
        "tokens": [
          51014,
          5459,
          11,
          364,
          11260,
          307,
          14702,
          490,
          264,
          1333,
          295,
          722,
          295,
          264,
          22317,
          484,
          293,
          1242,
          257,
          8174,
          300,
          9001,
          300,
          22317,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17073833432971922,
        "compression_ratio": 1.7037037037037037,
        "end": 5370,
        "id": 1520,
        "no_speech_prob": 0.020022965967655182,
        "seek": 534200,
        "start": 5363,
        "temperature": 0,
        "text": " So if I get some sort of result and I say console.log result, I should get nothing.",
        "tokens": [
          51414,
          407,
          498,
          286,
          483,
          512,
          1333,
          295,
          1874,
          293,
          286,
          584,
          11076,
          13,
          4987,
          1874,
          11,
          286,
          820,
          483,
          1825,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5373,
        "id": 1521,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5371,
        "temperature": 0,
        "text": " So no grammar rules found.",
        "tokens": [
          50414,
          407,
          572,
          22317,
          4474,
          1352,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5376,
        "id": 1522,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5373,
        "temperature": 0,
        "text": " So the first thing that I need for a grammar to do anything is to have some rules.",
        "tokens": [
          50514,
          407,
          264,
          700,
          551,
          300,
          286,
          643,
          337,
          257,
          22317,
          281,
          360,
          1340,
          307,
          281,
          362,
          512,
          4474,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5382,
        "id": 1523,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5376,
        "temperature": 0,
        "text": " So let's look now at the add rule function.",
        "tokens": [
          50664,
          407,
          718,
          311,
          574,
          586,
          412,
          264,
          909,
          4978,
          2445,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5386,
        "id": 1524,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5382,
        "temperature": 0,
        "text": " So the add rule function requires a name.",
        "tokens": [
          50964,
          407,
          264,
          909,
          4978,
          2445,
          7029,
          257,
          1315,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5387,
        "id": 1525,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5386,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51164,
          876,
          11,
          574,
          412,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5388,
        "id": 1526,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5387,
        "temperature": 0,
        "text": " Oh, wait.",
        "tokens": [
          51214,
          876,
          11,
          1699,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5389,
        "id": 1527,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5388,
        "temperature": 0,
        "text": " Oh, I love that this has that.",
        "tokens": [
          51264,
          876,
          11,
          286,
          959,
          300,
          341,
          575,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5390,
        "id": 1528,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5389,
        "temperature": 0,
        "text": " That is so fantastic.",
        "tokens": [
          51314,
          663,
          307,
          370,
          5456,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5394,
        "id": 1529,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5390,
        "temperature": 0,
        "text": " So it has the rule name and the rule definition and the rule weight.",
        "tokens": [
          51364,
          407,
          309,
          575,
          264,
          4978,
          1315,
          293,
          264,
          4978,
          7123,
          293,
          264,
          4978,
          3364,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5396,
        "id": 1530,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5394,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51564,
          407,
          510,
          311,
          264,
          551,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5398,
        "id": 1531,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5396,
        "temperature": 0,
        "text": " We're going to have to figure out what does Rita.",
        "tokens": [
          51664,
          492,
          434,
          516,
          281,
          362,
          281,
          2573,
          484,
          437,
          775,
          32672,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16683698583532264,
        "compression_ratio": 1.834710743801653,
        "end": 5399,
        "id": 1532,
        "no_speech_prob": 0.0014103511348366737,
        "seek": 537000,
        "start": 5398,
        "temperature": 0,
        "text": " I honestly don't know this.",
        "tokens": [
          51764,
          286,
          6095,
          500,
          380,
          458,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5401,
        "id": 1533,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5399,
        "temperature": 0,
        "text": " I'm going to figure this out while doing the video.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          2573,
          341,
          484,
          1339,
          884,
          264,
          960,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5404,
        "id": 1534,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5401,
        "temperature": 0,
        "text": " What does Rita expect that how this is formatted?",
        "tokens": [
          50464,
          708,
          775,
          32672,
          2066,
          300,
          577,
          341,
          307,
          1254,
          32509,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5405,
        "id": 1535,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5404,
        "temperature": 0,
        "text": " So I'm going to look.",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          574,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5407,
        "id": 1536,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5405,
        "temperature": 0,
        "text": " I'm sure there's an example that I can look at.",
        "tokens": [
          50664,
          286,
          478,
          988,
          456,
          311,
          364,
          1365,
          300,
          286,
          393,
          574,
          412,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5411,
        "id": 1537,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5407,
        "temperature": 0,
        "text": " But on the one hand, I know that I could say RG.add rule.",
        "tokens": [
          50764,
          583,
          322,
          264,
          472,
          1011,
          11,
          286,
          458,
          300,
          286,
          727,
          584,
          497,
          38,
          13,
          25224,
          4978,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5417,
        "id": 1538,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5411,
        "temperature": 0,
        "text": " And so I could say maybe like start becomes a sentence.",
        "tokens": [
          50964,
          400,
          370,
          286,
          727,
          584,
          1310,
          411,
          722,
          3643,
          257,
          8174,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5421,
        "id": 1539,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5417,
        "temperature": 0,
        "text": " Or, you know, I could let me just say the cat meows.",
        "tokens": [
          51264,
          1610,
          11,
          291,
          458,
          11,
          286,
          727,
          718,
          385,
          445,
          584,
          264,
          3857,
          385,
          1509,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5425,
        "id": 1540,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5421,
        "temperature": 0,
        "text": " There's a rule sentence becomes the cat meows.",
        "tokens": [
          51464,
          821,
          311,
          257,
          4978,
          8174,
          3643,
          264,
          3857,
          385,
          1509,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19011877477169037,
        "compression_ratio": 1.7254098360655739,
        "end": 5428,
        "id": 1541,
        "no_speech_prob": 0.007937935180962086,
        "seek": 539900,
        "start": 5425,
        "temperature": 0,
        "text": " The probability of a weight of one.",
        "tokens": [
          51664,
          440,
          8482,
          295,
          257,
          3364,
          295,
          472,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5431,
        "id": 1542,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5428,
        "temperature": 0,
        "text": " Now, I doubt that's enough.",
        "tokens": [
          50364,
          823,
          11,
          286,
          6385,
          300,
          311,
          1547,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5433,
        "id": 1543,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5431,
        "temperature": 0,
        "text": " So that did not work.",
        "tokens": [
          50514,
          407,
          300,
          630,
          406,
          589,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5439,
        "id": 1544,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5433,
        "temperature": 0,
        "text": " So I expect that I've got to conform to the syntax of the Rita library",
        "tokens": [
          50614,
          407,
          286,
          2066,
          300,
          286,
          600,
          658,
          281,
          18975,
          281,
          264,
          28431,
          295,
          264,
          32672,
          6405,
          50914
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5441,
        "id": 1545,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5439,
        "temperature": 0,
        "text": " and how it expects it to work.",
        "tokens": [
          50914,
          293,
          577,
          309,
          33280,
          309,
          281,
          589,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5443,
        "id": 1546,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5441,
        "temperature": 0,
        "text": " Now, I'm kind of getting a little clue here.",
        "tokens": [
          51014,
          823,
          11,
          286,
          478,
          733,
          295,
          1242,
          257,
          707,
          13602,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5445,
        "id": 1547,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5443,
        "temperature": 0,
        "text": " Rule not found start.",
        "tokens": [
          51114,
          27533,
          406,
          1352,
          722,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5448,
        "id": 1548,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5445,
        "temperature": 0,
        "text": " So I think by definition, Rita probably expects –",
        "tokens": [
          51214,
          407,
          286,
          519,
          538,
          7123,
          11,
          32672,
          1391,
          33280,
          220,
          5815,
          51364
        ]
      },
      {
        "avg_logprob": -0.17328157791724572,
        "compression_ratio": 1.5913043478260869,
        "end": 5454,
        "id": 1549,
        "no_speech_prob": 0.00037409510696306825,
        "seek": 542800,
        "start": 5448,
        "temperature": 0,
        "text": " I'm just guessing from looking at this error that Rita expects there to be a rule called start.",
        "tokens": [
          51364,
          286,
          478,
          445,
          17939,
          490,
          1237,
          412,
          341,
          6713,
          300,
          32672,
          33280,
          456,
          281,
          312,
          257,
          4978,
          1219,
          722,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17990506864061542,
        "compression_ratio": 1.6237113402061856,
        "end": 5459,
        "id": 1550,
        "no_speech_prob": 0.012431452982127666,
        "seek": 545400,
        "start": 5454,
        "temperature": 0,
        "text": " So let's see if that works, if I now get the cat meows.",
        "tokens": [
          50364,
          407,
          718,
          311,
          536,
          498,
          300,
          1985,
          11,
          498,
          286,
          586,
          483,
          264,
          3857,
          385,
          1509,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17990506864061542,
        "compression_ratio": 1.6237113402061856,
        "end": 5460,
        "id": 1551,
        "no_speech_prob": 0.012431452982127666,
        "seek": 545400,
        "start": 5459,
        "temperature": 0,
        "text": " Ah, I did.",
        "tokens": [
          50614,
          2438,
          11,
          286,
          630,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17990506864061542,
        "compression_ratio": 1.6237113402061856,
        "end": 5462,
        "id": 1552,
        "no_speech_prob": 0.012431452982127666,
        "seek": 545400,
        "start": 5460,
        "temperature": 0,
        "text": " So now every time I get the cat meows.",
        "tokens": [
          50664,
          407,
          586,
          633,
          565,
          286,
          483,
          264,
          3857,
          385,
          1509,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17990506864061542,
        "compression_ratio": 1.6237113402061856,
        "end": 5468,
        "id": 1553,
        "no_speech_prob": 0.012431452982127666,
        "seek": 545400,
        "start": 5462,
        "temperature": 0,
        "text": " Now, how can I get maybe – so let me see if I can now call this.",
        "tokens": [
          50764,
          823,
          11,
          577,
          393,
          286,
          483,
          1310,
          1662,
          370,
          718,
          385,
          536,
          498,
          286,
          393,
          586,
          818,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17990506864061542,
        "compression_ratio": 1.6237113402061856,
        "end": 5474,
        "id": 1554,
        "no_speech_prob": 0.012431452982127666,
        "seek": 545400,
        "start": 5468,
        "temperature": 0,
        "text": " Now, I'm expecting maybe if I make a rule that has this syntax with the sort of tag symbols around it,",
        "tokens": [
          51064,
          823,
          11,
          286,
          478,
          9650,
          1310,
          498,
          286,
          652,
          257,
          4978,
          300,
          575,
          341,
          28431,
          365,
          264,
          1333,
          295,
          6162,
          16944,
          926,
          309,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.17990506864061542,
        "compression_ratio": 1.6237113402061856,
        "end": 5482,
        "id": 1555,
        "no_speech_prob": 0.012431452982127666,
        "seek": 545400,
        "start": 5474,
        "temperature": 0,
        "text": " I can say add rule n and I can say cat.",
        "tokens": [
          51364,
          286,
          393,
          584,
          909,
          4978,
          297,
          293,
          286,
          393,
          584,
          3857,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17154851167098337,
        "compression_ratio": 1.4768518518518519,
        "end": 5487,
        "id": 1556,
        "no_speech_prob": 0.0011335554299876094,
        "seek": 548200,
        "start": 5482,
        "temperature": 0,
        "text": " So now let's just see if I have a rule which the start is the n meows",
        "tokens": [
          50364,
          407,
          586,
          718,
          311,
          445,
          536,
          498,
          286,
          362,
          257,
          4978,
          597,
          264,
          722,
          307,
          264,
          297,
          385,
          1509,
          50614
        ]
      },
      {
        "avg_logprob": -0.17154851167098337,
        "compression_ratio": 1.4768518518518519,
        "end": 5490,
        "id": 1557,
        "no_speech_prob": 0.0011335554299876094,
        "seek": 548200,
        "start": 5487,
        "temperature": 0,
        "text": " and maybe I'm going to get cat.",
        "tokens": [
          50614,
          293,
          1310,
          286,
          478,
          516,
          281,
          483,
          3857,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17154851167098337,
        "compression_ratio": 1.4768518518518519,
        "end": 5495,
        "id": 1558,
        "no_speech_prob": 0.0011335554299876094,
        "seek": 548200,
        "start": 5490,
        "temperature": 0,
        "text": " Perfect. Now, how do I get – now, I have a feeling that the syntax it expects is this.",
        "tokens": [
          50764,
          10246,
          13,
          823,
          11,
          577,
          360,
          286,
          483,
          1662,
          586,
          11,
          286,
          362,
          257,
          2633,
          300,
          264,
          28431,
          309,
          33280,
          307,
          341,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17154851167098337,
        "compression_ratio": 1.4768518518518519,
        "end": 5503,
        "id": 1559,
        "no_speech_prob": 0.0011335554299876094,
        "seek": 548200,
        "start": 5495,
        "temperature": 0,
        "text": " So there are a bunch of sort of conventional syntaxes for grammars.",
        "tokens": [
          51014,
          407,
          456,
          366,
          257,
          3840,
          295,
          1333,
          295,
          16011,
          28431,
          279,
          337,
          17570,
          685,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17154851167098337,
        "compression_ratio": 1.4768518518518519,
        "end": 5507,
        "id": 1560,
        "no_speech_prob": 0.0011335554299876094,
        "seek": 548200,
        "start": 5503,
        "temperature": 0,
        "text": " And you're going to see them in a variety of different ways.",
        "tokens": [
          51414,
          400,
          291,
          434,
          516,
          281,
          536,
          552,
          294,
          257,
          5673,
          295,
          819,
          2098,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5512,
        "id": 1561,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5507,
        "temperature": 0,
        "text": " You can encode it in JSON as we saw in tracery with those sort of pound symbols.",
        "tokens": [
          50364,
          509,
          393,
          2058,
          1429,
          309,
          294,
          31828,
          382,
          321,
          1866,
          294,
          504,
          326,
          2109,
          365,
          729,
          1333,
          295,
          12013,
          16944,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5514,
        "id": 1562,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5512,
        "temperature": 0,
        "text": " This, I believe, is based on some standard.",
        "tokens": [
          50614,
          639,
          11,
          286,
          1697,
          11,
          307,
          2361,
          322,
          512,
          3832,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5516,
        "id": 1563,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5514,
        "temperature": 0,
        "text": " I should look it up and try to figure out what it is.",
        "tokens": [
          50714,
          286,
          820,
          574,
          309,
          493,
          293,
          853,
          281,
          2573,
          484,
          437,
          309,
          307,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5518,
        "id": 1564,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5516,
        "temperature": 0,
        "text": " Annotation appear here to explain.",
        "tokens": [
          50814,
          1107,
          2247,
          399,
          4204,
          510,
          281,
          2903,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5521,
        "id": 1565,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5518,
        "temperature": 0,
        "text": " But I have a feeling based on what I've done before and seen before",
        "tokens": [
          50914,
          583,
          286,
          362,
          257,
          2633,
          2361,
          322,
          437,
          286,
          600,
          1096,
          949,
          293,
          1612,
          949,
          51064
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5526,
        "id": 1566,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5521,
        "temperature": 0,
        "text": " that it's expecting the pipe symbol as one or the other.",
        "tokens": [
          51064,
          300,
          309,
          311,
          9650,
          264,
          11240,
          5986,
          382,
          472,
          420,
          264,
          661,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5529,
        "id": 1567,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5526,
        "temperature": 0,
        "text": " Let's say what would happen if I didn't do this, okay, cat, dog.",
        "tokens": [
          51314,
          961,
          311,
          584,
          437,
          576,
          1051,
          498,
          286,
          994,
          380,
          360,
          341,
          11,
          1392,
          11,
          3857,
          11,
          3000,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5531,
        "id": 1568,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5529,
        "temperature": 0,
        "text": " Well, I'm going to get the cat, dog, meows.",
        "tokens": [
          51464,
          1042,
          11,
          286,
          478,
          516,
          281,
          483,
          264,
          3857,
          11,
          3000,
          11,
          385,
          1509,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5532,
        "id": 1569,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5531,
        "temperature": 0,
        "text": " That's what I'm getting.",
        "tokens": [
          51564,
          663,
          311,
          437,
          286,
          478,
          1242,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20355416582776353,
        "compression_ratio": 1.6677524429967427,
        "end": 5534,
        "id": 1570,
        "no_speech_prob": 0.7370662093162537,
        "seek": 550700,
        "start": 5532,
        "temperature": 0,
        "text": " That's the whole thing that's replaced.",
        "tokens": [
          51614,
          663,
          311,
          264,
          1379,
          551,
          300,
          311,
          10772,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5540,
        "id": 1571,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5534,
        "temperature": 0,
        "text": " But if I put this pipe symbol here, the cat meows, the dog meows, the cat meows, the dog meows.",
        "tokens": [
          50364,
          583,
          498,
          286,
          829,
          341,
          11240,
          5986,
          510,
          11,
          264,
          3857,
          385,
          1509,
          11,
          264,
          3000,
          385,
          1509,
          11,
          264,
          3857,
          385,
          1509,
          11,
          264,
          3000,
          385,
          1509,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5541,
        "id": 1572,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5540,
        "temperature": 0,
        "text": " So we can see now the rules.",
        "tokens": [
          50664,
          407,
          321,
          393,
          536,
          586,
          264,
          4474,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5547,
        "id": 1573,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5541,
        "temperature": 0,
        "text": " Now, one thing I'm curious about is does this require these tags?",
        "tokens": [
          50714,
          823,
          11,
          472,
          551,
          286,
          478,
          6369,
          466,
          307,
          775,
          341,
          3651,
          613,
          18632,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5549,
        "id": 1574,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5547,
        "temperature": 0,
        "text": " It does not.",
        "tokens": [
          51014,
          467,
          775,
          406,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5552,
        "id": 1575,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5549,
        "temperature": 0,
        "text": " The cat, the cat, the cat, the cat, the dog.",
        "tokens": [
          51114,
          440,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3000,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5558,
        "id": 1576,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5552,
        "temperature": 0,
        "text": " So we can see here that this can be a useful distinction just for ourselves",
        "tokens": [
          51264,
          407,
          321,
          393,
          536,
          510,
          300,
          341,
          393,
          312,
          257,
          4420,
          16844,
          445,
          337,
          4175,
          51564
        ]
      },
      {
        "avg_logprob": -0.1572202156329977,
        "compression_ratio": 1.7830188679245282,
        "end": 5562,
        "id": 1577,
        "no_speech_prob": 0.01771184802055359,
        "seek": 553400,
        "start": 5558,
        "temperature": 0,
        "text": " to kind of illustrate what I mean to be non-terminal,",
        "tokens": [
          51564,
          281,
          733,
          295,
          23221,
          437,
          286,
          914,
          281,
          312,
          2107,
          12,
          7039,
          2071,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.208012833887217,
        "compression_ratio": 1.734375,
        "end": 5565,
        "id": 1578,
        "no_speech_prob": 0.11756902188062668,
        "seek": 556200,
        "start": 5562,
        "temperature": 0,
        "text": " maybe put the tag, the greater than, less than around it.",
        "tokens": [
          50364,
          1310,
          829,
          264,
          6162,
          11,
          264,
          5044,
          813,
          11,
          1570,
          813,
          926,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.208012833887217,
        "compression_ratio": 1.734375,
        "end": 5567,
        "id": 1579,
        "no_speech_prob": 0.11756902188062668,
        "seek": 556200,
        "start": 5565,
        "temperature": 0,
        "text": " And that can be useful here.",
        "tokens": [
          50514,
          400,
          300,
          393,
          312,
          4420,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.208012833887217,
        "compression_ratio": 1.734375,
        "end": 5573,
        "id": 1580,
        "no_speech_prob": 0.11756902188062668,
        "seek": 556200,
        "start": 5567,
        "temperature": 0,
        "text": " So one thing that I'm kind of the other thing that I'm kind of curious about is if I say this,",
        "tokens": [
          50614,
          407,
          472,
          551,
          300,
          286,
          478,
          733,
          295,
          220,
          3322,
          661,
          551,
          300,
          286,
          478,
          733,
          295,
          6369,
          466,
          307,
          498,
          286,
          584,
          341,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.208012833887217,
        "compression_ratio": 1.734375,
        "end": 5580,
        "id": 1581,
        "no_speech_prob": 0.11756902188062668,
        "seek": 556200,
        "start": 5573,
        "temperature": 0,
        "text": " I could also probably put them in a separate line, the dog, the dog, the cat, the cat, the dog.",
        "tokens": [
          50914,
          286,
          727,
          611,
          1391,
          829,
          552,
          294,
          257,
          4994,
          1622,
          11,
          264,
          3000,
          11,
          264,
          3000,
          11,
          264,
          3857,
          11,
          264,
          3857,
          11,
          264,
          3000,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.208012833887217,
        "compression_ratio": 1.734375,
        "end": 5584,
        "id": 1582,
        "no_speech_prob": 0.11756902188062668,
        "seek": 556200,
        "start": 5580,
        "temperature": 0,
        "text": " And so now let's look at let's think about this weight.",
        "tokens": [
          51264,
          400,
          370,
          586,
          718,
          311,
          574,
          412,
          718,
          311,
          519,
          466,
          341,
          3364,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16643309305949383,
        "compression_ratio": 1.5353535353535352,
        "end": 5592,
        "id": 1583,
        "no_speech_prob": 0.324201762676239,
        "seek": 558400,
        "start": 5584,
        "temperature": 0,
        "text": " So if I go back now to the documentation and we look at the rule weight optional defaults to one.",
        "tokens": [
          50364,
          407,
          498,
          286,
          352,
          646,
          586,
          281,
          264,
          14333,
          293,
          321,
          574,
          412,
          264,
          4978,
          3364,
          17312,
          7576,
          82,
          281,
          472,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16643309305949383,
        "compression_ratio": 1.5353535353535352,
        "end": 5596,
        "id": 1584,
        "no_speech_prob": 0.324201762676239,
        "seek": 558400,
        "start": 5592,
        "temperature": 0,
        "text": " So how might I alter the probability?",
        "tokens": [
          50764,
          407,
          577,
          1062,
          286,
          11337,
          264,
          8482,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.16643309305949383,
        "compression_ratio": 1.5353535353535352,
        "end": 5601,
        "id": 1585,
        "no_speech_prob": 0.324201762676239,
        "seek": 558400,
        "start": 5596,
        "temperature": 0,
        "text": " So I'm just going to make sort of a guess that if I do something like five,",
        "tokens": [
          50964,
          407,
          286,
          478,
          445,
          516,
          281,
          652,
          1333,
          295,
          257,
          2041,
          300,
          498,
          286,
          360,
          746,
          411,
          1732,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.16643309305949383,
        "compression_ratio": 1.5353535353535352,
        "end": 5607,
        "id": 1586,
        "no_speech_prob": 0.324201762676239,
        "seek": 558400,
        "start": 5601,
        "temperature": 0,
        "text": " then I've got kind of a five to one, maybe a five out of six chance of picking cat over dog.",
        "tokens": [
          51214,
          550,
          286,
          600,
          658,
          733,
          295,
          257,
          1732,
          281,
          472,
          11,
          1310,
          257,
          1732,
          484,
          295,
          2309,
          2931,
          295,
          8867,
          3857,
          670,
          3000,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2725701275993796,
        "compression_ratio": 1.783132530120482,
        "end": 5619,
        "id": 1587,
        "no_speech_prob": 0.40354132652282715,
        "seek": 560700,
        "start": 5607,
        "temperature": 0,
        "text": " And what we could do is I could also do this, you know, maybe a hundred times just to sort of see how this works.",
        "tokens": [
          50364,
          400,
          437,
          321,
          727,
          360,
          307,
          286,
          727,
          611,
          360,
          341,
          11,
          291,
          458,
          11,
          1310,
          257,
          3262,
          1413,
          445,
          281,
          1333,
          295,
          536,
          577,
          341,
          1985,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2725701275993796,
        "compression_ratio": 1.783132530120482,
        "end": 5623,
        "id": 1588,
        "no_speech_prob": 0.40354132652282715,
        "seek": 560700,
        "start": 5619,
        "temperature": 0,
        "text": " And let's run this.",
        "tokens": [
          50964,
          400,
          718,
          311,
          1190,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2725701275993796,
        "compression_ratio": 1.783132530120482,
        "end": 5629,
        "id": 1589,
        "no_speech_prob": 0.40354132652282715,
        "seek": 560700,
        "start": 5623,
        "temperature": 0,
        "text": " And so you can see here it's picking cat, you know, pick cat 16 times, then a pick dog and cat four times,",
        "tokens": [
          51164,
          400,
          370,
          291,
          393,
          536,
          510,
          309,
          311,
          8867,
          3857,
          11,
          291,
          458,
          11,
          1888,
          3857,
          3165,
          1413,
          11,
          550,
          257,
          1888,
          3000,
          293,
          3857,
          1451,
          1413,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.2725701275993796,
        "compression_ratio": 1.783132530120482,
        "end": 5632,
        "id": 1590,
        "no_speech_prob": 0.40354132652282715,
        "seek": 560700,
        "start": 5629,
        "temperature": 0,
        "text": " then a pick dog and cat four times and cat seven times.",
        "tokens": [
          51464,
          550,
          257,
          1888,
          3000,
          293,
          3857,
          1451,
          1413,
          293,
          3857,
          3407,
          1413,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16495921395041727,
        "compression_ratio": 1.8083623693379791,
        "end": 5638,
        "id": 1591,
        "no_speech_prob": 0.5155789852142334,
        "seek": 563200,
        "start": 5632,
        "temperature": 0,
        "text": " So you can see that that weighting allows you to add the rules and kind of weight them particularly.",
        "tokens": [
          50364,
          407,
          291,
          393,
          536,
          300,
          300,
          3364,
          278,
          4045,
          291,
          281,
          909,
          264,
          4474,
          293,
          733,
          295,
          3364,
          552,
          4098,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16495921395041727,
        "compression_ratio": 1.8083623693379791,
        "end": 5640,
        "id": 1592,
        "no_speech_prob": 0.5155789852142334,
        "seek": 563200,
        "start": 5638,
        "temperature": 0,
        "text": " And I could also probably do cat or unicorn.",
        "tokens": [
          50664,
          400,
          286,
          727,
          611,
          1391,
          360,
          3857,
          420,
          28122,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16495921395041727,
        "compression_ratio": 1.8083623693379791,
        "end": 5645,
        "id": 1593,
        "no_speech_prob": 0.5155789852142334,
        "seek": 563200,
        "start": 5640,
        "temperature": 0,
        "text": " And both I'm imagining both of those probably have the weight of five and the dog has the weight of one.",
        "tokens": [
          50764,
          400,
          1293,
          286,
          478,
          27798,
          1293,
          295,
          729,
          1391,
          362,
          264,
          3364,
          295,
          1732,
          293,
          264,
          3000,
          575,
          264,
          3364,
          295,
          472,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16495921395041727,
        "compression_ratio": 1.8083623693379791,
        "end": 5651,
        "id": 1594,
        "no_speech_prob": 0.5155789852142334,
        "seek": 563200,
        "start": 5645,
        "temperature": 0,
        "text": " So if I ran this again, we can see there's going to be a lot of cat and unicorn and not so much dog.",
        "tokens": [
          51014,
          407,
          498,
          286,
          5872,
          341,
          797,
          11,
          321,
          393,
          536,
          456,
          311,
          516,
          281,
          312,
          257,
          688,
          295,
          3857,
          293,
          28122,
          293,
          406,
          370,
          709,
          3000,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16495921395041727,
        "compression_ratio": 1.8083623693379791,
        "end": 5655,
        "id": 1595,
        "no_speech_prob": 0.5155789852142334,
        "seek": 563200,
        "start": 5651,
        "temperature": 0,
        "text": " I'm sort of guessing. So I'd have to really like strictly evaluate how this is working.",
        "tokens": [
          51314,
          286,
          478,
          1333,
          295,
          17939,
          13,
          407,
          286,
          1116,
          362,
          281,
          534,
          411,
          20792,
          13059,
          577,
          341,
          307,
          1364,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16495921395041727,
        "compression_ratio": 1.8083623693379791,
        "end": 5658,
        "id": 1596,
        "no_speech_prob": 0.5155789852142334,
        "seek": 563200,
        "start": 5655,
        "temperature": 0,
        "text": " But you can see it's nice that you have this ability to manipulate the weights.",
        "tokens": [
          51514,
          583,
          291,
          393,
          536,
          309,
          311,
          1481,
          300,
          291,
          362,
          341,
          3485,
          281,
          20459,
          264,
          17443,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19954062143961587,
        "compression_ratio": 1.528735632183908,
        "end": 5664,
        "id": 1597,
        "no_speech_prob": 0.32764729857444763,
        "seek": 565800,
        "start": 5658,
        "temperature": 0,
        "text": " So if I go back to this particular simple scenario, let's just finish implementing that.",
        "tokens": [
          50364,
          407,
          498,
          286,
          352,
          646,
          281,
          341,
          1729,
          2199,
          9005,
          11,
          718,
          311,
          445,
          2413,
          18114,
          300,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19954062143961587,
        "compression_ratio": 1.528735632183908,
        "end": 5671,
        "id": 1598,
        "no_speech_prob": 0.32764729857444763,
        "seek": 565800,
        "start": 5664,
        "temperature": 0,
        "text": " I'm going to say the noun and I can add a cat, unicorn, dog.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          584,
          264,
          23307,
          293,
          286,
          393,
          909,
          257,
          3857,
          11,
          28122,
          11,
          3000,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19954062143961587,
        "compression_ratio": 1.528735632183908,
        "end": 5674,
        "id": 1599,
        "no_speech_prob": 0.32764729857444763,
        "seek": 565800,
        "start": 5671,
        "temperature": 0,
        "text": " I'm going to just leave the default weights.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          445,
          1856,
          264,
          7576,
          17443,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19954062143961587,
        "compression_ratio": 1.528735632183908,
        "end": 5678,
        "id": 1600,
        "no_speech_prob": 0.32764729857444763,
        "seek": 565800,
        "start": 5674,
        "temperature": 0,
        "text": " And then I'm going to add another rule.",
        "tokens": [
          51164,
          400,
          550,
          286,
          478,
          516,
          281,
          909,
          1071,
          4978,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19954062143961587,
        "compression_ratio": 1.528735632183908,
        "end": 5680,
        "id": 1601,
        "no_speech_prob": 0.32764729857444763,
        "seek": 565800,
        "start": 5678,
        "temperature": 0,
        "text": " What sound does a unicorn make?",
        "tokens": [
          51364,
          708,
          1626,
          775,
          257,
          28122,
          652,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.1915244674682617,
        "compression_ratio": 1.5660377358490567,
        "end": 5689,
        "id": 1602,
        "no_speech_prob": 0.21731430292129517,
        "seek": 568000,
        "start": 5680,
        "temperature": 0,
        "text": " Meows, cat meows, the dog barks, the unicorn, the tulips.",
        "tokens": [
          50364,
          1923,
          1509,
          11,
          3857,
          385,
          1509,
          11,
          264,
          3000,
          16202,
          82,
          11,
          264,
          28122,
          11,
          264,
          30210,
          2600,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1915244674682617,
        "compression_ratio": 1.5660377358490567,
        "end": 5693,
        "id": 1603,
        "no_speech_prob": 0.21731430292129517,
        "seek": 568000,
        "start": 5689,
        "temperature": 0,
        "text": " That's the sound of a unicorn. It's a word that I made up called tulips.",
        "tokens": [
          50814,
          663,
          311,
          264,
          1626,
          295,
          257,
          28122,
          13,
          467,
          311,
          257,
          1349,
          300,
          286,
          1027,
          493,
          1219,
          30210,
          2600,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1915244674682617,
        "compression_ratio": 1.5660377358490567,
        "end": 5695,
        "id": 1604,
        "no_speech_prob": 0.21731430292129517,
        "seek": 568000,
        "start": 5693,
        "temperature": 0,
        "text": " And then I'm going to put a period here.",
        "tokens": [
          51014,
          400,
          550,
          286,
          478,
          516,
          281,
          829,
          257,
          2896,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1915244674682617,
        "compression_ratio": 1.5660377358490567,
        "end": 5702,
        "id": 1605,
        "no_speech_prob": 0.21731430292129517,
        "seek": 568000,
        "start": 5695,
        "temperature": 0,
        "text": " And so now we can see if I generate this, we can see all of these different possible sentences,",
        "tokens": [
          51114,
          400,
          370,
          586,
          321,
          393,
          536,
          498,
          286,
          8460,
          341,
          11,
          321,
          393,
          536,
          439,
          295,
          613,
          819,
          1944,
          16579,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.1915244674682617,
        "compression_ratio": 1.5660377358490567,
        "end": 5704,
        "id": 1606,
        "no_speech_prob": 0.21731430292129517,
        "seek": 568000,
        "start": 5702,
        "temperature": 0,
        "text": " all which conform to that grammar.",
        "tokens": [
          51464,
          439,
          597,
          18975,
          281,
          300,
          22317,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1915244674682617,
        "compression_ratio": 1.5660377358490567,
        "end": 5706,
        "id": 1607,
        "no_speech_prob": 0.21731430292129517,
        "seek": 568000,
        "start": 5704,
        "temperature": 0,
        "text": " So this is a very basic idea.",
        "tokens": [
          51564,
          407,
          341,
          307,
          257,
          588,
          3875,
          1558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19783579628422576,
        "compression_ratio": 1.6538461538461537,
        "end": 5711,
        "id": 1608,
        "no_speech_prob": 0.22536009550094604,
        "seek": 570600,
        "start": 5707,
        "temperature": 0,
        "text": " You can imagine how you could make this much more sophisticated through nesting.",
        "tokens": [
          50414,
          509,
          393,
          3811,
          577,
          291,
          727,
          652,
          341,
          709,
          544,
          16950,
          807,
          297,
          8714,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19783579628422576,
        "compression_ratio": 1.6538461538461537,
        "end": 5720,
        "id": 1609,
        "no_speech_prob": 0.22536009550094604,
        "seek": 570600,
        "start": 5715,
        "temperature": 0,
        "text": " So I'm going to kind of like stay away from more exciting and interesting possibilities with this.",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          733,
          295,
          411,
          1754,
          1314,
          490,
          544,
          4670,
          293,
          1880,
          12178,
          365,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19783579628422576,
        "compression_ratio": 1.6538461538461537,
        "end": 5722,
        "id": 1610,
        "no_speech_prob": 0.22536009550094604,
        "seek": 570600,
        "start": 5720,
        "temperature": 0,
        "text": " Here I'm just kind of giving you the building blocks.",
        "tokens": [
          51064,
          1692,
          286,
          478,
          445,
          733,
          295,
          2902,
          291,
          264,
          2390,
          8474,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19783579628422576,
        "compression_ratio": 1.6538461538461537,
        "end": 5727,
        "id": 1611,
        "no_speech_prob": 0.22536009550094604,
        "seek": 570600,
        "start": 5722,
        "temperature": 0,
        "text": " But let's look at actually what happens if you want to encode a grammar,",
        "tokens": [
          51164,
          583,
          718,
          311,
          574,
          412,
          767,
          437,
          2314,
          498,
          291,
          528,
          281,
          2058,
          1429,
          257,
          22317,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.19783579628422576,
        "compression_ratio": 1.6538461538461537,
        "end": 5730,
        "id": 1612,
        "no_speech_prob": 0.22536009550094604,
        "seek": 570600,
        "start": 5727,
        "temperature": 0,
        "text": " not in your code but have it come from a separate file.",
        "tokens": [
          51414,
          406,
          294,
          428,
          3089,
          457,
          362,
          309,
          808,
          490,
          257,
          4994,
          3991,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19783579628422576,
        "compression_ratio": 1.6538461538461537,
        "end": 5735,
        "id": 1613,
        "no_speech_prob": 0.22536009550094604,
        "seek": 570600,
        "start": 5730,
        "temperature": 0,
        "text": " So what I'm going to do there is I actually already have that here.",
        "tokens": [
          51564,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          456,
          307,
          286,
          767,
          1217,
          362,
          300,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5738,
        "id": 1614,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5735,
        "temperature": 0,
        "text": " So this is a particular grammar.",
        "tokens": [
          50364,
          407,
          341,
          307,
          257,
          1729,
          22317,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5744,
        "id": 1615,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5738,
        "temperature": 0,
        "text": " It's a little bit further along from what I just made in that example.",
        "tokens": [
          50514,
          467,
          311,
          257,
          707,
          857,
          3052,
          2051,
          490,
          437,
          286,
          445,
          1027,
          294,
          300,
          1365,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5747,
        "id": 1616,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5744,
        "temperature": 0,
        "text": " And you can see it written with this particular syntax of the production rules.",
        "tokens": [
          50814,
          400,
          291,
          393,
          536,
          309,
          3720,
          365,
          341,
          1729,
          28431,
          295,
          264,
          4265,
          4474,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5750,
        "id": 1617,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5747,
        "temperature": 0,
        "text": " S becomes noun phrase, verb phrase.",
        "tokens": [
          50964,
          318,
          3643,
          23307,
          9535,
          11,
          9595,
          9535,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5752,
        "id": 1618,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5750,
        "temperature": 0,
        "text": " NP for noun phrase becomes a term or noun.",
        "tokens": [
          51114,
          38611,
          337,
          23307,
          9535,
          3643,
          257,
          1433,
          420,
          23307,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5754,
        "id": 1619,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5752,
        "temperature": 0,
        "text": " Verb phrase becomes verb or verb noun phrase.",
        "tokens": [
          51214,
          27034,
          9535,
          3643,
          9595,
          420,
          9595,
          23307,
          9535,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5757,
        "id": 1620,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5754,
        "temperature": 0,
        "text": " Term is a or the. A noun is rainbow or unicorn. And V is dancers.",
        "tokens": [
          51314,
          19835,
          307,
          257,
          420,
          264,
          13,
          316,
          23307,
          307,
          18526,
          420,
          28122,
          13,
          400,
          691,
          307,
          25199,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22706484998393262,
        "compression_ratio": 1.7083333333333333,
        "end": 5761,
        "id": 1621,
        "no_speech_prob": 0.002889522584155202,
        "seek": 573500,
        "start": 5757,
        "temperature": 0,
        "text": " So the syntax that Rita expects, though, however, looks something like this.",
        "tokens": [
          51464,
          407,
          264,
          28431,
          300,
          32672,
          33280,
          11,
          1673,
          11,
          4461,
          11,
          1542,
          746,
          411,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5765,
        "id": 1622,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5762,
        "temperature": 0,
        "text": " So you can see start. We have curly brackets.",
        "tokens": [
          50414,
          407,
          291,
          393,
          536,
          722,
          13,
          492,
          362,
          32066,
          26179,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5767,
        "id": 1623,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5765,
        "temperature": 0,
        "text": " Start becomes noun phrase, verb phrase.",
        "tokens": [
          50564,
          6481,
          3643,
          23307,
          9535,
          11,
          9595,
          9535,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5770,
        "id": 1624,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5767,
        "temperature": 0,
        "text": " Noun phrase becomes a term or noun, etc., etc.",
        "tokens": [
          50664,
          426,
          1733,
          9535,
          3643,
          257,
          1433,
          420,
          23307,
          11,
          5183,
          7933,
          5183,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5772,
        "id": 1625,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5770,
        "temperature": 0,
        "text": " So you can see. And then noun.",
        "tokens": [
          50814,
          407,
          291,
          393,
          536,
          13,
          400,
          550,
          23307,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5774,
        "id": 1626,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5772,
        "temperature": 0,
        "text": " Okay. I think I'm back.",
        "tokens": [
          50914,
          1033,
          13,
          286,
          519,
          286,
          478,
          646,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5777,
        "id": 1627,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5774,
        "temperature": 0,
        "text": " And hopefully...",
        "tokens": [
          51014,
          400,
          4696,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5779,
        "id": 1628,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5777,
        "temperature": 0,
        "text": " Okay. That's as good as I'm going to get it right now.",
        "tokens": [
          51164,
          1033,
          13,
          663,
          311,
          382,
          665,
          382,
          286,
          478,
          516,
          281,
          483,
          309,
          558,
          586,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5782,
        "id": 1629,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5779,
        "temperature": 0,
        "text": " Okay. So let me see where I was.",
        "tokens": [
          51264,
          1033,
          13,
          407,
          718,
          385,
          536,
          689,
          286,
          390,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.291634023757208,
        "compression_ratio": 1.558252427184466,
        "end": 5789,
        "id": 1630,
        "no_speech_prob": 0.032588403671979904,
        "seek": 576100,
        "start": 5786,
        "temperature": 0,
        "text": " The function of file or URL.",
        "tokens": [
          51614,
          440,
          2445,
          295,
          3991,
          420,
          12905,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5792,
        "id": 1631,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5790,
        "temperature": 0,
        "text": " Check of the object.",
        "tokens": [
          50414,
          6881,
          295,
          264,
          2657,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5797,
        "id": 1632,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5794,
        "temperature": 0,
        "text": " Okay. So what are the options?",
        "tokens": [
          50614,
          1033,
          13,
          407,
          437,
          366,
          264,
          3956,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5799,
        "id": 1633,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5797,
        "temperature": 0,
        "text": " I'm just reading this.",
        "tokens": [
          50764,
          286,
          478,
          445,
          3760,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5805,
        "id": 1634,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5803,
        "temperature": 0,
        "text": " Function or object. Oh, I can do a callback.",
        "tokens": [
          51064,
          11166,
          882,
          420,
          2657,
          13,
          876,
          11,
          286,
          393,
          360,
          257,
          818,
          3207,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5807,
        "id": 1635,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5805,
        "temperature": 0,
        "text": " Great, great, great, great, great, great, great.",
        "tokens": [
          51164,
          3769,
          11,
          869,
          11,
          869,
          11,
          869,
          11,
          869,
          11,
          869,
          11,
          869,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5810,
        "id": 1636,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5807,
        "temperature": 0,
        "text": " Okay. So let's see if we get this to work.",
        "tokens": [
          51264,
          1033,
          13,
          407,
          718,
          311,
          536,
          498,
          321,
          483,
          341,
          281,
          589,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5815,
        "id": 1637,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5812,
        "temperature": 0,
        "text": " And I think I was coming over here.",
        "tokens": [
          51514,
          400,
          286,
          519,
          286,
          390,
          1348,
          670,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20135887632978725,
        "compression_ratio": 1.6626506024096386,
        "end": 5818,
        "id": 1638,
        "no_speech_prob": 0.001187867601402104,
        "seek": 578900,
        "start": 5815,
        "temperature": 0,
        "text": " Okay. So I'm recording this.",
        "tokens": [
          51664,
          1033,
          13,
          407,
          286,
          478,
          6613,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5822,
        "id": 1639,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5820,
        "temperature": 0,
        "text": " I'm going to try to...",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          853,
          281,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5826,
        "id": 1640,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5822,
        "temperature": 0,
        "text": " I have this sort of panicked feeling that I forgot to do something.",
        "tokens": [
          50514,
          286,
          362,
          341,
          1333,
          295,
          2462,
          12598,
          2633,
          300,
          286,
          5298,
          281,
          360,
          746,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5830,
        "id": 1641,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5828,
        "temperature": 0,
        "text": " No good. I didn't.",
        "tokens": [
          50814,
          883,
          665,
          13,
          286,
          994,
          380,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5835,
        "id": 1642,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5830,
        "temperature": 0,
        "text": " I had a panicked feeling that I forgot to hit record to disk",
        "tokens": [
          50914,
          286,
          632,
          257,
          2462,
          12598,
          2633,
          300,
          286,
          5298,
          281,
          2045,
          2136,
          281,
          12355,
          51164
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5838,
        "id": 1643,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5835,
        "temperature": 0,
        "text": " for the whole first hour and a half of this.",
        "tokens": [
          51164,
          337,
          264,
          1379,
          700,
          1773,
          293,
          257,
          1922,
          295,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5840,
        "id": 1644,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5838,
        "temperature": 0,
        "text": " YouTube would save it.",
        "tokens": [
          51314,
          3088,
          576,
          3155,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5842,
        "id": 1645,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5840,
        "temperature": 0,
        "text": " But it's really good to have the disk backup",
        "tokens": [
          51414,
          583,
          309,
          311,
          534,
          665,
          281,
          362,
          264,
          12355,
          14807,
          51514
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5844,
        "id": 1646,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5842,
        "temperature": 0,
        "text": " because sometimes the stream has a problem with it",
        "tokens": [
          51514,
          570,
          2171,
          264,
          4309,
          575,
          257,
          1154,
          365,
          309,
          51614
        ]
      },
      {
        "avg_logprob": -0.17654502802881702,
        "compression_ratio": 1.7695652173913043,
        "end": 5847,
        "id": 1647,
        "no_speech_prob": 0.0029809356201440096,
        "seek": 581900,
        "start": 5844,
        "temperature": 0,
        "text": " and I sort of thought I forgot to hit record, but I did not, thankfully.",
        "tokens": [
          51614,
          293,
          286,
          1333,
          295,
          1194,
          286,
          5298,
          281,
          2045,
          2136,
          11,
          457,
          286,
          630,
          406,
          11,
          27352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5849,
        "id": 1648,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5847,
        "temperature": 0,
        "text": " Okay. What time is it? 3.45.",
        "tokens": [
          50364,
          1033,
          13,
          708,
          565,
          307,
          309,
          30,
          805,
          13,
          8465,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5852,
        "id": 1649,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5849,
        "temperature": 0,
        "text": " Oh, I'm kind of running out of time here.",
        "tokens": [
          50464,
          876,
          11,
          286,
          478,
          733,
          295,
          2614,
          484,
          295,
          565,
          510,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5855,
        "id": 1650,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5852,
        "temperature": 0,
        "text": " But I'm going to keep going.",
        "tokens": [
          50614,
          583,
          286,
          478,
          516,
          281,
          1066,
          516,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5860,
        "id": 1651,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5856,
        "temperature": 0,
        "text": " So I'm just sort of curious here to see...",
        "tokens": [
          50814,
          407,
          286,
          478,
          445,
          1333,
          295,
          6369,
          510,
          281,
          536,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5863,
        "id": 1652,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5861,
        "temperature": 0,
        "text": " I'm just going to... Okay.",
        "tokens": [
          51064,
          286,
          478,
          445,
          516,
          281,
          485,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5868,
        "id": 1653,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5863,
        "temperature": 0,
        "text": " Okay. So I'm going to go from where I attempted to...",
        "tokens": [
          51164,
          1033,
          13,
          407,
          286,
          478,
          516,
          281,
          352,
          490,
          689,
          286,
          18997,
          281,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.18395275316740337,
        "compression_ratio": 1.779874213836478,
        "end": 5875,
        "id": 1654,
        "no_speech_prob": 0.00006204954843269661,
        "seek": 584700,
        "start": 5871,
        "temperature": 0,
        "text": " I'm going to go from where I attempted to load from a file.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          352,
          490,
          689,
          286,
          18997,
          281,
          3677,
          490,
          257,
          3991,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5876,
        "id": 1655,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5875,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5883,
        "id": 1656,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5878,
        "temperature": 0,
        "text": " So I'm going to go here to the reference and look at load from.",
        "tokens": [
          50514,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          281,
          264,
          6408,
          293,
          574,
          412,
          3677,
          490,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5886,
        "id": 1657,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5883,
        "temperature": 0,
        "text": " And if I look at load from, I can see here's a function,",
        "tokens": [
          50764,
          400,
          498,
          286,
          574,
          412,
          3677,
          490,
          11,
          286,
          393,
          536,
          510,
          311,
          257,
          2445,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5890,
        "id": 1658,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5886,
        "temperature": 0,
        "text": " load from file or URL and then option.",
        "tokens": [
          50914,
          3677,
          490,
          3991,
          420,
          12905,
          293,
          550,
          3614,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5893,
        "id": 1659,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5890,
        "temperature": 0,
        "text": " And in JavaScript, that option we can see here in JavaScript",
        "tokens": [
          51114,
          400,
          294,
          15778,
          11,
          300,
          3614,
          321,
          393,
          536,
          510,
          294,
          15778,
          51264
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5896,
        "id": 1660,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5893,
        "temperature": 0,
        "text": " is a callback, at least to tell you when the file is loaded",
        "tokens": [
          51264,
          307,
          257,
          818,
          3207,
          11,
          412,
          1935,
          281,
          980,
          291,
          562,
          264,
          3991,
          307,
          13210,
          51414
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5898,
        "id": 1661,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5896,
        "temperature": 0,
        "text": " because that's not going to happen immediately.",
        "tokens": [
          51414,
          570,
          300,
          311,
          406,
          516,
          281,
          1051,
          4258,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5900,
        "id": 1662,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5898,
        "temperature": 0,
        "text": " So let's go to the code.",
        "tokens": [
          51514,
          407,
          718,
          311,
          352,
          281,
          264,
          3089,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2004664711330248,
        "compression_ratio": 1.720524017467249,
        "end": 5902,
        "id": 1663,
        "no_speech_prob": 0.00015355988580267876,
        "seek": 587500,
        "start": 5900,
        "temperature": 0,
        "text": " And I should be able to now say...",
        "tokens": [
          51614,
          400,
          286,
          820,
          312,
          1075,
          281,
          586,
          584,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5910,
        "id": 1664,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5906,
        "temperature": 0,
        "text": " Rg load from test...",
        "tokens": [
          50414,
          497,
          70,
          3677,
          490,
          1500,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5913,
        "id": 1665,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5910,
        "temperature": 0,
        "text": " Oh, and then the name of the file, test.grammar.",
        "tokens": [
          50614,
          876,
          11,
          293,
          550,
          264,
          1315,
          295,
          264,
          3991,
          11,
          1500,
          13,
          1342,
          6209,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5915,
        "id": 1666,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5913,
        "temperature": 0,
        "text": " And then I'm going to give it a callback.",
        "tokens": [
          50764,
          400,
          550,
          286,
          478,
          516,
          281,
          976,
          309,
          257,
          818,
          3207,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5918,
        "id": 1667,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5915,
        "temperature": 0,
        "text": " I'm just going to call it grammar ready.",
        "tokens": [
          50864,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          22317,
          1919,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5921,
        "id": 1668,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5919,
        "temperature": 0,
        "text": " Do you guys hear that beeping?",
        "tokens": [
          51064,
          1144,
          291,
          1074,
          1568,
          300,
          34800,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5924,
        "id": 1669,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5921,
        "temperature": 0,
        "text": " Something beeped. I have no idea what it was.",
        "tokens": [
          51164,
          6595,
          28678,
          292,
          13,
          286,
          362,
          572,
          1558,
          437,
          309,
          390,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5927,
        "id": 1670,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5924,
        "temperature": 0,
        "text": " Edit that out maybe. Okay. Grammar ready.",
        "tokens": [
          51314,
          33241,
          300,
          484,
          1310,
          13,
          1033,
          13,
          22130,
          6209,
          1919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20670193964892095,
        "compression_ratio": 1.6111111111111112,
        "end": 5932,
        "id": 1671,
        "no_speech_prob": 0.004754969850182533,
        "seek": 590500,
        "start": 5927,
        "temperature": 0,
        "text": " Then I'm going to write function grammar ready.",
        "tokens": [
          51464,
          1396,
          286,
          478,
          516,
          281,
          2464,
          2445,
          22317,
          1919,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5935,
        "id": 1672,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5932,
        "temperature": 0,
        "text": " And I'm just going to say console.log ready.",
        "tokens": [
          50364,
          400,
          286,
          478,
          445,
          516,
          281,
          584,
          11076,
          13,
          4987,
          1919,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5937,
        "id": 1673,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5935,
        "temperature": 0,
        "text": " So let's see if this works.",
        "tokens": [
          50514,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5940,
        "id": 1674,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5937,
        "temperature": 0,
        "text": " And I'm going to comment this out down here.",
        "tokens": [
          50614,
          400,
          286,
          478,
          516,
          281,
          2871,
          341,
          484,
          760,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5942,
        "id": 1675,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5940,
        "temperature": 0,
        "text": " And I'm going to run this again.",
        "tokens": [
          50764,
          400,
          286,
          478,
          516,
          281,
          1190,
          341,
          797,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5944,
        "id": 1676,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5942,
        "temperature": 0,
        "text": " Let's see if we at least see the callback happen.",
        "tokens": [
          50864,
          961,
          311,
          536,
          498,
          321,
          412,
          1935,
          536,
          264,
          818,
          3207,
          1051,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5947,
        "id": 1677,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5944,
        "temperature": 0,
        "text": " So grammar appears to be invalid JSON.",
        "tokens": [
          50964,
          407,
          22317,
          7038,
          281,
          312,
          34702,
          31828,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5949,
        "id": 1678,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5947,
        "temperature": 0,
        "text": " Please check it at JSONLint.",
        "tokens": [
          51114,
          2555,
          1520,
          309,
          412,
          31828,
          43,
          686,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5953,
        "id": 1679,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5949,
        "temperature": 0,
        "text": " If you are using YAML, please be sure to include YAMLJS.",
        "tokens": [
          51214,
          759,
          291,
          366,
          1228,
          398,
          2865,
          43,
          11,
          1767,
          312,
          988,
          281,
          4090,
          398,
          2865,
          43,
          41,
          50,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5955,
        "id": 1680,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5954,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51464,
          8239,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16514588916112508,
        "compression_ratio": 1.603305785123967,
        "end": 5959,
        "id": 1681,
        "no_speech_prob": 0.001838618773035705,
        "seek": 593200,
        "start": 5955,
        "temperature": 0,
        "text": " So I think I need to work on the formatting of this file.",
        "tokens": [
          51514,
          407,
          286,
          519,
          286,
          643,
          281,
          589,
          322,
          264,
          39366,
          295,
          341,
          3991,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5962,
        "id": 1682,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5960,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          50414,
          6161,
          484,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5965,
        "id": 1683,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5962,
        "temperature": 0,
        "text": " So I guess this wants it to be JSON.",
        "tokens": [
          50514,
          407,
          286,
          2041,
          341,
          2738,
          309,
          281,
          312,
          31828,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5970,
        "id": 1684,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5968,
        "temperature": 0,
        "text": " So why...",
        "tokens": [
          50814,
          407,
          983,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5974,
        "id": 1685,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5970,
        "temperature": 0,
        "text": " So I'm going to have to figure this out and edit this.",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          362,
          281,
          2573,
          341,
          484,
          293,
          8129,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5978,
        "id": 1686,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5974,
        "temperature": 0,
        "text": " I actually have not used the Rita library for the context-free grammar stuff before.",
        "tokens": [
          51114,
          286,
          767,
          362,
          406,
          1143,
          264,
          32672,
          6405,
          337,
          264,
          4319,
          12,
          10792,
          22317,
          1507,
          949,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5980,
        "id": 1687,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5978,
        "temperature": 0,
        "text": " This is how I do things.",
        "tokens": [
          51314,
          639,
          307,
          577,
          286,
          360,
          721,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5981,
        "id": 1688,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5980,
        "temperature": 0,
        "text": " I don't try them.",
        "tokens": [
          51414,
          286,
          500,
          380,
          853,
          552,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5984,
        "id": 1689,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5981,
        "temperature": 0,
        "text": " I just try to... I'll teach this thing that I don't actually know.",
        "tokens": [
          51464,
          286,
          445,
          853,
          281,
          485,
          286,
          603,
          2924,
          341,
          551,
          300,
          286,
          500,
          380,
          767,
          458,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2135845850972296,
        "compression_ratio": 1.5625,
        "end": 5986,
        "id": 1690,
        "no_speech_prob": 0.0002913671778514981,
        "seek": 595900,
        "start": 5984,
        "temperature": 0,
        "text": " And I just try it.",
        "tokens": [
          51614,
          400,
          286,
          445,
          853,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 5987,
        "id": 1691,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 5986,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 5989,
        "id": 1692,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 5987,
        "temperature": 0,
        "text": " So let me see...",
        "tokens": [
          50414,
          407,
          718,
          385,
          536,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 5991,
        "id": 1693,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 5989,
        "temperature": 0,
        "text": " Let me look for example...",
        "tokens": [
          50514,
          961,
          385,
          574,
          337,
          1365,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 5997,
        "id": 1694,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 5993,
        "temperature": 0,
        "text": " What I want to see is Rita.js examples.",
        "tokens": [
          50714,
          708,
          286,
          528,
          281,
          536,
          307,
          32672,
          13,
          25530,
          5110,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6002,
        "id": 1695,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6000,
        "temperature": 0,
        "text": " And haiku grammar.",
        "tokens": [
          51064,
          400,
          324,
          24320,
          22317,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6004,
        "id": 1696,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6002,
        "temperature": 0,
        "text": " Yeah, yeah, this is what I want to look at.",
        "tokens": [
          51164,
          865,
          11,
          1338,
          11,
          341,
          307,
          437,
          286,
          528,
          281,
          574,
          412,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6006,
        "id": 1697,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6005,
        "temperature": 0,
        "text": " So let's look at this.",
        "tokens": [
          51314,
          407,
          718,
          311,
          574,
          412,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6007,
        "id": 1698,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6006,
        "temperature": 0,
        "text": " Aha!",
        "tokens": [
          51364,
          27448,
          0,
          51414
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6009,
        "id": 1699,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6007,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51414,
          14711,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6010,
        "id": 1700,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6009,
        "temperature": 0,
        "text": " So how is it doing this?",
        "tokens": [
          51514,
          407,
          577,
          307,
          309,
          884,
          341,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6012,
        "id": 1701,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6010,
        "temperature": 0,
        "text": " Is that YAML?",
        "tokens": [
          51564,
          1119,
          300,
          398,
          2865,
          43,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.20096899538624044,
        "compression_ratio": 1.4790419161676647,
        "end": 6014,
        "id": 1702,
        "no_speech_prob": 0.0007208222523331642,
        "seek": 598600,
        "start": 6012,
        "temperature": 0,
        "text": " Ah, so it's...",
        "tokens": [
          51664,
          2438,
          11,
          370,
          309,
          311,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6020,
        "id": 1703,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6014,
        "temperature": 0,
        "text": " So this is using the YAML format and then loading it.",
        "tokens": [
          50364,
          407,
          341,
          307,
          1228,
          264,
          398,
          2865,
          43,
          7877,
          293,
          550,
          15114,
          309,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6022,
        "id": 1704,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6020,
        "temperature": 0,
        "text": " So I don't want to do it that way.",
        "tokens": [
          50664,
          407,
          286,
          500,
          380,
          528,
          281,
          360,
          309,
          300,
          636,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6025,
        "id": 1705,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6022,
        "temperature": 0,
        "text": " I want to do it, I think, with JSON.",
        "tokens": [
          50764,
          286,
          528,
          281,
          360,
          309,
          11,
          286,
          519,
          11,
          365,
          31828,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6027,
        "id": 1706,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6025,
        "temperature": 0,
        "text": " So...",
        "tokens": [
          50914,
          407,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6034,
        "id": 1707,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6032,
        "temperature": 0,
        "text": " So let's try to make that work.",
        "tokens": [
          51264,
          407,
          718,
          311,
          853,
          281,
          652,
          300,
          589,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6037,
        "id": 1708,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6036,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18662514744034733,
        "compression_ratio": 1.4591194968553458,
        "end": 6042,
        "id": 1709,
        "no_speech_prob": 0.0023595723323524,
        "seek": 601400,
        "start": 6038,
        "temperature": 0,
        "text": " I think I'm going to do this now off, not in part of the video",
        "tokens": [
          51564,
          286,
          519,
          286,
          478,
          516,
          281,
          360,
          341,
          586,
          766,
          11,
          406,
          294,
          644,
          295,
          264,
          960,
          51764
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6045,
        "id": 1710,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6042,
        "temperature": 0,
        "text": " because it will be tedious to see me try to retype this.",
        "tokens": [
          50364,
          570,
          309,
          486,
          312,
          38284,
          281,
          536,
          385,
          853,
          281,
          319,
          20467,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6049,
        "id": 1711,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6045,
        "temperature": 0,
        "text": " But let me make a new file.",
        "tokens": [
          50514,
          583,
          718,
          385,
          652,
          257,
          777,
          3991,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6052,
        "id": 1712,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6050,
        "temperature": 0,
        "text": " I actually have a...",
        "tokens": [
          50764,
          286,
          767,
          362,
          257,
          485,
          50864
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6057,
        "id": 1713,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6054,
        "temperature": 0,
        "text": " Oops, I'm in the wrong folder.",
        "tokens": [
          50964,
          21726,
          11,
          286,
          478,
          294,
          264,
          2085,
          10820,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6060,
        "id": 1714,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6058,
        "temperature": 0,
        "text": " So I'm making a file called grammar.json.",
        "tokens": [
          51164,
          407,
          286,
          478,
          1455,
          257,
          3991,
          1219,
          22317,
          13,
          73,
          3015,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6064,
        "id": 1715,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6060,
        "temperature": 0,
        "text": " Now fortunately for us is I have done this before.",
        "tokens": [
          51264,
          823,
          25511,
          337,
          505,
          307,
          286,
          362,
          1096,
          341,
          949,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6066,
        "id": 1716,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6065,
        "temperature": 0,
        "text": " Aha!",
        "tokens": [
          51514,
          27448,
          0,
          51564
        ]
      },
      {
        "avg_logprob": -0.19384208092322716,
        "compression_ratio": 1.4619289340101522,
        "end": 6070,
        "id": 1717,
        "no_speech_prob": 0.0015730594750493765,
        "seek": 604200,
        "start": 6066,
        "temperature": 0,
        "text": " So I have a feeling that this is the syntax it wants.",
        "tokens": [
          51564,
          407,
          286,
          362,
          257,
          2633,
          300,
          341,
          307,
          264,
          28431,
          309,
          2738,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19473576127437123,
        "compression_ratio": 1.3727272727272728,
        "end": 6077,
        "id": 1718,
        "no_speech_prob": 0.0000976120209088549,
        "seek": 607200,
        "start": 6073,
        "temperature": 0,
        "text": " So let's see if that's the case.",
        "tokens": [
          50414,
          407,
          718,
          311,
          536,
          498,
          300,
          311,
          264,
          1389,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19473576127437123,
        "compression_ratio": 1.3727272727272728,
        "end": 6080,
        "id": 1719,
        "no_speech_prob": 0.0000976120209088549,
        "seek": 607200,
        "start": 6078,
        "temperature": 0,
        "text": " And then I'm going to...",
        "tokens": [
          50664,
          400,
          550,
          286,
          478,
          516,
          281,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.19473576127437123,
        "compression_ratio": 1.3727272727272728,
        "end": 6086,
        "id": 1720,
        "no_speech_prob": 0.0000976120209088549,
        "seek": 607200,
        "start": 6081,
        "temperature": 0,
        "text": " And then I'm going to go to grammar.json.",
        "tokens": [
          50814,
          400,
          550,
          286,
          478,
          516,
          281,
          352,
          281,
          22317,
          13,
          73,
          3015,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19473576127437123,
        "compression_ratio": 1.3727272727272728,
        "end": 6089,
        "id": 1721,
        "no_speech_prob": 0.0000976120209088549,
        "seek": 607200,
        "start": 6088,
        "temperature": 0,
        "text": " Aha!",
        "tokens": [
          51164,
          27448,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.19473576127437123,
        "compression_ratio": 1.3727272727272728,
        "end": 6091,
        "id": 1722,
        "no_speech_prob": 0.0000976120209088549,
        "seek": 607200,
        "start": 6089,
        "temperature": 0,
        "text": " So that's promising.",
        "tokens": [
          51214,
          407,
          300,
          311,
          20257,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19473576127437123,
        "compression_ratio": 1.3727272727272728,
        "end": 6099,
        "id": 1723,
        "no_speech_prob": 0.0000976120209088549,
        "seek": 607200,
        "start": 6097,
        "temperature": 0,
        "text": " No, rule not found start.",
        "tokens": [
          51614,
          883,
          11,
          4978,
          406,
          1352,
          722,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6105,
        "id": 1724,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6103,
        "temperature": 0,
        "text": " Let's see if that does it.",
        "tokens": [
          50414,
          961,
          311,
          536,
          498,
          300,
          775,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6108,
        "id": 1725,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6107,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50614,
          21726,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6110,
        "id": 1726,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6109,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50714,
          876,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6115,
        "id": 1727,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6114,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50964,
          821,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6118,
        "id": 1728,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6116,
        "temperature": 0,
        "text": " Okay, so this, that works.",
        "tokens": [
          51064,
          1033,
          11,
          370,
          341,
          11,
          300,
          1985,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6121,
        "id": 1729,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6119,
        "temperature": 0,
        "text": " So, okay.",
        "tokens": [
          51214,
          407,
          11,
          1392,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2176952362060547,
        "compression_ratio": 1.2280701754385965,
        "end": 6127,
        "id": 1730,
        "no_speech_prob": 0.00036826898576691747,
        "seek": 610200,
        "start": 6121,
        "temperature": 0,
        "text": " So I guess, I don't know where to splice all this in.",
        "tokens": [
          51314,
          407,
          286,
          2041,
          11,
          286,
          500,
          380,
          458,
          689,
          281,
          4732,
          573,
          439,
          341,
          294,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24939664204915366,
        "compression_ratio": 1.4666666666666666,
        "end": 6136,
        "id": 1731,
        "no_speech_prob": 0.00009461199078941718,
        "seek": 613200,
        "start": 6133,
        "temperature": 0,
        "text": " So I think I'm going to...",
        "tokens": [
          50414,
          407,
          286,
          519,
          286,
          478,
          516,
          281,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.24939664204915366,
        "compression_ratio": 1.4666666666666666,
        "end": 6138,
        "id": 1732,
        "no_speech_prob": 0.00009461199078941718,
        "seek": 613200,
        "start": 6136,
        "temperature": 0,
        "text": " Ah, I'm going to do the cooking show thing.",
        "tokens": [
          50564,
          2438,
          11,
          286,
          478,
          516,
          281,
          360,
          264,
          6361,
          855,
          551,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24939664204915366,
        "compression_ratio": 1.4666666666666666,
        "end": 6142,
        "id": 1733,
        "no_speech_prob": 0.00009461199078941718,
        "seek": 613200,
        "start": 6138,
        "temperature": 0,
        "text": " Where I'm going to go back and have that error.",
        "tokens": [
          50664,
          2305,
          286,
          478,
          516,
          281,
          352,
          646,
          293,
          362,
          300,
          6713,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24939664204915366,
        "compression_ratio": 1.4666666666666666,
        "end": 6145,
        "id": 1734,
        "no_speech_prob": 0.00009461199078941718,
        "seek": 613200,
        "start": 6142,
        "temperature": 0,
        "text": " And then switch to the JSON file.",
        "tokens": [
          50864,
          400,
          550,
          3679,
          281,
          264,
          31828,
          3991,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24939664204915366,
        "compression_ratio": 1.4666666666666666,
        "end": 6147,
        "id": 1735,
        "no_speech_prob": 0.00009461199078941718,
        "seek": 613200,
        "start": 6145,
        "temperature": 0,
        "text": " So let me go to here.",
        "tokens": [
          51014,
          407,
          718,
          385,
          352,
          281,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24939664204915366,
        "compression_ratio": 1.4666666666666666,
        "end": 6151,
        "id": 1736,
        "no_speech_prob": 0.00009461199078941718,
        "seek": 613200,
        "start": 6147,
        "temperature": 0,
        "text": " And go to test.grammar.",
        "tokens": [
          51114,
          400,
          352,
          281,
          1500,
          13,
          1342,
          6209,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3318956693013509,
        "compression_ratio": 1.393939393939394,
        "end": 6156,
        "id": 1737,
        "no_speech_prob": 0.0023230465594679117,
        "seek": 615100,
        "start": 6152,
        "temperature": 0,
        "text": " And then, oh, let me modify this grammar.",
        "tokens": [
          50414,
          400,
          550,
          11,
          1954,
          11,
          718,
          385,
          16927,
          341,
          22317,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3318956693013509,
        "compression_ratio": 1.393939393939394,
        "end": 6158,
        "id": 1738,
        "no_speech_prob": 0.0023230465594679117,
        "seek": 615100,
        "start": 6156,
        "temperature": 0,
        "text": " To just be this simpler thing.",
        "tokens": [
          50614,
          1407,
          445,
          312,
          341,
          18587,
          551,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3318956693013509,
        "compression_ratio": 1.393939393939394,
        "end": 6160,
        "id": 1739,
        "no_speech_prob": 0.0023230465594679117,
        "seek": 615100,
        "start": 6158,
        "temperature": 0,
        "text": " So, hold on a second.",
        "tokens": [
          50714,
          407,
          11,
          1797,
          322,
          257,
          1150,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3318956693013509,
        "compression_ratio": 1.393939393939394,
        "end": 6165,
        "id": 1740,
        "no_speech_prob": 0.0023230465594679117,
        "seek": 615100,
        "start": 6160,
        "temperature": 0,
        "text": " So it's, I need start, noun phrase, verb phrase.",
        "tokens": [
          50814,
          407,
          309,
          311,
          11,
          286,
          643,
          722,
          11,
          23307,
          9535,
          11,
          9595,
          9535,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3318956693013509,
        "compression_ratio": 1.393939393939394,
        "end": 6176,
        "id": 1741,
        "no_speech_prob": 0.0023230465594679117,
        "seek": 615100,
        "start": 6170,
        "temperature": 0,
        "text": " And then noun phrase is determiner noun.",
        "tokens": [
          51314,
          400,
          550,
          23307,
          9535,
          307,
          3618,
          4564,
          23307,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20321528664950667,
        "compression_ratio": 1.3790322580645162,
        "end": 6179,
        "id": 1742,
        "no_speech_prob": 0.0010816436260938644,
        "seek": 617600,
        "start": 6177,
        "temperature": 0,
        "text": " Noun phrase is...",
        "tokens": [
          50414,
          426,
          1733,
          9535,
          307,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.20321528664950667,
        "compression_ratio": 1.3790322580645162,
        "end": 6191,
        "id": 1743,
        "no_speech_prob": 0.0010816436260938644,
        "seek": 617600,
        "start": 6189,
        "temperature": 0,
        "text": " And then, I'm simplifying this.",
        "tokens": [
          51014,
          400,
          550,
          11,
          286,
          478,
          6883,
          5489,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20321528664950667,
        "compression_ratio": 1.3790322580645162,
        "end": 6193,
        "id": 1744,
        "no_speech_prob": 0.0010816436260938644,
        "seek": 617600,
        "start": 6191,
        "temperature": 0,
        "text": " I know the camera just shut off.",
        "tokens": [
          51114,
          286,
          458,
          264,
          2799,
          445,
          5309,
          766,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20321528664950667,
        "compression_ratio": 1.3790322580645162,
        "end": 6194,
        "id": 1745,
        "no_speech_prob": 0.0010816436260938644,
        "seek": 617600,
        "start": 6193,
        "temperature": 0,
        "text": " Hold on a sec.",
        "tokens": [
          51214,
          6962,
          322,
          257,
          907,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20321528664950667,
        "compression_ratio": 1.3790322580645162,
        "end": 6198,
        "id": 1746,
        "no_speech_prob": 0.0010816436260938644,
        "seek": 617600,
        "start": 6194,
        "temperature": 0,
        "text": " And then verb phrase is verb or verb noun phrase.",
        "tokens": [
          51264,
          400,
          550,
          9595,
          9535,
          307,
          9595,
          420,
          9595,
          23307,
          9535,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20321528664950667,
        "compression_ratio": 1.3790322580645162,
        "end": 6200,
        "id": 1747,
        "no_speech_prob": 0.0010816436260938644,
        "seek": 617600,
        "start": 6198,
        "temperature": 0,
        "text": " I'll turn this back on.",
        "tokens": [
          51464,
          286,
          603,
          1261,
          341,
          646,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.37006750414448397,
        "compression_ratio": 1.025,
        "end": 6208,
        "id": 1748,
        "no_speech_prob": 0.01771179772913456,
        "seek": 620600,
        "start": 6206,
        "temperature": 0,
        "text": " Is...",
        "tokens": [
          50364,
          1119,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.37006750414448397,
        "compression_ratio": 1.025,
        "end": 6226,
        "id": 1749,
        "no_speech_prob": 0.01771179772913456,
        "seek": 620600,
        "start": 6223,
        "temperature": 0,
        "text": " Verb is, oh, this is silly what I'm doing here.",
        "tokens": [
          51214,
          27034,
          307,
          11,
          1954,
          11,
          341,
          307,
          11774,
          437,
          286,
          478,
          884,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.37006750414448397,
        "compression_ratio": 1.025,
        "end": 6229,
        "id": 1750,
        "no_speech_prob": 0.01771179772913456,
        "seek": 620600,
        "start": 6226,
        "temperature": 0,
        "text": " Is verb or verb noun phrase.",
        "tokens": [
          51364,
          1119,
          9595,
          420,
          9595,
          23307,
          9535,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6232,
        "id": 1751,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6230,
        "temperature": 0,
        "text": " Uh...",
        "tokens": [
          50414,
          4019,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6237,
        "id": 1752,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6234,
        "temperature": 0,
        "text": " Verb, so this could be an array.",
        "tokens": [
          50614,
          27034,
          11,
          370,
          341,
          727,
          312,
          364,
          10225,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6239,
        "id": 1753,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6237,
        "temperature": 0,
        "text": " Verb.",
        "tokens": [
          50764,
          27034,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6242,
        "id": 1754,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6240,
        "temperature": 0,
        "text": " Or...",
        "tokens": [
          50914,
          1610,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6246,
        "id": 1755,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6243,
        "temperature": 0,
        "text": " I wonder if this is actually right.",
        "tokens": [
          51064,
          286,
          2441,
          498,
          341,
          307,
          767,
          558,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6248,
        "id": 1756,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6247,
        "temperature": 0,
        "text": " This is kind of a mess.",
        "tokens": [
          51264,
          639,
          307,
          733,
          295,
          257,
          2082,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6251,
        "id": 1757,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6248,
        "temperature": 0,
        "text": " I should have just gone to making my own grammar.",
        "tokens": [
          51314,
          286,
          820,
          362,
          445,
          2780,
          281,
          1455,
          452,
          1065,
          22317,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6253,
        "id": 1758,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6251,
        "temperature": 0,
        "text": " Verb noun phrase.",
        "tokens": [
          51464,
          27034,
          23307,
          9535,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.28132539913978105,
        "compression_ratio": 1.4451219512195121,
        "end": 6258,
        "id": 1759,
        "no_speech_prob": 0.0009849959751591086,
        "seek": 622900,
        "start": 6255,
        "temperature": 0,
        "text": " I just want to, let me do a simple one and we can test it.",
        "tokens": [
          51664,
          286,
          445,
          528,
          281,
          11,
          718,
          385,
          360,
          257,
          2199,
          472,
          293,
          321,
          393,
          1500,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22770817425786233,
        "compression_ratio": 1.2475247524752475,
        "end": 6262,
        "id": 1760,
        "no_speech_prob": 0.0008558477275073528,
        "seek": 625900,
        "start": 6260,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          50414,
          400,
          550,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.22770817425786233,
        "compression_ratio": 1.2475247524752475,
        "end": 6266,
        "id": 1761,
        "no_speech_prob": 0.0008558477275073528,
        "seek": 625900,
        "start": 6264,
        "temperature": 0,
        "text": " Determiner is a or the.",
        "tokens": [
          50614,
          4237,
          966,
          4564,
          307,
          257,
          420,
          264,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22770817425786233,
        "compression_ratio": 1.2475247524752475,
        "end": 6269,
        "id": 1762,
        "no_speech_prob": 0.0008558477275073528,
        "seek": 625900,
        "start": 6267,
        "temperature": 0,
        "text": " Got that.",
        "tokens": [
          50764,
          5803,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22770817425786233,
        "compression_ratio": 1.2475247524752475,
        "end": 6276,
        "id": 1763,
        "no_speech_prob": 0.0008558477275073528,
        "seek": 625900,
        "start": 6274,
        "temperature": 0,
        "text": " I'm just going to change that to a or the.",
        "tokens": [
          51114,
          286,
          478,
          445,
          516,
          281,
          1319,
          300,
          281,
          257,
          420,
          264,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22770817425786233,
        "compression_ratio": 1.2475247524752475,
        "end": 6281,
        "id": 1764,
        "no_speech_prob": 0.0008558477275073528,
        "seek": 625900,
        "start": 6279,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51364,
          400,
          550,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.22770817425786233,
        "compression_ratio": 1.2475247524752475,
        "end": 6286,
        "id": 1765,
        "no_speech_prob": 0.0008558477275073528,
        "seek": 625900,
        "start": 6283,
        "temperature": 0,
        "text": " Noun, unicorn or rainbow.",
        "tokens": [
          51564,
          426,
          1733,
          11,
          28122,
          420,
          18526,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6292,
        "id": 1766,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6290,
        "temperature": 0,
        "text": " Rainbow.",
        "tokens": [
          50414,
          29477,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6294,
        "id": 1767,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6292,
        "temperature": 0,
        "text": " You guys are very patient to be watching this.",
        "tokens": [
          50514,
          509,
          1074,
          366,
          588,
          4537,
          281,
          312,
          1976,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6296,
        "id": 1768,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6294,
        "temperature": 0,
        "text": " Hopefully you're all doing something else right now.",
        "tokens": [
          50614,
          10429,
          291,
          434,
          439,
          884,
          746,
          1646,
          558,
          586,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6298,
        "id": 1769,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6296,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          50714,
          400,
          550,
          485,
          50814
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6301,
        "id": 1770,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6299,
        "temperature": 0,
        "text": " Dance, verb dances.",
        "tokens": [
          50864,
          16114,
          11,
          9595,
          28322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6310,
        "id": 1771,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6308,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51314,
          45263,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6315,
        "id": 1772,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6313,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51564,
          45263,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19969262395586287,
        "compression_ratio": 1.286764705882353,
        "end": 6317,
        "id": 1773,
        "no_speech_prob": 0.00006108813249738887,
        "seek": 628900,
        "start": 6315,
        "temperature": 0,
        "text": " This is just noun.",
        "tokens": [
          51664,
          639,
          307,
          445,
          23307,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6321,
        "id": 1774,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6319,
        "temperature": 0,
        "text": " Verb.",
        "tokens": [
          50364,
          27034,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6323,
        "id": 1775,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6321,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          50464,
          400,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6331,
        "id": 1776,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6328,
        "temperature": 0,
        "text": " Boy, the grammar that I'm getting rid of is much more interesting.",
        "tokens": [
          50814,
          9486,
          11,
          264,
          22317,
          300,
          286,
          478,
          1242,
          3973,
          295,
          307,
          709,
          544,
          1880,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6333,
        "id": 1777,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6331,
        "temperature": 0,
        "text": " Which was, thank you to Alison Parrish.",
        "tokens": [
          50964,
          3013,
          390,
          11,
          1309,
          291,
          281,
          41001,
          47890,
          742,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6338,
        "id": 1778,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6333,
        "temperature": 0,
        "text": " I'm not, so I think that's everything now.",
        "tokens": [
          51064,
          286,
          478,
          406,
          11,
          370,
          286,
          519,
          300,
          311,
          1203,
          586,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6341,
        "id": 1779,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6339,
        "temperature": 0,
        "text": " So if I were to run this.",
        "tokens": [
          51364,
          407,
          498,
          286,
          645,
          281,
          1190,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6343,
        "id": 1780,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6341,
        "temperature": 0,
        "text": " Okay, whoops.",
        "tokens": [
          51464,
          1033,
          11,
          567,
          3370,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6345,
        "id": 1781,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6343,
        "temperature": 0,
        "text": " So where's my syntax error?",
        "tokens": [
          51564,
          407,
          689,
          311,
          452,
          28431,
          6713,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.20833344295107084,
        "compression_ratio": 1.372340425531915,
        "end": 6347,
        "id": 1782,
        "no_speech_prob": 0.0005614589317701757,
        "seek": 631900,
        "start": 6345,
        "temperature": 0,
        "text": " Here's a JavaScript object.",
        "tokens": [
          51664,
          1692,
          311,
          257,
          15778,
          2657,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6349,
        "id": 1783,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6347,
        "temperature": 0,
        "text": " Start is this.",
        "tokens": [
          50364,
          6481,
          307,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6354,
        "id": 1784,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6350,
        "temperature": 0,
        "text": " Followed by noun phrase is this.",
        "tokens": [
          50514,
          9876,
          292,
          538,
          23307,
          9535,
          307,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6356,
        "id": 1785,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6354,
        "temperature": 0,
        "text": " This.",
        "tokens": [
          50714,
          639,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6360,
        "id": 1786,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6356,
        "temperature": 0,
        "text": " Let's go to JSON formatter.",
        "tokens": [
          50814,
          961,
          311,
          352,
          281,
          31828,
          1254,
          1161,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6362,
        "id": 1787,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6360,
        "temperature": 0,
        "text": " Let's check my JSON.",
        "tokens": [
          51014,
          961,
          311,
          1520,
          452,
          31828,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6366,
        "id": 1788,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6365,
        "temperature": 0,
        "text": " Error.",
        "tokens": [
          51264,
          3300,
          2874,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6368,
        "id": 1789,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6366,
        "temperature": 0,
        "text": " Where's the error?",
        "tokens": [
          51314,
          2305,
          311,
          264,
          6713,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6370,
        "id": 1790,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6368,
        "temperature": 0,
        "text": " Dance has a comma.",
        "tokens": [
          51414,
          16114,
          575,
          257,
          22117,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6372,
        "id": 1791,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6370,
        "temperature": 0,
        "text": " This should not have a comma here.",
        "tokens": [
          51514,
          639,
          820,
          406,
          362,
          257,
          22117,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6374,
        "id": 1792,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6372,
        "temperature": 0,
        "text": " And let's see if now...",
        "tokens": [
          51614,
          400,
          718,
          311,
          536,
          498,
          586,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.21438143974126772,
        "compression_ratio": 1.4320987654320987,
        "end": 6376,
        "id": 1793,
        "no_speech_prob": 0.007695396430790424,
        "seek": 634700,
        "start": 6374,
        "temperature": 0,
        "text": " This gets me what I want.",
        "tokens": [
          51714,
          639,
          2170,
          385,
          437,
          286,
          528,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6379,
        "id": 1794,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6377,
        "temperature": 0,
        "text": " Closer.",
        "tokens": [
          50364,
          2033,
          22150,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6381,
        "id": 1795,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6379,
        "temperature": 0,
        "text": " I'm sure some of you see this.",
        "tokens": [
          50464,
          286,
          478,
          988,
          512,
          295,
          291,
          536,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6383,
        "id": 1796,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6381,
        "temperature": 0,
        "text": " Leave off the comma.",
        "tokens": [
          50564,
          9825,
          766,
          264,
          22117,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6387,
        "id": 1797,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6383,
        "temperature": 0,
        "text": " Oh, this is not going well today.",
        "tokens": [
          50664,
          876,
          11,
          341,
          307,
          406,
          516,
          731,
          965,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6389,
        "id": 1798,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6387,
        "temperature": 0,
        "text": " JSON formatter.",
        "tokens": [
          50864,
          31828,
          1254,
          1161,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6395,
        "id": 1799,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6393,
        "temperature": 0,
        "text": " Hey, duplicate key.",
        "tokens": [
          51164,
          1911,
          11,
          23976,
          2141,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6397,
        "id": 1800,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6395,
        "temperature": 0,
        "text": " Verb.",
        "tokens": [
          51264,
          27034,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6399,
        "id": 1801,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6397,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          51364,
          876,
          11,
          1392,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6401,
        "id": 1802,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6399,
        "temperature": 0,
        "text": " That's a problem.",
        "tokens": [
          51464,
          663,
          311,
          257,
          1154,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19823312759399414,
        "compression_ratio": 1.3766233766233766,
        "end": 6403,
        "id": 1803,
        "no_speech_prob": 0.0006361744599416852,
        "seek": 637700,
        "start": 6401,
        "temperature": 0,
        "text": " No, duplicate key should be fine according to...",
        "tokens": [
          51564,
          883,
          11,
          23976,
          2141,
          820,
          312,
          2489,
          4650,
          281,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.26870380915128267,
        "compression_ratio": 1.26890756302521,
        "end": 6407,
        "id": 1804,
        "no_speech_prob": 0.004905115347355604,
        "seek": 640300,
        "start": 6403,
        "temperature": 0,
        "text": " The way I think this works.",
        "tokens": [
          50364,
          440,
          636,
          286,
          519,
          341,
          1985,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.26870380915128267,
        "compression_ratio": 1.26890756302521,
        "end": 6417,
        "id": 1805,
        "no_speech_prob": 0.004905115347355604,
        "seek": 640300,
        "start": 6415,
        "temperature": 0,
        "text": " Oh, so sad.",
        "tokens": [
          50964,
          876,
          11,
          370,
          4227,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.26870380915128267,
        "compression_ratio": 1.26890756302521,
        "end": 6419,
        "id": 1806,
        "no_speech_prob": 0.004905115347355604,
        "seek": 640300,
        "start": 6417,
        "temperature": 0,
        "text": " I could have sworn I had this.",
        "tokens": [
          51064,
          286,
          727,
          362,
          40068,
          286,
          632,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26870380915128267,
        "compression_ratio": 1.26890756302521,
        "end": 6423,
        "id": 1807,
        "no_speech_prob": 0.004905115347355604,
        "seek": 640300,
        "start": 6421,
        "temperature": 0,
        "text": " Oh, there's a comma here.",
        "tokens": [
          51264,
          876,
          11,
          456,
          311,
          257,
          22117,
          510,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.26870380915128267,
        "compression_ratio": 1.26890756302521,
        "end": 6431,
        "id": 1808,
        "no_speech_prob": 0.004905115347355604,
        "seek": 640300,
        "start": 6427,
        "temperature": 0,
        "text": " I don't even have my sound effects or debugging music.",
        "tokens": [
          51564,
          286,
          500,
          380,
          754,
          362,
          452,
          1626,
          5065,
          420,
          45592,
          1318,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6433,
        "id": 1809,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6431,
        "temperature": 0,
        "text": " Let's...",
        "tokens": [
          50364,
          961,
          311,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6439,
        "id": 1810,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6437,
        "temperature": 0,
        "text": " That.",
        "tokens": [
          50664,
          663,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6441,
        "id": 1811,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6439,
        "temperature": 0,
        "text": " Oh, okay. Whoa.",
        "tokens": [
          50764,
          876,
          11,
          1392,
          13,
          7521,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6443,
        "id": 1812,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6441,
        "temperature": 0,
        "text": " Definitely was some mistakes there.",
        "tokens": [
          50864,
          12151,
          390,
          512,
          8038,
          456,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6445,
        "id": 1813,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6443,
        "temperature": 0,
        "text": " All right, what's going on here?",
        "tokens": [
          50964,
          1057,
          558,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6447,
        "id": 1814,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6445,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          51064,
          876,
          11,
          1392,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6453,
        "id": 1815,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6451,
        "temperature": 0,
        "text": " Let's see here.",
        "tokens": [
          51364,
          961,
          311,
          536,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6455,
        "id": 1816,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6453,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51464,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6457,
        "id": 1817,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6455,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51564,
          1033,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2578595968393179,
        "compression_ratio": 1.2796610169491525,
        "end": 6459,
        "id": 1818,
        "no_speech_prob": 0.0007672745850868523,
        "seek": 643100,
        "start": 6457,
        "temperature": 0,
        "text": " This is this.",
        "tokens": [
          51664,
          639,
          307,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6461,
        "id": 1819,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6459,
        "temperature": 0,
        "text": " This is an array which has three things.",
        "tokens": [
          50364,
          639,
          307,
          364,
          10225,
          597,
          575,
          1045,
          721,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6463,
        "id": 1820,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6461,
        "temperature": 0,
        "text": " This is an array which has two things.",
        "tokens": [
          50464,
          639,
          307,
          364,
          10225,
          597,
          575,
          732,
          721,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6465,
        "id": 1821,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6463,
        "temperature": 0,
        "text": " This is an array which has two things.",
        "tokens": [
          50564,
          639,
          307,
          364,
          10225,
          597,
          575,
          732,
          721,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6467,
        "id": 1822,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6465,
        "temperature": 0,
        "text": " I don't see any syntax error.",
        "tokens": [
          50664,
          286,
          500,
          380,
          536,
          604,
          28431,
          6713,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6469,
        "id": 1823,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6467,
        "temperature": 0,
        "text": " You don't have verb phrase.",
        "tokens": [
          50764,
          509,
          500,
          380,
          362,
          9595,
          9535,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6471,
        "id": 1824,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6469,
        "temperature": 0,
        "text": " Oh, thank you.",
        "tokens": [
          50864,
          876,
          11,
          1309,
          291,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6473,
        "id": 1825,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6471,
        "temperature": 0,
        "text": " Oh, verb phrase.",
        "tokens": [
          50964,
          876,
          11,
          9595,
          9535,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6475,
        "id": 1826,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6473,
        "temperature": 0,
        "text": " Oh, that's why I had a duplicate thing.",
        "tokens": [
          51064,
          876,
          11,
          300,
          311,
          983,
          286,
          632,
          257,
          23976,
          551,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6477,
        "id": 1827,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6475,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51164,
          1044,
          291,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6479,
        "id": 1828,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6477,
        "temperature": 0,
        "text": " And...",
        "tokens": [
          51264,
          400,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6481,
        "id": 1829,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6479,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          51364,
          1033,
          11,
          1797,
          322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6483,
        "id": 1830,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6481,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51464,
          1044,
          291,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6485,
        "id": 1831,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6483,
        "temperature": 0,
        "text": " Verb.",
        "tokens": [
          51564,
          27034,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.167998236578864,
        "compression_ratio": 1.9254658385093169,
        "end": 6487,
        "id": 1832,
        "no_speech_prob": 0.025177298113703728,
        "seek": 645900,
        "start": 6485,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51664,
          400,
          550,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6489,
        "id": 1833,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6487,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          50364,
          400,
          550,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6491,
        "id": 1834,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6489,
        "temperature": 0,
        "text": " Verb.",
        "tokens": [
          50464,
          27034,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6497,
        "id": 1835,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6495,
        "temperature": 0,
        "text": " Dances.",
        "tokens": [
          50764,
          413,
          2676,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6501,
        "id": 1836,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6499,
        "temperature": 0,
        "text": " Let's see how this goes now.",
        "tokens": [
          50964,
          961,
          311,
          536,
          577,
          341,
          1709,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6503,
        "id": 1837,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6501,
        "temperature": 0,
        "text": " So close.",
        "tokens": [
          51064,
          407,
          1998,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6505,
        "id": 1838,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6503,
        "temperature": 0,
        "text": " Look at this again.",
        "tokens": [
          51164,
          2053,
          412,
          341,
          797,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6507,
        "id": 1839,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6505,
        "temperature": 0,
        "text": " Verb phrase.",
        "tokens": [
          51264,
          27034,
          9535,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6509,
        "id": 1840,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6507,
        "temperature": 0,
        "text": " Verb. Noun phrase.",
        "tokens": [
          51364,
          27034,
          13,
          426,
          1733,
          9535,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6511,
        "id": 1841,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6509,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51464,
          6962,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19130159146857983,
        "compression_ratio": 1.35,
        "end": 6513,
        "id": 1842,
        "no_speech_prob": 0.0029345699585974216,
        "seek": 648700,
        "start": 6511,
        "temperature": 0,
        "text": " Let's paste this into the formatter.",
        "tokens": [
          51564,
          961,
          311,
          9163,
          341,
          666,
          264,
          1254,
          1161,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6519,
        "id": 1843,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6517,
        "temperature": 0,
        "text": " It likes it.",
        "tokens": [
          50364,
          467,
          5902,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6521,
        "id": 1844,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6519,
        "temperature": 0,
        "text": " Duplicate key.",
        "tokens": [
          50464,
          5153,
          4770,
          473,
          2141,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6523,
        "id": 1845,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6521,
        "temperature": 0,
        "text": " Where's my duplicate key?",
        "tokens": [
          50564,
          2305,
          311,
          452,
          23976,
          2141,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6525,
        "id": 1846,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6523,
        "temperature": 0,
        "text": " I don't see a duplicate key.",
        "tokens": [
          50664,
          286,
          500,
          380,
          536,
          257,
          23976,
          2141,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6529,
        "id": 1847,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6527,
        "temperature": 0,
        "text": " Oh, I've gone off the rails here, everybody.",
        "tokens": [
          50864,
          876,
          11,
          286,
          600,
          2780,
          766,
          264,
          27649,
          510,
          11,
          2201,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6543,
        "id": 1848,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6541,
        "temperature": 0,
        "text": " Should this be in an array?",
        "tokens": [
          51564,
          6454,
          341,
          312,
          294,
          364,
          10225,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.16257293188749855,
        "compression_ratio": 1.4166666666666667,
        "end": 6545,
        "id": 1849,
        "no_speech_prob": 0.018261319026350975,
        "seek": 651700,
        "start": 6543,
        "temperature": 0,
        "text": " I guess I should have looked at this beforehand.",
        "tokens": [
          51664,
          286,
          2041,
          286,
          820,
          362,
          2956,
          412,
          341,
          22893,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6549,
        "id": 1850,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6547,
        "temperature": 0,
        "text": " It's funny because when I just...",
        "tokens": [
          50364,
          467,
          311,
          4074,
          570,
          562,
          286,
          445,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6551,
        "id": 1851,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6549,
        "temperature": 0,
        "text": " All right, let me go back.",
        "tokens": [
          50464,
          1057,
          558,
          11,
          718,
          385,
          352,
          646,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6553,
        "id": 1852,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6551,
        "temperature": 0,
        "text": " Backwards.",
        "tokens": [
          50564,
          5833,
          2015,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6555,
        "id": 1853,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6553,
        "temperature": 0,
        "text": " Let me go back and get this grammar that I know works.",
        "tokens": [
          50664,
          961,
          385,
          352,
          646,
          293,
          483,
          341,
          22317,
          300,
          286,
          458,
          1985,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6557,
        "id": 1854,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6555,
        "temperature": 0,
        "text": " I don't know what I did wrong.",
        "tokens": [
          50764,
          286,
          500,
          380,
          458,
          437,
          286,
          630,
          2085,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6559,
        "id": 1855,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6557,
        "temperature": 0,
        "text": " But I'm going to just use this one.",
        "tokens": [
          50864,
          583,
          286,
          478,
          516,
          281,
          445,
          764,
          341,
          472,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6561,
        "id": 1856,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6559,
        "temperature": 0,
        "text": " And I will...",
        "tokens": [
          50964,
          400,
          286,
          486,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6563,
        "id": 1857,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6561,
        "temperature": 0,
        "text": " I don't know why...",
        "tokens": [
          51064,
          286,
          500,
          380,
          458,
          983,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6565,
        "id": 1858,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6563,
        "temperature": 0,
        "text": " And now I've lost where I am.",
        "tokens": [
          51164,
          400,
          586,
          286,
          600,
          2731,
          689,
          286,
          669,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6567,
        "id": 1859,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6565,
        "temperature": 0,
        "text": " I'm going to use this one.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          764,
          341,
          472,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6569,
        "id": 1860,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6567,
        "temperature": 0,
        "text": " And I will...",
        "tokens": [
          51364,
          400,
          286,
          486,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6571,
        "id": 1861,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6569,
        "temperature": 0,
        "text": " I don't know why...",
        "tokens": [
          51464,
          286,
          500,
          380,
          458,
          983,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6573,
        "id": 1862,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6571,
        "temperature": 0,
        "text": " And now I've lost where I am.",
        "tokens": [
          51564,
          400,
          586,
          286,
          600,
          2731,
          689,
          286,
          669,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.28765301174587676,
        "compression_ratio": 2.1306818181818183,
        "end": 6575,
        "id": 1863,
        "no_speech_prob": 0.0025506350211799145,
        "seek": 654700,
        "start": 6573,
        "temperature": 0,
        "text": " I'm going to use this one.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          764,
          341,
          472,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6577,
        "id": 1864,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6575,
        "temperature": 0,
        "text": " I didn't mind this one.",
        "tokens": [
          50364,
          286,
          994,
          380,
          1575,
          341,
          472,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6579,
        "id": 1865,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6577,
        "temperature": 0,
        "text": " Maybe am I...",
        "tokens": [
          50464,
          2704,
          669,
          286,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6581,
        "id": 1866,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6579,
        "temperature": 0,
        "text": " Didn't that work at one point?",
        "tokens": [
          50564,
          11151,
          380,
          300,
          589,
          412,
          472,
          935,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6593,
        "id": 1867,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6591,
        "temperature": 0,
        "text": " You're trying to load test.",
        "tokens": [
          51164,
          509,
          434,
          1382,
          281,
          3677,
          1500,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6595,
        "id": 1868,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6593,
        "temperature": 0,
        "text": " Am I loading the wrong file?",
        "tokens": [
          51264,
          2012,
          286,
          15114,
          264,
          2085,
          3991,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6597,
        "id": 1869,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6595,
        "temperature": 0,
        "text": " I've totally lost where I am.",
        "tokens": [
          51364,
          286,
          600,
          3879,
          2731,
          689,
          286,
          669,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6599,
        "id": 1870,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6597,
        "temperature": 0,
        "text": " Ah, it's in test.grammar.",
        "tokens": [
          51464,
          2438,
          11,
          309,
          311,
          294,
          1500,
          13,
          1342,
          6209,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6601,
        "id": 1871,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6599,
        "temperature": 0,
        "text": " Oh my god.",
        "tokens": [
          51564,
          876,
          452,
          3044,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3865955835101248,
        "compression_ratio": 1.4620253164556962,
        "end": 6603,
        "id": 1872,
        "no_speech_prob": 0.00460939621552825,
        "seek": 657500,
        "start": 6601,
        "temperature": 0,
        "text": " I'm going to try to load test.grammar.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          853,
          281,
          3677,
          1500,
          13,
          1342,
          6209,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6605,
        "id": 1873,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6603,
        "temperature": 0,
        "text": " Oh my god.",
        "tokens": [
          50364,
          876,
          452,
          3044,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6607,
        "id": 1874,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6605,
        "temperature": 0,
        "text": " The whole time.",
        "tokens": [
          50464,
          440,
          1379,
          565,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6609,
        "id": 1875,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6607,
        "temperature": 0,
        "text": " The whole time I'm loading the wrong file.",
        "tokens": [
          50564,
          440,
          1379,
          565,
          286,
          478,
          15114,
          264,
          2085,
          3991,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6619,
        "id": 1876,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6617,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          51064,
          865,
          11,
          1392,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6621,
        "id": 1877,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6619,
        "temperature": 0,
        "text": " Sorry everybody.",
        "tokens": [
          51164,
          4919,
          2201,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6623,
        "id": 1878,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6621,
        "temperature": 0,
        "text": " I was losing my mind.",
        "tokens": [
          51264,
          286,
          390,
          7027,
          452,
          1575,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6625,
        "id": 1879,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6623,
        "temperature": 0,
        "text": " I probably had it correct all along.",
        "tokens": [
          51364,
          286,
          1391,
          632,
          309,
          3006,
          439,
          2051,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6627,
        "id": 1880,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6625,
        "temperature": 0,
        "text": " Okay, so...",
        "tokens": [
          51464,
          1033,
          11,
          370,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6629,
        "id": 1881,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6627,
        "temperature": 0,
        "text": " Let's...",
        "tokens": [
          51564,
          961,
          311,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.16986745024380617,
        "compression_ratio": 1.3972602739726028,
        "end": 6631,
        "id": 1882,
        "no_speech_prob": 0.05499539151787758,
        "seek": 660300,
        "start": 6629,
        "temperature": 0,
        "text": " Oh my goodness, everyone.",
        "tokens": [
          51664,
          876,
          452,
          8387,
          11,
          1518,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6635,
        "id": 1883,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6633,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6639,
        "id": 1884,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6637,
        "temperature": 0,
        "text": " Da da da da.",
        "tokens": [
          50564,
          3933,
          1120,
          1120,
          1120,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6641,
        "id": 1885,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6639,
        "temperature": 0,
        "text": " Stretch.",
        "tokens": [
          50664,
          38817,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6643,
        "id": 1886,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6641,
        "temperature": 0,
        "text": " Welcome to life as a programmer.",
        "tokens": [
          50764,
          4027,
          281,
          993,
          382,
          257,
          32116,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6645,
        "id": 1887,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6643,
        "temperature": 0,
        "text": " Wasting half an hour on an incredibly obvious...",
        "tokens": [
          50864,
          343,
          30587,
          1922,
          364,
          1773,
          322,
          364,
          6252,
          6322,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6647,
        "id": 1888,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6645,
        "temperature": 0,
        "text": " Wasting half an hour on an incredibly obvious...",
        "tokens": [
          50964,
          343,
          30587,
          1922,
          364,
          1773,
          322,
          364,
          6252,
          6322,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6649,
        "id": 1889,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6647,
        "temperature": 0,
        "text": " Wasting half an hour on an incredibly obvious...",
        "tokens": [
          51064,
          343,
          30587,
          1922,
          364,
          1773,
          322,
          364,
          6252,
          6322,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6651,
        "id": 1890,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6649,
        "temperature": 0,
        "text": " The other day I was actually in a classroom",
        "tokens": [
          51164,
          440,
          661,
          786,
          286,
          390,
          767,
          294,
          257,
          7419,
          51264
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6653,
        "id": 1891,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6651,
        "temperature": 0,
        "text": " trying to get something to work",
        "tokens": [
          51264,
          1382,
          281,
          483,
          746,
          281,
          589,
          51364
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6655,
        "id": 1892,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6653,
        "temperature": 0,
        "text": " and I just hadn't saved the thing.",
        "tokens": [
          51364,
          293,
          286,
          445,
          8782,
          380,
          6624,
          264,
          551,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6657,
        "id": 1893,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6655,
        "temperature": 0,
        "text": " Losing my mind here.",
        "tokens": [
          51464,
          441,
          6110,
          452,
          1575,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6659,
        "id": 1894,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6657,
        "temperature": 0,
        "text": " Okay, I'm going to get through this.",
        "tokens": [
          51564,
          1033,
          11,
          286,
          478,
          516,
          281,
          483,
          807,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2121095359325409,
        "compression_ratio": 1.9375,
        "end": 6661,
        "id": 1895,
        "no_speech_prob": 0.00027802525437437,
        "seek": 663300,
        "start": 6659,
        "temperature": 0,
        "text": " I have no idea how this is going to get spliced together.",
        "tokens": [
          51664,
          286,
          362,
          572,
          1558,
          577,
          341,
          307,
          516,
          281,
          483,
          4732,
          4233,
          1214,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6663,
        "id": 1896,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6661,
        "temperature": 0,
        "text": " I have no idea how this is going to get spliced together.",
        "tokens": [
          50364,
          286,
          362,
          572,
          1558,
          577,
          341,
          307,
          516,
          281,
          483,
          4732,
          4233,
          1214,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6665,
        "id": 1897,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6663,
        "temperature": 0,
        "text": " But I'm going to go back",
        "tokens": [
          50464,
          583,
          286,
          478,
          516,
          281,
          352,
          646,
          50564
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6669,
        "id": 1898,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6667,
        "temperature": 0,
        "text": " to the point where...",
        "tokens": [
          50664,
          281,
          264,
          935,
          689,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6673,
        "id": 1899,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6671,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50864,
          1779,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6675,
        "id": 1900,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6673,
        "temperature": 0,
        "text": " Because remember I put this in here",
        "tokens": [
          50964,
          1436,
          1604,
          286,
          829,
          341,
          294,
          510,
          51064
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6677,
        "id": 1901,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6675,
        "temperature": 0,
        "text": " because I was going to demonstrate",
        "tokens": [
          51064,
          570,
          286,
          390,
          516,
          281,
          11698,
          51164
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6679,
        "id": 1902,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6677,
        "temperature": 0,
        "text": " how I was going to have an error.",
        "tokens": [
          51164,
          577,
          286,
          390,
          516,
          281,
          362,
          364,
          6713,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6683,
        "id": 1903,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6681,
        "temperature": 0,
        "text": " So I'm going to just go all the way back to",
        "tokens": [
          51364,
          407,
          286,
          478,
          516,
          281,
          445,
          352,
          439,
          264,
          636,
          646,
          281,
          51464
        ]
      },
      {
        "avg_logprob": -0.17896436875866306,
        "compression_ratio": 1.7142857142857142,
        "end": 6687,
        "id": 1904,
        "no_speech_prob": 0.0022517843171954155,
        "seek": 666100,
        "start": 6685,
        "temperature": 0,
        "text": " where I'm going to load it from a file.",
        "tokens": [
          51564,
          689,
          286,
          478,
          516,
          281,
          3677,
          309,
          490,
          257,
          3991,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6689,
        "id": 1905,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6687,
        "temperature": 0,
        "text": " So this is where I last was.",
        "tokens": [
          50364,
          407,
          341,
          307,
          689,
          286,
          1036,
          390,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6691,
        "id": 1906,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6689,
        "temperature": 0,
        "text": " So this is where I last was.",
        "tokens": [
          50464,
          407,
          341,
          307,
          689,
          286,
          1036,
          390,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6693,
        "id": 1907,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6691,
        "temperature": 0,
        "text": " This is a high degree of difficulty.",
        "tokens": [
          50564,
          639,
          307,
          257,
          1090,
          4314,
          295,
          10360,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6695,
        "id": 1908,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6693,
        "temperature": 0,
        "text": " And here we go.",
        "tokens": [
          50664,
          400,
          510,
          321,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6697,
        "id": 1909,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6695,
        "temperature": 0,
        "text": " Here we go. Okay.",
        "tokens": [
          50764,
          1692,
          321,
          352,
          13,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6699,
        "id": 1910,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6697,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          50864,
          1033,
          11,
          510,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6701,
        "id": 1911,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6699,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          50964,
          1033,
          11,
          510,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6703,
        "id": 1912,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6701,
        "temperature": 0,
        "text": " So what I want to do now is",
        "tokens": [
          51064,
          407,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          51164
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6705,
        "id": 1913,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6703,
        "temperature": 0,
        "text": " try to load the grammar from a file",
        "tokens": [
          51164,
          853,
          281,
          3677,
          264,
          22317,
          490,
          257,
          3991,
          51264
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6707,
        "id": 1914,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6705,
        "temperature": 0,
        "text": " and I can look here in the reference",
        "tokens": [
          51264,
          293,
          286,
          393,
          574,
          510,
          294,
          264,
          6408,
          51364
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6709,
        "id": 1915,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6707,
        "temperature": 0,
        "text": " and look at load from.",
        "tokens": [
          51364,
          293,
          574,
          412,
          3677,
          490,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6711,
        "id": 1916,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6709,
        "temperature": 0,
        "text": " Whoops, I clicked on the wrong thing.",
        "tokens": [
          51464,
          45263,
          11,
          286,
          23370,
          322,
          264,
          2085,
          551,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6713,
        "id": 1917,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6711,
        "temperature": 0,
        "text": " I'm going to click at load from.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          2052,
          412,
          3677,
          490,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19166224239436724,
        "compression_ratio": 1.8682926829268294,
        "end": 6715,
        "id": 1918,
        "no_speech_prob": 0.0071210055612027645,
        "seek": 668700,
        "start": 6713,
        "temperature": 0,
        "text": " So what load from says,",
        "tokens": [
          51664,
          407,
          437,
          3677,
          490,
          1619,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6717,
        "id": 1919,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6715,
        "temperature": 0,
        "text": " load from a file or URL with an option.",
        "tokens": [
          50364,
          3677,
          490,
          257,
          3991,
          420,
          12905,
          365,
          364,
          3614,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6719,
        "id": 1920,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6717,
        "temperature": 0,
        "text": " So in option,",
        "tokens": [
          50464,
          407,
          294,
          3614,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6721,
        "id": 1921,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6719,
        "temperature": 0,
        "text": " the option in JavaScript is going to be a callback",
        "tokens": [
          50564,
          264,
          3614,
          294,
          15778,
          307,
          516,
          281,
          312,
          257,
          818,
          3207,
          50664
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6723,
        "id": 1922,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6721,
        "temperature": 0,
        "text": " because when you ask for a file",
        "tokens": [
          50664,
          570,
          562,
          291,
          1029,
          337,
          257,
          3991,
          50764
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6725,
        "id": 1923,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6723,
        "temperature": 0,
        "text": " it's going to happen, the file is going to be loaded",
        "tokens": [
          50764,
          309,
          311,
          516,
          281,
          1051,
          11,
          264,
          3991,
          307,
          516,
          281,
          312,
          13210,
          50864
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6727,
        "id": 1924,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6725,
        "temperature": 0,
        "text": " asynchronously so I need to know when the grammar is ready.",
        "tokens": [
          50864,
          42642,
          5098,
          370,
          286,
          643,
          281,
          458,
          562,
          264,
          22317,
          307,
          1919,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6729,
        "id": 1925,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6727,
        "temperature": 0,
        "text": " So there are a bunch of different ways",
        "tokens": [
          50964,
          407,
          456,
          366,
          257,
          3840,
          295,
          819,
          2098,
          51064
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6731,
        "id": 1926,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6729,
        "temperature": 0,
        "text": " grammar files can be formatted.",
        "tokens": [
          51064,
          22317,
          7098,
          393,
          312,
          1254,
          32509,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6733,
        "id": 1927,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6731,
        "temperature": 0,
        "text": " And a typical way you might see",
        "tokens": [
          51164,
          400,
          257,
          7476,
          636,
          291,
          1062,
          536,
          51264
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6735,
        "id": 1928,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6733,
        "temperature": 0,
        "text": " is with a syntax that looks something like this.",
        "tokens": [
          51264,
          307,
          365,
          257,
          28431,
          300,
          1542,
          746,
          411,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6737,
        "id": 1929,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6735,
        "temperature": 0,
        "text": " And I have some examples",
        "tokens": [
          51364,
          400,
          286,
          362,
          512,
          5110,
          51464
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6739,
        "id": 1930,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6737,
        "temperature": 0,
        "text": " that when you look at the code examples",
        "tokens": [
          51464,
          300,
          562,
          291,
          574,
          412,
          264,
          3089,
          5110,
          51564
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6741,
        "id": 1931,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6739,
        "temperature": 0,
        "text": " that load files that look like this.",
        "tokens": [
          51564,
          300,
          3677,
          7098,
          300,
          574,
          411,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21747589111328125,
        "compression_ratio": 1.8403908794788273,
        "end": 6743,
        "id": 1932,
        "no_speech_prob": 0.07476288825273514,
        "seek": 671500,
        "start": 6741,
        "temperature": 0,
        "text": " Here's another sort of way that looks a little bit like JSON.",
        "tokens": [
          51664,
          1692,
          311,
          1071,
          1333,
          295,
          636,
          300,
          1542,
          257,
          707,
          857,
          411,
          31828,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6745,
        "id": 1933,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6743,
        "temperature": 0,
        "text": " This I found in some of Daniel Howe's examples.",
        "tokens": [
          50364,
          639,
          286,
          1352,
          294,
          512,
          295,
          8033,
          1012,
          68,
          311,
          5110,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6747,
        "id": 1934,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6745,
        "temperature": 0,
        "text": " But Rita, so I'm going to try loading this particular file",
        "tokens": [
          50464,
          583,
          32672,
          11,
          370,
          286,
          478,
          516,
          281,
          853,
          15114,
          341,
          1729,
          3991,
          50564
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6749,
        "id": 1935,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6747,
        "temperature": 0,
        "text": " which is a.grammar file.",
        "tokens": [
          50564,
          597,
          307,
          257,
          2411,
          1342,
          6209,
          3991,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6751,
        "id": 1936,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6749,
        "temperature": 0,
        "text": " And whoops, so let me comment this out.",
        "tokens": [
          50664,
          400,
          567,
          3370,
          11,
          370,
          718,
          385,
          2871,
          341,
          484,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6753,
        "id": 1937,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6751,
        "temperature": 0,
        "text": " And I'm going to say",
        "tokens": [
          50764,
          400,
          286,
          478,
          516,
          281,
          584,
          50864
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6755,
        "id": 1938,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6753,
        "temperature": 0,
        "text": " rg.load from",
        "tokens": [
          50864,
          367,
          70,
          13,
          2907,
          490,
          50964
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6757,
        "id": 1939,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6755,
        "temperature": 0,
        "text": " test.grammar",
        "tokens": [
          50964,
          1500,
          13,
          1342,
          6209,
          51064
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6759,
        "id": 1940,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6757,
        "temperature": 0,
        "text": " and I'm going to say",
        "tokens": [
          51064,
          293,
          286,
          478,
          516,
          281,
          584,
          51164
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6761,
        "id": 1941,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6759,
        "temperature": 0,
        "text": " grammar ready.",
        "tokens": [
          51164,
          22317,
          1919,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6763,
        "id": 1942,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6761,
        "temperature": 0,
        "text": " So this is my callback for when",
        "tokens": [
          51264,
          407,
          341,
          307,
          452,
          818,
          3207,
          337,
          562,
          51364
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6765,
        "id": 1943,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6763,
        "temperature": 0,
        "text": " the grammar is ready.",
        "tokens": [
          51364,
          264,
          22317,
          307,
          1919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6767,
        "id": 1944,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6765,
        "temperature": 0,
        "text": " I'm going to just say",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          445,
          584,
          51564
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6769,
        "id": 1945,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6767,
        "temperature": 0,
        "text": " ready.",
        "tokens": [
          51564,
          1919,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22764813232421874,
        "compression_ratio": 1.7722772277227723,
        "end": 6771,
        "id": 1946,
        "no_speech_prob": 0.042716264724731445,
        "seek": 674300,
        "start": 6769,
        "temperature": 0,
        "text": " And I'm going to say",
        "tokens": [
          51664,
          400,
          286,
          478,
          516,
          281,
          584,
          51764
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6773,
        "id": 1947,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6771,
        "temperature": 0,
        "text": " ready.",
        "tokens": [
          50364,
          1919,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6775,
        "id": 1948,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6773,
        "temperature": 0,
        "text": " So if I do this",
        "tokens": [
          50464,
          407,
          498,
          286,
          360,
          341,
          50564
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6777,
        "id": 1949,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6775,
        "temperature": 0,
        "text": " and run this now",
        "tokens": [
          50564,
          293,
          1190,
          341,
          586,
          50664
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6779,
        "id": 1950,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6777,
        "temperature": 0,
        "text": " it's going to say, ah, grammar",
        "tokens": [
          50664,
          309,
          311,
          516,
          281,
          584,
          11,
          3716,
          11,
          22317,
          50764
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6781,
        "id": 1951,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6779,
        "temperature": 0,
        "text": " appears to be invalid JSON.",
        "tokens": [
          50764,
          7038,
          281,
          312,
          34702,
          31828,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6783,
        "id": 1952,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6781,
        "temperature": 0,
        "text": " Please check it if you're using YAML.",
        "tokens": [
          50864,
          2555,
          1520,
          309,
          498,
          291,
          434,
          1228,
          398,
          2865,
          43,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6785,
        "id": 1953,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6783,
        "temperature": 0,
        "text": " So there are so many different kinds",
        "tokens": [
          50964,
          407,
          456,
          366,
          370,
          867,
          819,
          3685,
          51064
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6787,
        "id": 1954,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6785,
        "temperature": 0,
        "text": " of standardized data formats.",
        "tokens": [
          51064,
          295,
          31677,
          1412,
          25879,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6789,
        "id": 1955,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6787,
        "temperature": 0,
        "text": " There's XML markup and",
        "tokens": [
          51164,
          821,
          311,
          43484,
          1491,
          1010,
          293,
          51264
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6791,
        "id": 1956,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6789,
        "temperature": 0,
        "text": " YAML and blah blah blah blah blah blah.",
        "tokens": [
          51264,
          398,
          2865,
          43,
          293,
          12288,
          12288,
          12288,
          12288,
          12288,
          12288,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6793,
        "id": 1957,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6791,
        "temperature": 0,
        "text": " If you've watched some of my data videos I kind of cover",
        "tokens": [
          51364,
          759,
          291,
          600,
          6337,
          512,
          295,
          452,
          1412,
          2145,
          286,
          733,
          295,
          2060,
          51464
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6795,
        "id": 1958,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6793,
        "temperature": 0,
        "text": " some of these different formats.",
        "tokens": [
          51464,
          512,
          295,
          613,
          819,
          25879,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6797,
        "id": 1959,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6795,
        "temperature": 0,
        "text": " I think JSON is going to be the easiest format",
        "tokens": [
          51564,
          286,
          519,
          31828,
          307,
          516,
          281,
          312,
          264,
          12889,
          7877,
          51664
        ]
      },
      {
        "avg_logprob": -0.1641614767221304,
        "compression_ratio": 1.6600790513833992,
        "end": 6799,
        "id": 1960,
        "no_speech_prob": 0.042085207998752594,
        "seek": 677100,
        "start": 6797,
        "temperature": 0,
        "text": " for us to encode",
        "tokens": [
          51664,
          337,
          505,
          281,
          2058,
          1429,
          51764
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6801,
        "id": 1961,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6799,
        "temperature": 0,
        "text": " a grammar and then load it",
        "tokens": [
          50364,
          257,
          22317,
          293,
          550,
          3677,
          309,
          50464
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6803,
        "id": 1962,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6801,
        "temperature": 0,
        "text": " into Rita or another program that we write.",
        "tokens": [
          50464,
          666,
          32672,
          420,
          1071,
          1461,
          300,
          321,
          2464,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6805,
        "id": 1963,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6803,
        "temperature": 0,
        "text": " So I actually have already",
        "tokens": [
          50564,
          407,
          286,
          767,
          362,
          1217,
          50664
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6807,
        "id": 1964,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6805,
        "temperature": 0,
        "text": " taken this exact",
        "tokens": [
          50664,
          2726,
          341,
          1900,
          50764
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6809,
        "id": 1965,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6807,
        "temperature": 0,
        "text": " grammar and rewritten",
        "tokens": [
          50764,
          22317,
          293,
          319,
          26859,
          50864
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6811,
        "id": 1966,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6809,
        "temperature": 0,
        "text": " it using a JSON syntax.",
        "tokens": [
          50864,
          309,
          1228,
          257,
          31828,
          28431,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6813,
        "id": 1967,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6811,
        "temperature": 0,
        "text": " And you can see that here. So I have a start",
        "tokens": [
          50964,
          400,
          291,
          393,
          536,
          300,
          510,
          13,
          407,
          286,
          362,
          257,
          722,
          51064
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6815,
        "id": 1968,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6813,
        "temperature": 0,
        "text": " which is a noun phrase or a verb phrase.",
        "tokens": [
          51064,
          597,
          307,
          257,
          23307,
          9535,
          420,
          257,
          9595,
          9535,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6817,
        "id": 1969,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6815,
        "temperature": 0,
        "text": " A noun phrase is a determiner and a noun.",
        "tokens": [
          51164,
          316,
          23307,
          9535,
          307,
          257,
          3618,
          4564,
          293,
          257,
          23307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6819,
        "id": 1970,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6817,
        "temperature": 0,
        "text": " A verb phrase could be verb phrase",
        "tokens": [
          51264,
          316,
          9595,
          9535,
          727,
          312,
          9595,
          9535,
          51364
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6821,
        "id": 1971,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6819,
        "temperature": 0,
        "text": " followed by a noun phrase or",
        "tokens": [
          51364,
          6263,
          538,
          257,
          23307,
          9535,
          420,
          51464
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6823,
        "id": 1972,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6821,
        "temperature": 0,
        "text": " just a verb. So you can see there is some",
        "tokens": [
          51464,
          445,
          257,
          9595,
          13,
          407,
          291,
          393,
          536,
          456,
          307,
          512,
          51564
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6825,
        "id": 1973,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6823,
        "temperature": 0,
        "text": " nesting into this grammar. And then here",
        "tokens": [
          51564,
          297,
          8714,
          666,
          341,
          22317,
          13,
          400,
          550,
          510,
          51664
        ]
      },
      {
        "avg_logprob": -0.18889286570305372,
        "compression_ratio": 1.950207468879668,
        "end": 6827,
        "id": 1974,
        "no_speech_prob": 0.15201643109321594,
        "seek": 679900,
        "start": 6825,
        "temperature": 0,
        "text": " you can see the sort of terminals.",
        "tokens": [
          51664,
          291,
          393,
          536,
          264,
          1333,
          295,
          38579,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6829,
        "id": 1975,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6827,
        "temperature": 0,
        "text": " And each key has an array",
        "tokens": [
          50364,
          400,
          1184,
          2141,
          575,
          364,
          10225,
          50464
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6831,
        "id": 1976,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6829,
        "temperature": 0,
        "text": " for multiple possibilities. So now",
        "tokens": [
          50464,
          337,
          3866,
          12178,
          13,
          407,
          586,
          50564
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6833,
        "id": 1977,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6831,
        "temperature": 0,
        "text": " if I were to go back to my",
        "tokens": [
          50564,
          498,
          286,
          645,
          281,
          352,
          646,
          281,
          452,
          50664
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6835,
        "id": 1978,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6833,
        "temperature": 0,
        "text": " code and load",
        "tokens": [
          50664,
          3089,
          293,
          3677,
          50764
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6837,
        "id": 1979,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6835,
        "temperature": 0,
        "text": " grammar.json",
        "tokens": [
          50764,
          22317,
          13,
          73,
          3015,
          50864
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6839,
        "id": 1980,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6837,
        "temperature": 0,
        "text": " I should at least be able",
        "tokens": [
          50864,
          286,
          820,
          412,
          1935,
          312,
          1075,
          50964
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6841,
        "id": 1981,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6839,
        "temperature": 0,
        "text": " to run this. And I see no error.",
        "tokens": [
          50964,
          281,
          1190,
          341,
          13,
          400,
          286,
          536,
          572,
          6713,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6843,
        "id": 1982,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6841,
        "temperature": 0,
        "text": " I just see ready. And now I have a grammar",
        "tokens": [
          51064,
          286,
          445,
          536,
          1919,
          13,
          400,
          586,
          286,
          362,
          257,
          22317,
          51164
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6845,
        "id": 1983,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6843,
        "temperature": 0,
        "text": " already going and I could say",
        "tokens": [
          51164,
          1217,
          516,
          293,
          286,
          727,
          584,
          51264
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6847,
        "id": 1984,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6845,
        "temperature": 0,
        "text": " result",
        "tokens": [
          51264,
          1874,
          51364
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6849,
        "id": 1985,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6847,
        "temperature": 0,
        "text": " equals grammar",
        "tokens": [
          51364,
          6915,
          22317,
          51464
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6851,
        "id": 1986,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6849,
        "temperature": 0,
        "text": " rg.expand",
        "tokens": [
          51464,
          367,
          70,
          13,
          15952,
          474,
          51564
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6853,
        "id": 1987,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6851,
        "temperature": 0,
        "text": " and then console.log",
        "tokens": [
          51564,
          293,
          550,
          11076,
          13,
          4987,
          51664
        ]
      },
      {
        "avg_logprob": -0.17578610506924716,
        "compression_ratio": 1.529126213592233,
        "end": 6855,
        "id": 1988,
        "no_speech_prob": 0.09008336812257767,
        "seek": 682700,
        "start": 6853,
        "temperature": 0,
        "text": " rg. Here we go.",
        "tokens": [
          51664,
          367,
          70,
          13,
          1692,
          321,
          352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6857,
        "id": 1989,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6855,
        "temperature": 0,
        "text": " We can see. Oh! Look at",
        "tokens": [
          50364,
          492,
          393,
          536,
          13,
          876,
          0,
          2053,
          412,
          50464
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6859,
        "id": 1990,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6857,
        "temperature": 0,
        "text": " that. What did I just say?",
        "tokens": [
          50464,
          300,
          13,
          708,
          630,
          286,
          445,
          584,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6861,
        "id": 1991,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6859,
        "temperature": 0,
        "text": " rg. No, that was interesting though. Result is",
        "tokens": [
          50564,
          367,
          70,
          13,
          883,
          11,
          300,
          390,
          1880,
          1673,
          13,
          5015,
          723,
          307,
          50664
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6863,
        "id": 1992,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6861,
        "temperature": 0,
        "text": " what I want to see. And we can see the unicorn",
        "tokens": [
          50664,
          437,
          286,
          528,
          281,
          536,
          13,
          400,
          321,
          393,
          536,
          264,
          28122,
          50764
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6865,
        "id": 1993,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6863,
        "temperature": 0,
        "text": " dances. The unicorn dances the rainbow.",
        "tokens": [
          50764,
          28322,
          13,
          440,
          28122,
          28322,
          264,
          18526,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6867,
        "id": 1994,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6865,
        "temperature": 0,
        "text": " The unicorn dances. The rainbow dances. A rainbow",
        "tokens": [
          50864,
          440,
          28122,
          28322,
          13,
          440,
          18526,
          28322,
          13,
          316,
          18526,
          50964
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6869,
        "id": 1995,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6867,
        "temperature": 0,
        "text": " dances the rainbow. A unicorn dances. A rainbow",
        "tokens": [
          50964,
          28322,
          264,
          18526,
          13,
          316,
          28122,
          28322,
          13,
          316,
          18526,
          51064
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6871,
        "id": 1996,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6869,
        "temperature": 0,
        "text": " dances. A unicorn dances. A rainbow dances.",
        "tokens": [
          51064,
          28322,
          13,
          316,
          28122,
          28322,
          13,
          316,
          18526,
          28322,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6873,
        "id": 1997,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6871,
        "temperature": 0,
        "text": " A unicorn dances the rainbow. Somebody could",
        "tokens": [
          51164,
          316,
          28122,
          28322,
          264,
          18526,
          13,
          13463,
          727,
          51264
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6875,
        "id": 1998,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6873,
        "temperature": 0,
        "text": " make a song out of that. The unicorn dances the",
        "tokens": [
          51264,
          652,
          257,
          2153,
          484,
          295,
          300,
          13,
          440,
          28122,
          28322,
          264,
          51364
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6877,
        "id": 1999,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6875,
        "temperature": 0,
        "text": " rainbow. The rainbow dances the rainbow.",
        "tokens": [
          51364,
          18526,
          13,
          440,
          18526,
          28322,
          264,
          18526,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6879,
        "id": 2000,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6877,
        "temperature": 0,
        "text": " Unicorn dances the unicorn. Okay.",
        "tokens": [
          51464,
          1156,
          23115,
          28322,
          264,
          28122,
          13,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6881,
        "id": 2001,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6879,
        "temperature": 0,
        "text": " So, yes, please not yaml",
        "tokens": [
          51564,
          407,
          11,
          2086,
          11,
          1767,
          406,
          288,
          335,
          75,
          51664
        ]
      },
      {
        "avg_logprob": -0.23662943927788296,
        "compression_ratio": 2.388888888888889,
        "end": 6883,
        "id": 2002,
        "no_speech_prob": 0.4686581492424011,
        "seek": 685500,
        "start": 6881,
        "temperature": 0,
        "text": " someone says in the chat. Not to worry.",
        "tokens": [
          51664,
          1580,
          1619,
          294,
          264,
          5081,
          13,
          1726,
          281,
          3292,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6885,
        "id": 2003,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6883,
        "temperature": 0,
        "text": " So, now we can see here",
        "tokens": [
          50364,
          407,
          11,
          586,
          321,
          393,
          536,
          510,
          50464
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6887,
        "id": 2004,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6885,
        "temperature": 0,
        "text": " once again just as with",
        "tokens": [
          50464,
          1564,
          797,
          445,
          382,
          365,
          50564
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6889,
        "id": 2005,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6887,
        "temperature": 0,
        "text": " tracery, it's your job",
        "tokens": [
          50564,
          504,
          326,
          2109,
          11,
          309,
          311,
          428,
          1691,
          50664
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6891,
        "id": 2006,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6889,
        "temperature": 0,
        "text": " if you want to work",
        "tokens": [
          50664,
          498,
          291,
          528,
          281,
          589,
          50764
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6893,
        "id": 2007,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6891,
        "temperature": 0,
        "text": " with context free grammars to design",
        "tokens": [
          50764,
          365,
          4319,
          1737,
          17570,
          685,
          281,
          1715,
          50864
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6895,
        "id": 2008,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6893,
        "temperature": 0,
        "text": " the grammar. And this is an effective way of working",
        "tokens": [
          50864,
          264,
          22317,
          13,
          400,
          341,
          307,
          364,
          4942,
          636,
          295,
          1364,
          50964
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6897,
        "id": 2009,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6895,
        "temperature": 0,
        "text": " in that you could actually have",
        "tokens": [
          50964,
          294,
          300,
          291,
          727,
          767,
          362,
          51064
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6899,
        "id": 2010,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6897,
        "temperature": 0,
        "text": " a completely separate",
        "tokens": [
          51064,
          257,
          2584,
          4994,
          51164
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6901,
        "id": 2011,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6899,
        "temperature": 0,
        "text": " file where you put all",
        "tokens": [
          51164,
          3991,
          689,
          291,
          829,
          439,
          51264
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6903,
        "id": 2012,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6901,
        "temperature": 0,
        "text": " of the grammar. So this could become very long.",
        "tokens": [
          51264,
          295,
          264,
          22317,
          13,
          407,
          341,
          727,
          1813,
          588,
          938,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6905,
        "id": 2013,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6903,
        "temperature": 0,
        "text": " In fact, you might start thinking about",
        "tokens": [
          51364,
          682,
          1186,
          11,
          291,
          1062,
          722,
          1953,
          466,
          51464
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6907,
        "id": 2014,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6905,
        "temperature": 0,
        "text": " how could I do things",
        "tokens": [
          51464,
          577,
          727,
          286,
          360,
          721,
          51564
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6909,
        "id": 2015,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6907,
        "temperature": 0,
        "text": " like whenever I get to a noun",
        "tokens": [
          51564,
          411,
          5699,
          286,
          483,
          281,
          257,
          23307,
          51664
        ]
      },
      {
        "avg_logprob": -0.18964070722091297,
        "compression_ratio": 1.6377952755905512,
        "end": 6911,
        "id": 2016,
        "no_speech_prob": 0.005641650408506393,
        "seek": 688300,
        "start": 6909,
        "temperature": 0,
        "text": " instead of picking",
        "tokens": [
          51664,
          2602,
          295,
          8867,
          51764
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6913,
        "id": 2017,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6911,
        "temperature": 0,
        "text": " from just a fixed list, actually use the",
        "tokens": [
          50364,
          490,
          445,
          257,
          6806,
          1329,
          11,
          767,
          764,
          264,
          50464
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6915,
        "id": 2018,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6913,
        "temperature": 0,
        "text": " read a lexicon to give me a random noun",
        "tokens": [
          50464,
          1401,
          257,
          476,
          87,
          11911,
          281,
          976,
          385,
          257,
          4974,
          23307,
          50564
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6917,
        "id": 2019,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6915,
        "temperature": 0,
        "text": " or query word nick",
        "tokens": [
          50564,
          420,
          14581,
          1349,
          15416,
          50664
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6919,
        "id": 2020,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6917,
        "temperature": 0,
        "text": " like an API to get a noun from.",
        "tokens": [
          50664,
          411,
          364,
          9362,
          281,
          483,
          257,
          23307,
          490,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6921,
        "id": 2021,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6919,
        "temperature": 0,
        "text": " There's a lot of possible ways",
        "tokens": [
          50764,
          821,
          311,
          257,
          688,
          295,
          1944,
          2098,
          50864
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6923,
        "id": 2022,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6921,
        "temperature": 0,
        "text": " you could sort of think about this.",
        "tokens": [
          50864,
          291,
          727,
          1333,
          295,
          519,
          466,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6925,
        "id": 2023,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6923,
        "temperature": 0,
        "text": " One other grammar that I want",
        "tokens": [
          50964,
          1485,
          661,
          22317,
          300,
          286,
          528,
          51064
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6927,
        "id": 2024,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6925,
        "temperature": 0,
        "text": " to show you which again is thank you to",
        "tokens": [
          51064,
          281,
          855,
          291,
          597,
          797,
          307,
          1309,
          291,
          281,
          51164
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6929,
        "id": 2025,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6927,
        "temperature": 0,
        "text": " Daniel Howe, the creator of Rita. I'm going",
        "tokens": [
          51164,
          8033,
          1012,
          68,
          11,
          264,
          14181,
          295,
          32672,
          13,
          286,
          478,
          516,
          51264
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6931,
        "id": 2026,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6929,
        "temperature": 0,
        "text": " to see if I can pull this up",
        "tokens": [
          51264,
          281,
          536,
          498,
          286,
          393,
          2235,
          341,
          493,
          51364
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6933,
        "id": 2027,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6931,
        "temperature": 0,
        "text": " because I have it in one of my other examples.",
        "tokens": [
          51364,
          570,
          286,
          362,
          309,
          294,
          472,
          295,
          452,
          661,
          5110,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6935,
        "id": 2028,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6933,
        "temperature": 0,
        "text": " Ah, this one. So let's see if this works.",
        "tokens": [
          51464,
          2438,
          11,
          341,
          472,
          13,
          407,
          718,
          311,
          536,
          498,
          341,
          1985,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6937,
        "id": 2029,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6935,
        "temperature": 0,
        "text": " I'm going to copy paste this grammar",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          5055,
          9163,
          341,
          22317,
          51664
        ]
      },
      {
        "avg_logprob": -0.19840599508846507,
        "compression_ratio": 1.6478405315614617,
        "end": 6939,
        "id": 2030,
        "no_speech_prob": 0.2450331747531891,
        "seek": 691100,
        "start": 6937,
        "temperature": 0,
        "text": " and I'm just going to put it",
        "tokens": [
          51664,
          293,
          286,
          478,
          445,
          516,
          281,
          829,
          309,
          51764
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6941,
        "id": 2031,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6939,
        "temperature": 0,
        "text": " over right here, grammar.json",
        "tokens": [
          50364,
          670,
          558,
          510,
          11,
          22317,
          13,
          73,
          3015,
          50464
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6943,
        "id": 2032,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6941,
        "temperature": 0,
        "text": " paste it in, hit save",
        "tokens": [
          50464,
          9163,
          309,
          294,
          11,
          2045,
          3155,
          50564
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6945,
        "id": 2033,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6943,
        "temperature": 0,
        "text": " and I'm going to run it and we can see now",
        "tokens": [
          50564,
          293,
          286,
          478,
          516,
          281,
          1190,
          309,
          293,
          321,
          393,
          536,
          586,
          50664
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6947,
        "id": 2034,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6945,
        "temperature": 0,
        "text": " and actually what I'm going to do is",
        "tokens": [
          50664,
          293,
          767,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          50764
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6949,
        "id": 2035,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6947,
        "temperature": 0,
        "text": " let's be a little bit more",
        "tokens": [
          50764,
          718,
          311,
          312,
          257,
          707,
          857,
          544,
          50864
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6951,
        "id": 2036,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6949,
        "temperature": 0,
        "text": " sophisticated about this.",
        "tokens": [
          50864,
          16950,
          466,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6953,
        "id": 2037,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6951,
        "temperature": 0,
        "text": " This is a very sophisticated",
        "tokens": [
          50964,
          639,
          307,
          257,
          588,
          16950,
          51064
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6955,
        "id": 2038,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6953,
        "temperature": 0,
        "text": " cooking show. By the way, this is called the cooking show now",
        "tokens": [
          51064,
          6361,
          855,
          13,
          3146,
          264,
          636,
          11,
          341,
          307,
          1219,
          264,
          6361,
          855,
          586,
          51164
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6957,
        "id": 2039,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6955,
        "temperature": 0,
        "text": " because I'm like cooking with code. Maybe that's it.",
        "tokens": [
          51164,
          570,
          286,
          478,
          411,
          6361,
          365,
          3089,
          13,
          2704,
          300,
          311,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6959,
        "id": 2040,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6957,
        "temperature": 0,
        "text": " Button",
        "tokens": [
          51264,
          38435,
          51364
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6961,
        "id": 2041,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6959,
        "temperature": 0,
        "text": " equals create button",
        "tokens": [
          51364,
          6915,
          1884,
          2960,
          51464
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6963,
        "id": 2042,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6961,
        "temperature": 0,
        "text": " generate",
        "tokens": [
          51464,
          8460,
          51564
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6965,
        "id": 2043,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6963,
        "temperature": 0,
        "text": " button.mousepressed",
        "tokens": [
          51564,
          2960,
          13,
          76,
          1316,
          79,
          3805,
          51664
        ]
      },
      {
        "avg_logprob": -0.20568479703167292,
        "compression_ratio": 1.689795918367347,
        "end": 6967,
        "id": 2044,
        "no_speech_prob": 0.04813443869352341,
        "seek": 693900,
        "start": 6965,
        "temperature": 0,
        "text": " I'm using the p5 dom library",
        "tokens": [
          51664,
          286,
          478,
          1228,
          264,
          280,
          20,
          3285,
          6405,
          51764
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6969,
        "id": 2045,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6967,
        "temperature": 0,
        "text": " to attach a click event to a",
        "tokens": [
          50364,
          281,
          5085,
          257,
          2052,
          2280,
          281,
          257,
          50464
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6971,
        "id": 2046,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6969,
        "temperature": 0,
        "text": " button and I'm going to say",
        "tokens": [
          50464,
          2960,
          293,
          286,
          478,
          516,
          281,
          584,
          50564
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6973,
        "id": 2047,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6971,
        "temperature": 0,
        "text": " new haiku",
        "tokens": [
          50564,
          777,
          324,
          24320,
          50664
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6977,
        "id": 2048,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6975,
        "temperature": 0,
        "text": " and then I'm going to say",
        "tokens": [
          50764,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          50864
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6979,
        "id": 2049,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6977,
        "temperature": 0,
        "text": " function new haiku",
        "tokens": [
          50864,
          2445,
          777,
          324,
          24320,
          50964
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6983,
        "id": 2050,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6981,
        "temperature": 0,
        "text": " and I'm going",
        "tokens": [
          51064,
          293,
          286,
          478,
          516,
          51164
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6985,
        "id": 2051,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6983,
        "temperature": 0,
        "text": " to say, and now I'm going to do here",
        "tokens": [
          51164,
          281,
          584,
          11,
          293,
          586,
          286,
          478,
          516,
          281,
          360,
          510,
          51264
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6987,
        "id": 2052,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6985,
        "temperature": 0,
        "text": " I'm going to get the result",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          483,
          264,
          1874,
          51364
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6989,
        "id": 2053,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6987,
        "temperature": 0,
        "text": " is expand the grammar and then",
        "tokens": [
          51364,
          307,
          5268,
          264,
          22317,
          293,
          550,
          51464
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6991,
        "id": 2054,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6989,
        "temperature": 0,
        "text": " I'm going to say create p result",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          584,
          1884,
          280,
          1874,
          51564
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6993,
        "id": 2055,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6991,
        "temperature": 0,
        "text": " so let me run this",
        "tokens": [
          51564,
          370,
          718,
          385,
          1190,
          341,
          51664
        ]
      },
      {
        "avg_logprob": -0.18074775464607007,
        "compression_ratio": 1.9795918367346939,
        "end": 6995,
        "id": 2056,
        "no_speech_prob": 0.3275744915008545,
        "seek": 696700,
        "start": 6993,
        "temperature": 0,
        "text": " and we should see",
        "tokens": [
          51664,
          293,
          321,
          820,
          536,
          51764
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 6997,
        "id": 2057,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 6995,
        "temperature": 0,
        "text": " result is not defined, line 12",
        "tokens": [
          50364,
          1874,
          307,
          406,
          7642,
          11,
          1622,
          2272,
          50464
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 6999,
        "id": 2058,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 6997,
        "temperature": 0,
        "text": " I forgot that I have",
        "tokens": [
          50464,
          286,
          5298,
          300,
          286,
          362,
          50564
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7001,
        "id": 2059,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 6999,
        "temperature": 0,
        "text": " some extra code there. So the idea",
        "tokens": [
          50564,
          512,
          2857,
          3089,
          456,
          13,
          407,
          264,
          1558,
          50664
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7003,
        "id": 2060,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7001,
        "temperature": 0,
        "text": " here is that I generate and I get these haikus",
        "tokens": [
          50664,
          510,
          307,
          300,
          286,
          8460,
          293,
          286,
          483,
          613,
          324,
          1035,
          301,
          50764
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7005,
        "id": 2061,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7003,
        "temperature": 0,
        "text": " now a couple things about this",
        "tokens": [
          50764,
          586,
          257,
          1916,
          721,
          466,
          341,
          50864
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7007,
        "id": 2062,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7005,
        "temperature": 0,
        "text": " why is there this percent sign",
        "tokens": [
          50864,
          983,
          307,
          456,
          341,
          3043,
          1465,
          50964
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7009,
        "id": 2063,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7007,
        "temperature": 0,
        "text": " in there? So one of the things you can do",
        "tokens": [
          50964,
          294,
          456,
          30,
          407,
          472,
          295,
          264,
          721,
          291,
          393,
          360,
          51064
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7011,
        "id": 2064,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7009,
        "temperature": 0,
        "text": " when designing a grammar is kind of create your own",
        "tokens": [
          51064,
          562,
          14685,
          257,
          22317,
          307,
          733,
          295,
          1884,
          428,
          1065,
          51164
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7013,
        "id": 2065,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7011,
        "temperature": 0,
        "text": " protocol. Like, I really what I want to",
        "tokens": [
          51164,
          10336,
          13,
          1743,
          11,
          286,
          534,
          437,
          286,
          528,
          281,
          51264
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7015,
        "id": 2066,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7013,
        "temperature": 0,
        "text": " have is like a br tag there",
        "tokens": [
          51264,
          362,
          307,
          411,
          257,
          738,
          6162,
          456,
          51364
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7017,
        "id": 2067,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7015,
        "temperature": 0,
        "text": " so I could just go into the grammar",
        "tokens": [
          51364,
          370,
          286,
          727,
          445,
          352,
          666,
          264,
          22317,
          51464
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7019,
        "id": 2068,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7017,
        "temperature": 0,
        "text": " and just do this",
        "tokens": [
          51464,
          293,
          445,
          360,
          341,
          51564
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7021,
        "id": 2069,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7019,
        "temperature": 0,
        "text": " which will probably",
        "tokens": [
          51564,
          597,
          486,
          1391,
          51664
        ]
      },
      {
        "avg_logprob": -0.20960526168346405,
        "compression_ratio": 1.6926070038910506,
        "end": 7023,
        "id": 2070,
        "no_speech_prob": 0.00898524560034275,
        "seek": 699500,
        "start": 7021,
        "temperature": 0,
        "text": " work",
        "tokens": [
          51664,
          589,
          51764
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7025,
        "id": 2071,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7023,
        "temperature": 0,
        "text": " and",
        "tokens": [
          50364,
          293,
          50464
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7027,
        "id": 2072,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7025,
        "temperature": 0,
        "text": " because I'm outputting to html",
        "tokens": [
          50464,
          570,
          286,
          478,
          5598,
          783,
          281,
          276,
          83,
          15480,
          50564
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7029,
        "id": 2073,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7027,
        "temperature": 0,
        "text": " I'm getting a br tag but I might",
        "tokens": [
          50564,
          286,
          478,
          1242,
          257,
          738,
          6162,
          457,
          286,
          1062,
          50664
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7031,
        "id": 2074,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7029,
        "temperature": 0,
        "text": " be outputting to other things and I actually want to",
        "tokens": [
          50664,
          312,
          5598,
          783,
          281,
          661,
          721,
          293,
          286,
          767,
          528,
          281,
          50764
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7033,
        "id": 2075,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7031,
        "temperature": 0,
        "text": " replace that with a line break so",
        "tokens": [
          50764,
          7406,
          300,
          365,
          257,
          1622,
          1821,
          370,
          50864
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7035,
        "id": 2076,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7033,
        "temperature": 0,
        "text": " but you can see here, let's look at how this grammar",
        "tokens": [
          50864,
          457,
          291,
          393,
          536,
          510,
          11,
          718,
          311,
          574,
          412,
          577,
          341,
          22317,
          50964
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7037,
        "id": 2077,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7035,
        "temperature": 0,
        "text": " works. This is an interesting way that you can",
        "tokens": [
          50964,
          1985,
          13,
          639,
          307,
          364,
          1880,
          636,
          300,
          291,
          393,
          51064
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7039,
        "id": 2078,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7037,
        "temperature": 0,
        "text": " use a grammar to generate",
        "tokens": [
          51064,
          764,
          257,
          22317,
          281,
          8460,
          51164
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7041,
        "id": 2079,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7039,
        "temperature": 0,
        "text": " a haiku. So",
        "tokens": [
          51164,
          257,
          324,
          24320,
          13,
          407,
          51264
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7043,
        "id": 2080,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7041,
        "temperature": 0,
        "text": " haiku form is a complex thing",
        "tokens": [
          51264,
          324,
          24320,
          1254,
          307,
          257,
          3997,
          551,
          51364
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7045,
        "id": 2081,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7043,
        "temperature": 0,
        "text": " there is a variety of ways you can sort of",
        "tokens": [
          51364,
          456,
          307,
          257,
          5673,
          295,
          2098,
          291,
          393,
          1333,
          295,
          51464
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7047,
        "id": 2082,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7045,
        "temperature": 0,
        "text": " think of haiku but here's one scenario",
        "tokens": [
          51464,
          519,
          295,
          324,
          24320,
          457,
          510,
          311,
          472,
          9005,
          51564
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7049,
        "id": 2083,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7047,
        "temperature": 0,
        "text": " a line with five syllables",
        "tokens": [
          51564,
          257,
          1622,
          365,
          1732,
          45364,
          51664
        ]
      },
      {
        "avg_logprob": -0.17461308815496432,
        "compression_ratio": 1.8359375,
        "end": 7051,
        "id": 2084,
        "no_speech_prob": 0.0008830295992083848,
        "seek": 702300,
        "start": 7049,
        "temperature": 0,
        "text": " a line with seven syllables and a line",
        "tokens": [
          51664,
          257,
          1622,
          365,
          3407,
          45364,
          293,
          257,
          1622,
          51764
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7053,
        "id": 2085,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7051,
        "temperature": 0,
        "text": " with five syllables",
        "tokens": [
          50364,
          365,
          1732,
          45364,
          50464
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7055,
        "id": 2086,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7053,
        "temperature": 0,
        "text": " so that is the",
        "tokens": [
          50464,
          370,
          300,
          307,
          264,
          50564
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7057,
        "id": 2087,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7055,
        "temperature": 0,
        "text": " start axiom",
        "tokens": [
          50564,
          722,
          6360,
          72,
          298,
          50664
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7059,
        "id": 2088,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7057,
        "temperature": 0,
        "text": " then here are all a bunch of",
        "tokens": [
          50664,
          550,
          510,
          366,
          439,
          257,
          3840,
          295,
          50764
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7061,
        "id": 2089,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7059,
        "temperature": 0,
        "text": " ways you can create a line with five syllables",
        "tokens": [
          50764,
          2098,
          291,
          393,
          1884,
          257,
          1622,
          365,
          1732,
          45364,
          50864
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7063,
        "id": 2090,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7061,
        "temperature": 0,
        "text": " a one syllable followed by a four syllable",
        "tokens": [
          50864,
          257,
          472,
          40151,
          6263,
          538,
          257,
          1451,
          40151,
          50964
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7065,
        "id": 2091,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7063,
        "temperature": 0,
        "text": " a one syllable followed by a three or a one",
        "tokens": [
          50964,
          257,
          472,
          40151,
          6263,
          538,
          257,
          1045,
          420,
          257,
          472,
          51064
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7067,
        "id": 2092,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7065,
        "temperature": 0,
        "text": " a one, a one three, one two two, one two",
        "tokens": [
          51064,
          257,
          472,
          11,
          257,
          472,
          1045,
          11,
          472,
          732,
          732,
          11,
          472,
          732,
          51164
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7069,
        "id": 2093,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7067,
        "temperature": 0,
        "text": " one one so you can see here's a whole set of",
        "tokens": [
          51164,
          472,
          472,
          370,
          291,
          393,
          536,
          510,
          311,
          257,
          1379,
          992,
          295,
          51264
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7071,
        "id": 2094,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7069,
        "temperature": 0,
        "text": " possibilities. Here are possibilities",
        "tokens": [
          51264,
          12178,
          13,
          1692,
          366,
          12178,
          51364
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7073,
        "id": 2095,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7071,
        "temperature": 0,
        "text": " for seven line. Notice how I'm reusing",
        "tokens": [
          51364,
          337,
          3407,
          1622,
          13,
          13428,
          577,
          286,
          478,
          319,
          7981,
          51464
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7075,
        "id": 2096,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7073,
        "temperature": 0,
        "text": " the five line here because I could have one",
        "tokens": [
          51464,
          264,
          1732,
          1622,
          510,
          570,
          286,
          727,
          362,
          472,
          51564
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7077,
        "id": 2097,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7075,
        "temperature": 0,
        "text": " one five line, two five line, five line",
        "tokens": [
          51564,
          472,
          1732,
          1622,
          11,
          732,
          1732,
          1622,
          11,
          1732,
          1622,
          51664
        ]
      },
      {
        "avg_logprob": -0.19380761536074356,
        "compression_ratio": 2.0762711864406778,
        "end": 7079,
        "id": 2098,
        "no_speech_prob": 0.37383145093917847,
        "seek": 705100,
        "start": 7077,
        "temperature": 0,
        "text": " one one or five line two and then",
        "tokens": [
          51664,
          472,
          472,
          420,
          1732,
          1622,
          732,
          293,
          550,
          51764
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7081,
        "id": 2099,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7079,
        "temperature": 0,
        "text": " here's a whole lot of one syllable words",
        "tokens": [
          50364,
          510,
          311,
          257,
          1379,
          688,
          295,
          472,
          40151,
          2283,
          50464
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7083,
        "id": 2100,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7081,
        "temperature": 0,
        "text": " this is all from Daniel Howe",
        "tokens": [
          50464,
          341,
          307,
          439,
          490,
          8033,
          1012,
          68,
          50564
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7085,
        "id": 2101,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7083,
        "temperature": 0,
        "text": " a whole lot of two syllable words",
        "tokens": [
          50564,
          257,
          1379,
          688,
          295,
          732,
          40151,
          2283,
          50664
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7087,
        "id": 2102,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7085,
        "temperature": 0,
        "text": " a whole lot of three syllable, not just words but",
        "tokens": [
          50664,
          257,
          1379,
          688,
          295,
          1045,
          40151,
          11,
          406,
          445,
          2283,
          457,
          50764
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7089,
        "id": 2103,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7087,
        "temperature": 0,
        "text": " phrases, four syllables, etc",
        "tokens": [
          50764,
          20312,
          11,
          1451,
          45364,
          11,
          5183,
          50864
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7091,
        "id": 2104,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7089,
        "temperature": 0,
        "text": " so now if I were to",
        "tokens": [
          50864,
          370,
          586,
          498,
          286,
          645,
          281,
          50964
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7093,
        "id": 2105,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7091,
        "temperature": 0,
        "text": " run this we can see I'm always",
        "tokens": [
          50964,
          1190,
          341,
          321,
          393,
          536,
          286,
          478,
          1009,
          51064
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7095,
        "id": 2106,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7093,
        "temperature": 0,
        "text": " going to get cranes Japan",
        "tokens": [
          51064,
          516,
          281,
          483,
          941,
          12779,
          3367,
          51164
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7097,
        "id": 2107,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7095,
        "temperature": 0,
        "text": " I'm going to get five syllables",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          483,
          1732,
          45364,
          51264
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7099,
        "id": 2108,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7097,
        "temperature": 0,
        "text": " cranes Japan day breaks",
        "tokens": [
          51264,
          941,
          12779,
          3367,
          786,
          9857,
          51364
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7101,
        "id": 2109,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7099,
        "temperature": 0,
        "text": " followed by seven, dawn smoke",
        "tokens": [
          51364,
          6263,
          538,
          3407,
          11,
          18192,
          8439,
          51464
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7103,
        "id": 2110,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7101,
        "temperature": 0,
        "text": " Japan dawn rushing",
        "tokens": [
          51464,
          3367,
          18192,
          25876,
          51564
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7105,
        "id": 2111,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7103,
        "temperature": 0,
        "text": " followed by five syllables, through smoke",
        "tokens": [
          51564,
          6263,
          538,
          1732,
          45364,
          11,
          807,
          8439,
          51664
        ]
      },
      {
        "avg_logprob": -0.21525460815429687,
        "compression_ratio": 1.9035087719298245,
        "end": 7107,
        "id": 2112,
        "no_speech_prob": 0.43382886052131653,
        "seek": 707900,
        "start": 7105,
        "temperature": 0,
        "text": " Juniper. So I encourage you",
        "tokens": [
          51664,
          8492,
          15402,
          13,
          407,
          286,
          5373,
          291,
          51764
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7109,
        "id": 2113,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7107,
        "temperature": 0,
        "text": " to think about what might be some creative",
        "tokens": [
          50364,
          281,
          519,
          466,
          437,
          1062,
          312,
          512,
          5880,
          50464
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7111,
        "id": 2114,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7109,
        "temperature": 0,
        "text": " ways you can write a grammar",
        "tokens": [
          50464,
          2098,
          291,
          393,
          2464,
          257,
          22317,
          50564
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7113,
        "id": 2115,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7111,
        "temperature": 0,
        "text": " to generate text",
        "tokens": [
          50564,
          281,
          8460,
          2487,
          50664
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7115,
        "id": 2116,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7113,
        "temperature": 0,
        "text": " and now we've seen how you can do",
        "tokens": [
          50664,
          293,
          586,
          321,
          600,
          1612,
          577,
          291,
          393,
          360,
          50764
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7117,
        "id": 2117,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7115,
        "temperature": 0,
        "text": " this same type of context free",
        "tokens": [
          50764,
          341,
          912,
          2010,
          295,
          4319,
          1737,
          50864
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7119,
        "id": 2118,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7117,
        "temperature": 0,
        "text": " grammar with tracery, we've seen how you",
        "tokens": [
          50864,
          22317,
          365,
          504,
          326,
          2109,
          11,
          321,
          600,
          1612,
          577,
          291,
          50964
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7121,
        "id": 2119,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7119,
        "temperature": 0,
        "text": " can do it with the",
        "tokens": [
          50964,
          393,
          360,
          309,
          365,
          264,
          51064
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7123,
        "id": 2120,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7121,
        "temperature": 0,
        "text": " readalibrary and in the next video",
        "tokens": [
          51064,
          1401,
          304,
          6414,
          822,
          293,
          294,
          264,
          958,
          960,
          51164
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7125,
        "id": 2121,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7123,
        "temperature": 0,
        "text": " which will be coming at some point",
        "tokens": [
          51164,
          597,
          486,
          312,
          1348,
          412,
          512,
          935,
          51264
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7127,
        "id": 2122,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7125,
        "temperature": 0,
        "text": " if it's not already there, I'm going to just kind of",
        "tokens": [
          51264,
          498,
          309,
          311,
          406,
          1217,
          456,
          11,
          286,
          478,
          516,
          281,
          445,
          733,
          295,
          51364
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7129,
        "id": 2123,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7127,
        "temperature": 0,
        "text": " look at the basic recursive algorithm",
        "tokens": [
          51364,
          574,
          412,
          264,
          3875,
          20560,
          488,
          9284,
          51464
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7131,
        "id": 2124,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7129,
        "temperature": 0,
        "text": " for doing this expansion from scratch",
        "tokens": [
          51464,
          337,
          884,
          341,
          11260,
          490,
          8459,
          51564
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7133,
        "id": 2125,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7131,
        "temperature": 0,
        "text": " in case you at some point want to start",
        "tokens": [
          51564,
          294,
          1389,
          291,
          412,
          512,
          935,
          528,
          281,
          722,
          51664
        ]
      },
      {
        "avg_logprob": -0.1761535031952127,
        "compression_ratio": 1.7681159420289856,
        "end": 7135,
        "id": 2126,
        "no_speech_prob": 0.2017751783132553,
        "seek": 710700,
        "start": 7133,
        "temperature": 0,
        "text": " playing around with the guts of how",
        "tokens": [
          51664,
          2433,
          926,
          365,
          264,
          28560,
          295,
          577,
          51764
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7137,
        "id": 2127,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7135,
        "temperature": 0,
        "text": " context free grammar generation system works",
        "tokens": [
          50364,
          4319,
          1737,
          22317,
          5125,
          1185,
          1985,
          50464
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7139,
        "id": 2128,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7137,
        "temperature": 0,
        "text": " ok, thanks for watching",
        "tokens": [
          50464,
          3133,
          11,
          3231,
          337,
          1976,
          50564
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7141,
        "id": 2129,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7139,
        "temperature": 0,
        "text": " ok",
        "tokens": [
          50564,
          3133,
          50664
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7143,
        "id": 2130,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7141,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50664,
          1105,
          50764
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7145,
        "id": 2131,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7143,
        "temperature": 0,
        "text": " alright",
        "tokens": [
          50764,
          5845,
          50864
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7147,
        "id": 2132,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7145,
        "temperature": 0,
        "text": " thank you, yes, coding nightmares",
        "tokens": [
          50864,
          1309,
          291,
          11,
          2086,
          11,
          17720,
          36911,
          50964
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7149,
        "id": 2133,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7147,
        "temperature": 0,
        "text": " is probably a good name",
        "tokens": [
          50964,
          307,
          1391,
          257,
          665,
          1315,
          51064
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7151,
        "id": 2134,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7149,
        "temperature": 0,
        "text": " I'm way past the",
        "tokens": [
          51064,
          286,
          478,
          636,
          1791,
          264,
          51164
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7153,
        "id": 2135,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7151,
        "temperature": 0,
        "text": " time that I said I had until",
        "tokens": [
          51164,
          565,
          300,
          286,
          848,
          286,
          632,
          1826,
          51264
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7155,
        "id": 2136,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7153,
        "temperature": 0,
        "text": " but I want to see if I can get",
        "tokens": [
          51264,
          457,
          286,
          528,
          281,
          536,
          498,
          286,
          393,
          483,
          51364
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7157,
        "id": 2137,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7155,
        "temperature": 0,
        "text": " through the last couple",
        "tokens": [
          51364,
          807,
          264,
          1036,
          1916,
          51464
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7159,
        "id": 2138,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7157,
        "temperature": 0,
        "text": " topics",
        "tokens": [
          51464,
          8378,
          51564
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7161,
        "id": 2139,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7159,
        "temperature": 0,
        "text": " here or I might come back later, I'm just going to check",
        "tokens": [
          51564,
          510,
          420,
          286,
          1062,
          808,
          646,
          1780,
          11,
          286,
          478,
          445,
          516,
          281,
          1520,
          51664
        ]
      },
      {
        "avg_logprob": -0.21173271379972758,
        "compression_ratio": 1.6200873362445414,
        "end": 7163,
        "id": 2140,
        "no_speech_prob": 0.3556489944458008,
        "seek": 713500,
        "start": 7161,
        "temperature": 0,
        "text": " I'm going to mute my, I'm going to put some music on for you guys",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          24523,
          452,
          11,
          286,
          478,
          516,
          281,
          829,
          512,
          1318,
          322,
          337,
          291,
          1074,
          51764
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7165,
        "id": 2141,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7163,
        "temperature": 0,
        "text": " um",
        "tokens": [
          50364,
          1105,
          50464
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7167,
        "id": 2142,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7165,
        "temperature": 0,
        "text": " I'm going to mute my microphone for a second",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          24523,
          452,
          10952,
          337,
          257,
          1150,
          50564
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7169,
        "id": 2143,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7167,
        "temperature": 0,
        "text": " and take a little short break",
        "tokens": [
          50564,
          293,
          747,
          257,
          707,
          2099,
          1821,
          50664
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7171,
        "id": 2144,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7169,
        "temperature": 0,
        "text": " and then I'll come back and let you know what I have time",
        "tokens": [
          50664,
          293,
          550,
          286,
          603,
          808,
          646,
          293,
          718,
          291,
          458,
          437,
          286,
          362,
          565,
          50764
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7173,
        "id": 2145,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7171,
        "temperature": 0,
        "text": " for left, so let's play",
        "tokens": [
          50764,
          337,
          1411,
          11,
          370,
          718,
          311,
          862,
          50864
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7175,
        "id": 2146,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7173,
        "temperature": 0,
        "text": " F Looper's Perlinois Song",
        "tokens": [
          50864,
          479,
          6130,
          7192,
          311,
          3026,
          75,
          15936,
          11862,
          50964
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7177,
        "id": 2147,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7175,
        "temperature": 0,
        "text": " this is random, this is noise",
        "tokens": [
          50964,
          341,
          307,
          4974,
          11,
          341,
          307,
          5658,
          51064
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7179,
        "id": 2148,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7177,
        "temperature": 0,
        "text": " Perlinois that is, in the core",
        "tokens": [
          51064,
          3026,
          75,
          15936,
          300,
          307,
          11,
          294,
          264,
          4965,
          51164
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7181,
        "id": 2149,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7179,
        "temperature": 0,
        "text": " random algorithm, the actual",
        "tokens": [
          51164,
          4974,
          9284,
          11,
          264,
          3539,
          51264
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7183,
        "id": 2150,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7181,
        "temperature": 0,
        "text": " random algorithm, it's probably really really",
        "tokens": [
          51264,
          4974,
          9284,
          11,
          309,
          311,
          1391,
          534,
          534,
          51364
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7185,
        "id": 2151,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7183,
        "temperature": 0,
        "text": " quiet right? related at all",
        "tokens": [
          51364,
          5677,
          558,
          30,
          4077,
          412,
          439,
          51464
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7187,
        "id": 2152,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7185,
        "temperature": 0,
        "text": " I'm picking random numbers between",
        "tokens": [
          51464,
          286,
          478,
          8867,
          4974,
          3547,
          1296,
          51564
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7189,
        "id": 2153,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7187,
        "temperature": 0,
        "text": " 0 and 10, 8, 2, 7",
        "tokens": [
          51564,
          1958,
          293,
          1266,
          11,
          1649,
          11,
          568,
          11,
          1614,
          51664
        ]
      },
      {
        "avg_logprob": -0.2438774254485851,
        "compression_ratio": 1.6141732283464567,
        "end": 7191,
        "id": 2154,
        "no_speech_prob": 0.0008294337894767523,
        "seek": 716300,
        "start": 7189,
        "temperature": 0,
        "text": " 6, 1, 9",
        "tokens": [
          51664,
          1386,
          11,
          502,
          11,
          1722,
          51764
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7193,
        "id": 2155,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7191,
        "temperature": 0,
        "text": " 4, 8, 9",
        "tokens": [
          50364,
          1017,
          11,
          1649,
          11,
          1722,
          50464
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7195,
        "id": 2156,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7193,
        "temperature": 0,
        "text": " 2, 1, 3, I picked 9 a lot",
        "tokens": [
          50464,
          568,
          11,
          502,
          11,
          805,
          11,
          286,
          6183,
          1722,
          257,
          688,
          50564
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7197,
        "id": 2157,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7195,
        "temperature": 0,
        "text": " apparently, but with Perlinois",
        "tokens": [
          50564,
          7970,
          11,
          457,
          365,
          3026,
          75,
          15936,
          50664
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7199,
        "id": 2158,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7197,
        "temperature": 0,
        "text": " I might pick numbers like this",
        "tokens": [
          50664,
          286,
          1062,
          1888,
          3547,
          411,
          341,
          50764
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7201,
        "id": 2159,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7199,
        "temperature": 0,
        "text": " 2, 3, 4, 3, 4",
        "tokens": [
          50764,
          568,
          11,
          805,
          11,
          1017,
          11,
          805,
          11,
          1017,
          50864
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7203,
        "id": 2160,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7201,
        "temperature": 0,
        "text": " 5, 6, 5, 4",
        "tokens": [
          50864,
          1025,
          11,
          1386,
          11,
          1025,
          11,
          1017,
          50964
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7205,
        "id": 2161,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7203,
        "temperature": 0,
        "text": " 5, 6, 7, 5",
        "tokens": [
          50964,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1025,
          51064
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7207,
        "id": 2162,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7205,
        "temperature": 0,
        "text": " 6, 7, 5, 6, 7, 8",
        "tokens": [
          51064,
          1386,
          11,
          1614,
          11,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1649,
          51164
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7209,
        "id": 2163,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7207,
        "temperature": 0,
        "text": " 9, 8, 7, 6",
        "tokens": [
          51164,
          1722,
          11,
          1649,
          11,
          1614,
          11,
          1386,
          51264
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7211,
        "id": 2164,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7209,
        "temperature": 0,
        "text": " this is like Perlinois's performance",
        "tokens": [
          51264,
          341,
          307,
          411,
          3026,
          75,
          15936,
          311,
          3389,
          51364
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7213,
        "id": 2165,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7211,
        "temperature": 0,
        "text": " art",
        "tokens": [
          51364,
          1523,
          51464
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7215,
        "id": 2166,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7213,
        "temperature": 0,
        "text": " 9, 2, 7, 6, 1",
        "tokens": [
          51464,
          1722,
          11,
          568,
          11,
          1614,
          11,
          1386,
          11,
          502,
          51564
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7217,
        "id": 2167,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7215,
        "temperature": 0,
        "text": " 9, 4, 8, 9",
        "tokens": [
          51564,
          1722,
          11,
          1017,
          11,
          1649,
          11,
          1722,
          51664
        ]
      },
      {
        "avg_logprob": -0.10254981624546336,
        "compression_ratio": 1.6442953020134228,
        "end": 7219,
        "id": 2168,
        "no_speech_prob": 0.3804008662700653,
        "seek": 719100,
        "start": 7217,
        "temperature": 0,
        "text": " 2, 1, 3, I picked 9",
        "tokens": [
          51664,
          568,
          11,
          502,
          11,
          805,
          11,
          286,
          6183,
          1722,
          51764
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7221,
        "id": 2169,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7219,
        "temperature": 0,
        "text": " 2, 3, 4, 3, 4",
        "tokens": [
          50364,
          568,
          11,
          805,
          11,
          1017,
          11,
          805,
          11,
          1017,
          50464
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7223,
        "id": 2170,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7221,
        "temperature": 0,
        "text": " 5, 6, 5, 4",
        "tokens": [
          50464,
          1025,
          11,
          1386,
          11,
          1025,
          11,
          1017,
          50564
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7225,
        "id": 2171,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7223,
        "temperature": 0,
        "text": " this is like Perlinois's performance art",
        "tokens": [
          50564,
          341,
          307,
          411,
          3026,
          75,
          15936,
          311,
          3389,
          1523,
          50664
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7227,
        "id": 2172,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7225,
        "temperature": 0,
        "text": " 7, 5, 9",
        "tokens": [
          50664,
          1614,
          11,
          1025,
          11,
          1722,
          50764
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7229,
        "id": 2173,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7227,
        "temperature": 0,
        "text": " 2, 7, 6, 1",
        "tokens": [
          50764,
          568,
          11,
          1614,
          11,
          1386,
          11,
          502,
          50864
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7231,
        "id": 2174,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7229,
        "temperature": 0,
        "text": " 9, 4, 8",
        "tokens": [
          50864,
          1722,
          11,
          1017,
          11,
          1649,
          50964
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7233,
        "id": 2175,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7231,
        "temperature": 0,
        "text": " but with Perlinois's I might pick numbers like this",
        "tokens": [
          50964,
          457,
          365,
          3026,
          75,
          15936,
          311,
          286,
          1062,
          1888,
          3547,
          411,
          341,
          51064
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7235,
        "id": 2176,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7233,
        "temperature": 0,
        "text": " 2, 3, 4, 3, 4",
        "tokens": [
          51064,
          568,
          11,
          805,
          11,
          1017,
          11,
          805,
          11,
          1017,
          51164
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7237,
        "id": 2177,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7235,
        "temperature": 0,
        "text": " 5, 6, 5, 4",
        "tokens": [
          51164,
          1025,
          11,
          1386,
          11,
          1025,
          11,
          1017,
          51264
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7239,
        "id": 2178,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7237,
        "temperature": 0,
        "text": " 5, 6, 7, 5",
        "tokens": [
          51264,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1025,
          51364
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7241,
        "id": 2179,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7239,
        "temperature": 0,
        "text": " 6, 7, 5",
        "tokens": [
          51364,
          1386,
          11,
          1614,
          11,
          1025,
          51464
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7243,
        "id": 2180,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7241,
        "temperature": 0,
        "text": " Perlinois's that is, Perlinois",
        "tokens": [
          51464,
          3026,
          75,
          15936,
          311,
          300,
          307,
          11,
          3026,
          75,
          15936,
          51564
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7245,
        "id": 2181,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7243,
        "temperature": 0,
        "text": " so this is Perlinois's that is, Perlinois",
        "tokens": [
          51564,
          370,
          341,
          307,
          3026,
          75,
          15936,
          311,
          300,
          307,
          11,
          3026,
          75,
          15936,
          51664
        ]
      },
      {
        "avg_logprob": -0.1399321004646976,
        "compression_ratio": 2.127659574468085,
        "end": 7247,
        "id": 2182,
        "no_speech_prob": 0.4670626223087311,
        "seek": 721900,
        "start": 7245,
        "temperature": 0,
        "text": " this is Perlinois's that is, Perlinois",
        "tokens": [
          51664,
          341,
          307,
          3026,
          75,
          15936,
          311,
          300,
          307,
          11,
          3026,
          75,
          15936,
          51764
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7249.18,
        "id": 2183,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7247,
        "temperature": 1,
        "text": " I'm back but I'm gonna take still another break to get some water",
        "tokens": [
          50364,
          286,
          478,
          646,
          457,
          286,
          478,
          290,
          19968,
          64,
          747,
          920,
          1071,
          1821,
          220,
          1353,
          483,
          512,
          1281,
          50473
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7249.54,
        "id": 2184,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7249.18,
        "temperature": 1,
        "text": " and then I'll be back again",
        "tokens": [
          50473,
          293,
          550,
          286,
          603,
          312,
          646,
          797,
          50491
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7256.08,
        "id": 2185,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7255.54,
        "temperature": 1,
        "text": " but I'm gonna take still another break to get some water",
        "tokens": [
          50791,
          758,
          83,
          286,
          478,
          799,
          747,
          920,
          364,
          310,
          511,
          272,
          265,
          514,
          281,
          483,
          512,
          1281,
          50818
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7259.3,
        "id": 2186,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7258.24,
        "temperature": 1,
        "text": " yes, it is on Soundcloud, so I made the check and give it a listen",
        "tokens": [
          50926,
          2086,
          11,
          309,
          307,
          322,
          14673,
          44495,
          11,
          370,
          286,
          1027,
          264,
          417,
          68,
          547,
          364,
          67,
          976,
          309,
          257,
          2140,
          50979
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7266.34,
        "id": 2187,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7265.3,
        "temperature": 1,
        "text": " but with Perlinois's I might pick numbers like this",
        "tokens": [
          51279,
          758,
          83,
          365,
          3026,
          75,
          15936,
          311,
          286,
          275,
          910,
          83,
          1888,
          3547,
          411,
          341,
          51331
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7269.14,
        "id": 2188,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7266.34,
        "temperature": 1,
        "text": " 2, 3, 4, 3, 4",
        "tokens": [
          51331,
          568,
          11,
          805,
          11,
          1017,
          11,
          805,
          11,
          1017,
          51471
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7269.88,
        "id": 2189,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7269.14,
        "temperature": 1,
        "text": " 5, 6, 7, 6",
        "tokens": [
          51471,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1386,
          51508
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7269.92,
        "id": 2190,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7269.88,
        "temperature": 1,
        "text": " Perlinois's that is",
        "tokens": [
          51508,
          3026,
          75,
          2982,
          271,
          311,
          300,
          307,
          51510
        ]
      },
      {
        "avg_logprob": -1.3151439428329468,
        "compression_ratio": 1.7567567567567568,
        "end": 7275.24,
        "id": 2191,
        "no_speech_prob": 0.4978247582912445,
        "seek": 724700,
        "start": 7274.74,
        "temperature": 1,
        "text": " 6, 7, 7, 8",
        "tokens": [
          51751,
          1386,
          11,
          1614,
          11,
          1614,
          11,
          1649,
          51776
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7275.74,
        "id": 2192,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7275.24,
        "temperature": 0,
        "text": " Perlinois's that is",
        "tokens": [
          50364,
          3026,
          75,
          2982,
          271,
          311,
          300,
          307,
          50389
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7278.24,
        "id": 2193,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7275.74,
        "temperature": 0,
        "text": " 2, 3, 4, 3, 4",
        "tokens": [
          50389,
          568,
          11,
          805,
          11,
          1017,
          11,
          805,
          11,
          1017,
          50514
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7280.24,
        "id": 2194,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7278.24,
        "temperature": 0,
        "text": " 5, 6, 5, 4",
        "tokens": [
          50514,
          1025,
          11,
          1386,
          11,
          1025,
          11,
          1017,
          50614
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7282.24,
        "id": 2195,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7280.24,
        "temperature": 0,
        "text": " 5, 6, 7, 5",
        "tokens": [
          50614,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1025,
          50714
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7284.24,
        "id": 2196,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7282.24,
        "temperature": 0,
        "text": " 6, 7, 5",
        "tokens": [
          50714,
          1386,
          11,
          1614,
          11,
          1025,
          50814
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7286.24,
        "id": 2197,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7284.24,
        "temperature": 0,
        "text": " 2, 3, 4, 3, 4",
        "tokens": [
          50814,
          568,
          11,
          805,
          11,
          1017,
          11,
          805,
          11,
          1017,
          50914
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7288.24,
        "id": 2198,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7286.24,
        "temperature": 0,
        "text": " 5, 6, 5, 4",
        "tokens": [
          50914,
          1025,
          11,
          1386,
          11,
          1025,
          11,
          1017,
          51014
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7290.24,
        "id": 2199,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7288.24,
        "temperature": 0,
        "text": " 5, 6, 7, 5",
        "tokens": [
          51014,
          1025,
          11,
          1386,
          11,
          1614,
          11,
          1025,
          51114
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7292.24,
        "id": 2200,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7290.24,
        "temperature": 0,
        "text": " 6, 7, 5",
        "tokens": [
          51114,
          1386,
          11,
          1614,
          11,
          1025,
          51214
        ]
      },
      {
        "avg_logprob": -0.27649743506248964,
        "compression_ratio": 1.8271604938271604,
        "end": 7294.24,
        "id": 2201,
        "no_speech_prob": 0.18524549901485443,
        "seek": 727524,
        "start": 7292.24,
        "temperature": 0,
        "text": " this is like Perlinois's performance art",
        "tokens": [
          51214,
          341,
          307,
          411,
          3026,
          75,
          2982,
          271,
          311,
          3389,
          1523,
          51314
        ]
      },
      {
        "avg_logprob": -0.7570292949676514,
        "compression_ratio": 0.5789473684210527,
        "end": 7307.24,
        "id": 2202,
        "no_speech_prob": 0.785598635673523,
        "seek": 730524,
        "start": 7305.24,
        "temperature": 0,
        "text": " Perlinois's",
        "tokens": [
          50364,
          3026,
          75,
          2982,
          271,
          311,
          50464
        ]
      },
      {
        "avg_logprob": -1.7610133244441106,
        "compression_ratio": 1.16,
        "end": 7338.2,
        "id": 2203,
        "no_speech_prob": 0.41394180059432983,
        "seek": 733524,
        "start": 7336.2,
        "temperature": 1,
        "text": " Silence",
        "tokens": [
          50412,
          34570,
          50512
        ]
      },
      {
        "avg_logprob": -1.7610133244441106,
        "compression_ratio": 1.16,
        "end": 7340.34,
        "id": 2204,
        "no_speech_prob": 0.41394180059432983,
        "seek": 733524,
        "start": 7338.2,
        "temperature": 1,
        "text": " Silence",
        "tokens": [
          50512,
          318,
          794,
          77,
          384,
          50619
        ]
      },
      {
        "avg_logprob": -1.7610133244441106,
        "compression_ratio": 1.16,
        "end": 7346.44,
        "id": 2205,
        "no_speech_prob": 0.41394180059432983,
        "seek": 733524,
        "start": 7344.44,
        "temperature": 1,
        "text": " Silence",
        "tokens": [
          50824,
          34570,
          50924
        ]
      },
      {
        "avg_logprob": -1.7610133244441106,
        "compression_ratio": 1.16,
        "end": 7359.94,
        "id": 2206,
        "no_speech_prob": 0.41394180059432983,
        "seek": 733524,
        "start": 7357.9,
        "temperature": 1,
        "text": " I guess the music ended but I am back now",
        "tokens": [
          51497,
          286,
          2041,
          264,
          1318,
          4590,
          457,
          286,
          220,
          335,
          646,
          586,
          51599
        ]
      },
      {
        "avg_logprob": -1.7610133244441106,
        "compression_ratio": 1.16,
        "end": 7362.44,
        "id": 2207,
        "no_speech_prob": 0.41394180059432983,
        "seek": 733524,
        "start": 7359.94,
        "temperature": 1,
        "text": " Ok, let me see, Ok",
        "tokens": [
          51599,
          3477,
          11,
          718,
          385,
          536,
          11,
          3477,
          51724
        ]
      },
      {
        "avg_logprob": -1.7610133244441106,
        "compression_ratio": 1.16,
        "end": 7364.44,
        "id": 2208,
        "no_speech_prob": 0.41394180059432983,
        "seek": 733524,
        "start": 7362.44,
        "temperature": 1,
        "text": " So",
        "tokens": [
          51724,
          407,
          51824
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7368.44,
        "id": 2209,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7365.44,
        "temperature": 0,
        "text": " Alright, so that was",
        "tokens": [
          50414,
          2798,
          11,
          370,
          300,
          390,
          50564
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7370.44,
        "id": 2210,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7368.44,
        "temperature": 0,
        "text": " Yes, you look at like on SoundCloud",
        "tokens": [
          50564,
          1079,
          11,
          291,
          574,
          412,
          411,
          322,
          14673,
          32787,
          50664
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7372.44,
        "id": 2211,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7370.44,
        "temperature": 0,
        "text": " There's a bunch of remixes that people have made",
        "tokens": [
          50664,
          821,
          311,
          257,
          3840,
          295,
          890,
          36005,
          300,
          561,
          362,
          1027,
          50764
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7374.44,
        "id": 2212,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7372.44,
        "temperature": 0,
        "text": " Including the This Dot song",
        "tokens": [
          50764,
          27137,
          264,
          639,
          38753,
          2153,
          50864
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7376.44,
        "id": 2213,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7374.44,
        "temperature": 0,
        "text": " Which I know you guys have enjoyed in the past",
        "tokens": [
          50864,
          3013,
          286,
          458,
          291,
          1074,
          362,
          4626,
          294,
          264,
          1791,
          50964
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7377.44,
        "id": 2214,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7376.44,
        "temperature": 0,
        "text": " Ok",
        "tokens": [
          50964,
          3477,
          51014
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7381.44,
        "id": 2215,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7377.44,
        "temperature": 0,
        "text": " Boy, I'm having trouble with this context free grammar topic",
        "tokens": [
          51014,
          9486,
          11,
          286,
          478,
          1419,
          5253,
          365,
          341,
          4319,
          1737,
          22317,
          4829,
          51214
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7385.44,
        "id": 2216,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7381.44,
        "temperature": 0,
        "text": " So let's see, let me",
        "tokens": [
          51214,
          407,
          718,
          311,
          536,
          11,
          718,
          385,
          51414
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7389.44,
        "id": 2217,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7387.44,
        "temperature": 0,
        "text": " Let me see if I can manage",
        "tokens": [
          51514,
          961,
          385,
          536,
          498,
          286,
          393,
          3067,
          51614
        ]
      },
      {
        "avg_logprob": -0.3158902218467311,
        "compression_ratio": 1.4516129032258065,
        "end": 7393.44,
        "id": 2218,
        "no_speech_prob": 0.005890590604394674,
        "seek": 736444,
        "start": 7389.44,
        "temperature": 0,
        "text": " To make, to do another",
        "tokens": [
          51614,
          1407,
          652,
          11,
          281,
          360,
          1071,
          51814
        ]
      },
      {
        "avg_logprob": -0.27938175201416016,
        "compression_ratio": 1.1666666666666667,
        "end": 7396.44,
        "id": 2219,
        "no_speech_prob": 0.006794110871851444,
        "seek": 739344,
        "start": 7394.44,
        "temperature": 0,
        "text": " Video",
        "tokens": [
          50414,
          9777,
          50514
        ]
      },
      {
        "avg_logprob": -0.27938175201416016,
        "compression_ratio": 1.1666666666666667,
        "end": 7398.44,
        "id": 2220,
        "no_speech_prob": 0.006794110871851444,
        "seek": 739344,
        "start": 7396.44,
        "temperature": 0,
        "text": " Where I just",
        "tokens": [
          50514,
          2305,
          286,
          445,
          50614
        ]
      },
      {
        "avg_logprob": -0.27938175201416016,
        "compression_ratio": 1.1666666666666667,
        "end": 7406.44,
        "id": 2221,
        "no_speech_prob": 0.006794110871851444,
        "seek": 739344,
        "start": 7402.44,
        "temperature": 0,
        "text": " Where I kind of program the context free",
        "tokens": [
          50814,
          2305,
          286,
          733,
          295,
          1461,
          264,
          4319,
          1737,
          51014
        ]
      },
      {
        "avg_logprob": -0.27938175201416016,
        "compression_ratio": 1.1666666666666667,
        "end": 7409.44,
        "id": 2222,
        "no_speech_prob": 0.006794110871851444,
        "seek": 739344,
        "start": 7406.44,
        "temperature": 0,
        "text": " Algorithm from scratch",
        "tokens": [
          51014,
          35014,
          6819,
          76,
          490,
          8459,
          51164
        ]
      },
      {
        "avg_logprob": -0.27938175201416016,
        "compression_ratio": 1.1666666666666667,
        "end": 7417.44,
        "id": 2223,
        "no_speech_prob": 0.006794110871851444,
        "seek": 739344,
        "start": 7415.44,
        "temperature": 0,
        "text": " I don't need draw, Ok",
        "tokens": [
          51464,
          286,
          500,
          380,
          643,
          2642,
          11,
          3477,
          51564
        ]
      },
      {
        "avg_logprob": -0.27938175201416016,
        "compression_ratio": 1.1666666666666667,
        "end": 7420.44,
        "id": 2224,
        "no_speech_prob": 0.006794110871851444,
        "seek": 739344,
        "start": 7417.44,
        "temperature": 0,
        "text": " So let's try doing it",
        "tokens": [
          51564,
          407,
          718,
          311,
          853,
          884,
          309,
          51714
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7427.44,
        "id": 2225,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7423.44,
        "temperature": 0,
        "text": " And then what I'll do is I will compare it to",
        "tokens": [
          50364,
          400,
          550,
          437,
          286,
          603,
          360,
          307,
          286,
          486,
          6794,
          309,
          281,
          50564
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7430.44,
        "id": 2226,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7427.44,
        "temperature": 0,
        "text": " This particular example",
        "tokens": [
          50564,
          639,
          1729,
          1365,
          50714
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7432.44,
        "id": 2227,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7430.44,
        "temperature": 0,
        "text": " Which has this all in a",
        "tokens": [
          50714,
          3013,
          575,
          341,
          439,
          294,
          257,
          50814
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7434.44,
        "id": 2228,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7432.44,
        "temperature": 0,
        "text": " Kind of function, Ok",
        "tokens": [
          50814,
          9242,
          295,
          2445,
          11,
          3477,
          50914
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7442.44,
        "id": 2229,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7438.44,
        "temperature": 0,
        "text": " Ok, here we go, so I'm going to do that now",
        "tokens": [
          51114,
          3477,
          11,
          510,
          321,
          352,
          11,
          370,
          286,
          478,
          516,
          281,
          360,
          300,
          586,
          51314
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7446.44,
        "id": 2230,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7443.44,
        "temperature": 0,
        "text": " And I'm hoping this is something that I can do",
        "tokens": [
          51364,
          400,
          286,
          478,
          7159,
          341,
          307,
          746,
          300,
          286,
          393,
          360,
          51514
        ]
      },
      {
        "avg_logprob": -0.20188450813293457,
        "compression_ratio": 1.395973154362416,
        "end": 7448.44,
        "id": 2231,
        "no_speech_prob": 0.005818674340844154,
        "seek": 742344,
        "start": 7446.44,
        "temperature": 0,
        "text": " In",
        "tokens": [
          51514,
          682,
          51614
        ]
      },
      {
        "avg_logprob": -0.28786471154954696,
        "compression_ratio": 1.3888888888888888,
        "end": 7454.44,
        "id": 2232,
        "no_speech_prob": 0.0020189026836305857,
        "seek": 744844,
        "start": 7449.44,
        "temperature": 0,
        "text": " Just about 10 or 15 minutes",
        "tokens": [
          50414,
          1449,
          466,
          1266,
          420,
          2119,
          2077,
          50664
        ]
      },
      {
        "avg_logprob": -0.28786471154954696,
        "compression_ratio": 1.3888888888888888,
        "end": 7457.44,
        "id": 2233,
        "no_speech_prob": 0.0020189026836305857,
        "seek": 744844,
        "start": 7454.44,
        "temperature": 0,
        "text": " Ha ha ha ha, that means it's going to take at least an hour and a half",
        "tokens": [
          50664,
          4064,
          324,
          324,
          324,
          11,
          300,
          1355,
          309,
          311,
          516,
          281,
          747,
          412,
          1935,
          364,
          1773,
          293,
          257,
          1922,
          50814
        ]
      },
      {
        "avg_logprob": -0.28786471154954696,
        "compression_ratio": 1.3888888888888888,
        "end": 7467.44,
        "id": 2234,
        "no_speech_prob": 0.0020189026836305857,
        "seek": 744844,
        "start": 7463.44,
        "temperature": 0,
        "text": " I'm sorry, I'm looking at Twitter, people are tweeting at me",
        "tokens": [
          51114,
          286,
          478,
          2597,
          11,
          286,
          478,
          1237,
          412,
          5794,
          11,
          561,
          366,
          40090,
          412,
          385,
          51314
        ]
      },
      {
        "avg_logprob": -0.28786471154954696,
        "compression_ratio": 1.3888888888888888,
        "end": 7471.44,
        "id": 2235,
        "no_speech_prob": 0.0020189026836305857,
        "seek": 744844,
        "start": 7467.44,
        "temperature": 0,
        "text": " Ok, let's give this a try, shall we?",
        "tokens": [
          51314,
          3477,
          11,
          718,
          311,
          976,
          341,
          257,
          853,
          11,
          4393,
          321,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.28786471154954696,
        "compression_ratio": 1.3888888888888888,
        "end": 7473.44,
        "id": 2236,
        "no_speech_prob": 0.0020189026836305857,
        "seek": 744844,
        "start": 7471.44,
        "temperature": 0,
        "text": " Ok",
        "tokens": [
          51514,
          3477,
          51614
        ]
      },
      {
        "avg_logprob": -0.28786471154954696,
        "compression_ratio": 1.3888888888888888,
        "end": 7475.44,
        "id": 2237,
        "no_speech_prob": 0.0020189026836305857,
        "seek": 744844,
        "start": 7473.44,
        "temperature": 0,
        "text": " Hello, welcome to another",
        "tokens": [
          51614,
          2425,
          11,
          2928,
          281,
          1071,
          51714
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7478.44,
        "id": 2238,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7475.44,
        "temperature": 0,
        "text": " Another, oh my god, I can't believe I'm making a fourth or fifth",
        "tokens": [
          50364,
          3996,
          11,
          1954,
          452,
          3044,
          11,
          286,
          393,
          380,
          1697,
          286,
          478,
          1455,
          257,
          6409,
          420,
          9266,
          50514
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7481.44,
        "id": 2239,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7478.44,
        "temperature": 0,
        "text": " I've lost track, video about context free grammar",
        "tokens": [
          50514,
          286,
          600,
          2731,
          2837,
          11,
          960,
          466,
          4319,
          1737,
          22317,
          50664
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7484.44,
        "id": 2240,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7481.44,
        "temperature": 0,
        "text": " So in this video I'm going to do something a little scary",
        "tokens": [
          50664,
          407,
          294,
          341,
          960,
          286,
          478,
          516,
          281,
          360,
          746,
          257,
          707,
          6958,
          50814
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7488.44,
        "id": 2241,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7484.44,
        "temperature": 0,
        "text": " Which is instead of using an engine or library or framework",
        "tokens": [
          50814,
          3013,
          307,
          2602,
          295,
          1228,
          364,
          2848,
          420,
          6405,
          420,
          8388,
          51014
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7492.44,
        "id": 2242,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7488.44,
        "temperature": 0,
        "text": " Like Tracery or Rita, I'm just going to program a little context free grammar",
        "tokens": [
          51014,
          1743,
          1765,
          326,
          2109,
          420,
          32672,
          11,
          286,
          478,
          445,
          516,
          281,
          1461,
          257,
          707,
          4319,
          1737,
          22317,
          51214
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7495.44,
        "id": 2243,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7492.44,
        "temperature": 0,
        "text": " Expansion system without anything at all",
        "tokens": [
          51214,
          21391,
          599,
          313,
          1185,
          1553,
          1340,
          412,
          439,
          51364
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7497.44,
        "id": 2244,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7495.44,
        "temperature": 0,
        "text": " Just my own wits and fingers",
        "tokens": [
          51364,
          1449,
          452,
          1065,
          261,
          1208,
          293,
          7350,
          51464
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7499.44,
        "id": 2245,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7497.44,
        "temperature": 0,
        "text": " We're going to see how that goes, right?",
        "tokens": [
          51464,
          492,
          434,
          516,
          281,
          536,
          577,
          300,
          1709,
          11,
          558,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.24679708850476167,
        "compression_ratio": 1.6655172413793105,
        "end": 7503.44,
        "id": 2246,
        "no_speech_prob": 0.06559102237224579,
        "seek": 747544,
        "start": 7499.44,
        "temperature": 0,
        "text": " So remember the idea here is that I have a system, a language",
        "tokens": [
          51564,
          407,
          1604,
          264,
          1558,
          510,
          307,
          300,
          286,
          362,
          257,
          1185,
          11,
          257,
          2856,
          51764
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7507.44,
        "id": 2247,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7503.44,
        "temperature": 0,
        "text": " That has valid elements of it, valid letters of the alphabet, so to speak",
        "tokens": [
          50364,
          663,
          575,
          7363,
          4959,
          295,
          309,
          11,
          7363,
          7825,
          295,
          264,
          23339,
          11,
          370,
          281,
          1710,
          50564
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7510.44,
        "id": 2248,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7507.44,
        "temperature": 0,
        "text": " There are a set of production rules",
        "tokens": [
          50564,
          821,
          366,
          257,
          992,
          295,
          4265,
          4474,
          50714
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7513.44,
        "id": 2249,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7510.44,
        "temperature": 0,
        "text": " And I'm going to use a very simple set of production rules",
        "tokens": [
          50714,
          400,
          286,
          478,
          516,
          281,
          764,
          257,
          588,
          2199,
          992,
          295,
          4265,
          4474,
          50864
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7515.44,
        "id": 2250,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7513.44,
        "temperature": 0,
        "text": " And try to write a recursive function",
        "tokens": [
          50864,
          400,
          853,
          281,
          2464,
          257,
          20560,
          488,
          2445,
          50964
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7521.44,
        "id": 2251,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7515.44,
        "temperature": 0,
        "text": " A function that references itself to recursively expand this grammar tree",
        "tokens": [
          50964,
          316,
          2445,
          300,
          15400,
          2564,
          281,
          20560,
          3413,
          5268,
          341,
          22317,
          4230,
          51264
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7523.44,
        "id": 2252,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7521.44,
        "temperature": 0,
        "text": " It'll be like magic, I think",
        "tokens": [
          51264,
          467,
          603,
          312,
          411,
          5585,
          11,
          286,
          519,
          51364
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7525.44,
        "id": 2253,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7523.44,
        "temperature": 0,
        "text": " Or there's going to be a lot of problems that are going to happen",
        "tokens": [
          51364,
          1610,
          456,
          311,
          516,
          281,
          312,
          257,
          688,
          295,
          2740,
          300,
          366,
          516,
          281,
          1051,
          51464
        ]
      },
      {
        "avg_logprob": -0.19166056315104166,
        "compression_ratio": 1.7489878542510122,
        "end": 7529.44,
        "id": 2254,
        "no_speech_prob": 0.010012930259108543,
        "seek": 750344,
        "start": 7525.44,
        "temperature": 0,
        "text": " Ok, so I have pre-existing examples where I've done this",
        "tokens": [
          51464,
          3477,
          11,
          370,
          286,
          362,
          659,
          12,
          36447,
          5110,
          689,
          286,
          600,
          1096,
          341,
          51664
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7533.44,
        "id": 2255,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7529.44,
        "temperature": 0,
        "text": " But I think I did that many years ago and I ported it from somebody else's examples",
        "tokens": [
          50364,
          583,
          286,
          519,
          286,
          630,
          300,
          867,
          924,
          2057,
          293,
          286,
          2436,
          292,
          309,
          490,
          2618,
          1646,
          311,
          5110,
          50564
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7537.44,
        "id": 2256,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7533.44,
        "temperature": 0,
        "text": " Namely Allison Parish's wonderful Python examples",
        "tokens": [
          50564,
          10684,
          736,
          32638,
          3457,
          742,
          311,
          3715,
          15329,
          5110,
          50764
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7541.44,
        "id": 2257,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7537.44,
        "temperature": 0,
        "text": " Link to Allison's resources on a course called Reading and Writing Electronic Text",
        "tokens": [
          50764,
          8466,
          281,
          32638,
          311,
          3593,
          322,
          257,
          1164,
          1219,
          29766,
          293,
          32774,
          46921,
          18643,
          50964
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7543.44,
        "id": 2258,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7541.44,
        "temperature": 0,
        "text": " In this video's description",
        "tokens": [
          50964,
          682,
          341,
          960,
          311,
          3855,
          51064
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7545.44,
        "id": 2259,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7543.44,
        "temperature": 0,
        "text": " So the first thing that I want to do is",
        "tokens": [
          51064,
          407,
          264,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          51164
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7549.44,
        "id": 2260,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7545.44,
        "temperature": 0,
        "text": " I know I'm going to need some sort of object",
        "tokens": [
          51164,
          286,
          458,
          286,
          478,
          516,
          281,
          643,
          512,
          1333,
          295,
          2657,
          51364
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7552.44,
        "id": 2261,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7549.44,
        "temperature": 0,
        "text": " Probably a JavaScript object that has a set of rules in it",
        "tokens": [
          51364,
          9210,
          257,
          15778,
          2657,
          300,
          575,
          257,
          992,
          295,
          4474,
          294,
          309,
          51514
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7556.44,
        "id": 2262,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7552.44,
        "temperature": 0,
        "text": " So, and I could just write these in",
        "tokens": [
          51514,
          407,
          11,
          293,
          286,
          727,
          445,
          2464,
          613,
          294,
          51714
        ]
      },
      {
        "avg_logprob": -0.23937473625972353,
        "compression_ratio": 1.5985915492957747,
        "end": 7558.44,
        "id": 2263,
        "no_speech_prob": 0.03732476383447647,
        "seek": 752944,
        "start": 7556.44,
        "temperature": 0,
        "text": " Maybe I'll just write them in",
        "tokens": [
          51714,
          2704,
          286,
          603,
          445,
          2464,
          552,
          294,
          51814
        ]
      },
      {
        "avg_logprob": -0.25921596329787683,
        "compression_ratio": 1.3464566929133859,
        "end": 7562.44,
        "id": 2264,
        "no_speech_prob": 0.021286385133862495,
        "seek": 755844,
        "start": 7559.44,
        "temperature": 0,
        "text": " So I could say, and if I'm kind of going off of what's here",
        "tokens": [
          50414,
          407,
          286,
          727,
          584,
          11,
          293,
          498,
          286,
          478,
          733,
          295,
          516,
          766,
          295,
          437,
          311,
          510,
          50564
        ]
      },
      {
        "avg_logprob": -0.25921596329787683,
        "compression_ratio": 1.3464566929133859,
        "end": 7567.44,
        "id": 2265,
        "no_speech_prob": 0.021286385133862495,
        "seek": 755844,
        "start": 7562.44,
        "temperature": 0,
        "text": " I could say, ok, a sentence becomes the NV",
        "tokens": [
          50564,
          286,
          727,
          584,
          11,
          3133,
          11,
          257,
          8174,
          3643,
          264,
          46512,
          50814
        ]
      },
      {
        "avg_logprob": -0.25921596329787683,
        "compression_ratio": 1.3464566929133859,
        "end": 7572.44,
        "id": 2266,
        "no_speech_prob": 0.021286385133862495,
        "seek": 755844,
        "start": 7567.44,
        "temperature": 0,
        "text": " And a, well I have to go over here and look",
        "tokens": [
          50814,
          400,
          257,
          11,
          731,
          286,
          362,
          281,
          352,
          670,
          510,
          293,
          574,
          51064
        ]
      },
      {
        "avg_logprob": -0.25921596329787683,
        "compression_ratio": 1.3464566929133859,
        "end": 7581.44,
        "id": 2267,
        "no_speech_prob": 0.021286385133862495,
        "seek": 755844,
        "start": 7572.44,
        "temperature": 0,
        "text": " A noun is a cat or a dog",
        "tokens": [
          51064,
          316,
          23307,
          307,
          257,
          3857,
          420,
          257,
          3000,
          51514
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7591.44,
        "id": 2268,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7581.44,
        "temperature": 0,
        "text": " And a verb is a, whoo, a meows or barks",
        "tokens": [
          50364,
          400,
          257,
          9595,
          307,
          257,
          11,
          567,
          78,
          11,
          257,
          45132,
          82,
          420,
          16202,
          82,
          50864
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7595.44,
        "id": 2269,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7591.44,
        "temperature": 0,
        "text": " So again, this is my incredibly lame grammar",
        "tokens": [
          50864,
          407,
          797,
          11,
          341,
          307,
          452,
          6252,
          27635,
          22317,
          51064
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7597.44,
        "id": 2270,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7595.44,
        "temperature": 0,
        "text": " Boy, we could do so, so much better",
        "tokens": [
          51064,
          9486,
          11,
          321,
          727,
          360,
          370,
          11,
          370,
          709,
          1101,
          51164
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7601.44,
        "id": 2271,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7597.44,
        "temperature": 0,
        "text": " And we also have to think, well what really is going on here",
        "tokens": [
          51164,
          400,
          321,
          611,
          362,
          281,
          519,
          11,
          731,
          437,
          534,
          307,
          516,
          322,
          510,
          51364
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7605.44,
        "id": 2272,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7601.44,
        "temperature": 0,
        "text": " Should I be, what syntax should I use",
        "tokens": [
          51364,
          6454,
          286,
          312,
          11,
          437,
          28431,
          820,
          286,
          764,
          51564
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7607.44,
        "id": 2273,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7605.44,
        "temperature": 0,
        "text": " Like, maybe it makes more sense",
        "tokens": [
          51564,
          1743,
          11,
          1310,
          309,
          1669,
          544,
          2020,
          51664
        ]
      },
      {
        "avg_logprob": -0.22869189032192888,
        "compression_ratio": 1.5351351351351352,
        "end": 7609.44,
        "id": 2274,
        "no_speech_prob": 0.030213600024580956,
        "seek": 758144,
        "start": 7607.44,
        "temperature": 0,
        "text": " I think it might make more sense",
        "tokens": [
          51664,
          286,
          519,
          309,
          1062,
          652,
          544,
          2020,
          51764
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7613.44,
        "id": 2275,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7609.44,
        "temperature": 0,
        "text": " I sort of prefer to do this, like have these all be an array",
        "tokens": [
          50364,
          286,
          1333,
          295,
          4382,
          281,
          360,
          341,
          11,
          411,
          362,
          613,
          439,
          312,
          364,
          10225,
          50564
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7618.44,
        "id": 2276,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7613.44,
        "temperature": 0,
        "text": " Because an array is going to be easier for me to work with ultimately",
        "tokens": [
          50564,
          1436,
          364,
          10225,
          307,
          516,
          281,
          312,
          3571,
          337,
          385,
          281,
          589,
          365,
          6284,
          50814
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7620.44,
        "id": 2277,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7618.44,
        "temperature": 0,
        "text": " So I'm going to do that",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          360,
          300,
          50914
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7624.44,
        "id": 2278,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7620.44,
        "temperature": 0,
        "text": " Right, I don't want to have to parse this pipe symbol and all of that",
        "tokens": [
          50914,
          1779,
          11,
          286,
          500,
          380,
          528,
          281,
          362,
          281,
          48377,
          341,
          11240,
          5986,
          293,
          439,
          295,
          300,
          51114
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7626.44,
        "id": 2279,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7624.44,
        "temperature": 0,
        "text": " So what I'm going to consider is an array",
        "tokens": [
          51114,
          407,
          437,
          286,
          478,
          516,
          281,
          1949,
          307,
          364,
          10225,
          51214
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7630.44,
        "id": 2280,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7626.44,
        "temperature": 0,
        "text": " Is an array of options with equal probabilities",
        "tokens": [
          51214,
          1119,
          364,
          10225,
          295,
          3956,
          365,
          2681,
          33783,
          51414
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7634.44,
        "id": 2281,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7630.44,
        "temperature": 0,
        "text": " And right now the only possible sentence is the NV",
        "tokens": [
          51414,
          400,
          558,
          586,
          264,
          787,
          1944,
          8174,
          307,
          264,
          46512,
          51614
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7636.44,
        "id": 2282,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7634.44,
        "temperature": 0,
        "text": " The only possible N's are cat and dog",
        "tokens": [
          51614,
          440,
          787,
          1944,
          426,
          311,
          366,
          3857,
          293,
          3000,
          51714
        ]
      },
      {
        "avg_logprob": -0.21080246292242483,
        "compression_ratio": 1.7689243027888446,
        "end": 7638.44,
        "id": 2283,
        "no_speech_prob": 0.7604497671127319,
        "seek": 760944,
        "start": 7636.44,
        "temperature": 0,
        "text": " And the only possible V is meow and bark",
        "tokens": [
          51714,
          400,
          264,
          787,
          1944,
          691,
          307,
          45132,
          293,
          16202,
          51814
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7641.44,
        "id": 2284,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7638.44,
        "temperature": 0,
        "text": " So what I want to do is I want to figure out now",
        "tokens": [
          50364,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          2573,
          484,
          586,
          50514
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7643.44,
        "id": 2285,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7641.44,
        "temperature": 0,
        "text": " I need some sort of expansion algorithm",
        "tokens": [
          50514,
          286,
          643,
          512,
          1333,
          295,
          11260,
          9284,
          50614
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7645.44,
        "id": 2286,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7643.44,
        "temperature": 0,
        "text": " So what I need to do is I have a start",
        "tokens": [
          50614,
          407,
          437,
          286,
          643,
          281,
          360,
          307,
          286,
          362,
          257,
          722,
          50714
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7648.44,
        "id": 2287,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7645.44,
        "temperature": 0,
        "text": " So my start is just going to be the sentence S",
        "tokens": [
          50714,
          407,
          452,
          722,
          307,
          445,
          516,
          281,
          312,
          264,
          8174,
          318,
          50864
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7652.44,
        "id": 2288,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7648.44,
        "temperature": 0,
        "text": " Okay, now what I need to do is",
        "tokens": [
          50864,
          1033,
          11,
          586,
          437,
          286,
          643,
          281,
          360,
          307,
          51064
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7655.44,
        "id": 2289,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7652.44,
        "temperature": 0,
        "text": " Let's just make sure this program is kind of",
        "tokens": [
          51064,
          961,
          311,
          445,
          652,
          988,
          341,
          1461,
          307,
          733,
          295,
          51214
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7657.44,
        "id": 2290,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7655.44,
        "temperature": 0,
        "text": " And I have some errors here, like I'm missing a comma here",
        "tokens": [
          51214,
          400,
          286,
          362,
          512,
          13603,
          510,
          11,
          411,
          286,
          478,
          5361,
          257,
          22117,
          510,
          51314
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7663.44,
        "id": 2291,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7657.44,
        "temperature": 0,
        "text": " So let me just kind of say result equals start",
        "tokens": [
          51314,
          407,
          718,
          385,
          445,
          733,
          295,
          584,
          1874,
          6915,
          722,
          51614
        ]
      },
      {
        "avg_logprob": -0.1963956659490412,
        "compression_ratio": 1.7363636363636363,
        "end": 7665.44,
        "id": 2292,
        "no_speech_prob": 0.24216578900814056,
        "seek": 763844,
        "start": 7663.44,
        "temperature": 0,
        "text": " And see what happens here",
        "tokens": [
          51614,
          400,
          536,
          437,
          2314,
          510,
          51714
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7668.44,
        "id": 2293,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7665.44,
        "temperature": 0,
        "text": " Whoops, I'm in, I don't know where I am",
        "tokens": [
          50364,
          45263,
          11,
          286,
          478,
          294,
          11,
          286,
          500,
          380,
          458,
          689,
          286,
          669,
          50514
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7670.44,
        "id": 2294,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7668.44,
        "temperature": 0,
        "text": " I want to be, I'm probably",
        "tokens": [
          50514,
          286,
          528,
          281,
          312,
          11,
          286,
          478,
          1391,
          50614
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7674.44,
        "id": 2295,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7670.44,
        "temperature": 0,
        "text": " I'm probably editing the wrong code",
        "tokens": [
          50614,
          286,
          478,
          1391,
          10000,
          264,
          2085,
          3089,
          50814
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7676.44,
        "id": 2296,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7674.44,
        "temperature": 0,
        "text": " Don't I always do this? No, I'm in the right place",
        "tokens": [
          50814,
          1468,
          380,
          286,
          1009,
          360,
          341,
          30,
          883,
          11,
          286,
          478,
          294,
          264,
          558,
          1081,
          50914
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7679.44,
        "id": 2297,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7676.44,
        "temperature": 0,
        "text": " Oh, I just didn't console log anything",
        "tokens": [
          50914,
          876,
          11,
          286,
          445,
          994,
          380,
          11076,
          3565,
          1340,
          51064
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7684.44,
        "id": 2298,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7679.44,
        "temperature": 0,
        "text": " And I'm just going to say create P result",
        "tokens": [
          51064,
          400,
          286,
          478,
          445,
          516,
          281,
          584,
          1884,
          430,
          1874,
          51314
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7688.44,
        "id": 2299,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7684.44,
        "temperature": 0,
        "text": " So the idea here is, oops, S",
        "tokens": [
          51314,
          407,
          264,
          1558,
          510,
          307,
          11,
          34166,
          11,
          318,
          51514
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7690.44,
        "id": 2300,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7688.44,
        "temperature": 0,
        "text": " So I want to get more than S",
        "tokens": [
          51514,
          407,
          286,
          528,
          281,
          483,
          544,
          813,
          318,
          51614
        ]
      },
      {
        "avg_logprob": -0.19749754779743697,
        "compression_ratio": 1.5808080808080809,
        "end": 7692.44,
        "id": 2301,
        "no_speech_prob": 0.1968110054731369,
        "seek": 766544,
        "start": 7690.44,
        "temperature": 0,
        "text": " So how do I do this?",
        "tokens": [
          51614,
          407,
          577,
          360,
          286,
          360,
          341,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7695.44,
        "id": 2302,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7692.44,
        "temperature": 0,
        "text": " Well, there's a variety of ways I could",
        "tokens": [
          50364,
          1042,
          11,
          456,
          311,
          257,
          5673,
          295,
          2098,
          286,
          727,
          50514
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7697.44,
        "id": 2303,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7695.44,
        "temperature": 0,
        "text": " It could sort of think about doing this",
        "tokens": [
          50514,
          467,
          727,
          1333,
          295,
          519,
          466,
          884,
          341,
          50614
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7699.44,
        "id": 2304,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7697.44,
        "temperature": 0,
        "text": " But I think what I want to do",
        "tokens": [
          50614,
          583,
          286,
          519,
          437,
          286,
          528,
          281,
          360,
          50714
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7702.44,
        "id": 2305,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7699.44,
        "temperature": 0,
        "text": " Is I want to sort of build out an array",
        "tokens": [
          50714,
          1119,
          286,
          528,
          281,
          1333,
          295,
          1322,
          484,
          364,
          10225,
          50864
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7705.44,
        "id": 2306,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7702.44,
        "temperature": 0,
        "text": " So I'm going to say expansion equals",
        "tokens": [
          50864,
          407,
          286,
          478,
          516,
          281,
          584,
          11260,
          6915,
          51014
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7707.44,
        "id": 2307,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7705.44,
        "temperature": 0,
        "text": " You know, I could try to use a for loop",
        "tokens": [
          51014,
          509,
          458,
          11,
          286,
          727,
          853,
          281,
          764,
          257,
          337,
          6367,
          51114
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7709.44,
        "id": 2308,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7707.44,
        "temperature": 0,
        "text": " And maybe run a for loop, a nested for loop",
        "tokens": [
          51114,
          400,
          1310,
          1190,
          257,
          337,
          6367,
          11,
          257,
          15646,
          292,
          337,
          6367,
          51214
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7711.44,
        "id": 2309,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7709.44,
        "temperature": 0,
        "text": " To do it multiple generations",
        "tokens": [
          51214,
          1407,
          360,
          309,
          3866,
          10593,
          51314
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7713.44,
        "id": 2310,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7711.44,
        "temperature": 0,
        "text": " But really, this type of system",
        "tokens": [
          51314,
          583,
          534,
          11,
          341,
          2010,
          295,
          1185,
          51414
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7715.44,
        "id": 2311,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7713.44,
        "temperature": 0,
        "text": " I don't really have anything in here that's nested",
        "tokens": [
          51414,
          286,
          500,
          380,
          534,
          362,
          1340,
          294,
          510,
          300,
          311,
          15646,
          292,
          51514
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7718.44,
        "id": 2312,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7715.44,
        "temperature": 0,
        "text": " But if I add some nested stuff to it",
        "tokens": [
          51514,
          583,
          498,
          286,
          909,
          512,
          15646,
          292,
          1507,
          281,
          309,
          51664
        ]
      },
      {
        "avg_logprob": -0.16132476750542135,
        "compression_ratio": 1.7490494296577948,
        "end": 7720.44,
        "id": 2313,
        "no_speech_prob": 0.07807428389787674,
        "seek": 769244,
        "start": 7718.44,
        "temperature": 0,
        "text": " I'm going to need a recursive algorithm",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          643,
          257,
          20560,
          488,
          9284,
          51764
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7723.44,
        "id": 2314,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7720.44,
        "temperature": 0,
        "text": " So I would love to refer you to some videos I have",
        "tokens": [
          50364,
          407,
          286,
          576,
          959,
          281,
          2864,
          291,
          281,
          512,
          2145,
          286,
          362,
          50514
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7725.44,
        "id": 2315,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7723.44,
        "temperature": 0,
        "text": " About the concept of recursion",
        "tokens": [
          50514,
          7769,
          264,
          3410,
          295,
          20560,
          313,
          50614
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7727.44,
        "id": 2316,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7725.44,
        "temperature": 0,
        "text": " Which typically in other videos I've made",
        "tokens": [
          50614,
          3013,
          5850,
          294,
          661,
          2145,
          286,
          600,
          1027,
          50714
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7729.44,
        "id": 2317,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7727.44,
        "temperature": 0,
        "text": " I've used for graphics drawing",
        "tokens": [
          50714,
          286,
          600,
          1143,
          337,
          11837,
          6316,
          50814
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7731.44,
        "id": 2318,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7729.44,
        "temperature": 0,
        "text": " I could make a recursive tree structure",
        "tokens": [
          50814,
          286,
          727,
          652,
          257,
          20560,
          488,
          4230,
          3877,
          50914
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7733.44,
        "id": 2319,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7731.44,
        "temperature": 0,
        "text": " And a self-similar shape",
        "tokens": [
          50914,
          400,
          257,
          2698,
          12,
          30937,
          2202,
          3909,
          51014
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7735.44,
        "id": 2320,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7733.44,
        "temperature": 0,
        "text": " A recursive something is",
        "tokens": [
          51014,
          316,
          20560,
          488,
          746,
          307,
          51114
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7738.44,
        "id": 2321,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7735.44,
        "temperature": 0,
        "text": " A function that's defined recursively",
        "tokens": [
          51114,
          316,
          2445,
          300,
          311,
          7642,
          20560,
          3413,
          51264
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7740.44,
        "id": 2322,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7738.44,
        "temperature": 0,
        "text": " Is a function that calls itself",
        "tokens": [
          51264,
          1119,
          257,
          2445,
          300,
          5498,
          2564,
          51364
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7743.44,
        "id": 2323,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7740.44,
        "temperature": 0,
        "text": " So I'm going to come back to that",
        "tokens": [
          51364,
          407,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          300,
          51514
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7745.44,
        "id": 2324,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7743.44,
        "temperature": 0,
        "text": " But let me start writing this code",
        "tokens": [
          51514,
          583,
          718,
          385,
          722,
          3579,
          341,
          3089,
          51614
        ]
      },
      {
        "avg_logprob": -0.17723518762833032,
        "compression_ratio": 1.6732283464566928,
        "end": 7747.44,
        "id": 2325,
        "no_speech_prob": 0.042719800025224686,
        "seek": 772044,
        "start": 7745.44,
        "temperature": 0,
        "text": " Is this a coding challenge? I think it is",
        "tokens": [
          51614,
          1119,
          341,
          257,
          17720,
          3430,
          30,
          286,
          519,
          309,
          307,
          51714
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7750.44,
        "id": 2326,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7748.44,
        "temperature": 0,
        "text": " Okay, so I have an expansion",
        "tokens": [
          50414,
          1033,
          11,
          370,
          286,
          362,
          364,
          11260,
          50514
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7752.44,
        "id": 2327,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7750.44,
        "temperature": 0,
        "text": " And what I want to say is",
        "tokens": [
          50514,
          400,
          437,
          286,
          528,
          281,
          584,
          307,
          50614
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7755.44,
        "id": 2328,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7752.44,
        "temperature": 0,
        "text": " I want to say expand start expansion",
        "tokens": [
          50614,
          286,
          528,
          281,
          584,
          5268,
          722,
          11260,
          50764
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7757.44,
        "id": 2329,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7755.44,
        "temperature": 0,
        "text": " Because what I want to do is",
        "tokens": [
          50764,
          1436,
          437,
          286,
          528,
          281,
          360,
          307,
          50864
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7759.44,
        "id": 2330,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7757.44,
        "temperature": 0,
        "text": " I want to call a function",
        "tokens": [
          50864,
          286,
          528,
          281,
          818,
          257,
          2445,
          50964
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7761.44,
        "id": 2331,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7759.44,
        "temperature": 0,
        "text": " And I'm going to say here",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          584,
          510,
          51064
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7763.44,
        "id": 2332,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7761.44,
        "temperature": 0,
        "text": " Result equals that",
        "tokens": [
          51064,
          5015,
          723,
          6915,
          300,
          51164
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7766.44,
        "id": 2333,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7763.44,
        "temperature": 0,
        "text": " So I want to have a result",
        "tokens": [
          51164,
          407,
          286,
          528,
          281,
          362,
          257,
          1874,
          51314
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7769.44,
        "id": 2334,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7766.44,
        "temperature": 0,
        "text": " That comes from starting with this",
        "tokens": [
          51314,
          663,
          1487,
          490,
          2891,
          365,
          341,
          51464
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7771.44,
        "id": 2335,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7769.44,
        "temperature": 0,
        "text": " And I want to pass it an empty array",
        "tokens": [
          51464,
          400,
          286,
          528,
          281,
          1320,
          309,
          364,
          6707,
          10225,
          51564
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7773.44,
        "id": 2336,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7771.44,
        "temperature": 0,
        "text": " Because then I want that array to be filled",
        "tokens": [
          51564,
          1436,
          550,
          286,
          528,
          300,
          10225,
          281,
          312,
          6412,
          51664
        ]
      },
      {
        "avg_logprob": -0.172497490856135,
        "compression_ratio": 1.8350515463917525,
        "end": 7775.44,
        "id": 2337,
        "no_speech_prob": 0.033084578812122345,
        "seek": 774744,
        "start": 7773.44,
        "temperature": 0,
        "text": " As it's going through",
        "tokens": [
          51664,
          1018,
          309,
          311,
          516,
          807,
          51764
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7778.44,
        "id": 2338,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7775.44,
        "temperature": 0,
        "text": " And expanding based on the rules",
        "tokens": [
          50364,
          400,
          14702,
          2361,
          322,
          264,
          4474,
          50514
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7779.44,
        "id": 2339,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7778.44,
        "temperature": 0,
        "text": " So to speak",
        "tokens": [
          50514,
          407,
          281,
          1710,
          50564
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7781.44,
        "id": 2340,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7779.44,
        "temperature": 0,
        "text": " So I'm going to write this function up here",
        "tokens": [
          50564,
          407,
          286,
          478,
          516,
          281,
          2464,
          341,
          2445,
          493,
          510,
          50664
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7783.44,
        "id": 2341,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7781.44,
        "temperature": 0,
        "text": " And it gets",
        "tokens": [
          50664,
          400,
          309,
          2170,
          50764
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7785.44,
        "id": 2342,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7783.44,
        "temperature": 0,
        "text": " I don't know what to call this",
        "tokens": [
          50764,
          286,
          500,
          380,
          458,
          437,
          281,
          818,
          341,
          50864
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7787.44,
        "id": 2343,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7785.44,
        "temperature": 0,
        "text": " An element, a phrase",
        "tokens": [
          50864,
          1107,
          4478,
          11,
          257,
          9535,
          50964
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7789.44,
        "id": 2344,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7787.44,
        "temperature": 0,
        "text": " I'm just going to call it",
        "tokens": [
          50964,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          51064
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7791.44,
        "id": 2345,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7789.44,
        "temperature": 0,
        "text": " A start so to speak",
        "tokens": [
          51064,
          316,
          722,
          370,
          281,
          1710,
          51164
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7793.44,
        "id": 2346,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7791.44,
        "temperature": 0,
        "text": " And I'm going to call this expansion",
        "tokens": [
          51164,
          400,
          286,
          478,
          516,
          281,
          818,
          341,
          11260,
          51264
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7794.44,
        "id": 2347,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7793.44,
        "temperature": 0,
        "text": " Which is kind of a little awkward",
        "tokens": [
          51264,
          3013,
          307,
          733,
          295,
          257,
          707,
          11411,
          51314
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7795.44,
        "id": 2348,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7794.44,
        "temperature": 0,
        "text": " That I'm using the same variable names",
        "tokens": [
          51314,
          663,
          286,
          478,
          1228,
          264,
          912,
          7006,
          5288,
          51364
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7796.44,
        "id": 2349,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7795.44,
        "temperature": 0,
        "text": " But I'm going to do that anyway",
        "tokens": [
          51364,
          583,
          286,
          478,
          516,
          281,
          360,
          300,
          4033,
          51414
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7799.44,
        "id": 2350,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7796.44,
        "temperature": 0,
        "text": " Okay, so what do I do here?",
        "tokens": [
          51414,
          1033,
          11,
          370,
          437,
          360,
          286,
          360,
          510,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7801.44,
        "id": 2351,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7799.44,
        "temperature": 0,
        "text": " Well first I need to determine",
        "tokens": [
          51564,
          1042,
          700,
          286,
          643,
          281,
          6997,
          51664
        ]
      },
      {
        "avg_logprob": -0.16525989590269147,
        "compression_ratio": 1.7075098814229248,
        "end": 7803.44,
        "id": 2352,
        "no_speech_prob": 0.23933038115501404,
        "seek": 777544,
        "start": 7801.44,
        "temperature": 0,
        "text": " Is start something in the rules?",
        "tokens": [
          51664,
          1119,
          722,
          746,
          294,
          264,
          4474,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7805.44,
        "id": 2353,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7803.44,
        "temperature": 0,
        "text": " Is it terminal or not terminal?",
        "tokens": [
          50364,
          1119,
          309,
          14709,
          420,
          406,
          14709,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7809.44,
        "id": 2354,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7805.44,
        "temperature": 0,
        "text": " If rules start, right?",
        "tokens": [
          50464,
          759,
          4474,
          722,
          11,
          558,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7810.44,
        "id": 2355,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7809.44,
        "temperature": 0,
        "text": " It doesn't exist",
        "tokens": [
          50664,
          467,
          1177,
          380,
          2514,
          50714
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7812.44,
        "id": 2356,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7810.44,
        "temperature": 0,
        "text": " Is it something in the rules?",
        "tokens": [
          50714,
          1119,
          309,
          746,
          294,
          264,
          4474,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7814.44,
        "id": 2357,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7812.44,
        "temperature": 0,
        "text": " If it is, what do I need to do?",
        "tokens": [
          50814,
          759,
          309,
          307,
          11,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7816.44,
        "id": 2358,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7814.44,
        "temperature": 0,
        "text": " Well I need to expand",
        "tokens": [
          50914,
          1042,
          286,
          643,
          281,
          5268,
          51014
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7819.44,
        "id": 2359,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7816.44,
        "temperature": 0,
        "text": " Whatever, I need to expand",
        "tokens": [
          51014,
          8541,
          11,
          286,
          643,
          281,
          5268,
          51164
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7821.44,
        "id": 2360,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7819.44,
        "temperature": 0,
        "text": " One of the possibilities that it might pick",
        "tokens": [
          51164,
          1485,
          295,
          264,
          12178,
          300,
          309,
          1062,
          1888,
          51264
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7823.44,
        "id": 2361,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7821.44,
        "temperature": 0,
        "text": " So first what I need to do is",
        "tokens": [
          51264,
          407,
          700,
          437,
          286,
          643,
          281,
          360,
          307,
          51364
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7824.44,
        "id": 2362,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7823.44,
        "temperature": 0,
        "text": " I need to pick something",
        "tokens": [
          51364,
          286,
          643,
          281,
          1888,
          746,
          51414
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7826.44,
        "id": 2363,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7824.44,
        "temperature": 0,
        "text": " And one of the lovely things I can do",
        "tokens": [
          51414,
          400,
          472,
          295,
          264,
          7496,
          721,
          286,
          393,
          360,
          51514
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7829.44,
        "id": 2364,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7826.44,
        "temperature": 0,
        "text": " In p5 is I can pass an array to",
        "tokens": [
          51514,
          682,
          280,
          20,
          307,
          286,
          393,
          1320,
          364,
          10225,
          281,
          51664
        ]
      },
      {
        "avg_logprob": -0.18873302753155047,
        "compression_ratio": 1.7740384615384615,
        "end": 7830.44,
        "id": 2365,
        "no_speech_prob": 0.03789100795984268,
        "seek": 780344,
        "start": 7829.44,
        "temperature": 0,
        "text": " A random function",
        "tokens": [
          51664,
          316,
          4974,
          2445,
          51714
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7834.44,
        "id": 2366,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7830.44,
        "temperature": 0,
        "text": " So if I say give me a random value",
        "tokens": [
          50364,
          407,
          498,
          286,
          584,
          976,
          385,
          257,
          4974,
          2158,
          50564
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7835.44,
        "id": 2367,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7834.44,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50564,
          1779,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7837.44,
        "id": 2368,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7835.44,
        "temperature": 0,
        "text": " That's going to be picking",
        "tokens": [
          50614,
          663,
          311,
          516,
          281,
          312,
          8867,
          50714
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7838.44,
        "id": 2369,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7837.44,
        "temperature": 0,
        "text": " If it's getting n",
        "tokens": [
          50714,
          759,
          309,
          311,
          1242,
          297,
          50764
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7840.44,
        "id": 2370,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7838.44,
        "temperature": 0,
        "text": " It's going to pick one of cat or dog",
        "tokens": [
          50764,
          467,
          311,
          516,
          281,
          1888,
          472,
          295,
          3857,
          420,
          3000,
          50864
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7842.44,
        "id": 2371,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7840.44,
        "temperature": 0,
        "text": " And then I need to expand that",
        "tokens": [
          50864,
          400,
          550,
          286,
          643,
          281,
          5268,
          300,
          50964
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7844.44,
        "id": 2372,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7842.44,
        "temperature": 0,
        "text": " So then I need to expand",
        "tokens": [
          50964,
          407,
          550,
          286,
          643,
          281,
          5268,
          51064
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7847.44,
        "id": 2373,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7844.44,
        "temperature": 0,
        "text": " What it picked",
        "tokens": [
          51064,
          708,
          309,
          6183,
          51214
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7850.44,
        "id": 2374,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7847.44,
        "temperature": 0,
        "text": " And then I need to continue to pass this expansion array",
        "tokens": [
          51214,
          400,
          550,
          286,
          643,
          281,
          2354,
          281,
          1320,
          341,
          11260,
          10225,
          51364
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7853.44,
        "id": 2375,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7850.44,
        "temperature": 0,
        "text": " Because this expansion array is just getting filled recursively",
        "tokens": [
          51364,
          1436,
          341,
          11260,
          10225,
          307,
          445,
          1242,
          6412,
          20560,
          3413,
          51514
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7855.44,
        "id": 2376,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7853.44,
        "temperature": 0,
        "text": " As this kind of function unfurls",
        "tokens": [
          51514,
          1018,
          341,
          733,
          295,
          2445,
          3971,
          374,
          11784,
          51614
        ]
      },
      {
        "avg_logprob": -0.2204201328861821,
        "compression_ratio": 1.7850467289719627,
        "end": 7858.44,
        "id": 2377,
        "no_speech_prob": 0.07476697117090225,
        "seek": 783044,
        "start": 7855.44,
        "temperature": 0,
        "text": " So I would have to like come back",
        "tokens": [
          51614,
          407,
          286,
          576,
          362,
          281,
          411,
          808,
          646,
          51764
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7860.44,
        "id": 2378,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7858.44,
        "temperature": 0,
        "text": " And this is going to be",
        "tokens": [
          50364,
          400,
          341,
          307,
          516,
          281,
          312,
          50464
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7861.44,
        "id": 2379,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7860.44,
        "temperature": 0,
        "text": " I can tell already",
        "tokens": [
          50464,
          286,
          393,
          980,
          1217,
          50514
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7862.44,
        "id": 2380,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7861.44,
        "temperature": 0,
        "text": " This is going to be",
        "tokens": [
          50514,
          639,
          307,
          516,
          281,
          312,
          50564
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7864.44,
        "id": 2381,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7862.44,
        "temperature": 0,
        "text": " Not the kind of video that you need to watch over and over again",
        "tokens": [
          50564,
          1726,
          264,
          733,
          295,
          960,
          300,
          291,
          643,
          281,
          1159,
          670,
          293,
          670,
          797,
          50664
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7865.44,
        "id": 2382,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7864.44,
        "temperature": 0,
        "text": " But this is going to be the kind of thing",
        "tokens": [
          50664,
          583,
          341,
          307,
          516,
          281,
          312,
          264,
          733,
          295,
          551,
          50714
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7866.44,
        "id": 2383,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7865.44,
        "temperature": 0,
        "text": " That you're going to want to sort of like",
        "tokens": [
          50714,
          663,
          291,
          434,
          516,
          281,
          528,
          281,
          1333,
          295,
          411,
          50764
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7868.44,
        "id": 2384,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7866.44,
        "temperature": 0,
        "text": " Hand write this code and play act it out",
        "tokens": [
          50764,
          8854,
          2464,
          341,
          3089,
          293,
          862,
          605,
          309,
          484,
          50864
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7870.44,
        "id": 2385,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7868.44,
        "temperature": 0,
        "text": " Or something with a friend",
        "tokens": [
          50864,
          1610,
          746,
          365,
          257,
          1277,
          50964
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7872.44,
        "id": 2386,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7870.44,
        "temperature": 0,
        "text": " To sort of figure out what's going on here",
        "tokens": [
          50964,
          1407,
          1333,
          295,
          2573,
          484,
          437,
          311,
          516,
          322,
          510,
          51064
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7874.44,
        "id": 2387,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7872.44,
        "temperature": 0,
        "text": " Now what if it's not",
        "tokens": [
          51064,
          823,
          437,
          498,
          309,
          311,
          406,
          51164
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7875.44,
        "id": 2388,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7874.44,
        "temperature": 0,
        "text": " And something that expands",
        "tokens": [
          51164,
          400,
          746,
          300,
          33706,
          51214
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7878.44,
        "id": 2389,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7875.44,
        "temperature": 0,
        "text": " Then what do I want to do?",
        "tokens": [
          51214,
          1396,
          437,
          360,
          286,
          528,
          281,
          360,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.22356494392935686,
        "compression_ratio": 1.8608695652173912,
        "end": 7879.44,
        "id": 2390,
        "no_speech_prob": 0.2120353877544403,
        "seek": 785844,
        "start": 7878.44,
        "temperature": 0,
        "text": " I want to add it to that array",
        "tokens": [
          51364,
          286,
          528,
          281,
          909,
          309,
          281,
          300,
          10225,
          51414
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7883.44,
        "id": 2391,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7880.44,
        "temperature": 0,
        "text": " Expand, push, what I picked",
        "tokens": [
          50414,
          21391,
          474,
          11,
          2944,
          11,
          437,
          286,
          6183,
          50564
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7886.44,
        "id": 2392,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7883.44,
        "temperature": 0,
        "text": " So the idea is that",
        "tokens": [
          50564,
          407,
          264,
          1558,
          307,
          300,
          50714
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7888.44,
        "id": 2393,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7886.44,
        "temperature": 0,
        "text": " I want this to keep going",
        "tokens": [
          50714,
          286,
          528,
          341,
          281,
          1066,
          516,
          50814
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7890.44,
        "id": 2394,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7888.44,
        "temperature": 0,
        "text": " And we can think about what the tree",
        "tokens": [
          50814,
          400,
          321,
          393,
          519,
          466,
          437,
          264,
          4230,
          50914
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7892.44,
        "id": 2395,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7890.44,
        "temperature": 0,
        "text": " I wonder if there's a way I can diagram this",
        "tokens": [
          50914,
          286,
          2441,
          498,
          456,
          311,
          257,
          636,
          286,
          393,
          10686,
          341,
          51014
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7893.44,
        "id": 2396,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7892.44,
        "temperature": 0,
        "text": " To help you",
        "tokens": [
          51014,
          1407,
          854,
          291,
          51064
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7895.44,
        "id": 2397,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7893.44,
        "temperature": 0,
        "text": " First of all let's just see if this works",
        "tokens": [
          51064,
          2386,
          295,
          439,
          718,
          311,
          445,
          536,
          498,
          341,
          1985,
          51164
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7897.44,
        "id": 2398,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7895.44,
        "temperature": 0,
        "text": " And then I'm going to",
        "tokens": [
          51164,
          400,
          550,
          286,
          478,
          516,
          281,
          51264
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7899.44,
        "id": 2399,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7897.44,
        "temperature": 0,
        "text": " What I want to do is I'm going to say result",
        "tokens": [
          51264,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          1874,
          51364
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7900.44,
        "id": 2400,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7899.44,
        "temperature": 0,
        "text": " Join with",
        "tokens": [
          51364,
          19642,
          365,
          51414
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7901.44,
        "id": 2401,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7900.44,
        "temperature": 0,
        "text": " It's a",
        "tokens": [
          51414,
          467,
          311,
          257,
          51464
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7902.44,
        "id": 2402,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7901.44,
        "temperature": 0,
        "text": " Let's console this",
        "tokens": [
          51464,
          961,
          311,
          11076,
          341,
          51514
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7903.44,
        "id": 2403,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7902.44,
        "temperature": 0,
        "text": " And then I'm going to",
        "tokens": [
          51514,
          400,
          550,
          286,
          478,
          516,
          281,
          51564
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7904.44,
        "id": 2404,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7903.44,
        "temperature": 0,
        "text": " I'm going to say",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          584,
          51614
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7905.44,
        "id": 2405,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7904.44,
        "temperature": 0,
        "text": " I'm going to say",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          584,
          51664
        ]
      },
      {
        "avg_logprob": -0.39148732235557154,
        "compression_ratio": 1.8599033816425121,
        "end": 7906.44,
        "id": 2406,
        "no_speech_prob": 0.43391790986061096,
        "seek": 787944,
        "start": 7905.44,
        "temperature": 0,
        "text": " I'm going to say",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          584,
          51714
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7907.44,
        "id": 2407,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7906.44,
        "temperature": 0,
        "text": " Join with",
        "tokens": [
          50364,
          19642,
          365,
          50414
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7908.44,
        "id": 2408,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7907.44,
        "temperature": 0,
        "text": " It's a",
        "tokens": [
          50414,
          467,
          311,
          257,
          50464
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7910.44,
        "id": 2409,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7908.44,
        "temperature": 0,
        "text": " Let's console log the result",
        "tokens": [
          50464,
          961,
          311,
          11076,
          3565,
          264,
          1874,
          50564
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7912.44,
        "id": 2410,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7910.44,
        "temperature": 0,
        "text": " It's going to be an array",
        "tokens": [
          50564,
          467,
          311,
          516,
          281,
          312,
          364,
          10225,
          50664
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7913.44,
        "id": 2411,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7912.44,
        "temperature": 0,
        "text": " Let's see if this even works",
        "tokens": [
          50664,
          961,
          311,
          536,
          498,
          341,
          754,
          1985,
          50714
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7914.44,
        "id": 2412,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7913.44,
        "temperature": 0,
        "text": " Because I might have made a mistake",
        "tokens": [
          50714,
          1436,
          286,
          1062,
          362,
          1027,
          257,
          6146,
          50764
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7915.44,
        "id": 2413,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7914.44,
        "temperature": 0,
        "text": " Undefined",
        "tokens": [
          50764,
          2719,
          5666,
          2001,
          50814
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7916.44,
        "id": 2414,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7915.44,
        "temperature": 0,
        "text": " Hey undefined",
        "tokens": [
          50814,
          1911,
          674,
          5666,
          2001,
          50864
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7917.44,
        "id": 2415,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7916.44,
        "temperature": 0,
        "text": " There we go",
        "tokens": [
          50864,
          821,
          321,
          352,
          50914
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7918.44,
        "id": 2416,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7917.44,
        "temperature": 0,
        "text": " Ta-da",
        "tokens": [
          50914,
          6551,
          12,
          2675,
          50964
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7922.44,
        "id": 2417,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7920.44,
        "temperature": 0,
        "text": " Alright so what went wrong?",
        "tokens": [
          51064,
          2798,
          370,
          437,
          1437,
          2085,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7924.44,
        "id": 2418,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7922.44,
        "temperature": 0,
        "text": " Looking at the chat",
        "tokens": [
          51164,
          11053,
          412,
          264,
          5081,
          51264
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7925.44,
        "id": 2419,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7924.44,
        "temperature": 0,
        "text": " Rules tart",
        "tokens": [
          51264,
          38897,
          22491,
          51314
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7926.44,
        "id": 2420,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7925.44,
        "temperature": 0,
        "text": " No I thought",
        "tokens": [
          51314,
          883,
          286,
          1194,
          51364
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7928.44,
        "id": 2421,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7926.44,
        "temperature": 0,
        "text": " Someone was saying I made a typo there",
        "tokens": [
          51364,
          8734,
          390,
          1566,
          286,
          1027,
          257,
          2125,
          78,
          456,
          51464
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7931.44,
        "id": 2422,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7928.44,
        "temperature": 0,
        "text": " So let's see if we can",
        "tokens": [
          51464,
          407,
          718,
          311,
          536,
          498,
          321,
          393,
          51614
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7933.44,
        "id": 2423,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7931.44,
        "temperature": 0,
        "text": " Figure out what's going on",
        "tokens": [
          51614,
          43225,
          484,
          437,
          311,
          516,
          322,
          51714
        ]
      },
      {
        "avg_logprob": -0.2121231885460334,
        "compression_ratio": 1.5746606334841629,
        "end": 7935.44,
        "id": 2424,
        "no_speech_prob": 0.6333053708076477,
        "seek": 790644,
        "start": 7933.44,
        "temperature": 0,
        "text": " So let's",
        "tokens": [
          51714,
          407,
          718,
          311,
          51814
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7937.44,
        "id": 2425,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7935.44,
        "temperature": 0,
        "text": " Console.log pick",
        "tokens": [
          50364,
          44152,
          13,
          4987,
          1888,
          50464
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7939.44,
        "id": 2426,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7937.44,
        "temperature": 0,
        "text": " See if that's even working",
        "tokens": [
          50464,
          3008,
          498,
          300,
          311,
          754,
          1364,
          50564
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7941.44,
        "id": 2427,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7939.44,
        "temperature": 0,
        "text": " Ah so that worked",
        "tokens": [
          50564,
          2438,
          370,
          300,
          2732,
          50664
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7942.44,
        "id": 2428,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7941.44,
        "temperature": 0,
        "text": " We got the",
        "tokens": [
          50664,
          492,
          658,
          264,
          50714
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7944.44,
        "id": 2429,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7942.44,
        "temperature": 0,
        "text": " I don't know why I'm zoomed out",
        "tokens": [
          50714,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          8863,
          292,
          484,
          50814
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7945.44,
        "id": 2430,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7944.44,
        "temperature": 0,
        "text": " We got the nv",
        "tokens": [
          50814,
          492,
          658,
          264,
          297,
          85,
          50864
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7946.44,
        "id": 2431,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7945.44,
        "temperature": 0,
        "text": " Sketch line 10",
        "tokens": [
          50864,
          49245,
          1622,
          1266,
          50914
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7947.44,
        "id": 2432,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7946.44,
        "temperature": 0,
        "text": " So that worked",
        "tokens": [
          50914,
          407,
          300,
          2732,
          50964
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7949.44,
        "id": 2433,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7947.44,
        "temperature": 0,
        "text": " And then",
        "tokens": [
          50964,
          400,
          550,
          51064
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7950.44,
        "id": 2434,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7949.44,
        "temperature": 0,
        "text": " Pick",
        "tokens": [
          51064,
          14129,
          51114
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7951.44,
        "id": 2435,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7950.44,
        "temperature": 0,
        "text": " Oh",
        "tokens": [
          51114,
          876,
          51164
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7953.44,
        "id": 2436,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7951.44,
        "temperature": 0,
        "text": " Oh oh oh oh oh",
        "tokens": [
          51164,
          876,
          1954,
          1954,
          1954,
          1954,
          51264
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7956.44,
        "id": 2437,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7953.44,
        "temperature": 0,
        "text": " So here's something that's kind of important",
        "tokens": [
          51264,
          407,
          510,
          311,
          746,
          300,
          311,
          733,
          295,
          1021,
          51414
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7959.44,
        "id": 2438,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7956.44,
        "temperature": 0,
        "text": " Right",
        "tokens": [
          51414,
          1779,
          51564
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7960.44,
        "id": 2439,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7959.44,
        "temperature": 0,
        "text": " This would have",
        "tokens": [
          51564,
          639,
          576,
          362,
          51614
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7961.44,
        "id": 2440,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7960.44,
        "temperature": 0,
        "text": " This would work",
        "tokens": [
          51614,
          639,
          576,
          589,
          51664
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7963.44,
        "id": 2441,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7961.44,
        "temperature": 0,
        "text": " I haven't been paying attention",
        "tokens": [
          51664,
          286,
          2378,
          380,
          668,
          6229,
          3202,
          51764
        ]
      },
      {
        "avg_logprob": -0.22558500148631908,
        "compression_ratio": 1.582010582010582,
        "end": 7964.44,
        "id": 2442,
        "no_speech_prob": 0.07158798724412918,
        "seek": 793544,
        "start": 7963.44,
        "temperature": 0,
        "text": " But",
        "tokens": [
          51764,
          583,
          51814
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7965.44,
        "id": 2443,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7964.44,
        "temperature": 0,
        "text": " These",
        "tokens": [
          50364,
          1981,
          50414
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7967.44,
        "id": 2444,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7965.44,
        "temperature": 0,
        "text": " These are three different",
        "tokens": [
          50414,
          1981,
          366,
          1045,
          819,
          50514
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7969.44,
        "id": 2445,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7967.44,
        "temperature": 0,
        "text": " Kind of elements that I need to expand",
        "tokens": [
          50514,
          9242,
          295,
          4959,
          300,
          286,
          643,
          281,
          5268,
          50614
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7972.44,
        "id": 2446,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7969.44,
        "temperature": 0,
        "text": " So I hate to do this to you",
        "tokens": [
          50614,
          407,
          286,
          4700,
          281,
          360,
          341,
          281,
          291,
          50764
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7974.44,
        "id": 2447,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7972.44,
        "temperature": 0,
        "text": " But I really kind of feel like",
        "tokens": [
          50764,
          583,
          286,
          534,
          733,
          295,
          841,
          411,
          50864
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7976.44,
        "id": 2448,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7974.44,
        "temperature": 0,
        "text": " What this should be",
        "tokens": [
          50864,
          708,
          341,
          820,
          312,
          50964
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7982.44,
        "id": 2449,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7976.44,
        "temperature": 0,
        "text": " Is an array inside the array",
        "tokens": [
          50964,
          1119,
          364,
          10225,
          1854,
          264,
          10225,
          51264
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7985.44,
        "id": 2450,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7982.44,
        "temperature": 0,
        "text": " I could start to use split and stuff",
        "tokens": [
          51264,
          286,
          727,
          722,
          281,
          764,
          7472,
          293,
          1507,
          51414
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7988.44,
        "id": 2451,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7985.44,
        "temperature": 0,
        "text": " But I want to",
        "tokens": [
          51414,
          583,
          286,
          528,
          281,
          51564
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7991.44,
        "id": 2452,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7988.44,
        "temperature": 0,
        "text": " I want to think about a way that might make sense",
        "tokens": [
          51564,
          286,
          528,
          281,
          519,
          466,
          257,
          636,
          300,
          1062,
          652,
          2020,
          51714
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7992.44,
        "id": 2453,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7991.44,
        "temperature": 0,
        "text": " And I've missed something here",
        "tokens": [
          51714,
          400,
          286,
          600,
          6721,
          746,
          510,
          51764
        ]
      },
      {
        "avg_logprob": -0.1722729422829368,
        "compression_ratio": 1.5980861244019138,
        "end": 7993.44,
        "id": 2454,
        "no_speech_prob": 0.0015730973100289702,
        "seek": 796444,
        "start": 7992.44,
        "temperature": 0,
        "text": " Oh I need a quote there",
        "tokens": [
          51764,
          876,
          286,
          643,
          257,
          6513,
          456,
          51814
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 7995.44,
        "id": 2455,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 7993.44,
        "temperature": 0,
        "text": " Let me just make this change",
        "tokens": [
          50364,
          961,
          385,
          445,
          652,
          341,
          1319,
          50464
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8000.44,
        "id": 2456,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 7995.44,
        "temperature": 0,
        "text": " And then we'll kind of discuss it",
        "tokens": [
          50464,
          400,
          550,
          321,
          603,
          733,
          295,
          2248,
          309,
          50714
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8002.44,
        "id": 2457,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8000.44,
        "temperature": 0,
        "text": " This is my own strange way of encoding this",
        "tokens": [
          50714,
          639,
          307,
          452,
          1065,
          5861,
          636,
          295,
          43430,
          341,
          50814
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8005.44,
        "id": 2458,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8002.44,
        "temperature": 0,
        "text": " I'm sure any of you watching will come up with a better way",
        "tokens": [
          50814,
          286,
          478,
          988,
          604,
          295,
          291,
          1976,
          486,
          808,
          493,
          365,
          257,
          1101,
          636,
          50964
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8007.44,
        "id": 2459,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8005.44,
        "temperature": 0,
        "text": " And you will share it with me in the comments",
        "tokens": [
          50964,
          400,
          291,
          486,
          2073,
          309,
          365,
          385,
          294,
          264,
          3053,
          51064
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8009.44,
        "id": 2460,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8007.44,
        "temperature": 0,
        "text": " And I will feel embarrassed",
        "tokens": [
          51064,
          400,
          286,
          486,
          841,
          16843,
          51164
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8010.44,
        "id": 2461,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8009.44,
        "temperature": 0,
        "text": " That's part of programming",
        "tokens": [
          51164,
          663,
          311,
          644,
          295,
          9410,
          51214
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8011.44,
        "id": 2462,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8010.44,
        "temperature": 0,
        "text": " Feeling embarrassed",
        "tokens": [
          51214,
          29945,
          16843,
          51264
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8012.44,
        "id": 2463,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8011.44,
        "temperature": 0,
        "text": " Although you shouldn't feel embarrassed",
        "tokens": [
          51264,
          5780,
          291,
          4659,
          380,
          841,
          16843,
          51314
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8013.44,
        "id": 2464,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8012.44,
        "temperature": 0,
        "text": " It's okay if I",
        "tokens": [
          51314,
          467,
          311,
          1392,
          498,
          286,
          51364
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8014.44,
        "id": 2465,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8013.44,
        "temperature": 0,
        "text": " I'm going to feel embarrassed",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          841,
          16843,
          51414
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8015.44,
        "id": 2466,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8014.44,
        "temperature": 0,
        "text": " Because that's",
        "tokens": [
          51414,
          1436,
          300,
          311,
          51464
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8017.44,
        "id": 2467,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8015.44,
        "temperature": 0,
        "text": " I generally operate in life by feeling embarrassed",
        "tokens": [
          51464,
          286,
          5101,
          9651,
          294,
          993,
          538,
          2633,
          16843,
          51564
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8019.44,
        "id": 2468,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8017.44,
        "temperature": 0,
        "text": " But coding is about figuring stuff out",
        "tokens": [
          51564,
          583,
          17720,
          307,
          466,
          15213,
          1507,
          484,
          51664
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8020.44,
        "id": 2469,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8019.44,
        "temperature": 0,
        "text": " And playing around",
        "tokens": [
          51664,
          400,
          2433,
          926,
          51714
        ]
      },
      {
        "avg_logprob": -0.17051427260689114,
        "compression_ratio": 1.831615120274914,
        "end": 8022.44,
        "id": 2470,
        "no_speech_prob": 0.059201717376708984,
        "seek": 799344,
        "start": 8020.44,
        "temperature": 0,
        "text": " And iterating to refine things later",
        "tokens": [
          51714,
          400,
          17138,
          990,
          281,
          33906,
          721,
          1780,
          51814
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8023.44,
        "id": 2471,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8022.44,
        "temperature": 0,
        "text": " So the reason why I'm doing this",
        "tokens": [
          50364,
          407,
          264,
          1778,
          983,
          286,
          478,
          884,
          341,
          50414
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8024.44,
        "id": 2472,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8023.44,
        "temperature": 0,
        "text": " Woo! Look at that",
        "tokens": [
          50414,
          10468,
          0,
          2053,
          412,
          300,
          50464
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8026.44,
        "id": 2473,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8024.44,
        "temperature": 0,
        "text": " It auto formatted it for me",
        "tokens": [
          50464,
          467,
          8399,
          1254,
          32509,
          309,
          337,
          385,
          50564
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8028.44,
        "id": 2474,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8026.44,
        "temperature": 0,
        "text": " The reason why I'm doing this is because",
        "tokens": [
          50564,
          440,
          1778,
          983,
          286,
          478,
          884,
          341,
          307,
          570,
          50664
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8031.44,
        "id": 2475,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8028.44,
        "temperature": 0,
        "text": " What I want is to have a bunch of options",
        "tokens": [
          50664,
          708,
          286,
          528,
          307,
          281,
          362,
          257,
          3840,
          295,
          3956,
          50814
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8033.44,
        "id": 2476,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8031.44,
        "temperature": 0,
        "text": " But one of the options",
        "tokens": [
          50814,
          583,
          472,
          295,
          264,
          3956,
          50914
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8035.44,
        "id": 2477,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8033.44,
        "temperature": 0,
        "text": " This is not three possible options",
        "tokens": [
          50914,
          639,
          307,
          406,
          1045,
          1944,
          3956,
          51014
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8039.44,
        "id": 2478,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8035.44,
        "temperature": 0,
        "text": " This is expanding S into three tokens so to speak",
        "tokens": [
          51014,
          639,
          307,
          14702,
          318,
          666,
          1045,
          22667,
          370,
          281,
          1710,
          51214
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8043.44,
        "id": 2479,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8039.44,
        "temperature": 0,
        "text": " This is expanding N into one token",
        "tokens": [
          51214,
          639,
          307,
          14702,
          426,
          666,
          472,
          14862,
          51414
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8045.44,
        "id": 2480,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8043.44,
        "temperature": 0,
        "text": " Or this other one token",
        "tokens": [
          51414,
          1610,
          341,
          661,
          472,
          14862,
          51514
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8047.44,
        "id": 2481,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8045.44,
        "temperature": 0,
        "text": " So I could say this or something",
        "tokens": [
          51514,
          407,
          286,
          727,
          584,
          341,
          420,
          746,
          51614
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8048.44,
        "id": 2482,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8047.44,
        "temperature": 0,
        "text": " Like the funny cat",
        "tokens": [
          51614,
          1743,
          264,
          4074,
          3857,
          51664
        ]
      },
      {
        "avg_logprob": -0.21213382785603152,
        "compression_ratio": 1.8274336283185841,
        "end": 8050.44,
        "id": 2483,
        "no_speech_prob": 0.004069989547133446,
        "seek": 802244,
        "start": 8048.44,
        "temperature": 0,
        "text": " Oops and it would look like this",
        "tokens": [
          51664,
          21726,
          293,
          309,
          576,
          574,
          411,
          341,
          51764
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8051.44,
        "id": 2484,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8050.44,
        "temperature": 0,
        "text": " You know",
        "tokens": [
          50364,
          509,
          458,
          50414
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8053.44,
        "id": 2485,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8051.44,
        "temperature": 0,
        "text": " But the reason why I need to separate this out",
        "tokens": [
          50414,
          583,
          264,
          1778,
          983,
          286,
          643,
          281,
          4994,
          341,
          484,
          50514
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8056.44,
        "id": 2486,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8053.44,
        "temperature": 0,
        "text": " Is because the N or V might be things that need to be expanded",
        "tokens": [
          50514,
          1119,
          570,
          264,
          426,
          420,
          691,
          1062,
          312,
          721,
          300,
          643,
          281,
          312,
          14342,
          50664
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8057.44,
        "id": 2487,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8056.44,
        "temperature": 0,
        "text": " And the truth of the matter is",
        "tokens": [
          50664,
          400,
          264,
          3494,
          295,
          264,
          1871,
          307,
          50714
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8059.44,
        "id": 2488,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8057.44,
        "temperature": 0,
        "text": " I could just do this",
        "tokens": [
          50714,
          286,
          727,
          445,
          360,
          341,
          50814
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8061.44,
        "id": 2489,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8059.44,
        "temperature": 0,
        "text": " But not if I need to treat these separately",
        "tokens": [
          50814,
          583,
          406,
          498,
          286,
          643,
          281,
          2387,
          613,
          14759,
          50914
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8062.44,
        "id": 2490,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8061.44,
        "temperature": 0,
        "text": " As things that might be expanded",
        "tokens": [
          50914,
          1018,
          721,
          300,
          1062,
          312,
          14342,
          50964
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8064.44,
        "id": 2491,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8062.44,
        "temperature": 0,
        "text": " So you know I could do something different with splitting",
        "tokens": [
          50964,
          407,
          291,
          458,
          286,
          727,
          360,
          746,
          819,
          365,
          30348,
          51064
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8067.44,
        "id": 2492,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8064.44,
        "temperature": 0,
        "text": " But I'm going to keep my train of thought here",
        "tokens": [
          51064,
          583,
          286,
          478,
          516,
          281,
          1066,
          452,
          3847,
          295,
          1194,
          510,
          51214
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8069.44,
        "id": 2493,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8067.44,
        "temperature": 0,
        "text": " And what I'm going to do now is",
        "tokens": [
          51214,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          51314
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8072.44,
        "id": 2494,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8069.44,
        "temperature": 0,
        "text": " Once I pick something here",
        "tokens": [
          51314,
          3443,
          286,
          1888,
          746,
          510,
          51464
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8075.44,
        "id": 2495,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8072.44,
        "temperature": 0,
        "text": " I'm picking an array, right?",
        "tokens": [
          51464,
          286,
          478,
          8867,
          364,
          10225,
          11,
          558,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8077.44,
        "id": 2496,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8075.44,
        "temperature": 0,
        "text": " And so what I need to expand",
        "tokens": [
          51614,
          400,
          370,
          437,
          286,
          643,
          281,
          5268,
          51714
        ]
      },
      {
        "avg_logprob": -0.1795872536258421,
        "compression_ratio": 1.856060606060606,
        "end": 8079.44,
        "id": 2497,
        "no_speech_prob": 0.012431190349161625,
        "seek": 805044,
        "start": 8077.44,
        "temperature": 0,
        "text": " Is each one of these",
        "tokens": [
          51714,
          1119,
          1184,
          472,
          295,
          613,
          51814
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8081.44,
        "id": 2498,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8079.44,
        "temperature": 0,
        "text": " So I need to say",
        "tokens": [
          50364,
          407,
          286,
          643,
          281,
          584,
          50464
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8083.44,
        "id": 2499,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8081.44,
        "temperature": 0,
        "text": " For var i equals zero",
        "tokens": [
          50464,
          1171,
          1374,
          741,
          6915,
          4018,
          50564
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8087.44,
        "id": 2500,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8083.44,
        "temperature": 0,
        "text": " i is less than pick.length i++",
        "tokens": [
          50564,
          741,
          307,
          1570,
          813,
          1888,
          13,
          45390,
          741,
          25472,
          50764
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8091.44,
        "id": 2501,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8087.44,
        "temperature": 0,
        "text": " And then I want to expand pick index i",
        "tokens": [
          50764,
          400,
          550,
          286,
          528,
          281,
          5268,
          1888,
          8186,
          741,
          50964
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8093.44,
        "id": 2502,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8091.44,
        "temperature": 0,
        "text": " So I want to go through and expand",
        "tokens": [
          50964,
          407,
          286,
          528,
          281,
          352,
          807,
          293,
          5268,
          51064
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8096.44,
        "id": 2503,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8093.44,
        "temperature": 0,
        "text": " The, then N, and then V",
        "tokens": [
          51064,
          440,
          11,
          550,
          426,
          11,
          293,
          550,
          691,
          51214
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8099.44,
        "id": 2504,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8096.44,
        "temperature": 0,
        "text": " And then push",
        "tokens": [
          51214,
          400,
          550,
          2944,
          51364
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8101.44,
        "id": 2505,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8099.44,
        "temperature": 0,
        "text": " So let's look at this now and see what happens",
        "tokens": [
          51364,
          407,
          718,
          311,
          574,
          412,
          341,
          586,
          293,
          536,
          437,
          2314,
          51464
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8103.44,
        "id": 2506,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8101.44,
        "temperature": 0,
        "text": " And we can see",
        "tokens": [
          51464,
          400,
          321,
          393,
          536,
          51564
        ]
      },
      {
        "avg_logprob": -0.2385209736071135,
        "compression_ratio": 1.484375,
        "end": 8106.44,
        "id": 2507,
        "no_speech_prob": 0.02975919283926487,
        "seek": 807944,
        "start": 8103.44,
        "temperature": 0,
        "text": " Oh I'm still getting undefined at the end",
        "tokens": [
          51564,
          876,
          286,
          478,
          920,
          1242,
          674,
          5666,
          2001,
          412,
          264,
          917,
          51714
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8108.44,
        "id": 2508,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8106.44,
        "temperature": 0,
        "text": " So, but I'm getting something promising",
        "tokens": [
          50364,
          407,
          11,
          457,
          286,
          478,
          1242,
          746,
          20257,
          50464
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8111.44,
        "id": 2509,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8108.44,
        "temperature": 0,
        "text": " Where I got the, and V, and then I got cat, and then I got barks",
        "tokens": [
          50464,
          2305,
          286,
          658,
          264,
          11,
          293,
          691,
          11,
          293,
          550,
          286,
          658,
          3857,
          11,
          293,
          550,
          286,
          658,
          16202,
          82,
          50614
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8113.44,
        "id": 2510,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8111.44,
        "temperature": 0,
        "text": " So it looks like things are working correctly",
        "tokens": [
          50614,
          407,
          309,
          1542,
          411,
          721,
          366,
          1364,
          8944,
          50714
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8115.44,
        "id": 2511,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8113.44,
        "temperature": 0,
        "text": " Oh I'm console.logging result",
        "tokens": [
          50714,
          876,
          286,
          478,
          11076,
          13,
          4987,
          3249,
          1874,
          50814
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8119.44,
        "id": 2512,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8115.44,
        "temperature": 0,
        "text": " Really what I want to console.log is expansion",
        "tokens": [
          50814,
          4083,
          437,
          286,
          528,
          281,
          11076,
          13,
          4987,
          307,
          11260,
          51014
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8122.44,
        "id": 2513,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8119.44,
        "temperature": 0,
        "text": " Undefined, undefined, undefined",
        "tokens": [
          51014,
          2719,
          5666,
          2001,
          11,
          674,
          5666,
          2001,
          11,
          674,
          5666,
          2001,
          51164
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8124.44,
        "id": 2514,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8122.44,
        "temperature": 0,
        "text": " That's promising",
        "tokens": [
          51164,
          663,
          311,
          20257,
          51264
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8125.44,
        "id": 2515,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8124.44,
        "temperature": 0,
        "text": " So let's look up here",
        "tokens": [
          51264,
          407,
          718,
          311,
          574,
          493,
          510,
          51314
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8127.44,
        "id": 2516,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8125.44,
        "temperature": 0,
        "text": " Ah, pick, hmm",
        "tokens": [
          51314,
          2438,
          11,
          1888,
          11,
          16478,
          51414
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8130.44,
        "id": 2517,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8127.44,
        "temperature": 0,
        "text": " Oh no no no no, I want to push start",
        "tokens": [
          51414,
          876,
          572,
          572,
          572,
          572,
          11,
          286,
          528,
          281,
          2944,
          722,
          51564
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8132.44,
        "id": 2518,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8130.44,
        "temperature": 0,
        "text": " So there we go, sorry",
        "tokens": [
          51564,
          407,
          456,
          321,
          352,
          11,
          2597,
          51664
        ]
      },
      {
        "avg_logprob": -0.25651772077693497,
        "compression_ratio": 1.7327586206896552,
        "end": 8134.44,
        "id": 2519,
        "no_speech_prob": 0.1293943077325821,
        "seek": 810644,
        "start": 8132.44,
        "temperature": 0,
        "text": " So this is the thing coming in",
        "tokens": [
          51664,
          407,
          341,
          307,
          264,
          551,
          1348,
          294,
          51764
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8136.44,
        "id": 2520,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8134.44,
        "temperature": 0,
        "text": " If it is part of the rules",
        "tokens": [
          50364,
          759,
          309,
          307,
          644,
          295,
          264,
          4474,
          50464
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8138.44,
        "id": 2521,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8136.44,
        "temperature": 0,
        "text": " Then I need to split it up and expand it",
        "tokens": [
          50464,
          1396,
          286,
          643,
          281,
          7472,
          309,
          493,
          293,
          5268,
          309,
          50564
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8140.44,
        "id": 2522,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8138.44,
        "temperature": 0,
        "text": " Otherwise I need to add that to the end",
        "tokens": [
          50564,
          10328,
          286,
          643,
          281,
          909,
          300,
          281,
          264,
          917,
          50664
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8142.44,
        "id": 2523,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8140.44,
        "temperature": 0,
        "text": " So that's what I was missing there",
        "tokens": [
          50664,
          407,
          300,
          311,
          437,
          286,
          390,
          5361,
          456,
          50764
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8144.44,
        "id": 2524,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8142.44,
        "temperature": 0,
        "text": " And now we can see I get the dog barks",
        "tokens": [
          50764,
          400,
          586,
          321,
          393,
          536,
          286,
          483,
          264,
          3000,
          16202,
          82,
          50864
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8146.44,
        "id": 2525,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8144.44,
        "temperature": 0,
        "text": " And what do I want to do now?",
        "tokens": [
          50864,
          400,
          437,
          360,
          286,
          528,
          281,
          360,
          586,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8148.44,
        "id": 2526,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8146.44,
        "temperature": 0,
        "text": " The thing that it results in is a",
        "tokens": [
          50964,
          440,
          551,
          300,
          309,
          3542,
          294,
          307,
          257,
          51064
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8152.44,
        "id": 2527,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8148.44,
        "temperature": 0,
        "text": " An array of elements",
        "tokens": [
          51064,
          1107,
          10225,
          295,
          4959,
          51264
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8156.44,
        "id": 2528,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8152.44,
        "temperature": 0,
        "text": " And I want to, and so I wonder by the way if it makes sense for me to just say",
        "tokens": [
          51264,
          400,
          286,
          528,
          281,
          11,
          293,
          370,
          286,
          2441,
          538,
          264,
          636,
          498,
          309,
          1669,
          2020,
          337,
          385,
          281,
          445,
          584,
          51464
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8158.44,
        "id": 2529,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8156.44,
        "temperature": 0,
        "text": " Return expansion",
        "tokens": [
          51464,
          24350,
          11260,
          51564
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8160.44,
        "id": 2530,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8158.44,
        "temperature": 0,
        "text": " And in that sense",
        "tokens": [
          51564,
          400,
          294,
          300,
          2020,
          51664
        ]
      },
      {
        "avg_logprob": -0.19554541661189154,
        "compression_ratio": 1.7469879518072289,
        "end": 8163.44,
        "id": 2531,
        "no_speech_prob": 0.0913776233792305,
        "seek": 813444,
        "start": 8160.44,
        "temperature": 0,
        "text": " I can have the function also sort of return that array",
        "tokens": [
          51664,
          286,
          393,
          362,
          264,
          2445,
          611,
          1333,
          295,
          2736,
          300,
          10225,
          51814
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8165.44,
        "id": 2532,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8163.44,
        "temperature": 0,
        "text": " Which is sort of unnecessary but",
        "tokens": [
          50364,
          3013,
          307,
          1333,
          295,
          19350,
          457,
          50464
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8167.44,
        "id": 2533,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8165.44,
        "temperature": 0,
        "text": " Yeah that makes sort of sense to do that",
        "tokens": [
          50464,
          865,
          300,
          1669,
          1333,
          295,
          2020,
          281,
          360,
          300,
          50564
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8172.44,
        "id": 2534,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8167.44,
        "temperature": 0,
        "text": " And then what I can do is I can also say return expansion join",
        "tokens": [
          50564,
          400,
          550,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          611,
          584,
          2736,
          11260,
          3917,
          50814
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8174.44,
        "id": 2535,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8172.44,
        "temperature": 0,
        "text": " With a space",
        "tokens": [
          50814,
          2022,
          257,
          1901,
          50914
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8177.44,
        "id": 2536,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8174.44,
        "temperature": 0,
        "text": " And then now you can see I'm getting these sentences",
        "tokens": [
          50914,
          400,
          550,
          586,
          291,
          393,
          536,
          286,
          478,
          1242,
          613,
          16579,
          51064
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8178.44,
        "id": 2537,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8177.44,
        "temperature": 0,
        "text": " The dog barks",
        "tokens": [
          51064,
          440,
          3000,
          16202,
          82,
          51114
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8182.44,
        "id": 2538,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8178.44,
        "temperature": 0,
        "text": " So now what I have is console.log result",
        "tokens": [
          51114,
          407,
          586,
          437,
          286,
          362,
          307,
          11076,
          13,
          4987,
          1874,
          51314
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8184.44,
        "id": 2539,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8182.44,
        "temperature": 0,
        "text": " Create p, oh there it is, the dog barks",
        "tokens": [
          51314,
          20248,
          280,
          11,
          1954,
          456,
          309,
          307,
          11,
          264,
          3000,
          16202,
          82,
          51414
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8187.44,
        "id": 2540,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8184.44,
        "temperature": 0,
        "text": " So you can see I'm getting these and I could do this a bunch of times",
        "tokens": [
          51414,
          407,
          291,
          393,
          536,
          286,
          478,
          1242,
          613,
          293,
          286,
          727,
          360,
          341,
          257,
          3840,
          295,
          1413,
          51564
        ]
      },
      {
        "avg_logprob": -0.21079068348325533,
        "compression_ratio": 1.7672413793103448,
        "end": 8192.439999999999,
        "id": 2541,
        "no_speech_prob": 0.01428100187331438,
        "seek": 816344,
        "start": 8187.44,
        "temperature": 0,
        "text": " Just to get a bunch of different sentences",
        "tokens": [
          51564,
          1449,
          281,
          483,
          257,
          3840,
          295,
          819,
          16579,
          51814
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8194.44,
        "id": 2542,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8192.44,
        "temperature": 0,
        "text": " To make sure this is really working",
        "tokens": [
          50364,
          1407,
          652,
          988,
          341,
          307,
          534,
          1364,
          50464
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8203.44,
        "id": 2543,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8201.44,
        "temperature": 0,
        "text": " And now I'm going to run this",
        "tokens": [
          50814,
          400,
          586,
          286,
          478,
          516,
          281,
          1190,
          341,
          50914
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8205.44,
        "id": 2544,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8203.44,
        "temperature": 0,
        "text": " And we can see, oh look at this, craziness",
        "tokens": [
          50914,
          400,
          321,
          393,
          536,
          11,
          1954,
          574,
          412,
          341,
          11,
          46348,
          1324,
          51014
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8206.44,
        "id": 2545,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8205.44,
        "temperature": 0,
        "text": " Ah, what's going on here?",
        "tokens": [
          51014,
          2438,
          11,
          437,
          311,
          516,
          322,
          510,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8209.44,
        "id": 2546,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8206.44,
        "temperature": 0,
        "text": " I made a mistake and I've got to start over",
        "tokens": [
          51064,
          286,
          1027,
          257,
          6146,
          293,
          286,
          600,
          658,
          281,
          722,
          670,
          51214
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8211.44,
        "id": 2547,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8209.44,
        "temperature": 0,
        "text": " Each time",
        "tokens": [
          51214,
          6947,
          565,
          51314
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8213.44,
        "id": 2548,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8211.44,
        "temperature": 0,
        "text": " So I want to do that ten times",
        "tokens": [
          51314,
          407,
          286,
          528,
          281,
          360,
          300,
          2064,
          1413,
          51414
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8216.44,
        "id": 2549,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8213.44,
        "temperature": 0,
        "text": " So we can see the dog barks, the dog meows, the dog meows, the cat meows",
        "tokens": [
          51414,
          407,
          321,
          393,
          536,
          264,
          3000,
          16202,
          82,
          11,
          264,
          3000,
          385,
          1509,
          11,
          264,
          3000,
          385,
          1509,
          11,
          264,
          3857,
          385,
          1509,
          51564
        ]
      },
      {
        "avg_logprob": -0.2185105653566735,
        "compression_ratio": 1.6717171717171717,
        "end": 8220.44,
        "id": 2550,
        "no_speech_prob": 0.0070114717818796635,
        "seek": 819244,
        "start": 8216.44,
        "temperature": 0,
        "text": " So this in theory is working right now",
        "tokens": [
          51564,
          407,
          341,
          294,
          5261,
          307,
          1364,
          558,
          586,
          51764
        ]
      },
      {
        "avg_logprob": -0.1978761023217505,
        "compression_ratio": 1.6650246305418719,
        "end": 8225.44,
        "id": 2551,
        "no_speech_prob": 0.025563513860106468,
        "seek": 822044,
        "start": 8221.44,
        "temperature": 0,
        "text": " And what I would like to do is take somebody else's grammar",
        "tokens": [
          50414,
          400,
          437,
          286,
          576,
          411,
          281,
          360,
          307,
          747,
          2618,
          1646,
          311,
          22317,
          50614
        ]
      },
      {
        "avg_logprob": -0.1978761023217505,
        "compression_ratio": 1.6650246305418719,
        "end": 8229.44,
        "id": 2552,
        "no_speech_prob": 0.025563513860106468,
        "seek": 822044,
        "start": 8225.44,
        "temperature": 0,
        "text": " And apply it in here to see if we can get something that's a bit more sophisticated",
        "tokens": [
          50614,
          400,
          3079,
          309,
          294,
          510,
          281,
          536,
          498,
          321,
          393,
          483,
          746,
          300,
          311,
          257,
          857,
          544,
          16950,
          50814
        ]
      },
      {
        "avg_logprob": -0.1978761023217505,
        "compression_ratio": 1.6650246305418719,
        "end": 8234.44,
        "id": 2553,
        "no_speech_prob": 0.025563513860106468,
        "seek": 822044,
        "start": 8229.44,
        "temperature": 0,
        "text": " So I'm going to pull an example grammar file from Allison Parish",
        "tokens": [
          50814,
          407,
          286,
          478,
          516,
          281,
          2235,
          364,
          1365,
          22317,
          3991,
          490,
          32638,
          3457,
          742,
          51064
        ]
      },
      {
        "avg_logprob": -0.1978761023217505,
        "compression_ratio": 1.6650246305418719,
        "end": 8238.44,
        "id": 2554,
        "no_speech_prob": 0.025563513860106468,
        "seek": 822044,
        "start": 8234.44,
        "temperature": 0,
        "text": " And I believe that is this",
        "tokens": [
          51064,
          400,
          286,
          1697,
          300,
          307,
          341,
          51264
        ]
      },
      {
        "avg_logprob": -0.1978761023217505,
        "compression_ratio": 1.6650246305418719,
        "end": 8241.44,
        "id": 2555,
        "no_speech_prob": 0.025563513860106468,
        "seek": 822044,
        "start": 8238.44,
        "temperature": 0,
        "text": " So this is a much nicer grammar",
        "tokens": [
          51264,
          407,
          341,
          307,
          257,
          709,
          22842,
          22317,
          51414
        ]
      },
      {
        "avg_logprob": -0.1978761023217505,
        "compression_ratio": 1.6650246305418719,
        "end": 8247.44,
        "id": 2556,
        "no_speech_prob": 0.025563513860106468,
        "seek": 822044,
        "start": 8241.44,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going to just paste it to the top here",
        "tokens": [
          51414,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          445,
          9163,
          309,
          281,
          264,
          1192,
          510,
          51714
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8249.44,
        "id": 2557,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8247.44,
        "temperature": 0,
        "text": " And I'm going to put it in comments",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          829,
          309,
          294,
          3053,
          50464
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8252.44,
        "id": 2558,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8249.44,
        "temperature": 0,
        "text": " Just to sort of make the argument",
        "tokens": [
          50464,
          1449,
          281,
          1333,
          295,
          652,
          264,
          6770,
          50614
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8255.44,
        "id": 2559,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8252.44,
        "temperature": 0,
        "text": " And I feel like this cooking show thing should happen",
        "tokens": [
          50614,
          400,
          286,
          841,
          411,
          341,
          6361,
          855,
          551,
          820,
          1051,
          50764
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8257.44,
        "id": 2560,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8255.44,
        "temperature": 0,
        "text": " Where now this video is going to get edited",
        "tokens": [
          50764,
          2305,
          586,
          341,
          960,
          307,
          516,
          281,
          483,
          23016,
          50864
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8261.44,
        "id": 2561,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8257.44,
        "temperature": 0,
        "text": " Where all of a sudden you see the result down here",
        "tokens": [
          50864,
          2305,
          439,
          295,
          257,
          3990,
          291,
          536,
          264,
          1874,
          760,
          510,
          51064
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8262.44,
        "id": 2562,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8261.44,
        "temperature": 0,
        "text": " Of me translating it",
        "tokens": [
          51064,
          2720,
          385,
          35030,
          309,
          51114
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8264.44,
        "id": 2563,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8262.44,
        "temperature": 0,
        "text": " But I'm going to walk through translating one at a time",
        "tokens": [
          51114,
          583,
          286,
          478,
          516,
          281,
          1792,
          807,
          35030,
          472,
          412,
          257,
          565,
          51214
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8267.44,
        "id": 2564,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8264.44,
        "temperature": 0,
        "text": " In the archives live stream and we'll see what happens in the video later",
        "tokens": [
          51214,
          682,
          264,
          25607,
          1621,
          4309,
          293,
          321,
          603,
          536,
          437,
          2314,
          294,
          264,
          960,
          1780,
          51364
        ]
      },
      {
        "avg_logprob": -0.20781602945413674,
        "compression_ratio": 1.7863247863247864,
        "end": 8271.44,
        "id": 2565,
        "no_speech_prob": 0.013636023737490177,
        "seek": 824744,
        "start": 8267.44,
        "temperature": 0,
        "text": " So what I'm going to do here is I'm going to say",
        "tokens": [
          51364,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          307,
          286,
          478,
          516,
          281,
          584,
          51564
        ]
      },
      {
        "avg_logprob": -0.2946643829345703,
        "compression_ratio": 1.463768115942029,
        "end": 8279.44,
        "id": 2566,
        "no_speech_prob": 0.4842502772808075,
        "seek": 827144,
        "start": 8272.44,
        "temperature": 0,
        "text": " var rules equals s colon",
        "tokens": [
          50414,
          1374,
          4474,
          6915,
          262,
          8255,
          50764
        ]
      },
      {
        "avg_logprob": -0.2946643829345703,
        "compression_ratio": 1.463768115942029,
        "end": 8281.44,
        "id": 2567,
        "no_speech_prob": 0.4842502772808075,
        "seek": 827144,
        "start": 8279.44,
        "temperature": 0,
        "text": " And then this is an array, let's see",
        "tokens": [
          50764,
          400,
          550,
          341,
          307,
          364,
          10225,
          11,
          718,
          311,
          536,
          50864
        ]
      },
      {
        "avg_logprob": -0.2946643829345703,
        "compression_ratio": 1.463768115942029,
        "end": 8283.44,
        "id": 2568,
        "no_speech_prob": 0.4842502772808075,
        "seek": 827144,
        "start": 8281.44,
        "temperature": 0,
        "text": " This is an array",
        "tokens": [
          50864,
          639,
          307,
          364,
          10225,
          50964
        ]
      },
      {
        "avg_logprob": -0.2946643829345703,
        "compression_ratio": 1.463768115942029,
        "end": 8286.44,
        "id": 2569,
        "no_speech_prob": 0.4842502772808075,
        "seek": 827144,
        "start": 8283.44,
        "temperature": 0,
        "text": " I should use a regular expression to like format this",
        "tokens": [
          50964,
          286,
          820,
          764,
          257,
          3890,
          6114,
          281,
          411,
          7877,
          341,
          51114
        ]
      },
      {
        "avg_logprob": -0.2946643829345703,
        "compression_ratio": 1.463768115942029,
        "end": 8290.44,
        "id": 2570,
        "no_speech_prob": 0.4842502772808075,
        "seek": 827144,
        "start": 8286.44,
        "temperature": 0,
        "text": " Right, so this is one option",
        "tokens": [
          51114,
          1779,
          11,
          370,
          341,
          307,
          472,
          3614,
          51314
        ]
      },
      {
        "avg_logprob": -0.2946643829345703,
        "compression_ratio": 1.463768115942029,
        "end": 8293.44,
        "id": 2571,
        "no_speech_prob": 0.4842502772808075,
        "seek": 827144,
        "start": 8290.44,
        "temperature": 0,
        "text": " I'm going to, and this is another option",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          11,
          293,
          341,
          307,
          1071,
          3614,
          51464
        ]
      },
      {
        "avg_logprob": -0.23846184412638347,
        "compression_ratio": 1.393939393939394,
        "end": 8301.44,
        "id": 2572,
        "no_speech_prob": 0.021614421159029007,
        "seek": 829344,
        "start": 8294.44,
        "temperature": 0,
        "text": " Yeah, this is going to get edited out, I can tell already",
        "tokens": [
          50414,
          865,
          11,
          341,
          307,
          516,
          281,
          483,
          23016,
          484,
          11,
          286,
          393,
          980,
          1217,
          50764
        ]
      },
      {
        "avg_logprob": -0.23846184412638347,
        "compression_ratio": 1.393939393939394,
        "end": 8304.44,
        "id": 2573,
        "no_speech_prob": 0.021614421159029007,
        "seek": 829344,
        "start": 8301.44,
        "temperature": 0,
        "text": " So I'm going to do this now in a slow way",
        "tokens": [
          50764,
          407,
          286,
          478,
          516,
          281,
          360,
          341,
          586,
          294,
          257,
          2964,
          636,
          50914
        ]
      },
      {
        "avg_logprob": -0.23846184412638347,
        "compression_ratio": 1.393939393939394,
        "end": 8308.44,
        "id": 2574,
        "no_speech_prob": 0.021614421159029007,
        "seek": 829344,
        "start": 8304.44,
        "temperature": 0,
        "text": " And then I will come back",
        "tokens": [
          50914,
          400,
          550,
          286,
          486,
          808,
          646,
          51114
        ]
      },
      {
        "avg_logprob": -0.23846184412638347,
        "compression_ratio": 1.393939393939394,
        "end": 8315.44,
        "id": 2575,
        "no_speech_prob": 0.021614421159029007,
        "seek": 829344,
        "start": 8308.44,
        "temperature": 0,
        "text": " And so we can see that",
        "tokens": [
          51114,
          400,
          370,
          321,
          393,
          536,
          300,
          51464
        ]
      },
      {
        "avg_logprob": -0.23846184412638347,
        "compression_ratio": 1.393939393939394,
        "end": 8318.44,
        "id": 2576,
        "no_speech_prob": 0.021614421159029007,
        "seek": 829344,
        "start": 8315.44,
        "temperature": 0,
        "text": " Now I'm getting, now let me do this",
        "tokens": [
          51464,
          823,
          286,
          478,
          1242,
          11,
          586,
          718,
          385,
          360,
          341,
          51614
        ]
      },
      {
        "avg_logprob": -0.2401485158436334,
        "compression_ratio": 1.4807692307692308,
        "end": 8323.44,
        "id": 2577,
        "no_speech_prob": 0.039043232798576355,
        "seek": 831844,
        "start": 8319.44,
        "temperature": 0,
        "text": " Noun phrase is, I'm going to make this faster",
        "tokens": [
          50414,
          426,
          1733,
          9535,
          307,
          11,
          286,
          478,
          516,
          281,
          652,
          341,
          4663,
          50614
        ]
      },
      {
        "avg_logprob": -0.2401485158436334,
        "compression_ratio": 1.4807692307692308,
        "end": 8330.44,
        "id": 2578,
        "no_speech_prob": 0.039043232798576355,
        "seek": 831844,
        "start": 8323.44,
        "temperature": 0,
        "text": " I'm going to create this",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          1884,
          341,
          50964
        ]
      },
      {
        "avg_logprob": -0.2401485158436334,
        "compression_ratio": 1.4807692307692308,
        "end": 8335.44,
        "id": 2579,
        "no_speech_prob": 0.039043232798576355,
        "seek": 831844,
        "start": 8330.44,
        "temperature": 0,
        "text": " I really should have come up with some of my own creative possibilities here",
        "tokens": [
          50964,
          286,
          534,
          820,
          362,
          808,
          493,
          365,
          512,
          295,
          452,
          1065,
          5880,
          12178,
          510,
          51214
        ]
      },
      {
        "avg_logprob": -0.2401485158436334,
        "compression_ratio": 1.4807692307692308,
        "end": 8338.44,
        "id": 2580,
        "no_speech_prob": 0.039043232798576355,
        "seek": 831844,
        "start": 8335.44,
        "temperature": 0,
        "text": " But it's too late now",
        "tokens": [
          51214,
          583,
          309,
          311,
          886,
          3469,
          586,
          51364
        ]
      },
      {
        "avg_logprob": -0.2401485158436334,
        "compression_ratio": 1.4807692307692308,
        "end": 8342.44,
        "id": 2581,
        "no_speech_prob": 0.039043232798576355,
        "seek": 831844,
        "start": 8338.44,
        "temperature": 0,
        "text": " And here's another one, determiner, adjective",
        "tokens": [
          51364,
          400,
          510,
          311,
          1071,
          472,
          11,
          3618,
          4564,
          11,
          44129,
          51564
        ]
      },
      {
        "avg_logprob": -0.2401485158436334,
        "compression_ratio": 1.4807692307692308,
        "end": 8346.44,
        "id": 2582,
        "no_speech_prob": 0.039043232798576355,
        "seek": 831844,
        "start": 8342.44,
        "temperature": 0,
        "text": " Adjective, noun",
        "tokens": [
          51564,
          1999,
          1020,
          488,
          11,
          23307,
          51764
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8350.44,
        "id": 2583,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8346.44,
        "temperature": 0,
        "text": " I'm sure this is thrilling for you guys to watch in the live stream",
        "tokens": [
          50364,
          286,
          478,
          988,
          341,
          307,
          39347,
          337,
          291,
          1074,
          281,
          1159,
          294,
          264,
          1621,
          4309,
          50564
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8354.44,
        "id": 2584,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8350.44,
        "temperature": 0,
        "text": " Then verb phrase",
        "tokens": [
          50564,
          1396,
          9595,
          9535,
          50764
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8356.44,
        "id": 2585,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8354.44,
        "temperature": 0,
        "text": " I'm going to be done with this soon",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          312,
          1096,
          365,
          341,
          2321,
          50864
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8360.44,
        "id": 2586,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8356.44,
        "temperature": 0,
        "text": " Verb phrase is transitive verb",
        "tokens": [
          50864,
          27034,
          9535,
          307,
          1145,
          2187,
          9595,
          51064
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8364.44,
        "id": 2587,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8360.44,
        "temperature": 0,
        "text": " Noun phrase because they have objects",
        "tokens": [
          51064,
          426,
          1733,
          9535,
          570,
          436,
          362,
          6565,
          51264
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8368.44,
        "id": 2588,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8364.44,
        "temperature": 0,
        "text": " And another verb phrase, or",
        "tokens": [
          51264,
          400,
          1071,
          9595,
          9535,
          11,
          420,
          51464
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8372.44,
        "id": 2589,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8368.44,
        "temperature": 0,
        "text": " Oh, I did this wrong",
        "tokens": [
          51464,
          876,
          11,
          286,
          630,
          341,
          2085,
          51664
        ]
      },
      {
        "avg_logprob": -0.2739190804330926,
        "compression_ratio": 1.5508982035928143,
        "end": 8374.44,
        "id": 2590,
        "no_speech_prob": 0.031142042949795723,
        "seek": 834644,
        "start": 8372.44,
        "temperature": 0,
        "text": " No, I did this right",
        "tokens": [
          51664,
          883,
          11,
          286,
          630,
          341,
          558,
          51764
        ]
      },
      {
        "avg_logprob": -0.3620469395707293,
        "compression_ratio": 1.1553398058252426,
        "end": 8380.44,
        "id": 2591,
        "no_speech_prob": 0.3206770718097687,
        "seek": 837444,
        "start": 8374.44,
        "temperature": 0,
        "text": " Or, right, intransitive verb",
        "tokens": [
          50364,
          1610,
          11,
          558,
          11,
          17467,
          599,
          2187,
          9595,
          50664
        ]
      },
      {
        "avg_logprob": -0.3620469395707293,
        "compression_ratio": 1.1553398058252426,
        "end": 8388.44,
        "id": 2592,
        "no_speech_prob": 0.3206770718097687,
        "seek": 837444,
        "start": 8380.44,
        "temperature": 0,
        "text": " Okay, now we're going to do this",
        "tokens": [
          50664,
          1033,
          11,
          586,
          321,
          434,
          516,
          281,
          360,
          341,
          51064
        ]
      },
      {
        "avg_logprob": -0.3620469395707293,
        "compression_ratio": 1.1553398058252426,
        "end": 8390.44,
        "id": 2593,
        "no_speech_prob": 0.3206770718097687,
        "seek": 837444,
        "start": 8388.44,
        "temperature": 0,
        "text": " Should be pretty easy",
        "tokens": [
          51064,
          6454,
          312,
          1238,
          1858,
          51164
        ]
      },
      {
        "avg_logprob": -0.3620469395707293,
        "compression_ratio": 1.1553398058252426,
        "end": 8398.44,
        "id": 2594,
        "no_speech_prob": 0.3206770718097687,
        "seek": 837444,
        "start": 8390.44,
        "temperature": 0,
        "text": " Interj",
        "tokens": [
          51164,
          5751,
          73,
          51564
        ]
      },
      {
        "avg_logprob": -0.3620469395707293,
        "compression_ratio": 1.1553398058252426,
        "end": 8401.44,
        "id": 2595,
        "no_speech_prob": 0.3206770718097687,
        "seek": 837444,
        "start": 8398.44,
        "temperature": 0,
        "text": " Sorry everybody, is an array",
        "tokens": [
          51564,
          4919,
          2201,
          11,
          307,
          364,
          10225,
          51714
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8406.44,
        "id": 2596,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8402.44,
        "temperature": 0,
        "text": " With, now I'm tempted to use split",
        "tokens": [
          50414,
          2022,
          11,
          586,
          286,
          478,
          29941,
          281,
          764,
          7472,
          50614
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8408.44,
        "id": 2597,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8406.44,
        "temperature": 0,
        "text": " And use the pipe symbol",
        "tokens": [
          50614,
          400,
          764,
          264,
          11240,
          5986,
          50714
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8410.44,
        "id": 2598,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8408.44,
        "temperature": 0,
        "text": " I don't know why I didn't do that",
        "tokens": [
          50714,
          286,
          500,
          380,
          458,
          983,
          286,
          994,
          380,
          360,
          300,
          50814
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8412.44,
        "id": 2599,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8410.44,
        "temperature": 0,
        "text": " But I'm going to do this",
        "tokens": [
          50814,
          583,
          286,
          478,
          516,
          281,
          360,
          341,
          50914
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8418.44,
        "id": 2600,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8412.44,
        "temperature": 0,
        "text": " My, wow, darn, I'm cleaning it up",
        "tokens": [
          50914,
          1222,
          11,
          6076,
          11,
          29063,
          11,
          286,
          478,
          8924,
          309,
          493,
          51214
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8424.44,
        "id": 2601,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8418.44,
        "temperature": 0,
        "text": " Determiner, is it determiner, is that right?",
        "tokens": [
          51214,
          4237,
          966,
          4564,
          11,
          307,
          309,
          3618,
          4564,
          11,
          307,
          300,
          558,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.21544683432277245,
        "compression_ratio": 1.48,
        "end": 8429.44,
        "id": 2602,
        "no_speech_prob": 0.5232571363449097,
        "seek": 840144,
        "start": 8424.44,
        "temperature": 0,
        "text": " This, that, this dot, the",
        "tokens": [
          51514,
          639,
          11,
          300,
          11,
          341,
          5893,
          11,
          264,
          51764
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8433.44,
        "id": 2603,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8429.44,
        "temperature": 0,
        "text": " Yeah, this is definitely not making it to the final released video",
        "tokens": [
          50364,
          865,
          11,
          341,
          307,
          2138,
          406,
          1455,
          309,
          281,
          264,
          2572,
          4736,
          960,
          50564
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8435.44,
        "id": 2604,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8433.44,
        "temperature": 0,
        "text": " Do you think?",
        "tokens": [
          50564,
          1144,
          291,
          519,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8439.44,
        "id": 2605,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8435.44,
        "temperature": 0,
        "text": " Noun, oh and this is adjective",
        "tokens": [
          50664,
          426,
          1733,
          11,
          1954,
          293,
          341,
          307,
          44129,
          50864
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8443.44,
        "id": 2606,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8439.44,
        "temperature": 0,
        "text": " And this is noun",
        "tokens": [
          50864,
          400,
          341,
          307,
          23307,
          51064
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8451.44,
        "id": 2607,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8443.44,
        "temperature": 0,
        "text": " Bald, smug",
        "tokens": [
          51064,
          27306,
          11,
          899,
          697,
          51464
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8454.44,
        "id": 2608,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8451.44,
        "temperature": 0,
        "text": " Oh, it's at 4.30, I'm really going way over",
        "tokens": [
          51464,
          876,
          11,
          309,
          311,
          412,
          1017,
          13,
          3446,
          11,
          286,
          478,
          534,
          516,
          636,
          670,
          51614
        ]
      },
      {
        "avg_logprob": -0.276174495746563,
        "compression_ratio": 1.3542857142857143,
        "end": 8457.44,
        "id": 2609,
        "no_speech_prob": 0.2281254678964615,
        "seek": 842944,
        "start": 8454.44,
        "temperature": 0,
        "text": " I think that my guest, Tiga, might be waiting outside",
        "tokens": [
          51614,
          286,
          519,
          300,
          452,
          8341,
          11,
          314,
          9900,
          11,
          1062,
          312,
          3806,
          2380,
          51764
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8464.44,
        "id": 2610,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8457.44,
        "temperature": 0,
        "text": " Or maybe, hopefully she's getting herself set up",
        "tokens": [
          50364,
          1610,
          1310,
          11,
          4696,
          750,
          311,
          1242,
          7530,
          992,
          493,
          50714
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8469.44,
        "id": 2611,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8464.44,
        "temperature": 0,
        "text": " Corsage, okay, I think I won't finish this whole thing",
        "tokens": [
          50714,
          383,
          830,
          609,
          11,
          1392,
          11,
          286,
          519,
          286,
          1582,
          380,
          2413,
          341,
          1379,
          551,
          50964
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8471.44,
        "id": 2612,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8469.44,
        "temperature": 0,
        "text": " We'll do this now",
        "tokens": [
          50964,
          492,
          603,
          360,
          341,
          586,
          51064
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8475.44,
        "id": 2613,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8471.44,
        "temperature": 0,
        "text": " Now I need to do, what was that?",
        "tokens": [
          51064,
          823,
          286,
          643,
          281,
          360,
          11,
          437,
          390,
          300,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8476.44,
        "id": 2614,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8475.44,
        "temperature": 0,
        "text": " That was adjective, sorry",
        "tokens": [
          51264,
          663,
          390,
          44129,
          11,
          2597,
          51314
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8478.44,
        "id": 2615,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8476.44,
        "temperature": 0,
        "text": " Oh my goodness, I'm all out of whack",
        "tokens": [
          51314,
          876,
          452,
          8387,
          11,
          286,
          478,
          439,
          484,
          295,
          42877,
          51414
        ]
      },
      {
        "avg_logprob": -0.25010979175567627,
        "compression_ratio": 1.3945945945945946,
        "end": 8484.44,
        "id": 2616,
        "no_speech_prob": 0.1347484141588211,
        "seek": 845744,
        "start": 8478.44,
        "temperature": 0,
        "text": " Determiner, adjective, come on everybody",
        "tokens": [
          51414,
          4237,
          966,
          4564,
          11,
          44129,
          11,
          808,
          322,
          2201,
          51714
        ]
      },
      {
        "avg_logprob": -0.2856084025183389,
        "compression_ratio": 1.236842105263158,
        "end": 8489.44,
        "id": 2617,
        "no_speech_prob": 0.2199305295944214,
        "seek": 848444,
        "start": 8485.44,
        "temperature": 0,
        "text": " Talk about not preparing",
        "tokens": [
          50414,
          8780,
          466,
          406,
          10075,
          50614
        ]
      },
      {
        "avg_logprob": -0.2856084025183389,
        "compression_ratio": 1.236842105263158,
        "end": 8497.44,
        "id": 2618,
        "no_speech_prob": 0.2199305295944214,
        "seek": 848444,
        "start": 8489.44,
        "temperature": 0,
        "text": " Computes, let's see, computes",
        "tokens": [
          50614,
          6620,
          1819,
          11,
          718,
          311,
          536,
          11,
          715,
          1819,
          51014
        ]
      },
      {
        "avg_logprob": -0.2856084025183389,
        "compression_ratio": 1.236842105263158,
        "end": 8505.44,
        "id": 2619,
        "no_speech_prob": 0.2199305295944214,
        "seek": 848444,
        "start": 8497.44,
        "temperature": 0,
        "text": " Examines, foregrounds, that's good enough for me right now",
        "tokens": [
          51014,
          24755,
          1652,
          11,
          32058,
          82,
          11,
          300,
          311,
          665,
          1547,
          337,
          385,
          558,
          586,
          51414
        ]
      },
      {
        "avg_logprob": -0.2856084025183389,
        "compression_ratio": 1.236842105263158,
        "end": 8507.44,
        "id": 2620,
        "no_speech_prob": 0.2199305295944214,
        "seek": 848444,
        "start": 8505.44,
        "temperature": 0,
        "text": " I'm losing my patience here",
        "tokens": [
          51414,
          286,
          478,
          7027,
          452,
          14826,
          510,
          51514
        ]
      },
      {
        "avg_logprob": -0.4922382354736328,
        "compression_ratio": 0.8823529411764706,
        "end": 8517.44,
        "id": 2621,
        "no_speech_prob": 0.5424658060073853,
        "seek": 850744,
        "start": 8507.44,
        "temperature": 0,
        "text": " And then, intransitive",
        "tokens": [
          50364,
          400,
          550,
          11,
          17467,
          599,
          2187,
          50864
        ]
      },
      {
        "avg_logprob": -0.4922382354736328,
        "compression_ratio": 0.8823529411764706,
        "end": 8525.44,
        "id": 2622,
        "no_speech_prob": 0.5424658060073853,
        "seek": 850744,
        "start": 8517.44,
        "temperature": 0,
        "text": " Daydreams, wines, okay",
        "tokens": [
          50864,
          5226,
          67,
          1572,
          82,
          11,
          35970,
          11,
          1392,
          51264
        ]
      },
      {
        "avg_logprob": -0.30230993154097574,
        "compression_ratio": 1.35,
        "end": 8533.44,
        "id": 2623,
        "no_speech_prob": 0.851249635219574,
        "seek": 852544,
        "start": 8526.44,
        "temperature": 0,
        "text": " So now I'm commenting out",
        "tokens": [
          50414,
          407,
          586,
          286,
          478,
          29590,
          484,
          50764
        ]
      },
      {
        "avg_logprob": -0.30230993154097574,
        "compression_ratio": 1.35,
        "end": 8538.44,
        "id": 2624,
        "no_speech_prob": 0.851249635219574,
        "seek": 852544,
        "start": 8533.44,
        "temperature": 0,
        "text": " What var rules is this object with all these in it",
        "tokens": [
          50764,
          708,
          1374,
          4474,
          307,
          341,
          2657,
          365,
          439,
          613,
          294,
          309,
          51014
        ]
      },
      {
        "avg_logprob": -0.30230993154097574,
        "compression_ratio": 1.35,
        "end": 8543.44,
        "id": 2625,
        "no_speech_prob": 0.851249635219574,
        "seek": 852544,
        "start": 8538.44,
        "temperature": 0,
        "text": " And then I can comment out this",
        "tokens": [
          51014,
          400,
          550,
          286,
          393,
          2871,
          484,
          341,
          51264
        ]
      },
      {
        "avg_logprob": -0.30230993154097574,
        "compression_ratio": 1.35,
        "end": 8546.44,
        "id": 2626,
        "no_speech_prob": 0.851249635219574,
        "seek": 852544,
        "start": 8543.44,
        "temperature": 0,
        "text": " And this, let's just make sure this works",
        "tokens": [
          51264,
          400,
          341,
          11,
          718,
          311,
          445,
          652,
          988,
          341,
          1985,
          51414
        ]
      },
      {
        "avg_logprob": -0.30230993154097574,
        "compression_ratio": 1.35,
        "end": 8550.44,
        "id": 2627,
        "no_speech_prob": 0.851249635219574,
        "seek": 852544,
        "start": 8546.44,
        "temperature": 0,
        "text": " The n costs",
        "tokens": [
          51414,
          440,
          297,
          5497,
          51614
        ]
      },
      {
        "avg_logprob": -0.32745535899016814,
        "compression_ratio": 1.232,
        "end": 8557.44,
        "id": 2628,
        "no_speech_prob": 0.2909245193004608,
        "seek": 855044,
        "start": 8551.44,
        "temperature": 0,
        "text": " Rules, NP, what happened here?",
        "tokens": [
          50414,
          38897,
          11,
          38611,
          11,
          437,
          2011,
          510,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.32745535899016814,
        "compression_ratio": 1.232,
        "end": 8563.44,
        "id": 2629,
        "no_speech_prob": 0.2909245193004608,
        "seek": 855044,
        "start": 8557.44,
        "temperature": 0,
        "text": " Expand, start is S, whoops",
        "tokens": [
          50714,
          21391,
          474,
          11,
          722,
          307,
          318,
          11,
          567,
          3370,
          51014
        ]
      },
      {
        "avg_logprob": -0.32745535899016814,
        "compression_ratio": 1.232,
        "end": 8567.44,
        "id": 2630,
        "no_speech_prob": 0.2909245193004608,
        "seek": 855044,
        "start": 8563.44,
        "temperature": 0,
        "text": " Oh yeah, NPVP, the NP, what?",
        "tokens": [
          51014,
          876,
          1338,
          11,
          38611,
          53,
          47,
          11,
          264,
          38611,
          11,
          437,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.32745535899016814,
        "compression_ratio": 1.232,
        "end": 8572.44,
        "id": 2631,
        "no_speech_prob": 0.2909245193004608,
        "seek": 855044,
        "start": 8567.44,
        "temperature": 0,
        "text": " Oh, where are my nouns?",
        "tokens": [
          51214,
          876,
          11,
          689,
          366,
          452,
          48184,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.32745535899016814,
        "compression_ratio": 1.232,
        "end": 8575.44,
        "id": 2632,
        "no_speech_prob": 0.2909245193004608,
        "seek": 855044,
        "start": 8572.44,
        "temperature": 0,
        "text": " Guess I forgot them",
        "tokens": [
          51464,
          17795,
          286,
          5298,
          552,
          51614
        ]
      },
      {
        "avg_logprob": -0.32745535899016814,
        "compression_ratio": 1.232,
        "end": 8578.44,
        "id": 2633,
        "no_speech_prob": 0.2909245193004608,
        "seek": 855044,
        "start": 8575.44,
        "temperature": 0,
        "text": " Where was that grammar?",
        "tokens": [
          51614,
          2305,
          390,
          300,
          22317,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.23749688819602685,
        "compression_ratio": 1.218045112781955,
        "end": 8581.44,
        "id": 2634,
        "no_speech_prob": 0.019418681040406227,
        "seek": 857844,
        "start": 8578.44,
        "temperature": 0,
        "text": " Let's add some nouns",
        "tokens": [
          50364,
          961,
          311,
          909,
          512,
          48184,
          50514
        ]
      },
      {
        "avg_logprob": -0.23749688819602685,
        "compression_ratio": 1.218045112781955,
        "end": 8585.44,
        "id": 2635,
        "no_speech_prob": 0.019418681040406227,
        "seek": 857844,
        "start": 8581.44,
        "temperature": 0,
        "text": " Sorry everybody",
        "tokens": [
          50514,
          4919,
          2201,
          50714
        ]
      },
      {
        "avg_logprob": -0.23749688819602685,
        "compression_ratio": 1.218045112781955,
        "end": 8589.44,
        "id": 2636,
        "no_speech_prob": 0.019418681040406227,
        "seek": 857844,
        "start": 8585.44,
        "temperature": 0,
        "text": " Put them here",
        "tokens": [
          50714,
          4935,
          552,
          510,
          50914
        ]
      },
      {
        "avg_logprob": -0.23749688819602685,
        "compression_ratio": 1.218045112781955,
        "end": 8596.44,
        "id": 2637,
        "no_speech_prob": 0.019418681040406227,
        "seek": 857844,
        "start": 8589.44,
        "temperature": 0,
        "text": " N, amoeba, dichotomy, seagull",
        "tokens": [
          50914,
          426,
          11,
          669,
          7921,
          4231,
          11,
          10390,
          310,
          8488,
          11,
          369,
          559,
          858,
          51264
        ]
      },
      {
        "avg_logprob": -0.23749688819602685,
        "compression_ratio": 1.218045112781955,
        "end": 8600.44,
        "id": 2638,
        "no_speech_prob": 0.019418681040406227,
        "seek": 857844,
        "start": 8596.44,
        "temperature": 0,
        "text": " I should have just picked random stuff from",
        "tokens": [
          51264,
          286,
          820,
          362,
          445,
          6183,
          4974,
          1507,
          490,
          51464
        ]
      },
      {
        "avg_logprob": -0.23749688819602685,
        "compression_ratio": 1.218045112781955,
        "end": 8603.44,
        "id": 2639,
        "no_speech_prob": 0.019418681040406227,
        "seek": 857844,
        "start": 8600.44,
        "temperature": 0,
        "text": " And this is, oh I lost something here",
        "tokens": [
          51464,
          400,
          341,
          307,
          11,
          1954,
          286,
          2731,
          746,
          510,
          51614
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8609.44,
        "id": 2640,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8603.44,
        "temperature": 0,
        "text": " This is, adjective, oh boy",
        "tokens": [
          50364,
          639,
          307,
          11,
          44129,
          11,
          1954,
          3237,
          50664
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8611.44,
        "id": 2641,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8609.44,
        "temperature": 0,
        "text": " Let's see what we get now",
        "tokens": [
          50664,
          961,
          311,
          536,
          437,
          321,
          483,
          586,
          50764
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8614.44,
        "id": 2642,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8611.44,
        "temperature": 0,
        "text": " Okay, I think this is working",
        "tokens": [
          50764,
          1033,
          11,
          286,
          519,
          341,
          307,
          1364,
          50914
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8616.44,
        "id": 2643,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8614.44,
        "temperature": 0,
        "text": " That important corsage, foregrounds, the trombone",
        "tokens": [
          50914,
          663,
          1021,
          46511,
          609,
          11,
          32058,
          82,
          11,
          264,
          504,
          3548,
          546,
          51014
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8621.44,
        "id": 2644,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8616.44,
        "temperature": 0,
        "text": " Okay, so let's come over here and say",
        "tokens": [
          51014,
          1033,
          11,
          370,
          718,
          311,
          808,
          670,
          510,
          293,
          584,
          51264
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8625.44,
        "id": 2645,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8621.44,
        "temperature": 0,
        "text": " Okay, so we're going to magically come back",
        "tokens": [
          51264,
          1033,
          11,
          370,
          321,
          434,
          516,
          281,
          39763,
          808,
          646,
          51464
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8628.44,
        "id": 2646,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8625.44,
        "temperature": 0,
        "text": " Magically come back",
        "tokens": [
          51464,
          6395,
          984,
          808,
          646,
          51614
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8630.44,
        "id": 2647,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8628.44,
        "temperature": 0,
        "text": " Okay, so you didn't have to watch all that",
        "tokens": [
          51614,
          1033,
          11,
          370,
          291,
          994,
          380,
          362,
          281,
          1159,
          439,
          300,
          51714
        ]
      },
      {
        "avg_logprob": -0.22960419905813118,
        "compression_ratio": 1.5594059405940595,
        "end": 8632.44,
        "id": 2648,
        "no_speech_prob": 0.05920722335577011,
        "seek": 860344,
        "start": 8630.44,
        "temperature": 0,
        "text": " But I went and converted this grammar",
        "tokens": [
          51714,
          583,
          286,
          1437,
          293,
          16424,
          341,
          22317,
          51814
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8635.44,
        "id": 2649,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8632.44,
        "temperature": 0,
        "text": " Which is from an example from Allison Parrish",
        "tokens": [
          50364,
          3013,
          307,
          490,
          364,
          1365,
          490,
          32638,
          47890,
          742,
          50514
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8636.44,
        "id": 2650,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8635.44,
        "temperature": 0,
        "text": " Thank you Allison Parrish",
        "tokens": [
          50514,
          1044,
          291,
          32638,
          47890,
          742,
          50564
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8638.44,
        "id": 2651,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8636.44,
        "temperature": 0,
        "text": " And I converted it to this syntax that I developed",
        "tokens": [
          50564,
          400,
          286,
          16424,
          309,
          281,
          341,
          28431,
          300,
          286,
          4743,
          50664
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8643.44,
        "id": 2652,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8638.44,
        "temperature": 0,
        "text": " Which is probably, and you can see now I have a slightly more complex sentence",
        "tokens": [
          50664,
          3013,
          307,
          1391,
          11,
          293,
          291,
          393,
          536,
          586,
          286,
          362,
          257,
          4748,
          544,
          3997,
          8174,
          50914
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8645.44,
        "id": 2653,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8643.44,
        "temperature": 0,
        "text": " First of all I have two different options",
        "tokens": [
          50914,
          2386,
          295,
          439,
          286,
          362,
          732,
          819,
          3956,
          51014
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8648.44,
        "id": 2654,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8645.44,
        "temperature": 0,
        "text": " Noun phrase, verb phrase, interjection, noun phrase, verb phrase",
        "tokens": [
          51014,
          426,
          1733,
          9535,
          11,
          9595,
          9535,
          11,
          46787,
          313,
          11,
          23307,
          9535,
          11,
          9595,
          9535,
          51164
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8650.44,
        "id": 2655,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8648.44,
        "temperature": 0,
        "text": " And the powerful thing here is that",
        "tokens": [
          51164,
          400,
          264,
          4005,
          551,
          510,
          307,
          300,
          51264
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8654.44,
        "id": 2656,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8650.44,
        "temperature": 0,
        "text": " A verb phrase can also include a noun phrase or no noun phrase",
        "tokens": [
          51264,
          316,
          9595,
          9535,
          393,
          611,
          4090,
          257,
          23307,
          9535,
          420,
          572,
          23307,
          9535,
          51464
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8656.44,
        "id": 2657,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8654.44,
        "temperature": 0,
        "text": " So there's the recursive nature of this algorithm",
        "tokens": [
          51464,
          407,
          456,
          311,
          264,
          20560,
          488,
          3687,
          295,
          341,
          9284,
          51564
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8659.44,
        "id": 2658,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8656.44,
        "temperature": 0,
        "text": " Of kind of expanding this sort of nested tree",
        "tokens": [
          51564,
          2720,
          733,
          295,
          14702,
          341,
          1333,
          295,
          15646,
          292,
          4230,
          51714
        ]
      },
      {
        "avg_logprob": -0.2227191347064394,
        "compression_ratio": 1.7692307692307692,
        "end": 8661.44,
        "id": 2659,
        "no_speech_prob": 0.21464881300926208,
        "seek": 863244,
        "start": 8659.44,
        "temperature": 0,
        "text": " Is much more apparent now",
        "tokens": [
          51714,
          1119,
          709,
          544,
          18335,
          586,
          51814
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8665.44,
        "id": 2660,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8661.44,
        "temperature": 0,
        "text": " So let me go and I think what I should do is",
        "tokens": [
          50364,
          407,
          718,
          385,
          352,
          293,
          286,
          519,
          437,
          286,
          820,
          360,
          307,
          50564
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8669.44,
        "id": 2661,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8665.44,
        "temperature": 0,
        "text": " Quickly create a nice little button to do the generation",
        "tokens": [
          50564,
          31800,
          1884,
          257,
          1481,
          707,
          2960,
          281,
          360,
          264,
          5125,
          50764
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8673.44,
        "id": 2662,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8669.44,
        "temperature": 0,
        "text": " So where am I? I'm going to say button",
        "tokens": [
          50764,
          407,
          689,
          669,
          286,
          30,
          286,
          478,
          516,
          281,
          584,
          2960,
          50964
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8676.44,
        "id": 2663,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8673.44,
        "temperature": 0,
        "text": " And I'm going to say button equals create button",
        "tokens": [
          50964,
          400,
          286,
          478,
          516,
          281,
          584,
          2960,
          6915,
          1884,
          2960,
          51114
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8678.44,
        "id": 2664,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8676.44,
        "temperature": 0,
        "text": " Generate",
        "tokens": [
          51114,
          15409,
          473,
          51214
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8682.44,
        "id": 2665,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8678.44,
        "temperature": 0,
        "text": " And then button, mouse pressed",
        "tokens": [
          51214,
          400,
          550,
          2960,
          11,
          9719,
          17355,
          51414
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8684.44,
        "id": 2666,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8682.44,
        "temperature": 0,
        "text": " CFG",
        "tokens": [
          51414,
          21792,
          38,
          51514
        ]
      },
      {
        "avg_logprob": -0.2095266819000244,
        "compression_ratio": 1.5705521472392638,
        "end": 8687.44,
        "id": 2667,
        "no_speech_prob": 0.09135595709085464,
        "seek": 866144,
        "start": 8684.44,
        "temperature": 0,
        "text": " Like the BFG but a CFG",
        "tokens": [
          51514,
          1743,
          264,
          363,
          37,
          38,
          457,
          257,
          21792,
          38,
          51664
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8690.44,
        "id": 2668,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8687.44,
        "temperature": 0,
        "text": " And then I'm going to say function CFG",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          2445,
          21792,
          38,
          50514
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8697.44,
        "id": 2669,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8692.44,
        "temperature": 0,
        "text": " And I don't, I'm going to expand this grammar",
        "tokens": [
          50614,
          400,
          286,
          500,
          380,
          11,
          286,
          478,
          516,
          281,
          5268,
          341,
          22317,
          50864
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8699.44,
        "id": 2670,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8697.44,
        "temperature": 0,
        "text": " And create a paragraph",
        "tokens": [
          50864,
          400,
          1884,
          257,
          18865,
          50964
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8702.44,
        "id": 2671,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8699.44,
        "temperature": 0,
        "text": " So let's look and see I have a button",
        "tokens": [
          50964,
          407,
          718,
          311,
          574,
          293,
          536,
          286,
          362,
          257,
          2960,
          51114
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8705.44,
        "id": 2672,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8702.44,
        "temperature": 0,
        "text": " The dichotomy that winds foregrounds that tame seagull",
        "tokens": [
          51114,
          440,
          10390,
          310,
          8488,
          300,
          17765,
          32058,
          82,
          300,
          45774,
          369,
          559,
          858,
          51264
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8709.44,
        "id": 2673,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8705.44,
        "temperature": 0,
        "text": " The corsage foregrounds the corsage that foregrounds this amoeba",
        "tokens": [
          51264,
          440,
          46511,
          609,
          32058,
          82,
          264,
          46511,
          609,
          300,
          32058,
          82,
          341,
          669,
          7921,
          4231,
          51464
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8711.44,
        "id": 2674,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8709.44,
        "temperature": 0,
        "text": " The corsage amoeba winds",
        "tokens": [
          51464,
          440,
          46511,
          609,
          669,
          7921,
          4231,
          17765,
          51564
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8713.44,
        "id": 2675,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8711.44,
        "temperature": 0,
        "text": " I feel like I messed something up",
        "tokens": [
          51564,
          286,
          841,
          411,
          286,
          16507,
          746,
          493,
          51664
        ]
      },
      {
        "avg_logprob": -0.19571375413374467,
        "compression_ratio": 1.7813953488372094,
        "end": 8715.44,
        "id": 2676,
        "no_speech_prob": 0.09669878333806992,
        "seek": 868744,
        "start": 8713.44,
        "temperature": 0,
        "text": " But I'm sure I probably messed something up in the grammar",
        "tokens": [
          51664,
          583,
          286,
          478,
          988,
          286,
          1391,
          16507,
          746,
          493,
          294,
          264,
          22317,
          51764
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8720.44,
        "id": 2677,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8715.44,
        "temperature": 0,
        "text": " But you'll have a, you get the idea here",
        "tokens": [
          50364,
          583,
          291,
          603,
          362,
          257,
          11,
          291,
          483,
          264,
          1558,
          510,
          50614
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8722.44,
        "id": 2678,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8720.44,
        "temperature": 0,
        "text": " So this is, the key piece of this is",
        "tokens": [
          50614,
          407,
          341,
          307,
          11,
          264,
          2141,
          2522,
          295,
          341,
          307,
          50714
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8725.44,
        "id": 2679,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8722.44,
        "temperature": 0,
        "text": " A, how are you deciding to format your grammar?",
        "tokens": [
          50714,
          316,
          11,
          577,
          366,
          291,
          17990,
          281,
          7877,
          428,
          22317,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8729.44,
        "id": 2680,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8725.44,
        "temperature": 0,
        "text": " Right, how are you creating terminal and non-terminal symbols?",
        "tokens": [
          50864,
          1779,
          11,
          577,
          366,
          291,
          4084,
          14709,
          293,
          2107,
          12,
          7039,
          2071,
          16944,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8731.44,
        "id": 2681,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8729.44,
        "temperature": 0,
        "text": " I've chosen to use this sort of set of nested arrays",
        "tokens": [
          51064,
          286,
          600,
          8614,
          281,
          764,
          341,
          1333,
          295,
          992,
          295,
          15646,
          292,
          41011,
          51164
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8735.44,
        "id": 2682,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8731.44,
        "temperature": 0,
        "text": " And the real key here of course is this recursive algorithm",
        "tokens": [
          51164,
          400,
          264,
          957,
          2141,
          510,
          295,
          1164,
          307,
          341,
          20560,
          488,
          9284,
          51364
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8738.44,
        "id": 2683,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8735.44,
        "temperature": 0,
        "text": " So as I'm starting with one element",
        "tokens": [
          51364,
          407,
          382,
          286,
          478,
          2891,
          365,
          472,
          4478,
          51514
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8742.44,
        "id": 2684,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8738.44,
        "temperature": 0,
        "text": " I expand that and then I look over those elements",
        "tokens": [
          51514,
          286,
          5268,
          300,
          293,
          550,
          286,
          574,
          670,
          729,
          4959,
          51714
        ]
      },
      {
        "avg_logprob": -0.2156333591627038,
        "compression_ratio": 1.7183673469387755,
        "end": 8743.44,
        "id": 2685,
        "no_speech_prob": 0.020021945238113403,
        "seek": 871544,
        "start": 8742.44,
        "temperature": 0,
        "text": " And call expand on those elements",
        "tokens": [
          51714,
          400,
          818,
          5268,
          322,
          729,
          4959,
          51764
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8745.44,
        "id": 2686,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8743.44,
        "temperature": 0,
        "text": " And call expand recursive",
        "tokens": [
          50364,
          400,
          818,
          5268,
          20560,
          488,
          50464
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8747.44,
        "id": 2687,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8745.44,
        "temperature": 0,
        "text": " This function is just calling itself, calling itself",
        "tokens": [
          50464,
          639,
          2445,
          307,
          445,
          5141,
          2564,
          11,
          5141,
          2564,
          50564
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8749.44,
        "id": 2688,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8747.44,
        "temperature": 0,
        "text": " And this like computer is just keeping track of everything",
        "tokens": [
          50564,
          400,
          341,
          411,
          3820,
          307,
          445,
          5145,
          2837,
          295,
          1203,
          50664
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8752.44,
        "id": 2689,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8749.44,
        "temperature": 0,
        "text": " And then at the, eventually it's going to finish doing all that",
        "tokens": [
          50664,
          400,
          550,
          412,
          264,
          11,
          4728,
          309,
          311,
          516,
          281,
          2413,
          884,
          439,
          300,
          50814
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8754.44,
        "id": 2690,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8752.44,
        "temperature": 0,
        "text": " And at the end it's going to have this big array",
        "tokens": [
          50814,
          400,
          412,
          264,
          917,
          309,
          311,
          516,
          281,
          362,
          341,
          955,
          10225,
          50914
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8758.44,
        "id": 2691,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8754.44,
        "temperature": 0,
        "text": " Of all of the terminal elements of this new sentence",
        "tokens": [
          50914,
          2720,
          439,
          295,
          264,
          14709,
          4959,
          295,
          341,
          777,
          8174,
          51114
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8761.44,
        "id": 2692,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8758.44,
        "temperature": 0,
        "text": " And will join them with a space bar",
        "tokens": [
          51114,
          400,
          486,
          3917,
          552,
          365,
          257,
          1901,
          2159,
          51264
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8763.44,
        "id": 2693,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8761.44,
        "temperature": 0,
        "text": " And give you that result back which is displayed in the browser",
        "tokens": [
          51264,
          400,
          976,
          291,
          300,
          1874,
          646,
          597,
          307,
          16372,
          294,
          264,
          11185,
          51364
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8765.44,
        "id": 2694,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8763.44,
        "temperature": 0,
        "text": " So again just to summarize",
        "tokens": [
          51364,
          407,
          797,
          445,
          281,
          20858,
          51464
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8767.44,
        "id": 2695,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8765.44,
        "temperature": 0,
        "text": " I think if you want to work with context free grammars",
        "tokens": [
          51464,
          286,
          519,
          498,
          291,
          528,
          281,
          589,
          365,
          4319,
          1737,
          17570,
          685,
          51564
        ]
      },
      {
        "avg_logprob": -0.24593677805430852,
        "compression_ratio": 1.7371794871794872,
        "end": 8772.44,
        "id": 2696,
        "no_speech_prob": 0.013222347013652325,
        "seek": 874344,
        "start": 8767.44,
        "temperature": 0,
        "text": " Using a, using a JavaScript library like Tracery or Rita",
        "tokens": [
          51564,
          11142,
          257,
          11,
          1228,
          257,
          15778,
          6405,
          411,
          1765,
          326,
          2109,
          420,
          32672,
          51814
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8773.44,
        "id": 2697,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8772.44,
        "temperature": 0,
        "text": " Are both great options",
        "tokens": [
          50364,
          2014,
          1293,
          869,
          3956,
          50414
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8776.44,
        "id": 2698,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8773.44,
        "temperature": 0,
        "text": " If you're interested in digging into the algorithm itself",
        "tokens": [
          50414,
          759,
          291,
          434,
          3102,
          294,
          17343,
          666,
          264,
          9284,
          2564,
          50564
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8778.44,
        "id": 2699,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8776.44,
        "temperature": 0,
        "text": " This is now an example that kind of shows you that",
        "tokens": [
          50564,
          639,
          307,
          586,
          364,
          1365,
          300,
          733,
          295,
          3110,
          291,
          300,
          50664
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8781.44,
        "id": 2700,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8778.44,
        "temperature": 0,
        "text": " And just to kind of make this point a little bit more",
        "tokens": [
          50664,
          400,
          445,
          281,
          733,
          295,
          652,
          341,
          935,
          257,
          707,
          857,
          544,
          50814
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8784.44,
        "id": 2701,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8781.44,
        "temperature": 0,
        "text": " I want to show you that you can also find a whole bunch of examples of mine",
        "tokens": [
          50814,
          286,
          528,
          281,
          855,
          291,
          300,
          291,
          393,
          611,
          915,
          257,
          1379,
          3840,
          295,
          5110,
          295,
          3892,
          50964
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8786.44,
        "id": 2702,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8784.44,
        "temperature": 0,
        "text": " That do this and a little bit more",
        "tokens": [
          50964,
          663,
          360,
          341,
          293,
          257,
          707,
          857,
          544,
          51064
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8789.44,
        "id": 2703,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8786.44,
        "temperature": 0,
        "text": " So if you go to the A to Z GitHub repository",
        "tokens": [
          51064,
          407,
          498,
          291,
          352,
          281,
          264,
          316,
          281,
          1176,
          23331,
          25841,
          51214
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8792.44,
        "id": 2704,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8789.44,
        "temperature": 0,
        "text": " You'll see that I have a context",
        "tokens": [
          51214,
          509,
          603,
          536,
          300,
          286,
          362,
          257,
          4319,
          51364
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8795.44,
        "id": 2705,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8792.44,
        "temperature": 0,
        "text": " I have this same exact algorithm",
        "tokens": [
          51364,
          286,
          362,
          341,
          912,
          1900,
          9284,
          51514
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8797.44,
        "id": 2706,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8795.44,
        "temperature": 0,
        "text": " But packaged up into an object",
        "tokens": [
          51514,
          583,
          38162,
          493,
          666,
          364,
          2657,
          51614
        ]
      },
      {
        "avg_logprob": -0.1825669042525753,
        "compression_ratio": 1.7706766917293233,
        "end": 8800.44,
        "id": 2707,
        "no_speech_prob": 0.025177601724863052,
        "seek": 877244,
        "start": 8797.44,
        "temperature": 0,
        "text": " So this is a context free object",
        "tokens": [
          51614,
          407,
          341,
          307,
          257,
          4319,
          1737,
          2657,
          51764
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8802.44,
        "id": 2708,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8800.44,
        "temperature": 0,
        "text": " That has the rules object",
        "tokens": [
          50364,
          663,
          575,
          264,
          4474,
          2657,
          50464
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8803.44,
        "id": 2709,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8802.44,
        "temperature": 0,
        "text": " It has an add rule function",
        "tokens": [
          50464,
          467,
          575,
          364,
          909,
          4978,
          2445,
          50514
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8806.44,
        "id": 2710,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8803.44,
        "temperature": 0,
        "text": " So you can even look at this if you want to kind of think about",
        "tokens": [
          50514,
          407,
          291,
          393,
          754,
          574,
          412,
          341,
          498,
          291,
          528,
          281,
          733,
          295,
          519,
          466,
          50664
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8810.44,
        "id": 2711,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8806.44,
        "temperature": 0,
        "text": " Organizing this context free grammar into its own kind of library",
        "tokens": [
          50664,
          12538,
          3319,
          341,
          4319,
          1737,
          22317,
          666,
          1080,
          1065,
          733,
          295,
          6405,
          50864
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8811.44,
        "id": 2712,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8810.44,
        "temperature": 0,
        "text": " So to speak, much like Rita does",
        "tokens": [
          50864,
          407,
          281,
          1710,
          11,
          709,
          411,
          32672,
          775,
          50914
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8813.44,
        "id": 2713,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8811.44,
        "temperature": 0,
        "text": " Rita's more sophisticated than mine",
        "tokens": [
          50914,
          32672,
          311,
          544,
          16950,
          813,
          3892,
          51014
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8815.44,
        "id": 2714,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8813.44,
        "temperature": 0,
        "text": " So you can look at these examples",
        "tokens": [
          51014,
          407,
          291,
          393,
          574,
          412,
          613,
          5110,
          51114
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8817.44,
        "id": 2715,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8815.44,
        "temperature": 0,
        "text": " They do much in the same way of things",
        "tokens": [
          51114,
          814,
          360,
          709,
          294,
          264,
          912,
          636,
          295,
          721,
          51214
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8820.44,
        "id": 2716,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8817.44,
        "temperature": 0,
        "text": " That we, this is the exact same grammar actually",
        "tokens": [
          51214,
          663,
          321,
          11,
          341,
          307,
          264,
          1900,
          912,
          22317,
          767,
          51364
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8824.44,
        "id": 2717,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8820.44,
        "temperature": 0,
        "text": " You can look at this one which actually reads it from a JSON file",
        "tokens": [
          51364,
          509,
          393,
          574,
          412,
          341,
          472,
          597,
          767,
          15700,
          309,
          490,
          257,
          31828,
          3991,
          51564
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8827.44,
        "id": 2718,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8824.44,
        "temperature": 0,
        "text": " Does the haiku generation",
        "tokens": [
          51564,
          4402,
          264,
          324,
          24320,
          5125,
          51714
        ]
      },
      {
        "avg_logprob": -0.21448075593407476,
        "compression_ratio": 1.764505119453925,
        "end": 8829.44,
        "id": 2719,
        "no_speech_prob": 0.04602978378534317,
        "seek": 880044,
        "start": 8827.44,
        "temperature": 0,
        "text": " There's this other example that I want to show you",
        "tokens": [
          51714,
          821,
          311,
          341,
          661,
          1365,
          300,
          286,
          528,
          281,
          855,
          291,
          51814
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8831.44,
        "id": 2720,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8829.44,
        "temperature": 0,
        "text": " Because what it's actually doing",
        "tokens": [
          50364,
          1436,
          437,
          309,
          311,
          767,
          884,
          50464
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8834.44,
        "id": 2721,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8831.44,
        "temperature": 0,
        "text": " Is it's taking, this is doing something more",
        "tokens": [
          50464,
          1119,
          309,
          311,
          1940,
          11,
          341,
          307,
          884,
          746,
          544,
          50614
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8838.44,
        "id": 2722,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8834.44,
        "temperature": 0,
        "text": " It's using a text, a file I could upload or drag or paste in",
        "tokens": [
          50614,
          467,
          311,
          1228,
          257,
          2487,
          11,
          257,
          3991,
          286,
          727,
          6580,
          420,
          5286,
          420,
          9163,
          294,
          50814
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8841.44,
        "id": 2723,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8838.44,
        "temperature": 0,
        "text": " But it's actually generating the grammar on the fly",
        "tokens": [
          50814,
          583,
          309,
          311,
          767,
          17746,
          264,
          22317,
          322,
          264,
          3603,
          50964
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8843.44,
        "id": 2724,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8841.44,
        "temperature": 0,
        "text": " Based on input words",
        "tokens": [
          50964,
          18785,
          322,
          4846,
          2283,
          51064
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8846.44,
        "id": 2725,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8843.44,
        "temperature": 0,
        "text": " So here I have the text from the rainbow Wikipedia page",
        "tokens": [
          51064,
          407,
          510,
          286,
          362,
          264,
          2487,
          490,
          264,
          18526,
          28999,
          3028,
          51214
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8849.44,
        "id": 2726,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8846.44,
        "temperature": 0,
        "text": " And I could sort of generate haikus",
        "tokens": [
          51214,
          400,
          286,
          727,
          1333,
          295,
          8460,
          324,
          1035,
          301,
          51364
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8851.44,
        "id": 2727,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8849.44,
        "temperature": 0,
        "text": " With that particular text",
        "tokens": [
          51364,
          2022,
          300,
          1729,
          2487,
          51464
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8853.44,
        "id": 2728,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8851.44,
        "temperature": 0,
        "text": " You know, if I made up my own text",
        "tokens": [
          51464,
          509,
          458,
          11,
          498,
          286,
          1027,
          493,
          452,
          1065,
          2487,
          51564
        ]
      },
      {
        "avg_logprob": -0.18695283819127967,
        "compression_ratio": 1.6359832635983265,
        "end": 8855.44,
        "id": 2729,
        "no_speech_prob": 0.029757898300886154,
        "seek": 882944,
        "start": 8853.44,
        "temperature": 0,
        "text": " If I refresh this and said",
        "tokens": [
          51564,
          759,
          286,
          15134,
          341,
          293,
          848,
          51664
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8858.44,
        "id": 2730,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8856.44,
        "temperature": 0,
        "text": " Generate some haikus",
        "tokens": [
          50414,
          15409,
          473,
          512,
          324,
          1035,
          301,
          50514
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8868.44,
        "id": 2731,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8860.44,
        "temperature": 0,
        "text": " 1, 2, 3, 1, 1, 2, 3, happy, dancing, rainbows, unicorn",
        "tokens": [
          50614,
          502,
          11,
          568,
          11,
          805,
          11,
          502,
          11,
          502,
          11,
          568,
          11,
          805,
          11,
          2055,
          11,
          8898,
          11,
          4830,
          21118,
          11,
          28122,
          51014
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8871.44,
        "id": 2732,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8868.44,
        "temperature": 0,
        "text": " What else, what else?",
        "tokens": [
          51014,
          708,
          1646,
          11,
          437,
          1646,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8873.44,
        "id": 2733,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8871.44,
        "temperature": 0,
        "text": " Purple, pink, right?",
        "tokens": [
          51164,
          28483,
          11,
          7022,
          11,
          558,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8875.44,
        "id": 2734,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8873.44,
        "temperature": 0,
        "text": " We can sort of see I can generate the grammar",
        "tokens": [
          51264,
          492,
          393,
          1333,
          295,
          536,
          286,
          393,
          8460,
          264,
          22317,
          51364
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8876.44,
        "id": 2735,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8875.44,
        "temperature": 0,
        "text": " And I can generate some haikus",
        "tokens": [
          51364,
          400,
          286,
          393,
          8460,
          512,
          324,
          1035,
          301,
          51414
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8879.44,
        "id": 2736,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8876.44,
        "temperature": 0,
        "text": " And you can see I don't have any, I don't have enough stuff",
        "tokens": [
          51414,
          400,
          291,
          393,
          536,
          286,
          500,
          380,
          362,
          604,
          11,
          286,
          500,
          380,
          362,
          1547,
          1507,
          51564
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8881.44,
        "id": 2737,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8879.44,
        "temperature": 0,
        "text": " So I'm kind of getting some of the",
        "tokens": [
          51564,
          407,
          286,
          478,
          733,
          295,
          1242,
          512,
          295,
          264,
          51664
        ]
      },
      {
        "avg_logprob": -0.2277504937690601,
        "compression_ratio": 1.6857142857142857,
        "end": 8883.44,
        "id": 2738,
        "no_speech_prob": 0.23366808891296387,
        "seek": 885544,
        "start": 8881.44,
        "temperature": 0,
        "text": " These became terminal symbols because I don't have enough stuff",
        "tokens": [
          51664,
          1981,
          3062,
          14709,
          16944,
          570,
          286,
          500,
          380,
          362,
          1547,
          1507,
          51764
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8887.44,
        "id": 2739,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8883.44,
        "temperature": 0,
        "text": " But if I had, you can see haikus 2, unicorn, pink, pink, dancing 2",
        "tokens": [
          50364,
          583,
          498,
          286,
          632,
          11,
          291,
          393,
          536,
          324,
          1035,
          301,
          568,
          11,
          28122,
          11,
          7022,
          11,
          7022,
          11,
          8898,
          568,
          50564
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8889.44,
        "id": 2740,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8887.44,
        "temperature": 0,
        "text": " So this is also something you might want to think of",
        "tokens": [
          50564,
          407,
          341,
          307,
          611,
          746,
          291,
          1062,
          528,
          281,
          519,
          295,
          50664
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8891.44,
        "id": 2741,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8889.44,
        "temperature": 0,
        "text": " And this by the way also has a little button",
        "tokens": [
          50664,
          400,
          341,
          538,
          264,
          636,
          611,
          575,
          257,
          707,
          2960,
          50764
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8892.44,
        "id": 2742,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8891.44,
        "temperature": 0,
        "text": " That allows me to save that",
        "tokens": [
          50764,
          663,
          4045,
          385,
          281,
          3155,
          300,
          50814
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8896.44,
        "id": 2743,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8892.44,
        "temperature": 0,
        "text": " And I can actually look at the JSON file itself",
        "tokens": [
          50814,
          400,
          286,
          393,
          767,
          574,
          412,
          264,
          31828,
          3991,
          2564,
          51014
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8899.44,
        "id": 2744,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8896.44,
        "temperature": 0,
        "text": " That the program actually generates that grammar",
        "tokens": [
          51014,
          663,
          264,
          1461,
          767,
          23815,
          300,
          22317,
          51164
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8901.44,
        "id": 2745,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8899.44,
        "temperature": 0,
        "text": " And you can see here, it sort of calculates",
        "tokens": [
          51164,
          400,
          291,
          393,
          536,
          510,
          11,
          309,
          1333,
          295,
          4322,
          1024,
          51264
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8904.44,
        "id": 2746,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8901.44,
        "temperature": 0,
        "text": " And it sort of, it couldn't find any 4 syllable or 5 syllable words",
        "tokens": [
          51264,
          400,
          309,
          1333,
          295,
          11,
          309,
          2809,
          380,
          915,
          604,
          1017,
          40151,
          420,
          1025,
          40151,
          2283,
          51414
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8906.44,
        "id": 2747,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8904.44,
        "temperature": 0,
        "text": " In the seed text that I gave it",
        "tokens": [
          51414,
          682,
          264,
          8871,
          2487,
          300,
          286,
          2729,
          309,
          51514
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8909.44,
        "id": 2748,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8906.44,
        "temperature": 0,
        "text": " So I'm going to see if there's any other",
        "tokens": [
          51514,
          407,
          286,
          478,
          516,
          281,
          536,
          498,
          456,
          311,
          604,
          661,
          51664
        ]
      },
      {
        "avg_logprob": -0.21787755018999788,
        "compression_ratio": 1.7049180327868851,
        "end": 8912.44,
        "id": 2749,
        "no_speech_prob": 0.07055450230836868,
        "seek": 888344,
        "start": 8909.44,
        "temperature": 0,
        "text": " Yeah, so that's, I want to make another video",
        "tokens": [
          51664,
          865,
          11,
          370,
          300,
          311,
          11,
          286,
          528,
          281,
          652,
          1071,
          960,
          51814
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8915.44,
        "id": 2750,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8912.44,
        "temperature": 0,
        "text": " Where I sort of maybe tie into context free grammars with L-systems",
        "tokens": [
          50364,
          2305,
          286,
          1333,
          295,
          1310,
          7582,
          666,
          4319,
          1737,
          17570,
          685,
          365,
          441,
          12,
          28215,
          82,
          50514
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8918.44,
        "id": 2751,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8915.44,
        "temperature": 0,
        "text": " I encourage you to sort of look at some of my other videos about L-systems",
        "tokens": [
          50514,
          286,
          5373,
          291,
          281,
          1333,
          295,
          574,
          412,
          512,
          295,
          452,
          661,
          2145,
          466,
          441,
          12,
          28215,
          82,
          50664
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8920.44,
        "id": 2752,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8918.44,
        "temperature": 0,
        "text": " Which are a context free grammar",
        "tokens": [
          50664,
          3013,
          366,
          257,
          4319,
          1737,
          22317,
          50764
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8924.44,
        "id": 2753,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8920.44,
        "temperature": 0,
        "text": " But the idea of them is to create graphics",
        "tokens": [
          50764,
          583,
          264,
          1558,
          295,
          552,
          307,
          281,
          1884,
          11837,
          50964
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8927.44,
        "id": 2754,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8924.44,
        "temperature": 0,
        "text": " And I will do one wrap up video to talk about",
        "tokens": [
          50964,
          400,
          286,
          486,
          360,
          472,
          7019,
          493,
          960,
          281,
          751,
          466,
          51114
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8929.44,
        "id": 2755,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8927.44,
        "temperature": 0,
        "text": " Some exercise ideas that you might make",
        "tokens": [
          51114,
          2188,
          5380,
          3487,
          300,
          291,
          1062,
          652,
          51214
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8931.44,
        "id": 2756,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8929.44,
        "temperature": 0,
        "text": " And certainly one of the things that I'll talk about",
        "tokens": [
          51214,
          400,
          3297,
          472,
          295,
          264,
          721,
          300,
          286,
          603,
          751,
          466,
          51314
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8933.44,
        "id": 2757,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8931.44,
        "temperature": 0,
        "text": " And I'm mentioning this now because I don't know if I have time to make that video today",
        "tokens": [
          51314,
          400,
          286,
          478,
          18315,
          341,
          586,
          570,
          286,
          500,
          380,
          458,
          498,
          286,
          362,
          565,
          281,
          652,
          300,
          960,
          965,
          51414
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8934.44,
        "id": 2758,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8933.44,
        "temperature": 0,
        "text": " But it will come eventually",
        "tokens": [
          51414,
          583,
          309,
          486,
          808,
          4728,
          51464
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8937.44,
        "id": 2759,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8934.44,
        "temperature": 0,
        "text": " Is you might think of what if the elements of this grammar, right?",
        "tokens": [
          51464,
          1119,
          291,
          1062,
          519,
          295,
          437,
          498,
          264,
          4959,
          295,
          341,
          22317,
          11,
          558,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.22736965409861315,
        "compression_ratio": 1.8075709779179812,
        "end": 8939.44,
        "id": 2760,
        "no_speech_prob": 0.14800985157489777,
        "seek": 891244,
        "start": 8937.44,
        "temperature": 0,
        "text": " Aren't words, but musical notes",
        "tokens": [
          51614,
          15464,
          380,
          2283,
          11,
          457,
          9165,
          5570,
          51714
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8941.44,
        "id": 2761,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8939.44,
        "temperature": 0,
        "text": " Or design elements, color form",
        "tokens": [
          50364,
          1610,
          1715,
          4959,
          11,
          2017,
          1254,
          50464
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8944.44,
        "id": 2762,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8941.44,
        "temperature": 0,
        "text": " How could you use a context free grammar to generate visual designs",
        "tokens": [
          50464,
          1012,
          727,
          291,
          764,
          257,
          4319,
          1737,
          22317,
          281,
          8460,
          5056,
          11347,
          50614
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8947.44,
        "id": 2763,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8944.44,
        "temperature": 0,
        "text": " Generate music, other types of things beyond just text",
        "tokens": [
          50614,
          15409,
          473,
          1318,
          11,
          661,
          3467,
          295,
          721,
          4399,
          445,
          2487,
          50764
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8949.44,
        "id": 2764,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8947.44,
        "temperature": 0,
        "text": " Okay, so I hope you enjoyed this coding challenge",
        "tokens": [
          50764,
          1033,
          11,
          370,
          286,
          1454,
          291,
          4626,
          341,
          17720,
          3430,
          50864
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8951.44,
        "id": 2765,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8949.44,
        "temperature": 0,
        "text": " Of kind of coding a context free grammar from scratch",
        "tokens": [
          50864,
          2720,
          733,
          295,
          17720,
          257,
          4319,
          1737,
          22317,
          490,
          8459,
          50964
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8954.44,
        "id": 2766,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8951.44,
        "temperature": 0,
        "text": " And I'll see you in a future one at some point in the future",
        "tokens": [
          50964,
          400,
          286,
          603,
          536,
          291,
          294,
          257,
          2027,
          472,
          412,
          512,
          935,
          294,
          264,
          2027,
          51114
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8959.44,
        "id": 2767,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8954.44,
        "temperature": 0,
        "text": " Okay, everyone, I'm going to mute myself for a second",
        "tokens": [
          51114,
          1033,
          11,
          1518,
          11,
          286,
          478,
          516,
          281,
          24523,
          2059,
          337,
          257,
          1150,
          51364
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8961.44,
        "id": 2768,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8959.44,
        "temperature": 0,
        "text": " And check and see what's happening",
        "tokens": [
          51364,
          400,
          1520,
          293,
          536,
          437,
          311,
          2737,
          51464
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8964.44,
        "id": 2769,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8961.44,
        "temperature": 0,
        "text": " And then I'll come back and sort of wrap things up",
        "tokens": [
          51464,
          400,
          550,
          286,
          603,
          808,
          646,
          293,
          1333,
          295,
          7019,
          721,
          493,
          51614
        ]
      },
      {
        "avg_logprob": -0.21732088923454285,
        "compression_ratio": 1.7659574468085106,
        "end": 8966.44,
        "id": 2770,
        "no_speech_prob": 0.13649441301822662,
        "seek": 893944,
        "start": 8964.44,
        "temperature": 0,
        "text": " I'm going to give you the this dot song",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          976,
          291,
          264,
          341,
          5893,
          2153,
          51714
        ]
      },
      {
        "avg_logprob": -0.6987722396850586,
        "compression_ratio": 0.9354838709677419,
        "end": 8968.44,
        "id": 2771,
        "no_speech_prob": 0.9343924522399902,
        "seek": 896644,
        "start": 8966.44,
        "temperature": 1,
        "text": " As always, I always forget to",
        "tokens": [
          50364,
          1018,
          1009,
          11,
          286,
          1009,
          2870,
          281,
          50464
        ]
      },
      {
        "avg_logprob": -0.5045138888888889,
        "compression_ratio": 1.673913043478261,
        "end": 9031.6,
        "id": 2772,
        "no_speech_prob": 0.5272758603096008,
        "seek": 902644,
        "start": 9026.44,
        "temperature": 0,
        "text": " do the this dot. I'm gonna do the this dot. This dot, this dot, this dot, the this dot",
        "tokens": [
          50364,
          360,
          264,
          341,
          5893,
          13,
          286,
          478,
          799,
          360,
          264,
          341,
          5893,
          13,
          639,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          264,
          341,
          5893,
          50622
        ]
      },
      {
        "avg_logprob": -0.5045138888888889,
        "compression_ratio": 1.673913043478261,
        "end": 9035.6,
        "id": 2773,
        "no_speech_prob": 0.5272758603096008,
        "seek": 902644,
        "start": 9031.6,
        "temperature": 0,
        "text": " song. Never forget the this dot. Somebody compose that song for me.",
        "tokens": [
          50622,
          2153,
          13,
          7344,
          2870,
          264,
          341,
          5893,
          13,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.9780851602554321,
        "compression_ratio": 0.2727272727272727,
        "end": 9058.5,
        "id": 2774,
        "no_speech_prob": 0.9815179705619812,
        "seek": 905644,
        "start": 9056.44,
        "temperature": 0,
        "text": " you",
        "tokens": [
          50364,
          291,
          50467
        ]
      },
      {
        "avg_logprob": -0.40922463108116475,
        "compression_ratio": 1.4339622641509433,
        "end": 9106.44,
        "id": 2775,
        "no_speech_prob": 0.14404551684856415,
        "seek": 908644,
        "start": 9086.44,
        "temperature": 0,
        "text": " The music end. Okay, I'm back everybody. Okay, so what I think I do have five minutes to record kind of like I kind of just did it at the end of...",
        "tokens": [
          50364,
          440,
          1318,
          917,
          13,
          1033,
          11,
          286,
          478,
          646,
          2201,
          13,
          1033,
          11,
          370,
          437,
          286,
          519,
          286,
          360,
          362,
          1732,
          2077,
          281,
          2136,
          733,
          295,
          411,
          286,
          733,
          295,
          445,
          630,
          309,
          412,
          264,
          917,
          295,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.40922463108116475,
        "compression_ratio": 1.4339622641509433,
        "end": 9110.44,
        "id": 2776,
        "no_speech_prob": 0.14404551684856415,
        "seek": 908644,
        "start": 9106.44,
        "temperature": 0,
        "text": " Oh wait, I don't, I can't see where I am. Can you hear me? Yes, you can hear me.",
        "tokens": [
          51364,
          876,
          1699,
          11,
          286,
          500,
          380,
          11,
          286,
          393,
          380,
          536,
          689,
          286,
          669,
          13,
          1664,
          291,
          1568,
          385,
          30,
          1079,
          11,
          291,
          393,
          1568,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2842252548426798,
        "compression_ratio": 1.4329896907216495,
        "end": 9116.44,
        "id": 2777,
        "no_speech_prob": 0.3006773591041565,
        "seek": 911044,
        "start": 9110.44,
        "temperature": 0,
        "text": " Boy, someday I'll just come back and redo all these videos. That's what I always say.",
        "tokens": [
          50364,
          9486,
          11,
          19412,
          286,
          603,
          445,
          808,
          646,
          293,
          29956,
          439,
          613,
          2145,
          13,
          663,
          311,
          437,
          286,
          1009,
          584,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2842252548426798,
        "compression_ratio": 1.4329896907216495,
        "end": 9122.44,
        "id": 2778,
        "no_speech_prob": 0.3006773591041565,
        "seek": 911044,
        "start": 9116.44,
        "temperature": 0,
        "text": " I think what I will do is record a quick wrap-up video even though I tried to just do it there.",
        "tokens": [
          50664,
          286,
          519,
          437,
          286,
          486,
          360,
          307,
          2136,
          257,
          1702,
          7019,
          12,
          1010,
          960,
          754,
          1673,
          286,
          3031,
          281,
          445,
          360,
          309,
          456,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2842252548426798,
        "compression_ratio": 1.4329896907216495,
        "end": 9132.44,
        "id": 2779,
        "no_speech_prob": 0.3006773591041565,
        "seek": 911044,
        "start": 9122.44,
        "temperature": 0,
        "text": " For thinking about an exercise for using a context-free grammar. Coding pineapple I really like.",
        "tokens": [
          50964,
          1171,
          1953,
          466,
          364,
          5380,
          337,
          1228,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          383,
          8616,
          25740,
          286,
          534,
          411,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.3077661799288344,
        "compression_ratio": 1.5253456221198156,
        "end": 9143.44,
        "id": 2780,
        "no_speech_prob": 0.3275306522846222,
        "seek": 913244,
        "start": 9132.44,
        "temperature": 0,
        "text": " And then I'll be finished. Maybe I'll answer a question or two. I'm actually gonna record another video not on a live stream with a guest.",
        "tokens": [
          50364,
          400,
          550,
          286,
          603,
          312,
          4335,
          13,
          2704,
          286,
          603,
          1867,
          257,
          1168,
          420,
          732,
          13,
          286,
          478,
          767,
          799,
          2136,
          1071,
          960,
          406,
          322,
          257,
          1621,
          4309,
          365,
          257,
          8341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3077661799288344,
        "compression_ratio": 1.5253456221198156,
        "end": 9147.44,
        "id": 2781,
        "no_speech_prob": 0.3275306522846222,
        "seek": 913244,
        "start": 9143.44,
        "temperature": 0,
        "text": " And so you'll stay, hopefully you'll look forward to that coming sometime later this week. I'll publish it.",
        "tokens": [
          50914,
          400,
          370,
          291,
          603,
          1754,
          11,
          4696,
          291,
          603,
          574,
          2128,
          281,
          300,
          1348,
          15053,
          1780,
          341,
          1243,
          13,
          286,
          603,
          11374,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3077661799288344,
        "compression_ratio": 1.5253456221198156,
        "end": 9159.44,
        "id": 2782,
        "no_speech_prob": 0.3275306522846222,
        "seek": 913244,
        "start": 9147.44,
        "temperature": 0,
        "text": " And that's that. So, okay, so let me think about this wrap-up for session six video.",
        "tokens": [
          51114,
          400,
          300,
          311,
          300,
          13,
          407,
          11,
          1392,
          11,
          370,
          718,
          385,
          519,
          466,
          341,
          7019,
          12,
          1010,
          337,
          5481,
          2309,
          960,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22537835036651999,
        "compression_ratio": 1.5,
        "end": 9167.44,
        "id": 2783,
        "no_speech_prob": 0.037320658564567566,
        "seek": 915944,
        "start": 9159.44,
        "temperature": 0,
        "text": " Which, I don't know why I just did that in the previous video because what I meant to do was kind of go through these examples.",
        "tokens": [
          50364,
          3013,
          11,
          286,
          500,
          380,
          458,
          983,
          286,
          445,
          630,
          300,
          294,
          264,
          3894,
          960,
          570,
          437,
          286,
          4140,
          281,
          360,
          390,
          733,
          295,
          352,
          807,
          613,
          5110,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22537835036651999,
        "compression_ratio": 1.5,
        "end": 9177.44,
        "id": 2784,
        "no_speech_prob": 0.037320658564567566,
        "seek": 915944,
        "start": 9167.44,
        "temperature": 0,
        "text": " But, such is life. Okay, I'm gonna do this anyway and if it's unnecessary it is what it is.",
        "tokens": [
          50764,
          583,
          11,
          1270,
          307,
          993,
          13,
          1033,
          11,
          286,
          478,
          799,
          360,
          341,
          4033,
          293,
          498,
          309,
          311,
          19350,
          309,
          307,
          437,
          309,
          307,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22537835036651999,
        "compression_ratio": 1.5,
        "end": 9182.44,
        "id": 2785,
        "no_speech_prob": 0.037320658564567566,
        "seek": 915944,
        "start": 9177.44,
        "temperature": 0,
        "text": " Or redundant, it is what it is. Okay, let me cycle the camera.",
        "tokens": [
          51264,
          1610,
          40997,
          11,
          309,
          307,
          437,
          309,
          307,
          13,
          1033,
          11,
          718,
          385,
          6586,
          264,
          2799,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2603828596032184,
        "compression_ratio": 1.0129870129870129,
        "end": 9199.44,
        "id": 2786,
        "no_speech_prob": 0.06655678153038025,
        "seek": 918244,
        "start": 9182.44,
        "temperature": 0,
        "text": " Alright, what's going on with the dislike and liking? I'm looking at the chat.",
        "tokens": [
          50364,
          2798,
          11,
          437,
          311,
          516,
          322,
          365,
          264,
          26006,
          293,
          16933,
          30,
          286,
          478,
          1237,
          412,
          264,
          5081,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.31100164140973774,
        "compression_ratio": 1.1132075471698113,
        "end": 9220.44,
        "id": 2787,
        "no_speech_prob": 0.044014669954776764,
        "seek": 919944,
        "start": 9199.44,
        "temperature": 0,
        "text": " Okay, let's see here. What should I, I think I will. I'm gonna end with my lovely children's Once Upon a Time stories.",
        "tokens": [
          50364,
          1033,
          11,
          718,
          311,
          536,
          510,
          13,
          708,
          820,
          286,
          11,
          286,
          519,
          286,
          486,
          13,
          286,
          478,
          799,
          917,
          365,
          452,
          7496,
          2227,
          311,
          3443,
          25184,
          257,
          6161,
          3676,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2574761708577474,
        "compression_ratio": 1.5674603174603174,
        "end": 9227.44,
        "id": 2788,
        "no_speech_prob": 0.1241927519440651,
        "seek": 922044,
        "start": 9221.44,
        "temperature": 0,
        "text": " And this will be my write your own story. Okay, I have some things to say about this. Excellent.",
        "tokens": [
          50414,
          400,
          341,
          486,
          312,
          452,
          2464,
          428,
          1065,
          1657,
          13,
          1033,
          11,
          286,
          362,
          512,
          721,
          281,
          584,
          466,
          341,
          13,
          16723,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2574761708577474,
        "compression_ratio": 1.5674603174603174,
        "end": 9239.44,
        "id": 2789,
        "no_speech_prob": 0.1241927519440651,
        "seek": 922044,
        "start": 9227.44,
        "temperature": 0,
        "text": " Okay. Hello, welcome to a wrap-up video for session seven of programming from A to Z on this YouTube channel of mine that has an undefined name at the moment.",
        "tokens": [
          50714,
          1033,
          13,
          2425,
          11,
          2928,
          281,
          257,
          7019,
          12,
          1010,
          960,
          337,
          5481,
          3407,
          295,
          9410,
          490,
          316,
          281,
          1176,
          322,
          341,
          3088,
          2269,
          295,
          3892,
          300,
          575,
          364,
          674,
          5666,
          2001,
          1315,
          412,
          264,
          1623,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2574761708577474,
        "compression_ratio": 1.5674603174603174,
        "end": 9245.44,
        "id": 2790,
        "no_speech_prob": 0.1241927519440651,
        "seek": 922044,
        "start": 9239.44,
        "temperature": 0,
        "text": " But someday it might have a defined name. So, what I'm asking for you to do as a homework exercise for this particular session on grammars,",
        "tokens": [
          51314,
          583,
          19412,
          309,
          1062,
          362,
          257,
          7642,
          1315,
          13,
          407,
          11,
          437,
          286,
          478,
          3365,
          337,
          291,
          281,
          360,
          382,
          257,
          14578,
          5380,
          337,
          341,
          1729,
          5481,
          322,
          17570,
          685,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.23675231646774406,
        "compression_ratio": 1.7910958904109588,
        "end": 9250.44,
        "id": 2791,
        "no_speech_prob": 0.0627826675772667,
        "seek": 924544,
        "start": 9245.44,
        "temperature": 0,
        "text": " specifically context-free grammars, is essentially to write a computer, well, there's a lot of things you could do.",
        "tokens": [
          50364,
          4682,
          4319,
          12,
          10792,
          17570,
          685,
          11,
          307,
          4476,
          281,
          2464,
          257,
          3820,
          11,
          731,
          11,
          456,
          311,
          257,
          688,
          295,
          721,
          291,
          727,
          360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23675231646774406,
        "compression_ratio": 1.7910958904109588,
        "end": 9254.44,
        "id": 2792,
        "no_speech_prob": 0.0627826675772667,
        "seek": 924544,
        "start": 9250.44,
        "temperature": 0,
        "text": " But if you're looking for something, have a computer program write your own story.",
        "tokens": [
          50614,
          583,
          498,
          291,
          434,
          1237,
          337,
          746,
          11,
          362,
          257,
          3820,
          1461,
          2464,
          428,
          1065,
          1657,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23675231646774406,
        "compression_ratio": 1.7910958904109588,
        "end": 9258.44,
        "id": 2793,
        "no_speech_prob": 0.0627826675772667,
        "seek": 924544,
        "start": 9254.44,
        "temperature": 0,
        "text": " And write that story differently each time. So you can see this one example that was written by a,",
        "tokens": [
          50814,
          400,
          2464,
          300,
          1657,
          7614,
          1184,
          565,
          13,
          407,
          291,
          393,
          536,
          341,
          472,
          1365,
          300,
          390,
          3720,
          538,
          257,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.23675231646774406,
        "compression_ratio": 1.7910958904109588,
        "end": 9262.44,
        "id": 2794,
        "no_speech_prob": 0.0627826675772667,
        "seek": 924544,
        "start": 9258.44,
        "temperature": 0,
        "text": " this was written by a five-year-old and an eight-year-old together collaboratively.",
        "tokens": [
          51014,
          341,
          390,
          3720,
          538,
          257,
          1732,
          12,
          5294,
          12,
          2641,
          293,
          364,
          3180,
          12,
          5294,
          12,
          2641,
          1214,
          16555,
          356,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23675231646774406,
        "compression_ratio": 1.7910958904109588,
        "end": 9267.44,
        "id": 2795,
        "no_speech_prob": 0.0627826675772667,
        "seek": 924544,
        "start": 9262.44,
        "temperature": 0,
        "text": " And using the tracery grammar. So that might be a first thing that you start.",
        "tokens": [
          51214,
          400,
          1228,
          264,
          504,
          326,
          2109,
          22317,
          13,
          407,
          300,
          1062,
          312,
          257,
          700,
          551,
          300,
          291,
          722,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23675231646774406,
        "compression_ratio": 1.7910958904109588,
        "end": 9270.44,
        "id": 2796,
        "no_speech_prob": 0.0627826675772667,
        "seek": 924544,
        "start": 9267.44,
        "temperature": 0,
        "text": " Find this example, link to in this video, and modify the story.",
        "tokens": [
          51464,
          11809,
          341,
          1365,
          11,
          2113,
          281,
          294,
          341,
          960,
          11,
          293,
          16927,
          264,
          1657,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22908567002982147,
        "compression_ratio": 1.7624113475177305,
        "end": 9277.44,
        "id": 2797,
        "no_speech_prob": 0.21201208233833313,
        "seek": 927044,
        "start": 9271.44,
        "temperature": 0,
        "text": " Really, I think one thing to think about is like how much variation can you embed into the grammar.",
        "tokens": [
          50414,
          4083,
          11,
          286,
          519,
          472,
          551,
          281,
          519,
          466,
          307,
          411,
          577,
          709,
          12990,
          393,
          291,
          12240,
          666,
          264,
          22317,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22908567002982147,
        "compression_ratio": 1.7624113475177305,
        "end": 9283.44,
        "id": 2798,
        "no_speech_prob": 0.21201208233833313,
        "seek": 927044,
        "start": 9277.44,
        "temperature": 0,
        "text": " Can the story sometimes only be one sentence long? And sometimes be, you know, hundreds or thousands of words long.",
        "tokens": [
          50714,
          1664,
          264,
          1657,
          2171,
          787,
          312,
          472,
          8174,
          938,
          30,
          400,
          2171,
          312,
          11,
          291,
          458,
          11,
          6779,
          420,
          5383,
          295,
          2283,
          938,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22908567002982147,
        "compression_ratio": 1.7624113475177305,
        "end": 9290.44,
        "id": 2799,
        "no_speech_prob": 0.21201208233833313,
        "seek": 927044,
        "start": 9283.44,
        "temperature": 0,
        "text": " So think about this sort of like how you might really explore variety and parameterize, if that's even a word to use,",
        "tokens": [
          51014,
          407,
          519,
          466,
          341,
          1333,
          295,
          411,
          577,
          291,
          1062,
          534,
          6839,
          5673,
          293,
          13075,
          1125,
          11,
          498,
          300,
          311,
          754,
          257,
          1349,
          281,
          764,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.22908567002982147,
        "compression_ratio": 1.7624113475177305,
        "end": 9294.44,
        "id": 2800,
        "no_speech_prob": 0.21201208233833313,
        "seek": 927044,
        "start": 9290.44,
        "temperature": 0,
        "text": " the way that the grammar works, how nested or unnested it could be.",
        "tokens": [
          51364,
          264,
          636,
          300,
          264,
          22317,
          1985,
          11,
          577,
          15646,
          292,
          420,
          517,
          77,
          21885,
          309,
          727,
          312,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22908567002982147,
        "compression_ratio": 1.7624113475177305,
        "end": 9299.44,
        "id": 2801,
        "no_speech_prob": 0.21201208233833313,
        "seek": 927044,
        "start": 9294.44,
        "temperature": 0,
        "text": " So you can think about writing a story. The other thing that grammars are particularly good at,",
        "tokens": [
          51564,
          407,
          291,
          393,
          519,
          466,
          3579,
          257,
          1657,
          13,
          440,
          661,
          551,
          300,
          17570,
          685,
          366,
          4098,
          665,
          412,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9304.44,
        "id": 2802,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9299.44,
        "temperature": 0,
        "text": " context-free grammars are generating text that fits into a very sort of prescriptive pattern.",
        "tokens": [
          50364,
          4319,
          12,
          10792,
          17570,
          685,
          366,
          17746,
          2487,
          300,
          9001,
          666,
          257,
          588,
          1333,
          295,
          1183,
          5944,
          488,
          5102,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9309.44,
        "id": 2803,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9304.44,
        "temperature": 0,
        "text": " So one of my favorite bots on Twitter is the art assignment bot.",
        "tokens": [
          50614,
          407,
          472,
          295,
          452,
          2954,
          35410,
          322,
          5794,
          307,
          264,
          1523,
          15187,
          10592,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9315.44,
        "id": 2804,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9309.44,
        "temperature": 0,
        "text": " And you can skip the exercise that I'm talking about. You can just do this one, which is from 42 minutes ago.",
        "tokens": [
          50864,
          400,
          291,
          393,
          10023,
          264,
          5380,
          300,
          286,
          478,
          1417,
          466,
          13,
          509,
          393,
          445,
          360,
          341,
          472,
          11,
          597,
          307,
          490,
          14034,
          2077,
          2057,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9318.44,
        "id": 2805,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9315.44,
        "temperature": 0,
        "text": " Construct a wood carving researching the history of embosses.",
        "tokens": [
          51164,
          8574,
          1757,
          257,
          4576,
          31872,
          24176,
          264,
          2503,
          295,
          4605,
          772,
          279,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9321.44,
        "id": 2806,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9318.44,
        "temperature": 0,
        "text": " Due on Thursday, May 25th, 2017.",
        "tokens": [
          51314,
          18980,
          322,
          10383,
          11,
          1891,
          3552,
          392,
          11,
          6591,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9324.44,
        "id": 2807,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9321.44,
        "temperature": 0,
        "text": " Or build a photograph about tools. Due on Tuesday, November 2nd.",
        "tokens": [
          51464,
          1610,
          1322,
          257,
          8348,
          466,
          3873,
          13,
          18980,
          322,
          10017,
          11,
          7674,
          568,
          273,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20655884502602995,
        "compression_ratio": 1.6253869969040247,
        "end": 9328.44,
        "id": 2808,
        "no_speech_prob": 0.01115762535482645,
        "seek": 929944,
        "start": 9324.44,
        "temperature": 0,
        "text": " So this you can see, you can really, I don't know that this is made with a context-free grammar.",
        "tokens": [
          51614,
          407,
          341,
          291,
          393,
          536,
          11,
          291,
          393,
          534,
          11,
          286,
          500,
          380,
          458,
          300,
          341,
          307,
          1027,
          365,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9332.44,
        "id": 2809,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9328.44,
        "temperature": 0,
        "text": " But you could imagine describing the grammar for this.",
        "tokens": [
          50364,
          583,
          291,
          727,
          3811,
          16141,
          264,
          22317,
          337,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9336.44,
        "id": 2810,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9332.44,
        "temperature": 0,
        "text": " So if you were to create a spell book, I think is a classic scenario,",
        "tokens": [
          50564,
          407,
          498,
          291,
          645,
          281,
          1884,
          257,
          9827,
          1446,
          11,
          286,
          519,
          307,
          257,
          7230,
          9005,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9339.44,
        "id": 2811,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9336.44,
        "temperature": 0,
        "text": " that there are some tracery examples that do this.",
        "tokens": [
          50764,
          300,
          456,
          366,
          512,
          504,
          326,
          2109,
          5110,
          300,
          360,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9344.44,
        "id": 2812,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9339.44,
        "temperature": 0,
        "text": " Creating a recipe book, or what types of kind of statements define statements.",
        "tokens": [
          50914,
          40002,
          257,
          6782,
          1446,
          11,
          420,
          437,
          3467,
          295,
          733,
          295,
          12363,
          6964,
          12363,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9350.44,
        "id": 2813,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9344.44,
        "temperature": 0,
        "text": " The other thing that I think is, you know, what I've done in these two sessions is I've showed you Markov chains.",
        "tokens": [
          51164,
          440,
          661,
          551,
          300,
          286,
          519,
          307,
          11,
          291,
          458,
          11,
          437,
          286,
          600,
          1096,
          294,
          613,
          732,
          11081,
          307,
          286,
          600,
          4712,
          291,
          3934,
          5179,
          12626,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9353.44,
        "id": 2814,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9350.44,
        "temperature": 0,
        "text": " Here's what a Markov chain is, and here's what a Markov chain does.",
        "tokens": [
          51464,
          1692,
          311,
          437,
          257,
          3934,
          5179,
          5021,
          307,
          11,
          293,
          510,
          311,
          437,
          257,
          3934,
          5179,
          5021,
          775,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19381820291712665,
        "compression_ratio": 1.933085501858736,
        "end": 9356.44,
        "id": 2815,
        "no_speech_prob": 0.003824369516223669,
        "seek": 932844,
        "start": 9353.44,
        "temperature": 0,
        "text": " Here's what a context-free grammar is, and here's what a context-free grammar does.",
        "tokens": [
          51614,
          1692,
          311,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          307,
          11,
          293,
          510,
          311,
          437,
          257,
          4319,
          12,
          10792,
          22317,
          775,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22266794505872226,
        "compression_ratio": 1.6159169550173011,
        "end": 9361.44,
        "id": 2816,
        "no_speech_prob": 0.03021087683737278,
        "seek": 935644,
        "start": 9356.44,
        "temperature": 0,
        "text": " So on the one hand, an exercise is just take my exact examples and produce output.",
        "tokens": [
          50364,
          407,
          322,
          264,
          472,
          1011,
          11,
          364,
          5380,
          307,
          445,
          747,
          452,
          1900,
          5110,
          293,
          5258,
          5598,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22266794505872226,
        "compression_ratio": 1.6159169550173011,
        "end": 9366.44,
        "id": 2817,
        "no_speech_prob": 0.03021087683737278,
        "seek": 935644,
        "start": 9361.44,
        "temperature": 0,
        "text": " But I think really the magic of a project happens in the spaces in between.",
        "tokens": [
          50614,
          583,
          286,
          519,
          534,
          264,
          5585,
          295,
          257,
          1716,
          2314,
          294,
          264,
          7673,
          294,
          1296,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22266794505872226,
        "compression_ratio": 1.6159169550173011,
        "end": 9370.44,
        "id": 2818,
        "no_speech_prob": 0.03021087683737278,
        "seek": 935644,
        "start": 9366.44,
        "temperature": 0,
        "text": " So maybe a Markov chain is just a little piece of one word inside of some text you're generating.",
        "tokens": [
          50864,
          407,
          1310,
          257,
          3934,
          5179,
          5021,
          307,
          445,
          257,
          707,
          2522,
          295,
          472,
          1349,
          1854,
          295,
          512,
          2487,
          291,
          434,
          17746,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22266794505872226,
        "compression_ratio": 1.6159169550173011,
        "end": 9376.44,
        "id": 2819,
        "no_speech_prob": 0.03021087683737278,
        "seek": 935644,
        "start": 9370.44,
        "temperature": 0,
        "text": " And the context-free grammar just creates an overall structure, also interfaces with an API.",
        "tokens": [
          51064,
          400,
          264,
          4319,
          12,
          10792,
          22317,
          445,
          7829,
          364,
          4787,
          3877,
          11,
          611,
          28416,
          365,
          364,
          9362,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22266794505872226,
        "compression_ratio": 1.6159169550173011,
        "end": 9379.44,
        "id": 2820,
        "no_speech_prob": 0.03021087683737278,
        "seek": 935644,
        "start": 9376.44,
        "temperature": 0,
        "text": " So how is it that these could be a piece of the project?",
        "tokens": [
          51364,
          407,
          577,
          307,
          309,
          300,
          613,
          727,
          312,
          257,
          2522,
          295,
          264,
          1716,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.22266794505872226,
        "compression_ratio": 1.6159169550173011,
        "end": 9382.44,
        "id": 2821,
        "no_speech_prob": 0.03021087683737278,
        "seek": 935644,
        "start": 9379.44,
        "temperature": 0,
        "text": " And also really, in thinking about what's your presentation?",
        "tokens": [
          51514,
          400,
          611,
          534,
          11,
          294,
          1953,
          466,
          437,
          311,
          428,
          5860,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1866953933940214,
        "compression_ratio": 1.678343949044586,
        "end": 9389.44,
        "id": 2822,
        "no_speech_prob": 0.20685574412345886,
        "seek": 938244,
        "start": 9382.44,
        "temperature": 0,
        "text": " So on the one hand, if you look at any of my examples, you know, this is just generating little sentences.",
        "tokens": [
          50364,
          407,
          322,
          264,
          472,
          1011,
          11,
          498,
          291,
          574,
          412,
          604,
          295,
          452,
          5110,
          11,
          291,
          458,
          11,
          341,
          307,
          445,
          17746,
          707,
          16579,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1866953933940214,
        "compression_ratio": 1.678343949044586,
        "end": 9392.44,
        "id": 2823,
        "no_speech_prob": 0.20685574412345886,
        "seek": 938244,
        "start": 9389.44,
        "temperature": 0,
        "text": " But who is the character that's speaking?",
        "tokens": [
          50714,
          583,
          567,
          307,
          264,
          2517,
          300,
          311,
          4124,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.1866953933940214,
        "compression_ratio": 1.678343949044586,
        "end": 9395.44,
        "id": 2824,
        "no_speech_prob": 0.20685574412345886,
        "seek": 938244,
        "start": 9392.44,
        "temperature": 0,
        "text": " You know, what's the context? Is it a Twitter bot? Is it a web page?",
        "tokens": [
          50864,
          509,
          458,
          11,
          437,
          311,
          264,
          4319,
          30,
          1119,
          309,
          257,
          5794,
          10592,
          30,
          1119,
          309,
          257,
          3670,
          3028,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1866953933940214,
        "compression_ratio": 1.678343949044586,
        "end": 9401.44,
        "id": 2825,
        "no_speech_prob": 0.20685574412345886,
        "seek": 938244,
        "start": 9395.44,
        "temperature": 0,
        "text": " There's a wonderful project in my class today that was looking at generating fake election ballots.",
        "tokens": [
          51014,
          821,
          311,
          257,
          3715,
          1716,
          294,
          452,
          1508,
          965,
          300,
          390,
          1237,
          412,
          17746,
          7592,
          6618,
          36410,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1866953933940214,
        "compression_ratio": 1.678343949044586,
        "end": 9406.44,
        "id": 2826,
        "no_speech_prob": 0.20685574412345886,
        "seek": 938244,
        "start": 9401.44,
        "temperature": 0,
        "text": " And so using the visual language of a system that you're trying to emulate to sort of spark the idea in the viewer,",
        "tokens": [
          51314,
          400,
          370,
          1228,
          264,
          5056,
          2856,
          295,
          257,
          1185,
          300,
          291,
          434,
          1382,
          281,
          45497,
          281,
          1333,
          295,
          9908,
          264,
          1558,
          294,
          264,
          16767,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.1866953933940214,
        "compression_ratio": 1.678343949044586,
        "end": 9411.44,
        "id": 2827,
        "no_speech_prob": 0.20685574412345886,
        "seek": 938244,
        "start": 9406.44,
        "temperature": 0,
        "text": " in either a playful way or a subversive way, or to make a statement, or just to tell a story.",
        "tokens": [
          51564,
          294,
          2139,
          257,
          30730,
          636,
          420,
          257,
          1422,
          840,
          488,
          636,
          11,
          420,
          281,
          652,
          257,
          5629,
          11,
          420,
          445,
          281,
          980,
          257,
          1657,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9415.44,
        "id": 2828,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9411.44,
        "temperature": 0,
        "text": " I think there's a lot of possibilities in thinking about the context and the visual design elements",
        "tokens": [
          50364,
          286,
          519,
          456,
          311,
          257,
          688,
          295,
          12178,
          294,
          1953,
          466,
          264,
          4319,
          293,
          264,
          5056,
          1715,
          4959,
          50564
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9418.44,
        "id": 2829,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9415.44,
        "temperature": 0,
        "text": " that surround how and where you're generating that text.",
        "tokens": [
          50564,
          300,
          6262,
          577,
          293,
          689,
          291,
          434,
          17746,
          300,
          2487,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9425.44,
        "id": 2830,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9418.44,
        "temperature": 0,
        "text": " The other thing that I think is worth really noting here is that both with Markov chains and with context-free grammars,",
        "tokens": [
          50714,
          440,
          661,
          551,
          300,
          286,
          519,
          307,
          3163,
          534,
          26801,
          510,
          307,
          300,
          1293,
          365,
          3934,
          5179,
          12626,
          293,
          365,
          4319,
          12,
          10792,
          17570,
          685,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9429.44,
        "id": 2831,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9425.44,
        "temperature": 0,
        "text": " that words or characters, what is it, what's the sequence of the grammar?",
        "tokens": [
          51064,
          300,
          2283,
          420,
          4342,
          11,
          437,
          307,
          309,
          11,
          437,
          311,
          264,
          8310,
          295,
          264,
          22317,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9432.44,
        "id": 2832,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9429.44,
        "temperature": 0,
        "text": " What is the grammar describing? Is it describing language?",
        "tokens": [
          51264,
          708,
          307,
          264,
          22317,
          16141,
          30,
          1119,
          309,
          16141,
          2856,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9435.44,
        "id": 2833,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9432.44,
        "temperature": 0,
        "text": " Is the language English? Is it for another language?",
        "tokens": [
          51414,
          1119,
          264,
          2856,
          3669,
          30,
          1119,
          309,
          337,
          1071,
          2856,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.1992205470061499,
        "compression_ratio": 1.8430656934306568,
        "end": 9440.44,
        "id": 2834,
        "no_speech_prob": 0.0009399274131283164,
        "seek": 941144,
        "start": 9435.44,
        "temperature": 0,
        "text": " Or is it musical notes? Or is it designs?",
        "tokens": [
          51564,
          1610,
          307,
          309,
          9165,
          5570,
          30,
          1610,
          307,
          309,
          11347,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.216365563242059,
        "compression_ratio": 1.5878136200716846,
        "end": 9445.44,
        "id": 2835,
        "no_speech_prob": 0.02843182533979416,
        "seek": 944044,
        "start": 9440.44,
        "temperature": 0,
        "text": " Do you have a context-free grammar that builds a design out of shapes and color?",
        "tokens": [
          50364,
          1144,
          291,
          362,
          257,
          4319,
          12,
          10792,
          22317,
          300,
          15182,
          257,
          1715,
          484,
          295,
          10854,
          293,
          2017,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.216365563242059,
        "compression_ratio": 1.5878136200716846,
        "end": 9447.44,
        "id": 2836,
        "no_speech_prob": 0.02843182533979416,
        "seek": 944044,
        "start": 9445.44,
        "temperature": 0,
        "text": " How might you explore something like that?",
        "tokens": [
          50614,
          1012,
          1062,
          291,
          6839,
          746,
          411,
          300,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.216365563242059,
        "compression_ratio": 1.5878136200716846,
        "end": 9451.44,
        "id": 2837,
        "no_speech_prob": 0.02843182533979416,
        "seek": 944044,
        "start": 9447.44,
        "temperature": 0,
        "text": " So I encourage you to look at these examples, try Tracery, try Rita.",
        "tokens": [
          50714,
          407,
          286,
          5373,
          291,
          281,
          574,
          412,
          613,
          5110,
          11,
          853,
          1765,
          326,
          2109,
          11,
          853,
          32672,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.216365563242059,
        "compression_ratio": 1.5878136200716846,
        "end": 9454.44,
        "id": 2838,
        "no_speech_prob": 0.02843182533979416,
        "seek": 944044,
        "start": 9451.44,
        "temperature": 0,
        "text": " You know, as an exercise, you might try programming that recursive algorithm on your own",
        "tokens": [
          50914,
          509,
          458,
          11,
          382,
          364,
          5380,
          11,
          291,
          1062,
          853,
          9410,
          300,
          20560,
          488,
          9284,
          322,
          428,
          1065,
          51064
        ]
      },
      {
        "avg_logprob": -0.216365563242059,
        "compression_ratio": 1.5878136200716846,
        "end": 9457.44,
        "id": 2839,
        "no_speech_prob": 0.02843182533979416,
        "seek": 944044,
        "start": 9454.44,
        "temperature": 0,
        "text": " and see what types of results you can get.",
        "tokens": [
          51064,
          293,
          536,
          437,
          3467,
          295,
          3542,
          291,
          393,
          483,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.216365563242059,
        "compression_ratio": 1.5878136200716846,
        "end": 9464.44,
        "id": 2840,
        "no_speech_prob": 0.02843182533979416,
        "seek": 944044,
        "start": 9457.44,
        "temperature": 0,
        "text": " Okay, so I hope you enjoyed session 7, and you can share anything you make in the comments or at Schiffman on Twitter.",
        "tokens": [
          51214,
          1033,
          11,
          370,
          286,
          1454,
          291,
          4626,
          5481,
          1614,
          11,
          293,
          291,
          393,
          2073,
          1340,
          291,
          652,
          294,
          264,
          3053,
          420,
          412,
          2065,
          3661,
          1601,
          322,
          5794,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21729892423783226,
        "compression_ratio": 1.5097087378640777,
        "end": 9470.44,
        "id": 2841,
        "no_speech_prob": 0.3414554297924042,
        "seek": 946444,
        "start": 9464.44,
        "temperature": 0,
        "text": " And of course, I always sort of plug that if you feel so inclined, you can join the Patreon page,",
        "tokens": [
          50364,
          400,
          295,
          1164,
          11,
          286,
          1009,
          1333,
          295,
          5452,
          300,
          498,
          291,
          841,
          370,
          28173,
          11,
          291,
          393,
          3917,
          264,
          15692,
          3028,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.21729892423783226,
        "compression_ratio": 1.5097087378640777,
        "end": 9473.44,
        "id": 2842,
        "no_speech_prob": 0.3414554297924042,
        "seek": 946444,
        "start": 9470.44,
        "temperature": 0,
        "text": " and there's a Slack channel too to discuss and ask questions.",
        "tokens": [
          50664,
          293,
          456,
          311,
          257,
          37211,
          2269,
          886,
          281,
          2248,
          293,
          1029,
          1651,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21729892423783226,
        "compression_ratio": 1.5097087378640777,
        "end": 9479.44,
        "id": 2843,
        "no_speech_prob": 0.3414554297924042,
        "seek": 946444,
        "start": 9473.44,
        "temperature": 0,
        "text": " Okay, so see you in a future session, video, whatever, and talk to you soon.",
        "tokens": [
          50814,
          1033,
          11,
          370,
          536,
          291,
          294,
          257,
          2027,
          5481,
          11,
          960,
          11,
          2035,
          11,
          293,
          751,
          281,
          291,
          2321,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21729892423783226,
        "compression_ratio": 1.5097087378640777,
        "end": 9485.44,
        "id": 2844,
        "no_speech_prob": 0.3414554297924042,
        "seek": 946444,
        "start": 9479.44,
        "temperature": 0,
        "text": " Okay, so there we go.",
        "tokens": [
          51114,
          1033,
          11,
          370,
          456,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21729892423783226,
        "compression_ratio": 1.5097087378640777,
        "end": 9489.44,
        "id": 2845,
        "no_speech_prob": 0.3414554297924042,
        "seek": 946444,
        "start": 9485.44,
        "temperature": 0,
        "text": " I have now, I think, finished everything from today.",
        "tokens": [
          51414,
          286,
          362,
          586,
          11,
          286,
          519,
          11,
          4335,
          1203,
          490,
          965,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19526244464673495,
        "compression_ratio": 1.4705882352941178,
        "end": 9494.44,
        "id": 2846,
        "no_speech_prob": 0.2974078357219696,
        "seek": 948944,
        "start": 9489.44,
        "temperature": 0,
        "text": " I can take about 5 minutes or so to answer a last question or two.",
        "tokens": [
          50364,
          286,
          393,
          747,
          466,
          1025,
          2077,
          420,
          370,
          281,
          1867,
          257,
          1036,
          1168,
          420,
          732,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19526244464673495,
        "compression_ratio": 1.4705882352941178,
        "end": 9500.44,
        "id": 2847,
        "no_speech_prob": 0.2974078357219696,
        "seek": 948944,
        "start": 9494.44,
        "temperature": 0,
        "text": " I'm going to kind of clean up here and close a bunch of links.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          733,
          295,
          2541,
          493,
          510,
          293,
          1998,
          257,
          3840,
          295,
          6123,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19526244464673495,
        "compression_ratio": 1.4705882352941178,
        "end": 9508.44,
        "id": 2848,
        "no_speech_prob": 0.2974078357219696,
        "seek": 948944,
        "start": 9500.44,
        "temperature": 0,
        "text": " I still have this cough that never goes away.",
        "tokens": [
          50914,
          286,
          920,
          362,
          341,
          22777,
          300,
          1128,
          1709,
          1314,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19526244464673495,
        "compression_ratio": 1.4705882352941178,
        "end": 9512.44,
        "id": 2849,
        "no_speech_prob": 0.2974078357219696,
        "seek": 948944,
        "start": 9508.44,
        "temperature": 0,
        "text": " And make sure everything is saved.",
        "tokens": [
          51314,
          400,
          652,
          988,
          1203,
          307,
          6624,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19526244464673495,
        "compression_ratio": 1.4705882352941178,
        "end": 9515.44,
        "id": 2850,
        "no_speech_prob": 0.2974078357219696,
        "seek": 948944,
        "start": 9512.44,
        "temperature": 0,
        "text": " Boy, this took a lot longer than I ever imagined doing all this.",
        "tokens": [
          51514,
          9486,
          11,
          341,
          1890,
          257,
          688,
          2854,
          813,
          286,
          1562,
          16590,
          884,
          439,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23035565400734925,
        "compression_ratio": 1.565,
        "end": 9518.44,
        "id": 2851,
        "no_speech_prob": 0.6295957565307617,
        "seek": 951544,
        "start": 9515.44,
        "temperature": 0,
        "text": " Are there any other Rita-like libraries for languages?",
        "tokens": [
          50364,
          2014,
          456,
          604,
          661,
          32672,
          12,
          4092,
          15148,
          337,
          8650,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.23035565400734925,
        "compression_ratio": 1.565,
        "end": 9520.44,
        "id": 2852,
        "no_speech_prob": 0.6295957565307617,
        "seek": 951544,
        "start": 9518.44,
        "temperature": 0,
        "text": " Absolutely, there are.",
        "tokens": [
          50514,
          7021,
          11,
          456,
          366,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23035565400734925,
        "compression_ratio": 1.565,
        "end": 9530.44,
        "id": 2853,
        "no_speech_prob": 0.6295957565307617,
        "seek": 951544,
        "start": 9520.44,
        "temperature": 0,
        "text": " You know, working in the Python programming languages, there are certainly many Python packages, libraries,",
        "tokens": [
          50614,
          509,
          458,
          11,
          1364,
          294,
          264,
          15329,
          9410,
          8650,
          11,
          456,
          366,
          3297,
          867,
          15329,
          17401,
          11,
          15148,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.23035565400734925,
        "compression_ratio": 1.565,
        "end": 9532.44,
        "id": 2854,
        "no_speech_prob": 0.6295957565307617,
        "seek": 951544,
        "start": 9530.44,
        "temperature": 0,
        "text": " whatever you want to call them, for working with text.",
        "tokens": [
          51114,
          2035,
          291,
          528,
          281,
          818,
          552,
          11,
          337,
          1364,
          365,
          2487,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23035565400734925,
        "compression_ratio": 1.565,
        "end": 9536.44,
        "id": 2855,
        "no_speech_prob": 0.6295957565307617,
        "seek": 951544,
        "start": 9532.44,
        "temperature": 0,
        "text": " I think the most famous one being the NLTK, or Natural Language Toolkit.",
        "tokens": [
          51214,
          286,
          519,
          264,
          881,
          4618,
          472,
          885,
          264,
          426,
          43,
          51,
          42,
          11,
          420,
          20137,
          24445,
          15934,
          22681,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2342020586917275,
        "compression_ratio": 1.5577889447236182,
        "end": 9547.44,
        "id": 2856,
        "no_speech_prob": 0.23364323377609253,
        "seek": 953644,
        "start": 9537.44,
        "temperature": 0,
        "text": " In JavaScript, another one that I described, that I covered in another video, was NLP Compromise.",
        "tokens": [
          50414,
          682,
          15778,
          11,
          1071,
          472,
          300,
          286,
          7619,
          11,
          300,
          286,
          5343,
          294,
          1071,
          960,
          11,
          390,
          426,
          45196,
          2432,
          28722,
          908,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2342020586917275,
        "compression_ratio": 1.5577889447236182,
        "end": 9552.44,
        "id": 2857,
        "no_speech_prob": 0.23364323377609253,
        "seek": 953644,
        "start": 9547.44,
        "temperature": 0,
        "text": " I hope to look at, as I do more videos with Node, I hope to look at some more packages that work with text in Node.",
        "tokens": [
          50914,
          286,
          1454,
          281,
          574,
          412,
          11,
          382,
          286,
          360,
          544,
          2145,
          365,
          38640,
          11,
          286,
          1454,
          281,
          574,
          412,
          512,
          544,
          17401,
          300,
          589,
          365,
          2487,
          294,
          38640,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2342020586917275,
        "compression_ratio": 1.5577889447236182,
        "end": 9557.44,
        "id": 2858,
        "no_speech_prob": 0.23364323377609253,
        "seek": 953644,
        "start": 9552.44,
        "temperature": 0,
        "text": " But certainly if you're interested in kind of creative expression through programming with text,",
        "tokens": [
          51164,
          583,
          3297,
          498,
          291,
          434,
          3102,
          294,
          733,
          295,
          5880,
          6114,
          807,
          9410,
          365,
          2487,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2505065270189969,
        "compression_ratio": 1.5850622406639003,
        "end": 9564.44,
        "id": 2859,
        "no_speech_prob": 0.30400407314300537,
        "seek": 955744,
        "start": 9557.44,
        "temperature": 0,
        "text": " I think Rita might be exactly where you want to be, in terms of both the analyzing text and generating text.",
        "tokens": [
          50364,
          286,
          519,
          32672,
          1062,
          312,
          2293,
          689,
          291,
          528,
          281,
          312,
          11,
          294,
          2115,
          295,
          1293,
          264,
          23663,
          2487,
          293,
          17746,
          2487,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2505065270189969,
        "compression_ratio": 1.5850622406639003,
        "end": 9571.44,
        "id": 2860,
        "no_speech_prob": 0.30400407314300537,
        "seek": 955744,
        "start": 9564.44,
        "temperature": 0,
        "text": " Okay, so this was quite a long stream.",
        "tokens": [
          50714,
          1033,
          11,
          370,
          341,
          390,
          1596,
          257,
          938,
          4309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2505065270189969,
        "compression_ratio": 1.5850622406639003,
        "end": 9577.44,
        "id": 2861,
        "no_speech_prob": 0.30400407314300537,
        "seek": 955744,
        "start": 9571.44,
        "temperature": 0,
        "text": " Oh, I'm hoping this is connected as one file, because it's telling me that this is 2 hours and 45 minutes.",
        "tokens": [
          51064,
          876,
          11,
          286,
          478,
          7159,
          341,
          307,
          4582,
          382,
          472,
          3991,
          11,
          570,
          309,
          311,
          3585,
          385,
          300,
          341,
          307,
          568,
          2496,
          293,
          6905,
          2077,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2505065270189969,
        "compression_ratio": 1.5850622406639003,
        "end": 9578.44,
        "id": 2862,
        "no_speech_prob": 0.30400407314300537,
        "seek": 955744,
        "start": 9577.44,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51364,
          876,
          452,
          8387,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2505065270189969,
        "compression_ratio": 1.5850622406639003,
        "end": 9579.44,
        "id": 2863,
        "no_speech_prob": 0.30400407314300537,
        "seek": 955744,
        "start": 9578.44,
        "temperature": 0,
        "text": " Okay, I've got to go.",
        "tokens": [
          51414,
          1033,
          11,
          286,
          600,
          658,
          281,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2505065270189969,
        "compression_ratio": 1.5850622406639003,
        "end": 9584.44,
        "id": 2864,
        "no_speech_prob": 0.30400407314300537,
        "seek": 955744,
        "start": 9579.44,
        "temperature": 0,
        "text": " This took about an hour longer, or an hour and a half longer than I expected to do today.",
        "tokens": [
          51464,
          639,
          1890,
          466,
          364,
          1773,
          2854,
          11,
          420,
          364,
          1773,
          293,
          257,
          1922,
          2854,
          813,
          286,
          5176,
          281,
          360,
          965,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9588.44,
        "id": 2865,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9584.44,
        "temperature": 0,
        "text": " Right now, every Tuesday afternoon, I'm not so good at sending out the announcements.",
        "tokens": [
          50364,
          1779,
          586,
          11,
          633,
          10017,
          6499,
          11,
          286,
          478,
          406,
          370,
          665,
          412,
          7750,
          484,
          264,
          23785,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9593.44,
        "id": 2866,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9588.44,
        "temperature": 0,
        "text": " But hopefully, if things go well, I'll be having another live stream next Tuesday afternoon.",
        "tokens": [
          50564,
          583,
          4696,
          11,
          498,
          721,
          352,
          731,
          11,
          286,
          603,
          312,
          1419,
          1071,
          1621,
          4309,
          958,
          10017,
          6499,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9597.44,
        "id": 2867,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9593.44,
        "temperature": 0,
        "text": " I will likely miss a week or two, I expect, over the next month or two,",
        "tokens": [
          50814,
          286,
          486,
          3700,
          1713,
          257,
          1243,
          420,
          732,
          11,
          286,
          2066,
          11,
          670,
          264,
          958,
          1618,
          420,
          732,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9603.44,
        "id": 2868,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9597.44,
        "temperature": 0,
        "text": " as things really ramp up with other things that I have going on work-wise.",
        "tokens": [
          51014,
          382,
          721,
          534,
          12428,
          493,
          365,
          661,
          721,
          300,
          286,
          362,
          516,
          322,
          589,
          12,
          3711,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9608.44,
        "id": 2869,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9603.44,
        "temperature": 0,
        "text": " But January is winter break, and I'm not teaching over winter break, and I will be in New York.",
        "tokens": [
          51314,
          583,
          7061,
          307,
          6355,
          1821,
          11,
          293,
          286,
          478,
          406,
          4571,
          670,
          6355,
          1821,
          11,
          293,
          286,
          486,
          312,
          294,
          1873,
          3609,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9609.44,
        "id": 2870,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9608.44,
        "temperature": 0,
        "text": " So hopefully I'll do a couple extra.",
        "tokens": [
          51564,
          407,
          4696,
          286,
          603,
          360,
          257,
          1916,
          2857,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18334838019476996,
        "compression_ratio": 1.740484429065744,
        "end": 9612.44,
        "id": 2871,
        "no_speech_prob": 0.3556002974510193,
        "seek": 958444,
        "start": 9609.44,
        "temperature": 0,
        "text": " If I miss some weeks, I'll do some catch-up.",
        "tokens": [
          51614,
          759,
          286,
          1713,
          512,
          3259,
          11,
          286,
          603,
          360,
          512,
          3745,
          12,
          1010,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9616.44,
        "id": 2872,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9613.44,
        "temperature": 0,
        "text": " Okay, thanks everyone for being here.",
        "tokens": [
          50414,
          1033,
          11,
          3231,
          1518,
          337,
          885,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9618.44,
        "id": 2873,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9616.44,
        "temperature": 0,
        "text": " Thanks for all your support.",
        "tokens": [
          50564,
          2561,
          337,
          439,
          428,
          1406,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9622.44,
        "id": 2874,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9618.44,
        "temperature": 0,
        "text": " These videos will get released over the week, along with the code examples.",
        "tokens": [
          50664,
          1981,
          2145,
          486,
          483,
          4736,
          670,
          264,
          1243,
          11,
          2051,
          365,
          264,
          3089,
          5110,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9626.44,
        "id": 2875,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9622.44,
        "temperature": 0,
        "text": " Stay in touch, and maybe see you next week, okay?",
        "tokens": [
          50864,
          8691,
          294,
          2557,
          11,
          293,
          1310,
          536,
          291,
          958,
          1243,
          11,
          1392,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9632.44,
        "id": 2876,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9626.44,
        "temperature": 0,
        "text": " I hope this was a new topic, and that you guys discover something new and make something with it.",
        "tokens": [
          51064,
          286,
          1454,
          341,
          390,
          257,
          777,
          4829,
          11,
          293,
          300,
          291,
          1074,
          4411,
          746,
          777,
          293,
          652,
          746,
          365,
          309,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9634.44,
        "id": 2877,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9632.44,
        "temperature": 0,
        "text": " I don't know what I'm supposed to click now.",
        "tokens": [
          51364,
          286,
          500,
          380,
          458,
          437,
          286,
          478,
          3442,
          281,
          2052,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9635.44,
        "id": 2878,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9634.44,
        "temperature": 0,
        "text": " Over here.",
        "tokens": [
          51464,
          4886,
          510,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20291019439697267,
        "compression_ratio": 1.6044444444444443,
        "end": 9637.44,
        "id": 2879,
        "no_speech_prob": 0.005909028463065624,
        "seek": 961244,
        "start": 9635.44,
        "temperature": 0,
        "text": " Okay, goodbye.",
        "tokens": [
          51514,
          1033,
          11,
          12084,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.7732252597808837,
        "compression_ratio": 0.7586206896551724,
        "end": 9647.44,
        "id": 2880,
        "no_speech_prob": 0.9587832093238831,
        "seek": 963744,
        "start": 9637.44,
        "temperature": 0,
        "text": " [♪ music playing ♪",
        "tokens": [
          50414,
          44529,
          1318,
          2433,
          220,
          158,
          247,
          103,
          50864
        ]
      }
    ],
    "transcription": " Did you think that learning coding would be really rough? Throw your hands up in the air and say enough's enough! Do you want to learn to code and make some awesome stuff? Learn that anyone can when you're coding with Danon! Whether you're a pro or this is all brand new, Learn the overarching concepts and some fun stuff too! And with Dan as your guide, come along for the ride on! Make a crazy pixel mirror to reflect your face, You can make a jump to light speed into outer space, You can generate a maze that can go on for days, You can make your own terrain and some purple rain, You can make a retro game to see how it's done, And then tweak a piece to make it yours for everyone! Make some fractally trees or twitter bots if you please, And when the seeds are a-sown, you can make them your own! Write the colors of code, you can follow the road too! Hello, welcome! I think I am live. I'm using a... this is Dan, welcome to my YouTube live stream of undefined name. I would like to know first off... First of all, I'd like to know first off if the audio is okay if you hear static. Because last week this particular microphone that I'm using right now was having static issues. But I decided maybe if it just rested for a week and I put it on again, that there wouldn't be any static. So I'm going to check the chat and see the other thing... Ah! The other thing I have to say is I... Normally when I come down here, I'm live from the school for poetic computation, Normally when I get ready to come to a live stream, I bring three devices with me. I bring two laptops and a tablet, because I have like the chat on one, and I have a soundboard on the other, and then I have the computer I'm using to code, and I completely just this morning forgot everything but my regular laptop. So I do have the streaming computer which I am now running... I'm kind of... which usually I just use as a monitor, but I'm actually looking at the chat on that. So when I'm looking this direction, it looks like I'm referring to this beautiful rainbow over here, but really I am looking at your chat, which for example it says it's a little bit too quiet, or sometimes I do read the messages, sometimes I don't. There's a discussion. Okay, good news for you is that I can easily... I have a mixing board. It's very exciting. I can turn the volume up a tiny bit, which I'm going to do. I'm a little bit low to do this, because last week there were some peaking issues, where as I talked the volume peaked, but I can see where the bar is going is not going too high. So I think... I don't see any red lights over here, so I think I'm okay. I'm also... I have to admit which... Last spring when I started doing the weekly live streams, and last spring I was doing it twice a week, I was kind of excited about it, I'm energetic about it, which I still am, but I was sort of curious how this would go, teaching full time at ITP at NYU and doing this YouTube channel. And I think it's been going pretty well, but this week I'm starting to feel the crunch, and I'm just like overloaded with things to do, and I'm like not prepared, and I wasn't even sure if I'd have time to do this today, which is why I didn't send out an announcement to like an hour in advance. So hopefully schedule-wise things will start to... There will be ebbs and flows, and so maybe I'll catch up and do a couple extra live streams in January, for example, if I miss some in November and December, but I can tell already that the next couple months is only getting busier and busier. But first, a big thank you to... Ah, okay, so lots of people are asking questions about the name. I did talk about this on the live stream last week, I will just mention it again. Unfortunately, due to a trademark issue with Reading Rainbow, who has been nothing but nice and generous with me in their support and discussion about this, but it looks like based on all the advice and research that I've done that it is a legitimate trademark conflict, Reading Rainbow and the previous name of this channel, which I guess I'm avoiding saying. So I'm looking, I'm in the market for a new name. However, I still have a rainbow. I don't know, you guys can all tweet at LeVar Burton if you want to register your... But you should only tweet with love, because Reading Rainbow is a wonderful, wonderful kids program and show, and I believe they have an app now about learning to read. So I don't want to spend too much time talking about the name of this channel, because primarily I think the point of this channel is... I was going to say rainbows, but is friendly and accessible tutorials about coding. I would also like for the viewers of this channel to see a lot of different faces and voices, talk and demonstrate stuff about coding. So each week I'm also hoping to have a guest now, and I have a guest coming. I probably won't live stream it later today in the studio. So if you subscribe to the channel, you'll see a video with a guest tutorial coming sometime soon. I would love to partner with Reading Rainbow. I don't think that that's an option for me, although that would certainly be wonderful. One name that I have that I actually really like, but a lot of people don't like, so I recognize that in fact. I'm thinking of kind of kids show style names, even though this is not a kids show, but my sort of aesthetic and attitude and things that I love are kind of in the realm of Reading Rainbow, Mr. Rogers' Neighborhood, things like that. So I was thinking of... Actually it was suggested on Twitter. I have to look up who suggested this. The Coding Train. The reason why now, before you get too upset about that as a name, picture this, a train coming in, a steam train with rainbows coming out of the steam engine, and in the back, in the train, riding along a horde of unicorns and other people or something. So that's sort of what I'm thinking. The Joy of Coding is also something that I've been thinking about. Choo-choo all aboard the coding train. Can't you imagine, you know, something... Anyway, so I don't want to get too... I did do a Markov chain. Oh, I haven't released all my videos yet. I'm so behind on everything. I did a Markov chain tutorial last week, which is an algorithm that can be used to generate text randomly based on other text. I tried to generate a name for the channel. I was not able to do that. Okay. Okay. So if you have strong... I'm looking over here at the chat. If you have strong opinions about the name, I kind of almost feel like I might take it easy for a while and just kind of leave the channel as undefined, which in many ways is a very appropriate name, and return to hopefully launch in 2017 with a new name if it takes me a month or two to kind of get that all settled. Markov train. Yes, I like that. Okay. No, the stream is not ending soon. We have just started. So today's topic, beyond me just really wanting to take a nap. Have you ever had that feeling where you just want to take a nap? It's the afternoon. You're tired. It's been a long day already. You already taught a three-hour class. Morning. It's cold, which I think the one good thing about it being cold in New York City now is that this room used to get so hot with the lights, but it's cold, so I'm waiting for the lights to warm me up. Okay, so this.coding. Yes, of course this. And the other thing is I forgot my soundboard, but I have a backup soundboard. Let's see if this works. Can you guys hear the this.song? Let me know if you can hear it. And I can't see my monitor anymore. Oh, I turned my camera off. Too quiet. You can hear it, but it's quiet. All right, let me work on that. That's an easy fix. I believe that's coming from this, this. Is that a lot louder now? All right, I'm not going to worry too much about the sound because that's not really the point of today here. Let me come back. Wrong screen. See, I'm really a mess without still a bit quiet. I could have made it louder still. If I need to play that song later, I will make it louder. Okay, so I'm all out of whack still without my multiple computers. Okay, so let's get started. I'm completely unprepared. I mean, I'm not unprepared in terms of thinking about and having, but I'm completely unprepared in terms of what's on my screen here. So I've got to get set up a little bit, and I'll talk you through what's going on. So here we are. What I am doing this fall. So first of all, you can still actually go to this website, which it's codingrainbow.com. At some point, I will change that URL. And if you're interested, I would encourage you to subscribe to the channel. You can become a patron on Patreon if you're so inclined. And also, I do send out emails once a week about scheduling of when I'm going to do these live streams if you want to get an email update. So let me mention those things to you. Now, what I've been using this fall for in the live stream is I'm teaching a class at itp.nyu.edu. The class is called Programming from A to Z. You can see here a variety of topics that I have already explored. I made a set of videos on regular expressions. I looked at using different JavaScript libraries around text. I haven't actually done videos about server-side programming with Node yet, but there's a page of notes. I have a bunch of videos about Twitter bots. I don't know why I can't get this to scroll correctly. And more recently, I did a session on text analysis, looking at word counting and what types of applications you can create from just counting the frequency of words in a document. And then last week, I looked at a particular algorithm, highly related to word counting, which involved... which involved... looking at too many screens at once... which involved looking at the sequence of words or characters and the probabilities of those sequences occurring in the context of a Markov chain, a Markov chain being a sequence of states, and the states in this case being either characters or words, and then evaluating a text based on all of the ways that the characters appear next to each other and generating new text from that. So if you're interested in that, those are the videos from last week. And there's actually even one or two more that I didn't release. So one thing I should say, by the way, for those of you... here's a little secret. For... you know, I release videos in multiple ways. And let me just go to my channel here for a second. So for example, if you go here, the most recent thing that's happening right now is Coding Rainbow Live, which you can see there. But you can see here that I also... the most recent video that I published is Coding Challenge 42.1 Markov Chains. So once a day, and I just forgot to do it this morning, I usually have a backlog of videos that I've made. So once a day, I try to release a new one, meaning make it public. But I usually have a lot of videos that are on my channel that I haven't released yet that are unlisted. And you can always find those by going to the playlists. So if I went to, for example, session 6 playlist, you'll see that even though this is the most recent video that has been released, there's also the second part to that there, and a video about kind of a homework assignment that's there as well. So I'm just mentioning that. If you're ever, like, poking around the playlist, you'll often find additional videos that haven't been released yet. You can always tweet me at Shiffman about that. So what's the topic for today? Because the last topic on this list is Ngrams and Markov Chains. So if there's no topic after it, then what can I possibly talk about? Well, I have something to talk about, which is grammars. Today's topic is looking at what a grammar is, how you can define a grammar in code, encode a grammar, and how you can generate text based on that grammar. And there's a variety of things. My glasses are very dirty. There's a variety of applications of this and things that we can look at. And in particular, I want to look at something called Tracery. Tracery is an engine for generating text from grammar, and it's by Kate Compton, GalaxyKate on Twitter. And it's a really easy, powerful entry point into text generation in JavaScript using grammars. So that's kind of going to be the main topic. I am looking at the chat for a moment to see if there is anything. Dun, dun, dun. Grammar. It doesn't look like there's any questions I need to answer at the moment. So every once in a while, I try to take a peek at the chat. And once I do, I've got – this isn't going to be – I'll probably be here for at least an hour now. And I want to walk through a few different examples and make a couple examples. And then I've lost my train of thought. And then I will be gone. But once I finish these few examples, I'll stick around for maybe – I'll try to leave like 15 minutes or even a half an hour at the end for just questions. And I can answer questions or make quick and dirty little examples of things that you guys are wondering about. Okay. I know everyone's like, I woke up this morning and I heard there was going to be a live stream about coding. And I found out it was about grammar. Well, that's what it is. Okay. So let me – let's see if I can get the – some music going for you guys. I have a little – I don't know what this music is. A little music in the background. And let me get set up here. So I'm going to my Finder. Wait, week six. This is session seven technically. You should really call it session, not week. Let's rename all these. How about riveting things to watch on YouTube? Watching somebody rename six folders. And I seem to have lost my ability to count. Oh, boy. Oh, what just happened? Everything went awry. One, two, three. I'll have to fix this later. All I care is that this is section seven. Okay. I'm so tired today. Hope I can do this. Let's go in here. Let's do our first example, I think, going to be tracery grammar. And what I need to do is open up terminal. Oh, I better see if I have any good markers here. Okay. Desktop. I'm going to the desktop. And A to Z. Maybe our coding – oh, I've got to change the name of that folder. I'm going to run a server here. And I'm going to open this up in Atom. Minimize this. And let's look at this tracery grammar example that I will make at some point. Function setup. And hello, function draw. Okay. So now if I go here and I go to session seven, I should have a nice little browser window and JavaScript console. Let's just put something here to make sure everything is working. No canvas. And what was I going to say here? No canvas and console log unicorn. Okay. There we go. Okay. So things are working. I have a code example ready to go. And I have got a code example ready to go. Now, some things I want to get up and running in the browser with is I want to make sure I have a window open to tracery. So this is the GitHub repository for tracery by Kate Compton, Galaxy Kate on GitHub and on Twitter. Story grammar generation library for JavaScript. Another thing I want to do is I want to make sure I want to have my let's see here. I want to go I have some pre-made examples that I might want to refer to. So I better clone my GitHub repo for the course. Can I find that clone? So I can grab this and I can say git clone. Oh, yeah. So let's just do this because I'm not logged in as myself. So let me grab all of this stuff. And then I'm also going to run a server from this directory. So that should be running now. This is the stuff that I really would like to make a habit of doing before I start live streaming. So now we can look. These are a bunch of pre-existing examples that I will cover and discuss here in this session as well. And let's see. In particular, I want to maybe and I want to also have these available for me here. Add project folder. Use the F16. You know what? I think I'm just going to I hesitate to do this. I'm just going to add this week 8. Okay. So now I have my code. I have my pre-made examples. I really, by the way, think of this like a cooking show. And so I have thought like the joy of coding, like the joy of cooking kind of works in that sense. But there are other good like cooking show kind of style names that might be something to think of. Okay. So it's funny. I have this like preview of the chat. I can only see like half of it. So it's a little confusing to look at. Okay. So now what do I need? So one thing I want to also do. I hate to do this. So this is a some links and references that I would like to refer to. I think these will be on my new page of notes that I just haven't made yet. This is useful. This one was really good, I think. I think. Interesting, interesting, interesting. So I'm looking for what links might be the most illustrative, although I will most likely just diagram myself on the whiteboard. Let's look at this one. Yeah. So this is interesting as it relates to the grammar for programming. So I will have that available. And okay. So that's good. And where are my these are my notes here. If I see anything useful here. And then also I'm almost there. I'm almost ready. Example grammars. Did I look at that already? And then I want to look at Chomsky hierarchy. Look at this. Have this page available to us as well. Okay. So I've got this. I don't need I've got this. I've got this. I've got this. So I think I first want to do is the first video, the first sort of chunk of information that I will start with. Let me see if I have a marker and an eraser that works. Definitely have an eraser here. Let's see how this goes. That's pretty good. How's the focus on that? Let me come see. Looks pretty good to me, I think. Okay. Okay. Here we are. So. Okay. So I'm trying to think of what a good opening screen is. This isn't the worst. I think. Okay. Everybody hold on. I'll be right back. Just give me a second. I'm losing my things are going. Things are beeping in weird places on different screens. Okay. Hold on. Okay. I am back. So I'm going to get started. So let me cycle the cameras. And this will be this first like five or ten minute little video. So for those of you who might be watching this for the first time, this is a live session. It lasts somewhere between one and two hours. And then after, excuse me, after the session is over, with the help of Mathieu, I take certain sections of the live stream out and edit those together for some shorter tutorial videos which get uploaded separately. But always the live session is also available if you want to watch the full archive of the live session with all the extra me needing to take a break kind of stuff. Okay. Here we go. So grammars. Okay. So session seven. Darth Taurus asked what goofiness did I miss? There's not a lot of, let me answer some of these questions for a second. There hasn't been a lot of goofiness yet because I'm having like a low energy day. Why LeVay asked what is the end result you're trying to get with all the text analysis topics? What's the true goal you're striving for? Well, this is a great question. And I like to think that I covered or talked about this in the introduction to programming from A to Z video about the sort of course as a whole. And I think for me one of the things that I'm interested in is I would say like coding for blank. So what is your field of interest? What is it that you work on? What's your job? What are you studying? What's your hobby? And what does computation or coding add to that? And I think something that one possible blank is language, writing, the humanities to put it like a broad kind of stroke over everything. And so in particular in creative coding so to speak with tools like processing or P5.js or open frameworks, there's a lot of focus on graphics programming. And there's a lot of wonderful things you can do. And I will come back to focusing on algorithms for graphics programming. But here I'm asking the question what types of creative experiments, what types of new possibilities can you discover if you're working with algorithms whose purpose is to read text and generate text? And there are a lot of classic applications of this like sentiment analysis, reading in a text, determining whether it's positive or negative. There's lots of academic papers and lots of research and companies using this sort of stuff. And for me I'm looking forward to provide a set of explanations and simple tutorials for some of the basic concepts around working with algorithms, programming, and text and see what the viewers, you folks watching, what creative outcomes you might have that are things that I can't think of. And so that to me is sort of the plan here. Okay. So yes, this van beers us. Are we looking at stuff people sent in today? And I don't know why I can't get it. I'm having, as you guys have mentioned a few times, I'm having a lot of trouble keeping up with everything just in the last couple weeks. So I need to do a better job. I have a Slack channel for the patrons of the channel. And there is where people post things they're working on, share work, and we have discussion and feedback and help around those things. And I usually try to pull a few to share in the live stream. And I said last week I didn't do it. I said I would next week. And this week I didn't do it again. So I'm going to try to get do a better job of sort of keeping up with this sort of thing. So if you are a patron and you're on Slack, feel free to remind me about this, especially if you have something that you'd like me to share to get feedback with on the channel. Okay. So I want to talk about grammars. Okay. Drop the marker. Yeah. It's like a, you know, some people have like a nice teddy stuffed animal or something as a comfort object. I have a whiteboard marker. Put it down over here. I'm going to use it in a second to draw on that whiteboard. Okay. So here we go. This will be an introduction to context-free grammars and such. Okay. So I'm just looking at this. Yeah, I'm looking at this page and trying to remember some of these URLs. Okay. Okay. Okay. Hello and welcome to session seven from a session. One more time. This is my free Mulligan start over thing. Okay. Hello, welcome to session seven of programming from A to Z. The topic for session seven is grammars and what I mean specifically a certain kind of grammar called a context-free grammar. So in this introductory video, I want to just kind of talk, give a brief overview of what grammars are, what the various, what a context-free grammar is and how that fits into that sort of larger concept of a grammar, so to speak. And what are some tools that you can work with in JavaScript to generate text based on grammars? And then I'm going to, this video is going to end and I'm going to launch right into some code examples of writing grammars and generating text with grammar. So hopefully this is going to be kind of a short video, just give you kind of an overview. If you're not interested in the overview, skip to the next video and get right into the code of using and generating text with a grammar. Okay. So first of all, I have this Wikipedia page up behind me, which is from, which is the Chomsky hierarchy. So one way that I think is useful to think of a grammar, I lost this diagram that I wanted. A grammar is really the structure and syntax of language or you might say the language of the languages of a language. That didn't make any sense. Right. So how do you define how the pieces of a language, so to speak? So there are a variety of kinds of grammars and I'll include a link to Chomsky's kind of seminal paper about different types of grammars. And you can see here this, these are, this is a set of different possible grammars, regular, context free, context sensitive, recursively enumerable. And context free is the grammar that I really want to focus on. And if I go, I have some other links that you can kind of look at that I'm going to put. This is a great language. This is obviously where I got that from, from this article, the grammar being the language of languages. And you can see that there are a variety of different kinds of notation. Backus now form is a kind of notation. It is sort of a syntax of grammar. So we're looking at this idea of grammars outside of programming in a way. And then what we want to do is pull the grammars into our code and figure out how we can, how we can mess around with them. I just want to like do this video over again. Hooray for Backus now. What's something there's, hold on. I just had to, I had to pause for a moment because I'm not feeling it. I can't see the chat. Okay. Okay. Let me, if you guys will bear with me today. I would like to do a take two here. Because I realized, and rather than, sorry, my preview screen is all messed up with the chat. Rather than edit together, I think I'm just going to start over. Because I sort of forgot that I was pulling this idea of the language of languages from this. And then I have the Chomsky hierarchy here. Okay. Okay. So, yeah. So, oh, wow. Somebody said that Nara was actually a professor at the university where they went. That's great. Okay. All right. So, I apologize for this. I try never to do this. But you guys got to cut me some slack today. I almost didn't come. I don't mean to complain. This is awful. Everyone's allowed to have a bad day. Okay. So, here we go. One more time. Let me cycle that camera. Oh, no, this is going to be so short. I want to just get into doing the stuff with the grammar. So, I'm going to make this short. Okay. Hello, and welcome to session 7 of programming from A to Z. And the topic for this session is generating text with something called a context-free grammar. So, what I want to do in this video is just talk a little bit about the broader topic of what a grammar is. And then specifically what a context-free grammar is. And look at some different and give you an overview of what code libraries and algorithms you might use to generate text with a context-free grammar. And as soon as I'm done with that, I'm going to just move into the next video and actually start to implement a grammar to generate stories and text or poems or whatever. And you will see how you can do that. So, if you want to just jump to the code, you can skip to the next video. But here I'll give you kind of an overview. So, if you're interested in the topic. First of all, so what is a grammar? And this is a page about grammars by, by, by. I want to give reference to who this is by. Matt, Matt Might on Twitter. Okay, hold on. Matt, too, will edit this back in. This is a page about grammars by Matt Might on Twitter. I find it a useful overview of grammars. I'll link to it in this video's description. And Matt Might makes the point which is grammar, you can think of it as the language of languages. Right? So, we have language. But how do you describe the syntax and structure of a language? What's the language for a language? And that's what a grammar is. And if I were to scan through this page, there's, you know, different Bacchus Now form grammar. And Bacchus Now, extended Bacchus Now. There's all these different syntax, syntaxes. How do you say, what's the plural syntax? Somebody write in the comments for me. And a variety of ways of expressing grammars for a language. One thing I'll point out to you, whoops, is this is a grammar. Programming languages are made actually with this thing called a context-free grammar. So, I haven't described what a context-free grammar is. But you can see here, this is a context-free grammar for C++ statements. So, you can see what is a statement could be if expression and statement. Or if expression statement else statement. What is a statement? A statement could be do statement while expression. So, this idea of fitting things in to a grammar, a defined structure. So, let's think of, okay. And so, there are a variety of seminal work on grammars. You can read, I'll link to the paper by Noam Chomsky. Where you can think of grammars divided into four categories. So, there's this kind of unrestricted grammar, type 0, which is just basically everything. English language is a highly sophisticated, complex grammar. But there are also context-sensitive grammars, which I think will actually make a lot more sense. Once I describe what a context-free grammar is. So, there's a bunch of different kinds of grammars. And I encourage you to explore this hierarchy of grammars. And think more deeply about grammars beyond what I'm going to do in these videos. But the classic grammar that can be used to create generative text is a context-free grammar. So, let me talk to you a little bit about, in general, what a context-free grammar is. And then I'll show you some tools that allow you to generate with context-free grammars. And then I'll just start to write in code. So, context-free grammar is made up by, I'm going to say, we can use different terms for these things. But there's an alphabet. Or there's a set of valid elements in the language. Like, you can only say, the, cat, meow, and puppy. That's the alphabet of the language. It only has four possible words. Right? There are also, in a grammar, some of these are what are known as terminal. And some of these are known as non-terminal. So, the alphabet is terminal and non-terminal. Now, this is probably a bad idea. But I'm going to just use, like, sort of generic characters for this alphabet. So, let's pretend that we have an alphabet which is A, B, and C. And those are, this is the alphabet. And these are non-terminal characters. I don't know what I put these little quotes around them for, for no particular reason. And then we also have terminal characters. And those will be D, E, and F. Okay? So, these are terminal characters. Now, the grammar will also have production rules. A production rule is a rule, and these are also referred to as, like, replacement rules. So, a production rule is a rule by which, if you have a certain character, like A, what does that get replaced with? Let's say A gets replaced with B, D, E. And B gets replaced with A, F. And C gets replaced with A. So, this now could make up the entire grammar. And I kind of hate what I'm doing here. And I'm doing it anyway. And I knew this morning when I was having the same discussion that I shouldn't do it this way. Because I think this makes so much more sense if I have content here, right? But let's look at it, let's just think about it in the abstract sense. And as I start to go through code examples, we'll get to, well, I think it might, if this is confusing to you, when I have some actual content, it might click in for you. Okay. So, these are the production rules. So, now what I need is, this is sometimes referred to as an axiom or maybe a starting sentence. But what I, I'm going to call it an axiom just to be formal here. What I need is an axiom. So, what do I start with? So, let's say I start with the axiom AC. So, what that means is I start with AC and then I start to go through my replacement rules. What am I doing here? A becomes BDE. So, this becomes BDE. And C becomes A. Now, we do this again. B becomes AF. And D is terminal, so D stays as D. E is terminal, so E stays as E. And A becomes what? BDE. So, I could keep going. Now, I didn't do this very smartly because my non-terminal characters all get replaced with something that is also non-terminal. So, this is kind of, this way, this is known as an expansion. I'm expanding out the grammar by iteratively running these replacement rules over and over again. And when we write the code for this, you'll see this happens with this fancy thing called a recursive algorithm. But you can see here that this is going to go until infinity. But if I were to do this in a slightly different way, for example, I'm going to show you a grammar created by Allison Parrish. For a class that she teaches called Reading and Writing Electronic Text. I encourage you to check out those examples. A lot of my code is ported from her code in Python. And you can see here, here are the sets of production rules. Sentence becomes noun phrase, verb phrase. Or a sentence becomes interjection, noun phrase, verb phrase. A noun phrase becomes determiner noun or determiner noun that verb phrase. So, you can see these are all the possible, and these are all non-terminal elements of the grammar. And then here you can see, here are some terminal elements. For example, an interjection could be oh, or my, or wow, or damn. Sort of like a curse on my YouTube stream. Did I just call it my YouTube stream? That's also a little bit weird. Determiner is this, that, or the. So, if I were to just go to the example, I'm going to not bother looking at the code. But we can see here, if I go to week 8, context-free grammar reader. This example generates, is this the right one that I was looking at? Yes. This example generates sentences based on that grammar. Let me move this a little bit over and zoom in here. And you can see, wow, the bald restaurant sneezes. My, the smug corsage computes that overstaffed corsage. This corsage interprets the blue restaurant. So, there's a lot of corsages in this particular generative system. So, it's interestingly enough, typically, what you might use a grammar for, I'm over here now, and I kind of want to leave this because I think I want to refer to this later. What you might use a grammar for is you have an existing sentence. Maybe you have a bit of code. Like, for example, what if I go to a code editor. I'm jumping around like a crazy person here. Let's see if this works with CodePen. I'm going to go to CodePen, and I'm going to make a new pen, and I'm going to say something like, if for var i equals 0, let's make this bigger, i is less than i++. Now, where's my JavaScript lintern? Ah, here we go. Here. Look at this, unexpected token. So, look at this. How does the code environment understand that the semicolon is unexpected and shouldn't be there? So, normally, not normally, but one way of using a grammar, and in this case a context-free grammar, is to look at an existing sentence, like this block of code, and see if it fits, right? The reverse. See if it fits the structure of the grammar going in reverse. And if it doesn't, right, then there's an error like, oh, there's got to be something here. Like, let's look at it without the parentheses. We can see here, right, unexpected token. So, it's a lot of unexpected token. It's getting some new thing that doesn't fit, doesn't fit the grammar. So, this is one way that grammars are used to evaluate text, and that might be something you explore. But, what I'm exploring is the reverse, which is saying, here is the grammar, start with a sentence, start with an s, turn that into either noun phrase, verb phrase, or interjection noun phrase, verb phrase, and let's see what we get. Again, I showed this to you already, but let me make a new one. And we can see that seagull, right, that is a noun phrase, determiner noun, that seagull, so I can see that that fits, that computes this, corsage, is a verb phrase, right, which is, I probably ended up getting, oh, you know what, that, it actually made the noun phrase, determiner noun, that, so you can see how this gets complicated, right? I'm trying to, I could diagram and run it backwards, but the point is, I don't need to do that. All I need to do is write the grammar, and then if I have a system that generates text, it happens. So, one of the nice things about working with this, and say you're going to do an exercise or try some playful experiment based on these videos that I'm making, is you can just write your grammar. You don't need to write any code, potentially, because there are a lot of existing systems that will read a grammar file and generate text based on it. And so, let me give you an overview. So, I'm going to show you three things. The first thing I'm going to use is a grammar called Tracery, sorry, a story grammar generation system called Tracery for JavaScript, written by Kate Compton at GalaxyKate here on GitHub, and you can see there's a syntax to it, which I'll go over and talk about in the next video. There's some nice examples I'll just pull up. This is one of my favorite ones. I don't know if this is going to... This is called Interruption Junction. So, I don't... I encourage... So, this is... Interruption Junction! I don't know if you guys can hear that, but... Oh, you can't, because I haven't piped the sound of this laptop in through the stream. But I need to click, I need to click. So, you can see this is one of the things that's interesting about working with these generative systems, whether you're doing a Markov chain or context-free grammar or combining them in some way, is really not just the algorithm and what it generates, but the context where you display those results. And I think thinking about dialogue or an interactive animated story system, there's a lot of interesting possibilities there. And if you look through Tracery's... the GitHub repository for Tracery, you'll find a lot of links to a lot of fun and interesting projects made with these kind of crazy grammars. So, Tracery is the number... It's the first video that I'm going to make after this one. We'll be showing you how to build and generate text with a Tracery grammar. Another JavaScript library, Rita.js, that I have mentioned before, has a grammar object, right? It's called RIGrammar. You can add rules to it. You can expand those grammars. You can check if there's a rule. You can load text into it. You can remove a rule, reset. So, you can see that this is essentially a JavaScript library that allows you to generate those grammars. Sorry, that allows you to generate text based on an existing grammar from a file, potentially. So, I'd encourage you to look at Tracery and the Rita library. Finally, I think for educational purposes, and ultimately, if you really want to play around with this idea of grammars and context-free grammar, that is, and customize it highly, you might want to write your own code or at least play around with my example code and modify it. For example, what if, while the text is being generated, you're querying an API to grab words from, say, Wordnik or something like that. You might be limited with using some of these existing libraries or frameworks, but if you've written all of the code yourself, you can kind of add in sort of features that are more procedurally based inside of the algorithm itself as it's running. So, in that sense, the last thing that I'll do besides Tracery and Rita is I will show you how to write your own grammar object. And so, I have an example that makes a context-free grammar object and that you can simply just add rules to it, whether it's coming from a file or whether it's just directly in the code. So, those are the things I'm going to show you. I'm going to make probably two or three or four little video tutorials all about context-free grammars. Somewhere in there, I'll try to make sure I mention the whole idea of a context-sensitive grammar, but I think it'll make more sense once we start looking at the nitty-gritty. Okay? So, I hope you enjoyed this brief overview. Check some of the links in this video's description for more reading and materials about the background and theory of using grammars with text, and hopefully I'll see you in some of the actual coding tutorial videos next. Okay. So, all right. Hopefully that was something useful. And... Next, I am going to use Tracery. So, while you guys are catching up to me, because you'll never catch up to me, I'm going to close a bunch of windows here. And... I'm back to here. And Tracery. I'm here and here. So... So, let me open up my... Whoa. What happened to the context-free grammar? I'm in the wrong place, aren't I? Oh, yeah. Oops. Sorry, everybody. Confusion. There we go. Tracery. So, okay. So, first of all, I will say this... The reason I said you'll never catch up to me is because I... The live stream has about a 15 to 20 second delay. So, you will all catch up to me and bypass me, I hope, at some point. And hopefully you will still continue to watch. Or maybe you won't watch and you'll make your own YouTube live stream. Okay. So, I'm... I guess I'll mention this. I was going to describe what this is, but I'm just going to start in doing the Tracery grammar. Yes, emojis. Emojis are upon us. I want to do a whole... I want to do a whole... I don't have an undefined... I don't have a name. Undefined session all about emojis. So, one day we're going to do a whole afternoon that's just only about emojis and programming with emojis. Okay. I'm so glad when people say I just got the perfect idea because that's the point of doing this. I want you guys to have interesting ideas of things to make. And please share them with me if you do. Okay. So... Wow, there are 138 people watching, which is really exciting and nice. Thank you all for being here. I'm feeling your energy and it's giving me a little bit of a spark. So, let me... Okay. So, what I've got this... Where's... I've got the marker. And I'm going to work with Tracery in this first video. Okay. This, by the way, is something I'm... I'll just talk about what this is in a second. Okay. Here we go. Oh, boy. Remember when I said here we go? Now I really mean it. What time is it? 2.50. Oh, good. We're doing pretty well on time. Hello. Welcome to another video tutorial. This is part of session 7, Programming from A to Z. And all these videos are about grammar, specifically, context-free grammars. So, today I want to talk about a particular grammar generation library for JavaScript called Tracery. Ah, Tracery. Tracery is by Kate Compton, at GalaxyKate on GitHub. It's a wonderful project. It allows you to be really creative with generating text, generating stories, making a Twitter bot, just by putting together a bunch of possibilities, in a way. A grammar, so to speak. So, first I'm going to show you an example. This is actually... This is called Once Upon a Time Stories. It is by a 5-year-old and an 8-year-old who happen to be related to me. They're my children. And they didn't write the code for this, but they wrote the grammar. So, I'm going to just generate a story and read it to you. Once upon a time there was a princess, and that princess was very happy. And the princess liked hamburgers. The princess was very jealous. Then the princess met a lovely, sad chupacabra, and she killed the chupacabra. Yahoo! And then the princess ate the burrito, and she was so sunglasses, and she was heart eyes too today. I don't know. Let's generate another one. Oh, here's a princess again. Ah, dragon. Okay. Once upon a time there was a dragon, and that dragon was very angry. And the dragon liked shrimp. The dragon was very funny, and then the dragon met a... I better stop reading these. We'll edit that down. So, you can see this is one way of using a grammar like tracery to generate. And there's a little bit of color and emojis and stuff going on here, but to generate text. So, let me just look into the code for this for a second so that I can point out to you what the grammar actually... Oops, I'm in the wrong place. What the grammar actually looks like. So, this is what the grammar actually looks like. And the grammar is simply a JavaScript object. And remember, if you watched my first video about context-free grammar, everything is about production rules. Take this and replace it with this. And if you have this, replace it with this. And if you have this, replace it with this. And you've got to start with something. So, if I come back to here, you're going to see here there is a start. Now, there's some strange syntax. There's a hash symbol and a bracket, colon and a character. There's a story. There's characters. But you can see there's a selection of food options, a selection of monster options, that sort of thing. And I should point out to you one thing you'll notice, by the way, is in JavaScript, if you want to have emojis, you can just stick emojis in there. They're read just as text like anything else. I mean, how they're interpreted and displayed depends on what the environment you're living in. But the Unicode characters themselves are there for you to use. Okay. So... Okay. So, let's make our own tracery grammar. And then we'll come back to this one. Okay. So, what am I doing here? I want to go to my example, which is over here. This is some blank code. I'm going to go here, make sure it's running. Great. So, the first thing I need to do is get that tracery library. And tracery as a library is just this JavaScript file, tracery.js. So, I'm going to grab this file. And I'm going to do something silly, which is just copy. I could download it, but I'm just going to copy-paste it into a new file, which I'm going to call... I guess I could have done this not in the video. Tracery.js. I'm going to copy it there. And then I need to make sure if I'm using another JavaScript library that I want to make sure that I also reference it in the index.html file. So, just like I'm using p5.dom, I want to use tracery. Now, another thing, actually, by the way, is tracery is dependent on jQuery. So, it uses jQuery behind the scenes. So, I also should make sure I download and grab jQuery. You could fast-forward ahead 30 seconds if you want. Or maybe this will get edited out. jQuery CDN. And I'm going to go here. Let's just use this. And copy. Copy to clipboard. And I should be able to paste it in here. That didn't work. I'm having this trouble today. Why does this not work? This is driving me crazy. Maybe this will get edited out. Normally, I say that and it doesn't actually get edited out. But this is actually something that could get edited out, especially because I'm doing ridiculous, unnecessary things. Okay. So, if this does get edited out, I'm coming back in. So, I also have a reference to jQuery here. One thing I'll note, by the way, is that you can reference JavaScript libraries either as local files. Like I have a local copy of p5.dom.js here in my folder. But you can also reference libraries through something called a CDN or content delivery network. Meaning, if it's a really popular library, somebody might have just hosted it somewhere. Instead of having to download it, I could just reference the URL. And, you know, there's good reasons for doing one or the other. And I'm kind of mixing and matching here. But I just want to get stuff working. So, now I should have the Tracery library and the jQuery library. And I'm ready to start making stuff happen with Tracery. Okay. So, let me at least just go here back to my example. And wherever that is, I lost it. Here it is. I'm going to hit refresh. And I'm going to go back to my code. And what I want to do is start writing the grammar. So, I'm going to make a variable called – and let's make it a story. And what I need is to have – now, Tracery, by default, looks for something called start. So, I'm going to – you don't have to name it start, but I'm going to call it start. I'm going to say start is – and I'm going to need the chat, by the way, to start giving me ideas for story things. But I guess I'll just be making this up as I go right now. It was a dark and stormy night. So, now, if I have this JavaScript object, which essentially holds the grammar, I should be able to make a variable called grammar. Pause. How do you spell grammar? E-R or A-R? It's A-R, right? Grammar, grammar. It's got – oh, E-R. Ah, E-R, A-R. How do you spell grammar? How do you spell grammar? Is it like – is this like an English or American thing? No, A-R, I think. Which one is the correct spelling? I'm going to use A-R because I think it's A-R. You can all tell me in the chat. Yeah, A-R, A-R, A-R. Yeah, yeah, yeah. That will get edited out. Oops, I misspelled grammar. A-R. Okay, so I'm going to have a variable called grammar. And I'm going to say grammar equals tracery. I think create grammar story. Boy, I don't actually remember if that's correct. So, one of the things when you're working with a JavaScript library is you've got to look at documentation. So, I'm going to just go back to the GitHub page for tracery and just to like kind of remind myself. Yes, tracery.creategrammar spellbook. By the way, if you're looking for an idea, certain things like a cooking recipe or a spellbook, there's a wonderful Twitter bot called ArtAssignmentBot. I don't know that it uses a grammar. But these kinds of highly structured types of narrative scenarios can work really well to have a grammar generate different possibilities. I'll also show you at some point that you can use a grammar to generate, you know, haiku patterns or certain patterns or certain syllables. It's another way to use a grammar. Okay. So, tracery.creategrammar story. Perfect. Now, what I want to say is story. I guess I called it story. Result, I'll call it, equals tracery. And let's look here. I believe it's get expansion or create flattened. Pause. Let me just look up. There's a bunch of different ways of doing this. And because this is actually... Hold on. Time out. I'm going to edit this back. I'm going to go back from where I typed that. Sorry, Matthew. This is going to be a lot of editing, this one. I apologize. I just want to look at how I did it in this one. Flatten. That's what I thought. Grammar.flatten. There's a bunch of different functions. Okay. Sorry. So, now I want to look at the result. And I'll say var result equals grammar.flatten. So, again, why the word flatten? So, there's two words that involve generating text from a grammar. One is expansion and the other is flatten. So, this is the idea of an... Where am I here? This is the idea of an expansion, right? I'm expanding out from the sort of start and iteratively applying these replacement rules. Now, tracery behind the scenes or any grammar system is probably keeping track of the entire tree that's being generated. But all I want is the end result. So, I want to flatten it and get the end result. And that's what's happening over here. So, I can say console.log result. And if I run this, come back to my example. That didn't work. Now, I thought it would automatically use start. Maybe it doesn't. So, I'm going to add this in there. Oh, yeah. Okay. So, I had mistakenly... Oh, maybe it's origin. I think tracery uses the keyword origin as the automatic. And I just used start in my example. So, let me... Nope. I imagined that too. Okay. So, I don't know. I thought we could look at the documentation later. Boy, this is going well. But the point is it doesn't really... Come back to me, code. Help. Let me make sure this is working again. Okay. The point is what I want is to give that axiom, that seed phrase start in... I want to pass that to the grammar. And the grammar object, the tracery grammar object, is then going to expand it out based on all those production rules. Now, right now... And you'll notice that the syntax for tracery, specifically, is a non-terminal element. It's wrapped in the pound or hash symbol. So, this means please replace me as opposed to the word start. And so, if I did something like this, we would have a real problem because this would kind of generate to infinity. I almost want to run it to see what happens. I do. Let's just do it. What's the worst thing that can happen? Maximum cost tag received. So, you can see that this idea of replacing. But what I can do is say it was an... And I can say adjective. And then I could add another rule. Adjective, some possibilities are... It was a dark. Shout out your adjectives in the live chat that's going on right now. Dark. Sleepy, somebody wrote. It was a quiet. So, right. If I give all these adjectives now, now I have two non-terminal characters. Elements, I should say. They're not characters. Start, which generates this sentence. Adjectives, which has three possibilities. And so, now if I run this, you can see it was a sleepy and stormy night. It was a sleepy. It was a dark. It was a sleepy. It was a sleepy. It was a quiet. So, each time I refresh, I get a new possibility. Okay. So, this is level one here of using a tracery grammar. And even this is like plenty to play with. One thing I should mention is that each one of these has a one out of three chance of being picked. And another reason why you might use a system or modify tracery... Think about programming your own sort of grammar generation system from scratch. You might be interested in playing around with those probabilities. What if it's 60... But, of course, I could do that also right here by just... Now I've played with the probabilities that dark has a 50% chance of being picked, whereas sleepy and quiet only have a 25% chance of being picked. Okay. So, let's write a story with a character. And what I'm going to do, actually, I'm going to do something different. I'm going to say I'm going to have a story. And I'm going to just use the same kind of story that my children wrote last night, which is a... And I'll call it a hero. A hero fights the monster. Go, hero, go. But what I want is for this hero to be picked. So, what I... And I'm running out of space here, so let me open this up a little bit. What I want is... So, let me give some options for a hero. And I'm going to say dragon, fairy, amusing... The same... I don't know. I don't know why that makes sense. Character... You know, I don't... Let me just... Pause. Let me go back. Let me make this different. Unicorn. Yes, unicorn. Okay, okay, okay. Dragon. Unicorn. Rainbow. Etc. Okay, so these are my possible heroes. And I want the story... I lost the story. I want to say story... Wait, hold on. Ah! I have to go back. Matt, you can cleverly edit, but I'm just going to go from dragon to unicorn. Dragon, unicorn, rainbow. These are the possible heroes. Okay? So, the story is a hero fights the monster. Go, hero, go. So, what I'm going to do now is I am going to change this to story. So, I want to flatten starting with story. And I'm going to hit refresh. A dragon fights the monster. Go, dragon, go. So, that's good. A unicorn fights the monster. Go, unicorn, go. Well, this is kind of working by accident. A rainbow fights the monster. Go, dragon, go. So, you'll notice here what I haven't done is secured that I pick the same hero both times. So, you know, in this sort of Mad Libs way of thinking about this, sometimes I want to have a different adjective. So, I could say a adjective hero fights the adjective monster. And so, in this case, right, refresh, a sleepy unicorn fights the dark monster. Go, unicorn, go. A dark dragon fights the quiet monster. Go, unicorn, go. So, I do want a different adjective. I want a random adjective for the hero and the monster. But when I say hero, I want to get the same hero twice. So, one of the wonderful things that Tracery has is it has a mechanism for you to assign a production rule. Essentially, like, almost have like a variable that holds something that's picked in the grammar over time across the entire sentence, the story that's being generated. So, in that sense, what I can do here is I want to start with start. And what I want start to render, so to speak, to expand is the story. So, start expands the story, which is this. So, this should be the same. I'm just getting these little stories here. And now, though, what I want to do is put in here bracket. I'm going to assign hero. And the hero actually is going to come from this list. So, I need to give this list another name. This is, let's just call this characters. Hero, character. So, what this does is it says, render the story with a character being picked as the hero. So, first it will pick dragon, unicorn, or rainbow, assign that to hero, and then use hero throughout there. So, now as I render this, you can see a dark rainbow fights the sleepy monster. Go, rainbow, go. A dark unicorn fights the quiet monster. Go, unicorn, go. So, this is basically it. This is how tracery works. You know, I could keep going, and it would be sort of like an interesting experiment. Maybe what I'll do, actually, is we could create on GitHub some type of collaboratively edited grammar. If I publish this example, maybe I'll include a link to the grammar in this video's description if people want to contribute to it. Because really the creativity now lies in how far can you go with this? How long can you make this story? What is the story? What types of other things might you assign and pick randomly or assign in advance? But I just want to show you one other thing. Tracery also includes modifiers. So, for example, if I put.s here,.s will pluralize whatever character is picked. So, this isn't going to make a lot of sense. But you can say, a sleepy dragons fights the sleepy monster. Go, dragon, go. But the reason why this is a nice quality is I don't have to include a particular rule that's like plural character. Or I don't have to include dragon, unicorn, rainbow, dragons, unicorns, rainbow. So, there are a bunch of modifiers. I can also use, I believe,.capitalize is a modifier that's built into tracery which will capitalize the particular word. So, if I'm picking that here and putting it at the beginning of the sentence, I can always make sure that the grammar generates in such a way that that word is capitalized. And if you look through the documentation, I believe here we'll find also some... There'll be a list of modifiers. Okay. I also should mention here, by the way, one thing you might look at is under here there are many new examples of tracery in use. And I also have an exciting new interactive tutorial. So, I'd also encourage you to check out this tutorial which allows you to sort of type the grammars into these boxes and hit re-roll and see what kind of possibilities you can get. And the features are kind of explained through the various possibilities here. Okay. So, there's so much more here that I want to look into that I haven't. So, maybe someday I'll come back and show you some other additional advanced, so to speak, features of the tracery library. So, this example will be published for you. I encourage you to write your own grammar. Of course, you can use emojis as possibilities as you can see. And we can go back now, by the way. I might as well go back just to return to the beginning of this video and show you now the code which we can see here. Now we can understand how this works. That this story starts with a hero picked from a character, a villain picked from a list of monsters. And then the story is once upon a time there was hero.a which means a hero. It's always going to modify it with a. And that hero was very adjective and the hero liked food and the hero was very adjective. And then the hero met an adjective villain and she killed the villain! And the hero ate the food and she was so adjective that she adjective... that she was adjective to today. And if I go back to this, we can generate one more story. Thank you. Once upon a time there was a bear and that bear was very funny and the bear liked ice cream and the bear was very pretty. Then the bear met a happy, lovely dinosaur and she killed the dinosaur. Monkey face. And then the bear ate the... acorn? Walnut? I don't know what kind of nut that is. And she was so smart and she was green heart jealous to today. Okay, so thanks for watching this video on Tracery. If you make something with Tracery, please thank Galaxy Kate on Twitter I would say. Or contribute to the Tracery project or support it in some way. And I look forward to hearing what you think and what you make. And in the next video I'm going to look at the Rita library with context free grammars. Oh, oh, before I leave, you can also use Tracery as a node package. So maybe someday I'll return to that. But you can npm install Tracery and there's documentation for that on the Tracery GitHub as well. Okay, thanks and see you in another video sometime. Okay. Okay, everybody. I see everybody in the chat. I think I'm... how's the sound and everything? Am I finally better? You know, it's very nice of you guys to ask me. TwoTubers asked, are you finally better? You know, I was better and then I think I kind of caught something again. So I'm a little bit of... I'm feeling a little bit under the weather again. But, you know, I'm 94%. But it is a very busy week this week. So I'm a little run, a little haggard. But I'm okay. Don't worry too much about me. Cut. Yes. Okay. Everything looks and sounds good. Thank you, Mathieu. Mathieu in the chat does a wonderful job. Mathieu was gracious enough to figure out a way to, like, blur out some of the stuff so we could at least keep this video. What was the name of that art project bot? Yeah. Yeah, they took my weather, my rainbows. I'm under the weather. So let me show you guys. Art assignment bot is one of my favorite bots. I don't know who makes it. Oh, Jeffrey Thompson, it looks like. But this is a bot. I'll just read you a few. Create a welded metal sculpture with sows. Due Tuesday, November 2nd. Produce an etching with readiness. Due Sunday, October 25th, 2026. Create an intervention in the landscape using sub functions. Due in four seconds. So you can imagine how a bot like this might be made with a system like Tracery. Okay. I should look at ulipo.org. Oh, yes. Ulipo is a French collective of writers, I believe, as Code Cheetah in the chat mentions, from the 1950s, and does a lot of interesting work with generative text and different algorithms. Can you update your Atom package? What do you mean by that, the real crazy? Is there some sort of message here that's saying, like, I need to update? Oh, yeah, one update. I don't want to update right now. You're making me do it. Oh, okay. Sure, why not? Oh, this is dangerous. I'm updating! It's happening. Okay. Okay. So let me think now. Let's look at context-free grammars in Rita.js. And I actually so let me see if I can get set up for this. I'm kind of just making this stuff run in the console as opposed to generating anything on the page. So I'm going to make a new example. Okay. So let's trace the grammar. Let's do CFG Rita. Okay. So let's make this go back here. Session seven. CFG Rita. And then I'm going to go to where am I here? Sketch.js. I think what I will do here is I am going to just get the Rita library now. Ah, Coder for Life asks, hey, Daniel, are you going to talk about our briefly mentioned compilers? We're talking about grammar and stuff which can be linked to syntax rules. You even brought up Bacchus now form and stuff. Yes, I did reference it and I did briefly show a slide that showed a kind of syntax, a grammar for C++ expressions. I'm trying, I think in the limited time I have today to stay in the sort of creative writing text generation side. I don't have but I do think that is a rich and interesting topic. I would love to explore it. So let me think about that if there is a way that I might be able to look at that a little more later today or come back another time if that becomes relevant as well. Okay. So Rita.js. Let me go to distribution. Actually, I can just go to releases here and download this. And I'm sure I have Rita.js somewhere anyway. But let me look for distribution. Distribution is the same thing. Rita. So let me just use Rita full even though I might only need the smaller library for this. So copy. A to Z session 7. Put this here under libraries. And let me go back to the code. So I want to just get this set up in advance of doing the video. I don't need jQuery. I don't need tracery. But I do need I don't know why I've done this differently. I do need Rita. Rita-full.js. Okay. So now what I want to do is I also want to get a grammar file. Let's see. And let me see if I have. I guess I'll use this grammar file which comes from Alison Parrish. Sorry. I'm kind of like poking around here. Let me see how this goes. Test.grammar. And save. Okay. So let's go to the other thing that I believe I have. If I go to context free grammar Shiffman. I believe that I have a link here to Daniel Howe's page which I will reference. Okay. And let me just see here if this. Oh, this is a different format. Interesting. So let's see. So Rita looks like it expects this format. So I'm going to paste this in. Daniel has own property. Daniel Howe. Auto complete. Adam, please stop. And then let me just paste this URL in. Okay. So let's, oh, first of all, let me change this because you know me. Okay. So a, the rainbow, unicorn, and what is something that a rainbow and a unicorn does? Dances. Start, noun phrase, noun phrase, verb, noun phrase, a, the unicorn, rainbow, and dances. So, okay. So we're going to look at this. So I think if I just close everything out here. I am now ready to look at Rita.js and context-free grammars. Here we go. RI grammar. Okay. Oops. Back. Okay. So how's everybody doing here? Let's look. Oh, there's some discussion about code editors. So by the way, there is a, for p5.js, which is a JavaScript framework that I do a lot of my teaching with, and I work on as part of the Processing Foundation, there is currently a downloadable desktop editor. I'm choosing in this course to just use an editor like Atom or Sublime, a separate text editor, and then run my own kind of local web server. I will mention that soon, hopefully in 2017, early 2017, there's going to be a release of a web editor. And I should also just mention, by the way, give a little plug to Sinan, the creator of Open Processing. Open Processing just had a redesign, and it's really quite amazing. You can now create p5.js sketches in Open Processing. You can upload them. You can have an account. You can share them. It's a bit of a Flickr-style site for sharing JavaScript sketches, in particular made with Processing, Processing.js, or p5.js. So you should join. You should sign up. Tweet at Open Processing on Twitter and congratulate Sinan and all the work that went into this. So I would also encourage you to, this is something that maybe I'll take a look at using it in a live stream at some point. Okay. So let me come over here and see where I am. Great. And here we go. Let me just look at this real quick. New grammar, expand. Okay. Add rule. Okay. Okay, everybody. So, okay. So an hour and 20 minutes in, there's 117 of you still watching, which is really amazing. I thank you. I appreciate you. And now we're going to look at context-free grammars in the Rita library. And hopefully after this video I'm going to have time to build a little context-free grammar generator from scratch, if that interests you, which I think it might. Okay. So I'm going to get started now. I'm going to do some jumping jacks. Okay. Hello and welcome to yet another video about context-free grammars. Can you believe it? This is my life. I'm making, this is like my third whole video about context-free grammars. Okay. Now, in this video what I want to do is show you another JavaScript framework library for generating text using a context-free grammar. And the library this time that I want to show you, ah, I can't see myself in my preview screen. Let me fix this. Ah, over here, is called Rita.js. Now, Rita, I introduced the Rita library in a previous video, which you'll find linked in this description, which it has a lot of features and functionality. But one thing I didn't explore in my previous video was using the Rita grammar object. So if you are wondering what a context-free grammar is, I encourage you to double back a couple videos where I kind of talk through the pieces. But just to remind you right here, in a sort of quick way, a context-free grammar is a system for generating text based on, ah, I'm going to, I'm going to, ah, Matthew, you're going to, sorry, you're going to have to have a little edit point here. Um, I hate my, um, I hate my generic, like, nonsense characters because it would make so much more sense. I'm going to go back to where I say, ah, it would make so much more sense if I said, um, sentence is, and then if I said noun is, ah, there we go. So, um, just redoing this diagram, even though it won't be in any video. Go back and redo my first video. So this becomes the noun, verb, and this becomes cat, and this becomes, you know, barks. Okay, and then this is the flattened expansion. Okay, I'm going to have to, there's going to be like a magic moment where this, if we edit this together, where this diagram just magically transforms into something else. Let me just, I'm just going to start this over. Um, or I can start over from where I walk over to here. Um, so I think I'll be able to do that. Okay, uh, alright. Okay, so here we go. I'm going to, somehow this will get spliced together. Matthew, you let me know if this is a disaster. I can always re-record the beginning of this too. In my, uh, one more time. In case you're wondering what a context-free grammar is, um, very, you can go back, double back a couple videos where I describe to you what it is. I think I better just start this whole video over. Okay, it's fine. Ready? Come on, everybody. You're with me. I'm with me. Let's go. Hello and welcome to yet another video about context-free grammars. That's right. Video after video after video about grammar and programming, if you can believe that. So, um, here I am in this video. So in this video what I want to do is show you another, different JavaScript, uh, library that allows you, that will generate text based on a grammar, uh, for you automatically without you having to write the... You know what I got tripped up on there? Is I like, oh, I liked my weird little spontaneous joke about having made multiple... I'm just looking at the chat for no reason. Um, okay. One more, one more, um, one more time, everybody. Someday, I don't know. I'll have a more fluid way of doing this. Hey, hello there. Welcome to another video about context-free grammars. That's what I'm talking about. So, um, I've already done, I've sort of explained what a context-free grammar is. I looked at a JavaScript frame, a library called Tracery. And in this video I want to look at yet another JavaScript library, uh, called Rita.js that has, uh, a functionality that allows you to generate text based on a grammar. Now, I, I previously made a video about the Rita.js library. I showed some other aspects of it, um, ways that you can generate and do and evaluate, actually analyze text with the Rita library. And I'll make sure to link to that in this video's description. So I encourage you to check that out. But an aspect that I did not look at is the R, the Rita grammar, the Ri grammar object. So how does the Ri grammar object work and what kinds of things can you do with it? Okay, so first of all, um, the Ri grammar object is designed for use with a context-free grammar. Now, if you're wondering what a context-free grammar is, you can double back a couple videos where I maybe talk through it in a bit more detail. But just to remind you, if you're wondering, a context-free grammar is a, is a system that defines the structure of a particular language. And in this sense, it could be a very small, tiny little language. Like, here's a language that has only these elements. Sentence, nouns, verbs, and the cat, dog, meows, and barks. So there are terminal and non-terminal characters. These are non-terminal characters, meaning they get replaced with something. Sass, for sentence, gets replaced with the noun verb. Noun gets replaced with cat or dog. Verb gets replaced with meows or barks. So if I start with sentence, this gets expanded to the and v. The is terminal, so it stays as the. N becomes flip a coin, cat or dog. V becomes flip a coin, cat or dog. And we get this expansion. So certainly, the idea here is to design sophisticated and interesting grammars with all sorts of creative language in them to generate text with some purpose. Maybe you're making automatic Harry Potter spells. Or maybe you're making recipes that are going to randomly generate. You're going to cook some strange thing for dinner based on what your context-free grammar made you. Lots of possibilities there. But let's see if we can figure out how to make a simple grammar work with the Rita library. And then we'll also look at some other examples of grammars that you can generate with the Rita library. Okay. So looking at this, the first thing you might notice is I need to say make a new Rita grammar object. So let me go to code. And I'm going to say var. I'm going to call it RG, just like in the example. By the way, Rita is by Daniel Howe. Thank you, Daniel Howe, for this wonderful generative text library. I encourage everybody watching to thank Daniel Howe and contribute to the development of Rita. RG equals new RI grammar. Now I'm going to leave the argument here empty. So ultimately, there's a lot of different ways that we might be able to create the grammar. I could do it dynamically in code by just adding the rules, which is what I'm going to try to do right now. Or I could load the grammar from a preexisting file. And I can mix and match, too. But let's try to just dynamically generate it with code. So the first thing I want to do, just looking at this, is see if I have an object there. So you can see I have some Rita grammar object. It's got, like, some rules in it. Something's happening, but I can't do anything yet. Now, if I go to here and I say, let me look at a result. Let me expand. Remember, an expansion is expanding from the sort of start of the grammar out and getting a sentence that fits that grammar. So if I get some sort of result and I say console.log result, I should get nothing. So no grammar rules found. So the first thing that I need for a grammar to do anything is to have some rules. So let's look now at the add rule function. So the add rule function requires a name. Oh, look at this. Oh, wait. Oh, I love that this has that. That is so fantastic. So it has the rule name and the rule definition and the rule weight. So here's the thing. We're going to have to figure out what does Rita. I honestly don't know this. I'm going to figure this out while doing the video. What does Rita expect that how this is formatted? So I'm going to look. I'm sure there's an example that I can look at. But on the one hand, I know that I could say RG.add rule. And so I could say maybe like start becomes a sentence. Or, you know, I could let me just say the cat meows. There's a rule sentence becomes the cat meows. The probability of a weight of one. Now, I doubt that's enough. So that did not work. So I expect that I've got to conform to the syntax of the Rita library and how it expects it to work. Now, I'm kind of getting a little clue here. Rule not found start. So I think by definition, Rita probably expects – I'm just guessing from looking at this error that Rita expects there to be a rule called start. So let's see if that works, if I now get the cat meows. Ah, I did. So now every time I get the cat meows. Now, how can I get maybe – so let me see if I can now call this. Now, I'm expecting maybe if I make a rule that has this syntax with the sort of tag symbols around it, I can say add rule n and I can say cat. So now let's just see if I have a rule which the start is the n meows and maybe I'm going to get cat. Perfect. Now, how do I get – now, I have a feeling that the syntax it expects is this. So there are a bunch of sort of conventional syntaxes for grammars. And you're going to see them in a variety of different ways. You can encode it in JSON as we saw in tracery with those sort of pound symbols. This, I believe, is based on some standard. I should look it up and try to figure out what it is. Annotation appear here to explain. But I have a feeling based on what I've done before and seen before that it's expecting the pipe symbol as one or the other. Let's say what would happen if I didn't do this, okay, cat, dog. Well, I'm going to get the cat, dog, meows. That's what I'm getting. That's the whole thing that's replaced. But if I put this pipe symbol here, the cat meows, the dog meows, the cat meows, the dog meows. So we can see now the rules. Now, one thing I'm curious about is does this require these tags? It does not. The cat, the cat, the cat, the cat, the dog. So we can see here that this can be a useful distinction just for ourselves to kind of illustrate what I mean to be non-terminal, maybe put the tag, the greater than, less than around it. And that can be useful here. So one thing that I'm kind of the other thing that I'm kind of curious about is if I say this, I could also probably put them in a separate line, the dog, the dog, the cat, the cat, the dog. And so now let's look at let's think about this weight. So if I go back now to the documentation and we look at the rule weight optional defaults to one. So how might I alter the probability? So I'm just going to make sort of a guess that if I do something like five, then I've got kind of a five to one, maybe a five out of six chance of picking cat over dog. And what we could do is I could also do this, you know, maybe a hundred times just to sort of see how this works. And let's run this. And so you can see here it's picking cat, you know, pick cat 16 times, then a pick dog and cat four times, then a pick dog and cat four times and cat seven times. So you can see that that weighting allows you to add the rules and kind of weight them particularly. And I could also probably do cat or unicorn. And both I'm imagining both of those probably have the weight of five and the dog has the weight of one. So if I ran this again, we can see there's going to be a lot of cat and unicorn and not so much dog. I'm sort of guessing. So I'd have to really like strictly evaluate how this is working. But you can see it's nice that you have this ability to manipulate the weights. So if I go back to this particular simple scenario, let's just finish implementing that. I'm going to say the noun and I can add a cat, unicorn, dog. I'm going to just leave the default weights. And then I'm going to add another rule. What sound does a unicorn make? Meows, cat meows, the dog barks, the unicorn, the tulips. That's the sound of a unicorn. It's a word that I made up called tulips. And then I'm going to put a period here. And so now we can see if I generate this, we can see all of these different possible sentences, all which conform to that grammar. So this is a very basic idea. You can imagine how you could make this much more sophisticated through nesting. So I'm going to kind of like stay away from more exciting and interesting possibilities with this. Here I'm just kind of giving you the building blocks. But let's look at actually what happens if you want to encode a grammar, not in your code but have it come from a separate file. So what I'm going to do there is I actually already have that here. So this is a particular grammar. It's a little bit further along from what I just made in that example. And you can see it written with this particular syntax of the production rules. S becomes noun phrase, verb phrase. NP for noun phrase becomes a term or noun. Verb phrase becomes verb or verb noun phrase. Term is a or the. A noun is rainbow or unicorn. And V is dancers. So the syntax that Rita expects, though, however, looks something like this. So you can see start. We have curly brackets. Start becomes noun phrase, verb phrase. Noun phrase becomes a term or noun, etc., etc. So you can see. And then noun. Okay. I think I'm back. And hopefully... Okay. That's as good as I'm going to get it right now. Okay. So let me see where I was. The function of file or URL. Check of the object. Okay. So what are the options? I'm just reading this. Function or object. Oh, I can do a callback. Great, great, great, great, great, great, great. Okay. So let's see if we get this to work. And I think I was coming over here. Okay. So I'm recording this. I'm going to try to... I have this sort of panicked feeling that I forgot to do something. No good. I didn't. I had a panicked feeling that I forgot to hit record to disk for the whole first hour and a half of this. YouTube would save it. But it's really good to have the disk backup because sometimes the stream has a problem with it and I sort of thought I forgot to hit record, but I did not, thankfully. Okay. What time is it? 3.45. Oh, I'm kind of running out of time here. But I'm going to keep going. So I'm just sort of curious here to see... I'm just going to... Okay. Okay. So I'm going to go from where I attempted to... I'm going to go from where I attempted to load from a file. Okay. So I'm going to go here to the reference and look at load from. And if I look at load from, I can see here's a function, load from file or URL and then option. And in JavaScript, that option we can see here in JavaScript is a callback, at least to tell you when the file is loaded because that's not going to happen immediately. So let's go to the code. And I should be able to now say... Rg load from test... Oh, and then the name of the file, test.grammar. And then I'm going to give it a callback. I'm just going to call it grammar ready. Do you guys hear that beeping? Something beeped. I have no idea what it was. Edit that out maybe. Okay. Grammar ready. Then I'm going to write function grammar ready. And I'm just going to say console.log ready. So let's see if this works. And I'm going to comment this out down here. And I'm going to run this again. Let's see if we at least see the callback happen. So grammar appears to be invalid JSON. Please check it at JSONLint. If you are using YAML, please be sure to include YAMLJS. Hmm. So I think I need to work on the formatting of this file. Time out. So I guess this wants it to be JSON. So why... So I'm going to have to figure this out and edit this. I actually have not used the Rita library for the context-free grammar stuff before. This is how I do things. I don't try them. I just try to... I'll teach this thing that I don't actually know. And I just try it. Okay. So let me see... Let me look for example... What I want to see is Rita.js examples. And haiku grammar. Yeah, yeah, this is what I want to look at. So let's look at this. Aha! Interesting. So how is it doing this? Is that YAML? Ah, so it's... So this is using the YAML format and then loading it. So I don't want to do it that way. I want to do it, I think, with JSON. So... So let's try to make that work. Okay. I think I'm going to do this now off, not in part of the video because it will be tedious to see me try to retype this. But let me make a new file. I actually have a... Oops, I'm in the wrong folder. So I'm making a file called grammar.json. Now fortunately for us is I have done this before. Aha! So I have a feeling that this is the syntax it wants. So let's see if that's the case. And then I'm going to... And then I'm going to go to grammar.json. Aha! So that's promising. No, rule not found start. Let's see if that does it. Oops. Oh. There we go. Okay, so this, that works. So, okay. So I guess, I don't know where to splice all this in. So I think I'm going to... Ah, I'm going to do the cooking show thing. Where I'm going to go back and have that error. And then switch to the JSON file. So let me go to here. And go to test.grammar. And then, oh, let me modify this grammar. To just be this simpler thing. So, hold on a second. So it's, I need start, noun phrase, verb phrase. And then noun phrase is determiner noun. Noun phrase is... And then, I'm simplifying this. I know the camera just shut off. Hold on a sec. And then verb phrase is verb or verb noun phrase. I'll turn this back on. Is... Verb is, oh, this is silly what I'm doing here. Is verb or verb noun phrase. Uh... Verb, so this could be an array. Verb. Or... I wonder if this is actually right. This is kind of a mess. I should have just gone to making my own grammar. Verb noun phrase. I just want to, let me do a simple one and we can test it. And then... Determiner is a or the. Got that. I'm just going to change that to a or the. And then... Noun, unicorn or rainbow. Rainbow. You guys are very patient to be watching this. Hopefully you're all doing something else right now. And then... Dance, verb dances. Whoops. Whoops. This is just noun. Verb. And... Boy, the grammar that I'm getting rid of is much more interesting. Which was, thank you to Alison Parrish. I'm not, so I think that's everything now. So if I were to run this. Okay, whoops. So where's my syntax error? Here's a JavaScript object. Start is this. Followed by noun phrase is this. This. Let's go to JSON formatter. Let's check my JSON. Error. Where's the error? Dance has a comma. This should not have a comma here. And let's see if now... This gets me what I want. Closer. I'm sure some of you see this. Leave off the comma. Oh, this is not going well today. JSON formatter. Hey, duplicate key. Verb. Oh, okay. That's a problem. No, duplicate key should be fine according to... The way I think this works. Oh, so sad. I could have sworn I had this. Oh, there's a comma here. I don't even have my sound effects or debugging music. Let's... That. Oh, okay. Whoa. Definitely was some mistakes there. All right, what's going on here? Oh, okay. Let's see here. Okay. Okay. This is this. This is an array which has three things. This is an array which has two things. This is an array which has two things. I don't see any syntax error. You don't have verb phrase. Oh, thank you. Oh, verb phrase. Oh, that's why I had a duplicate thing. Thank you. And... Okay, hold on. Thank you. Verb. And then... And then... Verb. Dances. Let's see how this goes now. So close. Look at this again. Verb phrase. Verb. Noun phrase. Hold on. Let's paste this into the formatter. It likes it. Duplicate key. Where's my duplicate key? I don't see a duplicate key. Oh, I've gone off the rails here, everybody. Should this be in an array? I guess I should have looked at this beforehand. It's funny because when I just... All right, let me go back. Backwards. Let me go back and get this grammar that I know works. I don't know what I did wrong. But I'm going to just use this one. And I will... I don't know why... And now I've lost where I am. I'm going to use this one. And I will... I don't know why... And now I've lost where I am. I'm going to use this one. I didn't mind this one. Maybe am I... Didn't that work at one point? You're trying to load test. Am I loading the wrong file? I've totally lost where I am. Ah, it's in test.grammar. Oh my god. I'm going to try to load test.grammar. Oh my god. The whole time. The whole time I'm loading the wrong file. Yeah, okay. Sorry everybody. I was losing my mind. I probably had it correct all along. Okay, so... Let's... Oh my goodness, everyone. Okay. Da da da da. Stretch. Welcome to life as a programmer. Wasting half an hour on an incredibly obvious... Wasting half an hour on an incredibly obvious... Wasting half an hour on an incredibly obvious... The other day I was actually in a classroom trying to get something to work and I just hadn't saved the thing. Losing my mind here. Okay, I'm going to get through this. I have no idea how this is going to get spliced together. I have no idea how this is going to get spliced together. But I'm going to go back to the point where... Right? Because remember I put this in here because I was going to demonstrate how I was going to have an error. So I'm going to just go all the way back to where I'm going to load it from a file. So this is where I last was. So this is where I last was. This is a high degree of difficulty. And here we go. Here we go. Okay. Okay, here we go. Okay, here we go. So what I want to do now is try to load the grammar from a file and I can look here in the reference and look at load from. Whoops, I clicked on the wrong thing. I'm going to click at load from. So what load from says, load from a file or URL with an option. So in option, the option in JavaScript is going to be a callback because when you ask for a file it's going to happen, the file is going to be loaded asynchronously so I need to know when the grammar is ready. So there are a bunch of different ways grammar files can be formatted. And a typical way you might see is with a syntax that looks something like this. And I have some examples that when you look at the code examples that load files that look like this. Here's another sort of way that looks a little bit like JSON. This I found in some of Daniel Howe's examples. But Rita, so I'm going to try loading this particular file which is a.grammar file. And whoops, so let me comment this out. And I'm going to say rg.load from test.grammar and I'm going to say grammar ready. So this is my callback for when the grammar is ready. I'm going to just say ready. And I'm going to say ready. So if I do this and run this now it's going to say, ah, grammar appears to be invalid JSON. Please check it if you're using YAML. So there are so many different kinds of standardized data formats. There's XML markup and YAML and blah blah blah blah blah blah. If you've watched some of my data videos I kind of cover some of these different formats. I think JSON is going to be the easiest format for us to encode a grammar and then load it into Rita or another program that we write. So I actually have already taken this exact grammar and rewritten it using a JSON syntax. And you can see that here. So I have a start which is a noun phrase or a verb phrase. A noun phrase is a determiner and a noun. A verb phrase could be verb phrase followed by a noun phrase or just a verb. So you can see there is some nesting into this grammar. And then here you can see the sort of terminals. And each key has an array for multiple possibilities. So now if I were to go back to my code and load grammar.json I should at least be able to run this. And I see no error. I just see ready. And now I have a grammar already going and I could say result equals grammar rg.expand and then console.log rg. Here we go. We can see. Oh! Look at that. What did I just say? rg. No, that was interesting though. Result is what I want to see. And we can see the unicorn dances. The unicorn dances the rainbow. The unicorn dances. The rainbow dances. A rainbow dances the rainbow. A unicorn dances. A rainbow dances. A unicorn dances. A rainbow dances. A unicorn dances the rainbow. Somebody could make a song out of that. The unicorn dances the rainbow. The rainbow dances the rainbow. Unicorn dances the unicorn. Okay. So, yes, please not yaml someone says in the chat. Not to worry. So, now we can see here once again just as with tracery, it's your job if you want to work with context free grammars to design the grammar. And this is an effective way of working in that you could actually have a completely separate file where you put all of the grammar. So this could become very long. In fact, you might start thinking about how could I do things like whenever I get to a noun instead of picking from just a fixed list, actually use the read a lexicon to give me a random noun or query word nick like an API to get a noun from. There's a lot of possible ways you could sort of think about this. One other grammar that I want to show you which again is thank you to Daniel Howe, the creator of Rita. I'm going to see if I can pull this up because I have it in one of my other examples. Ah, this one. So let's see if this works. I'm going to copy paste this grammar and I'm just going to put it over right here, grammar.json paste it in, hit save and I'm going to run it and we can see now and actually what I'm going to do is let's be a little bit more sophisticated about this. This is a very sophisticated cooking show. By the way, this is called the cooking show now because I'm like cooking with code. Maybe that's it. Button equals create button generate button.mousepressed I'm using the p5 dom library to attach a click event to a button and I'm going to say new haiku and then I'm going to say function new haiku and I'm going to say, and now I'm going to do here I'm going to get the result is expand the grammar and then I'm going to say create p result so let me run this and we should see result is not defined, line 12 I forgot that I have some extra code there. So the idea here is that I generate and I get these haikus now a couple things about this why is there this percent sign in there? So one of the things you can do when designing a grammar is kind of create your own protocol. Like, I really what I want to have is like a br tag there so I could just go into the grammar and just do this which will probably work and because I'm outputting to html I'm getting a br tag but I might be outputting to other things and I actually want to replace that with a line break so but you can see here, let's look at how this grammar works. This is an interesting way that you can use a grammar to generate a haiku. So haiku form is a complex thing there is a variety of ways you can sort of think of haiku but here's one scenario a line with five syllables a line with seven syllables and a line with five syllables so that is the start axiom then here are all a bunch of ways you can create a line with five syllables a one syllable followed by a four syllable a one syllable followed by a three or a one a one, a one three, one two two, one two one one so you can see here's a whole set of possibilities. Here are possibilities for seven line. Notice how I'm reusing the five line here because I could have one one five line, two five line, five line one one or five line two and then here's a whole lot of one syllable words this is all from Daniel Howe a whole lot of two syllable words a whole lot of three syllable, not just words but phrases, four syllables, etc so now if I were to run this we can see I'm always going to get cranes Japan I'm going to get five syllables cranes Japan day breaks followed by seven, dawn smoke Japan dawn rushing followed by five syllables, through smoke Juniper. So I encourage you to think about what might be some creative ways you can write a grammar to generate text and now we've seen how you can do this same type of context free grammar with tracery, we've seen how you can do it with the readalibrary and in the next video which will be coming at some point if it's not already there, I'm going to just kind of look at the basic recursive algorithm for doing this expansion from scratch in case you at some point want to start playing around with the guts of how context free grammar generation system works ok, thanks for watching ok um alright thank you, yes, coding nightmares is probably a good name I'm way past the time that I said I had until but I want to see if I can get through the last couple topics here or I might come back later, I'm just going to check I'm going to mute my, I'm going to put some music on for you guys um I'm going to mute my microphone for a second and take a little short break and then I'll come back and let you know what I have time for left, so let's play F Looper's Perlinois Song this is random, this is noise Perlinois that is, in the core random algorithm, the actual random algorithm, it's probably really really quiet right? related at all I'm picking random numbers between 0 and 10, 8, 2, 7 6, 1, 9 4, 8, 9 2, 1, 3, I picked 9 a lot apparently, but with Perlinois I might pick numbers like this 2, 3, 4, 3, 4 5, 6, 5, 4 5, 6, 7, 5 6, 7, 5, 6, 7, 8 9, 8, 7, 6 this is like Perlinois's performance art 9, 2, 7, 6, 1 9, 4, 8, 9 2, 1, 3, I picked 9 2, 3, 4, 3, 4 5, 6, 5, 4 this is like Perlinois's performance art 7, 5, 9 2, 7, 6, 1 9, 4, 8 but with Perlinois's I might pick numbers like this 2, 3, 4, 3, 4 5, 6, 5, 4 5, 6, 7, 5 6, 7, 5 Perlinois's that is, Perlinois so this is Perlinois's that is, Perlinois this is Perlinois's that is, Perlinois I'm back but I'm gonna take still another break to get some water and then I'll be back again but I'm gonna take still another break to get some water yes, it is on Soundcloud, so I made the check and give it a listen but with Perlinois's I might pick numbers like this 2, 3, 4, 3, 4 5, 6, 7, 6 Perlinois's that is 6, 7, 7, 8 Perlinois's that is 2, 3, 4, 3, 4 5, 6, 5, 4 5, 6, 7, 5 6, 7, 5 2, 3, 4, 3, 4 5, 6, 5, 4 5, 6, 7, 5 6, 7, 5 this is like Perlinois's performance art Perlinois's Silence Silence Silence I guess the music ended but I am back now Ok, let me see, Ok So Alright, so that was Yes, you look at like on SoundCloud There's a bunch of remixes that people have made Including the This Dot song Which I know you guys have enjoyed in the past Ok Boy, I'm having trouble with this context free grammar topic So let's see, let me Let me see if I can manage To make, to do another Video Where I just Where I kind of program the context free Algorithm from scratch I don't need draw, Ok So let's try doing it And then what I'll do is I will compare it to This particular example Which has this all in a Kind of function, Ok Ok, here we go, so I'm going to do that now And I'm hoping this is something that I can do In Just about 10 or 15 minutes Ha ha ha ha, that means it's going to take at least an hour and a half I'm sorry, I'm looking at Twitter, people are tweeting at me Ok, let's give this a try, shall we? Ok Hello, welcome to another Another, oh my god, I can't believe I'm making a fourth or fifth I've lost track, video about context free grammar So in this video I'm going to do something a little scary Which is instead of using an engine or library or framework Like Tracery or Rita, I'm just going to program a little context free grammar Expansion system without anything at all Just my own wits and fingers We're going to see how that goes, right? So remember the idea here is that I have a system, a language That has valid elements of it, valid letters of the alphabet, so to speak There are a set of production rules And I'm going to use a very simple set of production rules And try to write a recursive function A function that references itself to recursively expand this grammar tree It'll be like magic, I think Or there's going to be a lot of problems that are going to happen Ok, so I have pre-existing examples where I've done this But I think I did that many years ago and I ported it from somebody else's examples Namely Allison Parish's wonderful Python examples Link to Allison's resources on a course called Reading and Writing Electronic Text In this video's description So the first thing that I want to do is I know I'm going to need some sort of object Probably a JavaScript object that has a set of rules in it So, and I could just write these in Maybe I'll just write them in So I could say, and if I'm kind of going off of what's here I could say, ok, a sentence becomes the NV And a, well I have to go over here and look A noun is a cat or a dog And a verb is a, whoo, a meows or barks So again, this is my incredibly lame grammar Boy, we could do so, so much better And we also have to think, well what really is going on here Should I be, what syntax should I use Like, maybe it makes more sense I think it might make more sense I sort of prefer to do this, like have these all be an array Because an array is going to be easier for me to work with ultimately So I'm going to do that Right, I don't want to have to parse this pipe symbol and all of that So what I'm going to consider is an array Is an array of options with equal probabilities And right now the only possible sentence is the NV The only possible N's are cat and dog And the only possible V is meow and bark So what I want to do is I want to figure out now I need some sort of expansion algorithm So what I need to do is I have a start So my start is just going to be the sentence S Okay, now what I need to do is Let's just make sure this program is kind of And I have some errors here, like I'm missing a comma here So let me just kind of say result equals start And see what happens here Whoops, I'm in, I don't know where I am I want to be, I'm probably I'm probably editing the wrong code Don't I always do this? No, I'm in the right place Oh, I just didn't console log anything And I'm just going to say create P result So the idea here is, oops, S So I want to get more than S So how do I do this? Well, there's a variety of ways I could It could sort of think about doing this But I think what I want to do Is I want to sort of build out an array So I'm going to say expansion equals You know, I could try to use a for loop And maybe run a for loop, a nested for loop To do it multiple generations But really, this type of system I don't really have anything in here that's nested But if I add some nested stuff to it I'm going to need a recursive algorithm So I would love to refer you to some videos I have About the concept of recursion Which typically in other videos I've made I've used for graphics drawing I could make a recursive tree structure And a self-similar shape A recursive something is A function that's defined recursively Is a function that calls itself So I'm going to come back to that But let me start writing this code Is this a coding challenge? I think it is Okay, so I have an expansion And what I want to say is I want to say expand start expansion Because what I want to do is I want to call a function And I'm going to say here Result equals that So I want to have a result That comes from starting with this And I want to pass it an empty array Because then I want that array to be filled As it's going through And expanding based on the rules So to speak So I'm going to write this function up here And it gets I don't know what to call this An element, a phrase I'm just going to call it A start so to speak And I'm going to call this expansion Which is kind of a little awkward That I'm using the same variable names But I'm going to do that anyway Okay, so what do I do here? Well first I need to determine Is start something in the rules? Is it terminal or not terminal? If rules start, right? It doesn't exist Is it something in the rules? If it is, what do I need to do? Well I need to expand Whatever, I need to expand One of the possibilities that it might pick So first what I need to do is I need to pick something And one of the lovely things I can do In p5 is I can pass an array to A random function So if I say give me a random value Right? That's going to be picking If it's getting n It's going to pick one of cat or dog And then I need to expand that So then I need to expand What it picked And then I need to continue to pass this expansion array Because this expansion array is just getting filled recursively As this kind of function unfurls So I would have to like come back And this is going to be I can tell already This is going to be Not the kind of video that you need to watch over and over again But this is going to be the kind of thing That you're going to want to sort of like Hand write this code and play act it out Or something with a friend To sort of figure out what's going on here Now what if it's not And something that expands Then what do I want to do? I want to add it to that array Expand, push, what I picked So the idea is that I want this to keep going And we can think about what the tree I wonder if there's a way I can diagram this To help you First of all let's just see if this works And then I'm going to What I want to do is I'm going to say result Join with It's a Let's console this And then I'm going to I'm going to say I'm going to say I'm going to say Join with It's a Let's console log the result It's going to be an array Let's see if this even works Because I might have made a mistake Undefined Hey undefined There we go Ta-da Alright so what went wrong? Looking at the chat Rules tart No I thought Someone was saying I made a typo there So let's see if we can Figure out what's going on So let's Console.log pick See if that's even working Ah so that worked We got the I don't know why I'm zoomed out We got the nv Sketch line 10 So that worked And then Pick Oh Oh oh oh oh oh So here's something that's kind of important Right This would have This would work I haven't been paying attention But These These are three different Kind of elements that I need to expand So I hate to do this to you But I really kind of feel like What this should be Is an array inside the array I could start to use split and stuff But I want to I want to think about a way that might make sense And I've missed something here Oh I need a quote there Let me just make this change And then we'll kind of discuss it This is my own strange way of encoding this I'm sure any of you watching will come up with a better way And you will share it with me in the comments And I will feel embarrassed That's part of programming Feeling embarrassed Although you shouldn't feel embarrassed It's okay if I I'm going to feel embarrassed Because that's I generally operate in life by feeling embarrassed But coding is about figuring stuff out And playing around And iterating to refine things later So the reason why I'm doing this Woo! Look at that It auto formatted it for me The reason why I'm doing this is because What I want is to have a bunch of options But one of the options This is not three possible options This is expanding S into three tokens so to speak This is expanding N into one token Or this other one token So I could say this or something Like the funny cat Oops and it would look like this You know But the reason why I need to separate this out Is because the N or V might be things that need to be expanded And the truth of the matter is I could just do this But not if I need to treat these separately As things that might be expanded So you know I could do something different with splitting But I'm going to keep my train of thought here And what I'm going to do now is Once I pick something here I'm picking an array, right? And so what I need to expand Is each one of these So I need to say For var i equals zero i is less than pick.length i++ And then I want to expand pick index i So I want to go through and expand The, then N, and then V And then push So let's look at this now and see what happens And we can see Oh I'm still getting undefined at the end So, but I'm getting something promising Where I got the, and V, and then I got cat, and then I got barks So it looks like things are working correctly Oh I'm console.logging result Really what I want to console.log is expansion Undefined, undefined, undefined That's promising So let's look up here Ah, pick, hmm Oh no no no no, I want to push start So there we go, sorry So this is the thing coming in If it is part of the rules Then I need to split it up and expand it Otherwise I need to add that to the end So that's what I was missing there And now we can see I get the dog barks And what do I want to do now? The thing that it results in is a An array of elements And I want to, and so I wonder by the way if it makes sense for me to just say Return expansion And in that sense I can have the function also sort of return that array Which is sort of unnecessary but Yeah that makes sort of sense to do that And then what I can do is I can also say return expansion join With a space And then now you can see I'm getting these sentences The dog barks So now what I have is console.log result Create p, oh there it is, the dog barks So you can see I'm getting these and I could do this a bunch of times Just to get a bunch of different sentences To make sure this is really working And now I'm going to run this And we can see, oh look at this, craziness Ah, what's going on here? I made a mistake and I've got to start over Each time So I want to do that ten times So we can see the dog barks, the dog meows, the dog meows, the cat meows So this in theory is working right now And what I would like to do is take somebody else's grammar And apply it in here to see if we can get something that's a bit more sophisticated So I'm going to pull an example grammar file from Allison Parish And I believe that is this So this is a much nicer grammar And what I'm going to do is I'm going to just paste it to the top here And I'm going to put it in comments Just to sort of make the argument And I feel like this cooking show thing should happen Where now this video is going to get edited Where all of a sudden you see the result down here Of me translating it But I'm going to walk through translating one at a time In the archives live stream and we'll see what happens in the video later So what I'm going to do here is I'm going to say var rules equals s colon And then this is an array, let's see This is an array I should use a regular expression to like format this Right, so this is one option I'm going to, and this is another option Yeah, this is going to get edited out, I can tell already So I'm going to do this now in a slow way And then I will come back And so we can see that Now I'm getting, now let me do this Noun phrase is, I'm going to make this faster I'm going to create this I really should have come up with some of my own creative possibilities here But it's too late now And here's another one, determiner, adjective Adjective, noun I'm sure this is thrilling for you guys to watch in the live stream Then verb phrase I'm going to be done with this soon Verb phrase is transitive verb Noun phrase because they have objects And another verb phrase, or Oh, I did this wrong No, I did this right Or, right, intransitive verb Okay, now we're going to do this Should be pretty easy Interj Sorry everybody, is an array With, now I'm tempted to use split And use the pipe symbol I don't know why I didn't do that But I'm going to do this My, wow, darn, I'm cleaning it up Determiner, is it determiner, is that right? This, that, this dot, the Yeah, this is definitely not making it to the final released video Do you think? Noun, oh and this is adjective And this is noun Bald, smug Oh, it's at 4.30, I'm really going way over I think that my guest, Tiga, might be waiting outside Or maybe, hopefully she's getting herself set up Corsage, okay, I think I won't finish this whole thing We'll do this now Now I need to do, what was that? That was adjective, sorry Oh my goodness, I'm all out of whack Determiner, adjective, come on everybody Talk about not preparing Computes, let's see, computes Examines, foregrounds, that's good enough for me right now I'm losing my patience here And then, intransitive Daydreams, wines, okay So now I'm commenting out What var rules is this object with all these in it And then I can comment out this And this, let's just make sure this works The n costs Rules, NP, what happened here? Expand, start is S, whoops Oh yeah, NPVP, the NP, what? Oh, where are my nouns? Guess I forgot them Where was that grammar? Let's add some nouns Sorry everybody Put them here N, amoeba, dichotomy, seagull I should have just picked random stuff from And this is, oh I lost something here This is, adjective, oh boy Let's see what we get now Okay, I think this is working That important corsage, foregrounds, the trombone Okay, so let's come over here and say Okay, so we're going to magically come back Magically come back Okay, so you didn't have to watch all that But I went and converted this grammar Which is from an example from Allison Parrish Thank you Allison Parrish And I converted it to this syntax that I developed Which is probably, and you can see now I have a slightly more complex sentence First of all I have two different options Noun phrase, verb phrase, interjection, noun phrase, verb phrase And the powerful thing here is that A verb phrase can also include a noun phrase or no noun phrase So there's the recursive nature of this algorithm Of kind of expanding this sort of nested tree Is much more apparent now So let me go and I think what I should do is Quickly create a nice little button to do the generation So where am I? I'm going to say button And I'm going to say button equals create button Generate And then button, mouse pressed CFG Like the BFG but a CFG And then I'm going to say function CFG And I don't, I'm going to expand this grammar And create a paragraph So let's look and see I have a button The dichotomy that winds foregrounds that tame seagull The corsage foregrounds the corsage that foregrounds this amoeba The corsage amoeba winds I feel like I messed something up But I'm sure I probably messed something up in the grammar But you'll have a, you get the idea here So this is, the key piece of this is A, how are you deciding to format your grammar? Right, how are you creating terminal and non-terminal symbols? I've chosen to use this sort of set of nested arrays And the real key here of course is this recursive algorithm So as I'm starting with one element I expand that and then I look over those elements And call expand on those elements And call expand recursive This function is just calling itself, calling itself And this like computer is just keeping track of everything And then at the, eventually it's going to finish doing all that And at the end it's going to have this big array Of all of the terminal elements of this new sentence And will join them with a space bar And give you that result back which is displayed in the browser So again just to summarize I think if you want to work with context free grammars Using a, using a JavaScript library like Tracery or Rita Are both great options If you're interested in digging into the algorithm itself This is now an example that kind of shows you that And just to kind of make this point a little bit more I want to show you that you can also find a whole bunch of examples of mine That do this and a little bit more So if you go to the A to Z GitHub repository You'll see that I have a context I have this same exact algorithm But packaged up into an object So this is a context free object That has the rules object It has an add rule function So you can even look at this if you want to kind of think about Organizing this context free grammar into its own kind of library So to speak, much like Rita does Rita's more sophisticated than mine So you can look at these examples They do much in the same way of things That we, this is the exact same grammar actually You can look at this one which actually reads it from a JSON file Does the haiku generation There's this other example that I want to show you Because what it's actually doing Is it's taking, this is doing something more It's using a text, a file I could upload or drag or paste in But it's actually generating the grammar on the fly Based on input words So here I have the text from the rainbow Wikipedia page And I could sort of generate haikus With that particular text You know, if I made up my own text If I refresh this and said Generate some haikus 1, 2, 3, 1, 1, 2, 3, happy, dancing, rainbows, unicorn What else, what else? Purple, pink, right? We can sort of see I can generate the grammar And I can generate some haikus And you can see I don't have any, I don't have enough stuff So I'm kind of getting some of the These became terminal symbols because I don't have enough stuff But if I had, you can see haikus 2, unicorn, pink, pink, dancing 2 So this is also something you might want to think of And this by the way also has a little button That allows me to save that And I can actually look at the JSON file itself That the program actually generates that grammar And you can see here, it sort of calculates And it sort of, it couldn't find any 4 syllable or 5 syllable words In the seed text that I gave it So I'm going to see if there's any other Yeah, so that's, I want to make another video Where I sort of maybe tie into context free grammars with L-systems I encourage you to sort of look at some of my other videos about L-systems Which are a context free grammar But the idea of them is to create graphics And I will do one wrap up video to talk about Some exercise ideas that you might make And certainly one of the things that I'll talk about And I'm mentioning this now because I don't know if I have time to make that video today But it will come eventually Is you might think of what if the elements of this grammar, right? Aren't words, but musical notes Or design elements, color form How could you use a context free grammar to generate visual designs Generate music, other types of things beyond just text Okay, so I hope you enjoyed this coding challenge Of kind of coding a context free grammar from scratch And I'll see you in a future one at some point in the future Okay, everyone, I'm going to mute myself for a second And check and see what's happening And then I'll come back and sort of wrap things up I'm going to give you the this dot song As always, I always forget to do the this dot. I'm gonna do the this dot. This dot, this dot, this dot, the this dot song. Never forget the this dot. Somebody compose that song for me. you The music end. Okay, I'm back everybody. Okay, so what I think I do have five minutes to record kind of like I kind of just did it at the end of... Oh wait, I don't, I can't see where I am. Can you hear me? Yes, you can hear me. Boy, someday I'll just come back and redo all these videos. That's what I always say. I think what I will do is record a quick wrap-up video even though I tried to just do it there. For thinking about an exercise for using a context-free grammar. Coding pineapple I really like. And then I'll be finished. Maybe I'll answer a question or two. I'm actually gonna record another video not on a live stream with a guest. And so you'll stay, hopefully you'll look forward to that coming sometime later this week. I'll publish it. And that's that. So, okay, so let me think about this wrap-up for session six video. Which, I don't know why I just did that in the previous video because what I meant to do was kind of go through these examples. But, such is life. Okay, I'm gonna do this anyway and if it's unnecessary it is what it is. Or redundant, it is what it is. Okay, let me cycle the camera. Alright, what's going on with the dislike and liking? I'm looking at the chat. Okay, let's see here. What should I, I think I will. I'm gonna end with my lovely children's Once Upon a Time stories. And this will be my write your own story. Okay, I have some things to say about this. Excellent. Okay. Hello, welcome to a wrap-up video for session seven of programming from A to Z on this YouTube channel of mine that has an undefined name at the moment. But someday it might have a defined name. So, what I'm asking for you to do as a homework exercise for this particular session on grammars, specifically context-free grammars, is essentially to write a computer, well, there's a lot of things you could do. But if you're looking for something, have a computer program write your own story. And write that story differently each time. So you can see this one example that was written by a, this was written by a five-year-old and an eight-year-old together collaboratively. And using the tracery grammar. So that might be a first thing that you start. Find this example, link to in this video, and modify the story. Really, I think one thing to think about is like how much variation can you embed into the grammar. Can the story sometimes only be one sentence long? And sometimes be, you know, hundreds or thousands of words long. So think about this sort of like how you might really explore variety and parameterize, if that's even a word to use, the way that the grammar works, how nested or unnested it could be. So you can think about writing a story. The other thing that grammars are particularly good at, context-free grammars are generating text that fits into a very sort of prescriptive pattern. So one of my favorite bots on Twitter is the art assignment bot. And you can skip the exercise that I'm talking about. You can just do this one, which is from 42 minutes ago. Construct a wood carving researching the history of embosses. Due on Thursday, May 25th, 2017. Or build a photograph about tools. Due on Tuesday, November 2nd. So this you can see, you can really, I don't know that this is made with a context-free grammar. But you could imagine describing the grammar for this. So if you were to create a spell book, I think is a classic scenario, that there are some tracery examples that do this. Creating a recipe book, or what types of kind of statements define statements. The other thing that I think is, you know, what I've done in these two sessions is I've showed you Markov chains. Here's what a Markov chain is, and here's what a Markov chain does. Here's what a context-free grammar is, and here's what a context-free grammar does. So on the one hand, an exercise is just take my exact examples and produce output. But I think really the magic of a project happens in the spaces in between. So maybe a Markov chain is just a little piece of one word inside of some text you're generating. And the context-free grammar just creates an overall structure, also interfaces with an API. So how is it that these could be a piece of the project? And also really, in thinking about what's your presentation? So on the one hand, if you look at any of my examples, you know, this is just generating little sentences. But who is the character that's speaking? You know, what's the context? Is it a Twitter bot? Is it a web page? There's a wonderful project in my class today that was looking at generating fake election ballots. And so using the visual language of a system that you're trying to emulate to sort of spark the idea in the viewer, in either a playful way or a subversive way, or to make a statement, or just to tell a story. I think there's a lot of possibilities in thinking about the context and the visual design elements that surround how and where you're generating that text. The other thing that I think is worth really noting here is that both with Markov chains and with context-free grammars, that words or characters, what is it, what's the sequence of the grammar? What is the grammar describing? Is it describing language? Is the language English? Is it for another language? Or is it musical notes? Or is it designs? Do you have a context-free grammar that builds a design out of shapes and color? How might you explore something like that? So I encourage you to look at these examples, try Tracery, try Rita. You know, as an exercise, you might try programming that recursive algorithm on your own and see what types of results you can get. Okay, so I hope you enjoyed session 7, and you can share anything you make in the comments or at Schiffman on Twitter. And of course, I always sort of plug that if you feel so inclined, you can join the Patreon page, and there's a Slack channel too to discuss and ask questions. Okay, so see you in a future session, video, whatever, and talk to you soon. Okay, so there we go. I have now, I think, finished everything from today. I can take about 5 minutes or so to answer a last question or two. I'm going to kind of clean up here and close a bunch of links. I still have this cough that never goes away. And make sure everything is saved. Boy, this took a lot longer than I ever imagined doing all this. Are there any other Rita-like libraries for languages? Absolutely, there are. You know, working in the Python programming languages, there are certainly many Python packages, libraries, whatever you want to call them, for working with text. I think the most famous one being the NLTK, or Natural Language Toolkit. In JavaScript, another one that I described, that I covered in another video, was NLP Compromise. I hope to look at, as I do more videos with Node, I hope to look at some more packages that work with text in Node. But certainly if you're interested in kind of creative expression through programming with text, I think Rita might be exactly where you want to be, in terms of both the analyzing text and generating text. Okay, so this was quite a long stream. Oh, I'm hoping this is connected as one file, because it's telling me that this is 2 hours and 45 minutes. Oh my goodness. Okay, I've got to go. This took about an hour longer, or an hour and a half longer than I expected to do today. Right now, every Tuesday afternoon, I'm not so good at sending out the announcements. But hopefully, if things go well, I'll be having another live stream next Tuesday afternoon. I will likely miss a week or two, I expect, over the next month or two, as things really ramp up with other things that I have going on work-wise. But January is winter break, and I'm not teaching over winter break, and I will be in New York. So hopefully I'll do a couple extra. If I miss some weeks, I'll do some catch-up. Okay, thanks everyone for being here. Thanks for all your support. These videos will get released over the week, along with the code examples. Stay in touch, and maybe see you next week, okay? I hope this was a new topic, and that you guys discover something new and make something with it. I don't know what I'm supposed to click now. Over here. Okay, goodbye. [♪ music playing ♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:42.121449Z",
  "started_at": "2023-09-26T21:16:16.916433Z",
  "completed_at": "2023-09-26T21:48:15.326902Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=X6IPcExkG30",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1918.410469
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/jewgjjbbamj4s45fw7vtn6ar5u/cancel",
    "get": "https://api.replicate.com/v1/predictions/jewgjjbbamj4s45fw7vtn6ar5u"
  }
}