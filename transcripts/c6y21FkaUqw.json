{
  "id": "7kj6txbbpg265sfjlzuoli353u",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/c6y21FkaUqw.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/143267 [00:00<?, ?frames/s]\n  2%|▏         | 2844/143267 [00:07<06:20, 369.19frames/s]\n  4%|▍         | 5692/143267 [00:15<06:24, 357.72frames/s]\n  6%|▌         | 8532/143267 [00:26<07:07, 315.01frames/s]\n  8%|▊         | 11384/143267 [00:36<07:19, 299.76frames/s]\n 10%|▉         | 13894/143267 [00:42<06:38, 324.70frames/s]\n 12%|█▏        | 16698/143267 [00:51<06:27, 326.70frames/s]\n 14%|█▎        | 19514/143267 [00:59<06:15, 329.19frames/s]\n 16%|█▌        | 22498/143267 [01:06<05:40, 354.67frames/s]\n 18%|█▊        | 25498/143267 [01:16<05:49, 337.39frames/s]\n 20%|█▉        | 28242/143267 [01:23<05:30, 347.92frames/s]\n 22%|██▏       | 31040/143267 [01:30<05:04, 368.29frames/s]\n 24%|██▎       | 33906/143267 [01:38<04:55, 369.65frames/s]\n 26%|██▌       | 36826/143267 [01:46<04:51, 365.07frames/s]\n 28%|██▊       | 39786/143267 [01:55<04:57, 348.42frames/s]\n 30%|██▉       | 42594/143267 [02:04<04:55, 341.05frames/s]\n 32%|███▏      | 45464/143267 [02:15<05:11, 313.66frames/s]\n 34%|███▍      | 48432/143267 [02:23<04:50, 326.99frames/s]\n 36%|███▌      | 51204/143267 [02:30<04:27, 344.80frames/s]\n 38%|███▊      | 54024/143267 [02:38<04:20, 342.90frames/s]\n 40%|███▉      | 57024/143267 [02:44<03:45, 382.07frames/s]\n 42%|████▏     | 59776/143267 [02:49<03:20, 416.21frames/s]\n 44%|████▎     | 62664/143267 [02:58<03:28, 387.39frames/s]\n 46%|████▌     | 65596/143267 [03:09<03:46, 343.21frames/s]\n 48%|████▊     | 68504/143267 [03:19<03:54, 318.39frames/s]\n 50%|████▉     | 70992/143267 [03:26<03:36, 333.91frames/s]\n 52%|█████▏    | 73856/143267 [03:32<03:13, 359.15frames/s]\n 53%|█████▎    | 76596/143267 [03:40<03:03, 363.41frames/s]\n 55%|█████▌    | 79416/143267 [03:47<02:52, 370.53frames/s]\n 57%|█████▋    | 82112/143267 [03:57<03:05, 329.69frames/s]\n 59%|█████▉    | 84772/143267 [04:04<02:47, 349.37frames/s]\n 61%|██████▏   | 87772/143267 [04:11<02:30, 369.22frames/s]\n 63%|██████▎   | 90572/143267 [04:18<02:20, 374.56frames/s]\n 63%|██████▎   | 90572/143267 [04:30<02:20, 374.56frames/s]\n 65%|██████▌   | 93370/143267 [04:30<02:33, 325.24frames/s]\n 67%|██████▋   | 95938/143267 [04:36<02:20, 337.81frames/s]\n 69%|██████▉   | 98834/143267 [04:44<02:05, 353.41frames/s]\n 71%|███████   | 101446/143267 [04:51<01:57, 356.46frames/s]\n 73%|███████▎  | 104446/143267 [04:58<01:43, 375.99frames/s]\n 75%|███████▍  | 107426/143267 [05:09<01:47, 333.15frames/s]\n 77%|███████▋  | 110342/143267 [05:19<01:42, 319.76frames/s]\n 79%|███████▉  | 113142/143267 [05:27<01:32, 324.71frames/s]\n 81%|████████  | 115864/143267 [05:34<01:19, 345.26frames/s]\n 83%|████████▎ | 118520/143267 [05:39<01:03, 389.20frames/s]\n 85%|████████▍ | 121328/143267 [05:43<00:49, 440.91frames/s]\n 87%|████████▋ | 124184/143267 [05:52<00:48, 396.85frames/s]\n 89%|████████▊ | 126976/143267 [06:00<00:42, 386.39frames/s]\n 91%|█████████ | 129780/143267 [06:07<00:35, 379.00frames/s]\n 92%|█████████▏| 132512/143267 [06:16<00:30, 355.69frames/s]\n 94%|█████████▍| 135380/143267 [06:26<00:23, 337.73frames/s]\n 96%|█████████▋| 138104/143267 [06:33<00:14, 352.87frames/s]\n 98%|█████████▊| 140924/143267 [06:40<00:06, 355.64frames/s]\n100%|██████████| 143267/143267 [06:45<00:00, 386.34frames/s]\n100%|██████████| 143267/143267 [06:45<00:00, 353.33frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 5,
        "id": 0,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " It's time for coding challenge number 100.",
        "tokens": [
          50364,
          467,
          311,
          565,
          337,
          17720,
          3430,
          1230,
          2319,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 7.28,
        "id": 1,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 6.36,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50682,
          1692,
          321,
          352,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 10.8,
        "id": 2,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 7.28,
        "temperature": 0,
        "text": " In this coding challenge, I am going to do something",
        "tokens": [
          50728,
          682,
          341,
          17720,
          3430,
          11,
          286,
          669,
          516,
          281,
          360,
          746,
          50904
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 13.120000000000001,
        "id": 3,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 10.8,
        "temperature": 0,
        "text": " that I have been wanting to do on this channel",
        "tokens": [
          50904,
          300,
          286,
          362,
          668,
          7935,
          281,
          360,
          322,
          341,
          2269,
          51020
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 15.52,
        "id": 4,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 13.120000000000001,
        "temperature": 0,
        "text": " for I don't know, about 100 coding challenges.",
        "tokens": [
          51020,
          337,
          286,
          500,
          380,
          458,
          11,
          466,
          2319,
          17720,
          4759,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 20.16,
        "id": 5,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 15.52,
        "temperature": 0,
        "text": " I'm going to make a project that involves neuroevolution.",
        "tokens": [
          51140,
          286,
          478,
          516,
          281,
          652,
          257,
          1716,
          300,
          11626,
          16499,
          13379,
          3386,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 22.68,
        "id": 6,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 20.16,
        "temperature": 0,
        "text": " I am going to combine both neural networks",
        "tokens": [
          51372,
          286,
          669,
          516,
          281,
          10432,
          1293,
          18161,
          9590,
          51498
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 26.240000000000002,
        "id": 7,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 22.68,
        "temperature": 0,
        "text": " and genetic algorithms into an agent,",
        "tokens": [
          51498,
          293,
          12462,
          14642,
          666,
          364,
          9461,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.2552534046739635,
        "compression_ratio": 1.7488372093023257,
        "end": 28.44,
        "id": 8,
        "no_speech_prob": 0.0009253003518097103,
        "seek": 0,
        "start": 26.240000000000002,
        "temperature": 0,
        "text": " into a simulation of a simple game,",
        "tokens": [
          51676,
          666,
          257,
          16575,
          295,
          257,
          2199,
          1216,
          11,
          51786
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 31.880000000000003,
        "id": 9,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 28.44,
        "temperature": 0,
        "text": " and I'm going to train, choo-choo,",
        "tokens": [
          50364,
          293,
          286,
          478,
          516,
          281,
          3847,
          11,
          1586,
          78,
          12,
          339,
          1986,
          11,
          50536
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 35.44,
        "id": 10,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 31.880000000000003,
        "temperature": 0,
        "text": " train that agent to play that game effectively",
        "tokens": [
          50536,
          3847,
          300,
          9461,
          281,
          862,
          300,
          1216,
          8659,
          50714
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 37.52,
        "id": 11,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 35.44,
        "temperature": 0,
        "text": " by making decisions with a neural network",
        "tokens": [
          50714,
          538,
          1455,
          5327,
          365,
          257,
          18161,
          3209,
          50818
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 40.760000000000005,
        "id": 12,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 37.52,
        "temperature": 0,
        "text": " and evolving its neural network with a genetic algorithm.",
        "tokens": [
          50818,
          293,
          21085,
          1080,
          18161,
          3209,
          365,
          257,
          12462,
          9284,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 42,
        "id": 13,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 40.760000000000005,
        "temperature": 0,
        "text": " Way too much explanation.",
        "tokens": [
          50980,
          9558,
          886,
          709,
          10835,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 46.08,
        "id": 14,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 42,
        "temperature": 0,
        "text": " So this is a demonstration that Versatilis",
        "tokens": [
          51042,
          407,
          341,
          307,
          257,
          16520,
          300,
          12226,
          267,
          388,
          271,
          51246
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 49.92,
        "id": 15,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 46.08,
        "temperature": 0,
        "text": " on GitHub, Coding Train Contributor, Eric made.",
        "tokens": [
          51246,
          322,
          23331,
          11,
          383,
          8616,
          28029,
          4839,
          2024,
          22163,
          11,
          9336,
          1027,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 53.34,
        "id": 16,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 49.92,
        "temperature": 0,
        "text": " This is using the Flappy Bird clone GitHub repository",
        "tokens": [
          51438,
          639,
          307,
          1228,
          264,
          479,
          875,
          7966,
          15931,
          26506,
          23331,
          25841,
          51609
        ]
      },
      {
        "avg_logprob": -0.24507847740536645,
        "compression_ratio": 1.584313725490196,
        "end": 56.92,
        "id": 17,
        "no_speech_prob": 0.000007071853360685054,
        "seek": 2844,
        "start": 53.34,
        "temperature": 0,
        "text": " that various folks have contributed design ideas to",
        "tokens": [
          51609,
          300,
          3683,
          4024,
          362,
          18434,
          1715,
          3487,
          281,
          51788
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 58.92,
        "id": 18,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 56.92,
        "temperature": 0,
        "text": " and is actually running neuroevolution right now.",
        "tokens": [
          50364,
          293,
          307,
          767,
          2614,
          16499,
          13379,
          3386,
          558,
          586,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 61.480000000000004,
        "id": 19,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 58.92,
        "temperature": 0,
        "text": " You can see these trains are kind of getting better",
        "tokens": [
          50464,
          509,
          393,
          536,
          613,
          16329,
          366,
          733,
          295,
          1242,
          1101,
          50592
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 64.8,
        "id": 20,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 61.480000000000004,
        "temperature": 0,
        "text": " and better at making their way through these little gaps.",
        "tokens": [
          50592,
          293,
          1101,
          412,
          1455,
          641,
          636,
          807,
          613,
          707,
          15031,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 67.4,
        "id": 21,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 64.8,
        "temperature": 0,
        "text": " So I'm going to program this myself.",
        "tokens": [
          50758,
          407,
          286,
          478,
          516,
          281,
          1461,
          341,
          2059,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 69.56,
        "id": 22,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 67.4,
        "temperature": 0,
        "text": " Now I'm going to make a version of this",
        "tokens": [
          50888,
          823,
          286,
          478,
          516,
          281,
          652,
          257,
          3037,
          295,
          341,
          50996
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 71.48,
        "id": 23,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 69.56,
        "temperature": 0,
        "text": " in this coding challenge.",
        "tokens": [
          50996,
          294,
          341,
          17720,
          3430,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 74.28,
        "id": 24,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 71.48,
        "temperature": 0,
        "text": " The difference, however, is I'm going to want to work",
        "tokens": [
          51092,
          440,
          2649,
          11,
          4461,
          11,
          307,
          286,
          478,
          516,
          281,
          528,
          281,
          589,
          51232
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 75.88,
        "id": 25,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 74.28,
        "temperature": 0,
        "text": " in a sort of a simpler place.",
        "tokens": [
          51232,
          294,
          257,
          1333,
          295,
          257,
          18587,
          1081,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 78.76,
        "id": 26,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 75.88,
        "temperature": 0,
        "text": " So I am going to use the code from,",
        "tokens": [
          51312,
          407,
          286,
          669,
          516,
          281,
          764,
          264,
          3089,
          490,
          11,
          51456
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 80.84,
        "id": 27,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 78.76,
        "temperature": 0,
        "text": " I think it was coding challenge number 31,",
        "tokens": [
          51456,
          286,
          519,
          309,
          390,
          17720,
          3430,
          1230,
          10353,
          11,
          51560
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 83.24000000000001,
        "id": 28,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 80.84,
        "temperature": 0,
        "text": " which just is this simple version of Flappy Bird",
        "tokens": [
          51560,
          597,
          445,
          307,
          341,
          2199,
          3037,
          295,
          479,
          875,
          7966,
          15931,
          51680
        ]
      },
      {
        "avg_logprob": -0.22382496120212794,
        "compression_ratio": 1.7483221476510067,
        "end": 85.32000000000001,
        "id": 29,
        "no_speech_prob": 0.00001618749593035318,
        "seek": 5692,
        "start": 83.24000000000001,
        "temperature": 0,
        "text": " that I'm playing with the space bar right now.",
        "tokens": [
          51680,
          300,
          286,
          478,
          2433,
          365,
          264,
          1901,
          2159,
          558,
          586,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 86.91999999999999,
        "id": 30,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 85.32,
        "temperature": 0,
        "text": " So I took out all the design stuff",
        "tokens": [
          50364,
          407,
          286,
          1890,
          484,
          439,
          264,
          1715,
          1507,
          50444
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 88.47999999999999,
        "id": 31,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 86.91999999999999,
        "temperature": 0,
        "text": " just to see if we can get the,",
        "tokens": [
          50444,
          445,
          281,
          536,
          498,
          321,
          393,
          483,
          264,
          11,
          50522
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 91.47999999999999,
        "id": 32,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 88.47999999999999,
        "temperature": 0,
        "text": " whoa, I'm terrible at this, the mechanic,",
        "tokens": [
          50522,
          13310,
          11,
          286,
          478,
          6237,
          412,
          341,
          11,
          264,
          23860,
          11,
          50672
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 93.16,
        "id": 33,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 91.47999999999999,
        "temperature": 0,
        "text": " the mechanic of the game working.",
        "tokens": [
          50672,
          264,
          23860,
          295,
          264,
          1216,
          1364,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 96.6,
        "id": 34,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 93.16,
        "temperature": 0,
        "text": " Now, I need to move over to the whiteboard to it",
        "tokens": [
          50756,
          823,
          11,
          286,
          643,
          281,
          1286,
          670,
          281,
          264,
          2418,
          3787,
          281,
          309,
          50928
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 97.44,
        "id": 35,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 96.6,
        "temperature": 0,
        "text": " for a second.",
        "tokens": [
          50928,
          337,
          257,
          1150,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 99.47999999999999,
        "id": 36,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 97.44,
        "temperature": 0,
        "text": " Before I can write any code,",
        "tokens": [
          50970,
          4546,
          286,
          393,
          2464,
          604,
          3089,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 102.32,
        "id": 37,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 99.47999999999999,
        "temperature": 0,
        "text": " I want to talk about all of the pieces going on here.",
        "tokens": [
          51072,
          286,
          528,
          281,
          751,
          466,
          439,
          295,
          264,
          3755,
          516,
          322,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 104.1,
        "id": 38,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 102.32,
        "temperature": 0,
        "text": " All right, so number one,",
        "tokens": [
          51214,
          1057,
          558,
          11,
          370,
          1230,
          472,
          11,
          51303
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 108.72,
        "id": 39,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 105.39999999999999,
        "temperature": 0,
        "text": " I need to have the Flappy Bird game.",
        "tokens": [
          51368,
          286,
          643,
          281,
          362,
          264,
          479,
          875,
          7966,
          15931,
          1216,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 111.83999999999999,
        "id": 40,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 109.96,
        "temperature": 0,
        "text": " So you can look and find,",
        "tokens": [
          51596,
          407,
          291,
          393,
          574,
          293,
          915,
          11,
          51690
        ]
      },
      {
        "avg_logprob": -0.22603393323493726,
        "compression_ratio": 1.640926640926641,
        "end": 113.83999999999999,
        "id": 41,
        "no_speech_prob": 0.000017502847185824066,
        "seek": 8532,
        "start": 111.83999999999999,
        "temperature": 0,
        "text": " if you wanted to recreate this coding challenge,",
        "tokens": [
          51690,
          498,
          291,
          1415,
          281,
          25833,
          341,
          17720,
          3430,
          11,
          51790
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 117.4,
        "id": 42,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 113.84,
        "temperature": 0,
        "text": " you can go and get coding challenge number 31.",
        "tokens": [
          50364,
          291,
          393,
          352,
          293,
          483,
          17720,
          3430,
          1230,
          10353,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 119.7,
        "id": 43,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 117.4,
        "temperature": 0,
        "text": " I've actually made a few minor tweaks to it,",
        "tokens": [
          50542,
          286,
          600,
          767,
          1027,
          257,
          1326,
          6696,
          46664,
          281,
          309,
          11,
          50657
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 121.52000000000001,
        "id": 44,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 119.7,
        "temperature": 0,
        "text": " but I will, I guess after this is over,",
        "tokens": [
          50657,
          457,
          286,
          486,
          11,
          286,
          2041,
          934,
          341,
          307,
          670,
          11,
          50748
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 122.36,
        "id": 45,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 121.52000000000001,
        "temperature": 0,
        "text": " I'm going to update those.",
        "tokens": [
          50748,
          286,
          478,
          516,
          281,
          5623,
          729,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 125.06,
        "id": 46,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 122.36,
        "temperature": 0,
        "text": " So coding challenge 31 will mirror the code",
        "tokens": [
          50790,
          407,
          17720,
          3430,
          10353,
          486,
          8013,
          264,
          3089,
          50925
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 126.88000000000001,
        "id": 47,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 125.06,
        "temperature": 0,
        "text": " as I start with.",
        "tokens": [
          50925,
          382,
          286,
          722,
          365,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 131.88,
        "id": 48,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 126.88000000000001,
        "temperature": 0,
        "text": " Then I also need the toy neural network library,",
        "tokens": [
          51016,
          1396,
          286,
          611,
          643,
          264,
          12058,
          18161,
          3209,
          6405,
          11,
          51266
        ]
      },
      {
        "avg_logprob": -0.2025987668470903,
        "compression_ratio": 1.5098039215686274,
        "end": 138.94,
        "id": 49,
        "no_speech_prob": 0.000002123377043972141,
        "seek": 11384,
        "start": 134.4,
        "temperature": 0,
        "text": " which has two files associated with it,",
        "tokens": [
          51392,
          597,
          575,
          732,
          7098,
          6615,
          365,
          309,
          11,
          51619
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 143.74,
        "id": 50,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 138.94,
        "temperature": 0,
        "text": " matrix.js and also,",
        "tokens": [
          50364,
          8141,
          13,
          25530,
          293,
          611,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 147.85999999999999,
        "id": 51,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 145.06,
        "temperature": 0,
        "text": " neural, I think it's just called nn.js.",
        "tokens": [
          50670,
          18161,
          11,
          286,
          519,
          309,
          311,
          445,
          1219,
          297,
          77,
          13,
          25530,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 149.85999999999999,
        "id": 52,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 147.85999999999999,
        "temperature": 0,
        "text": " So this is the code for the neural network",
        "tokens": [
          50810,
          407,
          341,
          307,
          264,
          3089,
          337,
          264,
          18161,
          3209,
          50910
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 153.18,
        "id": 53,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 149.85999999999999,
        "temperature": 0,
        "text": " and some code for some matrix multiplication math",
        "tokens": [
          50910,
          293,
          512,
          3089,
          337,
          512,
          8141,
          27290,
          5221,
          51076
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 154.66,
        "id": 54,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 153.18,
        "temperature": 0,
        "text": " that's part of the neural network.",
        "tokens": [
          51076,
          300,
          311,
          644,
          295,
          264,
          18161,
          3209,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 157.34,
        "id": 55,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 154.66,
        "temperature": 0,
        "text": " If you're interested in how this library was made,",
        "tokens": [
          51150,
          759,
          291,
          434,
          3102,
          294,
          577,
          341,
          6405,
          390,
          1027,
          11,
          51284
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 159.5,
        "id": 56,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 157.34,
        "temperature": 0,
        "text": " boy, do I have a lot of tutorials for you.",
        "tokens": [
          51284,
          3237,
          11,
          360,
          286,
          362,
          257,
          688,
          295,
          17616,
          337,
          291,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 161.74,
        "id": 57,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 159.5,
        "temperature": 0,
        "text": " Link to those somewhere in this video's description.",
        "tokens": [
          51392,
          8466,
          281,
          729,
          4079,
          294,
          341,
          960,
          311,
          3855,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 163.02,
        "id": 58,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 161.74,
        "temperature": 0,
        "text": " And this, by the way, incidentally,",
        "tokens": [
          51504,
          400,
          341,
          11,
          538,
          264,
          636,
          11,
          9348,
          379,
          11,
          51568
        ]
      },
      {
        "avg_logprob": -0.23915255570612035,
        "compression_ratio": 1.6747967479674797,
        "end": 166.98,
        "id": 59,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 13894,
        "start": 163.02,
        "temperature": 0,
        "text": " this just has a file for the main sketch.",
        "tokens": [
          51568,
          341,
          445,
          575,
          257,
          3991,
          337,
          264,
          2135,
          12325,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 169.89999999999998,
        "id": 60,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 166.98,
        "temperature": 0,
        "text": " I believe it has a file called pipe.js",
        "tokens": [
          50364,
          286,
          1697,
          309,
          575,
          257,
          3991,
          1219,
          11240,
          13,
          25530,
          50510
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 172.89999999999998,
        "id": 61,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 169.89999999999998,
        "temperature": 0,
        "text": " and one called, I know I'm probably writing off the side",
        "tokens": [
          50510,
          293,
          472,
          1219,
          11,
          286,
          458,
          286,
          478,
          1391,
          3579,
          766,
          264,
          1252,
          50660
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 177.89999999999998,
        "id": 62,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 172.89999999999998,
        "temperature": 0,
        "text": " here, but close enough, pipe.js and one called bird.js.",
        "tokens": [
          50660,
          510,
          11,
          457,
          1998,
          1547,
          11,
          11240,
          13,
          25530,
          293,
          472,
          1219,
          5255,
          13,
          25530,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 180.73999999999998,
        "id": 63,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 178.54,
        "temperature": 0,
        "text": " So this is all the code that I'm going to start with.",
        "tokens": [
          50942,
          407,
          341,
          307,
          439,
          264,
          3089,
          300,
          286,
          478,
          516,
          281,
          722,
          365,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 185.73999999999998,
        "id": 64,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 180.73999999999998,
        "temperature": 0,
        "text": " Now, nowhere in here is there anything",
        "tokens": [
          51052,
          823,
          11,
          11159,
          294,
          510,
          307,
          456,
          1340,
          51302
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 187.01999999999998,
        "id": 65,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 185.73999999999998,
        "temperature": 0,
        "text": " about a genetic algorithm.",
        "tokens": [
          51302,
          466,
          257,
          12462,
          9284,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 188.94,
        "id": 66,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 187.01999999999998,
        "temperature": 0,
        "text": " So most of the code that I'm going to write",
        "tokens": [
          51366,
          407,
          881,
          295,
          264,
          3089,
          300,
          286,
          478,
          516,
          281,
          2464,
          51462
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 191.01999999999998,
        "id": 67,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 188.94,
        "temperature": 0,
        "text": " during this coding challenge, I'm going to put",
        "tokens": [
          51462,
          1830,
          341,
          17720,
          3430,
          11,
          286,
          478,
          516,
          281,
          829,
          51566
        ]
      },
      {
        "avg_logprob": -0.18880608876546223,
        "compression_ratio": 1.7641921397379912,
        "end": 195.14,
        "id": 68,
        "no_speech_prob": 0.000005507604782906128,
        "seek": 16698,
        "start": 191.01999999999998,
        "temperature": 0,
        "text": " into a new file and I will call it ga.js.",
        "tokens": [
          51566,
          666,
          257,
          777,
          3991,
          293,
          286,
          486,
          818,
          309,
          5959,
          13,
          25530,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 199.1,
        "id": 69,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 195.14,
        "temperature": 0,
        "text": " There are a couple features that are in this",
        "tokens": [
          50364,
          821,
          366,
          257,
          1916,
          4122,
          300,
          366,
          294,
          341,
          50562
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 204.1,
        "id": 70,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 199.1,
        "temperature": 0,
        "text": " neural network class that I put there for the purposes",
        "tokens": [
          50562,
          18161,
          3209,
          1508,
          300,
          286,
          829,
          456,
          337,
          264,
          9932,
          50812
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 208.29999999999998,
        "id": 71,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 205.61999999999998,
        "temperature": 0,
        "text": " of being able to apply a genetic algorithm.",
        "tokens": [
          50888,
          295,
          885,
          1075,
          281,
          3079,
          257,
          12462,
          9284,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 211.22,
        "id": 72,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 208.29999999999998,
        "temperature": 0,
        "text": " And those are a function called copy,",
        "tokens": [
          51022,
          400,
          729,
          366,
          257,
          2445,
          1219,
          5055,
          11,
          51168
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 213.73999999999998,
        "id": 73,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 211.22,
        "temperature": 0,
        "text": " which allows me to make a complete copy",
        "tokens": [
          51168,
          597,
          4045,
          385,
          281,
          652,
          257,
          3566,
          5055,
          51294
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 217.1,
        "id": 74,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 213.73999999999998,
        "temperature": 0,
        "text": " of a neural network in its current state,",
        "tokens": [
          51294,
          295,
          257,
          18161,
          3209,
          294,
          1080,
          2190,
          1785,
          11,
          51462
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 219.98,
        "id": 75,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 217.1,
        "temperature": 0,
        "text": " as well as mutate, which is a function",
        "tokens": [
          51462,
          382,
          731,
          382,
          5839,
          473,
          11,
          597,
          307,
          257,
          2445,
          51606
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 223.27999999999997,
        "id": 76,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 219.98,
        "temperature": 0,
        "text": " that allows me to make some minor random changes",
        "tokens": [
          51606,
          300,
          4045,
          385,
          281,
          652,
          512,
          6696,
          4974,
          2962,
          51771
        ]
      },
      {
        "avg_logprob": -0.21397100448608397,
        "compression_ratio": 1.7798165137614679,
        "end": 224.98,
        "id": 77,
        "no_speech_prob": 0.0000019333563159307232,
        "seek": 19514,
        "start": 223.27999999999997,
        "temperature": 0,
        "text": " to the state of that neural network.",
        "tokens": [
          51771,
          281,
          264,
          1785,
          295,
          300,
          18161,
          3209,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 227.22,
        "id": 78,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 225.82,
        "temperature": 0,
        "text": " And when I say state, I mean all of the weights.",
        "tokens": [
          50406,
          400,
          562,
          286,
          584,
          1785,
          11,
          286,
          914,
          439,
          295,
          264,
          17443,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 229.29999999999998,
        "id": 79,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 227.22,
        "temperature": 0,
        "text": " So these are some things that I'm going to definitely",
        "tokens": [
          50476,
          407,
          613,
          366,
          512,
          721,
          300,
          286,
          478,
          516,
          281,
          2138,
          50580
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 230.5,
        "id": 80,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 229.29999999999998,
        "temperature": 0,
        "text": " need to make use of.",
        "tokens": [
          50580,
          643,
          281,
          652,
          764,
          295,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 233.76,
        "id": 81,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 230.5,
        "temperature": 0,
        "text": " What I will not be doing is I won't be training",
        "tokens": [
          50640,
          708,
          286,
          486,
          406,
          312,
          884,
          307,
          286,
          1582,
          380,
          312,
          3097,
          50803
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 236.38,
        "id": 82,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 233.76,
        "temperature": 0,
        "text": " the neural network in the sort of traditional way",
        "tokens": [
          50803,
          264,
          18161,
          3209,
          294,
          264,
          1333,
          295,
          5164,
          636,
          50934
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 238.07999999999998,
        "id": 83,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 236.38,
        "temperature": 0,
        "text": " that you might have seen in some of my other videos,",
        "tokens": [
          50934,
          300,
          291,
          1062,
          362,
          1612,
          294,
          512,
          295,
          452,
          661,
          2145,
          11,
          51019
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 241.32,
        "id": 84,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 238.07999999999998,
        "temperature": 0,
        "text": " like the doodle classifier or the XOR challenge,",
        "tokens": [
          51019,
          411,
          264,
          360,
          30013,
          1508,
          9902,
          420,
          264,
          1783,
          2483,
          3430,
          11,
          51181
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 244.01999999999998,
        "id": 85,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 241.32,
        "temperature": 0,
        "text": " where I'm using this thing called back propagation,",
        "tokens": [
          51181,
          689,
          286,
          478,
          1228,
          341,
          551,
          1219,
          646,
          38377,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 245.62,
        "id": 86,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 244.01999999999998,
        "temperature": 0,
        "text": " supervised learning.",
        "tokens": [
          51316,
          46533,
          2539,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 248.22,
        "id": 87,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 245.62,
        "temperature": 0,
        "text": " What I want to do in this video is something",
        "tokens": [
          51396,
          708,
          286,
          528,
          281,
          360,
          294,
          341,
          960,
          307,
          746,
          51526
        ]
      },
      {
        "avg_logprob": -0.21496353440612326,
        "compression_ratio": 1.7,
        "end": 253.22,
        "id": 88,
        "no_speech_prob": 0.000008801082003628835,
        "seek": 22498,
        "start": 248.22,
        "temperature": 0,
        "text": " that's akin to this idea of reinforcement learning.",
        "tokens": [
          51526,
          300,
          311,
          47540,
          281,
          341,
          1558,
          295,
          29280,
          2539,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 259.65999999999997,
        "id": 89,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 255.61999999999998,
        "temperature": 0,
        "text": " Now, reinforcement learning is a field of research",
        "tokens": [
          50396,
          823,
          11,
          29280,
          2539,
          307,
          257,
          2519,
          295,
          2132,
          50598
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 261.53999999999996,
        "id": 90,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 259.65999999999997,
        "temperature": 0,
        "text": " that's been around for a very long time.",
        "tokens": [
          50598,
          300,
          311,
          668,
          926,
          337,
          257,
          588,
          938,
          565,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 264.59999999999997,
        "id": 91,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 261.53999999999996,
        "temperature": 0,
        "text": " It predates deep learning, neural networks,",
        "tokens": [
          50692,
          467,
          3852,
          1024,
          2452,
          2539,
          11,
          18161,
          9590,
          11,
          50845
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 265.59999999999997,
        "id": 92,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 264.59999999999997,
        "temperature": 0,
        "text": " all that sort of stuff.",
        "tokens": [
          50845,
          439,
          300,
          1333,
          295,
          1507,
          13,
          50895
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 268.4,
        "id": 93,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 265.59999999999997,
        "temperature": 0,
        "text": " And I would love to come do lots more tutorials",
        "tokens": [
          50895,
          400,
          286,
          576,
          959,
          281,
          808,
          360,
          3195,
          544,
          17616,
          51035
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 269.74,
        "id": 94,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 268.4,
        "temperature": 0,
        "text": " about reinforcement learning.",
        "tokens": [
          51035,
          466,
          29280,
          2539,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 271.88,
        "id": 95,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 269.74,
        "temperature": 0,
        "text": " The recent advances that you might have seen",
        "tokens": [
          51102,
          440,
          5162,
          25297,
          300,
          291,
          1062,
          362,
          1612,
          51209
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 276.71999999999997,
        "id": 96,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 271.88,
        "temperature": 0,
        "text": " with things like DeepMind and its bot",
        "tokens": [
          51209,
          365,
          721,
          411,
          14895,
          44,
          471,
          293,
          1080,
          10592,
          51451
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 279.21999999999997,
        "id": 97,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 276.71999999999997,
        "temperature": 0,
        "text": " that learned to beat all of the Atari games,",
        "tokens": [
          51451,
          300,
          3264,
          281,
          4224,
          439,
          295,
          264,
          41381,
          2813,
          11,
          51576
        ]
      },
      {
        "avg_logprob": -0.22911780735231796,
        "compression_ratio": 1.66015625,
        "end": 282.42,
        "id": 98,
        "no_speech_prob": 0.0000022603210254601436,
        "seek": 25498,
        "start": 279.21999999999997,
        "temperature": 0,
        "text": " those were developed with a style of reinforcement learning",
        "tokens": [
          51576,
          729,
          645,
          4743,
          365,
          257,
          3758,
          295,
          29280,
          2539,
          51736
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 287.42,
        "id": 99,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 282.42,
        "temperature": 0,
        "text": " called deep Q learning, which uses a neural network",
        "tokens": [
          50364,
          1219,
          2452,
          1249,
          2539,
          11,
          597,
          4960,
          257,
          18161,
          3209,
          50614
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 291.14000000000004,
        "id": 100,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 288.62,
        "temperature": 0,
        "text": " and trains the neural network based",
        "tokens": [
          50674,
          293,
          16329,
          264,
          18161,
          3209,
          2361,
          50800
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 294.24,
        "id": 101,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 291.14000000000004,
        "temperature": 0,
        "text": " on this reward-based system.",
        "tokens": [
          50800,
          322,
          341,
          7782,
          12,
          6032,
          1185,
          13,
          50955
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 297.12,
        "id": 102,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 294.24,
        "temperature": 0,
        "text": " So you have this idea in reinforcement learning",
        "tokens": [
          50955,
          407,
          291,
          362,
          341,
          1558,
          294,
          29280,
          2539,
          51099
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 298.70000000000005,
        "id": 103,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 297.12,
        "temperature": 0,
        "text": " that you have a world.",
        "tokens": [
          51099,
          300,
          291,
          362,
          257,
          1002,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 300.26,
        "id": 104,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 298.70000000000005,
        "temperature": 0,
        "text": " The world is going to be, in our case,",
        "tokens": [
          51178,
          440,
          1002,
          307,
          516,
          281,
          312,
          11,
          294,
          527,
          1389,
          11,
          51256
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 302.44,
        "id": 105,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 300.26,
        "temperature": 0,
        "text": " the world of Flappy Bird.",
        "tokens": [
          51256,
          264,
          1002,
          295,
          479,
          875,
          7966,
          15931,
          13,
          51365
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 304.82,
        "id": 106,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 302.44,
        "temperature": 0,
        "text": " The world has a given state.",
        "tokens": [
          51365,
          440,
          1002,
          575,
          257,
          2212,
          1785,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.24560438176637056,
        "compression_ratio": 1.6802030456852792,
        "end": 310.40000000000003,
        "id": 107,
        "no_speech_prob": 9.42243332247017e-7,
        "seek": 28242,
        "start": 306.24,
        "temperature": 0,
        "text": " The agent or the entity that is being reinforced,",
        "tokens": [
          51555,
          440,
          9461,
          420,
          264,
          13977,
          300,
          307,
          885,
          31365,
          11,
          51763
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 314.32,
        "id": 108,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 310.4,
        "temperature": 0,
        "text": " trained, that is learning, based on that state,",
        "tokens": [
          50364,
          8895,
          11,
          300,
          307,
          2539,
          11,
          2361,
          322,
          300,
          1785,
          11,
          50560
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 317.47999999999996,
        "id": 109,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 316.03999999999996,
        "temperature": 0,
        "text": " decides to make an action.",
        "tokens": [
          50646,
          14898,
          281,
          652,
          364,
          3069,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 319.08,
        "id": 110,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 317.47999999999996,
        "temperature": 0,
        "text": " I'm going to jump up.",
        "tokens": [
          50718,
          286,
          478,
          516,
          281,
          3012,
          493,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 320.53999999999996,
        "id": 111,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 319.08,
        "temperature": 0,
        "text": " I'm going to not jump up.",
        "tokens": [
          50798,
          286,
          478,
          516,
          281,
          406,
          3012,
          493,
          13,
          50871
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 322.35999999999996,
        "id": 112,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 320.53999999999996,
        "temperature": 0,
        "text": " In this case, Flappy Bird is very simple.",
        "tokens": [
          50871,
          682,
          341,
          1389,
          11,
          479,
          875,
          7966,
          15931,
          307,
          588,
          2199,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 326.91999999999996,
        "id": 113,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 322.35999999999996,
        "temperature": 0,
        "text": " And then based on that, there is a reward.",
        "tokens": [
          50962,
          400,
          550,
          2361,
          322,
          300,
          11,
          456,
          307,
          257,
          7782,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 330.84,
        "id": 114,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 328,
        "temperature": 0,
        "text": " That reward is fed back into the system",
        "tokens": [
          51244,
          663,
          7782,
          307,
          4636,
          646,
          666,
          264,
          1185,
          51386
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 332.12,
        "id": 115,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 330.84,
        "temperature": 0,
        "text": " and we kind of repeat here.",
        "tokens": [
          51386,
          293,
          321,
          733,
          295,
          7149,
          510,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 333.12,
        "id": 116,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 332.12,
        "temperature": 0,
        "text": " Now, here's the thing.",
        "tokens": [
          51450,
          823,
          11,
          510,
          311,
          264,
          551,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 337.29999999999995,
        "id": 117,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 333.12,
        "temperature": 0,
        "text": " This is what makes deep reinforcement learning",
        "tokens": [
          51500,
          639,
          307,
          437,
          1669,
          2452,
          29280,
          2539,
          51709
        ]
      },
      {
        "avg_logprob": -0.2452296704317616,
        "compression_ratio": 1.7321428571428572,
        "end": 339.06,
        "id": 118,
        "no_speech_prob": 0.000011843102583952714,
        "seek": 31040,
        "start": 337.29999999999995,
        "temperature": 0,
        "text": " and other reinforcement learning scenarios",
        "tokens": [
          51709,
          293,
          661,
          29280,
          2539,
          15077,
          51797
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 340.5,
        "id": 119,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 339.06,
        "temperature": 0,
        "text": " very complicated.",
        "tokens": [
          50364,
          588,
          6179,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 343.5,
        "id": 120,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 340.5,
        "temperature": 0,
        "text": " Let's just think about this in the case of Flappy Bird.",
        "tokens": [
          50436,
          961,
          311,
          445,
          519,
          466,
          341,
          294,
          264,
          1389,
          295,
          479,
          875,
          7966,
          15931,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 346.08,
        "id": 121,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 344.82,
        "temperature": 0,
        "text": " I am a bird.",
        "tokens": [
          50652,
          286,
          669,
          257,
          5255,
          13,
          50715
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 347.58,
        "id": 122,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 346.08,
        "temperature": 0,
        "text": " I am over here.",
        "tokens": [
          50715,
          286,
          669,
          670,
          510,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 349.78000000000003,
        "id": 123,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 347.58,
        "temperature": 0,
        "text": " I now, this is the state.",
        "tokens": [
          50790,
          286,
          586,
          11,
          341,
          307,
          264,
          1785,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 352.14,
        "id": 124,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 349.78000000000003,
        "temperature": 0,
        "text": " The state could just be the pixels of the display,",
        "tokens": [
          50900,
          440,
          1785,
          727,
          445,
          312,
          264,
          18668,
          295,
          264,
          4674,
          11,
          51018
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 353.7,
        "id": 125,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 352.14,
        "temperature": 0,
        "text": " and that's in fact what was used",
        "tokens": [
          51018,
          293,
          300,
          311,
          294,
          1186,
          437,
          390,
          1143,
          51096
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 356.38,
        "id": 126,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 353.7,
        "temperature": 0,
        "text": " in the DeepMind project.",
        "tokens": [
          51096,
          294,
          264,
          14895,
          44,
          471,
          1716,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 362.02,
        "id": 127,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 358.02,
        "temperature": 0,
        "text": " I am a bird and I am looking at the state",
        "tokens": [
          51312,
          286,
          669,
          257,
          5255,
          293,
          286,
          669,
          1237,
          412,
          264,
          1785,
          51512
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 363.02,
        "id": 128,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 362.02,
        "temperature": 0,
        "text": " and evaluating the state.",
        "tokens": [
          51512,
          293,
          27479,
          264,
          1785,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 365.5,
        "id": 129,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 363.02,
        "temperature": 0,
        "text": " I'm going to choose to make an action.",
        "tokens": [
          51562,
          286,
          478,
          516,
          281,
          2826,
          281,
          652,
          364,
          3069,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.21283633649841813,
        "compression_ratio": 1.663677130044843,
        "end": 368.26,
        "id": 130,
        "no_speech_prob": 0.00000501473004987929,
        "seek": 33906,
        "start": 365.5,
        "temperature": 0,
        "text": " That choice is to jump up.",
        "tokens": [
          51686,
          663,
          3922,
          307,
          281,
          3012,
          493,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 369.78,
        "id": 131,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 368.26,
        "temperature": 0,
        "text": " I now expect my reward.",
        "tokens": [
          50364,
          286,
          586,
          2066,
          452,
          7782,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 371.74,
        "id": 132,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 369.78,
        "temperature": 0,
        "text": " Please, everybody, shower me with your gifts.",
        "tokens": [
          50440,
          2555,
          11,
          2201,
          11,
          10128,
          385,
          365,
          428,
          11449,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 373.78,
        "id": 133,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 371.74,
        "temperature": 0,
        "text": " I have made this wonderful decision to jump up.",
        "tokens": [
          50538,
          286,
          362,
          1027,
          341,
          3715,
          3537,
          281,
          3012,
          493,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 375.26,
        "id": 134,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 373.78,
        "temperature": 0,
        "text": " The problem is, how do I know",
        "tokens": [
          50640,
          440,
          1154,
          307,
          11,
          577,
          360,
          286,
          458,
          50714
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 376.58,
        "id": 135,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 375.26,
        "temperature": 0,
        "text": " if that was a good or bad decision?",
        "tokens": [
          50714,
          498,
          300,
          390,
          257,
          665,
          420,
          1578,
          3537,
          30,
          50780
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 378.18,
        "id": 136,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 376.58,
        "temperature": 0,
        "text": " I don't really right now.",
        "tokens": [
          50780,
          286,
          500,
          380,
          534,
          558,
          586,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 380.46,
        "id": 137,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 378.18,
        "temperature": 0,
        "text": " I don't until much later.",
        "tokens": [
          50860,
          286,
          500,
          380,
          1826,
          709,
          1780,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 383.46,
        "id": 138,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 380.46,
        "temperature": 0,
        "text": " I don't, the payoff for certain things",
        "tokens": [
          50974,
          286,
          500,
          380,
          11,
          264,
          46547,
          337,
          1629,
          721,
          51124
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 385.78,
        "id": 139,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 383.46,
        "temperature": 0,
        "text": " that I might do in a game scenario,",
        "tokens": [
          51124,
          300,
          286,
          1062,
          360,
          294,
          257,
          1216,
          9005,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 389.21999999999997,
        "id": 140,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 385.78,
        "temperature": 0,
        "text": " how do I know if I'm playing, say, the game chess,",
        "tokens": [
          51240,
          577,
          360,
          286,
          458,
          498,
          286,
          478,
          2433,
          11,
          584,
          11,
          264,
          1216,
          24122,
          11,
          51412
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 392.09999999999997,
        "id": 141,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 389.21999999999997,
        "temperature": 0,
        "text": " if this move is really going to be a good move",
        "tokens": [
          51412,
          498,
          341,
          1286,
          307,
          534,
          516,
          281,
          312,
          257,
          665,
          1286,
          51556
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 394.08,
        "id": 142,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 392.09999999999997,
        "temperature": 0,
        "text": " for way down the line?",
        "tokens": [
          51556,
          337,
          636,
          760,
          264,
          1622,
          30,
          51655
        ]
      },
      {
        "avg_logprob": -0.18936232205094963,
        "compression_ratio": 1.6771929824561405,
        "end": 397.86,
        "id": 143,
        "no_speech_prob": 0.000002443989615130704,
        "seek": 36826,
        "start": 394.08,
        "temperature": 0,
        "text": " This is something I really need to figure out.",
        "tokens": [
          51655,
          639,
          307,
          746,
          286,
          534,
          643,
          281,
          2573,
          484,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 399.54,
        "id": 144,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 398.5,
        "temperature": 0,
        "text": " It gets very complicated very quickly.",
        "tokens": [
          50396,
          467,
          2170,
          588,
          6179,
          588,
          2661,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 402.66,
        "id": 145,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 399.54,
        "temperature": 0,
        "text": " The good news is I can use a different system.",
        "tokens": [
          50448,
          440,
          665,
          2583,
          307,
          286,
          393,
          764,
          257,
          819,
          1185,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 404.82,
        "id": 146,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 402.66,
        "temperature": 0,
        "text": " I can say, eh, you know what,",
        "tokens": [
          50604,
          286,
          393,
          584,
          11,
          7670,
          11,
          291,
          458,
          437,
          11,
          50712
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 406.86,
        "id": 147,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 404.82,
        "temperature": 0,
        "text": " instead of trying to actually figure out",
        "tokens": [
          50712,
          2602,
          295,
          1382,
          281,
          767,
          2573,
          484,
          50814
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 408.62,
        "id": 148,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 406.86,
        "temperature": 0,
        "text": " whether it was a good or bad decision,",
        "tokens": [
          50814,
          1968,
          309,
          390,
          257,
          665,
          420,
          1578,
          3537,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 412.90000000000003,
        "id": 149,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 408.62,
        "temperature": 0,
        "text": " I'm just going to make a whole lot of these birds,",
        "tokens": [
          50902,
          286,
          478,
          445,
          516,
          281,
          652,
          257,
          1379,
          688,
          295,
          613,
          9009,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 414.54,
        "id": 150,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 412.90000000000003,
        "temperature": 0,
        "text": " maybe like 1,000 of them.",
        "tokens": [
          51116,
          1310,
          411,
          502,
          11,
          1360,
          295,
          552,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 417.06,
        "id": 151,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 414.54,
        "temperature": 0,
        "text": " They will all have random neural networks,",
        "tokens": [
          51198,
          814,
          486,
          439,
          362,
          4974,
          18161,
          9590,
          11,
          51324
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 418.58000000000004,
        "id": 152,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 417.06,
        "temperature": 0,
        "text": " random neural networks.",
        "tokens": [
          51324,
          4974,
          18161,
          9590,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 420.74,
        "id": 153,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 418.58000000000004,
        "temperature": 0,
        "text": " They will just make random decisions,",
        "tokens": [
          51400,
          814,
          486,
          445,
          652,
          4974,
          5327,
          11,
          51508
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 423.16,
        "id": 154,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 420.74,
        "temperature": 0,
        "text": " and maybe some of those random decisions",
        "tokens": [
          51508,
          293,
          1310,
          512,
          295,
          729,
          4974,
          5327,
          51629
        ]
      },
      {
        "avg_logprob": -0.23450493627740432,
        "compression_ratio": 1.8075471698113208,
        "end": 425.94,
        "id": 155,
        "no_speech_prob": 0.00004006361632491462,
        "seek": 39786,
        "start": 423.16,
        "temperature": 0,
        "text": " happen to be better than some of the other random decisions.",
        "tokens": [
          51629,
          1051,
          281,
          312,
          1101,
          813,
          512,
          295,
          264,
          661,
          4974,
          5327,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 428.3,
        "id": 156,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 425.94,
        "temperature": 0,
        "text": " I will then take those into a new generation",
        "tokens": [
          50364,
          286,
          486,
          550,
          747,
          729,
          666,
          257,
          777,
          5125,
          50482
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 431.34,
        "id": 157,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 428.3,
        "temperature": 0,
        "text": " and repopulate the world with 100 new birds",
        "tokens": [
          50482,
          293,
          1085,
          404,
          5256,
          264,
          1002,
          365,
          2319,
          777,
          9009,
          50634
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 433.3,
        "id": 158,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 431.34,
        "temperature": 0,
        "text": " based off of those ones that did well",
        "tokens": [
          50634,
          2361,
          766,
          295,
          729,
          2306,
          300,
          630,
          731,
          50732
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 434.5,
        "id": 159,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 433.3,
        "temperature": 0,
        "text": " over and over and over again,",
        "tokens": [
          50732,
          670,
          293,
          670,
          293,
          670,
          797,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 436.9,
        "id": 160,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 434.5,
        "temperature": 0,
        "text": " the same principles of a genetic algorithm.",
        "tokens": [
          50792,
          264,
          912,
          9156,
          295,
          257,
          12462,
          9284,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 438.42,
        "id": 161,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 436.9,
        "temperature": 0,
        "text": " So now I might refer to you,",
        "tokens": [
          50912,
          407,
          586,
          286,
          1062,
          2864,
          281,
          291,
          11,
          50988
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 440.98,
        "id": 162,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 438.42,
        "temperature": 0,
        "text": " if you have not ever worked with a genetic algorithm before,",
        "tokens": [
          50988,
          498,
          291,
          362,
          406,
          1562,
          2732,
          365,
          257,
          12462,
          9284,
          949,
          11,
          51116
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 444.7,
        "id": 163,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 440.98,
        "temperature": 0,
        "text": " I'll refer to you to my genetic algorithm tutorial series.",
        "tokens": [
          51116,
          286,
          603,
          2864,
          281,
          291,
          281,
          452,
          12462,
          9284,
          7073,
          2638,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 447.94,
        "id": 164,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 444.7,
        "temperature": 0,
        "text": " Okay, so let's go and write a little bit of code,",
        "tokens": [
          51302,
          1033,
          11,
          370,
          718,
          311,
          352,
          293,
          2464,
          257,
          707,
          857,
          295,
          3089,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 449.18,
        "id": 165,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 447.94,
        "temperature": 0,
        "text": " and then we're going to have to come back here",
        "tokens": [
          51464,
          293,
          550,
          321,
          434,
          516,
          281,
          362,
          281,
          808,
          646,
          510,
          51526
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 450.7,
        "id": 166,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 449.18,
        "temperature": 0,
        "text": " to the whiteboard I know in a second,",
        "tokens": [
          51526,
          281,
          264,
          2418,
          3787,
          286,
          458,
          294,
          257,
          1150,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 453.06,
        "id": 167,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 450.7,
        "temperature": 0,
        "text": " but let's start doing a little bit of code here.",
        "tokens": [
          51602,
          457,
          718,
          311,
          722,
          884,
          257,
          707,
          857,
          295,
          3089,
          510,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.19939060331140673,
        "compression_ratio": 1.8651315789473684,
        "end": 454.64,
        "id": 168,
        "no_speech_prob": 0.000013007094821659848,
        "seek": 42594,
        "start": 453.06,
        "temperature": 0,
        "text": " So I'm going to go into the code.",
        "tokens": [
          51720,
          407,
          286,
          478,
          516,
          281,
          352,
          666,
          264,
          3089,
          13,
          51799
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 456.8,
        "id": 169,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 454.64,
        "temperature": 0,
        "text": " I'm going to go into the bird class,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          352,
          666,
          264,
          5255,
          1508,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 458.32,
        "id": 170,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 456.8,
        "temperature": 0,
        "text": " and right here I'm noticing, okay,",
        "tokens": [
          50472,
          293,
          558,
          510,
          286,
          478,
          21814,
          11,
          1392,
          11,
          50548
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 463.32,
        "id": 171,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 458.32,
        "temperature": 0,
        "text": " this is the function that causes the bird to jump up.",
        "tokens": [
          50548,
          341,
          307,
          264,
          2445,
          300,
          7700,
          264,
          5255,
          281,
          3012,
          493,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 465.84,
        "id": 172,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 463.52,
        "temperature": 0,
        "text": " How is that currently decided?",
        "tokens": [
          50808,
          1012,
          307,
          300,
          4362,
          3047,
          30,
          50924
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 468.96,
        "id": 173,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 465.84,
        "temperature": 0,
        "text": " That is currently decided in sketch.js",
        "tokens": [
          50924,
          663,
          307,
          4362,
          3047,
          294,
          12325,
          13,
          25530,
          51080
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 470.71999999999997,
        "id": 174,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 468.96,
        "temperature": 0,
        "text": " here when I press a key.",
        "tokens": [
          51080,
          510,
          562,
          286,
          1886,
          257,
          2141,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 473.76,
        "id": 175,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 471.68,
        "temperature": 0,
        "text": " This will no longer be the case.",
        "tokens": [
          51216,
          639,
          486,
          572,
          2854,
          312,
          264,
          1389,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 476.52,
        "id": 176,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 473.76,
        "temperature": 0,
        "text": " This entire function is now going to be commented out.",
        "tokens": [
          51320,
          639,
          2302,
          2445,
          307,
          586,
          516,
          281,
          312,
          26940,
          484,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 479.28,
        "id": 177,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 476.52,
        "temperature": 0,
        "text": " I want the bird to make its own decision",
        "tokens": [
          51458,
          286,
          528,
          264,
          5255,
          281,
          652,
          1080,
          1065,
          3537,
          51596
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 481.56,
        "id": 178,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 479.28,
        "temperature": 0,
        "text": " whether it should jump up or not.",
        "tokens": [
          51596,
          1968,
          309,
          820,
          3012,
          493,
          420,
          406,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.19069865492523694,
        "compression_ratio": 1.7302904564315353,
        "end": 484.32,
        "id": 179,
        "no_speech_prob": 0.00008888065349310637,
        "seek": 45464,
        "start": 483.03999999999996,
        "temperature": 0,
        "text": " So now I'm going to go over here,",
        "tokens": [
          51784,
          407,
          586,
          286,
          478,
          516,
          281,
          352,
          670,
          510,
          11,
          51848
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 486.06,
        "id": 180,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 485,
        "temperature": 0,
        "text": " and I'm going to say,",
        "tokens": [
          50398,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          50451
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 493.3,
        "id": 181,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 488.71999999999997,
        "temperature": 0,
        "text": " this.brain equals new neural network.",
        "tokens": [
          50584,
          341,
          13,
          6198,
          259,
          6915,
          777,
          18161,
          3209,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 498.3,
        "id": 182,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 493.3,
        "temperature": 0,
        "text": " So the idea here is that the inside the bird object,",
        "tokens": [
          50813,
          407,
          264,
          1558,
          510,
          307,
          300,
          264,
          1854,
          264,
          5255,
          2657,
          11,
          51063
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 501.6,
        "id": 183,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 498.86,
        "temperature": 0,
        "text": " the bird object will have its own neural network,",
        "tokens": [
          51091,
          264,
          5255,
          2657,
          486,
          362,
          1080,
          1065,
          18161,
          3209,
          11,
          51228
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 503.56,
        "id": 184,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 501.6,
        "temperature": 0,
        "text": " and its neural network will be the thing",
        "tokens": [
          51228,
          293,
          1080,
          18161,
          3209,
          486,
          312,
          264,
          551,
          51326
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 506.03999999999996,
        "id": 185,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 503.56,
        "temperature": 0,
        "text": " that makes the decision whether it should jump or not.",
        "tokens": [
          51326,
          300,
          1669,
          264,
          3537,
          1968,
          309,
          820,
          3012,
          420,
          406,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 509.92,
        "id": 186,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 506.03999999999996,
        "temperature": 0,
        "text": " I'm remembering, this is not an original idea I have.",
        "tokens": [
          51450,
          286,
          478,
          20719,
          11,
          341,
          307,
          406,
          364,
          3380,
          1558,
          286,
          362,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.24683101971944174,
        "compression_ratio": 1.7024390243902439,
        "end": 512.04,
        "id": 187,
        "no_speech_prob": 0.00002111244248226285,
        "seek": 48432,
        "start": 509.92,
        "temperature": 0,
        "text": " Of course, I will include some links",
        "tokens": [
          51644,
          2720,
          1164,
          11,
          286,
          486,
          4090,
          512,
          6123,
          51750
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 514.0799999999999,
        "id": 188,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 512.04,
        "temperature": 0,
        "text": " in this video's description to other references",
        "tokens": [
          50364,
          294,
          341,
          960,
          311,
          3855,
          281,
          661,
          15400,
          50466
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 515.88,
        "id": 189,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 514.0799999999999,
        "temperature": 0,
        "text": " and papers on neuroevolution,",
        "tokens": [
          50466,
          293,
          10577,
          322,
          16499,
          13379,
          3386,
          11,
          50556
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 517.86,
        "id": 190,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 515.88,
        "temperature": 0,
        "text": " but I also want to briefly just point out",
        "tokens": [
          50556,
          457,
          286,
          611,
          528,
          281,
          10515,
          445,
          935,
          484,
          50655
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 522.48,
        "id": 191,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 517.86,
        "temperature": 0,
        "text": " a bunch of these links, which are here.",
        "tokens": [
          50655,
          257,
          3840,
          295,
          613,
          6123,
          11,
          597,
          366,
          510,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 526,
        "id": 192,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 522.48,
        "temperature": 0,
        "text": " These are some other neuroevolution demonstrations",
        "tokens": [
          50886,
          1981,
          366,
          512,
          661,
          16499,
          13379,
          3386,
          34714,
          51062
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 528.7199999999999,
        "id": 193,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 526,
        "temperature": 0,
        "text": " that are on GitHub from various other GitHub users.",
        "tokens": [
          51062,
          300,
          366,
          322,
          23331,
          490,
          3683,
          661,
          23331,
          5022,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 530.8199999999999,
        "id": 194,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 528.7199999999999,
        "temperature": 0,
        "text": " There's a Flappy learning one, an Asteroids learning one,",
        "tokens": [
          51198,
          821,
          311,
          257,
          479,
          875,
          7966,
          2539,
          472,
          11,
          364,
          12884,
          2032,
          3742,
          2539,
          472,
          11,
          51303
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 532.88,
        "id": 195,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 530.8199999999999,
        "temperature": 0,
        "text": " the Steering Agent, Snake Neuroevolution,",
        "tokens": [
          51303,
          264,
          3592,
          1794,
          27174,
          11,
          33885,
          1734,
          7052,
          13379,
          3386,
          11,
          51406
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 534.52,
        "id": 196,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 532.88,
        "temperature": 0,
        "text": " and Neuroevolution Playing Super Mario.",
        "tokens": [
          51406,
          293,
          1734,
          7052,
          13379,
          3386,
          24801,
          4548,
          9343,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 536.92,
        "id": 197,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 534.52,
        "temperature": 0,
        "text": " So I'll include links to all these as well,",
        "tokens": [
          51488,
          407,
          286,
          603,
          4090,
          6123,
          281,
          439,
          613,
          382,
          731,
          11,
          51608
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 538.88,
        "id": 198,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 536.92,
        "temperature": 0,
        "text": " as well as some of these papers and other resources",
        "tokens": [
          51608,
          382,
          731,
          382,
          512,
          295,
          613,
          10577,
          293,
          661,
          3593,
          51706
        ]
      },
      {
        "avg_logprob": -0.24238562076649767,
        "compression_ratio": 1.8263888888888888,
        "end": 540.24,
        "id": 199,
        "no_speech_prob": 0.0008693562122061849,
        "seek": 51204,
        "start": 538.88,
        "temperature": 0,
        "text": " in the video's description.",
        "tokens": [
          51706,
          294,
          264,
          960,
          311,
          3855,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 545.08,
        "id": 200,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 540.5600000000001,
        "temperature": 0,
        "text": " Okay, so now here's the thing.",
        "tokens": [
          50380,
          1033,
          11,
          370,
          586,
          510,
          311,
          264,
          551,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 548.24,
        "id": 201,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 545.08,
        "temperature": 0,
        "text": " If you watched any of my neural network tutorials,",
        "tokens": [
          50606,
          759,
          291,
          6337,
          604,
          295,
          452,
          18161,
          3209,
          17616,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 551.96,
        "id": 202,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 548.24,
        "temperature": 0,
        "text": " you might remember that what do I need to put in here?",
        "tokens": [
          50764,
          291,
          1062,
          1604,
          300,
          437,
          360,
          286,
          643,
          281,
          829,
          294,
          510,
          30,
          50950
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 555.16,
        "id": 203,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 551.96,
        "temperature": 0,
        "text": " I need to say how many inputs,",
        "tokens": [
          50950,
          286,
          643,
          281,
          584,
          577,
          867,
          15743,
          11,
          51110
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 557.12,
        "id": 204,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 555.16,
        "temperature": 0,
        "text": " I need to say how many outputs,",
        "tokens": [
          51110,
          286,
          643,
          281,
          584,
          577,
          867,
          23930,
          11,
          51208
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 559.16,
        "id": 205,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 557.12,
        "temperature": 0,
        "text": " and I need to say how many hidden nodes.",
        "tokens": [
          51208,
          293,
          286,
          643,
          281,
          584,
          577,
          867,
          7633,
          13891,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 564.1,
        "id": 206,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 562.36,
        "temperature": 0,
        "text": " So what goes in there?",
        "tokens": [
          51470,
          407,
          437,
          1709,
          294,
          456,
          30,
          51557
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 567.8,
        "id": 207,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 564.1,
        "temperature": 0,
        "text": " This is where we have to return to the whiteboard.",
        "tokens": [
          51557,
          639,
          307,
          689,
          321,
          362,
          281,
          2736,
          281,
          264,
          2418,
          3787,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.23771802661488356,
        "compression_ratio": 1.7577319587628866,
        "end": 569.64,
        "id": 208,
        "no_speech_prob": 0.000012411489478836302,
        "seek": 54024,
        "start": 567.8,
        "temperature": 0,
        "text": " Okay, so here's the thing.",
        "tokens": [
          51742,
          1033,
          11,
          370,
          510,
          311,
          264,
          551,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 573.4,
        "id": 209,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 571.12,
        "temperature": 0,
        "text": " This is the game Flappy Bird.",
        "tokens": [
          50408,
          639,
          307,
          264,
          1216,
          479,
          875,
          7966,
          15931,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 578.4,
        "id": 210,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 573.4,
        "temperature": 0,
        "text": " I'm going to now architect my neural network down here.",
        "tokens": [
          50522,
          286,
          478,
          516,
          281,
          586,
          6331,
          452,
          18161,
          3209,
          760,
          510,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 581.96,
        "id": 211,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 578.88,
        "temperature": 0,
        "text": " I need a bunch of inputs, I need a bunch of hidden,",
        "tokens": [
          50796,
          286,
          643,
          257,
          3840,
          295,
          15743,
          11,
          286,
          643,
          257,
          3840,
          295,
          7633,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 583.88,
        "id": 212,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 581.96,
        "temperature": 0,
        "text": " and I need a bunch of outputs.",
        "tokens": [
          50950,
          293,
          286,
          643,
          257,
          3840,
          295,
          23930,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 587.6800000000001,
        "id": 213,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 585.08,
        "temperature": 0,
        "text": " Let's go with the easy part first.",
        "tokens": [
          51106,
          961,
          311,
          352,
          365,
          264,
          1858,
          644,
          700,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 590.36,
        "id": 214,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 587.6800000000001,
        "temperature": 0,
        "text": " The easy part here is perhaps the outputs.",
        "tokens": [
          51236,
          440,
          1858,
          644,
          510,
          307,
          4317,
          264,
          23930,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 594.64,
        "id": 215,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 590.36,
        "temperature": 0,
        "text": " So let's say I wanted to train an agent",
        "tokens": [
          51370,
          407,
          718,
          311,
          584,
          286,
          1415,
          281,
          3847,
          364,
          9461,
          51584
        ]
      },
      {
        "avg_logprob": -0.1700318269055299,
        "compression_ratio": 1.626865671641791,
        "end": 597.76,
        "id": 216,
        "no_speech_prob": 4.812515044250176e-7,
        "seek": 57024,
        "start": 594.64,
        "temperature": 0,
        "text": " to play a game that used the arrow keys.",
        "tokens": [
          51584,
          281,
          862,
          257,
          1216,
          300,
          1143,
          264,
          11610,
          9317,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 601.16,
        "id": 217,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 597.76,
        "temperature": 0,
        "text": " So the player of the game can either move up,",
        "tokens": [
          50364,
          407,
          264,
          4256,
          295,
          264,
          1216,
          393,
          2139,
          1286,
          493,
          11,
          50534
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 603.36,
        "id": 218,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 601.16,
        "temperature": 0,
        "text": " down, left, or right, there's four options.",
        "tokens": [
          50534,
          760,
          11,
          1411,
          11,
          420,
          558,
          11,
          456,
          311,
          1451,
          3956,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 605.04,
        "id": 219,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 603.36,
        "temperature": 0,
        "text": " I would have four outputs.",
        "tokens": [
          50644,
          286,
          576,
          362,
          1451,
          23930,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 608.14,
        "id": 220,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 605.04,
        "temperature": 0,
        "text": " I want a vector with four outputs,",
        "tokens": [
          50728,
          286,
          528,
          257,
          8062,
          365,
          1451,
          23930,
          11,
          50883
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 611.3199999999999,
        "id": 221,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 608.14,
        "temperature": 0,
        "text": " each representing the probability or the confidence score",
        "tokens": [
          50883,
          1184,
          13460,
          264,
          8482,
          420,
          264,
          6687,
          6175,
          51042
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 614.36,
        "id": 222,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 611.3199999999999,
        "temperature": 0,
        "text": " of whether the agent should move up,",
        "tokens": [
          51042,
          295,
          1968,
          264,
          9461,
          820,
          1286,
          493,
          11,
          51194
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 616.36,
        "id": 223,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 614.36,
        "temperature": 0,
        "text": " move down, move left, or right.",
        "tokens": [
          51194,
          1286,
          760,
          11,
          1286,
          1411,
          11,
          420,
          558,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 618.64,
        "id": 224,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 616.36,
        "temperature": 0,
        "text": " In this case, I don't need four.",
        "tokens": [
          51294,
          682,
          341,
          1389,
          11,
          286,
          500,
          380,
          643,
          1451,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 621.4,
        "id": 225,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 618.64,
        "temperature": 0,
        "text": " The only decision is jump or don't jump.",
        "tokens": [
          51408,
          440,
          787,
          3537,
          307,
          3012,
          420,
          500,
          380,
          3012,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 623.72,
        "id": 226,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 621.4,
        "temperature": 0,
        "text": " In this case, I really only need one output.",
        "tokens": [
          51546,
          682,
          341,
          1389,
          11,
          286,
          534,
          787,
          643,
          472,
          5598,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.18159347356751906,
        "compression_ratio": 1.834008097165992,
        "end": 626.64,
        "id": 227,
        "no_speech_prob": 0.0000024439902972517302,
        "seek": 59776,
        "start": 623.72,
        "temperature": 0,
        "text": " I can have one output that ranges between zero and one.",
        "tokens": [
          51662,
          286,
          393,
          362,
          472,
          5598,
          300,
          22526,
          1296,
          4018,
          293,
          472,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 628.88,
        "id": 228,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 626.64,
        "temperature": 0,
        "text": " If it's greater than.5, jump.",
        "tokens": [
          50364,
          759,
          309,
          311,
          5044,
          813,
          2411,
          20,
          11,
          3012,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 630.4399999999999,
        "id": 229,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 628.88,
        "temperature": 0,
        "text": " If it's less than.5, don't jump.",
        "tokens": [
          50476,
          759,
          309,
          311,
          1570,
          813,
          2411,
          20,
          11,
          500,
          380,
          3012,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 632.4399999999999,
        "id": 230,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 630.4399999999999,
        "temperature": 0,
        "text": " Let's just do that.",
        "tokens": [
          50554,
          961,
          311,
          445,
          360,
          300,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 633.68,
        "id": 231,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 632.4399999999999,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50654,
          407,
          718,
          311,
          360,
          300,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 635.12,
        "id": 232,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 633.68,
        "temperature": 0,
        "text": " That's going to make our life so much easier.",
        "tokens": [
          50716,
          663,
          311,
          516,
          281,
          652,
          527,
          993,
          370,
          709,
          3571,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 637.64,
        "id": 233,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 635.12,
        "temperature": 0,
        "text": " So I'm just going to have one output.",
        "tokens": [
          50788,
          407,
          286,
          478,
          445,
          516,
          281,
          362,
          472,
          5598,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 638.8,
        "id": 234,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 637.64,
        "temperature": 0,
        "text": " So simple.",
        "tokens": [
          50914,
          407,
          2199,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 640.4,
        "id": 235,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 638.8,
        "temperature": 0,
        "text": " We'll do some other, I'll do some other examples",
        "tokens": [
          50972,
          492,
          603,
          360,
          512,
          661,
          11,
          286,
          603,
          360,
          512,
          661,
          5110,
          51052
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 642.34,
        "id": 236,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 640.4,
        "temperature": 0,
        "text": " in other videos with more complexity.",
        "tokens": [
          51052,
          294,
          661,
          2145,
          365,
          544,
          14024,
          13,
          51149
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 643.18,
        "id": 237,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 642.34,
        "temperature": 0,
        "text": " One output.",
        "tokens": [
          51149,
          1485,
          5598,
          13,
          51191
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 647.04,
        "id": 238,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 643.18,
        "temperature": 0,
        "text": " Now, how many inputs?",
        "tokens": [
          51191,
          823,
          11,
          577,
          867,
          15743,
          30,
          51384
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 648.68,
        "id": 239,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 647.04,
        "temperature": 0,
        "text": " This gets a little harder.",
        "tokens": [
          51384,
          639,
          2170,
          257,
          707,
          6081,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 653.68,
        "id": 240,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 648.68,
        "temperature": 0,
        "text": " Now wouldn't it be nice if I could write some generic code",
        "tokens": [
          51466,
          823,
          2759,
          380,
          309,
          312,
          1481,
          498,
          286,
          727,
          2464,
          512,
          19577,
          3089,
          51716
        ]
      },
      {
        "avg_logprob": -0.19893455505371094,
        "compression_ratio": 1.6996197718631179,
        "end": 655.96,
        "id": 241,
        "no_speech_prob": 0.000004425488441484049,
        "seek": 62664,
        "start": 653.78,
        "temperature": 0,
        "text": " that's basically going to work for any game?",
        "tokens": [
          51721,
          300,
          311,
          1936,
          516,
          281,
          589,
          337,
          604,
          1216,
          30,
          51830
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 658.1600000000001,
        "id": 242,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 655.96,
        "temperature": 0,
        "text": " As long as I have a way of evaluating the score",
        "tokens": [
          50364,
          1018,
          938,
          382,
          286,
          362,
          257,
          636,
          295,
          27479,
          264,
          6175,
          50474
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 662.12,
        "id": 243,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 658.1600000000001,
        "temperature": 0,
        "text": " of the game, the same code will work for everything.",
        "tokens": [
          50474,
          295,
          264,
          1216,
          11,
          264,
          912,
          3089,
          486,
          589,
          337,
          1203,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 664.64,
        "id": 244,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 662.12,
        "temperature": 0,
        "text": " And one way of doing that would actually be",
        "tokens": [
          50672,
          400,
          472,
          636,
          295,
          884,
          300,
          576,
          767,
          312,
          50798
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 668.0400000000001,
        "id": 245,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 664.64,
        "temperature": 0,
        "text": " the pixels of the game as inputs.",
        "tokens": [
          50798,
          264,
          18668,
          295,
          264,
          1216,
          382,
          15743,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 671.5600000000001,
        "id": 246,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 668.0400000000001,
        "temperature": 0,
        "text": " So maybe I take the visuals of the game,",
        "tokens": [
          50968,
          407,
          1310,
          286,
          747,
          264,
          26035,
          295,
          264,
          1216,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 674.2800000000001,
        "id": 247,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 671.5600000000001,
        "temperature": 0,
        "text": " I sample it down to a lower resolution image,",
        "tokens": [
          51144,
          286,
          6889,
          309,
          760,
          281,
          257,
          3126,
          8669,
          3256,
          11,
          51280
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 675.5600000000001,
        "id": 248,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 674.2800000000001,
        "temperature": 0,
        "text": " I flatten that into an array,",
        "tokens": [
          51280,
          286,
          24183,
          300,
          666,
          364,
          10225,
          11,
          51344
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 677.1600000000001,
        "id": 249,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 675.5600000000001,
        "temperature": 0,
        "text": " I take the brightness of every pixel,",
        "tokens": [
          51344,
          286,
          747,
          264,
          21367,
          295,
          633,
          19261,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 678.24,
        "id": 250,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 677.1600000000001,
        "temperature": 0,
        "text": " I feed that in as the inputs.",
        "tokens": [
          51424,
          286,
          3154,
          300,
          294,
          382,
          264,
          15743,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 679.76,
        "id": 251,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 678.24,
        "temperature": 0,
        "text": " That's certainly one thing I could do.",
        "tokens": [
          51478,
          663,
          311,
          3297,
          472,
          551,
          286,
          727,
          360,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 682.44,
        "id": 252,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 679.76,
        "temperature": 0,
        "text": " I would love to try that as an experiment",
        "tokens": [
          51554,
          286,
          576,
          959,
          281,
          853,
          300,
          382,
          364,
          5120,
          51688
        ]
      },
      {
        "avg_logprob": -0.21976429012650295,
        "compression_ratio": 1.7934782608695652,
        "end": 685.0400000000001,
        "id": 253,
        "no_speech_prob": 0.000007071883828757564,
        "seek": 65596,
        "start": 682.44,
        "temperature": 0,
        "text": " in as a counterpoint to the way I'm going to do it",
        "tokens": [
          51688,
          294,
          382,
          257,
          5682,
          6053,
          281,
          264,
          636,
          286,
          478,
          516,
          281,
          360,
          309,
          51818
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 685.9599999999999,
        "id": 254,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 685.04,
        "temperature": 0,
        "text": " in this video.",
        "tokens": [
          50364,
          294,
          341,
          960,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 688.8,
        "id": 255,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 685.9599999999999,
        "temperature": 0,
        "text": " I'm instead going to take somewhat",
        "tokens": [
          50410,
          286,
          478,
          2602,
          516,
          281,
          747,
          8344,
          50552
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 690.68,
        "id": 256,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 688.8,
        "temperature": 0,
        "text": " of a higher level approach,",
        "tokens": [
          50552,
          295,
          257,
          2946,
          1496,
          3109,
          11,
          50646
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 693.7199999999999,
        "id": 257,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 690.68,
        "temperature": 0,
        "text": " and I'm going to do some feature extraction manually",
        "tokens": [
          50646,
          293,
          286,
          478,
          516,
          281,
          360,
          512,
          4111,
          30197,
          16945,
          50798
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 695,
        "id": 258,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 693.7199999999999,
        "temperature": 0,
        "text": " with my brain.",
        "tokens": [
          50798,
          365,
          452,
          3567,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 697.56,
        "id": 259,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 695,
        "temperature": 0,
        "text": " I'm going to say that I think,",
        "tokens": [
          50862,
          286,
          478,
          516,
          281,
          584,
          300,
          286,
          519,
          11,
          50990
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 702.56,
        "id": 260,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 697.56,
        "temperature": 0,
        "text": " I'm going to decide that I think that the important",
        "tokens": [
          50990,
          286,
          478,
          516,
          281,
          4536,
          300,
          286,
          519,
          300,
          264,
          1021,
          51240
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 708.2199999999999,
        "id": 261,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 703.2199999999999,
        "temperature": 0,
        "text": " properties, the inputs, should be the Y location",
        "tokens": [
          51273,
          7221,
          11,
          264,
          15743,
          11,
          820,
          312,
          264,
          398,
          4914,
          51523
        ]
      },
      {
        "avg_logprob": -0.2803500680362477,
        "compression_ratio": 1.6292134831460674,
        "end": 709.92,
        "id": 262,
        "no_speech_prob": 0.000010783300240291283,
        "seek": 68504,
        "start": 708.7199999999999,
        "temperature": 0,
        "text": " of the bird,",
        "tokens": [
          51548,
          295,
          264,
          5255,
          11,
          51608
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 715.5999999999999,
        "id": 263,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 710.92,
        "temperature": 0,
        "text": " the X location of the closest pipe,",
        "tokens": [
          50414,
          264,
          1783,
          4914,
          295,
          264,
          13699,
          11240,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 721.0799999999999,
        "id": 264,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 717.16,
        "temperature": 0,
        "text": " the Y location of the top pipe,",
        "tokens": [
          50726,
          264,
          398,
          4914,
          295,
          264,
          1192,
          11240,
          11,
          50922
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 724.5999999999999,
        "id": 265,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 721.0799999999999,
        "temperature": 0,
        "text": " and the Y location of the bottom pipe.",
        "tokens": [
          50922,
          293,
          264,
          398,
          4914,
          295,
          264,
          2767,
          11240,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 726.16,
        "id": 266,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 724.5999999999999,
        "temperature": 0,
        "text": " How many inputs is that?",
        "tokens": [
          51098,
          1012,
          867,
          15743,
          307,
          300,
          30,
          51176
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 727,
        "id": 267,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 726.16,
        "temperature": 0,
        "text": " Four.",
        "tokens": [
          51176,
          7451,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 733.52,
        "id": 268,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 729.02,
        "temperature": 0,
        "text": " So I'm going to have one, two, three, four inputs,",
        "tokens": [
          51319,
          407,
          286,
          478,
          516,
          281,
          362,
          472,
          11,
          732,
          11,
          1045,
          11,
          1451,
          15743,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 735.16,
        "id": 269,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 733.52,
        "temperature": 0,
        "text": " and one output.",
        "tokens": [
          51544,
          293,
          472,
          5598,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.22353125781547734,
        "compression_ratio": 1.7315436241610738,
        "end": 738.56,
        "id": 270,
        "no_speech_prob": 0.000012606888049049303,
        "seek": 70992,
        "start": 735.16,
        "temperature": 0,
        "text": " So I've decided how many inputs and how many outputs.",
        "tokens": [
          51626,
          407,
          286,
          600,
          3047,
          577,
          867,
          15743,
          293,
          577,
          867,
          23930,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 740.1999999999999,
        "id": 271,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 738.56,
        "temperature": 0,
        "text": " So now the other question is,",
        "tokens": [
          50364,
          407,
          586,
          264,
          661,
          1168,
          307,
          11,
          50446
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 743.04,
        "id": 272,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 740.1999999999999,
        "temperature": 0,
        "text": " how many hidden nodes should I have?",
        "tokens": [
          50446,
          577,
          867,
          7633,
          13891,
          820,
          286,
          362,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 751.64,
        "id": 273,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 749.1999999999999,
        "temperature": 0,
        "text": " To be honest, this isn't a very complicated problem.",
        "tokens": [
          50896,
          1407,
          312,
          3245,
          11,
          341,
          1943,
          380,
          257,
          588,
          6179,
          1154,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 753.92,
        "id": 274,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 751.64,
        "temperature": 0,
        "text": " This might work with just one hidden node.",
        "tokens": [
          51018,
          639,
          1062,
          589,
          365,
          445,
          472,
          7633,
          9984,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 758.6999999999999,
        "id": 275,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 754.88,
        "temperature": 0,
        "text": " It might work with no hidden layer at all, even in fact.",
        "tokens": [
          51180,
          467,
          1062,
          589,
          365,
          572,
          7633,
          4583,
          412,
          439,
          11,
          754,
          294,
          1186,
          13,
          51371
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 760.7199999999999,
        "id": 276,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 758.6999999999999,
        "temperature": 0,
        "text": " It might work with just two of these inputs",
        "tokens": [
          51371,
          467,
          1062,
          589,
          365,
          445,
          732,
          295,
          613,
          15743,
          51472
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 762.28,
        "id": 277,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 760.7199999999999,
        "temperature": 0,
        "text": " and be able to figure it out.",
        "tokens": [
          51472,
          293,
          312,
          1075,
          281,
          2573,
          309,
          484,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.23643195027052755,
        "compression_ratio": 1.6203703703703705,
        "end": 765.9599999999999,
        "id": 278,
        "no_speech_prob": 4.5209387167233217e-7,
        "seek": 73856,
        "start": 762.28,
        "temperature": 0,
        "text": " But let's just decide that we're also going to use four,",
        "tokens": [
          51550,
          583,
          718,
          311,
          445,
          4536,
          300,
          321,
          434,
          611,
          516,
          281,
          764,
          1451,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 769.0400000000001,
        "id": 279,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 765.96,
        "temperature": 0,
        "text": " just for the sake of having some hidden nodes.",
        "tokens": [
          50364,
          445,
          337,
          264,
          9717,
          295,
          1419,
          512,
          7633,
          13891,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 770.44,
        "id": 280,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 769.0400000000001,
        "temperature": 0,
        "text": " We can experiment, does it work better",
        "tokens": [
          50518,
          492,
          393,
          5120,
          11,
          775,
          309,
          589,
          1101,
          50588
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 772.84,
        "id": 281,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 770.44,
        "temperature": 0,
        "text": " if I make 64 hidden, or four, or eight?",
        "tokens": [
          50588,
          498,
          286,
          652,
          12145,
          7633,
          11,
          420,
          1451,
          11,
          420,
          3180,
          30,
          50708
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 776.6,
        "id": 282,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 772.84,
        "temperature": 0,
        "text": " Trial and error is your friend in machine learning systems.",
        "tokens": [
          50708,
          314,
          7111,
          293,
          6713,
          307,
          428,
          1277,
          294,
          3479,
          2539,
          3652,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 781.6,
        "id": 283,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 776.6,
        "temperature": 0,
        "text": " Okay, so now, this is now the diagram of the neural network.",
        "tokens": [
          50896,
          1033,
          11,
          370,
          586,
          11,
          341,
          307,
          586,
          264,
          10686,
          295,
          264,
          18161,
          3209,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 789.34,
        "id": 284,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 784.34,
        "temperature": 0,
        "text": " I must sit here and connect all of the various lines.",
        "tokens": [
          51283,
          286,
          1633,
          1394,
          510,
          293,
          1745,
          439,
          295,
          264,
          3683,
          3876,
          13,
          51533
        ]
      },
      {
        "avg_logprob": -0.2129206004895662,
        "compression_ratio": 1.5201793721973094,
        "end": 794.1600000000001,
        "id": 285,
        "no_speech_prob": 0.000004222832558298251,
        "seek": 76596,
        "start": 791.76,
        "temperature": 0,
        "text": " All right, so the inputs come in here,",
        "tokens": [
          51654,
          1057,
          558,
          11,
          370,
          264,
          15743,
          808,
          294,
          510,
          11,
          51774
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 796.0799999999999,
        "id": 286,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 794.16,
        "temperature": 0,
        "text": " and the output comes in here.",
        "tokens": [
          50364,
          293,
          264,
          5598,
          1487,
          294,
          510,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 800.4,
        "id": 287,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 796.0799999999999,
        "temperature": 0,
        "text": " Four inputs, four hidden, one output.",
        "tokens": [
          50460,
          7451,
          15743,
          11,
          1451,
          7633,
          11,
          472,
          5598,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 804.3199999999999,
        "id": 288,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 801.4,
        "temperature": 0,
        "text": " If you want to learn more about how a neural network works,",
        "tokens": [
          50726,
          759,
          291,
          528,
          281,
          1466,
          544,
          466,
          577,
          257,
          18161,
          3209,
          1985,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 806.04,
        "id": 289,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 804.3199999999999,
        "temperature": 0,
        "text": " all of the internals that are going on here,",
        "tokens": [
          50872,
          439,
          295,
          264,
          2154,
          1124,
          300,
          366,
          516,
          322,
          510,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 807.68,
        "id": 290,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 806.04,
        "temperature": 0,
        "text": " what all these connections are in the weights,",
        "tokens": [
          50958,
          437,
          439,
          613,
          9271,
          366,
          294,
          264,
          17443,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 810.36,
        "id": 291,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 807.68,
        "temperature": 0,
        "text": " I'll refer you back to my neural network tutorial series.",
        "tokens": [
          51040,
          286,
          603,
          2864,
          291,
          646,
          281,
          452,
          18161,
          3209,
          7073,
          2638,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 811.48,
        "id": 292,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 810.36,
        "temperature": 0,
        "text": " But this is pretty similar also",
        "tokens": [
          51174,
          583,
          341,
          307,
          1238,
          2531,
          611,
          51230
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 812.9599999999999,
        "id": 293,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 811.48,
        "temperature": 0,
        "text": " to what I did in the color predictor.",
        "tokens": [
          51230,
          281,
          437,
          286,
          630,
          294,
          264,
          2017,
          6069,
          284,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 816.56,
        "id": 294,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 812.9599999999999,
        "temperature": 0,
        "text": " There were three inputs and two outputs, I can't remember.",
        "tokens": [
          51304,
          821,
          645,
          1045,
          15743,
          293,
          732,
          23930,
          11,
          286,
          393,
          380,
          1604,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.19727754211425783,
        "compression_ratio": 1.6776556776556777,
        "end": 821.12,
        "id": 295,
        "no_speech_prob": 0.0000033405372050765436,
        "seek": 79416,
        "start": 816.56,
        "temperature": 0,
        "text": " All right, so now we've decided that I want to have",
        "tokens": [
          51484,
          1057,
          558,
          11,
          370,
          586,
          321,
          600,
          3047,
          300,
          286,
          528,
          281,
          362,
          51712
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 826.16,
        "id": 296,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 821.16,
        "temperature": 0,
        "text": " four inputs, four hidden nodes, and one output.",
        "tokens": [
          50366,
          1451,
          15743,
          11,
          1451,
          7633,
          13891,
          11,
          293,
          472,
          5598,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 830,
        "id": 297,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 826.48,
        "temperature": 0,
        "text": " So we now have the brain of our bird.",
        "tokens": [
          50632,
          407,
          321,
          586,
          362,
          264,
          3567,
          295,
          527,
          5255,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 835,
        "id": 298,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 830,
        "temperature": 0,
        "text": " And then, in update, the bird is going to decide,",
        "tokens": [
          50808,
          400,
          550,
          11,
          294,
          5623,
          11,
          264,
          5255,
          307,
          516,
          281,
          4536,
          11,
          51058
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 841.24,
        "id": 299,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 836.72,
        "temperature": 0,
        "text": " oh, this is more complicated than I thought.",
        "tokens": [
          51144,
          1954,
          11,
          341,
          307,
          544,
          6179,
          813,
          286,
          1194,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 842.84,
        "id": 300,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 841.24,
        "temperature": 0,
        "text": " Let's write a new function.",
        "tokens": [
          51370,
          961,
          311,
          2464,
          257,
          777,
          2445,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 845.32,
        "id": 301,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 842.84,
        "temperature": 0,
        "text": " Let's write a function called think.",
        "tokens": [
          51450,
          961,
          311,
          2464,
          257,
          2445,
          1219,
          519,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.19279430613798254,
        "compression_ratio": 1.545945945945946,
        "end": 847.72,
        "id": 302,
        "no_speech_prob": 4.520939853591699e-7,
        "seek": 82112,
        "start": 845.32,
        "temperature": 0,
        "text": " So in think, basically what I want to do",
        "tokens": [
          51574,
          407,
          294,
          519,
          11,
          1936,
          437,
          286,
          528,
          281,
          360,
          51694
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 852.72,
        "id": 303,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 847.72,
        "temperature": 0,
        "text": " is I want to say, let the output equal this.brain.predict,",
        "tokens": [
          50364,
          307,
          286,
          528,
          281,
          584,
          11,
          718,
          264,
          5598,
          2681,
          341,
          13,
          6198,
          259,
          13,
          79,
          24945,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 856.9,
        "id": 304,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 854.6,
        "temperature": 0,
        "text": " and I want to send in the inputs.",
        "tokens": [
          50708,
          293,
          286,
          528,
          281,
          2845,
          294,
          264,
          15743,
          13,
          50823
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 859.4,
        "id": 305,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 856.9,
        "temperature": 0,
        "text": " So, for example, the inputs have to be",
        "tokens": [
          50823,
          407,
          11,
          337,
          1365,
          11,
          264,
          15743,
          362,
          281,
          312,
          50948
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 861.64,
        "id": 306,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 859.4,
        "temperature": 0,
        "text": " an array of four numbers.",
        "tokens": [
          50948,
          364,
          10225,
          295,
          1451,
          3547,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 868.1600000000001,
        "id": 307,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 865.96,
        "temperature": 0,
        "text": " Right, so they would look something like this.",
        "tokens": [
          51276,
          1779,
          11,
          370,
          436,
          576,
          574,
          746,
          411,
          341,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 869.6800000000001,
        "id": 308,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 868.1600000000001,
        "temperature": 0,
        "text": " I'm going to put them in there,",
        "tokens": [
          51386,
          286,
          478,
          516,
          281,
          829,
          552,
          294,
          456,
          11,
          51462
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 870.84,
        "id": 309,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 869.6800000000001,
        "temperature": 0,
        "text": " and then I'm just going to say,",
        "tokens": [
          51462,
          293,
          550,
          286,
          478,
          445,
          516,
          281,
          584,
          11,
          51520
        ]
      },
      {
        "avg_logprob": -0.247919783300283,
        "compression_ratio": 1.6137566137566137,
        "end": 875.84,
        "id": 310,
        "no_speech_prob": 0.000014738962818228174,
        "seek": 84772,
        "start": 870.84,
        "temperature": 0,
        "text": " and if the output is greater than.5,",
        "tokens": [
          51520,
          293,
          498,
          264,
          5598,
          307,
          5044,
          813,
          2411,
          20,
          11,
          51770
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 880.32,
        "id": 311,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 877.72,
        "temperature": 0,
        "text": " then this.up, right?",
        "tokens": [
          50364,
          550,
          341,
          13,
          1010,
          11,
          558,
          30,
          50494
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 884.2,
        "id": 312,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 880.32,
        "temperature": 0,
        "text": " So this is the idea here, that the neural network library",
        "tokens": [
          50494,
          407,
          341,
          307,
          264,
          1558,
          510,
          11,
          300,
          264,
          18161,
          3209,
          6405,
          50688
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 887.4,
        "id": 313,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 884.2,
        "temperature": 0,
        "text": " that I'm using has a function called predict.",
        "tokens": [
          50688,
          300,
          286,
          478,
          1228,
          575,
          257,
          2445,
          1219,
          6069,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 891.84,
        "id": 314,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 887.4,
        "temperature": 0,
        "text": " When I call that function, I send in the inputs.",
        "tokens": [
          50848,
          1133,
          286,
          818,
          300,
          2445,
          11,
          286,
          2845,
          294,
          264,
          15743,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 896.08,
        "id": 315,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 891.84,
        "temperature": 0,
        "text": " The inputs go feed through, times the weights,",
        "tokens": [
          51070,
          440,
          15743,
          352,
          3154,
          807,
          11,
          1413,
          264,
          17443,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 899.08,
        "id": 316,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 896.08,
        "temperature": 0,
        "text": " summed activation function, times the weights,",
        "tokens": [
          51282,
          2408,
          1912,
          24433,
          2445,
          11,
          1413,
          264,
          17443,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 902.2,
        "id": 317,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 899.08,
        "temperature": 0,
        "text": " summed activation function, I get the output.",
        "tokens": [
          51432,
          2408,
          1912,
          24433,
          2445,
          11,
          286,
          483,
          264,
          5598,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.21666932573505476,
        "compression_ratio": 1.7794117647058822,
        "end": 905.72,
        "id": 318,
        "no_speech_prob": 0.000004222831194056198,
        "seek": 87772,
        "start": 902.2,
        "temperature": 0,
        "text": " And based on that output, if it's greater than.5,",
        "tokens": [
          51588,
          400,
          2361,
          322,
          300,
          5598,
          11,
          498,
          309,
          311,
          5044,
          813,
          2411,
          20,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 908.0400000000001,
        "id": 319,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 905.72,
        "temperature": 0,
        "text": " the bird jumps, if it's less than.5,",
        "tokens": [
          50364,
          264,
          5255,
          16704,
          11,
          498,
          309,
          311,
          1570,
          813,
          2411,
          20,
          11,
          50480
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 909.7,
        "id": 320,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 908.0400000000001,
        "temperature": 0,
        "text": " the bird doesn't do anything.",
        "tokens": [
          50480,
          264,
          5255,
          1177,
          380,
          360,
          1340,
          13,
          50563
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 912.14,
        "id": 321,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 909.7,
        "temperature": 0,
        "text": " But this is no good here, right?",
        "tokens": [
          50563,
          583,
          341,
          307,
          572,
          665,
          510,
          11,
          558,
          30,
          50685
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 914.8000000000001,
        "id": 322,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 912.14,
        "temperature": 0,
        "text": " This is just me, let's just see if this works though.",
        "tokens": [
          50685,
          639,
          307,
          445,
          385,
          11,
          718,
          311,
          445,
          536,
          498,
          341,
          1985,
          1673,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 917.4,
        "id": 323,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 914.8000000000001,
        "temperature": 0,
        "text": " I mean, these are hard-coded inputs that never change,",
        "tokens": [
          50818,
          286,
          914,
          11,
          613,
          366,
          1152,
          12,
          66,
          12340,
          15743,
          300,
          1128,
          1319,
          11,
          50948
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 919.48,
        "id": 324,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 917.4,
        "temperature": 0,
        "text": " that's not what I want, but let's just at least see",
        "tokens": [
          50948,
          300,
          311,
          406,
          437,
          286,
          528,
          11,
          457,
          718,
          311,
          445,
          412,
          1935,
          536,
          51052
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 920.9,
        "id": 325,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 919.48,
        "temperature": 0,
        "text": " if I don't get any errors.",
        "tokens": [
          51052,
          498,
          286,
          500,
          380,
          483,
          604,
          13603,
          13,
          51123
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 924.24,
        "id": 326,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 920.9,
        "temperature": 0,
        "text": " So I'm going to in here now, I'm going to add something.",
        "tokens": [
          51123,
          407,
          286,
          478,
          516,
          281,
          294,
          510,
          586,
          11,
          286,
          478,
          516,
          281,
          909,
          746,
          13,
          51290
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 927.2,
        "id": 327,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 924.24,
        "temperature": 0,
        "text": " I'm going to say bird.think,",
        "tokens": [
          51290,
          286,
          478,
          516,
          281,
          584,
          5255,
          13,
          21074,
          11,
          51438
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 929.5600000000001,
        "id": 328,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 927.2,
        "temperature": 0,
        "text": " and I'm going to run the sketch again.",
        "tokens": [
          51438,
          293,
          286,
          478,
          516,
          281,
          1190,
          264,
          12325,
          797,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.21429909600151908,
        "compression_ratio": 1.7718631178707225,
        "end": 933.7,
        "id": 329,
        "no_speech_prob": 0.000015446290490217507,
        "seek": 90572,
        "start": 929.5600000000001,
        "temperature": 0,
        "text": " Oh, look at that, it's thinking, it's jumping, right?",
        "tokens": [
          51556,
          876,
          11,
          574,
          412,
          300,
          11,
          309,
          311,
          1953,
          11,
          309,
          311,
          11233,
          11,
          558,
          30,
          51763
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 936.1800000000001,
        "id": 330,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 933.7,
        "temperature": 0,
        "text": " It decided, every time, it's basically always",
        "tokens": [
          50364,
          467,
          3047,
          11,
          633,
          565,
          11,
          309,
          311,
          1936,
          1009,
          50488
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 938.82,
        "id": 331,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 936.1800000000001,
        "temperature": 0,
        "text": " going to be up at the top or at the bottom, right?",
        "tokens": [
          50488,
          516,
          281,
          312,
          493,
          412,
          264,
          1192,
          420,
          412,
          264,
          2767,
          11,
          558,
          30,
          50620
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 941.46,
        "id": 332,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 938.82,
        "temperature": 0,
        "text": " Because it's getting the same inputs over and over again.",
        "tokens": [
          50620,
          1436,
          309,
          311,
          1242,
          264,
          912,
          15743,
          670,
          293,
          670,
          797,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 944.72,
        "id": 333,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 941.46,
        "temperature": 0,
        "text": " Now what I need to do is actually make inputs",
        "tokens": [
          50752,
          823,
          437,
          286,
          643,
          281,
          360,
          307,
          767,
          652,
          15743,
          50915
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 948.46,
        "id": 334,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 944.72,
        "temperature": 0,
        "text": " out of these values, these values.",
        "tokens": [
          50915,
          484,
          295,
          613,
          4190,
          11,
          613,
          4190,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 951.22,
        "id": 335,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 948.46,
        "temperature": 0,
        "text": " It's y position, top, bottom,",
        "tokens": [
          51102,
          467,
          311,
          288,
          2535,
          11,
          1192,
          11,
          2767,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 953.22,
        "id": 336,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 951.22,
        "temperature": 0,
        "text": " and the x position of the pipe.",
        "tokens": [
          51240,
          293,
          264,
          2031,
          2535,
          295,
          264,
          11240,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 954.38,
        "id": 337,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 953.22,
        "temperature": 0,
        "text": " Okay, let's do that.",
        "tokens": [
          51340,
          1033,
          11,
          718,
          311,
          360,
          300,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2156705175127302,
        "compression_ratio": 1.6380090497737556,
        "end": 959.38,
        "id": 338,
        "no_speech_prob": 0.000006339204901451012,
        "seek": 93370,
        "start": 954.38,
        "temperature": 0,
        "text": " So now, I'm going to say, back in the bird,",
        "tokens": [
          51398,
          407,
          586,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          646,
          294,
          264,
          5255,
          11,
          51648
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 961.98,
        "id": 339,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 959.38,
        "temperature": 0,
        "text": " back in the bird, I'm going to say,",
        "tokens": [
          50364,
          646,
          294,
          264,
          5255,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          50494
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 966.26,
        "id": 340,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 961.98,
        "temperature": 0,
        "text": " let inputs equal an empty array.",
        "tokens": [
          50494,
          718,
          15743,
          2681,
          364,
          6707,
          10225,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 971.26,
        "id": 341,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 966.26,
        "temperature": 0,
        "text": " I'm going to say inputs zero is this bird's y position,",
        "tokens": [
          50708,
          286,
          478,
          516,
          281,
          584,
          15743,
          4018,
          307,
          341,
          5255,
          311,
          288,
          2535,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 979.14,
        "id": 342,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 975.06,
        "temperature": 0,
        "text": " y position, inputs one is, oh boy,",
        "tokens": [
          51148,
          288,
          2535,
          11,
          15743,
          472,
          307,
          11,
          1954,
          3237,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 981.18,
        "id": 343,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 979.14,
        "temperature": 0,
        "text": " okay, here's the problem now.",
        "tokens": [
          51352,
          1392,
          11,
          510,
          311,
          264,
          1154,
          586,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 983.3,
        "id": 344,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 981.18,
        "temperature": 0,
        "text": " I need to know about the pipes.",
        "tokens": [
          51454,
          286,
          643,
          281,
          458,
          466,
          264,
          21882,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 987.46,
        "id": 345,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 983.3,
        "temperature": 0,
        "text": " So I am a bird, and I need to know about the pipes.",
        "tokens": [
          51560,
          407,
          286,
          669,
          257,
          5255,
          11,
          293,
          286,
          643,
          281,
          458,
          466,
          264,
          21882,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.21338116753961622,
        "compression_ratio": 1.7218934911242603,
        "end": 988.34,
        "id": 346,
        "no_speech_prob": 0.00013341972953639925,
        "seek": 95938,
        "start": 987.46,
        "temperature": 0,
        "text": " How do I do that?",
        "tokens": [
          51768,
          1012,
          360,
          286,
          360,
          300,
          30,
          51812
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 992.02,
        "id": 347,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 988.34,
        "temperature": 0,
        "text": " So maybe what I'll do is I'll take in,",
        "tokens": [
          50364,
          407,
          1310,
          437,
          286,
          603,
          360,
          307,
          286,
          603,
          747,
          294,
          11,
          50548
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 994.22,
        "id": 348,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 992.02,
        "temperature": 0,
        "text": " as an argument to this function,",
        "tokens": [
          50548,
          382,
          364,
          6770,
          281,
          341,
          2445,
          11,
          50658
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 996.84,
        "id": 349,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 994.22,
        "temperature": 0,
        "text": " I will take in the pipes array.",
        "tokens": [
          50658,
          286,
          486,
          747,
          294,
          264,
          21882,
          10225,
          13,
          50789
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 1001.2,
        "id": 350,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 998.58,
        "temperature": 0,
        "text": " So that is sent in to the think function.",
        "tokens": [
          50876,
          407,
          300,
          307,
          2279,
          294,
          281,
          264,
          519,
          2445,
          13,
          51007
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 1004.98,
        "id": 351,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 1001.2,
        "temperature": 0,
        "text": " Now I'm going to go here, and I'm going to say,",
        "tokens": [
          51007,
          823,
          286,
          478,
          516,
          281,
          352,
          510,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 1007.94,
        "id": 352,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 1004.98,
        "temperature": 0,
        "text": " I'm just going to do pipes index zero.",
        "tokens": [
          51196,
          286,
          478,
          445,
          516,
          281,
          360,
          21882,
          8186,
          4018,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 1010.38,
        "id": 353,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 1007.94,
        "temperature": 0,
        "text": " This is a bad idea, but let's just start with this.",
        "tokens": [
          51344,
          639,
          307,
          257,
          1578,
          1558,
          11,
          457,
          718,
          311,
          445,
          722,
          365,
          341,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.21391934687548345,
        "compression_ratio": 1.641711229946524,
        "end": 1014.46,
        "id": 354,
        "no_speech_prob": 0.000007889253538451158,
        "seek": 98834,
        "start": 1010.38,
        "temperature": 0,
        "text": " Pipes index zero, top.",
        "tokens": [
          51466,
          35396,
          279,
          8186,
          4018,
          11,
          1192,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1019.22,
        "id": 355,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1014.46,
        "temperature": 0,
        "text": " Inputs two equal pipes index zero, bottom.",
        "tokens": [
          50364,
          682,
          2582,
          82,
          732,
          2681,
          21882,
          8186,
          4018,
          11,
          2767,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1026.38,
        "id": 356,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1021.38,
        "temperature": 0,
        "text": " Inputs three equal pipes index zero, x.",
        "tokens": [
          50710,
          682,
          2582,
          82,
          1045,
          2681,
          21882,
          8186,
          4018,
          11,
          2031,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1029.66,
        "id": 357,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1028.26,
        "temperature": 0,
        "text": " So this is the idea here.",
        "tokens": [
          51054,
          407,
          341,
          307,
          264,
          1558,
          510,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1032.52,
        "id": 358,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1029.66,
        "temperature": 0,
        "text": " I want all of those things to be the inputs",
        "tokens": [
          51124,
          286,
          528,
          439,
          295,
          729,
          721,
          281,
          312,
          264,
          15743,
          51267
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1033.66,
        "id": 359,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1032.52,
        "temperature": 0,
        "text": " to the neural network.",
        "tokens": [
          51267,
          281,
          264,
          18161,
          3209,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1035.9,
        "id": 360,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1033.66,
        "temperature": 0,
        "text": " I don't need this anymore, right,",
        "tokens": [
          51324,
          286,
          500,
          380,
          643,
          341,
          3602,
          11,
          558,
          11,
          51436
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1039.26,
        "id": 361,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1035.9,
        "temperature": 0,
        "text": " because I am getting them from the properties at sync,",
        "tokens": [
          51436,
          570,
          286,
          669,
          1242,
          552,
          490,
          264,
          7221,
          412,
          20271,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1042.02,
        "id": 362,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1039.26,
        "temperature": 0,
        "text": " and now let me run this and see what happens.",
        "tokens": [
          51604,
          293,
          586,
          718,
          385,
          1190,
          341,
          293,
          536,
          437,
          2314,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.27850494384765623,
        "compression_ratio": 1.6462264150943395,
        "end": 1043.92,
        "id": 363,
        "no_speech_prob": 0.000012805458027287386,
        "seek": 101446,
        "start": 1042.02,
        "temperature": 0,
        "text": " Eh, it's kind of jumping all the time.",
        "tokens": [
          51742,
          9663,
          11,
          309,
          311,
          733,
          295,
          11233,
          439,
          264,
          565,
          13,
          51837
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1046.74,
        "id": 364,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1045.3,
        "temperature": 0,
        "text": " All right, so this didn't really seem to,",
        "tokens": [
          50406,
          1057,
          558,
          11,
          370,
          341,
          994,
          380,
          534,
          1643,
          281,
          11,
          50478
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1048.22,
        "id": 365,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1046.74,
        "temperature": 0,
        "text": " ooh, look, ooh, it's doing something.",
        "tokens": [
          50478,
          17024,
          11,
          574,
          11,
          17024,
          11,
          309,
          311,
          884,
          746,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1049.7,
        "id": 366,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1048.22,
        "temperature": 0,
        "text": " That one actually kind of almost did something.",
        "tokens": [
          50552,
          663,
          472,
          767,
          733,
          295,
          1920,
          630,
          746,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1052.02,
        "id": 367,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1049.7,
        "temperature": 0,
        "text": " It's making some, its own decisions.",
        "tokens": [
          50626,
          467,
          311,
          1455,
          512,
          11,
          1080,
          1065,
          5327,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1053.5,
        "id": 368,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1052.02,
        "temperature": 0,
        "text": " That was very exciting.",
        "tokens": [
          50742,
          663,
          390,
          588,
          4670,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1055.6200000000001,
        "id": 369,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1053.5,
        "temperature": 0,
        "text": " All right, well, I've got some problems here.",
        "tokens": [
          50816,
          1057,
          558,
          11,
          731,
          11,
          286,
          600,
          658,
          512,
          2740,
          510,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1059.28,
        "id": 370,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1055.6200000000001,
        "temperature": 0,
        "text": " Number one is, when I sort of made my pretend version of it,",
        "tokens": [
          50922,
          5118,
          472,
          307,
          11,
          562,
          286,
          1333,
          295,
          1027,
          452,
          11865,
          3037,
          295,
          309,
          11,
          51105
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1062.38,
        "id": 371,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1059.28,
        "temperature": 0,
        "text": " I purposely made numbers between zero and one.",
        "tokens": [
          51105,
          286,
          41840,
          1027,
          3547,
          1296,
          4018,
          293,
          472,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1063.54,
        "id": 372,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1062.38,
        "temperature": 0,
        "text": " So one thing I should really do",
        "tokens": [
          51260,
          407,
          472,
          551,
          286,
          820,
          534,
          360,
          51318
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1065.3,
        "id": 373,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1063.54,
        "temperature": 0,
        "text": " is normalize all these values.",
        "tokens": [
          51318,
          307,
          2710,
          1125,
          439,
          613,
          4190,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1068.28,
        "id": 374,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1065.3,
        "temperature": 0,
        "text": " That's a pretty typical thing to sort of clean your data.",
        "tokens": [
          51406,
          663,
          311,
          257,
          1238,
          7476,
          551,
          281,
          1333,
          295,
          2541,
          428,
          1412,
          13,
          51555
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1069.42,
        "id": 375,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1068.28,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to say",
        "tokens": [
          51555,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          51612
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1071.82,
        "id": 376,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1069.42,
        "temperature": 0,
        "text": " this.y divided by height.",
        "tokens": [
          51612,
          341,
          13,
          88,
          6666,
          538,
          6681,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2319657990426728,
        "compression_ratio": 1.792332268370607,
        "end": 1074.26,
        "id": 377,
        "no_speech_prob": 0.000010616124200168997,
        "seek": 104446,
        "start": 1071.82,
        "temperature": 0,
        "text": " This.top divided by height.",
        "tokens": [
          51732,
          639,
          13,
          19337,
          6666,
          538,
          6681,
          13,
          51854
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1077.14,
        "id": 378,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1075.02,
        "temperature": 0,
        "text": " And the pipe's bottom divided by height,",
        "tokens": [
          50402,
          400,
          264,
          11240,
          311,
          2767,
          6666,
          538,
          6681,
          11,
          50508
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1080.02,
        "id": 379,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1077.14,
        "temperature": 0,
        "text": " and the pipe's x divided by width.",
        "tokens": [
          50508,
          293,
          264,
          11240,
          311,
          2031,
          6666,
          538,
          11402,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1082.84,
        "id": 380,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1080.02,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          50652,
          407,
          718,
          311,
          360,
          300,
          13,
          50793
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1087.86,
        "id": 381,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1083.94,
        "temperature": 0,
        "text": " And oops, let's get rid of this now.",
        "tokens": [
          50848,
          400,
          34166,
          11,
          718,
          311,
          483,
          3973,
          295,
          341,
          586,
          13,
          51044
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1089.62,
        "id": 382,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1087.86,
        "temperature": 0,
        "text": " You know, does this, nothing really different",
        "tokens": [
          51044,
          509,
          458,
          11,
          775,
          341,
          11,
          1825,
          534,
          819,
          51132
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1091.06,
        "id": 383,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1089.62,
        "temperature": 0,
        "text": " is going to happen here.",
        "tokens": [
          51132,
          307,
          516,
          281,
          1051,
          510,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1092.3,
        "id": 384,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1091.06,
        "temperature": 0,
        "text": " Going to run this a bunch of times.",
        "tokens": [
          51204,
          10963,
          281,
          1190,
          341,
          257,
          3840,
          295,
          1413,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1093.54,
        "id": 385,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1092.3,
        "temperature": 0,
        "text": " Oh, it's doing something.",
        "tokens": [
          51266,
          876,
          11,
          309,
          311,
          884,
          746,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1094.9,
        "id": 386,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1093.54,
        "temperature": 0,
        "text": " Oh my god, it's making some decisions.",
        "tokens": [
          51328,
          876,
          452,
          3044,
          11,
          309,
          311,
          1455,
          512,
          5327,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1096.3,
        "id": 387,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1094.9,
        "temperature": 0,
        "text": " Ooh, that was a good one, right?",
        "tokens": [
          51396,
          7951,
          11,
          300,
          390,
          257,
          665,
          472,
          11,
          558,
          30,
          51466
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1098.14,
        "id": 388,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1096.3,
        "temperature": 0,
        "text": " That was a pretty good one.",
        "tokens": [
          51466,
          663,
          390,
          257,
          1238,
          665,
          472,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1099.8799999999999,
        "id": 389,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1098.14,
        "temperature": 0,
        "text": " All right, so you can see that it's doing something.",
        "tokens": [
          51558,
          1057,
          558,
          11,
          370,
          291,
          393,
          536,
          300,
          309,
          311,
          884,
          746,
          13,
          51645
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1101.74,
        "id": 390,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1099.8799999999999,
        "temperature": 0,
        "text": " It's trying to think.",
        "tokens": [
          51645,
          467,
          311,
          1382,
          281,
          519,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.28145932191170303,
        "compression_ratio": 1.7593984962406015,
        "end": 1103.42,
        "id": 391,
        "no_speech_prob": 0.000004222828010824742,
        "seek": 107426,
        "start": 1101.74,
        "temperature": 0,
        "text": " But I've got another problem.",
        "tokens": [
          51738,
          583,
          286,
          600,
          658,
          1071,
          1154,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1106.74,
        "id": 392,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1103.42,
        "temperature": 0,
        "text": " I don't know, is pipe zero the right pipe?",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          11,
          307,
          11240,
          4018,
          264,
          558,
          11240,
          30,
          50530
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1109.14,
        "id": 393,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1106.74,
        "temperature": 0,
        "text": " I think I need to, I probably need an algorithm",
        "tokens": [
          50530,
          286,
          519,
          286,
          643,
          281,
          11,
          286,
          1391,
          643,
          364,
          9284,
          50650
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1111.8600000000001,
        "id": 394,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1109.14,
        "temperature": 0,
        "text": " to check which pipe is actually the one closest.",
        "tokens": [
          50650,
          281,
          1520,
          597,
          11240,
          307,
          767,
          264,
          472,
          13699,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1114.14,
        "id": 395,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1111.8600000000001,
        "temperature": 0,
        "text": " Let me remember, let me look at the main sketch.",
        "tokens": [
          50786,
          961,
          385,
          1604,
          11,
          718,
          385,
          574,
          412,
          264,
          2135,
          12325,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1115.5800000000002,
        "id": 396,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1114.14,
        "temperature": 0,
        "text": " How do I add the pipes?",
        "tokens": [
          50900,
          1012,
          360,
          286,
          909,
          264,
          21882,
          30,
          50972
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1117.1000000000001,
        "id": 397,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1115.5800000000002,
        "temperature": 0,
        "text": " Yeah, so first of all, the pipes are getting added",
        "tokens": [
          50972,
          865,
          11,
          370,
          700,
          295,
          439,
          11,
          264,
          21882,
          366,
          1242,
          3869,
          51048
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1118.66,
        "id": 398,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1117.1000000000001,
        "temperature": 0,
        "text": " to the end.",
        "tokens": [
          51048,
          281,
          264,
          917,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1120.6200000000001,
        "id": 399,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1118.66,
        "temperature": 0,
        "text": " And when did the, if the pipe goes off screen,",
        "tokens": [
          51126,
          400,
          562,
          630,
          264,
          11,
          498,
          264,
          11240,
          1709,
          766,
          2568,
          11,
          51224
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1124.66,
        "id": 400,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1120.6200000000001,
        "temperature": 0,
        "text": " it gets deleted from its spot,",
        "tokens": [
          51224,
          309,
          2170,
          22981,
          490,
          1080,
          4008,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1127.46,
        "id": 401,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1124.66,
        "temperature": 0,
        "text": " which would typically be the earliest one.",
        "tokens": [
          51426,
          597,
          576,
          5850,
          312,
          264,
          20573,
          472,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.21506632995605468,
        "compression_ratio": 1.6085271317829457,
        "end": 1131.42,
        "id": 402,
        "no_speech_prob": 0.000018342881958233193,
        "seek": 110342,
        "start": 1127.46,
        "temperature": 0,
        "text": " So, it might work.",
        "tokens": [
          51566,
          407,
          11,
          309,
          1062,
          589,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1134.42,
        "id": 403,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1132.26,
        "temperature": 0,
        "text": " But let's be smart about this.",
        "tokens": [
          50406,
          583,
          718,
          311,
          312,
          4069,
          466,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1136.22,
        "id": 404,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1134.42,
        "temperature": 0,
        "text": " Let's actually, let's just say,",
        "tokens": [
          50514,
          961,
          311,
          767,
          11,
          718,
          311,
          445,
          584,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1139.38,
        "id": 405,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1136.22,
        "temperature": 0,
        "text": " this is probably overdoing it,",
        "tokens": [
          50604,
          341,
          307,
          1391,
          670,
          42013,
          309,
          11,
          50762
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1141.5,
        "id": 406,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1139.38,
        "temperature": 0,
        "text": " but let's actually find the closest pipe.",
        "tokens": [
          50762,
          457,
          718,
          311,
          767,
          915,
          264,
          13699,
          11240,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1149.3400000000001,
        "id": 407,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1144.8600000000001,
        "temperature": 0,
        "text": " So I'm going to assume the closest pipe is pipes index zero.",
        "tokens": [
          51036,
          407,
          286,
          478,
          516,
          281,
          6552,
          264,
          13699,
          11240,
          307,
          21882,
          8186,
          4018,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1153.98,
        "id": 408,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1149.3400000000001,
        "temperature": 0,
        "text": " Then I am going to look at all of the pipes,",
        "tokens": [
          51260,
          1396,
          286,
          669,
          516,
          281,
          574,
          412,
          439,
          295,
          264,
          21882,
          11,
          51492
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1156.14,
        "id": 409,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1153.98,
        "temperature": 0,
        "text": " starting with one.",
        "tokens": [
          51492,
          2891,
          365,
          472,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.30223242441813153,
        "compression_ratio": 1.6368421052631579,
        "end": 1158.64,
        "id": 410,
        "no_speech_prob": 0.000013211943951318972,
        "seek": 113142,
        "start": 1156.14,
        "temperature": 0,
        "text": " And I'm going to say, oh, actually, you know what?",
        "tokens": [
          51600,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          1954,
          11,
          767,
          11,
          291,
          458,
          437,
          30,
          51725
        ]
      },
      {
        "avg_logprob": -0.3423923492431641,
        "compression_ratio": 1.4295774647887325,
        "end": 1162.24,
        "id": 411,
        "no_speech_prob": 0.000023187398255686276,
        "seek": 115864,
        "start": 1159.64,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          50414,
          961,
          311,
          360,
          341,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.3423923492431641,
        "compression_ratio": 1.4295774647887325,
        "end": 1167.24,
        "id": 412,
        "no_speech_prob": 0.000023187398255686276,
        "seek": 115864,
        "start": 1162.24,
        "temperature": 0,
        "text": " And I want closest different,",
        "tokens": [
          50544,
          400,
          286,
          528,
          13699,
          819,
          11,
          50794
        ]
      },
      {
        "avg_logprob": -0.3423923492431641,
        "compression_ratio": 1.4295774647887325,
        "end": 1169.44,
        "id": 413,
        "no_speech_prob": 0.000023187398255686276,
        "seek": 115864,
        "start": 1167.44,
        "temperature": 0,
        "text": " closest d being the closest distance",
        "tokens": [
          50804,
          13699,
          274,
          885,
          264,
          13699,
          4560,
          50904
        ]
      },
      {
        "avg_logprob": -0.3423923492431641,
        "compression_ratio": 1.4295774647887325,
        "end": 1174.44,
        "id": 414,
        "no_speech_prob": 0.000023187398255686276,
        "seek": 115864,
        "start": 1169.44,
        "temperature": 0,
        "text": " to be the absolute value of this.x minus closest.x.",
        "tokens": [
          50904,
          281,
          312,
          264,
          8236,
          2158,
          295,
          341,
          13,
          87,
          3175,
          13699,
          13,
          87,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.3423923492431641,
        "compression_ratio": 1.4295774647887325,
        "end": 1183.4,
        "id": 415,
        "no_speech_prob": 0.000023187398255686276,
        "seek": 115864,
        "start": 1178.4,
        "temperature": 0,
        "text": " Okay, then I'm going to say, let d equal,",
        "tokens": [
          51352,
          1033,
          11,
          550,
          286,
          478,
          516,
          281,
          584,
          11,
          718,
          274,
          2681,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.3423923492431641,
        "compression_ratio": 1.4295774647887325,
        "end": 1185.2,
        "id": 416,
        "no_speech_prob": 0.000023187398255686276,
        "seek": 115864,
        "start": 1183.5200000000002,
        "temperature": 0,
        "text": " we can start with one here.",
        "tokens": [
          51608,
          321,
          393,
          722,
          365,
          472,
          510,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.27169578306136594,
        "compression_ratio": 1.5303030303030303,
        "end": 1190.88,
        "id": 417,
        "no_speech_prob": 0.000070311660238076,
        "seek": 118520,
        "start": 1185.88,
        "temperature": 0,
        "text": " Absolute value of this.x minus closest,",
        "tokens": [
          50398,
          43965,
          1169,
          2158,
          295,
          341,
          13,
          87,
          3175,
          13699,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.27169578306136594,
        "compression_ratio": 1.5303030303030303,
        "end": 1197.0800000000002,
        "id": 418,
        "no_speech_prob": 0.000070311660238076,
        "seek": 118520,
        "start": 1194.4,
        "temperature": 0,
        "text": " closest.x.",
        "tokens": [
          50824,
          13699,
          13,
          87,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.27169578306136594,
        "compression_ratio": 1.5303030303030303,
        "end": 1202.0800000000002,
        "id": 419,
        "no_speech_prob": 0.000070311660238076,
        "seek": 118520,
        "start": 1197.0800000000002,
        "temperature": 0,
        "text": " And if d is less than closest d,",
        "tokens": [
          50958,
          400,
          498,
          274,
          307,
          1570,
          813,
          13699,
          274,
          11,
          51208
        ]
      },
      {
        "avg_logprob": -0.27169578306136594,
        "compression_ratio": 1.5303030303030303,
        "end": 1206.66,
        "id": 420,
        "no_speech_prob": 0.000070311660238076,
        "seek": 118520,
        "start": 1202.16,
        "temperature": 0,
        "text": " then the closest is that particular pipe.",
        "tokens": [
          51212,
          550,
          264,
          13699,
          307,
          300,
          1729,
          11240,
          13,
          51437
        ]
      },
      {
        "avg_logprob": -0.27169578306136594,
        "compression_ratio": 1.5303030303030303,
        "end": 1210.96,
        "id": 421,
        "no_speech_prob": 0.000070311660238076,
        "seek": 118520,
        "start": 1208,
        "temperature": 0,
        "text": " And the closest d is that new distance.",
        "tokens": [
          51504,
          400,
          264,
          13699,
          274,
          307,
          300,
          777,
          4560,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.27169578306136594,
        "compression_ratio": 1.5303030303030303,
        "end": 1213.28,
        "id": 422,
        "no_speech_prob": 0.000070311660238076,
        "seek": 118520,
        "start": 1210.96,
        "temperature": 0,
        "text": " So this is a little quick algorithm.",
        "tokens": [
          51652,
          407,
          341,
          307,
          257,
          707,
          1702,
          9284,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1215.52,
        "id": 423,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1213.28,
        "temperature": 0,
        "text": " Find the closest pipe.",
        "tokens": [
          50364,
          11809,
          264,
          13699,
          11240,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1216.52,
        "id": 424,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1215.52,
        "temperature": 0,
        "text": " Here's the thing, though.",
        "tokens": [
          50476,
          1692,
          311,
          264,
          551,
          11,
          1673,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1219.86,
        "id": 425,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1216.52,
        "temperature": 0,
        "text": " I don't want a pipe if it's gone behind me already.",
        "tokens": [
          50526,
          286,
          500,
          380,
          528,
          257,
          11240,
          498,
          309,
          311,
          2780,
          2261,
          385,
          1217,
          13,
          50693
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1221.48,
        "id": 426,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1219.86,
        "temperature": 0,
        "text": " That one shouldn't matter.",
        "tokens": [
          50693,
          663,
          472,
          4659,
          380,
          1871,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1222.92,
        "id": 427,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1221.48,
        "temperature": 0,
        "text": " I got an idea.",
        "tokens": [
          50774,
          286,
          658,
          364,
          1558,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1225.08,
        "id": 428,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1222.92,
        "temperature": 0,
        "text": " Let's get rid of that absolute value thing.",
        "tokens": [
          50846,
          961,
          311,
          483,
          3973,
          295,
          300,
          8236,
          2158,
          551,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1227.94,
        "id": 429,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1227.1,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51055,
          1779,
          30,
          51097
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1232.3999999999999,
        "id": 430,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1227.94,
        "temperature": 0,
        "text": " Because as long as the distance,",
        "tokens": [
          51097,
          1436,
          382,
          938,
          382,
          264,
          4560,
          11,
          51320
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1235.76,
        "id": 431,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1232.3999999999999,
        "temperature": 0,
        "text": " so what I can do, okay, the pipe's x minus my x,",
        "tokens": [
          51320,
          370,
          437,
          286,
          393,
          360,
          11,
          1392,
          11,
          264,
          11240,
          311,
          2031,
          3175,
          452,
          2031,
          11,
          51488
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1238.04,
        "id": 432,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1235.76,
        "temperature": 0,
        "text": " it's positive if it's over here,",
        "tokens": [
          51488,
          309,
          311,
          3353,
          498,
          309,
          311,
          670,
          510,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1239.84,
        "id": 433,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1238.04,
        "temperature": 0,
        "text": " and I want that to be a lower, lower number,",
        "tokens": [
          51602,
          293,
          286,
          528,
          300,
          281,
          312,
          257,
          3126,
          11,
          3126,
          1230,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.20038431744242824,
        "compression_ratio": 1.5877551020408163,
        "end": 1241.84,
        "id": 434,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 121328,
        "start": 1239.84,
        "temperature": 0,
        "text": " but I don't want it to be negative.",
        "tokens": [
          51692,
          457,
          286,
          500,
          380,
          528,
          309,
          281,
          312,
          3671,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1244.12,
        "id": 435,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1241.84,
        "temperature": 0,
        "text": " So as long as d is less than closest d",
        "tokens": [
          50364,
          407,
          382,
          938,
          382,
          274,
          307,
          1570,
          813,
          13699,
          274,
          50478
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1248.08,
        "id": 436,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1244.12,
        "temperature": 0,
        "text": " and d is greater than zero, then we're fine.",
        "tokens": [
          50478,
          293,
          274,
          307,
          5044,
          813,
          4018,
          11,
          550,
          321,
          434,
          2489,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1252.1599999999999,
        "id": 437,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1248.08,
        "temperature": 0,
        "text": " But what if this is negative?",
        "tokens": [
          50676,
          583,
          437,
          498,
          341,
          307,
          3671,
          30,
          50880
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1254.6799999999998,
        "id": 438,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1252.1599999999999,
        "temperature": 0,
        "text": " But it wouldn't be at the beginning.",
        "tokens": [
          50880,
          583,
          309,
          2759,
          380,
          312,
          412,
          264,
          2863,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1256.52,
        "id": 439,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1254.6799999999998,
        "temperature": 0,
        "text": " Okay, a couple mistakes here.",
        "tokens": [
          51006,
          1033,
          11,
          257,
          1916,
          8038,
          510,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1259.56,
        "id": 440,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1256.52,
        "temperature": 0,
        "text": " One is this should be pipe's index i.",
        "tokens": [
          51098,
          1485,
          307,
          341,
          820,
          312,
          11240,
          311,
          8186,
          741,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1262.6799999999998,
        "id": 441,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1259.56,
        "temperature": 0,
        "text": " I'm going to change this to say closest is null,",
        "tokens": [
          51250,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          584,
          13699,
          307,
          18184,
          11,
          51406
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1265.56,
        "id": 442,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1262.6799999999998,
        "temperature": 0,
        "text": " and the closest distance is infinity.",
        "tokens": [
          51406,
          293,
          264,
          13699,
          4560,
          307,
          13202,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1267.76,
        "id": 443,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1265.56,
        "temperature": 0,
        "text": " I love that you can type infinity in JavaScript",
        "tokens": [
          51550,
          286,
          959,
          300,
          291,
          393,
          2010,
          13202,
          294,
          15778,
          51660
        ]
      },
      {
        "avg_logprob": -0.20147654440550677,
        "compression_ratio": 1.5967078189300412,
        "end": 1269.76,
        "id": 444,
        "no_speech_prob": 0.000005255393261904828,
        "seek": 124184,
        "start": 1267.76,
        "temperature": 0,
        "text": " and it knows what that is somehow.",
        "tokens": [
          51660,
          293,
          309,
          3255,
          437,
          300,
          307,
          6063,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1272.8799999999999,
        "id": 445,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1269.92,
        "temperature": 0,
        "text": " If that's a number it could store in memory.",
        "tokens": [
          50372,
          759,
          300,
          311,
          257,
          1230,
          309,
          727,
          3531,
          294,
          4675,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1274.44,
        "id": 446,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1272.8799999999999,
        "temperature": 0,
        "text": " But what I'm actually going to do here,",
        "tokens": [
          50520,
          583,
          437,
          286,
          478,
          767,
          516,
          281,
          360,
          510,
          11,
          50598
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1275.48,
        "id": 447,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1274.44,
        "temperature": 0,
        "text": " I think this will work now,",
        "tokens": [
          50598,
          286,
          519,
          341,
          486,
          589,
          586,
          11,
          50650
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1277.36,
        "id": 448,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1275.48,
        "temperature": 0,
        "text": " and then I can start with zero.",
        "tokens": [
          50650,
          293,
          550,
          286,
          393,
          722,
          365,
          4018,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1280.64,
        "id": 449,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1277.36,
        "temperature": 0,
        "text": " So as long as it is in front of it,",
        "tokens": [
          50744,
          407,
          382,
          938,
          382,
          309,
          307,
          294,
          1868,
          295,
          309,
          11,
          50908
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1282.12,
        "id": 450,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1280.64,
        "temperature": 0,
        "text": " that's the closest one.",
        "tokens": [
          50908,
          300,
          311,
          264,
          13699,
          472,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1286.6,
        "id": 451,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1282.12,
        "temperature": 0,
        "text": " So now I can say instead of pipe's index zero,",
        "tokens": [
          50982,
          407,
          586,
          286,
          393,
          584,
          2602,
          295,
          11240,
          311,
          8186,
          4018,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1290.16,
        "id": 452,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1286.6,
        "temperature": 0,
        "text": " I'm going to say closest down here.",
        "tokens": [
          51206,
          286,
          478,
          516,
          281,
          584,
          13699,
          760,
          510,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1294.48,
        "id": 453,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1291.32,
        "temperature": 0,
        "text": " I'm going to say closest here and closest here,",
        "tokens": [
          51442,
          286,
          478,
          516,
          281,
          584,
          13699,
          510,
          293,
          13699,
          510,
          11,
          51600
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1296.48,
        "id": 454,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1294.48,
        "temperature": 0,
        "text": " and here we go.",
        "tokens": [
          51600,
          293,
          510,
          321,
          352,
          13,
          51700
        ]
      },
      {
        "avg_logprob": -0.21878454064120764,
        "compression_ratio": 1.7083333333333333,
        "end": 1297.8,
        "id": 455,
        "no_speech_prob": 0.00059766776394099,
        "seek": 126976,
        "start": 1296.48,
        "temperature": 0,
        "text": " Now we are ready.",
        "tokens": [
          51700,
          823,
          321,
          366,
          1919,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1300.9199999999998,
        "id": 456,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1297.8,
        "temperature": 0,
        "text": " Oh, cannot read property top of null.",
        "tokens": [
          50364,
          876,
          11,
          2644,
          1401,
          4707,
          1192,
          295,
          18184,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1303.12,
        "id": 457,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1300.9199999999998,
        "temperature": 0,
        "text": " All right, so what's going on here?",
        "tokens": [
          50520,
          1057,
          558,
          11,
          370,
          437,
          311,
          516,
          322,
          510,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1305.08,
        "id": 458,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1303.12,
        "temperature": 0,
        "text": " Oops, so the way I program this,",
        "tokens": [
          50630,
          21726,
          11,
          370,
          264,
          636,
          286,
          1461,
          341,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1306.8,
        "id": 459,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1305.08,
        "temperature": 0,
        "text": " I've got to say pipe's,",
        "tokens": [
          50728,
          286,
          600,
          658,
          281,
          584,
          11240,
          311,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1308.3,
        "id": 460,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1306.8,
        "temperature": 0,
        "text": " because I took out the absolute value,",
        "tokens": [
          50814,
          570,
          286,
          1890,
          484,
          264,
          8236,
          2158,
          11,
          50889
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1313.3,
        "id": 461,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1308.3,
        "temperature": 0,
        "text": " I've got to say pipe's index i minus this.x, right?",
        "tokens": [
          50889,
          286,
          600,
          658,
          281,
          584,
          11240,
          311,
          8186,
          741,
          3175,
          341,
          13,
          87,
          11,
          558,
          30,
          51139
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1316.6,
        "id": 462,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1315.04,
        "temperature": 0,
        "text": " Because I want it to be positive,",
        "tokens": [
          51226,
          1436,
          286,
          528,
          309,
          281,
          312,
          3353,
          11,
          51304
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1318.12,
        "id": 463,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1316.6,
        "temperature": 0,
        "text": " like the pipe, pipe, pipe, pipe, pipe,",
        "tokens": [
          51304,
          411,
          264,
          11240,
          11,
          11240,
          11,
          11240,
          11,
          11240,
          11,
          11240,
          11,
          51380
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1318.96,
        "id": 464,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1318.12,
        "temperature": 0,
        "text": " and then it goes past it.",
        "tokens": [
          51380,
          293,
          550,
          309,
          1709,
          1791,
          309,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1320.44,
        "id": 465,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1318.96,
        "temperature": 0,
        "text": " Okay, this should be fine now.",
        "tokens": [
          51422,
          1033,
          11,
          341,
          820,
          312,
          2489,
          586,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.30710814429111166,
        "compression_ratio": 1.6854460093896713,
        "end": 1325.12,
        "id": 466,
        "no_speech_prob": 0.00010229973122477531,
        "seek": 129780,
        "start": 1324.28,
        "temperature": 0,
        "text": " Or not.",
        "tokens": [
          51688,
          1610,
          406,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1330.3999999999999,
        "id": 467,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1325.3999999999999,
        "temperature": 0,
        "text": " Oh, dot x, dot x, pipe's index i dot x.",
        "tokens": [
          50378,
          876,
          11,
          5893,
          2031,
          11,
          5893,
          2031,
          11,
          11240,
          311,
          8186,
          741,
          5893,
          2031,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1332.2399999999998,
        "id": 468,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1330.3999999999999,
        "temperature": 0,
        "text": " Okay, there we go.",
        "tokens": [
          50628,
          1033,
          11,
          456,
          321,
          352,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1334.76,
        "id": 469,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1332.2399999999998,
        "temperature": 0,
        "text": " So I can do this a bunch of times,",
        "tokens": [
          50720,
          407,
          286,
          393,
          360,
          341,
          257,
          3840,
          295,
          1413,
          11,
          50846
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1337.36,
        "id": 470,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1334.76,
        "temperature": 0,
        "text": " and we can see I'm going to get a bunch of random birds",
        "tokens": [
          50846,
          293,
          321,
          393,
          536,
          286,
          478,
          516,
          281,
          483,
          257,
          3840,
          295,
          4974,
          9009,
          50976
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1339.84,
        "id": 471,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1337.36,
        "temperature": 0,
        "text": " that are doing sort of random things.",
        "tokens": [
          50976,
          300,
          366,
          884,
          1333,
          295,
          4974,
          721,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1341,
        "id": 472,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1339.84,
        "temperature": 0,
        "text": " All right, I think this is going to be",
        "tokens": [
          51100,
          1057,
          558,
          11,
          286,
          519,
          341,
          307,
          516,
          281,
          312,
          51158
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1342.56,
        "id": 473,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1341,
        "temperature": 0,
        "text": " a multi-parter coding challenge.",
        "tokens": [
          51158,
          257,
          4825,
          12,
          2181,
          391,
          17720,
          3430,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1345.7199999999998,
        "id": 474,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1342.56,
        "temperature": 0,
        "text": " I am now wrapping up the end of this first part,",
        "tokens": [
          51236,
          286,
          669,
          586,
          21993,
          493,
          264,
          917,
          295,
          341,
          700,
          644,
          11,
          51394
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1349.4799999999998,
        "id": 475,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1345.7199999999998,
        "temperature": 0,
        "text": " because just to summarize, what have I done so far?",
        "tokens": [
          51394,
          570,
          445,
          281,
          20858,
          11,
          437,
          362,
          286,
          1096,
          370,
          1400,
          30,
          51582
        ]
      },
      {
        "avg_logprob": -0.20872769211277817,
        "compression_ratio": 1.61003861003861,
        "end": 1353.8,
        "id": 476,
        "no_speech_prob": 0.000009368702194478828,
        "seek": 132512,
        "start": 1349.4799999999998,
        "temperature": 0,
        "text": " I have built a system where I have the game Flappy Bird,",
        "tokens": [
          51582,
          286,
          362,
          3094,
          257,
          1185,
          689,
          286,
          362,
          264,
          1216,
          479,
          875,
          7966,
          15931,
          11,
          51798
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1356.48,
        "id": 477,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1353.8,
        "temperature": 0,
        "text": " I have developed a neural network architecture",
        "tokens": [
          50364,
          286,
          362,
          4743,
          257,
          18161,
          3209,
          9482,
          50498
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1359.76,
        "id": 478,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1356.48,
        "temperature": 0,
        "text": " for the bird to read in the state,",
        "tokens": [
          50498,
          337,
          264,
          5255,
          281,
          1401,
          294,
          264,
          1785,
          11,
          50662
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1362.8,
        "id": 479,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1359.76,
        "temperature": 0,
        "text": " sort of evaluate the state of the game,",
        "tokens": [
          50662,
          1333,
          295,
          13059,
          264,
          1785,
          295,
          264,
          1216,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1364.96,
        "id": 480,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1362.8,
        "temperature": 0,
        "text": " make a guess as to what it should do,",
        "tokens": [
          50814,
          652,
          257,
          2041,
          382,
          281,
          437,
          309,
          820,
          360,
          11,
          50922
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1367.28,
        "id": 481,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1364.96,
        "temperature": 0,
        "text": " should it jump up, should it not, based on that,",
        "tokens": [
          50922,
          820,
          309,
          3012,
          493,
          11,
          820,
          309,
          406,
          11,
          2361,
          322,
          300,
          11,
          51038
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1369.08,
        "id": 482,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1367.28,
        "temperature": 0,
        "text": " and then I have put that into motion.",
        "tokens": [
          51038,
          293,
          550,
          286,
          362,
          829,
          300,
          666,
          5394,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1374.08,
        "id": 483,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1369.08,
        "temperature": 0,
        "text": " That neural network is part of the bird object now.",
        "tokens": [
          51128,
          663,
          18161,
          3209,
          307,
          644,
          295,
          264,
          5255,
          2657,
          586,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1378.9199999999998,
        "id": 484,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1374.1599999999999,
        "temperature": 0,
        "text": " It has a brain, 441, and then it has a think function",
        "tokens": [
          51382,
          467,
          575,
          257,
          3567,
          11,
          16408,
          16,
          11,
          293,
          550,
          309,
          575,
          257,
          519,
          2445,
          51620
        ]
      },
      {
        "avg_logprob": -0.19144047823819246,
        "compression_ratio": 1.7321428571428572,
        "end": 1381.04,
        "id": 485,
        "no_speech_prob": 0.0000015294122022169176,
        "seek": 135380,
        "start": 1378.9199999999998,
        "temperature": 0,
        "text": " which sends the data about the game",
        "tokens": [
          51620,
          597,
          14790,
          264,
          1412,
          466,
          264,
          1216,
          51726
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1383.8,
        "id": 486,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1381.04,
        "temperature": 0,
        "text": " into the neural network and decides to go up or not.",
        "tokens": [
          50364,
          666,
          264,
          18161,
          3209,
          293,
          14898,
          281,
          352,
          493,
          420,
          406,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1388.84,
        "id": 487,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1384.84,
        "temperature": 0,
        "text": " Now what I need to do is actually implement",
        "tokens": [
          50554,
          823,
          437,
          286,
          643,
          281,
          360,
          307,
          767,
          4445,
          50754
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1391.98,
        "id": 488,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1390.12,
        "temperature": 0,
        "text": " the neuroevolution part.",
        "tokens": [
          50818,
          264,
          16499,
          13379,
          3386,
          644,
          13,
          50911
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1394.1599999999999,
        "id": 489,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1391.98,
        "temperature": 0,
        "text": " So I've implemented the neuro part.",
        "tokens": [
          50911,
          407,
          286,
          600,
          12270,
          264,
          16499,
          644,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1397.04,
        "id": 490,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1394.1599999999999,
        "temperature": 0,
        "text": " I designed a way for the bird to make a decision",
        "tokens": [
          51020,
          286,
          4761,
          257,
          636,
          337,
          264,
          5255,
          281,
          652,
          257,
          3537,
          51164
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1399.96,
        "id": 491,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1397.04,
        "temperature": 0,
        "text": " based on how it's evaluating the scene,",
        "tokens": [
          51164,
          2361,
          322,
          577,
          309,
          311,
          27479,
          264,
          4145,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1402.5,
        "id": 492,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1399.96,
        "temperature": 0,
        "text": " and what I need to do now is make a population of them",
        "tokens": [
          51310,
          293,
          437,
          286,
          643,
          281,
          360,
          586,
          307,
          652,
          257,
          4415,
          295,
          552,
          51437
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1405.76,
        "id": 493,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1402.5,
        "temperature": 0,
        "text": " and try them all and evolve them over time.",
        "tokens": [
          51437,
          293,
          853,
          552,
          439,
          293,
          16693,
          552,
          670,
          565,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1408,
        "id": 494,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1405.76,
        "temperature": 0,
        "text": " So I'm going to take a little break here.",
        "tokens": [
          51600,
          407,
          286,
          478,
          516,
          281,
          747,
          257,
          707,
          1821,
          510,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.22714376048881466,
        "compression_ratio": 1.780590717299578,
        "end": 1409.24,
        "id": 495,
        "no_speech_prob": 0.00000801349051471334,
        "seek": 138104,
        "start": 1408,
        "temperature": 0,
        "text": " I'm going to meditate for a minute",
        "tokens": [
          51712,
          286,
          478,
          516,
          281,
          29989,
          337,
          257,
          3456,
          51774
        ]
      },
      {
        "avg_logprob": -0.33730354309082033,
        "compression_ratio": 1.3352601156069364,
        "end": 1412.24,
        "id": 496,
        "no_speech_prob": 0.000027535312256077304,
        "seek": 140924,
        "start": 1409.24,
        "temperature": 0,
        "text": " on how much my brain doesn't work as well",
        "tokens": [
          50364,
          322,
          577,
          709,
          452,
          3567,
          1177,
          380,
          589,
          382,
          731,
          50514
        ]
      },
      {
        "avg_logprob": -0.33730354309082033,
        "compression_ratio": 1.3352601156069364,
        "end": 1415.24,
        "id": 497,
        "no_speech_prob": 0.000027535312256077304,
        "seek": 140924,
        "start": 1412.24,
        "temperature": 0,
        "text": " as a simple multilayered perceptron,",
        "tokens": [
          50514,
          382,
          257,
          2199,
          2120,
          388,
          320,
          4073,
          43276,
          2044,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.33730354309082033,
        "compression_ratio": 1.3352601156069364,
        "end": 1417.1200000000001,
        "id": 498,
        "no_speech_prob": 0.000027535312256077304,
        "seek": 140924,
        "start": 1415.24,
        "temperature": 0,
        "text": " and I will be back in the next video",
        "tokens": [
          50664,
          293,
          286,
          486,
          312,
          646,
          294,
          264,
          958,
          960,
          50758
        ]
      },
      {
        "avg_logprob": -0.33730354309082033,
        "compression_ratio": 1.3352601156069364,
        "end": 1419.74,
        "id": 499,
        "no_speech_prob": 0.000027535312256077304,
        "seek": 140924,
        "start": 1417.1200000000001,
        "temperature": 0,
        "text": " to actually implement the genetic algorithm part.",
        "tokens": [
          50758,
          281,
          767,
          4445,
          264,
          12462,
          9284,
          644,
          13,
          50889
        ]
      },
      {
        "avg_logprob": -0.33730354309082033,
        "compression_ratio": 1.3352601156069364,
        "end": 1423.28,
        "id": 500,
        "no_speech_prob": 0.000027535312256077304,
        "seek": 140924,
        "start": 1419.74,
        "temperature": 0,
        "text": " Thank you for tuning in and being on this journey with me.",
        "tokens": [
          50889,
          1044,
          291,
          337,
          15164,
          294,
          293,
          885,
          322,
          341,
          4671,
          365,
          385,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.33730354309082033,
        "compression_ratio": 1.3352601156069364,
        "end": 1426.28,
        "id": 501,
        "no_speech_prob": 0.000027535312256077304,
        "seek": 140924,
        "start": 1423.28,
        "temperature": 0,
        "text": " ♪♪",
        "tokens": [
          51066,
          220,
          158,
          247,
          103,
          158,
          247,
          103,
          51216
        ]
      }
    ],
    "transcription": " It's time for coding challenge number 100. Here we go. In this coding challenge, I am going to do something that I have been wanting to do on this channel for I don't know, about 100 coding challenges. I'm going to make a project that involves neuroevolution. I am going to combine both neural networks and genetic algorithms into an agent, into a simulation of a simple game, and I'm going to train, choo-choo, train that agent to play that game effectively by making decisions with a neural network and evolving its neural network with a genetic algorithm. Way too much explanation. So this is a demonstration that Versatilis on GitHub, Coding Train Contributor, Eric made. This is using the Flappy Bird clone GitHub repository that various folks have contributed design ideas to and is actually running neuroevolution right now. You can see these trains are kind of getting better and better at making their way through these little gaps. So I'm going to program this myself. Now I'm going to make a version of this in this coding challenge. The difference, however, is I'm going to want to work in a sort of a simpler place. So I am going to use the code from, I think it was coding challenge number 31, which just is this simple version of Flappy Bird that I'm playing with the space bar right now. So I took out all the design stuff just to see if we can get the, whoa, I'm terrible at this, the mechanic, the mechanic of the game working. Now, I need to move over to the whiteboard to it for a second. Before I can write any code, I want to talk about all of the pieces going on here. All right, so number one, I need to have the Flappy Bird game. So you can look and find, if you wanted to recreate this coding challenge, you can go and get coding challenge number 31. I've actually made a few minor tweaks to it, but I will, I guess after this is over, I'm going to update those. So coding challenge 31 will mirror the code as I start with. Then I also need the toy neural network library, which has two files associated with it, matrix.js and also, neural, I think it's just called nn.js. So this is the code for the neural network and some code for some matrix multiplication math that's part of the neural network. If you're interested in how this library was made, boy, do I have a lot of tutorials for you. Link to those somewhere in this video's description. And this, by the way, incidentally, this just has a file for the main sketch. I believe it has a file called pipe.js and one called, I know I'm probably writing off the side here, but close enough, pipe.js and one called bird.js. So this is all the code that I'm going to start with. Now, nowhere in here is there anything about a genetic algorithm. So most of the code that I'm going to write during this coding challenge, I'm going to put into a new file and I will call it ga.js. There are a couple features that are in this neural network class that I put there for the purposes of being able to apply a genetic algorithm. And those are a function called copy, which allows me to make a complete copy of a neural network in its current state, as well as mutate, which is a function that allows me to make some minor random changes to the state of that neural network. And when I say state, I mean all of the weights. So these are some things that I'm going to definitely need to make use of. What I will not be doing is I won't be training the neural network in the sort of traditional way that you might have seen in some of my other videos, like the doodle classifier or the XOR challenge, where I'm using this thing called back propagation, supervised learning. What I want to do in this video is something that's akin to this idea of reinforcement learning. Now, reinforcement learning is a field of research that's been around for a very long time. It predates deep learning, neural networks, all that sort of stuff. And I would love to come do lots more tutorials about reinforcement learning. The recent advances that you might have seen with things like DeepMind and its bot that learned to beat all of the Atari games, those were developed with a style of reinforcement learning called deep Q learning, which uses a neural network and trains the neural network based on this reward-based system. So you have this idea in reinforcement learning that you have a world. The world is going to be, in our case, the world of Flappy Bird. The world has a given state. The agent or the entity that is being reinforced, trained, that is learning, based on that state, decides to make an action. I'm going to jump up. I'm going to not jump up. In this case, Flappy Bird is very simple. And then based on that, there is a reward. That reward is fed back into the system and we kind of repeat here. Now, here's the thing. This is what makes deep reinforcement learning and other reinforcement learning scenarios very complicated. Let's just think about this in the case of Flappy Bird. I am a bird. I am over here. I now, this is the state. The state could just be the pixels of the display, and that's in fact what was used in the DeepMind project. I am a bird and I am looking at the state and evaluating the state. I'm going to choose to make an action. That choice is to jump up. I now expect my reward. Please, everybody, shower me with your gifts. I have made this wonderful decision to jump up. The problem is, how do I know if that was a good or bad decision? I don't really right now. I don't until much later. I don't, the payoff for certain things that I might do in a game scenario, how do I know if I'm playing, say, the game chess, if this move is really going to be a good move for way down the line? This is something I really need to figure out. It gets very complicated very quickly. The good news is I can use a different system. I can say, eh, you know what, instead of trying to actually figure out whether it was a good or bad decision, I'm just going to make a whole lot of these birds, maybe like 1,000 of them. They will all have random neural networks, random neural networks. They will just make random decisions, and maybe some of those random decisions happen to be better than some of the other random decisions. I will then take those into a new generation and repopulate the world with 100 new birds based off of those ones that did well over and over and over again, the same principles of a genetic algorithm. So now I might refer to you, if you have not ever worked with a genetic algorithm before, I'll refer to you to my genetic algorithm tutorial series. Okay, so let's go and write a little bit of code, and then we're going to have to come back here to the whiteboard I know in a second, but let's start doing a little bit of code here. So I'm going to go into the code. I'm going to go into the bird class, and right here I'm noticing, okay, this is the function that causes the bird to jump up. How is that currently decided? That is currently decided in sketch.js here when I press a key. This will no longer be the case. This entire function is now going to be commented out. I want the bird to make its own decision whether it should jump up or not. So now I'm going to go over here, and I'm going to say, this.brain equals new neural network. So the idea here is that the inside the bird object, the bird object will have its own neural network, and its neural network will be the thing that makes the decision whether it should jump or not. I'm remembering, this is not an original idea I have. Of course, I will include some links in this video's description to other references and papers on neuroevolution, but I also want to briefly just point out a bunch of these links, which are here. These are some other neuroevolution demonstrations that are on GitHub from various other GitHub users. There's a Flappy learning one, an Asteroids learning one, the Steering Agent, Snake Neuroevolution, and Neuroevolution Playing Super Mario. So I'll include links to all these as well, as well as some of these papers and other resources in the video's description. Okay, so now here's the thing. If you watched any of my neural network tutorials, you might remember that what do I need to put in here? I need to say how many inputs, I need to say how many outputs, and I need to say how many hidden nodes. So what goes in there? This is where we have to return to the whiteboard. Okay, so here's the thing. This is the game Flappy Bird. I'm going to now architect my neural network down here. I need a bunch of inputs, I need a bunch of hidden, and I need a bunch of outputs. Let's go with the easy part first. The easy part here is perhaps the outputs. So let's say I wanted to train an agent to play a game that used the arrow keys. So the player of the game can either move up, down, left, or right, there's four options. I would have four outputs. I want a vector with four outputs, each representing the probability or the confidence score of whether the agent should move up, move down, move left, or right. In this case, I don't need four. The only decision is jump or don't jump. In this case, I really only need one output. I can have one output that ranges between zero and one. If it's greater than.5, jump. If it's less than.5, don't jump. Let's just do that. So let's do that. That's going to make our life so much easier. So I'm just going to have one output. So simple. We'll do some other, I'll do some other examples in other videos with more complexity. One output. Now, how many inputs? This gets a little harder. Now wouldn't it be nice if I could write some generic code that's basically going to work for any game? As long as I have a way of evaluating the score of the game, the same code will work for everything. And one way of doing that would actually be the pixels of the game as inputs. So maybe I take the visuals of the game, I sample it down to a lower resolution image, I flatten that into an array, I take the brightness of every pixel, I feed that in as the inputs. That's certainly one thing I could do. I would love to try that as an experiment in as a counterpoint to the way I'm going to do it in this video. I'm instead going to take somewhat of a higher level approach, and I'm going to do some feature extraction manually with my brain. I'm going to say that I think, I'm going to decide that I think that the important properties, the inputs, should be the Y location of the bird, the X location of the closest pipe, the Y location of the top pipe, and the Y location of the bottom pipe. How many inputs is that? Four. So I'm going to have one, two, three, four inputs, and one output. So I've decided how many inputs and how many outputs. So now the other question is, how many hidden nodes should I have? To be honest, this isn't a very complicated problem. This might work with just one hidden node. It might work with no hidden layer at all, even in fact. It might work with just two of these inputs and be able to figure it out. But let's just decide that we're also going to use four, just for the sake of having some hidden nodes. We can experiment, does it work better if I make 64 hidden, or four, or eight? Trial and error is your friend in machine learning systems. Okay, so now, this is now the diagram of the neural network. I must sit here and connect all of the various lines. All right, so the inputs come in here, and the output comes in here. Four inputs, four hidden, one output. If you want to learn more about how a neural network works, all of the internals that are going on here, what all these connections are in the weights, I'll refer you back to my neural network tutorial series. But this is pretty similar also to what I did in the color predictor. There were three inputs and two outputs, I can't remember. All right, so now we've decided that I want to have four inputs, four hidden nodes, and one output. So we now have the brain of our bird. And then, in update, the bird is going to decide, oh, this is more complicated than I thought. Let's write a new function. Let's write a function called think. So in think, basically what I want to do is I want to say, let the output equal this.brain.predict, and I want to send in the inputs. So, for example, the inputs have to be an array of four numbers. Right, so they would look something like this. I'm going to put them in there, and then I'm just going to say, and if the output is greater than.5, then this.up, right? So this is the idea here, that the neural network library that I'm using has a function called predict. When I call that function, I send in the inputs. The inputs go feed through, times the weights, summed activation function, times the weights, summed activation function, I get the output. And based on that output, if it's greater than.5, the bird jumps, if it's less than.5, the bird doesn't do anything. But this is no good here, right? This is just me, let's just see if this works though. I mean, these are hard-coded inputs that never change, that's not what I want, but let's just at least see if I don't get any errors. So I'm going to in here now, I'm going to add something. I'm going to say bird.think, and I'm going to run the sketch again. Oh, look at that, it's thinking, it's jumping, right? It decided, every time, it's basically always going to be up at the top or at the bottom, right? Because it's getting the same inputs over and over again. Now what I need to do is actually make inputs out of these values, these values. It's y position, top, bottom, and the x position of the pipe. Okay, let's do that. So now, I'm going to say, back in the bird, back in the bird, I'm going to say, let inputs equal an empty array. I'm going to say inputs zero is this bird's y position, y position, inputs one is, oh boy, okay, here's the problem now. I need to know about the pipes. So I am a bird, and I need to know about the pipes. How do I do that? So maybe what I'll do is I'll take in, as an argument to this function, I will take in the pipes array. So that is sent in to the think function. Now I'm going to go here, and I'm going to say, I'm just going to do pipes index zero. This is a bad idea, but let's just start with this. Pipes index zero, top. Inputs two equal pipes index zero, bottom. Inputs three equal pipes index zero, x. So this is the idea here. I want all of those things to be the inputs to the neural network. I don't need this anymore, right, because I am getting them from the properties at sync, and now let me run this and see what happens. Eh, it's kind of jumping all the time. All right, so this didn't really seem to, ooh, look, ooh, it's doing something. That one actually kind of almost did something. It's making some, its own decisions. That was very exciting. All right, well, I've got some problems here. Number one is, when I sort of made my pretend version of it, I purposely made numbers between zero and one. So one thing I should really do is normalize all these values. That's a pretty typical thing to sort of clean your data. So what I'm going to do is I'm going to say this.y divided by height. This.top divided by height. And the pipe's bottom divided by height, and the pipe's x divided by width. So let's do that. And oops, let's get rid of this now. You know, does this, nothing really different is going to happen here. Going to run this a bunch of times. Oh, it's doing something. Oh my god, it's making some decisions. Ooh, that was a good one, right? That was a pretty good one. All right, so you can see that it's doing something. It's trying to think. But I've got another problem. I don't know, is pipe zero the right pipe? I think I need to, I probably need an algorithm to check which pipe is actually the one closest. Let me remember, let me look at the main sketch. How do I add the pipes? Yeah, so first of all, the pipes are getting added to the end. And when did the, if the pipe goes off screen, it gets deleted from its spot, which would typically be the earliest one. So, it might work. But let's be smart about this. Let's actually, let's just say, this is probably overdoing it, but let's actually find the closest pipe. So I'm going to assume the closest pipe is pipes index zero. Then I am going to look at all of the pipes, starting with one. And I'm going to say, oh, actually, you know what? Let's do this. And I want closest different, closest d being the closest distance to be the absolute value of this.x minus closest.x. Okay, then I'm going to say, let d equal, we can start with one here. Absolute value of this.x minus closest, closest.x. And if d is less than closest d, then the closest is that particular pipe. And the closest d is that new distance. So this is a little quick algorithm. Find the closest pipe. Here's the thing, though. I don't want a pipe if it's gone behind me already. That one shouldn't matter. I got an idea. Let's get rid of that absolute value thing. Right? Because as long as the distance, so what I can do, okay, the pipe's x minus my x, it's positive if it's over here, and I want that to be a lower, lower number, but I don't want it to be negative. So as long as d is less than closest d and d is greater than zero, then we're fine. But what if this is negative? But it wouldn't be at the beginning. Okay, a couple mistakes here. One is this should be pipe's index i. I'm going to change this to say closest is null, and the closest distance is infinity. I love that you can type infinity in JavaScript and it knows what that is somehow. If that's a number it could store in memory. But what I'm actually going to do here, I think this will work now, and then I can start with zero. So as long as it is in front of it, that's the closest one. So now I can say instead of pipe's index zero, I'm going to say closest down here. I'm going to say closest here and closest here, and here we go. Now we are ready. Oh, cannot read property top of null. All right, so what's going on here? Oops, so the way I program this, I've got to say pipe's, because I took out the absolute value, I've got to say pipe's index i minus this.x, right? Because I want it to be positive, like the pipe, pipe, pipe, pipe, pipe, and then it goes past it. Okay, this should be fine now. Or not. Oh, dot x, dot x, pipe's index i dot x. Okay, there we go. So I can do this a bunch of times, and we can see I'm going to get a bunch of random birds that are doing sort of random things. All right, I think this is going to be a multi-parter coding challenge. I am now wrapping up the end of this first part, because just to summarize, what have I done so far? I have built a system where I have the game Flappy Bird, I have developed a neural network architecture for the bird to read in the state, sort of evaluate the state of the game, make a guess as to what it should do, should it jump up, should it not, based on that, and then I have put that into motion. That neural network is part of the bird object now. It has a brain, 441, and then it has a think function which sends the data about the game into the neural network and decides to go up or not. Now what I need to do is actually implement the neuroevolution part. So I've implemented the neuro part. I designed a way for the bird to make a decision based on how it's evaluating the scene, and what I need to do now is make a population of them and try them all and evolve them over time. So I'm going to take a little break here. I'm going to meditate for a minute on how much my brain doesn't work as well as a simple multilayered perceptron, and I will be back in the next video to actually implement the genetic algorithm part. Thank you for tuning in and being on this journey with me. ♪♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T20:41:49.384915Z",
  "started_at": "2023-09-26T20:52:45.654795Z",
  "completed_at": "2023-09-26T20:59:39.676405Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=c6y21FkaUqw",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 414.02161
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/7kj6txbbpg265sfjlzuoli353u/cancel",
    "get": "https://api.replicate.com/v1/predictions/7kj6txbbpg265sfjlzuoli353u"
  }
}